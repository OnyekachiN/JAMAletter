"","journal","pvalue","pubmedID","year","abstract","title"
"1","Lancet.8","0.01",10675115,2000,"For the surgical treatment of gastrooesophageal reflux disease (GORD), laparoscopic Nissen fundoplication has largely replaced the open procedure. Retrospective and prospective non-randomised studies have shown similar results after laparoscopic Nissen fundoplication compared with the open procedure.In a multicentre randomised trial candidates for surgical treatment of GORD were randomly assigned to either laparoscopic or open 360 degrees Nissen fundoplication. Primary endpoints were dysphagia, recurrent GORD, and intrathoracic hernia. Secondary endpoints were effectiveness and quality of life. This planned interim analysis focuses on endpoints and complications and in-hospital costs.At the time of interim analysis, 11 patients in the laparoscopic group and one in the conventional group had reached a primary endpoint (p=0.01; relative risk=8.8, 95% CI 1.2-66.3). This difference was caused mainly by whether or not patients had dysphagia (seven patients in the laparoscopic group and none in the conventional group, p=0.016).Although laparoscopic Nissen fundoplication was as effective as the open procedure in controlling reflux, the significantly higher risk of reaching a primary endpoint in the laparoscopic group led us to stop the study.","Laparoscopic or conventional Nissen fundoplication for gastro-oesophageal reflux disease: randomised clinical trial. The Netherlands Antireflux Surgery Study Group."
"2","JAMA.31","NA",10770148,2000,"Health plan utilization review rules are intended to enforce insurance contracts and can alter and constrain the services that physicians provide to their patients. Physicians can manipulate these rules, but how often they do so is unknown.To determine the frequency with which physicians manipulate reimbursement rules to obtain coverage for services they perceive as necessary, and the physician attitudes and personal and practice characteristics associated with these manipulations.A random national sample of 1124 practicing physicians was surveyed by mail in 1998; the response rate was 64% (n = 720).Use of 3 different tactics ""sometimes"" or more often in the last year: (1) exaggerating the severity of patients' conditions; (2) changing patients' billing diagnoses; and/or (3) reporting signs or symptoms that patients did not have to help the patients secure coverage for needed care.Thirty-nine percent of physicians reported using at least 1 tactic ""sometimes"" or more often in the last year. In multivariate models comparing these physicians with physicians who ""never"" or ""rarely"" used any of these tactics, physicians using these tactics were more likely to (1) believe that ""gaming the system"" is necessary to provide high-quality care today (odds ratio [OR], 3.67; 95% confidence interval [CI], 2.54-5.29); (2) have received requests from patients to deceive insurers (OR, 2.44; 95% CI, 1.72-3.45); (3) feel pressed for time during patient visits (OR, 1.69; 95% CI, 1.21-2.37); and (4) have more than 25% of their patients covered by Medicaid (OR, 1.60; 95% CI, 1.08-2.38). Notably, greater worry about prosecution for fraud did not affect physicians' use of these tactics (P = .34). Of those reporting using these tactics, 54% reported doing so more often now than 5 years ago.A sizable minority of physicians report manipulating reimbursement rules so patients can receive care that physicians perceive is necessary. Unless novel strategies are developed to address this, greater utilization restrictions in the health care system are likely to increase physicians' use of such manipulative ""covert advocacy"" tactics.","Physician manipulation of reimbursement rules for patients: between a rock and a hard place."
"3","JAMA.31","NA",10770148,2000,"Health plan utilization review rules are intended to enforce insurance contracts and can alter and constrain the services that physicians provide to their patients. Physicians can manipulate these rules, but how often they do so is unknown.To determine the frequency with which physicians manipulate reimbursement rules to obtain coverage for services they perceive as necessary, and the physician attitudes and personal and practice characteristics associated with these manipulations.A random national sample of 1124 practicing physicians was surveyed by mail in 1998; the response rate was 64% (n = 720).Use of 3 different tactics ""sometimes"" or more often in the last year: (1) exaggerating the severity of patients' conditions; (2) changing patients' billing diagnoses; and/or (3) reporting signs or symptoms that patients did not have to help the patients secure coverage for needed care.Thirty-nine percent of physicians reported using at least 1 tactic ""sometimes"" or more often in the last year. In multivariate models comparing these physicians with physicians who ""never"" or ""rarely"" used any of these tactics, physicians using these tactics were more likely to (1) believe that ""gaming the system"" is necessary to provide high-quality care today (odds ratio [OR], 3.67; 95% confidence interval [CI], 2.54-5.29); (2) have received requests from patients to deceive insurers (OR, 2.44; 95% CI, 1.72-3.45); (3) feel pressed for time during patient visits (OR, 1.69; 95% CI, 1.21-2.37); and (4) have more than 25% of their patients covered by Medicaid (OR, 1.60; 95% CI, 1.08-2.38). Notably, greater worry about prosecution for fraud did not affect physicians' use of these tactics (P = .34). Of those reporting using these tactics, 54% reported doing so more often now than 5 years ago.A sizable minority of physicians report manipulating reimbursement rules so patients can receive care that physicians perceive is necessary. Unless novel strategies are developed to address this, greater utilization restrictions in the health care system are likely to increase physicians' use of such manipulative ""covert advocacy"" tactics.","Physician manipulation of reimbursement rules for patients: between a rock and a hard place."
"4","JAMA.31","NA",10770148,2000,"Health plan utilization review rules are intended to enforce insurance contracts and can alter and constrain the services that physicians provide to their patients. Physicians can manipulate these rules, but how often they do so is unknown.To determine the frequency with which physicians manipulate reimbursement rules to obtain coverage for services they perceive as necessary, and the physician attitudes and personal and practice characteristics associated with these manipulations.A random national sample of 1124 practicing physicians was surveyed by mail in 1998; the response rate was 64% (n = 720).Use of 3 different tactics ""sometimes"" or more often in the last year: (1) exaggerating the severity of patients' conditions; (2) changing patients' billing diagnoses; and/or (3) reporting signs or symptoms that patients did not have to help the patients secure coverage for needed care.Thirty-nine percent of physicians reported using at least 1 tactic ""sometimes"" or more often in the last year. In multivariate models comparing these physicians with physicians who ""never"" or ""rarely"" used any of these tactics, physicians using these tactics were more likely to (1) believe that ""gaming the system"" is necessary to provide high-quality care today (odds ratio [OR], 3.67; 95% confidence interval [CI], 2.54-5.29); (2) have received requests from patients to deceive insurers (OR, 2.44; 95% CI, 1.72-3.45); (3) feel pressed for time during patient visits (OR, 1.69; 95% CI, 1.21-2.37); and (4) have more than 25% of their patients covered by Medicaid (OR, 1.60; 95% CI, 1.08-2.38). Notably, greater worry about prosecution for fraud did not affect physicians' use of these tactics (P = .34). Of those reporting using these tactics, 54% reported doing so more often now than 5 years ago.A sizable minority of physicians report manipulating reimbursement rules so patients can receive care that physicians perceive is necessary. Unless novel strategies are developed to address this, greater utilization restrictions in the health care system are likely to increase physicians' use of such manipulative ""covert advocacy"" tactics.","Physician manipulation of reimbursement rules for patients: between a rock and a hard place."
"5","JAMA.31","NA",10770148,2000,"Health plan utilization review rules are intended to enforce insurance contracts and can alter and constrain the services that physicians provide to their patients. Physicians can manipulate these rules, but how often they do so is unknown.To determine the frequency with which physicians manipulate reimbursement rules to obtain coverage for services they perceive as necessary, and the physician attitudes and personal and practice characteristics associated with these manipulations.A random national sample of 1124 practicing physicians was surveyed by mail in 1998; the response rate was 64% (n = 720).Use of 3 different tactics ""sometimes"" or more often in the last year: (1) exaggerating the severity of patients' conditions; (2) changing patients' billing diagnoses; and/or (3) reporting signs or symptoms that patients did not have to help the patients secure coverage for needed care.Thirty-nine percent of physicians reported using at least 1 tactic ""sometimes"" or more often in the last year. In multivariate models comparing these physicians with physicians who ""never"" or ""rarely"" used any of these tactics, physicians using these tactics were more likely to (1) believe that ""gaming the system"" is necessary to provide high-quality care today (odds ratio [OR], 3.67; 95% confidence interval [CI], 2.54-5.29); (2) have received requests from patients to deceive insurers (OR, 2.44; 95% CI, 1.72-3.45); (3) feel pressed for time during patient visits (OR, 1.69; 95% CI, 1.21-2.37); and (4) have more than 25% of their patients covered by Medicaid (OR, 1.60; 95% CI, 1.08-2.38). Notably, greater worry about prosecution for fraud did not affect physicians' use of these tactics (P = .34). Of those reporting using these tactics, 54% reported doing so more often now than 5 years ago.A sizable minority of physicians report manipulating reimbursement rules so patients can receive care that physicians perceive is necessary. Unless novel strategies are developed to address this, greater utilization restrictions in the health care system are likely to increase physicians' use of such manipulative ""covert advocacy"" tactics.","Physician manipulation of reimbursement rules for patients: between a rock and a hard place."
"6","JAMA.11","0.001",10819949,2000,"Multidrug-resistant Salmonella serotype Typhi infections have been reported worldwide, but data on the incidence of resistant strains in the United States are lacking.To determine the incidence of antimicrobial-resistant Salmonella Typhi infections and to identify risk factors for infection.Cross-sectional laboratory-based surveillance study.A total of 293 persons with symptomatic typhoid fever who had Salmonella Typhi isolates and epidemiological information submitted to US public health departments and laboratories from June 1, 1996, to May 31, 1997.Proportion of Salmonella Typhi isolates demonstrating resistance to 12 antimicrobial agents; patient epidemiological factors associated with drug-resistant infections.Median age was 21 years (range, 3 months to 84 years); 56% were male. Two hundred twenty-eight (80%) were hospitalized; 2 died. In the 6 weeks before illness onset, 81% of patients had traveled abroad. Seventy-four Salmonella Typhi isolates (25%) were resistant to 1 or more antimicrobial agent, and 51 (17%) were resistant to 5 or more agents, including ampicillin, chloramphenicol, and trimethoprim-sulfamethoxazole (multidrug-resistant Salmonella Typhi [MDRST]). Although no resistance to ciprofloxacin or ceftriaxone was observed, 20 isolates (7%) were nalidixic acid-resistant (NARST). Patients with MDRST and NARST infections were more likely to report travel outside the United States, particularly to the Indian subcontinent (Bangladesh, India, and Pakistan) (odds ratio [OR], 29.3; 95% confidence interval [CI], 6.8-126.7; P<.001 and OR, 35.9; 95% CI, 3.4-377.3; P<.001, respectively).Our data suggest that ciprofloxacin and ceftriaxone are appropriate empirical therapy for suspected typhoid fever; however, resistance may be anticipated. Continued monitoring of antimicrobial resistance among Salmonella Typhi strains will help determine vaccination and treatment policies. JAMA. 2000;283:2668-2673.","Laboratory-based surveillance of Salmonella serotype Typhi infections in the United States: antimicrobial resistance on the rise."
"7","JAMA.12","0.001",10819949,2000,"Multidrug-resistant Salmonella serotype Typhi infections have been reported worldwide, but data on the incidence of resistant strains in the United States are lacking.To determine the incidence of antimicrobial-resistant Salmonella Typhi infections and to identify risk factors for infection.Cross-sectional laboratory-based surveillance study.A total of 293 persons with symptomatic typhoid fever who had Salmonella Typhi isolates and epidemiological information submitted to US public health departments and laboratories from June 1, 1996, to May 31, 1997.Proportion of Salmonella Typhi isolates demonstrating resistance to 12 antimicrobial agents; patient epidemiological factors associated with drug-resistant infections.Median age was 21 years (range, 3 months to 84 years); 56% were male. Two hundred twenty-eight (80%) were hospitalized; 2 died. In the 6 weeks before illness onset, 81% of patients had traveled abroad. Seventy-four Salmonella Typhi isolates (25%) were resistant to 1 or more antimicrobial agent, and 51 (17%) were resistant to 5 or more agents, including ampicillin, chloramphenicol, and trimethoprim-sulfamethoxazole (multidrug-resistant Salmonella Typhi [MDRST]). Although no resistance to ciprofloxacin or ceftriaxone was observed, 20 isolates (7%) were nalidixic acid-resistant (NARST). Patients with MDRST and NARST infections were more likely to report travel outside the United States, particularly to the Indian subcontinent (Bangladesh, India, and Pakistan) (odds ratio [OR], 29.3; 95% confidence interval [CI], 6.8-126.7; P<.001 and OR, 35.9; 95% CI, 3.4-377.3; P<.001, respectively).Our data suggest that ciprofloxacin and ceftriaxone are appropriate empirical therapy for suspected typhoid fever; however, resistance may be anticipated. Continued monitoring of antimicrobial resistance among Salmonella Typhi strains will help determine vaccination and treatment policies. JAMA. 2000;283:2668-2673.","Laboratory-based surveillance of Salmonella serotype Typhi infections in the United States: antimicrobial resistance on the rise."
"8","JAMA.10","NA",10838652,2000,"Approximately 10 million cars with automatic shoulder belt systems are currently in use in the United States. However, reports on the effectiveness of such restraints have yielded conflicting results.To determine the effectiveness of automatic shoulder belt systems in reducing the risk of injury and death among front-seat passenger vehicle occupants.Analysis of data collected from the 1993-1996 National Highway Traffic Safety Administration Crashworthiness Data System on front-seat occupants involved in 25,811 tow-away crashes of passenger cars, light trucks, vans, and sport utility vehicles.Death and serious injury to specific body areas by use of manual lap and shoulder belts, automatic shoulder belts with manual lap belts, or automatic shoulder belts without lap belts, compared with no restraint use.Use of automatic shoulder belts without lap belts was associated with a decrease in the risk of death vs no restraint use but was not statistically significant for all crashes (odds ratio [OR], 0.66; 95% confidence interval [CI], 0.42-1.06) or for frontal crashes (OR, 0.71; 95% CI, 0.38-1.35) after adjustment for occupant age, sex, vehicle year, air-bag deployment, estimated change in vehicle speed during the crash, and principal direction of force. This association was significantly weaker than the 86% lower risk observed for use of automatic shoulder belts with lap belts (OR, 0.14; 95% CI, 0.07-0.26 vs no restraint; P<.05). Use of automatic shoulder belts without lap belts was associated with an increased risk of serious chest (OR, 2.66; 95% CI, 1.11-6.35) and abdominal (OR, 2.06; 95% CI, 1.004-4.22) injuries for all crashes.These data indicate that improperly used automatic restraint systems may be less effective than properly used systems and are associated with an increased risk of serious chest and abdominal injuries. Given the continued widespread use of these automatic systems, educational programs may be warranted. JAMA. 2000;283:2826-2828","Effectiveness of automatic shoulder belt systems in motor vehicle crashes."
"9","JAMA.10","NA",10838652,2000,"Approximately 10 million cars with automatic shoulder belt systems are currently in use in the United States. However, reports on the effectiveness of such restraints have yielded conflicting results.To determine the effectiveness of automatic shoulder belt systems in reducing the risk of injury and death among front-seat passenger vehicle occupants.Analysis of data collected from the 1993-1996 National Highway Traffic Safety Administration Crashworthiness Data System on front-seat occupants involved in 25,811 tow-away crashes of passenger cars, light trucks, vans, and sport utility vehicles.Death and serious injury to specific body areas by use of manual lap and shoulder belts, automatic shoulder belts with manual lap belts, or automatic shoulder belts without lap belts, compared with no restraint use.Use of automatic shoulder belts without lap belts was associated with a decrease in the risk of death vs no restraint use but was not statistically significant for all crashes (odds ratio [OR], 0.66; 95% confidence interval [CI], 0.42-1.06) or for frontal crashes (OR, 0.71; 95% CI, 0.38-1.35) after adjustment for occupant age, sex, vehicle year, air-bag deployment, estimated change in vehicle speed during the crash, and principal direction of force. This association was significantly weaker than the 86% lower risk observed for use of automatic shoulder belts with lap belts (OR, 0.14; 95% CI, 0.07-0.26 vs no restraint; P<.05). Use of automatic shoulder belts without lap belts was associated with an increased risk of serious chest (OR, 2.66; 95% CI, 1.11-6.35) and abdominal (OR, 2.06; 95% CI, 1.004-4.22) injuries for all crashes.These data indicate that improperly used automatic restraint systems may be less effective than properly used systems and are associated with an increased risk of serious chest and abdominal injuries. Given the continued widespread use of these automatic systems, educational programs may be warranted. JAMA. 2000;283:2826-2828","Effectiveness of automatic shoulder belt systems in motor vehicle crashes."
"10","JAMA.10","0.05",10838652,2000,"Approximately 10 million cars with automatic shoulder belt systems are currently in use in the United States. However, reports on the effectiveness of such restraints have yielded conflicting results.To determine the effectiveness of automatic shoulder belt systems in reducing the risk of injury and death among front-seat passenger vehicle occupants.Analysis of data collected from the 1993-1996 National Highway Traffic Safety Administration Crashworthiness Data System on front-seat occupants involved in 25,811 tow-away crashes of passenger cars, light trucks, vans, and sport utility vehicles.Death and serious injury to specific body areas by use of manual lap and shoulder belts, automatic shoulder belts with manual lap belts, or automatic shoulder belts without lap belts, compared with no restraint use.Use of automatic shoulder belts without lap belts was associated with a decrease in the risk of death vs no restraint use but was not statistically significant for all crashes (odds ratio [OR], 0.66; 95% confidence interval [CI], 0.42-1.06) or for frontal crashes (OR, 0.71; 95% CI, 0.38-1.35) after adjustment for occupant age, sex, vehicle year, air-bag deployment, estimated change in vehicle speed during the crash, and principal direction of force. This association was significantly weaker than the 86% lower risk observed for use of automatic shoulder belts with lap belts (OR, 0.14; 95% CI, 0.07-0.26 vs no restraint; P<.05). Use of automatic shoulder belts without lap belts was associated with an increased risk of serious chest (OR, 2.66; 95% CI, 1.11-6.35) and abdominal (OR, 2.06; 95% CI, 1.004-4.22) injuries for all crashes.These data indicate that improperly used automatic restraint systems may be less effective than properly used systems and are associated with an increased risk of serious chest and abdominal injuries. Given the continued widespread use of these automatic systems, educational programs may be warranted. JAMA. 2000;283:2826-2828","Effectiveness of automatic shoulder belt systems in motor vehicle crashes."
"11","JAMA.10","0.05",10838652,2000,"Approximately 10 million cars with automatic shoulder belt systems are currently in use in the United States. However, reports on the effectiveness of such restraints have yielded conflicting results.To determine the effectiveness of automatic shoulder belt systems in reducing the risk of injury and death among front-seat passenger vehicle occupants.Analysis of data collected from the 1993-1996 National Highway Traffic Safety Administration Crashworthiness Data System on front-seat occupants involved in 25,811 tow-away crashes of passenger cars, light trucks, vans, and sport utility vehicles.Death and serious injury to specific body areas by use of manual lap and shoulder belts, automatic shoulder belts with manual lap belts, or automatic shoulder belts without lap belts, compared with no restraint use.Use of automatic shoulder belts without lap belts was associated with a decrease in the risk of death vs no restraint use but was not statistically significant for all crashes (odds ratio [OR], 0.66; 95% confidence interval [CI], 0.42-1.06) or for frontal crashes (OR, 0.71; 95% CI, 0.38-1.35) after adjustment for occupant age, sex, vehicle year, air-bag deployment, estimated change in vehicle speed during the crash, and principal direction of force. This association was significantly weaker than the 86% lower risk observed for use of automatic shoulder belts with lap belts (OR, 0.14; 95% CI, 0.07-0.26 vs no restraint; P<.05). Use of automatic shoulder belts without lap belts was associated with an increased risk of serious chest (OR, 2.66; 95% CI, 1.11-6.35) and abdominal (OR, 2.06; 95% CI, 1.004-4.22) injuries for all crashes.These data indicate that improperly used automatic restraint systems may be less effective than properly used systems and are associated with an increased risk of serious chest and abdominal injuries. Given the continued widespread use of these automatic systems, educational programs may be warranted. JAMA. 2000;283:2826-2828","Effectiveness of automatic shoulder belt systems in motor vehicle crashes."
"12","JAMA.10","0.05",10838652,2000,"Approximately 10 million cars with automatic shoulder belt systems are currently in use in the United States. However, reports on the effectiveness of such restraints have yielded conflicting results.To determine the effectiveness of automatic shoulder belt systems in reducing the risk of injury and death among front-seat passenger vehicle occupants.Analysis of data collected from the 1993-1996 National Highway Traffic Safety Administration Crashworthiness Data System on front-seat occupants involved in 25,811 tow-away crashes of passenger cars, light trucks, vans, and sport utility vehicles.Death and serious injury to specific body areas by use of manual lap and shoulder belts, automatic shoulder belts with manual lap belts, or automatic shoulder belts without lap belts, compared with no restraint use.Use of automatic shoulder belts without lap belts was associated with a decrease in the risk of death vs no restraint use but was not statistically significant for all crashes (odds ratio [OR], 0.66; 95% confidence interval [CI], 0.42-1.06) or for frontal crashes (OR, 0.71; 95% CI, 0.38-1.35) after adjustment for occupant age, sex, vehicle year, air-bag deployment, estimated change in vehicle speed during the crash, and principal direction of force. This association was significantly weaker than the 86% lower risk observed for use of automatic shoulder belts with lap belts (OR, 0.14; 95% CI, 0.07-0.26 vs no restraint; P<.05). Use of automatic shoulder belts without lap belts was associated with an increased risk of serious chest (OR, 2.66; 95% CI, 1.11-6.35) and abdominal (OR, 2.06; 95% CI, 1.004-4.22) injuries for all crashes.These data indicate that improperly used automatic restraint systems may be less effective than properly used systems and are associated with an increased risk of serious chest and abdominal injuries. Given the continued widespread use of these automatic systems, educational programs may be warranted. JAMA. 2000;283:2826-2828","Effectiveness of automatic shoulder belt systems in motor vehicle crashes."
"13","Lancet","1.00E-04",10859038,2000,"In acute coronary syndrome without ST elevation, the role of unfractionated and low-molecular-weight heparin in aspirin-treated patients remains unclear, and there is conflicting evidence regarding the efficacy and safety of low-molecular-weight heparin (LMWH) relative to unfractionated heparin. We did a systematic overview of the randomised trials to assess the effect of unfractionated heparin and LMWH on death, myocardial infarction, and major bleeding.Randomised trials comparing unfractionated heparin or LMWH with placebo or untreated control, or comparing unfractionated heparin with LMWH, for the short-term and long-term management of patients with acute coronary syndrome without ST elevation, were identified by electronic and manual searches and through contact with experts and industry representatives. Odds ratios for death, myocardial infarction, and major bleeding were calculated for each trial, and results for the individual trials were combined by a modification of the Mantel-Haenszel method.12 trials, involving a total of 17157 patients, were included. The summary odds ratio (OR) for myocardial infarction or death during short-term (up to 7 days) unfractionated heparin or LMWH compared with placebo or untreated control was 0.53 (95% CI 0.38-0.73; p=0.0001) or 29 events prevented per 1000 patients treated; during short-term LMWH compared with unfractionated heparin was 0.88 (0.69-1.12; p=0.34); and during long-term LMWH (up to 3 months) compared with placebo or untreated control was 0.98 (0.81-1.17; p=0.80). Long-term LMWH was associated with a significantly increased risk of major bleeding (OR 2.26, [95% CI 1.63-3.14], p<0.0001), which is equivalent to 12 major bleeds per 1000 patients treated.In aspirin-treated patients with acute coronary syndrome without ST elevation, short-term unfractionated heparin or LMWH halves the risk of myocardial infarction or death. There is no convincing difference in efficacy or safety between LMWH and unfractionated heparin. Long-term LMWH has not been proven to confer benefit additional to aspirin and there is no evidence to support its use after the first 7 days.","Unfractionated heparin and low-molecular-weight heparin in acute coronary syndrome without ST elevation: a meta-analysis."
"14","Lancet.5","1.00E-04",10859038,2000,"In acute coronary syndrome without ST elevation, the role of unfractionated and low-molecular-weight heparin in aspirin-treated patients remains unclear, and there is conflicting evidence regarding the efficacy and safety of low-molecular-weight heparin (LMWH) relative to unfractionated heparin. We did a systematic overview of the randomised trials to assess the effect of unfractionated heparin and LMWH on death, myocardial infarction, and major bleeding.Randomised trials comparing unfractionated heparin or LMWH with placebo or untreated control, or comparing unfractionated heparin with LMWH, for the short-term and long-term management of patients with acute coronary syndrome without ST elevation, were identified by electronic and manual searches and through contact with experts and industry representatives. Odds ratios for death, myocardial infarction, and major bleeding were calculated for each trial, and results for the individual trials were combined by a modification of the Mantel-Haenszel method.12 trials, involving a total of 17157 patients, were included. The summary odds ratio (OR) for myocardial infarction or death during short-term (up to 7 days) unfractionated heparin or LMWH compared with placebo or untreated control was 0.53 (95% CI 0.38-0.73; p=0.0001) or 29 events prevented per 1000 patients treated; during short-term LMWH compared with unfractionated heparin was 0.88 (0.69-1.12; p=0.34); and during long-term LMWH (up to 3 months) compared with placebo or untreated control was 0.98 (0.81-1.17; p=0.80). Long-term LMWH was associated with a significantly increased risk of major bleeding (OR 2.26, [95% CI 1.63-3.14], p<0.0001), which is equivalent to 12 major bleeds per 1000 patients treated.In aspirin-treated patients with acute coronary syndrome without ST elevation, short-term unfractionated heparin or LMWH halves the risk of myocardial infarction or death. There is no convincing difference in efficacy or safety between LMWH and unfractionated heparin. Long-term LMWH has not been proven to confer benefit additional to aspirin and there is no evidence to support its use after the first 7 days.","Unfractionated heparin and low-molecular-weight heparin in acute coronary syndrome without ST elevation: a meta-analysis."
"15","Lancet.6","0.34",10859038,2000,"In acute coronary syndrome without ST elevation, the role of unfractionated and low-molecular-weight heparin in aspirin-treated patients remains unclear, and there is conflicting evidence regarding the efficacy and safety of low-molecular-weight heparin (LMWH) relative to unfractionated heparin. We did a systematic overview of the randomised trials to assess the effect of unfractionated heparin and LMWH on death, myocardial infarction, and major bleeding.Randomised trials comparing unfractionated heparin or LMWH with placebo or untreated control, or comparing unfractionated heparin with LMWH, for the short-term and long-term management of patients with acute coronary syndrome without ST elevation, were identified by electronic and manual searches and through contact with experts and industry representatives. Odds ratios for death, myocardial infarction, and major bleeding were calculated for each trial, and results for the individual trials were combined by a modification of the Mantel-Haenszel method.12 trials, involving a total of 17157 patients, were included. The summary odds ratio (OR) for myocardial infarction or death during short-term (up to 7 days) unfractionated heparin or LMWH compared with placebo or untreated control was 0.53 (95% CI 0.38-0.73; p=0.0001) or 29 events prevented per 1000 patients treated; during short-term LMWH compared with unfractionated heparin was 0.88 (0.69-1.12; p=0.34); and during long-term LMWH (up to 3 months) compared with placebo or untreated control was 0.98 (0.81-1.17; p=0.80). Long-term LMWH was associated with a significantly increased risk of major bleeding (OR 2.26, [95% CI 1.63-3.14], p<0.0001), which is equivalent to 12 major bleeds per 1000 patients treated.In aspirin-treated patients with acute coronary syndrome without ST elevation, short-term unfractionated heparin or LMWH halves the risk of myocardial infarction or death. There is no convincing difference in efficacy or safety between LMWH and unfractionated heparin. Long-term LMWH has not been proven to confer benefit additional to aspirin and there is no evidence to support its use after the first 7 days.","Unfractionated heparin and low-molecular-weight heparin in acute coronary syndrome without ST elevation: a meta-analysis."
"16","Lancet.7","0.8",10859038,2000,"In acute coronary syndrome without ST elevation, the role of unfractionated and low-molecular-weight heparin in aspirin-treated patients remains unclear, and there is conflicting evidence regarding the efficacy and safety of low-molecular-weight heparin (LMWH) relative to unfractionated heparin. We did a systematic overview of the randomised trials to assess the effect of unfractionated heparin and LMWH on death, myocardial infarction, and major bleeding.Randomised trials comparing unfractionated heparin or LMWH with placebo or untreated control, or comparing unfractionated heparin with LMWH, for the short-term and long-term management of patients with acute coronary syndrome without ST elevation, were identified by electronic and manual searches and through contact with experts and industry representatives. Odds ratios for death, myocardial infarction, and major bleeding were calculated for each trial, and results for the individual trials were combined by a modification of the Mantel-Haenszel method.12 trials, involving a total of 17157 patients, were included. The summary odds ratio (OR) for myocardial infarction or death during short-term (up to 7 days) unfractionated heparin or LMWH compared with placebo or untreated control was 0.53 (95% CI 0.38-0.73; p=0.0001) or 29 events prevented per 1000 patients treated; during short-term LMWH compared with unfractionated heparin was 0.88 (0.69-1.12; p=0.34); and during long-term LMWH (up to 3 months) compared with placebo or untreated control was 0.98 (0.81-1.17; p=0.80). Long-term LMWH was associated with a significantly increased risk of major bleeding (OR 2.26, [95% CI 1.63-3.14], p<0.0001), which is equivalent to 12 major bleeds per 1000 patients treated.In aspirin-treated patients with acute coronary syndrome without ST elevation, short-term unfractionated heparin or LMWH halves the risk of myocardial infarction or death. There is no convincing difference in efficacy or safety between LMWH and unfractionated heparin. Long-term LMWH has not been proven to confer benefit additional to aspirin and there is no evidence to support its use after the first 7 days.","Unfractionated heparin and low-molecular-weight heparin in acute coronary syndrome without ST elevation: a meta-analysis."
"17","JAMA.8","0.01",10865271,2000,"Rapid time to treatment with thrombolytic therapy is associated with lower mortality in patients with acute myocardial infarction (MI). However, data on time to primary angioplasty and its relationship to mortality are inconclusive.To test the hypothesis that more rapid time to reperfusion results in lower mortality in the strategy of primary angioplasty.Prospective observational study of data collected from the Second National Registry of Myocardial Infarction between June 1994 and March 1998.A total of 661 community and tertiary care hospitals in the United States.A cohort of 27,080 consecutive patients with acute MI associated with ST-segment elevation or left bundle-branch block who were treated with primary angioplasty.In-hospital mortality, compared by time from acute MI symptom onset to first balloon inflation and by time from hospital arrival to first balloon inflation (door-to-balloon time).Using a multivariate logistic regression model, the adjusted odds of in-hospital mortality did not increase significantly with increasing delay from MI symptom onset to first balloon inflation. However, for door-to-balloon time (median time 1 hour 56 minutes), the adjusted odds of mortality were significantly increased by 41% to 62% for patients with door-to-balloon times longer than 2 hours (for 121-150 minutes: odds ratio [OR], 1.41; 95% confidence interval [CI], 1.08-1.84; P=.01; for 151-180 minutes: OR, 1.62; 95% CI, 1.23-2.14; P<.001; and for >180 minutes: OR, 1.61; 95% CI, 1.25-2.08; P<.001).The relationship in our study between increased mortality and delay in door-to-balloon time longer than 2 hours (present in nearly 50% of this cohort) suggests that physicians and health care systems should work to minimize door-to-balloon times and that door-to-balloon time should be considered when choosing a reperfusion strategy. Door-to-balloon time also appears to be a valid quality-of-care indicator. JAMA. 2000.","Relationship of symptom-onset-to-balloon time and door-to-balloon time with mortality in patients undergoing angioplasty for acute myocardial infarction."
"18","JAMA.9","0.001",10865271,2000,"Rapid time to treatment with thrombolytic therapy is associated with lower mortality in patients with acute myocardial infarction (MI). However, data on time to primary angioplasty and its relationship to mortality are inconclusive.To test the hypothesis that more rapid time to reperfusion results in lower mortality in the strategy of primary angioplasty.Prospective observational study of data collected from the Second National Registry of Myocardial Infarction between June 1994 and March 1998.A total of 661 community and tertiary care hospitals in the United States.A cohort of 27,080 consecutive patients with acute MI associated with ST-segment elevation or left bundle-branch block who were treated with primary angioplasty.In-hospital mortality, compared by time from acute MI symptom onset to first balloon inflation and by time from hospital arrival to first balloon inflation (door-to-balloon time).Using a multivariate logistic regression model, the adjusted odds of in-hospital mortality did not increase significantly with increasing delay from MI symptom onset to first balloon inflation. However, for door-to-balloon time (median time 1 hour 56 minutes), the adjusted odds of mortality were significantly increased by 41% to 62% for patients with door-to-balloon times longer than 2 hours (for 121-150 minutes: odds ratio [OR], 1.41; 95% confidence interval [CI], 1.08-1.84; P=.01; for 151-180 minutes: OR, 1.62; 95% CI, 1.23-2.14; P<.001; and for >180 minutes: OR, 1.61; 95% CI, 1.25-2.08; P<.001).The relationship in our study between increased mortality and delay in door-to-balloon time longer than 2 hours (present in nearly 50% of this cohort) suggests that physicians and health care systems should work to minimize door-to-balloon times and that door-to-balloon time should be considered when choosing a reperfusion strategy. Door-to-balloon time also appears to be a valid quality-of-care indicator. JAMA. 2000.","Relationship of symptom-onset-to-balloon time and door-to-balloon time with mortality in patients undergoing angioplasty for acute myocardial infarction."
"19","JAMA.9","0.001",10865271,2000,"Rapid time to treatment with thrombolytic therapy is associated with lower mortality in patients with acute myocardial infarction (MI). However, data on time to primary angioplasty and its relationship to mortality are inconclusive.To test the hypothesis that more rapid time to reperfusion results in lower mortality in the strategy of primary angioplasty.Prospective observational study of data collected from the Second National Registry of Myocardial Infarction between June 1994 and March 1998.A total of 661 community and tertiary care hospitals in the United States.A cohort of 27,080 consecutive patients with acute MI associated with ST-segment elevation or left bundle-branch block who were treated with primary angioplasty.In-hospital mortality, compared by time from acute MI symptom onset to first balloon inflation and by time from hospital arrival to first balloon inflation (door-to-balloon time).Using a multivariate logistic regression model, the adjusted odds of in-hospital mortality did not increase significantly with increasing delay from MI symptom onset to first balloon inflation. However, for door-to-balloon time (median time 1 hour 56 minutes), the adjusted odds of mortality were significantly increased by 41% to 62% for patients with door-to-balloon times longer than 2 hours (for 121-150 minutes: odds ratio [OR], 1.41; 95% confidence interval [CI], 1.08-1.84; P=.01; for 151-180 minutes: OR, 1.62; 95% CI, 1.23-2.14; P<.001; and for >180 minutes: OR, 1.61; 95% CI, 1.25-2.08; P<.001).The relationship in our study between increased mortality and delay in door-to-balloon time longer than 2 hours (present in nearly 50% of this cohort) suggests that physicians and health care systems should work to minimize door-to-balloon times and that door-to-balloon time should be considered when choosing a reperfusion strategy. Door-to-balloon time also appears to be a valid quality-of-care indicator. JAMA. 2000.","Relationship of symptom-onset-to-balloon time and door-to-balloon time with mortality in patients undergoing angioplasty for acute myocardial infarction."
"20","JAMA.5","0.001",10904509,2000,"Previous studies have yielded conflicting data regarding whether a relationship exists between elevated cardiac troponin levels and acute allograft rejection in patients who have received heart transplants.To determine whether cardiac troponin I levels after heart transplantation were associated with a procoagulant microvasculature and long-term allograft outcome.Prospective cohort study with a mean (SE) follow-up of 45.1 (2.5) months. Serum troponin I levels were measured 9.9 (0.2) times per patient during the first 12 months after heart transplantation.Heart transplant center in the United States.A total of 110 consecutive patients who received a heart transplant between 1989 and 1997 and survived at least 1 year after transplantation.Histological and immunohistochemical biopsy findings, development of coronary artery disease (CAD), and graft failure in patients with vs without elevated serum cardiac troponin I levels.All recipients had elevated troponin I levels during the first month after transplantation. Troponin I levels remained persistently elevated during the first 12 months in 56 patients (51%) and became undetectable in 54 patients (49%). Persistently elevated troponin I levels were associated with increasing fibrin deposits in microvasculature and cardiomyocytes (P<.001). Patients with persistently elevated levels of troponin I had significantly increased risk for subsequent development of CAD (odds ratio [OR], 4. 3; 95% confidence interval [CI], 1.8-10.1; P<.001) and graft failure (OR, 3.4; 95% CI, 1.2-9.7; P =.02), and also developed more severe CAD (OR, 4.2; 95% CI, 1.9-9.3; P<.001) and showed more disease progression (OR, 3.7; 95% CI, 1.3-10.4; P =.009).In this study, elevated cardiac troponin I levels, which are considered to be a noninvasive surrogate marker of a procoagulant microvasculature, identified a subgroup of patients with high risk for developing CAD and graft failure after cardiac transplantation. JAMA. 2000;284:457-464","Cardiac-specific troponin I levels and risk of coronary artery disease and graft failure following heart transplantation."
"21","JAMA.6","0.02",10904509,2000,"Previous studies have yielded conflicting data regarding whether a relationship exists between elevated cardiac troponin levels and acute allograft rejection in patients who have received heart transplants.To determine whether cardiac troponin I levels after heart transplantation were associated with a procoagulant microvasculature and long-term allograft outcome.Prospective cohort study with a mean (SE) follow-up of 45.1 (2.5) months. Serum troponin I levels were measured 9.9 (0.2) times per patient during the first 12 months after heart transplantation.Heart transplant center in the United States.A total of 110 consecutive patients who received a heart transplant between 1989 and 1997 and survived at least 1 year after transplantation.Histological and immunohistochemical biopsy findings, development of coronary artery disease (CAD), and graft failure in patients with vs without elevated serum cardiac troponin I levels.All recipients had elevated troponin I levels during the first month after transplantation. Troponin I levels remained persistently elevated during the first 12 months in 56 patients (51%) and became undetectable in 54 patients (49%). Persistently elevated troponin I levels were associated with increasing fibrin deposits in microvasculature and cardiomyocytes (P<.001). Patients with persistently elevated levels of troponin I had significantly increased risk for subsequent development of CAD (odds ratio [OR], 4. 3; 95% confidence interval [CI], 1.8-10.1; P<.001) and graft failure (OR, 3.4; 95% CI, 1.2-9.7; P =.02), and also developed more severe CAD (OR, 4.2; 95% CI, 1.9-9.3; P<.001) and showed more disease progression (OR, 3.7; 95% CI, 1.3-10.4; P =.009).In this study, elevated cardiac troponin I levels, which are considered to be a noninvasive surrogate marker of a procoagulant microvasculature, identified a subgroup of patients with high risk for developing CAD and graft failure after cardiac transplantation. JAMA. 2000;284:457-464","Cardiac-specific troponin I levels and risk of coronary artery disease and graft failure following heart transplantation."
"22","JAMA.7","0.001",10904509,2000,"Previous studies have yielded conflicting data regarding whether a relationship exists between elevated cardiac troponin levels and acute allograft rejection in patients who have received heart transplants.To determine whether cardiac troponin I levels after heart transplantation were associated with a procoagulant microvasculature and long-term allograft outcome.Prospective cohort study with a mean (SE) follow-up of 45.1 (2.5) months. Serum troponin I levels were measured 9.9 (0.2) times per patient during the first 12 months after heart transplantation.Heart transplant center in the United States.A total of 110 consecutive patients who received a heart transplant between 1989 and 1997 and survived at least 1 year after transplantation.Histological and immunohistochemical biopsy findings, development of coronary artery disease (CAD), and graft failure in patients with vs without elevated serum cardiac troponin I levels.All recipients had elevated troponin I levels during the first month after transplantation. Troponin I levels remained persistently elevated during the first 12 months in 56 patients (51%) and became undetectable in 54 patients (49%). Persistently elevated troponin I levels were associated with increasing fibrin deposits in microvasculature and cardiomyocytes (P<.001). Patients with persistently elevated levels of troponin I had significantly increased risk for subsequent development of CAD (odds ratio [OR], 4. 3; 95% confidence interval [CI], 1.8-10.1; P<.001) and graft failure (OR, 3.4; 95% CI, 1.2-9.7; P =.02), and also developed more severe CAD (OR, 4.2; 95% CI, 1.9-9.3; P<.001) and showed more disease progression (OR, 3.7; 95% CI, 1.3-10.4; P =.009).In this study, elevated cardiac troponin I levels, which are considered to be a noninvasive surrogate marker of a procoagulant microvasculature, identified a subgroup of patients with high risk for developing CAD and graft failure after cardiac transplantation. JAMA. 2000;284:457-464","Cardiac-specific troponin I levels and risk of coronary artery disease and graft failure following heart transplantation."
"23","JAMA.7","0.009",10904509,2000,"Previous studies have yielded conflicting data regarding whether a relationship exists between elevated cardiac troponin levels and acute allograft rejection in patients who have received heart transplants.To determine whether cardiac troponin I levels after heart transplantation were associated with a procoagulant microvasculature and long-term allograft outcome.Prospective cohort study with a mean (SE) follow-up of 45.1 (2.5) months. Serum troponin I levels were measured 9.9 (0.2) times per patient during the first 12 months after heart transplantation.Heart transplant center in the United States.A total of 110 consecutive patients who received a heart transplant between 1989 and 1997 and survived at least 1 year after transplantation.Histological and immunohistochemical biopsy findings, development of coronary artery disease (CAD), and graft failure in patients with vs without elevated serum cardiac troponin I levels.All recipients had elevated troponin I levels during the first month after transplantation. Troponin I levels remained persistently elevated during the first 12 months in 56 patients (51%) and became undetectable in 54 patients (49%). Persistently elevated troponin I levels were associated with increasing fibrin deposits in microvasculature and cardiomyocytes (P<.001). Patients with persistently elevated levels of troponin I had significantly increased risk for subsequent development of CAD (odds ratio [OR], 4. 3; 95% confidence interval [CI], 1.8-10.1; P<.001) and graft failure (OR, 3.4; 95% CI, 1.2-9.7; P =.02), and also developed more severe CAD (OR, 4.2; 95% CI, 1.9-9.3; P<.001) and showed more disease progression (OR, 3.7; 95% CI, 1.3-10.4; P =.009).In this study, elevated cardiac troponin I levels, which are considered to be a noninvasive surrogate marker of a procoagulant microvasculature, identified a subgroup of patients with high risk for developing CAD and graft failure after cardiac transplantation. JAMA. 2000;284:457-464","Cardiac-specific troponin I levels and risk of coronary artery disease and graft failure following heart transplantation."
"24","American Journal of Epidemiology.6","NA",10905532,2000,"To better understand the etiology of recurrent urinary tract infection (UTI), the authors followed a cohort of 285 female college students with first UTI for 6 months or until second UTI. A first UTI due to Escherichia coli was followed by a second UTI three times more often than was a non-E. coli first UTI (24 vs. 8%; p = 0.02). In a logistic regression analysis limited to the 224 women from the University of Michigan Health Service and the University of Texas at Austin Health Service from September 1992 to December 1994, with a first UTI due to E. coli, vaginal intercourse increased the risk of a second UTI with both a different (odds ratio (OR) = 1.60, 95% confidence interval (CI): 1.19, 2.15) and the same (OR = 1.37, 95% CI: 0.91, 2.07) uropathogen, as did using a diaphragm, cervical cap, and/or spermicide (same uropathogen: OR = 1.53, 95% CI: 0.95, 2.47; different uropathogen: OR = 1.77, 95% CI: 1.22, 2.58). Condom use decreased the risk of a second UTI caused by a different uropathogen (OR = 0.68, 95% CI: 0.48, 0.99) but had no effect on a second UTI caused by the same E. coli (OR = 0.99; 95% CI: 0.66, 1.50). Type or duration of treatment was not associated with a second UTI. Although the risk of second UTI is strongly influenced by sexual behavior, women with a first UTI caused by E. coli are more likely than are those with a non-E. coli first UTI to have a second UTI within 6 months.","Risk factors for second urinary tract infection among college women."
"25","American Journal of Epidemiology.6","NA",10905532,2000,"To better understand the etiology of recurrent urinary tract infection (UTI), the authors followed a cohort of 285 female college students with first UTI for 6 months or until second UTI. A first UTI due to Escherichia coli was followed by a second UTI three times more often than was a non-E. coli first UTI (24 vs. 8%; p = 0.02). In a logistic regression analysis limited to the 224 women from the University of Michigan Health Service and the University of Texas at Austin Health Service from September 1992 to December 1994, with a first UTI due to E. coli, vaginal intercourse increased the risk of a second UTI with both a different (odds ratio (OR) = 1.60, 95% confidence interval (CI): 1.19, 2.15) and the same (OR = 1.37, 95% CI: 0.91, 2.07) uropathogen, as did using a diaphragm, cervical cap, and/or spermicide (same uropathogen: OR = 1.53, 95% CI: 0.95, 2.47; different uropathogen: OR = 1.77, 95% CI: 1.22, 2.58). Condom use decreased the risk of a second UTI caused by a different uropathogen (OR = 0.68, 95% CI: 0.48, 0.99) but had no effect on a second UTI caused by the same E. coli (OR = 0.99; 95% CI: 0.66, 1.50). Type or duration of treatment was not associated with a second UTI. Although the risk of second UTI is strongly influenced by sexual behavior, women with a first UTI caused by E. coli are more likely than are those with a non-E. coli first UTI to have a second UTI within 6 months.","Risk factors for second urinary tract infection among college women."
"26","American Journal of Epidemiology.6","NA",10905532,2000,"To better understand the etiology of recurrent urinary tract infection (UTI), the authors followed a cohort of 285 female college students with first UTI for 6 months or until second UTI. A first UTI due to Escherichia coli was followed by a second UTI three times more often than was a non-E. coli first UTI (24 vs. 8%; p = 0.02). In a logistic regression analysis limited to the 224 women from the University of Michigan Health Service and the University of Texas at Austin Health Service from September 1992 to December 1994, with a first UTI due to E. coli, vaginal intercourse increased the risk of a second UTI with both a different (odds ratio (OR) = 1.60, 95% confidence interval (CI): 1.19, 2.15) and the same (OR = 1.37, 95% CI: 0.91, 2.07) uropathogen, as did using a diaphragm, cervical cap, and/or spermicide (same uropathogen: OR = 1.53, 95% CI: 0.95, 2.47; different uropathogen: OR = 1.77, 95% CI: 1.22, 2.58). Condom use decreased the risk of a second UTI caused by a different uropathogen (OR = 0.68, 95% CI: 0.48, 0.99) but had no effect on a second UTI caused by the same E. coli (OR = 0.99; 95% CI: 0.66, 1.50). Type or duration of treatment was not associated with a second UTI. Although the risk of second UTI is strongly influenced by sexual behavior, women with a first UTI caused by E. coli are more likely than are those with a non-E. coli first UTI to have a second UTI within 6 months.","Risk factors for second urinary tract infection among college women."
"27","American Journal of Epidemiology.6","NA",10905532,2000,"To better understand the etiology of recurrent urinary tract infection (UTI), the authors followed a cohort of 285 female college students with first UTI for 6 months or until second UTI. A first UTI due to Escherichia coli was followed by a second UTI three times more often than was a non-E. coli first UTI (24 vs. 8%; p = 0.02). In a logistic regression analysis limited to the 224 women from the University of Michigan Health Service and the University of Texas at Austin Health Service from September 1992 to December 1994, with a first UTI due to E. coli, vaginal intercourse increased the risk of a second UTI with both a different (odds ratio (OR) = 1.60, 95% confidence interval (CI): 1.19, 2.15) and the same (OR = 1.37, 95% CI: 0.91, 2.07) uropathogen, as did using a diaphragm, cervical cap, and/or spermicide (same uropathogen: OR = 1.53, 95% CI: 0.95, 2.47; different uropathogen: OR = 1.77, 95% CI: 1.22, 2.58). Condom use decreased the risk of a second UTI caused by a different uropathogen (OR = 0.68, 95% CI: 0.48, 0.99) but had no effect on a second UTI caused by the same E. coli (OR = 0.99; 95% CI: 0.66, 1.50). Type or duration of treatment was not associated with a second UTI. Although the risk of second UTI is strongly influenced by sexual behavior, women with a first UTI caused by E. coli are more likely than are those with a non-E. coli first UTI to have a second UTI within 6 months.","Risk factors for second urinary tract infection among college women."
"28","American Journal of Epidemiology.6","NA",10905532,2000,"To better understand the etiology of recurrent urinary tract infection (UTI), the authors followed a cohort of 285 female college students with first UTI for 6 months or until second UTI. A first UTI due to Escherichia coli was followed by a second UTI three times more often than was a non-E. coli first UTI (24 vs. 8%; p = 0.02). In a logistic regression analysis limited to the 224 women from the University of Michigan Health Service and the University of Texas at Austin Health Service from September 1992 to December 1994, with a first UTI due to E. coli, vaginal intercourse increased the risk of a second UTI with both a different (odds ratio (OR) = 1.60, 95% confidence interval (CI): 1.19, 2.15) and the same (OR = 1.37, 95% CI: 0.91, 2.07) uropathogen, as did using a diaphragm, cervical cap, and/or spermicide (same uropathogen: OR = 1.53, 95% CI: 0.95, 2.47; different uropathogen: OR = 1.77, 95% CI: 1.22, 2.58). Condom use decreased the risk of a second UTI caused by a different uropathogen (OR = 0.68, 95% CI: 0.48, 0.99) but had no effect on a second UTI caused by the same E. coli (OR = 0.99; 95% CI: 0.66, 1.50). Type or duration of treatment was not associated with a second UTI. Although the risk of second UTI is strongly influenced by sexual behavior, women with a first UTI caused by E. coli are more likely than are those with a non-E. coli first UTI to have a second UTI within 6 months.","Risk factors for second urinary tract infection among college women."
"29","American Journal of Epidemiology.6","NA",10905532,2000,"To better understand the etiology of recurrent urinary tract infection (UTI), the authors followed a cohort of 285 female college students with first UTI for 6 months or until second UTI. A first UTI due to Escherichia coli was followed by a second UTI three times more often than was a non-E. coli first UTI (24 vs. 8%; p = 0.02). In a logistic regression analysis limited to the 224 women from the University of Michigan Health Service and the University of Texas at Austin Health Service from September 1992 to December 1994, with a first UTI due to E. coli, vaginal intercourse increased the risk of a second UTI with both a different (odds ratio (OR) = 1.60, 95% confidence interval (CI): 1.19, 2.15) and the same (OR = 1.37, 95% CI: 0.91, 2.07) uropathogen, as did using a diaphragm, cervical cap, and/or spermicide (same uropathogen: OR = 1.53, 95% CI: 0.95, 2.47; different uropathogen: OR = 1.77, 95% CI: 1.22, 2.58). Condom use decreased the risk of a second UTI caused by a different uropathogen (OR = 0.68, 95% CI: 0.48, 0.99) but had no effect on a second UTI caused by the same E. coli (OR = 0.99; 95% CI: 0.66, 1.50). Type or duration of treatment was not associated with a second UTI. Although the risk of second UTI is strongly influenced by sexual behavior, women with a first UTI caused by E. coli are more likely than are those with a non-E. coli first UTI to have a second UTI within 6 months.","Risk factors for second urinary tract infection among college women."
"30","JAMA.3","0.03",10944647,2000,"The benefit of adjuvant radiotherapy for resectable rectal cancer has been extensively studied, but data on survival are still equivocal despite a reduction in the rate of local recurrence.To assess the effectiveness of preoperative radiotherapy followed by surgery in the reduction of overall and cancer-related mortality and in the prevention of local recurrence and distant metastases.Computerized bibliographic searches of MEDLINE and CANCERLIT (1970 to December 1999), including non-English sources, were supplemented with hand searches of reference lists. The medical subject headings used were rectal cancer, radiotherapy, surgery, RCT, randomized, and clinical trial.Studies were included if they were randomized controlled trials (RCTs) comparing preoperative radiotherapy plus surgery with surgery alone and if they included patients with resectable histologically proven rectal adenocarcinoma, without metastatic disease. Fourteen RCTs were analyzed.Data on population, intervention, and outcomes were extracted from each RCT according to the intention-to-treat method by 3 independent observers and combined using the DerSimonian and Laird method.Radiotherapy plus surgery compared with surgery alone significantly reduced the 5-year overall mortality rate (odds ratio [OR] 0.84; 95% confidence interval [CI], 0.72-0.98; P =.03), cancer-related mortality rate (OR, 0.71; 95% CI, 0.61-0.82; P<.001), and local recurrence rate (OR, 0.49; 95% CI, 0.38-0.62; P<.001). No reduction was observed in the occurrence of distant metastases (OR, 0.93; 95% CI, 0.73-1.18; P =.54).In patients with resectable rectal cancer, preoperative radiotherapy significantly improved overall and cancer-specific survival compared with surgery alone. The magnitude of the benefit is relatively small and criteria are needed to identify patients most likely to benefit from adjuvant radiotherapy. JAMA. 2000;284:1008-1015","Preoperative radiotherapy for resectable rectal cancer: A meta-analysis."
"31","JAMA.3","0.001",10944647,2000,"The benefit of adjuvant radiotherapy for resectable rectal cancer has been extensively studied, but data on survival are still equivocal despite a reduction in the rate of local recurrence.To assess the effectiveness of preoperative radiotherapy followed by surgery in the reduction of overall and cancer-related mortality and in the prevention of local recurrence and distant metastases.Computerized bibliographic searches of MEDLINE and CANCERLIT (1970 to December 1999), including non-English sources, were supplemented with hand searches of reference lists. The medical subject headings used were rectal cancer, radiotherapy, surgery, RCT, randomized, and clinical trial.Studies were included if they were randomized controlled trials (RCTs) comparing preoperative radiotherapy plus surgery with surgery alone and if they included patients with resectable histologically proven rectal adenocarcinoma, without metastatic disease. Fourteen RCTs were analyzed.Data on population, intervention, and outcomes were extracted from each RCT according to the intention-to-treat method by 3 independent observers and combined using the DerSimonian and Laird method.Radiotherapy plus surgery compared with surgery alone significantly reduced the 5-year overall mortality rate (odds ratio [OR] 0.84; 95% confidence interval [CI], 0.72-0.98; P =.03), cancer-related mortality rate (OR, 0.71; 95% CI, 0.61-0.82; P<.001), and local recurrence rate (OR, 0.49; 95% CI, 0.38-0.62; P<.001). No reduction was observed in the occurrence of distant metastases (OR, 0.93; 95% CI, 0.73-1.18; P =.54).In patients with resectable rectal cancer, preoperative radiotherapy significantly improved overall and cancer-specific survival compared with surgery alone. The magnitude of the benefit is relatively small and criteria are needed to identify patients most likely to benefit from adjuvant radiotherapy. JAMA. 2000;284:1008-1015","Preoperative radiotherapy for resectable rectal cancer: A meta-analysis."
"32","JAMA.3","0.001",10944647,2000,"The benefit of adjuvant radiotherapy for resectable rectal cancer has been extensively studied, but data on survival are still equivocal despite a reduction in the rate of local recurrence.To assess the effectiveness of preoperative radiotherapy followed by surgery in the reduction of overall and cancer-related mortality and in the prevention of local recurrence and distant metastases.Computerized bibliographic searches of MEDLINE and CANCERLIT (1970 to December 1999), including non-English sources, were supplemented with hand searches of reference lists. The medical subject headings used were rectal cancer, radiotherapy, surgery, RCT, randomized, and clinical trial.Studies were included if they were randomized controlled trials (RCTs) comparing preoperative radiotherapy plus surgery with surgery alone and if they included patients with resectable histologically proven rectal adenocarcinoma, without metastatic disease. Fourteen RCTs were analyzed.Data on population, intervention, and outcomes were extracted from each RCT according to the intention-to-treat method by 3 independent observers and combined using the DerSimonian and Laird method.Radiotherapy plus surgery compared with surgery alone significantly reduced the 5-year overall mortality rate (odds ratio [OR] 0.84; 95% confidence interval [CI], 0.72-0.98; P =.03), cancer-related mortality rate (OR, 0.71; 95% CI, 0.61-0.82; P<.001), and local recurrence rate (OR, 0.49; 95% CI, 0.38-0.62; P<.001). No reduction was observed in the occurrence of distant metastases (OR, 0.93; 95% CI, 0.73-1.18; P =.54).In patients with resectable rectal cancer, preoperative radiotherapy significantly improved overall and cancer-specific survival compared with surgery alone. The magnitude of the benefit is relatively small and criteria are needed to identify patients most likely to benefit from adjuvant radiotherapy. JAMA. 2000;284:1008-1015","Preoperative radiotherapy for resectable rectal cancer: A meta-analysis."
"33","JAMA.4","0.54",10944647,2000,"The benefit of adjuvant radiotherapy for resectable rectal cancer has been extensively studied, but data on survival are still equivocal despite a reduction in the rate of local recurrence.To assess the effectiveness of preoperative radiotherapy followed by surgery in the reduction of overall and cancer-related mortality and in the prevention of local recurrence and distant metastases.Computerized bibliographic searches of MEDLINE and CANCERLIT (1970 to December 1999), including non-English sources, were supplemented with hand searches of reference lists. The medical subject headings used were rectal cancer, radiotherapy, surgery, RCT, randomized, and clinical trial.Studies were included if they were randomized controlled trials (RCTs) comparing preoperative radiotherapy plus surgery with surgery alone and if they included patients with resectable histologically proven rectal adenocarcinoma, without metastatic disease. Fourteen RCTs were analyzed.Data on population, intervention, and outcomes were extracted from each RCT according to the intention-to-treat method by 3 independent observers and combined using the DerSimonian and Laird method.Radiotherapy plus surgery compared with surgery alone significantly reduced the 5-year overall mortality rate (odds ratio [OR] 0.84; 95% confidence interval [CI], 0.72-0.98; P =.03), cancer-related mortality rate (OR, 0.71; 95% CI, 0.61-0.82; P<.001), and local recurrence rate (OR, 0.49; 95% CI, 0.38-0.62; P<.001). No reduction was observed in the occurrence of distant metastases (OR, 0.93; 95% CI, 0.73-1.18; P =.54).In patients with resectable rectal cancer, preoperative radiotherapy significantly improved overall and cancer-specific survival compared with surgery alone. The magnitude of the benefit is relatively small and criteria are needed to identify patients most likely to benefit from adjuvant radiotherapy. JAMA. 2000;284:1008-1015","Preoperative radiotherapy for resectable rectal cancer: A meta-analysis."
"34","American Journal of Epidemiology.4","NA",10968375,2000,"Occupational exposures were investigated in a multicenter case-control study of clinically and histologically diagnosed idiopathic pulmonary fibrosis (IPF), a chronic diffuse interstitial lung disease of unknown etiology. Results are based on 248 cases, aged 20-75 years, diagnosed at 16 referral centers between January 1989 and July 1993. There were 491 controls ascertained by random digit dialing and matched to cases on sex, age, and geographic region. Data were collected using a standard telephone questionnaire. Occupational factors were based on a detailed history of jobs lasting 6 months or more and job activity, hobby, and specific substance checklists. Several occupational factors, adjusted for age and smoking in conditional multivariate logistic regression analyses, were significantly associated with IPF: farming (odds ratio (OR) = 1.6, 95% confidence interval (CI): 1.0, 2.5); livestock (OR = 2.7, 95% CI: 1.3, 5.5); hairdressing (OR = 4.4, 95% CI: 1.2, 16.3); metal dust (OR = 2.0, 95% CI: 1.0, 4.0); raising birds (OR = 4.7, 95% CI: 1.6, 14.1); stone cutting/polishing (OR = 3.9, 95% CI: 1.2, 12.7); and vegetable dust/animal dust (OR = 4.7, 95% CI: 2.1, 10.4). Interaction was detected between smoking and exposure to livestock (p = 0.06) and farming (p = 0.08). Results confirm previous studies showing increased risk associated with dusty environments.","Occupational and environmental risk factors for idiopathic pulmonary fibrosis: a multicenter case-control study. Collaborating Centers."
"35","American Journal of Epidemiology.4","NA",10968375,2000,"Occupational exposures were investigated in a multicenter case-control study of clinically and histologically diagnosed idiopathic pulmonary fibrosis (IPF), a chronic diffuse interstitial lung disease of unknown etiology. Results are based on 248 cases, aged 20-75 years, diagnosed at 16 referral centers between January 1989 and July 1993. There were 491 controls ascertained by random digit dialing and matched to cases on sex, age, and geographic region. Data were collected using a standard telephone questionnaire. Occupational factors were based on a detailed history of jobs lasting 6 months or more and job activity, hobby, and specific substance checklists. Several occupational factors, adjusted for age and smoking in conditional multivariate logistic regression analyses, were significantly associated with IPF: farming (odds ratio (OR) = 1.6, 95% confidence interval (CI): 1.0, 2.5); livestock (OR = 2.7, 95% CI: 1.3, 5.5); hairdressing (OR = 4.4, 95% CI: 1.2, 16.3); metal dust (OR = 2.0, 95% CI: 1.0, 4.0); raising birds (OR = 4.7, 95% CI: 1.6, 14.1); stone cutting/polishing (OR = 3.9, 95% CI: 1.2, 12.7); and vegetable dust/animal dust (OR = 4.7, 95% CI: 2.1, 10.4). Interaction was detected between smoking and exposure to livestock (p = 0.06) and farming (p = 0.08). Results confirm previous studies showing increased risk associated with dusty environments.","Occupational and environmental risk factors for idiopathic pulmonary fibrosis: a multicenter case-control study. Collaborating Centers."
"36","American Journal of Epidemiology.4","NA",10968375,2000,"Occupational exposures were investigated in a multicenter case-control study of clinically and histologically diagnosed idiopathic pulmonary fibrosis (IPF), a chronic diffuse interstitial lung disease of unknown etiology. Results are based on 248 cases, aged 20-75 years, diagnosed at 16 referral centers between January 1989 and July 1993. There were 491 controls ascertained by random digit dialing and matched to cases on sex, age, and geographic region. Data were collected using a standard telephone questionnaire. Occupational factors were based on a detailed history of jobs lasting 6 months or more and job activity, hobby, and specific substance checklists. Several occupational factors, adjusted for age and smoking in conditional multivariate logistic regression analyses, were significantly associated with IPF: farming (odds ratio (OR) = 1.6, 95% confidence interval (CI): 1.0, 2.5); livestock (OR = 2.7, 95% CI: 1.3, 5.5); hairdressing (OR = 4.4, 95% CI: 1.2, 16.3); metal dust (OR = 2.0, 95% CI: 1.0, 4.0); raising birds (OR = 4.7, 95% CI: 1.6, 14.1); stone cutting/polishing (OR = 3.9, 95% CI: 1.2, 12.7); and vegetable dust/animal dust (OR = 4.7, 95% CI: 2.1, 10.4). Interaction was detected between smoking and exposure to livestock (p = 0.06) and farming (p = 0.08). Results confirm previous studies showing increased risk associated with dusty environments.","Occupational and environmental risk factors for idiopathic pulmonary fibrosis: a multicenter case-control study. Collaborating Centers."
"37","American Journal of Epidemiology.4","NA",10968375,2000,"Occupational exposures were investigated in a multicenter case-control study of clinically and histologically diagnosed idiopathic pulmonary fibrosis (IPF), a chronic diffuse interstitial lung disease of unknown etiology. Results are based on 248 cases, aged 20-75 years, diagnosed at 16 referral centers between January 1989 and July 1993. There were 491 controls ascertained by random digit dialing and matched to cases on sex, age, and geographic region. Data were collected using a standard telephone questionnaire. Occupational factors were based on a detailed history of jobs lasting 6 months or more and job activity, hobby, and specific substance checklists. Several occupational factors, adjusted for age and smoking in conditional multivariate logistic regression analyses, were significantly associated with IPF: farming (odds ratio (OR) = 1.6, 95% confidence interval (CI): 1.0, 2.5); livestock (OR = 2.7, 95% CI: 1.3, 5.5); hairdressing (OR = 4.4, 95% CI: 1.2, 16.3); metal dust (OR = 2.0, 95% CI: 1.0, 4.0); raising birds (OR = 4.7, 95% CI: 1.6, 14.1); stone cutting/polishing (OR = 3.9, 95% CI: 1.2, 12.7); and vegetable dust/animal dust (OR = 4.7, 95% CI: 2.1, 10.4). Interaction was detected between smoking and exposure to livestock (p = 0.06) and farming (p = 0.08). Results confirm previous studies showing increased risk associated with dusty environments.","Occupational and environmental risk factors for idiopathic pulmonary fibrosis: a multicenter case-control study. Collaborating Centers."
"38","American Journal of Epidemiology.4","NA",10968375,2000,"Occupational exposures were investigated in a multicenter case-control study of clinically and histologically diagnosed idiopathic pulmonary fibrosis (IPF), a chronic diffuse interstitial lung disease of unknown etiology. Results are based on 248 cases, aged 20-75 years, diagnosed at 16 referral centers between January 1989 and July 1993. There were 491 controls ascertained by random digit dialing and matched to cases on sex, age, and geographic region. Data were collected using a standard telephone questionnaire. Occupational factors were based on a detailed history of jobs lasting 6 months or more and job activity, hobby, and specific substance checklists. Several occupational factors, adjusted for age and smoking in conditional multivariate logistic regression analyses, were significantly associated with IPF: farming (odds ratio (OR) = 1.6, 95% confidence interval (CI): 1.0, 2.5); livestock (OR = 2.7, 95% CI: 1.3, 5.5); hairdressing (OR = 4.4, 95% CI: 1.2, 16.3); metal dust (OR = 2.0, 95% CI: 1.0, 4.0); raising birds (OR = 4.7, 95% CI: 1.6, 14.1); stone cutting/polishing (OR = 3.9, 95% CI: 1.2, 12.7); and vegetable dust/animal dust (OR = 4.7, 95% CI: 2.1, 10.4). Interaction was detected between smoking and exposure to livestock (p = 0.06) and farming (p = 0.08). Results confirm previous studies showing increased risk associated with dusty environments.","Occupational and environmental risk factors for idiopathic pulmonary fibrosis: a multicenter case-control study. Collaborating Centers."
"39","American Journal of Epidemiology.4","NA",10968375,2000,"Occupational exposures were investigated in a multicenter case-control study of clinically and histologically diagnosed idiopathic pulmonary fibrosis (IPF), a chronic diffuse interstitial lung disease of unknown etiology. Results are based on 248 cases, aged 20-75 years, diagnosed at 16 referral centers between January 1989 and July 1993. There were 491 controls ascertained by random digit dialing and matched to cases on sex, age, and geographic region. Data were collected using a standard telephone questionnaire. Occupational factors were based on a detailed history of jobs lasting 6 months or more and job activity, hobby, and specific substance checklists. Several occupational factors, adjusted for age and smoking in conditional multivariate logistic regression analyses, were significantly associated with IPF: farming (odds ratio (OR) = 1.6, 95% confidence interval (CI): 1.0, 2.5); livestock (OR = 2.7, 95% CI: 1.3, 5.5); hairdressing (OR = 4.4, 95% CI: 1.2, 16.3); metal dust (OR = 2.0, 95% CI: 1.0, 4.0); raising birds (OR = 4.7, 95% CI: 1.6, 14.1); stone cutting/polishing (OR = 3.9, 95% CI: 1.2, 12.7); and vegetable dust/animal dust (OR = 4.7, 95% CI: 2.1, 10.4). Interaction was detected between smoking and exposure to livestock (p = 0.06) and farming (p = 0.08). Results confirm previous studies showing increased risk associated with dusty environments.","Occupational and environmental risk factors for idiopathic pulmonary fibrosis: a multicenter case-control study. Collaborating Centers."
"40","American Journal of Epidemiology.5","NA",10968375,2000,"Occupational exposures were investigated in a multicenter case-control study of clinically and histologically diagnosed idiopathic pulmonary fibrosis (IPF), a chronic diffuse interstitial lung disease of unknown etiology. Results are based on 248 cases, aged 20-75 years, diagnosed at 16 referral centers between January 1989 and July 1993. There were 491 controls ascertained by random digit dialing and matched to cases on sex, age, and geographic region. Data were collected using a standard telephone questionnaire. Occupational factors were based on a detailed history of jobs lasting 6 months or more and job activity, hobby, and specific substance checklists. Several occupational factors, adjusted for age and smoking in conditional multivariate logistic regression analyses, were significantly associated with IPF: farming (odds ratio (OR) = 1.6, 95% confidence interval (CI): 1.0, 2.5); livestock (OR = 2.7, 95% CI: 1.3, 5.5); hairdressing (OR = 4.4, 95% CI: 1.2, 16.3); metal dust (OR = 2.0, 95% CI: 1.0, 4.0); raising birds (OR = 4.7, 95% CI: 1.6, 14.1); stone cutting/polishing (OR = 3.9, 95% CI: 1.2, 12.7); and vegetable dust/animal dust (OR = 4.7, 95% CI: 2.1, 10.4). Interaction was detected between smoking and exposure to livestock (p = 0.06) and farming (p = 0.08). Results confirm previous studies showing increased risk associated with dusty environments.","Occupational and environmental risk factors for idiopathic pulmonary fibrosis: a multicenter case-control study. Collaborating Centers."
"41","JAMA1","0.001",10989401,2000,"Both attenuated heart rate recovery following exercise and the Duke treadmill exercise score have been demonstrated to be independent predictors of mortality, but their prognostic value relative to each other has not been studied.To assess the associations among abnormal heart rate recovery, treadmill exercise score, and death in patients referred specifically for exercise electrocardiography.Prospective cohort study conducted in an academic medical center between September 1990 and December 1997, with a median follow-up of 5.2 years.A total of 9454 consecutive patients (mean [SD] age, 53 [11] years; 78% male) who underwent symptom-limited exercise electrocardiographic testing. Exclusion criteria included age younger than 30 years, history of heart failure or valvular disease, pacemaker implantation, and uninterpretable electrocardiograms.All-cause mortality, as predicted by abnormal heart rate recovery, defined as failure of heart rate to decrease by more than 12/min during the first minute after peak exercise, and by treadmill exercise score, defined as (exercise time) - (5 x maximum ST-segment deviation) - (4 x treadmill angina index).Three hundred twelve deaths occurred in the cohort. Abnormal heart rate recovery and intermediate- or high-risk treadmill exercise score were present in 20% (n = 1852) and 21% (n = 1996) of patients, respectively. In univariate analyses, death was predicted by both abnormal heart rate recovery (8% vs 2% in patients with normal heart rate recovery; hazard ratio [HR], 4.16; 95% confidence interval [CI], 3.33-5.19; chi(2) = 158; P<.001) and intermediate- or high-risk treadmill exercise score (8% vs 2% in patients with low-risk scores; HR, 4.28; 95% CI, 3.43-5.35; chi(2) = 164; P<.001). After adjusting for age, sex, standard cardiovascular risk factors, medication use, and other potential confounders, abnormal heart rate recovery remained predictive of death (among the 8549 patients not taking beta-blockers, adjusted HR, 2.13; 95% CI, 1.63-2.78; P<.001), as did intermediate- or high-risk treadmill exercise score (adjusted HR, 1. 49; 95% CI, 1.15-1.92; P =.002). There was no interaction between these 2 predictors.In this cohort of patients referred specifically for exercise electrocardiography, both abnormal heart rate recovery and treadmill exercise score were independent predictors of mortality. Heart rate recovery appears to provide additional prognostic information to the established treadmill exercise score and should be considered for routine incorporation into exercise test interpretation. JAMA. 2000;284:1392-1398.","Heart rate recovery and treadmill exercise score as predictors of mortality in patients referred for exercise ECG."
"42","JAMA.1100","0.001",10989401,2000,"Both attenuated heart rate recovery following exercise and the Duke treadmill exercise score have been demonstrated to be independent predictors of mortality, but their prognostic value relative to each other has not been studied.To assess the associations among abnormal heart rate recovery, treadmill exercise score, and death in patients referred specifically for exercise electrocardiography.Prospective cohort study conducted in an academic medical center between September 1990 and December 1997, with a median follow-up of 5.2 years.A total of 9454 consecutive patients (mean [SD] age, 53 [11] years; 78% male) who underwent symptom-limited exercise electrocardiographic testing. Exclusion criteria included age younger than 30 years, history of heart failure or valvular disease, pacemaker implantation, and uninterpretable electrocardiograms.All-cause mortality, as predicted by abnormal heart rate recovery, defined as failure of heart rate to decrease by more than 12/min during the first minute after peak exercise, and by treadmill exercise score, defined as (exercise time) - (5 x maximum ST-segment deviation) - (4 x treadmill angina index).Three hundred twelve deaths occurred in the cohort. Abnormal heart rate recovery and intermediate- or high-risk treadmill exercise score were present in 20% (n = 1852) and 21% (n = 1996) of patients, respectively. In univariate analyses, death was predicted by both abnormal heart rate recovery (8% vs 2% in patients with normal heart rate recovery; hazard ratio [HR], 4.16; 95% confidence interval [CI], 3.33-5.19; chi(2) = 158; P<.001) and intermediate- or high-risk treadmill exercise score (8% vs 2% in patients with low-risk scores; HR, 4.28; 95% CI, 3.43-5.35; chi(2) = 164; P<.001). After adjusting for age, sex, standard cardiovascular risk factors, medication use, and other potential confounders, abnormal heart rate recovery remained predictive of death (among the 8549 patients not taking beta-blockers, adjusted HR, 2.13; 95% CI, 1.63-2.78; P<.001), as did intermediate- or high-risk treadmill exercise score (adjusted HR, 1. 49; 95% CI, 1.15-1.92; P =.002). There was no interaction between these 2 predictors.In this cohort of patients referred specifically for exercise electrocardiography, both abnormal heart rate recovery and treadmill exercise score were independent predictors of mortality. Heart rate recovery appears to provide additional prognostic information to the established treadmill exercise score and should be considered for routine incorporation into exercise test interpretation. JAMA. 2000;284:1392-1398.","Heart rate recovery and treadmill exercise score as predictors of mortality in patients referred for exercise ECG."
"43","JAMA.2100","0.001",10989401,2000,"Both attenuated heart rate recovery following exercise and the Duke treadmill exercise score have been demonstrated to be independent predictors of mortality, but their prognostic value relative to each other has not been studied.To assess the associations among abnormal heart rate recovery, treadmill exercise score, and death in patients referred specifically for exercise electrocardiography.Prospective cohort study conducted in an academic medical center between September 1990 and December 1997, with a median follow-up of 5.2 years.A total of 9454 consecutive patients (mean [SD] age, 53 [11] years; 78% male) who underwent symptom-limited exercise electrocardiographic testing. Exclusion criteria included age younger than 30 years, history of heart failure or valvular disease, pacemaker implantation, and uninterpretable electrocardiograms.All-cause mortality, as predicted by abnormal heart rate recovery, defined as failure of heart rate to decrease by more than 12/min during the first minute after peak exercise, and by treadmill exercise score, defined as (exercise time) - (5 x maximum ST-segment deviation) - (4 x treadmill angina index).Three hundred twelve deaths occurred in the cohort. Abnormal heart rate recovery and intermediate- or high-risk treadmill exercise score were present in 20% (n = 1852) and 21% (n = 1996) of patients, respectively. In univariate analyses, death was predicted by both abnormal heart rate recovery (8% vs 2% in patients with normal heart rate recovery; hazard ratio [HR], 4.16; 95% confidence interval [CI], 3.33-5.19; chi(2) = 158; P<.001) and intermediate- or high-risk treadmill exercise score (8% vs 2% in patients with low-risk scores; HR, 4.28; 95% CI, 3.43-5.35; chi(2) = 164; P<.001). After adjusting for age, sex, standard cardiovascular risk factors, medication use, and other potential confounders, abnormal heart rate recovery remained predictive of death (among the 8549 patients not taking beta-blockers, adjusted HR, 2.13; 95% CI, 1.63-2.78; P<.001), as did intermediate- or high-risk treadmill exercise score (adjusted HR, 1. 49; 95% CI, 1.15-1.92; P =.002). There was no interaction between these 2 predictors.In this cohort of patients referred specifically for exercise electrocardiography, both abnormal heart rate recovery and treadmill exercise score were independent predictors of mortality. Heart rate recovery appears to provide additional prognostic information to the established treadmill exercise score and should be considered for routine incorporation into exercise test interpretation. JAMA. 2000;284:1392-1398.","Heart rate recovery and treadmill exercise score as predictors of mortality in patients referred for exercise ECG."
"44","JAMA.1110","0.002",10989401,2000,"Both attenuated heart rate recovery following exercise and the Duke treadmill exercise score have been demonstrated to be independent predictors of mortality, but their prognostic value relative to each other has not been studied.To assess the associations among abnormal heart rate recovery, treadmill exercise score, and death in patients referred specifically for exercise electrocardiography.Prospective cohort study conducted in an academic medical center between September 1990 and December 1997, with a median follow-up of 5.2 years.A total of 9454 consecutive patients (mean [SD] age, 53 [11] years; 78% male) who underwent symptom-limited exercise electrocardiographic testing. Exclusion criteria included age younger than 30 years, history of heart failure or valvular disease, pacemaker implantation, and uninterpretable electrocardiograms.All-cause mortality, as predicted by abnormal heart rate recovery, defined as failure of heart rate to decrease by more than 12/min during the first minute after peak exercise, and by treadmill exercise score, defined as (exercise time) - (5 x maximum ST-segment deviation) - (4 x treadmill angina index).Three hundred twelve deaths occurred in the cohort. Abnormal heart rate recovery and intermediate- or high-risk treadmill exercise score were present in 20% (n = 1852) and 21% (n = 1996) of patients, respectively. In univariate analyses, death was predicted by both abnormal heart rate recovery (8% vs 2% in patients with normal heart rate recovery; hazard ratio [HR], 4.16; 95% confidence interval [CI], 3.33-5.19; chi(2) = 158; P<.001) and intermediate- or high-risk treadmill exercise score (8% vs 2% in patients with low-risk scores; HR, 4.28; 95% CI, 3.43-5.35; chi(2) = 164; P<.001). After adjusting for age, sex, standard cardiovascular risk factors, medication use, and other potential confounders, abnormal heart rate recovery remained predictive of death (among the 8549 patients not taking beta-blockers, adjusted HR, 2.13; 95% CI, 1.63-2.78; P<.001), as did intermediate- or high-risk treadmill exercise score (adjusted HR, 1. 49; 95% CI, 1.15-1.92; P =.002). There was no interaction between these 2 predictors.In this cohort of patients referred specifically for exercise electrocardiography, both abnormal heart rate recovery and treadmill exercise score were independent predictors of mortality. Heart rate recovery appears to provide additional prognostic information to the established treadmill exercise score and should be considered for routine incorporation into exercise test interpretation. JAMA. 2000;284:1392-1398.","Heart rate recovery and treadmill exercise score as predictors of mortality in patients referred for exercise ECG."
"45","JAMA.2","0.002",10989404,2000,"Computerized systems to remind physicians to provide appropriate care have not been widely evaluated in large numbers of patients in multiple clinical settings.To examine whether a computerized reminder system operating in multiple Veterans Affairs (VA) ambulatory care clinics improves resident physician compliance with standards of ambulatory care.A total of 275 resident physicians at 12 VA medical centers were randomly assigned in firms or half-day clinic blocks to either a reminder group (n = 132) or a control group (n = 143). During a 17-month study period (January 31, 1995-June 30, 1996), the residents cared for 12,989 unique patients for whom at least 1 of the studied standards of care (SOC) was applicable.Compliance with 13 SOC, tracked using hospital databases and encounter forms completed by residents, compared between residents in the reminder group vs those in the control group.Measuring compliance as the proportion of patients in compliance with all applicable SOC by their last visit during the study period, the reminder group had statistically significantly higher rates of compliance than the control group for all standards combined (58.8% vs 53.5%; odds ratio [OR], 1.24; 95% confidence interval [CI], 1.08-1.42; P =.002) and for 5 of the 13 standards examined individually. Measuring compliance as the proportion of all visits for which care was indicated in which residents provided proper care, the reminder group also had statistically significantly higher rates of compliance than the control group for all standards combined (17.9% vs 12.2%; OR, 1.57; 95% CI, 1.45-1.71; P<.001) and for 9 of the 13 standards examined individually. The benefit of reminders, however, declined throughout the course of the study, even though the reminders remained active.Our data indicate that reminder systems installed at multiple sites can improve residents' compliance to multiple SOC. The benefits of such systems, however, appear to deteriorate over time. Future research needs to explore methods to better sustain the benefits of reminders. JAMA. 2000;284:1411-1416.","Improving residents' compliance with standards of ambulatory care: results from the VA Cooperative Study on Computerized Reminders."
"46","JAMA.2","0.001",10989404,2000,"Computerized systems to remind physicians to provide appropriate care have not been widely evaluated in large numbers of patients in multiple clinical settings.To examine whether a computerized reminder system operating in multiple Veterans Affairs (VA) ambulatory care clinics improves resident physician compliance with standards of ambulatory care.A total of 275 resident physicians at 12 VA medical centers were randomly assigned in firms or half-day clinic blocks to either a reminder group (n = 132) or a control group (n = 143). During a 17-month study period (January 31, 1995-June 30, 1996), the residents cared for 12,989 unique patients for whom at least 1 of the studied standards of care (SOC) was applicable.Compliance with 13 SOC, tracked using hospital databases and encounter forms completed by residents, compared between residents in the reminder group vs those in the control group.Measuring compliance as the proportion of patients in compliance with all applicable SOC by their last visit during the study period, the reminder group had statistically significantly higher rates of compliance than the control group for all standards combined (58.8% vs 53.5%; odds ratio [OR], 1.24; 95% confidence interval [CI], 1.08-1.42; P =.002) and for 5 of the 13 standards examined individually. Measuring compliance as the proportion of all visits for which care was indicated in which residents provided proper care, the reminder group also had statistically significantly higher rates of compliance than the control group for all standards combined (17.9% vs 12.2%; OR, 1.57; 95% CI, 1.45-1.71; P<.001) and for 9 of the 13 standards examined individually. The benefit of reminders, however, declined throughout the course of the study, even though the reminders remained active.Our data indicate that reminder systems installed at multiple sites can improve residents' compliance to multiple SOC. The benefits of such systems, however, appear to deteriorate over time. Future research needs to explore methods to better sustain the benefits of reminders. JAMA. 2000;284:1411-1416.","Improving residents' compliance with standards of ambulatory care: results from the VA Cooperative Study on Computerized Reminders."
"47","JAMA.910","NA",11025832,2000,"Women with coronary artery disease (CAD) are believed to have a higher risk for adverse outcomes than men after conventional coronary interventions. The increasing use of coronary stenting has improved the outcome of patients undergoing coronary interventions, but little is known about the nature of outcomes in men vs women after this procedure.To examine whether there are sex-based differences in prognostic factors and in early and late outcomes among CAD patients undergoing coronary stent placement.Inception cohort study, at 2 tertiary referral institutions in Germany. Consecutive series of 1001 women and 3263 men with symptomatic CAD who were treated with stenting between May 1992 and December 1998. Patients who underwent stenting in the setting of acute myocardial infarction were excluded.The combined event rates of death and nonfatal myocardial infarction, assessed at 30 days and 1 year after stenting and compared by sex.Compared with men, women undergoing coronary stenting were significantly older (mean age, 69 vs 63 years) and more likely to present with diabetes, arterial hypertension, or hypercholesterolemia. Women had less extensive CAD, a less frequent history of myocardial infarction and better preserved left ventricular function than men. Women presented an excess risk of death or nonfatal myocardial infarction only during the early period after stenting: the 30-day combined event rate of death or myocardial infarction was 3.1% in women and 1.8% in men (P =.02) and the multivariate-adjusted hazard ratio (HR) for women was 2.02 (95% confidence interval [CI], 1.27-3.19). At 1 year, the outcome was similar for both women and men (combined event rate for women, 6.0%, and for men, 5.8% (P =.77); multivariate-adjusted HR for women, 1.06 [95% CI, 0.75-1.48]). There was a sex difference in the prognostic value of baseline characteristics: the strongest prognostic factors were diabetes in women and age in men.The results of this study indicate that 1-year outcomes of women with CAD undergoing coronary artery stenting are similar to those of men. Despite the similarity in outcomes, there are several sex-specific differences in baseline characteristics, clinical course after the intervention, and relative weight of prognostic factors. JAMA. 2000;284:1799-1805.","Differences in prognostic factors and outcomes between women and men undergoing coronary artery stenting."
"48","JAMA.1010","NA",11025832,2000,"Women with coronary artery disease (CAD) are believed to have a higher risk for adverse outcomes than men after conventional coronary interventions. The increasing use of coronary stenting has improved the outcome of patients undergoing coronary interventions, but little is known about the nature of outcomes in men vs women after this procedure.To examine whether there are sex-based differences in prognostic factors and in early and late outcomes among CAD patients undergoing coronary stent placement.Inception cohort study, at 2 tertiary referral institutions in Germany. Consecutive series of 1001 women and 3263 men with symptomatic CAD who were treated with stenting between May 1992 and December 1998. Patients who underwent stenting in the setting of acute myocardial infarction were excluded.The combined event rates of death and nonfatal myocardial infarction, assessed at 30 days and 1 year after stenting and compared by sex.Compared with men, women undergoing coronary stenting were significantly older (mean age, 69 vs 63 years) and more likely to present with diabetes, arterial hypertension, or hypercholesterolemia. Women had less extensive CAD, a less frequent history of myocardial infarction and better preserved left ventricular function than men. Women presented an excess risk of death or nonfatal myocardial infarction only during the early period after stenting: the 30-day combined event rate of death or myocardial infarction was 3.1% in women and 1.8% in men (P =.02) and the multivariate-adjusted hazard ratio (HR) for women was 2.02 (95% confidence interval [CI], 1.27-3.19). At 1 year, the outcome was similar for both women and men (combined event rate for women, 6.0%, and for men, 5.8% (P =.77); multivariate-adjusted HR for women, 1.06 [95% CI, 0.75-1.48]). There was a sex difference in the prognostic value of baseline characteristics: the strongest prognostic factors were diabetes in women and age in men.The results of this study indicate that 1-year outcomes of women with CAD undergoing coronary artery stenting are similar to those of men. Despite the similarity in outcomes, there are several sex-specific differences in baseline characteristics, clinical course after the intervention, and relative weight of prognostic factors. JAMA. 2000;284:1799-1805.","Differences in prognostic factors and outcomes between women and men undergoing coronary artery stenting."
"49","American Journal of Epidemiology","NA",11032158,2000,"As part of a case-control study, the Auckland Hip Fracture Study (1991-1994), the authors examined associations between impaired vision and risk of hip fracture. Subjects (911 cases and 910 controls aged 60 years or older) completed a questionnaire and had vision measurements taken, including measurements of visual acuity and stereopsis (depth perception). Binocular visual acuity worse than 20/60 was statistically significantly associated with increased risk of hip fracture after adjustment for age, sex, proxy response, hours of activity per week, and height (odds ratio (OR) = 1.5; 95% confidence interval (CI): 1.1, 2.0), as was having poor vision (less than 20/100) in both eyes (OR = 2.4; 95% CI: 1.0, 6.1). Having no depth perception was associated with increased risk (OR = 6.0 95% CI: 3.2, 11.1), as were categories of decreasing stereopsis (trend p = 0.0001), self-reported poor vision (OR = 1.4; 95% CI: 1.0, 1.9), not wearing glasses at the time of the fall (OR = 1.2; 95% CI: 1.0, 1.6), and increasing time since the last eye examination (trend p = 0.03). The population attributable risk of hip fracture due to poor visual acuity or stereopsis was 40%. Visual factors are important fall-related factors which influence risk of hip fracture. Risk of hip fracture may be decreased by correcting refractive error, improving stereopsis, and administering regular eye examinations.","Visual impairment and risk of hip fracture."
"50","American Journal of Epidemiology","NA",11032158,2000,"As part of a case-control study, the Auckland Hip Fracture Study (1991-1994), the authors examined associations between impaired vision and risk of hip fracture. Subjects (911 cases and 910 controls aged 60 years or older) completed a questionnaire and had vision measurements taken, including measurements of visual acuity and stereopsis (depth perception). Binocular visual acuity worse than 20/60 was statistically significantly associated with increased risk of hip fracture after adjustment for age, sex, proxy response, hours of activity per week, and height (odds ratio (OR) = 1.5; 95% confidence interval (CI): 1.1, 2.0), as was having poor vision (less than 20/100) in both eyes (OR = 2.4; 95% CI: 1.0, 6.1). Having no depth perception was associated with increased risk (OR = 6.0 95% CI: 3.2, 11.1), as were categories of decreasing stereopsis (trend p = 0.0001), self-reported poor vision (OR = 1.4; 95% CI: 1.0, 1.9), not wearing glasses at the time of the fall (OR = 1.2; 95% CI: 1.0, 1.6), and increasing time since the last eye examination (trend p = 0.03). The population attributable risk of hip fracture due to poor visual acuity or stereopsis was 40%. Visual factors are important fall-related factors which influence risk of hip fracture. Risk of hip fracture may be decreased by correcting refractive error, improving stereopsis, and administering regular eye examinations.","Visual impairment and risk of hip fracture."
"51","American Journal of Epidemiology","NA",11032158,2000,"As part of a case-control study, the Auckland Hip Fracture Study (1991-1994), the authors examined associations between impaired vision and risk of hip fracture. Subjects (911 cases and 910 controls aged 60 years or older) completed a questionnaire and had vision measurements taken, including measurements of visual acuity and stereopsis (depth perception). Binocular visual acuity worse than 20/60 was statistically significantly associated with increased risk of hip fracture after adjustment for age, sex, proxy response, hours of activity per week, and height (odds ratio (OR) = 1.5; 95% confidence interval (CI): 1.1, 2.0), as was having poor vision (less than 20/100) in both eyes (OR = 2.4; 95% CI: 1.0, 6.1). Having no depth perception was associated with increased risk (OR = 6.0 95% CI: 3.2, 11.1), as were categories of decreasing stereopsis (trend p = 0.0001), self-reported poor vision (OR = 1.4; 95% CI: 1.0, 1.9), not wearing glasses at the time of the fall (OR = 1.2; 95% CI: 1.0, 1.6), and increasing time since the last eye examination (trend p = 0.03). The population attributable risk of hip fracture due to poor visual acuity or stereopsis was 40%. Visual factors are important fall-related factors which influence risk of hip fracture. Risk of hip fracture may be decreased by correcting refractive error, improving stereopsis, and administering regular eye examinations.","Visual impairment and risk of hip fracture."
"52","American Journal of Epidemiology","NA",11032158,2000,"As part of a case-control study, the Auckland Hip Fracture Study (1991-1994), the authors examined associations between impaired vision and risk of hip fracture. Subjects (911 cases and 910 controls aged 60 years or older) completed a questionnaire and had vision measurements taken, including measurements of visual acuity and stereopsis (depth perception). Binocular visual acuity worse than 20/60 was statistically significantly associated with increased risk of hip fracture after adjustment for age, sex, proxy response, hours of activity per week, and height (odds ratio (OR) = 1.5; 95% confidence interval (CI): 1.1, 2.0), as was having poor vision (less than 20/100) in both eyes (OR = 2.4; 95% CI: 1.0, 6.1). Having no depth perception was associated with increased risk (OR = 6.0 95% CI: 3.2, 11.1), as were categories of decreasing stereopsis (trend p = 0.0001), self-reported poor vision (OR = 1.4; 95% CI: 1.0, 1.9), not wearing glasses at the time of the fall (OR = 1.2; 95% CI: 1.0, 1.6), and increasing time since the last eye examination (trend p = 0.03). The population attributable risk of hip fracture due to poor visual acuity or stereopsis was 40%. Visual factors are important fall-related factors which influence risk of hip fracture. Risk of hip fracture may be decreased by correcting refractive error, improving stereopsis, and administering regular eye examinations.","Visual impairment and risk of hip fracture."
"53","American Journal of Epidemiology.1","NA",11032158,2000,"As part of a case-control study, the Auckland Hip Fracture Study (1991-1994), the authors examined associations between impaired vision and risk of hip fracture. Subjects (911 cases and 910 controls aged 60 years or older) completed a questionnaire and had vision measurements taken, including measurements of visual acuity and stereopsis (depth perception). Binocular visual acuity worse than 20/60 was statistically significantly associated with increased risk of hip fracture after adjustment for age, sex, proxy response, hours of activity per week, and height (odds ratio (OR) = 1.5; 95% confidence interval (CI): 1.1, 2.0), as was having poor vision (less than 20/100) in both eyes (OR = 2.4; 95% CI: 1.0, 6.1). Having no depth perception was associated with increased risk (OR = 6.0 95% CI: 3.2, 11.1), as were categories of decreasing stereopsis (trend p = 0.0001), self-reported poor vision (OR = 1.4; 95% CI: 1.0, 1.9), not wearing glasses at the time of the fall (OR = 1.2; 95% CI: 1.0, 1.6), and increasing time since the last eye examination (trend p = 0.03). The population attributable risk of hip fracture due to poor visual acuity or stereopsis was 40%. Visual factors are important fall-related factors which influence risk of hip fracture. Risk of hip fracture may be decreased by correcting refractive error, improving stereopsis, and administering regular eye examinations.","Visual impairment and risk of hip fracture."
"54","JAMA.19","0.01",11074776,2000,"Parents' understanding of prognosis or decision making about palliative care for children who die of cancer is largely unknown. However, a more accurate understanding of prognosis could alter treatment goals and expectations and lead to more effective care.To evaluate parental understanding of prognosis in children who die of cancer and to assess the association of this factor with treatment goals and the palliative care received by children.Survey, conducted between September 1997 and August 1998, of 103 parents of children who received treatment at the Dana-Farber Cancer Institute and Children's Hospital, Boston, Mass, and who died of cancer between 1990 and 1997 (72% of those eligible and those located) and 42 pediatric oncologists.Timing of parental understanding that the child had no realistic chance for cure compared with the timing of physician understanding of this prognosis, as documented in the medical record.Parents first recognized that the child had no realistic chance for cure a mean (SD) of 106 (150) days before the child's death, while physician recognition occurred earlier at 206 (330) days before death. Among children who died of progressive disease, the group characterized by earlier recognition of this prognosis by both parents and physicians had earlier discussions of hospice care (odds ratio [OR], 1.03; 95% confidence interval [CI], 1.01-1.06; P =.01), better parental ratings of the quality of home care (OR, 3.31; 95% CI, 1.15-9.54; P =.03), earlier institution of a do-not-resuscitate order (OR, 1.03; 95% CI, 1.00-1.06; P =.02), less use of cancer-directed therapy during the last month of life (OR, 2.80; 95% CI, 1.05-7.50; P =.04), and higher likelihood that the goal of cancer-directed therapy identified by both physician and parent was to lessen suffering (OR, 5.17; 95% CI, 1.86-14.4; P =.002 for physician and OR, 6.56; 95% CI, 1.54-27.86; P =.01 for parents).Considerable delay exists in parental recognition that children have no realistic chance for cure, but earlier recognition of this prognosis by both physicians and parents is associated with a stronger emphasis on treatment directed at lessening suffering and greater integration of palliative care. JAMA. 2000;284:2469-2475.","Understanding of prognosis among parents of children who died of cancer: impact on treatment goals and integration of palliative care."
"55","JAMA.20","0.03",11074776,2000,"Parents' understanding of prognosis or decision making about palliative care for children who die of cancer is largely unknown. However, a more accurate understanding of prognosis could alter treatment goals and expectations and lead to more effective care.To evaluate parental understanding of prognosis in children who die of cancer and to assess the association of this factor with treatment goals and the palliative care received by children.Survey, conducted between September 1997 and August 1998, of 103 parents of children who received treatment at the Dana-Farber Cancer Institute and Children's Hospital, Boston, Mass, and who died of cancer between 1990 and 1997 (72% of those eligible and those located) and 42 pediatric oncologists.Timing of parental understanding that the child had no realistic chance for cure compared with the timing of physician understanding of this prognosis, as documented in the medical record.Parents first recognized that the child had no realistic chance for cure a mean (SD) of 106 (150) days before the child's death, while physician recognition occurred earlier at 206 (330) days before death. Among children who died of progressive disease, the group characterized by earlier recognition of this prognosis by both parents and physicians had earlier discussions of hospice care (odds ratio [OR], 1.03; 95% confidence interval [CI], 1.01-1.06; P =.01), better parental ratings of the quality of home care (OR, 3.31; 95% CI, 1.15-9.54; P =.03), earlier institution of a do-not-resuscitate order (OR, 1.03; 95% CI, 1.00-1.06; P =.02), less use of cancer-directed therapy during the last month of life (OR, 2.80; 95% CI, 1.05-7.50; P =.04), and higher likelihood that the goal of cancer-directed therapy identified by both physician and parent was to lessen suffering (OR, 5.17; 95% CI, 1.86-14.4; P =.002 for physician and OR, 6.56; 95% CI, 1.54-27.86; P =.01 for parents).Considerable delay exists in parental recognition that children have no realistic chance for cure, but earlier recognition of this prognosis by both physicians and parents is associated with a stronger emphasis on treatment directed at lessening suffering and greater integration of palliative care. JAMA. 2000;284:2469-2475.","Understanding of prognosis among parents of children who died of cancer: impact on treatment goals and integration of palliative care."
"56","JAMA.21","0.02",11074776,2000,"Parents' understanding of prognosis or decision making about palliative care for children who die of cancer is largely unknown. However, a more accurate understanding of prognosis could alter treatment goals and expectations and lead to more effective care.To evaluate parental understanding of prognosis in children who die of cancer and to assess the association of this factor with treatment goals and the palliative care received by children.Survey, conducted between September 1997 and August 1998, of 103 parents of children who received treatment at the Dana-Farber Cancer Institute and Children's Hospital, Boston, Mass, and who died of cancer between 1990 and 1997 (72% of those eligible and those located) and 42 pediatric oncologists.Timing of parental understanding that the child had no realistic chance for cure compared with the timing of physician understanding of this prognosis, as documented in the medical record.Parents first recognized that the child had no realistic chance for cure a mean (SD) of 106 (150) days before the child's death, while physician recognition occurred earlier at 206 (330) days before death. Among children who died of progressive disease, the group characterized by earlier recognition of this prognosis by both parents and physicians had earlier discussions of hospice care (odds ratio [OR], 1.03; 95% confidence interval [CI], 1.01-1.06; P =.01), better parental ratings of the quality of home care (OR, 3.31; 95% CI, 1.15-9.54; P =.03), earlier institution of a do-not-resuscitate order (OR, 1.03; 95% CI, 1.00-1.06; P =.02), less use of cancer-directed therapy during the last month of life (OR, 2.80; 95% CI, 1.05-7.50; P =.04), and higher likelihood that the goal of cancer-directed therapy identified by both physician and parent was to lessen suffering (OR, 5.17; 95% CI, 1.86-14.4; P =.002 for physician and OR, 6.56; 95% CI, 1.54-27.86; P =.01 for parents).Considerable delay exists in parental recognition that children have no realistic chance for cure, but earlier recognition of this prognosis by both physicians and parents is associated with a stronger emphasis on treatment directed at lessening suffering and greater integration of palliative care. JAMA. 2000;284:2469-2475.","Understanding of prognosis among parents of children who died of cancer: impact on treatment goals and integration of palliative care."
"57","JAMA.22","0.04",11074776,2000,"Parents' understanding of prognosis or decision making about palliative care for children who die of cancer is largely unknown. However, a more accurate understanding of prognosis could alter treatment goals and expectations and lead to more effective care.To evaluate parental understanding of prognosis in children who die of cancer and to assess the association of this factor with treatment goals and the palliative care received by children.Survey, conducted between September 1997 and August 1998, of 103 parents of children who received treatment at the Dana-Farber Cancer Institute and Children's Hospital, Boston, Mass, and who died of cancer between 1990 and 1997 (72% of those eligible and those located) and 42 pediatric oncologists.Timing of parental understanding that the child had no realistic chance for cure compared with the timing of physician understanding of this prognosis, as documented in the medical record.Parents first recognized that the child had no realistic chance for cure a mean (SD) of 106 (150) days before the child's death, while physician recognition occurred earlier at 206 (330) days before death. Among children who died of progressive disease, the group characterized by earlier recognition of this prognosis by both parents and physicians had earlier discussions of hospice care (odds ratio [OR], 1.03; 95% confidence interval [CI], 1.01-1.06; P =.01), better parental ratings of the quality of home care (OR, 3.31; 95% CI, 1.15-9.54; P =.03), earlier institution of a do-not-resuscitate order (OR, 1.03; 95% CI, 1.00-1.06; P =.02), less use of cancer-directed therapy during the last month of life (OR, 2.80; 95% CI, 1.05-7.50; P =.04), and higher likelihood that the goal of cancer-directed therapy identified by both physician and parent was to lessen suffering (OR, 5.17; 95% CI, 1.86-14.4; P =.002 for physician and OR, 6.56; 95% CI, 1.54-27.86; P =.01 for parents).Considerable delay exists in parental recognition that children have no realistic chance for cure, but earlier recognition of this prognosis by both physicians and parents is associated with a stronger emphasis on treatment directed at lessening suffering and greater integration of palliative care. JAMA. 2000;284:2469-2475.","Understanding of prognosis among parents of children who died of cancer: impact on treatment goals and integration of palliative care."
"58","JAMA.23","0.002",11074776,2000,"Parents' understanding of prognosis or decision making about palliative care for children who die of cancer is largely unknown. However, a more accurate understanding of prognosis could alter treatment goals and expectations and lead to more effective care.To evaluate parental understanding of prognosis in children who die of cancer and to assess the association of this factor with treatment goals and the palliative care received by children.Survey, conducted between September 1997 and August 1998, of 103 parents of children who received treatment at the Dana-Farber Cancer Institute and Children's Hospital, Boston, Mass, and who died of cancer between 1990 and 1997 (72% of those eligible and those located) and 42 pediatric oncologists.Timing of parental understanding that the child had no realistic chance for cure compared with the timing of physician understanding of this prognosis, as documented in the medical record.Parents first recognized that the child had no realistic chance for cure a mean (SD) of 106 (150) days before the child's death, while physician recognition occurred earlier at 206 (330) days before death. Among children who died of progressive disease, the group characterized by earlier recognition of this prognosis by both parents and physicians had earlier discussions of hospice care (odds ratio [OR], 1.03; 95% confidence interval [CI], 1.01-1.06; P =.01), better parental ratings of the quality of home care (OR, 3.31; 95% CI, 1.15-9.54; P =.03), earlier institution of a do-not-resuscitate order (OR, 1.03; 95% CI, 1.00-1.06; P =.02), less use of cancer-directed therapy during the last month of life (OR, 2.80; 95% CI, 1.05-7.50; P =.04), and higher likelihood that the goal of cancer-directed therapy identified by both physician and parent was to lessen suffering (OR, 5.17; 95% CI, 1.86-14.4; P =.002 for physician and OR, 6.56; 95% CI, 1.54-27.86; P =.01 for parents).Considerable delay exists in parental recognition that children have no realistic chance for cure, but earlier recognition of this prognosis by both physicians and parents is associated with a stronger emphasis on treatment directed at lessening suffering and greater integration of palliative care. JAMA. 2000;284:2469-2475.","Understanding of prognosis among parents of children who died of cancer: impact on treatment goals and integration of palliative care."
"59","JAMA.24","0.01",11074776,2000,"Parents' understanding of prognosis or decision making about palliative care for children who die of cancer is largely unknown. However, a more accurate understanding of prognosis could alter treatment goals and expectations and lead to more effective care.To evaluate parental understanding of prognosis in children who die of cancer and to assess the association of this factor with treatment goals and the palliative care received by children.Survey, conducted between September 1997 and August 1998, of 103 parents of children who received treatment at the Dana-Farber Cancer Institute and Children's Hospital, Boston, Mass, and who died of cancer between 1990 and 1997 (72% of those eligible and those located) and 42 pediatric oncologists.Timing of parental understanding that the child had no realistic chance for cure compared with the timing of physician understanding of this prognosis, as documented in the medical record.Parents first recognized that the child had no realistic chance for cure a mean (SD) of 106 (150) days before the child's death, while physician recognition occurred earlier at 206 (330) days before death. Among children who died of progressive disease, the group characterized by earlier recognition of this prognosis by both parents and physicians had earlier discussions of hospice care (odds ratio [OR], 1.03; 95% confidence interval [CI], 1.01-1.06; P =.01), better parental ratings of the quality of home care (OR, 3.31; 95% CI, 1.15-9.54; P =.03), earlier institution of a do-not-resuscitate order (OR, 1.03; 95% CI, 1.00-1.06; P =.02), less use of cancer-directed therapy during the last month of life (OR, 2.80; 95% CI, 1.05-7.50; P =.04), and higher likelihood that the goal of cancer-directed therapy identified by both physician and parent was to lessen suffering (OR, 5.17; 95% CI, 1.86-14.4; P =.002 for physician and OR, 6.56; 95% CI, 1.54-27.86; P =.01 for parents).Considerable delay exists in parental recognition that children have no realistic chance for cure, but earlier recognition of this prognosis by both physicians and parents is associated with a stronger emphasis on treatment directed at lessening suffering and greater integration of palliative care. JAMA. 2000;284:2469-2475.","Understanding of prognosis among parents of children who died of cancer: impact on treatment goals and integration of palliative care."
"60","Lancet.3","0.001",11075768,2000,"Warfarin-associated coagulopathy is a frequent clinical complication. We aimed to assess whether treatment with vitamin K is safe and more effective than placebo in rapidly lowering the international normalised ratio (INR) into the therapeutic range in over anticoagulated patients receiving warfarin.We did a multicentre, double-blind, placebo-controlled, randomised trial in five tertiary care hospitals. In this study, patients receiving warfarin who had an INR value between 4.5 and 10.0, and who did not have an indication for the immediate normalisation of their INR, had their warfarin withheld, and were randomly allocated to receive either 1 mg of vitamin K or placebo orally. The primary outcome measure was the INR value on the day after treatment. Secondary outcome measures included INR values on subsequent days, and the risk of haemorrhage and recurrent thrombosis over a 3 month follow-up period.Patients given vitamin K had a more rapid decrease in the INR than those given placebo (25 of 45 (56%] vs nine of 44 [20%] patients with INR values of 1.8-3.2 on the day after treatment, respectively, p=0.001; odds ratio [OR] 0.21, 95% CI 0.07-0.57). Fewer patients given vitamin K had bleeding episodes during the follow-up period than those given placebo (two [4%] vs eight [17%] patients, respectively, p=0.050; OR 0.87, 95% CI 0.019-0.999).Low dose oral vitamin K is more effective than placebo for the rapid lowering of raised INR values in patients taking warfarin.","Treatment of warfarin-associated coagulopathy with oral vitamin K: a randomised controlled trial."
"61","Lancet.4","0.05",11075768,2000,"Warfarin-associated coagulopathy is a frequent clinical complication. We aimed to assess whether treatment with vitamin K is safe and more effective than placebo in rapidly lowering the international normalised ratio (INR) into the therapeutic range in over anticoagulated patients receiving warfarin.We did a multicentre, double-blind, placebo-controlled, randomised trial in five tertiary care hospitals. In this study, patients receiving warfarin who had an INR value between 4.5 and 10.0, and who did not have an indication for the immediate normalisation of their INR, had their warfarin withheld, and were randomly allocated to receive either 1 mg of vitamin K or placebo orally. The primary outcome measure was the INR value on the day after treatment. Secondary outcome measures included INR values on subsequent days, and the risk of haemorrhage and recurrent thrombosis over a 3 month follow-up period.Patients given vitamin K had a more rapid decrease in the INR than those given placebo (25 of 45 (56%] vs nine of 44 [20%] patients with INR values of 1.8-3.2 on the day after treatment, respectively, p=0.001; odds ratio [OR] 0.21, 95% CI 0.07-0.57). Fewer patients given vitamin K had bleeding episodes during the follow-up period than those given placebo (two [4%] vs eight [17%] patients, respectively, p=0.050; OR 0.87, 95% CI 0.019-0.999).Low dose oral vitamin K is more effective than placebo for the rapid lowering of raised INR values in patients taking warfarin.","Treatment of warfarin-associated coagulopathy with oral vitamin K: a randomised controlled trial."
"62","JAMA.16","NA",11122586,2000,"A relative paucity of data exist on the possible health effects of using cellular telephones.To test the hypothesis that using handheld cellular telephones is related to the risk of primary brain cancer.Case-control study conducted in 5 US academic medical centers between 1994 and 1998 using a structured questionnaire.A total of 469 men and women aged 18 to 80 years with primary brain cancer and 422 matched controls without brain cancer.Risk of brain cancer compared by use of handheld cellular telephones, in hours per month and years of use.The median monthly hours of use were 2.5 for cases and 2.2 for controls. Compared with patients who never used handheld cellular telephones, the multivariate odds ratio (OR) associated with regular past or current use was 0.85 (95% confidence interval [CI], 0.6-1.2). The OR for infrequent users (<0. 72 h/mo) was 1.0 (95% CI, 0.5-2.0) and for frequent users (>10.1 h/mo) was 0.7 (95% CI, 0.3-1.4). The mean duration of use was 2.8 years for cases and 2.7 years for controls; no association with brain cancer was observed according to duration of use (P =.54). In cases, cerebral tumors occurred more frequently on the same side of the head where cellular telephones had been used (26 vs 15 cases; P =.06), but in the cases with temporal lobe cancer a greater proportion of tumors occurred in the contralateral than ipsilateral side (9 vs 5 cases; P =.33). The OR was less than 1.0 for all histologic categories of brain cancer except for uncommon neuroepitheliomatous cancers (OR, 2.1; 95% CI, 0.9-4.7).Our data suggest that use of handheld cellular telephones is not associated with risk of brain cancer, but further studies are needed to account for longer induction periods, especially for slow-growing tumors with neuronal features.","Handheld cellular telephone use and risk of brain cancer."
"63","JAMA.17","NA",11122586,2000,"A relative paucity of data exist on the possible health effects of using cellular telephones.To test the hypothesis that using handheld cellular telephones is related to the risk of primary brain cancer.Case-control study conducted in 5 US academic medical centers between 1994 and 1998 using a structured questionnaire.A total of 469 men and women aged 18 to 80 years with primary brain cancer and 422 matched controls without brain cancer.Risk of brain cancer compared by use of handheld cellular telephones, in hours per month and years of use.The median monthly hours of use were 2.5 for cases and 2.2 for controls. Compared with patients who never used handheld cellular telephones, the multivariate odds ratio (OR) associated with regular past or current use was 0.85 (95% confidence interval [CI], 0.6-1.2). The OR for infrequent users (<0. 72 h/mo) was 1.0 (95% CI, 0.5-2.0) and for frequent users (>10.1 h/mo) was 0.7 (95% CI, 0.3-1.4). The mean duration of use was 2.8 years for cases and 2.7 years for controls; no association with brain cancer was observed according to duration of use (P =.54). In cases, cerebral tumors occurred more frequently on the same side of the head where cellular telephones had been used (26 vs 15 cases; P =.06), but in the cases with temporal lobe cancer a greater proportion of tumors occurred in the contralateral than ipsilateral side (9 vs 5 cases; P =.33). The OR was less than 1.0 for all histologic categories of brain cancer except for uncommon neuroepitheliomatous cancers (OR, 2.1; 95% CI, 0.9-4.7).Our data suggest that use of handheld cellular telephones is not associated with risk of brain cancer, but further studies are needed to account for longer induction periods, especially for slow-growing tumors with neuronal features.","Handheld cellular telephone use and risk of brain cancer."
"64","JAMA.18","NA",11122586,2000,"A relative paucity of data exist on the possible health effects of using cellular telephones.To test the hypothesis that using handheld cellular telephones is related to the risk of primary brain cancer.Case-control study conducted in 5 US academic medical centers between 1994 and 1998 using a structured questionnaire.A total of 469 men and women aged 18 to 80 years with primary brain cancer and 422 matched controls without brain cancer.Risk of brain cancer compared by use of handheld cellular telephones, in hours per month and years of use.The median monthly hours of use were 2.5 for cases and 2.2 for controls. Compared with patients who never used handheld cellular telephones, the multivariate odds ratio (OR) associated with regular past or current use was 0.85 (95% confidence interval [CI], 0.6-1.2). The OR for infrequent users (<0. 72 h/mo) was 1.0 (95% CI, 0.5-2.0) and for frequent users (>10.1 h/mo) was 0.7 (95% CI, 0.3-1.4). The mean duration of use was 2.8 years for cases and 2.7 years for controls; no association with brain cancer was observed according to duration of use (P =.54). In cases, cerebral tumors occurred more frequently on the same side of the head where cellular telephones had been used (26 vs 15 cases; P =.06), but in the cases with temporal lobe cancer a greater proportion of tumors occurred in the contralateral than ipsilateral side (9 vs 5 cases; P =.33). The OR was less than 1.0 for all histologic categories of brain cancer except for uncommon neuroepitheliomatous cancers (OR, 2.1; 95% CI, 0.9-4.7).Our data suggest that use of handheld cellular telephones is not associated with risk of brain cancer, but further studies are needed to account for longer induction periods, especially for slow-growing tumors with neuronal features.","Handheld cellular telephone use and risk of brain cancer."
"65","JAMA.18","NA",11122586,2000,"A relative paucity of data exist on the possible health effects of using cellular telephones.To test the hypothesis that using handheld cellular telephones is related to the risk of primary brain cancer.Case-control study conducted in 5 US academic medical centers between 1994 and 1998 using a structured questionnaire.A total of 469 men and women aged 18 to 80 years with primary brain cancer and 422 matched controls without brain cancer.Risk of brain cancer compared by use of handheld cellular telephones, in hours per month and years of use.The median monthly hours of use were 2.5 for cases and 2.2 for controls. Compared with patients who never used handheld cellular telephones, the multivariate odds ratio (OR) associated with regular past or current use was 0.85 (95% confidence interval [CI], 0.6-1.2). The OR for infrequent users (<0. 72 h/mo) was 1.0 (95% CI, 0.5-2.0) and for frequent users (>10.1 h/mo) was 0.7 (95% CI, 0.3-1.4). The mean duration of use was 2.8 years for cases and 2.7 years for controls; no association with brain cancer was observed according to duration of use (P =.54). In cases, cerebral tumors occurred more frequently on the same side of the head where cellular telephones had been used (26 vs 15 cases; P =.06), but in the cases with temporal lobe cancer a greater proportion of tumors occurred in the contralateral than ipsilateral side (9 vs 5 cases; P =.33). The OR was less than 1.0 for all histologic categories of brain cancer except for uncommon neuroepitheliomatous cancers (OR, 2.1; 95% CI, 0.9-4.7).Our data suggest that use of handheld cellular telephones is not associated with risk of brain cancer, but further studies are needed to account for longer induction periods, especially for slow-growing tumors with neuronal features.","Handheld cellular telephone use and risk of brain cancer."
"66","JAMA","0.01",11147987,2000,"Management of patients with acute transient ischemic attack (TIA) varies widely, with some institutions admitting all patients and others proceeding with outpatient evaluations. Defining the short-term prognosis and risk factors for stroke after TIA may provide guidance in determining which patients need rapid evaluation.To determine the short-term risk of stroke and other adverse events after emergency department (ED) diagnosis of TIA.Cohort study conducted from March 1997 through February 1998 in 16 hospitals in a health maintenance organization in northern California. Patients A total of 1707 patients (mean age, 72 years) identified by ED physicians as having presented with TIA.Risk of stroke during the 90 days after index TIA; other events, including death, recurrent TIA, and hospitalization for cardiovascular events.During the 90 days after index TIA, 180 patients (10.5%) returned to the ED with a stroke, 91 of which occurred in the first 2 days. Five factors were independently associated with stroke: age greater than 60 years (odds ratio [OR], 1.8; 95% confidence interval [CI], 1.1-2.7; P=.01), diabetes mellitus (OR, 2.0; 95% CI, 1.4-2.9; P<.001), symptom duration longer than 10 minutes (OR, 2.3; 95% CI, 1.3-4.2; P=.005), weakness (OR, 1.9; 95% CI, 1.4-2.6; P<.001), and speech impairment (OR, 1.5; 95% CI, 1.1-2.1; P=.01). Stroke or other adverse events occurred in 428 patients (25.1%) in the 90 days after the TIA and included 44 hospitalizations for cardiovascular events (2.6%), 45 deaths (2.6%), and 216 recurrent TIAs (12.7%).Our results indicate that the short-term risk of stroke and other adverse events among patients who present to an ED with a TIA is substantial. Characteristics of the patient and the TIA may be useful for identifying patients who may benefit from expeditious evaluation and treatment.","Short-term prognosis after emergency department diagnosis of TIA."
"67","JAMA","0.001",11147987,2000,"Management of patients with acute transient ischemic attack (TIA) varies widely, with some institutions admitting all patients and others proceeding with outpatient evaluations. Defining the short-term prognosis and risk factors for stroke after TIA may provide guidance in determining which patients need rapid evaluation.To determine the short-term risk of stroke and other adverse events after emergency department (ED) diagnosis of TIA.Cohort study conducted from March 1997 through February 1998 in 16 hospitals in a health maintenance organization in northern California. Patients A total of 1707 patients (mean age, 72 years) identified by ED physicians as having presented with TIA.Risk of stroke during the 90 days after index TIA; other events, including death, recurrent TIA, and hospitalization for cardiovascular events.During the 90 days after index TIA, 180 patients (10.5%) returned to the ED with a stroke, 91 of which occurred in the first 2 days. Five factors were independently associated with stroke: age greater than 60 years (odds ratio [OR], 1.8; 95% confidence interval [CI], 1.1-2.7; P=.01), diabetes mellitus (OR, 2.0; 95% CI, 1.4-2.9; P<.001), symptom duration longer than 10 minutes (OR, 2.3; 95% CI, 1.3-4.2; P=.005), weakness (OR, 1.9; 95% CI, 1.4-2.6; P<.001), and speech impairment (OR, 1.5; 95% CI, 1.1-2.1; P=.01). Stroke or other adverse events occurred in 428 patients (25.1%) in the 90 days after the TIA and included 44 hospitalizations for cardiovascular events (2.6%), 45 deaths (2.6%), and 216 recurrent TIAs (12.7%).Our results indicate that the short-term risk of stroke and other adverse events among patients who present to an ED with a TIA is substantial. Characteristics of the patient and the TIA may be useful for identifying patients who may benefit from expeditious evaluation and treatment.","Short-term prognosis after emergency department diagnosis of TIA."
"68","JAMA","0.005",11147987,2000,"Management of patients with acute transient ischemic attack (TIA) varies widely, with some institutions admitting all patients and others proceeding with outpatient evaluations. Defining the short-term prognosis and risk factors for stroke after TIA may provide guidance in determining which patients need rapid evaluation.To determine the short-term risk of stroke and other adverse events after emergency department (ED) diagnosis of TIA.Cohort study conducted from March 1997 through February 1998 in 16 hospitals in a health maintenance organization in northern California. Patients A total of 1707 patients (mean age, 72 years) identified by ED physicians as having presented with TIA.Risk of stroke during the 90 days after index TIA; other events, including death, recurrent TIA, and hospitalization for cardiovascular events.During the 90 days after index TIA, 180 patients (10.5%) returned to the ED with a stroke, 91 of which occurred in the first 2 days. Five factors were independently associated with stroke: age greater than 60 years (odds ratio [OR], 1.8; 95% confidence interval [CI], 1.1-2.7; P=.01), diabetes mellitus (OR, 2.0; 95% CI, 1.4-2.9; P<.001), symptom duration longer than 10 minutes (OR, 2.3; 95% CI, 1.3-4.2; P=.005), weakness (OR, 1.9; 95% CI, 1.4-2.6; P<.001), and speech impairment (OR, 1.5; 95% CI, 1.1-2.1; P=.01). Stroke or other adverse events occurred in 428 patients (25.1%) in the 90 days after the TIA and included 44 hospitalizations for cardiovascular events (2.6%), 45 deaths (2.6%), and 216 recurrent TIAs (12.7%).Our results indicate that the short-term risk of stroke and other adverse events among patients who present to an ED with a TIA is substantial. Characteristics of the patient and the TIA may be useful for identifying patients who may benefit from expeditious evaluation and treatment.","Short-term prognosis after emergency department diagnosis of TIA."
"69","JAMA","0.001",11147987,2000,"Management of patients with acute transient ischemic attack (TIA) varies widely, with some institutions admitting all patients and others proceeding with outpatient evaluations. Defining the short-term prognosis and risk factors for stroke after TIA may provide guidance in determining which patients need rapid evaluation.To determine the short-term risk of stroke and other adverse events after emergency department (ED) diagnosis of TIA.Cohort study conducted from March 1997 through February 1998 in 16 hospitals in a health maintenance organization in northern California. Patients A total of 1707 patients (mean age, 72 years) identified by ED physicians as having presented with TIA.Risk of stroke during the 90 days after index TIA; other events, including death, recurrent TIA, and hospitalization for cardiovascular events.During the 90 days after index TIA, 180 patients (10.5%) returned to the ED with a stroke, 91 of which occurred in the first 2 days. Five factors were independently associated with stroke: age greater than 60 years (odds ratio [OR], 1.8; 95% confidence interval [CI], 1.1-2.7; P=.01), diabetes mellitus (OR, 2.0; 95% CI, 1.4-2.9; P<.001), symptom duration longer than 10 minutes (OR, 2.3; 95% CI, 1.3-4.2; P=.005), weakness (OR, 1.9; 95% CI, 1.4-2.6; P<.001), and speech impairment (OR, 1.5; 95% CI, 1.1-2.1; P=.01). Stroke or other adverse events occurred in 428 patients (25.1%) in the 90 days after the TIA and included 44 hospitalizations for cardiovascular events (2.6%), 45 deaths (2.6%), and 216 recurrent TIAs (12.7%).Our results indicate that the short-term risk of stroke and other adverse events among patients who present to an ED with a TIA is substantial. Characteristics of the patient and the TIA may be useful for identifying patients who may benefit from expeditious evaluation and treatment.","Short-term prognosis after emergency department diagnosis of TIA."
"70","JAMA.1","0.01",11147987,2000,"Management of patients with acute transient ischemic attack (TIA) varies widely, with some institutions admitting all patients and others proceeding with outpatient evaluations. Defining the short-term prognosis and risk factors for stroke after TIA may provide guidance in determining which patients need rapid evaluation.To determine the short-term risk of stroke and other adverse events after emergency department (ED) diagnosis of TIA.Cohort study conducted from March 1997 through February 1998 in 16 hospitals in a health maintenance organization in northern California. Patients A total of 1707 patients (mean age, 72 years) identified by ED physicians as having presented with TIA.Risk of stroke during the 90 days after index TIA; other events, including death, recurrent TIA, and hospitalization for cardiovascular events.During the 90 days after index TIA, 180 patients (10.5%) returned to the ED with a stroke, 91 of which occurred in the first 2 days. Five factors were independently associated with stroke: age greater than 60 years (odds ratio [OR], 1.8; 95% confidence interval [CI], 1.1-2.7; P=.01), diabetes mellitus (OR, 2.0; 95% CI, 1.4-2.9; P<.001), symptom duration longer than 10 minutes (OR, 2.3; 95% CI, 1.3-4.2; P=.005), weakness (OR, 1.9; 95% CI, 1.4-2.6; P<.001), and speech impairment (OR, 1.5; 95% CI, 1.1-2.1; P=.01). Stroke or other adverse events occurred in 428 patients (25.1%) in the 90 days after the TIA and included 44 hospitalizations for cardiovascular events (2.6%), 45 deaths (2.6%), and 216 recurrent TIAs (12.7%).Our results indicate that the short-term risk of stroke and other adverse events among patients who present to an ED with a TIA is substantial. Characteristics of the patient and the TIA may be useful for identifying patients who may benefit from expeditious evaluation and treatment.","Short-term prognosis after emergency department diagnosis of TIA."
"71","JAMA.54","NA",11150108,2001,"Human papillomavirus (HPV) infection has been established as a cause of cervical cancer. Epidemiologic studies suggest that Chlamydia trachomatis infection also confers increased risk for cervical squamous cell carcinoma (SCC). Whether this risk is serotype-specific is unknown.To study the association between exposure to different C trachomatis serotypes and subsequent development of cervical SCC.Longitudinal, nested case-control study within a cohort of 530 000 women who provided samples to serum banks in Finland, Norway, and Sweden. The data files were linked to respective national cancer registries.One hundred twenty-eight women who had developed invasive cervical SCC at least 12 months following serum donation. Each case had 3 matched controls.Risk for the development of cervical SCC by IgG antibodies to 10 different C trachomatis serotypes, adjusted for antibodies to HPV types 16, 18, and 33 and for serum cotinine levels.Of specific C trachomatis serotypes, serotype G was most strongly associated with SCC (adjusted odds ratio [OR], 6.6; 95% confidence interval [CI], 1. 6-27.0). Other serotypes associated with SCC were I (OR, 3.8; 95% CI, 1.3-11.0) and D (OR, 2.7; 95% CI, 1.3-5.6). Presence of serum IgG antibodies to more than 1 serotype increased the adjusted ORs for SCC (P<.001 for trend).Chlamydia trachomatis serotype G is most strongly associated with subsequent development of cervical SCC. Increasing numbers of exposures to different C trachomatis serotypes also increases risk. Our results strengthen the evidence that there is a link between past C trachomatis infection and cervical SCC.","Serotypes of Chlamydia trachomatis and risk for development of cervical squamous cell carcinoma."
"72","JAMA.54","NA",11150108,2001,"Human papillomavirus (HPV) infection has been established as a cause of cervical cancer. Epidemiologic studies suggest that Chlamydia trachomatis infection also confers increased risk for cervical squamous cell carcinoma (SCC). Whether this risk is serotype-specific is unknown.To study the association between exposure to different C trachomatis serotypes and subsequent development of cervical SCC.Longitudinal, nested case-control study within a cohort of 530 000 women who provided samples to serum banks in Finland, Norway, and Sweden. The data files were linked to respective national cancer registries.One hundred twenty-eight women who had developed invasive cervical SCC at least 12 months following serum donation. Each case had 3 matched controls.Risk for the development of cervical SCC by IgG antibodies to 10 different C trachomatis serotypes, adjusted for antibodies to HPV types 16, 18, and 33 and for serum cotinine levels.Of specific C trachomatis serotypes, serotype G was most strongly associated with SCC (adjusted odds ratio [OR], 6.6; 95% confidence interval [CI], 1. 6-27.0). Other serotypes associated with SCC were I (OR, 3.8; 95% CI, 1.3-11.0) and D (OR, 2.7; 95% CI, 1.3-5.6). Presence of serum IgG antibodies to more than 1 serotype increased the adjusted ORs for SCC (P<.001 for trend).Chlamydia trachomatis serotype G is most strongly associated with subsequent development of cervical SCC. Increasing numbers of exposures to different C trachomatis serotypes also increases risk. Our results strengthen the evidence that there is a link between past C trachomatis infection and cervical SCC.","Serotypes of Chlamydia trachomatis and risk for development of cervical squamous cell carcinoma."
"73","JAMA.54","NA",11150108,2001,"Human papillomavirus (HPV) infection has been established as a cause of cervical cancer. Epidemiologic studies suggest that Chlamydia trachomatis infection also confers increased risk for cervical squamous cell carcinoma (SCC). Whether this risk is serotype-specific is unknown.To study the association between exposure to different C trachomatis serotypes and subsequent development of cervical SCC.Longitudinal, nested case-control study within a cohort of 530 000 women who provided samples to serum banks in Finland, Norway, and Sweden. The data files were linked to respective national cancer registries.One hundred twenty-eight women who had developed invasive cervical SCC at least 12 months following serum donation. Each case had 3 matched controls.Risk for the development of cervical SCC by IgG antibodies to 10 different C trachomatis serotypes, adjusted for antibodies to HPV types 16, 18, and 33 and for serum cotinine levels.Of specific C trachomatis serotypes, serotype G was most strongly associated with SCC (adjusted odds ratio [OR], 6.6; 95% confidence interval [CI], 1. 6-27.0). Other serotypes associated with SCC were I (OR, 3.8; 95% CI, 1.3-11.0) and D (OR, 2.7; 95% CI, 1.3-5.6). Presence of serum IgG antibodies to more than 1 serotype increased the adjusted ORs for SCC (P<.001 for trend).Chlamydia trachomatis serotype G is most strongly associated with subsequent development of cervical SCC. Increasing numbers of exposures to different C trachomatis serotypes also increases risk. Our results strengthen the evidence that there is a link between past C trachomatis infection and cervical SCC.","Serotypes of Chlamydia trachomatis and risk for development of cervical squamous cell carcinoma."
"74","American Journal of Epidemiology.8","0.001",11226980,2001,"Associations between metabolic syndrome components and prevalent ischemic heart disease (IHD) were investigated in a cross-sectional, community-based study of elderly men (n = 1,015) and women (n = 1,259) in Rancho Bernardo, California, in 1984-1987. In both sexes, there were significant positive associations between IHD defined by resting electrocardiogram criteria and age, systolic blood pressure, fasting and postchallenge hyperglycemia, total cholesterol/high density lipoprotein cholesterol (HDL cholesterol) ratio, and triglycerides and an inverse significant association with HDL cholesterol. High collinearity and interactions between serum insulin and metabolic syndrome variables were accounted for by uncorrelated principal components identified by factor analysis. In both men and women, three uncorrelated principal components were identified, representing a central metabolic factor (body mass index, fasting and 2-hour serum insulin, high serum triglycerides, and low HDL cholesterol), a glucose factor, and a blood pressure factor. In a multivariate model with age and sex, all three factors were significantly associated with IHD by electrocardiogram criteria; central metabolic factor (odds ratio (OR) = 1.6, p = 0.001), glucose factor (OR = 1.4, p < 0.001), blood pressure factor (OR = 1.2, p = 0.005), age (10 years) (OR = 1.8, p < 0.001), and female sex (OR = 0.5, p < 0.02). Similar results were obtained in analyses using clinically manifest IHD as the outcome. These results support the thesis that the metabolic syndrome exerts effects through different risk factors by different mechanisms.","Metabolic syndrome and ischemic heart disease in elderly men and women."
"75","American Journal of Epidemiology.9","0.001",11226980,2001,"Associations between metabolic syndrome components and prevalent ischemic heart disease (IHD) were investigated in a cross-sectional, community-based study of elderly men (n = 1,015) and women (n = 1,259) in Rancho Bernardo, California, in 1984-1987. In both sexes, there were significant positive associations between IHD defined by resting electrocardiogram criteria and age, systolic blood pressure, fasting and postchallenge hyperglycemia, total cholesterol/high density lipoprotein cholesterol (HDL cholesterol) ratio, and triglycerides and an inverse significant association with HDL cholesterol. High collinearity and interactions between serum insulin and metabolic syndrome variables were accounted for by uncorrelated principal components identified by factor analysis. In both men and women, three uncorrelated principal components were identified, representing a central metabolic factor (body mass index, fasting and 2-hour serum insulin, high serum triglycerides, and low HDL cholesterol), a glucose factor, and a blood pressure factor. In a multivariate model with age and sex, all three factors were significantly associated with IHD by electrocardiogram criteria; central metabolic factor (odds ratio (OR) = 1.6, p = 0.001), glucose factor (OR = 1.4, p < 0.001), blood pressure factor (OR = 1.2, p = 0.005), age (10 years) (OR = 1.8, p < 0.001), and female sex (OR = 0.5, p < 0.02). Similar results were obtained in analyses using clinically manifest IHD as the outcome. These results support the thesis that the metabolic syndrome exerts effects through different risk factors by different mechanisms.","Metabolic syndrome and ischemic heart disease in elderly men and women."
"76","American Journal of Epidemiology.10","0.02",11226980,2001,"Associations between metabolic syndrome components and prevalent ischemic heart disease (IHD) were investigated in a cross-sectional, community-based study of elderly men (n = 1,015) and women (n = 1,259) in Rancho Bernardo, California, in 1984-1987. In both sexes, there were significant positive associations between IHD defined by resting electrocardiogram criteria and age, systolic blood pressure, fasting and postchallenge hyperglycemia, total cholesterol/high density lipoprotein cholesterol (HDL cholesterol) ratio, and triglycerides and an inverse significant association with HDL cholesterol. High collinearity and interactions between serum insulin and metabolic syndrome variables were accounted for by uncorrelated principal components identified by factor analysis. In both men and women, three uncorrelated principal components were identified, representing a central metabolic factor (body mass index, fasting and 2-hour serum insulin, high serum triglycerides, and low HDL cholesterol), a glucose factor, and a blood pressure factor. In a multivariate model with age and sex, all three factors were significantly associated with IHD by electrocardiogram criteria; central metabolic factor (odds ratio (OR) = 1.6, p = 0.001), glucose factor (OR = 1.4, p < 0.001), blood pressure factor (OR = 1.2, p = 0.005), age (10 years) (OR = 1.8, p < 0.001), and female sex (OR = 0.5, p < 0.02). Similar results were obtained in analyses using clinically manifest IHD as the outcome. These results support the thesis that the metabolic syndrome exerts effects through different risk factors by different mechanisms.","Metabolic syndrome and ischemic heart disease in elderly men and women."
"77","American Journal of Epidemiology.16","0.001",11226980,2001,"Associations between metabolic syndrome components and prevalent ischemic heart disease (IHD) were investigated in a cross-sectional, community-based study of elderly men (n = 1,015) and women (n = 1,259) in Rancho Bernardo, California, in 1984-1987. In both sexes, there were significant positive associations between IHD defined by resting electrocardiogram criteria and age, systolic blood pressure, fasting and postchallenge hyperglycemia, total cholesterol/high density lipoprotein cholesterol (HDL cholesterol) ratio, and triglycerides and an inverse significant association with HDL cholesterol. High collinearity and interactions between serum insulin and metabolic syndrome variables were accounted for by uncorrelated principal components identified by factor analysis. In both men and women, three uncorrelated principal components were identified, representing a central metabolic factor (body mass index, fasting and 2-hour serum insulin, high serum triglycerides, and low HDL cholesterol), a glucose factor, and a blood pressure factor. In a multivariate model with age and sex, all three factors were significantly associated with IHD by electrocardiogram criteria; central metabolic factor (odds ratio (OR) = 1.6, p = 0.001), glucose factor (OR = 1.4, p < 0.001), blood pressure factor (OR = 1.2, p = 0.005), age (10 years) (OR = 1.8, p < 0.001), and female sex (OR = 0.5, p < 0.02). Similar results were obtained in analyses using clinically manifest IHD as the outcome. These results support the thesis that the metabolic syndrome exerts effects through different risk factors by different mechanisms.","Metabolic syndrome and ischemic heart disease in elderly men and women."
"78","American Journal of Epidemiology.17","0.005",11226980,2001,"Associations between metabolic syndrome components and prevalent ischemic heart disease (IHD) were investigated in a cross-sectional, community-based study of elderly men (n = 1,015) and women (n = 1,259) in Rancho Bernardo, California, in 1984-1987. In both sexes, there were significant positive associations between IHD defined by resting electrocardiogram criteria and age, systolic blood pressure, fasting and postchallenge hyperglycemia, total cholesterol/high density lipoprotein cholesterol (HDL cholesterol) ratio, and triglycerides and an inverse significant association with HDL cholesterol. High collinearity and interactions between serum insulin and metabolic syndrome variables were accounted for by uncorrelated principal components identified by factor analysis. In both men and women, three uncorrelated principal components were identified, representing a central metabolic factor (body mass index, fasting and 2-hour serum insulin, high serum triglycerides, and low HDL cholesterol), a glucose factor, and a blood pressure factor. In a multivariate model with age and sex, all three factors were significantly associated with IHD by electrocardiogram criteria; central metabolic factor (odds ratio (OR) = 1.6, p = 0.001), glucose factor (OR = 1.4, p < 0.001), blood pressure factor (OR = 1.2, p = 0.005), age (10 years) (OR = 1.8, p < 0.001), and female sex (OR = 0.5, p < 0.02). Similar results were obtained in analyses using clinically manifest IHD as the outcome. These results support the thesis that the metabolic syndrome exerts effects through different risk factors by different mechanisms.","Metabolic syndrome and ischemic heart disease in elderly men and women."
"79","JAMA.53","NA",11242425,2001,"Current evidence that breastfeeding is beneficial for infant and child health is based exclusively on observational studies. Potential sources of bias in such studies have led to doubts about the magnitude of these health benefits in industrialized countries.To assess the effects of breastfeeding promotion on breastfeeding duration and exclusivity and gastrointestinal and respiratory infection and atopic eczema among infants.The Promotion of Breastfeeding Intervention Trial (PROBIT), a cluster-randomized trial conducted June 1996-December 1997 with a 1-year follow-up.Thirty-one maternity hospitals and polyclinics in the Republic of Belarus.A total of 17 046 mother-infant pairs consisting of full-term singleton infants weighing at least 2500 g and their healthy mothers who intended to breastfeed, 16491 (96.7%) of which completed the entire 12 months of follow-up.Sites were randomly assigned to receive an experimental intervention (n = 16) modeled on the Baby-Friendly Hospital Initiative of the World Health Organization and United Nations Children's Fund, which emphasizes health care worker assistance with initiating and maintaining breastfeeding and lactation and postnatal breastfeeding support, or a control intervention (n = 15) of continuing usual infant feeding practices and policies.Duration of any breastfeeding, prevalence of predominant and exclusive breastfeeding at 3 and 6 months of life and occurrence of 1 or more episodes of gastrointestinal tract infection, 2 or more episodes of respiratory tract infection, and atopic eczema during the first 12 months of life, compared between the intervention and control groups.Infants from the intervention sites were significantly more likely than control infants to be breastfed to any degree at 12 months (19.7% vs 11.4%; adjusted odds ratio [OR], 0.47; 95% confidence interval [CI], 0.32-0.69), were more likely to be exclusively breastfed at 3 months (43.3% vs 6.4%; P<.001) and at 6 months (7.9% vs 0.6%; P =.01), and had a significant reduction in the risk of 1 or more gastrointestinal tract infections (9.1% vs 13.2%; adjusted OR, 0.60; 95% CI, 0.40-0.91) and of atopic eczema (3.3% vs 6.3%; adjusted OR, 0.54; 95% CI, 0.31-0.95), but no significant reduction in respiratory tract infection (intervention group, 39.2%; control group, 39.4%; adjusted OR, 0.87; 95% CI, 0.59-1.28).Our experimental intervention increased the duration and degree (exclusivity) of breastfeeding and decreased the risk of gastrointestinal tract infection and atopic eczema in the first year of life. These results provide a solid scientific underpinning for future interventions to promote breastfeeding.","Promotion of Breastfeeding Intervention Trial (PROBIT): a randomized trial in the Republic of Belarus."
"80","JAMA.53","NA",11242425,2001,"Current evidence that breastfeeding is beneficial for infant and child health is based exclusively on observational studies. Potential sources of bias in such studies have led to doubts about the magnitude of these health benefits in industrialized countries.To assess the effects of breastfeeding promotion on breastfeeding duration and exclusivity and gastrointestinal and respiratory infection and atopic eczema among infants.The Promotion of Breastfeeding Intervention Trial (PROBIT), a cluster-randomized trial conducted June 1996-December 1997 with a 1-year follow-up.Thirty-one maternity hospitals and polyclinics in the Republic of Belarus.A total of 17 046 mother-infant pairs consisting of full-term singleton infants weighing at least 2500 g and their healthy mothers who intended to breastfeed, 16491 (96.7%) of which completed the entire 12 months of follow-up.Sites were randomly assigned to receive an experimental intervention (n = 16) modeled on the Baby-Friendly Hospital Initiative of the World Health Organization and United Nations Children's Fund, which emphasizes health care worker assistance with initiating and maintaining breastfeeding and lactation and postnatal breastfeeding support, or a control intervention (n = 15) of continuing usual infant feeding practices and policies.Duration of any breastfeeding, prevalence of predominant and exclusive breastfeeding at 3 and 6 months of life and occurrence of 1 or more episodes of gastrointestinal tract infection, 2 or more episodes of respiratory tract infection, and atopic eczema during the first 12 months of life, compared between the intervention and control groups.Infants from the intervention sites were significantly more likely than control infants to be breastfed to any degree at 12 months (19.7% vs 11.4%; adjusted odds ratio [OR], 0.47; 95% confidence interval [CI], 0.32-0.69), were more likely to be exclusively breastfed at 3 months (43.3% vs 6.4%; P<.001) and at 6 months (7.9% vs 0.6%; P =.01), and had a significant reduction in the risk of 1 or more gastrointestinal tract infections (9.1% vs 13.2%; adjusted OR, 0.60; 95% CI, 0.40-0.91) and of atopic eczema (3.3% vs 6.3%; adjusted OR, 0.54; 95% CI, 0.31-0.95), but no significant reduction in respiratory tract infection (intervention group, 39.2%; control group, 39.4%; adjusted OR, 0.87; 95% CI, 0.59-1.28).Our experimental intervention increased the duration and degree (exclusivity) of breastfeeding and decreased the risk of gastrointestinal tract infection and atopic eczema in the first year of life. These results provide a solid scientific underpinning for future interventions to promote breastfeeding.","Promotion of Breastfeeding Intervention Trial (PROBIT): a randomized trial in the Republic of Belarus."
"81","JAMA.53","NA",11242425,2001,"Current evidence that breastfeeding is beneficial for infant and child health is based exclusively on observational studies. Potential sources of bias in such studies have led to doubts about the magnitude of these health benefits in industrialized countries.To assess the effects of breastfeeding promotion on breastfeeding duration and exclusivity and gastrointestinal and respiratory infection and atopic eczema among infants.The Promotion of Breastfeeding Intervention Trial (PROBIT), a cluster-randomized trial conducted June 1996-December 1997 with a 1-year follow-up.Thirty-one maternity hospitals and polyclinics in the Republic of Belarus.A total of 17 046 mother-infant pairs consisting of full-term singleton infants weighing at least 2500 g and their healthy mothers who intended to breastfeed, 16491 (96.7%) of which completed the entire 12 months of follow-up.Sites were randomly assigned to receive an experimental intervention (n = 16) modeled on the Baby-Friendly Hospital Initiative of the World Health Organization and United Nations Children's Fund, which emphasizes health care worker assistance with initiating and maintaining breastfeeding and lactation and postnatal breastfeeding support, or a control intervention (n = 15) of continuing usual infant feeding practices and policies.Duration of any breastfeeding, prevalence of predominant and exclusive breastfeeding at 3 and 6 months of life and occurrence of 1 or more episodes of gastrointestinal tract infection, 2 or more episodes of respiratory tract infection, and atopic eczema during the first 12 months of life, compared between the intervention and control groups.Infants from the intervention sites were significantly more likely than control infants to be breastfed to any degree at 12 months (19.7% vs 11.4%; adjusted odds ratio [OR], 0.47; 95% confidence interval [CI], 0.32-0.69), were more likely to be exclusively breastfed at 3 months (43.3% vs 6.4%; P<.001) and at 6 months (7.9% vs 0.6%; P =.01), and had a significant reduction in the risk of 1 or more gastrointestinal tract infections (9.1% vs 13.2%; adjusted OR, 0.60; 95% CI, 0.40-0.91) and of atopic eczema (3.3% vs 6.3%; adjusted OR, 0.54; 95% CI, 0.31-0.95), but no significant reduction in respiratory tract infection (intervention group, 39.2%; control group, 39.4%; adjusted OR, 0.87; 95% CI, 0.59-1.28).Our experimental intervention increased the duration and degree (exclusivity) of breastfeeding and decreased the risk of gastrointestinal tract infection and atopic eczema in the first year of life. These results provide a solid scientific underpinning for future interventions to promote breastfeeding.","Promotion of Breastfeeding Intervention Trial (PROBIT): a randomized trial in the Republic of Belarus."
"82","JAMA.87","NA",11242425,2001,"Current evidence that breastfeeding is beneficial for infant and child health is based exclusively on observational studies. Potential sources of bias in such studies have led to doubts about the magnitude of these health benefits in industrialized countries.To assess the effects of breastfeeding promotion on breastfeeding duration and exclusivity and gastrointestinal and respiratory infection and atopic eczema among infants.The Promotion of Breastfeeding Intervention Trial (PROBIT), a cluster-randomized trial conducted June 1996-December 1997 with a 1-year follow-up.Thirty-one maternity hospitals and polyclinics in the Republic of Belarus.A total of 17 046 mother-infant pairs consisting of full-term singleton infants weighing at least 2500 g and their healthy mothers who intended to breastfeed, 16491 (96.7%) of which completed the entire 12 months of follow-up.Sites were randomly assigned to receive an experimental intervention (n = 16) modeled on the Baby-Friendly Hospital Initiative of the World Health Organization and United Nations Children's Fund, which emphasizes health care worker assistance with initiating and maintaining breastfeeding and lactation and postnatal breastfeeding support, or a control intervention (n = 15) of continuing usual infant feeding practices and policies.Duration of any breastfeeding, prevalence of predominant and exclusive breastfeeding at 3 and 6 months of life and occurrence of 1 or more episodes of gastrointestinal tract infection, 2 or more episodes of respiratory tract infection, and atopic eczema during the first 12 months of life, compared between the intervention and control groups.Infants from the intervention sites were significantly more likely than control infants to be breastfed to any degree at 12 months (19.7% vs 11.4%; adjusted odds ratio [OR], 0.47; 95% confidence interval [CI], 0.32-0.69), were more likely to be exclusively breastfed at 3 months (43.3% vs 6.4%; P<.001) and at 6 months (7.9% vs 0.6%; P =.01), and had a significant reduction in the risk of 1 or more gastrointestinal tract infections (9.1% vs 13.2%; adjusted OR, 0.60; 95% CI, 0.40-0.91) and of atopic eczema (3.3% vs 6.3%; adjusted OR, 0.54; 95% CI, 0.31-0.95), but no significant reduction in respiratory tract infection (intervention group, 39.2%; control group, 39.4%; adjusted OR, 0.87; 95% CI, 0.59-1.28).Our experimental intervention increased the duration and degree (exclusivity) of breastfeeding and decreased the risk of gastrointestinal tract infection and atopic eczema in the first year of life. These results provide a solid scientific underpinning for future interventions to promote breastfeeding.","Promotion of Breastfeeding Intervention Trial (PROBIT): a randomized trial in the Republic of Belarus."
"83","JAMA.86","NA",11242429,2001,"Recent studies have reported disagreement between meta-analysis of small trials and subsequent large trials addressing the same question. However, disagreement for uncommon but serious adverse safety outcomes has not been examined.To explore disagreement for serious adverse safety (intracranial hemorrhage [ICH]) and efficacy outcomes between meta-analysis of phase 2 (small) vs meta-analysis of phase 3 (large) randomized controlled trials comparing the efficacy of bolus thrombolytic therapy with infusion for acute myocardial infarction (AMI).Electronic databases (MEDLINE, Cochrane Database of Clinical Trials) between January 1980 and December 1999 using the search terms thrombolysis, thrombolytic therapy, and myocardial infarction; conference proceedings; and reference lists.Fifteen randomized trials comparing thrombolytic agents administered by bolus injection with standard infusion therapy in patients with AMI.Data on ICH, other causes of stroke, total mortality, and reinfarction were independently extracted from each study by 2 observers.Meta-analysis of 9 phase 2 trials (n = 3956) revealed a lower risk of ICH with bolus thrombolytic therapy (odds ratio [OR], 0.53; 95% confidence interval [CI], 0.27-1.01), which was not statistically significant. Meta-analysis of 6 phase 3 trials (n = 62 673) indicated a significant increase in risk of ICH (OR, 1.25; 95% CI, 1.06-1.49). These results were significantly different (P =.01). There was no disagreement for efficacy outcomes. Phase 2 trials included younger and heavier patients with lower baseline blood pressures, and were more often open-label. Subgroup analyses suggested that each of these factors was associated with a lower estimate of risk of ICH with bolus agents.Our results suggest that when therapeutic interventions are associated with a potential for uncommon but serious adverse safety outcomes, there may be differences between small phase 2 and large phase 3 trials that result in their disagreement for safety but not necessarily efficacy outcomes. Further investigation of the frequency and causes of disagreement between small and large trials for safety outcomes is warranted.","Safety outcomes in meta-analyses of phase 2 vs phase 3 randomized trials: Intracranial hemorrhage in trials of bolus thrombolytic therapy."
"84","JAMA.86","NA",11242429,2001,"Recent studies have reported disagreement between meta-analysis of small trials and subsequent large trials addressing the same question. However, disagreement for uncommon but serious adverse safety outcomes has not been examined.To explore disagreement for serious adverse safety (intracranial hemorrhage [ICH]) and efficacy outcomes between meta-analysis of phase 2 (small) vs meta-analysis of phase 3 (large) randomized controlled trials comparing the efficacy of bolus thrombolytic therapy with infusion for acute myocardial infarction (AMI).Electronic databases (MEDLINE, Cochrane Database of Clinical Trials) between January 1980 and December 1999 using the search terms thrombolysis, thrombolytic therapy, and myocardial infarction; conference proceedings; and reference lists.Fifteen randomized trials comparing thrombolytic agents administered by bolus injection with standard infusion therapy in patients with AMI.Data on ICH, other causes of stroke, total mortality, and reinfarction were independently extracted from each study by 2 observers.Meta-analysis of 9 phase 2 trials (n = 3956) revealed a lower risk of ICH with bolus thrombolytic therapy (odds ratio [OR], 0.53; 95% confidence interval [CI], 0.27-1.01), which was not statistically significant. Meta-analysis of 6 phase 3 trials (n = 62 673) indicated a significant increase in risk of ICH (OR, 1.25; 95% CI, 1.06-1.49). These results were significantly different (P =.01). There was no disagreement for efficacy outcomes. Phase 2 trials included younger and heavier patients with lower baseline blood pressures, and were more often open-label. Subgroup analyses suggested that each of these factors was associated with a lower estimate of risk of ICH with bolus agents.Our results suggest that when therapeutic interventions are associated with a potential for uncommon but serious adverse safety outcomes, there may be differences between small phase 2 and large phase 3 trials that result in their disagreement for safety but not necessarily efficacy outcomes. Further investigation of the frequency and causes of disagreement between small and large trials for safety outcomes is warranted.","Safety outcomes in meta-analyses of phase 2 vs phase 3 randomized trials: Intracranial hemorrhage in trials of bolus thrombolytic therapy."
"85","JAMA.2510","NA",11308432,2001,"Studies have found that individuals who consume 1 alcoholic drink every 1 to 2 days have a lower risk of a first acute myocardial infarction (AMI) than abstainers or heavy drinkers, but the effect of prior drinking on mortality after AMI is uncertain.To determine the effect of prior alcohol consumption on long-term mortality among early survivors of AMI.Prospective inception cohort study conducted at 45 US community and tertiary care hospitals between August 1989 and September 1994, with a median follow-up of 3.8 years.A total of 1913 adults hospitalized with AMI between 1989 and 1994.All-cause mortality, compared by self-reported average weekly consumption of beer, wine, and liquor during the year prior to AMI.Of the 1913 patients, 896 (47%) abstained from alcohol, 696 (36%) consumed less than 7 alcoholic drinks/wk, and 321 (17%) consumed 7 or more alcoholic drinks/wk. Compared with abstainers, patients who consumed less than 7 drinks/wk had a lower all-cause mortality rate (3.4 vs 6.3 deaths per 100 person-years; hazard ratio [HR], 0.55; 95% confidence interval [CI], 0.43-0.71) as did those who consumed 7 or more drinks/wk (2.4 vs 6.3 deaths per 100 person-years; HR, 0.38; 95% CI, 0.25-0.55; P<.001 for trend). After adjusting for propensity to drink and other potential confounders, increasing alcohol consumption remained predictive of lower mortality for less than 7 drinks/wk, with an adjusted HR of 0.79 (95% CI, 0.60-1.03), and for 7 or more drinks/wk, with an adjusted HR of 0.68 (95% CI, 0.45-1.05; P =.01 for trend). The association was similar for total and cardiovascular mortality, among both men and women, and among different types of alcoholic beverages.Self-reported moderate alcohol consumption in the year prior to AMI is associated with reduced mortality following infarction.","Prior alcohol consumption and mortality following acute myocardial infarction."
"86","JAMA.2510","NA",11308432,2001,"Studies have found that individuals who consume 1 alcoholic drink every 1 to 2 days have a lower risk of a first acute myocardial infarction (AMI) than abstainers or heavy drinkers, but the effect of prior drinking on mortality after AMI is uncertain.To determine the effect of prior alcohol consumption on long-term mortality among early survivors of AMI.Prospective inception cohort study conducted at 45 US community and tertiary care hospitals between August 1989 and September 1994, with a median follow-up of 3.8 years.A total of 1913 adults hospitalized with AMI between 1989 and 1994.All-cause mortality, compared by self-reported average weekly consumption of beer, wine, and liquor during the year prior to AMI.Of the 1913 patients, 896 (47%) abstained from alcohol, 696 (36%) consumed less than 7 alcoholic drinks/wk, and 321 (17%) consumed 7 or more alcoholic drinks/wk. Compared with abstainers, patients who consumed less than 7 drinks/wk had a lower all-cause mortality rate (3.4 vs 6.3 deaths per 100 person-years; hazard ratio [HR], 0.55; 95% confidence interval [CI], 0.43-0.71) as did those who consumed 7 or more drinks/wk (2.4 vs 6.3 deaths per 100 person-years; HR, 0.38; 95% CI, 0.25-0.55; P<.001 for trend). After adjusting for propensity to drink and other potential confounders, increasing alcohol consumption remained predictive of lower mortality for less than 7 drinks/wk, with an adjusted HR of 0.79 (95% CI, 0.60-1.03), and for 7 or more drinks/wk, with an adjusted HR of 0.68 (95% CI, 0.45-1.05; P =.01 for trend). The association was similar for total and cardiovascular mortality, among both men and women, and among different types of alcoholic beverages.Self-reported moderate alcohol consumption in the year prior to AMI is associated with reduced mortality following infarction.","Prior alcohol consumption and mortality following acute myocardial infarction."
"87","JAMA.2510","0.001",11308432,2001,"Studies have found that individuals who consume 1 alcoholic drink every 1 to 2 days have a lower risk of a first acute myocardial infarction (AMI) than abstainers or heavy drinkers, but the effect of prior drinking on mortality after AMI is uncertain.To determine the effect of prior alcohol consumption on long-term mortality among early survivors of AMI.Prospective inception cohort study conducted at 45 US community and tertiary care hospitals between August 1989 and September 1994, with a median follow-up of 3.8 years.A total of 1913 adults hospitalized with AMI between 1989 and 1994.All-cause mortality, compared by self-reported average weekly consumption of beer, wine, and liquor during the year prior to AMI.Of the 1913 patients, 896 (47%) abstained from alcohol, 696 (36%) consumed less than 7 alcoholic drinks/wk, and 321 (17%) consumed 7 or more alcoholic drinks/wk. Compared with abstainers, patients who consumed less than 7 drinks/wk had a lower all-cause mortality rate (3.4 vs 6.3 deaths per 100 person-years; hazard ratio [HR], 0.55; 95% confidence interval [CI], 0.43-0.71) as did those who consumed 7 or more drinks/wk (2.4 vs 6.3 deaths per 100 person-years; HR, 0.38; 95% CI, 0.25-0.55; P<.001 for trend). After adjusting for propensity to drink and other potential confounders, increasing alcohol consumption remained predictive of lower mortality for less than 7 drinks/wk, with an adjusted HR of 0.79 (95% CI, 0.60-1.03), and for 7 or more drinks/wk, with an adjusted HR of 0.68 (95% CI, 0.45-1.05; P =.01 for trend). The association was similar for total and cardiovascular mortality, among both men and women, and among different types of alcoholic beverages.Self-reported moderate alcohol consumption in the year prior to AMI is associated with reduced mortality following infarction.","Prior alcohol consumption and mortality following acute myocardial infarction."
"88","JAMA.4610","0.01",11308432,2001,"Studies have found that individuals who consume 1 alcoholic drink every 1 to 2 days have a lower risk of a first acute myocardial infarction (AMI) than abstainers or heavy drinkers, but the effect of prior drinking on mortality after AMI is uncertain.To determine the effect of prior alcohol consumption on long-term mortality among early survivors of AMI.Prospective inception cohort study conducted at 45 US community and tertiary care hospitals between August 1989 and September 1994, with a median follow-up of 3.8 years.A total of 1913 adults hospitalized with AMI between 1989 and 1994.All-cause mortality, compared by self-reported average weekly consumption of beer, wine, and liquor during the year prior to AMI.Of the 1913 patients, 896 (47%) abstained from alcohol, 696 (36%) consumed less than 7 alcoholic drinks/wk, and 321 (17%) consumed 7 or more alcoholic drinks/wk. Compared with abstainers, patients who consumed less than 7 drinks/wk had a lower all-cause mortality rate (3.4 vs 6.3 deaths per 100 person-years; hazard ratio [HR], 0.55; 95% confidence interval [CI], 0.43-0.71) as did those who consumed 7 or more drinks/wk (2.4 vs 6.3 deaths per 100 person-years; HR, 0.38; 95% CI, 0.25-0.55; P<.001 for trend). After adjusting for propensity to drink and other potential confounders, increasing alcohol consumption remained predictive of lower mortality for less than 7 drinks/wk, with an adjusted HR of 0.79 (95% CI, 0.60-1.03), and for 7 or more drinks/wk, with an adjusted HR of 0.68 (95% CI, 0.45-1.05; P =.01 for trend). The association was similar for total and cardiovascular mortality, among both men and women, and among different types of alcoholic beverages.Self-reported moderate alcohol consumption in the year prior to AMI is associated with reduced mortality following infarction.","Prior alcohol consumption and mortality following acute myocardial infarction."
"89","JAMA.51","0.001",11311099,2001,"Many studies have found that patients with acute myocardial infarction (AMI) who are admitted to hospitals with on-site revascularization facilities have higher rates of invasive cardiac procedures and better outcomes than patients in hospitals without such facilities. Whether such differences are due to invasive procedure rates alone or to other patient, physician, and hospital characteristics is unknown.To determine whether invasive procedural rate variations alone account for outcome differences in patients with AMI admitted to hospitals with or without on-site revascularization facilities.Retrospective, observational cohort study using linked population-based administrative data from a universal health insurance system.One hundred ninety acute care hospitals in Ontario, 9 of which offered invasive procedures.A total of 25 697 patients hospitalized with AMI between April 1, 1992, and December 31, 1993, of whom 2832 (11%) were in invasive hospitals.Mortality, recurrent cardiac hospitalizations, and emergency department visits in the 5 years following the index admission, adjusted for patient age, sex, socioeconomic status, illness severity, and index revascularization procedures; attending physician specialty; and hospital volume, teaching status, and geographical proximity to invasive-procedure centers and compared by hospital type.Patients admitted to invasive-procedure hospitals were much more likely to undergo revascularization (11.4% vs 3.2% at other hospitals; P<.001). However, many other clinical and process-related factors differed between the 2 groups. Although mortality rates were similar between the 2 institution types, the nonfatal composite 5-year event rate (ie, recurrent cardiac hospitalization and emergency department visits) was lower for patients initially admitted to invasive-procedure hospitals (71.3% vs 80.4%; unadjusted odds ratio [OR], 0.65; 95% confidence interval [CI], 0.52-0.82; P<.001). This advantage persisted after adjustment for sociodemographic and clinical factors and procedure utilization (adjusted OR, 0.68; 95% CI, 0.53-0.89; P<.001). However, the nonfatal outcome advantages of invasive-procedure hospitals were explained by their teaching status (adjusted OR, 0.98; 95% CI, 0.73-1.30; P =.87).In this sample of patients admitted with AMI, the differing outcomes of apparently similar patients treated in 2 different practice settings were explained by multiple competing factors. Researchers conducting observational studies should be cautious about attributing patient outcome differences to any single factor.","Long-term MI outcomes at hospitals with or without on-site revascularization."
"90","JAMA.52","0.001",11311099,2001,"Many studies have found that patients with acute myocardial infarction (AMI) who are admitted to hospitals with on-site revascularization facilities have higher rates of invasive cardiac procedures and better outcomes than patients in hospitals without such facilities. Whether such differences are due to invasive procedure rates alone or to other patient, physician, and hospital characteristics is unknown.To determine whether invasive procedural rate variations alone account for outcome differences in patients with AMI admitted to hospitals with or without on-site revascularization facilities.Retrospective, observational cohort study using linked population-based administrative data from a universal health insurance system.One hundred ninety acute care hospitals in Ontario, 9 of which offered invasive procedures.A total of 25 697 patients hospitalized with AMI between April 1, 1992, and December 31, 1993, of whom 2832 (11%) were in invasive hospitals.Mortality, recurrent cardiac hospitalizations, and emergency department visits in the 5 years following the index admission, adjusted for patient age, sex, socioeconomic status, illness severity, and index revascularization procedures; attending physician specialty; and hospital volume, teaching status, and geographical proximity to invasive-procedure centers and compared by hospital type.Patients admitted to invasive-procedure hospitals were much more likely to undergo revascularization (11.4% vs 3.2% at other hospitals; P<.001). However, many other clinical and process-related factors differed between the 2 groups. Although mortality rates were similar between the 2 institution types, the nonfatal composite 5-year event rate (ie, recurrent cardiac hospitalization and emergency department visits) was lower for patients initially admitted to invasive-procedure hospitals (71.3% vs 80.4%; unadjusted odds ratio [OR], 0.65; 95% confidence interval [CI], 0.52-0.82; P<.001). This advantage persisted after adjustment for sociodemographic and clinical factors and procedure utilization (adjusted OR, 0.68; 95% CI, 0.53-0.89; P<.001). However, the nonfatal outcome advantages of invasive-procedure hospitals were explained by their teaching status (adjusted OR, 0.98; 95% CI, 0.73-1.30; P =.87).In this sample of patients admitted with AMI, the differing outcomes of apparently similar patients treated in 2 different practice settings were explained by multiple competing factors. Researchers conducting observational studies should be cautious about attributing patient outcome differences to any single factor.","Long-term MI outcomes at hospitals with or without on-site revascularization."
"91","JAMA.85","0.87",11311099,2001,"Many studies have found that patients with acute myocardial infarction (AMI) who are admitted to hospitals with on-site revascularization facilities have higher rates of invasive cardiac procedures and better outcomes than patients in hospitals without such facilities. Whether such differences are due to invasive procedure rates alone or to other patient, physician, and hospital characteristics is unknown.To determine whether invasive procedural rate variations alone account for outcome differences in patients with AMI admitted to hospitals with or without on-site revascularization facilities.Retrospective, observational cohort study using linked population-based administrative data from a universal health insurance system.One hundred ninety acute care hospitals in Ontario, 9 of which offered invasive procedures.A total of 25 697 patients hospitalized with AMI between April 1, 1992, and December 31, 1993, of whom 2832 (11%) were in invasive hospitals.Mortality, recurrent cardiac hospitalizations, and emergency department visits in the 5 years following the index admission, adjusted for patient age, sex, socioeconomic status, illness severity, and index revascularization procedures; attending physician specialty; and hospital volume, teaching status, and geographical proximity to invasive-procedure centers and compared by hospital type.Patients admitted to invasive-procedure hospitals were much more likely to undergo revascularization (11.4% vs 3.2% at other hospitals; P<.001). However, many other clinical and process-related factors differed between the 2 groups. Although mortality rates were similar between the 2 institution types, the nonfatal composite 5-year event rate (ie, recurrent cardiac hospitalization and emergency department visits) was lower for patients initially admitted to invasive-procedure hospitals (71.3% vs 80.4%; unadjusted odds ratio [OR], 0.65; 95% confidence interval [CI], 0.52-0.82; P<.001). This advantage persisted after adjustment for sociodemographic and clinical factors and procedure utilization (adjusted OR, 0.68; 95% CI, 0.53-0.89; P<.001). However, the nonfatal outcome advantages of invasive-procedure hospitals were explained by their teaching status (adjusted OR, 0.98; 95% CI, 0.73-1.30; P =.87).In this sample of patients admitted with AMI, the differing outcomes of apparently similar patients treated in 2 different practice settings were explained by multiple competing factors. Researchers conducting observational studies should be cautious about attributing patient outcome differences to any single factor.","Long-term MI outcomes at hospitals with or without on-site revascularization."
"92","American Journal of Epidemiology.7","NA",11323315,2001,"The majority of renal cell carcinomas (RCCs) are sporadic, and increasing incidence rates suggest that such environmental risk factors as smoking play a role in the etiology of the disease. Cases with RCC were selected from the population-based cancer registry of Orange County, California, between 1994 and 1997; controls were recruited by telephone using random digit dialing. A total of 115 case and 259 control subjects were genotyped for N-acetyltransferase 2 (NAT2), which codes for a polymorphic enzyme involved in tobacco-carcinogen metabolism. Subjects with slow acetylator genotypes were found to be at twofold increased risk (odds ratio (OR) = 1.8; 95 percent confidence interval (CI): 1.1, 2.9) of RCC. Although cancer risk doubled among smokers (OR = 2.2; 95 percent CI: 1.3, 3.7), stratified analysis revealed gene-environment interaction among slow acetylators that smoked (OR = 3.2; 95 percent CI: 1.7, 6.1) compared with rapid acetylators that smoked (OR = 1.4; 95 percent CI: 0.7, 2.9). A dose response was found for pack-years among slow acetylators (p < 0.01) but not among rapid acetylators (p = 0.06). Although smoking is a well-established risk factor of RCC, our data suggest that the risk is pronounced among slow rather than rapid acetylators.","Gene-environment interactions in renal cell carcinoma."
"93","American Journal of Epidemiology.7","NA",11323315,2001,"The majority of renal cell carcinomas (RCCs) are sporadic, and increasing incidence rates suggest that such environmental risk factors as smoking play a role in the etiology of the disease. Cases with RCC were selected from the population-based cancer registry of Orange County, California, between 1994 and 1997; controls were recruited by telephone using random digit dialing. A total of 115 case and 259 control subjects were genotyped for N-acetyltransferase 2 (NAT2), which codes for a polymorphic enzyme involved in tobacco-carcinogen metabolism. Subjects with slow acetylator genotypes were found to be at twofold increased risk (odds ratio (OR) = 1.8; 95 percent confidence interval (CI): 1.1, 2.9) of RCC. Although cancer risk doubled among smokers (OR = 2.2; 95 percent CI: 1.3, 3.7), stratified analysis revealed gene-environment interaction among slow acetylators that smoked (OR = 3.2; 95 percent CI: 1.7, 6.1) compared with rapid acetylators that smoked (OR = 1.4; 95 percent CI: 0.7, 2.9). A dose response was found for pack-years among slow acetylators (p < 0.01) but not among rapid acetylators (p = 0.06). Although smoking is a well-established risk factor of RCC, our data suggest that the risk is pronounced among slow rather than rapid acetylators.","Gene-environment interactions in renal cell carcinoma."
"94","American Journal of Epidemiology.7","NA",11323315,2001,"The majority of renal cell carcinomas (RCCs) are sporadic, and increasing incidence rates suggest that such environmental risk factors as smoking play a role in the etiology of the disease. Cases with RCC were selected from the population-based cancer registry of Orange County, California, between 1994 and 1997; controls were recruited by telephone using random digit dialing. A total of 115 case and 259 control subjects were genotyped for N-acetyltransferase 2 (NAT2), which codes for a polymorphic enzyme involved in tobacco-carcinogen metabolism. Subjects with slow acetylator genotypes were found to be at twofold increased risk (odds ratio (OR) = 1.8; 95 percent confidence interval (CI): 1.1, 2.9) of RCC. Although cancer risk doubled among smokers (OR = 2.2; 95 percent CI: 1.3, 3.7), stratified analysis revealed gene-environment interaction among slow acetylators that smoked (OR = 3.2; 95 percent CI: 1.7, 6.1) compared with rapid acetylators that smoked (OR = 1.4; 95 percent CI: 0.7, 2.9). A dose response was found for pack-years among slow acetylators (p < 0.01) but not among rapid acetylators (p = 0.06). Although smoking is a well-established risk factor of RCC, our data suggest that the risk is pronounced among slow rather than rapid acetylators.","Gene-environment interactions in renal cell carcinoma."
"95","American Journal of Epidemiology.15","NA",11323315,2001,"The majority of renal cell carcinomas (RCCs) are sporadic, and increasing incidence rates suggest that such environmental risk factors as smoking play a role in the etiology of the disease. Cases with RCC were selected from the population-based cancer registry of Orange County, California, between 1994 and 1997; controls were recruited by telephone using random digit dialing. A total of 115 case and 259 control subjects were genotyped for N-acetyltransferase 2 (NAT2), which codes for a polymorphic enzyme involved in tobacco-carcinogen metabolism. Subjects with slow acetylator genotypes were found to be at twofold increased risk (odds ratio (OR) = 1.8; 95 percent confidence interval (CI): 1.1, 2.9) of RCC. Although cancer risk doubled among smokers (OR = 2.2; 95 percent CI: 1.3, 3.7), stratified analysis revealed gene-environment interaction among slow acetylators that smoked (OR = 3.2; 95 percent CI: 1.7, 6.1) compared with rapid acetylators that smoked (OR = 1.4; 95 percent CI: 0.7, 2.9). A dose response was found for pack-years among slow acetylators (p < 0.01) but not among rapid acetylators (p = 0.06). Although smoking is a well-established risk factor of RCC, our data suggest that the risk is pronounced among slow rather than rapid acetylators.","Gene-environment interactions in renal cell carcinoma."
"96","JAMA.4210","0.002",11368699,2001,"The Enhanced Suppression of the Platelet IIb/IIIa Receptor with Integrilin Therapy (ESPRIT) trial showed the efficacy of adjunctive, double-bolus eptifibatide therapy in reducing ischemic complications of nonurgent coronary stent implantation at 48 hours and at 30 days.To determine whether the beneficial effects of eptifibatide persist at 6 months after treatment.Follow-up study of a randomized, double-blind, placebo-controlled, crossover-permitted trial conducted from June 1999 through February 2000.Ninety-two tertiary care centers in the United States and Canada.A total of 2064 patients scheduled to undergo nonurgent percutaneous coronary intervention with stent implantation.Patients were randomly assigned to receive placebo or eptifibatide (two 180-microg/kg boluses 10 minutes apart and continuous infusion of 2.0 microg/kg per minute), started immediately before stent implantation and continued for 18 to 24 hours. Complete follow-up data were available for 988 (95.0%) of 1040 patients given eptifibatide and 977 (95.4%) of 1024 patients given placebo.Composite rates of death or myocardial infarction (MI); death, MI, or target vessel revascularization; and their individual components 6 months after enrollment, compared between the 2 groups.By 6 months, the composite end point of death or MI had occurred in 7.5% of eptifibatide-treated patients and in 11.5% of placebo-treated patients (hazard ratio [HR], 0.63; 95% confidence interval [CI], 0.47-0.84; P =.002). The composite of death, MI, or target vessel revascularization was 14.2% in eptifibatide-treated patients vs 18.3% in placebo-treated patients (HR, 0.75; 95% CI, 0.60-0.93; P =.008). Most of this benefit accrued early (<48 hours after initiation of therapy) and was maintained through 6 months. Six-month mortality in the eptifibatide group was 0.8% vs 1.4% in the placebo group (HR, 0.56; 95% CI, 0.24-1.34; P =.19) and target vessel revascularization occurred in 8.6% of the eptifibatide group vs 9.4% of the placebo group (HR, 0.91; 95% CI, 0.68-1.22; P =.51).Adjunctive eptifibatide therapy during coronary stent implantation provides benefit through 6-month follow-up.","Platelet glycoprotein IIb/IIIa integrin blockade with eptifibatide in coronary stent intervention: the ESPRIT trial: a randomized controlled trial."
"97","JAMA.4310","0.008",11368699,2001,"The Enhanced Suppression of the Platelet IIb/IIIa Receptor with Integrilin Therapy (ESPRIT) trial showed the efficacy of adjunctive, double-bolus eptifibatide therapy in reducing ischemic complications of nonurgent coronary stent implantation at 48 hours and at 30 days.To determine whether the beneficial effects of eptifibatide persist at 6 months after treatment.Follow-up study of a randomized, double-blind, placebo-controlled, crossover-permitted trial conducted from June 1999 through February 2000.Ninety-two tertiary care centers in the United States and Canada.A total of 2064 patients scheduled to undergo nonurgent percutaneous coronary intervention with stent implantation.Patients were randomly assigned to receive placebo or eptifibatide (two 180-microg/kg boluses 10 minutes apart and continuous infusion of 2.0 microg/kg per minute), started immediately before stent implantation and continued for 18 to 24 hours. Complete follow-up data were available for 988 (95.0%) of 1040 patients given eptifibatide and 977 (95.4%) of 1024 patients given placebo.Composite rates of death or myocardial infarction (MI); death, MI, or target vessel revascularization; and their individual components 6 months after enrollment, compared between the 2 groups.By 6 months, the composite end point of death or MI had occurred in 7.5% of eptifibatide-treated patients and in 11.5% of placebo-treated patients (hazard ratio [HR], 0.63; 95% confidence interval [CI], 0.47-0.84; P =.002). The composite of death, MI, or target vessel revascularization was 14.2% in eptifibatide-treated patients vs 18.3% in placebo-treated patients (HR, 0.75; 95% CI, 0.60-0.93; P =.008). Most of this benefit accrued early (<48 hours after initiation of therapy) and was maintained through 6 months. Six-month mortality in the eptifibatide group was 0.8% vs 1.4% in the placebo group (HR, 0.56; 95% CI, 0.24-1.34; P =.19) and target vessel revascularization occurred in 8.6% of the eptifibatide group vs 9.4% of the placebo group (HR, 0.91; 95% CI, 0.68-1.22; P =.51).Adjunctive eptifibatide therapy during coronary stent implantation provides benefit through 6-month follow-up.","Platelet glycoprotein IIb/IIIa integrin blockade with eptifibatide in coronary stent intervention: the ESPRIT trial: a randomized controlled trial."
"98","JAMA.4410","0.19",11368699,2001,"The Enhanced Suppression of the Platelet IIb/IIIa Receptor with Integrilin Therapy (ESPRIT) trial showed the efficacy of adjunctive, double-bolus eptifibatide therapy in reducing ischemic complications of nonurgent coronary stent implantation at 48 hours and at 30 days.To determine whether the beneficial effects of eptifibatide persist at 6 months after treatment.Follow-up study of a randomized, double-blind, placebo-controlled, crossover-permitted trial conducted from June 1999 through February 2000.Ninety-two tertiary care centers in the United States and Canada.A total of 2064 patients scheduled to undergo nonurgent percutaneous coronary intervention with stent implantation.Patients were randomly assigned to receive placebo or eptifibatide (two 180-microg/kg boluses 10 minutes apart and continuous infusion of 2.0 microg/kg per minute), started immediately before stent implantation and continued for 18 to 24 hours. Complete follow-up data were available for 988 (95.0%) of 1040 patients given eptifibatide and 977 (95.4%) of 1024 patients given placebo.Composite rates of death or myocardial infarction (MI); death, MI, or target vessel revascularization; and their individual components 6 months after enrollment, compared between the 2 groups.By 6 months, the composite end point of death or MI had occurred in 7.5% of eptifibatide-treated patients and in 11.5% of placebo-treated patients (hazard ratio [HR], 0.63; 95% confidence interval [CI], 0.47-0.84; P =.002). The composite of death, MI, or target vessel revascularization was 14.2% in eptifibatide-treated patients vs 18.3% in placebo-treated patients (HR, 0.75; 95% CI, 0.60-0.93; P =.008). Most of this benefit accrued early (<48 hours after initiation of therapy) and was maintained through 6 months. Six-month mortality in the eptifibatide group was 0.8% vs 1.4% in the placebo group (HR, 0.56; 95% CI, 0.24-1.34; P =.19) and target vessel revascularization occurred in 8.6% of the eptifibatide group vs 9.4% of the placebo group (HR, 0.91; 95% CI, 0.68-1.22; P =.51).Adjunctive eptifibatide therapy during coronary stent implantation provides benefit through 6-month follow-up.","Platelet glycoprotein IIb/IIIa integrin blockade with eptifibatide in coronary stent intervention: the ESPRIT trial: a randomized controlled trial."
"99","JAMA.4510","0.51",11368699,2001,"The Enhanced Suppression of the Platelet IIb/IIIa Receptor with Integrilin Therapy (ESPRIT) trial showed the efficacy of adjunctive, double-bolus eptifibatide therapy in reducing ischemic complications of nonurgent coronary stent implantation at 48 hours and at 30 days.To determine whether the beneficial effects of eptifibatide persist at 6 months after treatment.Follow-up study of a randomized, double-blind, placebo-controlled, crossover-permitted trial conducted from June 1999 through February 2000.Ninety-two tertiary care centers in the United States and Canada.A total of 2064 patients scheduled to undergo nonurgent percutaneous coronary intervention with stent implantation.Patients were randomly assigned to receive placebo or eptifibatide (two 180-microg/kg boluses 10 minutes apart and continuous infusion of 2.0 microg/kg per minute), started immediately before stent implantation and continued for 18 to 24 hours. Complete follow-up data were available for 988 (95.0%) of 1040 patients given eptifibatide and 977 (95.4%) of 1024 patients given placebo.Composite rates of death or myocardial infarction (MI); death, MI, or target vessel revascularization; and their individual components 6 months after enrollment, compared between the 2 groups.By 6 months, the composite end point of death or MI had occurred in 7.5% of eptifibatide-treated patients and in 11.5% of placebo-treated patients (hazard ratio [HR], 0.63; 95% confidence interval [CI], 0.47-0.84; P =.002). The composite of death, MI, or target vessel revascularization was 14.2% in eptifibatide-treated patients vs 18.3% in placebo-treated patients (HR, 0.75; 95% CI, 0.60-0.93; P =.008). Most of this benefit accrued early (<48 hours after initiation of therapy) and was maintained through 6 months. Six-month mortality in the eptifibatide group was 0.8% vs 1.4% in the placebo group (HR, 0.56; 95% CI, 0.24-1.34; P =.19) and target vessel revascularization occurred in 8.6% of the eptifibatide group vs 9.4% of the placebo group (HR, 0.91; 95% CI, 0.68-1.22; P =.51).Adjunctive eptifibatide therapy during coronary stent implantation provides benefit through 6-month follow-up.","Platelet glycoprotein IIb/IIIa integrin blockade with eptifibatide in coronary stent intervention: the ESPRIT trial: a randomized controlled trial."
"100","Lancet.16","0.036",11377606,2001,"We sought genetic evidence for the importance of host-parasite interactions involving CD36 in severe malaria. We identified a non-sense mutation in Cd36 gene and looked at the influence of this mutation on the outcome of malaria infection in 693 African children with severe malaria and a similar number of ethnically matched controls. We showed that heterozygosity for this mutation is associated with protection from severe disease (OR 0.74, 95% CI 0.55-0.99; p=0.036). These findings suggest that this Cd36 mutation might have a complex effect on malaria infection by decreasing parasite sequestration, and also by decreasing host immune responses.","A non-sense mutation in Cd36 gene is associated with protection from severe malaria."
"101","JAMA.4110","NA",11401606,2001,"Transgenic animal experiments suggest that increased expression of transforming growth factor beta1 (TGF-beta1) is protective against early tumor development, particularly in breast cancer. A T-->C (thymine to cytosine) transition in the 29th nucleotide in the coding sequence results in a leucine to proline substitution at the 10th amino acid and is associated with increased serum levels of TGF-beta1.To determine whether an association exists between this TGF-beta1 polymorphism and breast cancer risk.The Study of Osteoporotic Fractures, a prospective cohort study of white, community-dwelling women aged 65 years or older who were recruited at 4 US centers between 1986 and 1988. Three thousand seventy-five women who provided sufficient clinical information, buffy coat samples, and adequate consent for genotyping are included in this analysis.Breast cancer cases during a mean (SD) follow-up of 9.3 (1.9) years, verified by medical chart review and compared by genotype.Risk of breast cancer was similar in the 1124 women with the T/T genotype (56 cases; 5.4 per 1000 person-years) and the 1493 women with the T/C genotype (80 cases; 5.8 per 1000 person-years) but was significantly lower (P =.01) in the 458 women with the C/C genotype (10 cases; 2.3 per 1000 person-years). In analyses that adjusted for age, age at menarche, age at menopause, estrogen use, parity, body mass index, and bone mineral density, women with the C/C genotype had a significantly lower risk of developing breast cancer compared with women with the T/T or T/C genotype (hazard ratio [HR], 0.36; 95% confidence interval [CI], 0.17-0.75). There was no significant difference between the risk for women with the T/C genotype compared with women with the T/T genotype (adjusted HR, 1.04; 95% CI, 0.73-1.48).Our findings suggest that TGF-beta1 genotype is associated with risk of breast cancer in white women aged 65 years or older. Because the T allele is the common variant and confers an increased risk, it may be associated with a large proportion of breast cancer cases.","Association between the T29-->C polymorphism in the transforming growth factor beta1 gene and breast cancer among elderly white women: The Study of Osteoporotic Fractures."
"102","JAMA.4110","NA",11401606,2001,"Transgenic animal experiments suggest that increased expression of transforming growth factor beta1 (TGF-beta1) is protective against early tumor development, particularly in breast cancer. A T-->C (thymine to cytosine) transition in the 29th nucleotide in the coding sequence results in a leucine to proline substitution at the 10th amino acid and is associated with increased serum levels of TGF-beta1.To determine whether an association exists between this TGF-beta1 polymorphism and breast cancer risk.The Study of Osteoporotic Fractures, a prospective cohort study of white, community-dwelling women aged 65 years or older who were recruited at 4 US centers between 1986 and 1988. Three thousand seventy-five women who provided sufficient clinical information, buffy coat samples, and adequate consent for genotyping are included in this analysis.Breast cancer cases during a mean (SD) follow-up of 9.3 (1.9) years, verified by medical chart review and compared by genotype.Risk of breast cancer was similar in the 1124 women with the T/T genotype (56 cases; 5.4 per 1000 person-years) and the 1493 women with the T/C genotype (80 cases; 5.8 per 1000 person-years) but was significantly lower (P =.01) in the 458 women with the C/C genotype (10 cases; 2.3 per 1000 person-years). In analyses that adjusted for age, age at menarche, age at menopause, estrogen use, parity, body mass index, and bone mineral density, women with the C/C genotype had a significantly lower risk of developing breast cancer compared with women with the T/T or T/C genotype (hazard ratio [HR], 0.36; 95% confidence interval [CI], 0.17-0.75). There was no significant difference between the risk for women with the T/C genotype compared with women with the T/T genotype (adjusted HR, 1.04; 95% CI, 0.73-1.48).Our findings suggest that TGF-beta1 genotype is associated with risk of breast cancer in white women aged 65 years or older. Because the T allele is the common variant and confers an increased risk, it may be associated with a large proportion of breast cancer cases.","Association between the T29-->C polymorphism in the transforming growth factor beta1 gene and breast cancer among elderly white women: The Study of Osteoporotic Fractures."
"103","JAMA.49","NA",11401608,2001,"Performance feedback and benchmarking, common tools for health care improvement, are rarely studied in randomized trials. Achievable Benchmarks of Care (ABCs) are standards of excellence attained by top performers in a peer group and are easily and reproducibly calculated from existing performance data.To evaluate the effectiveness of using achievable benchmarks to enhance typical physician performance feedback and improve care.Group-randomized controlled trial conducted in December 1996, with follow-up through 1998.Seventy community physicians and 2978 fee-for-service Medicare patients with diabetes mellitus who were part of the Ambulatory Care Quality Improvement Project in Alabama.Physicians were randomly assigned to receive a multimodal improvement intervention, including chart review and physician-specific feedback (comparison group; n = 35) or an identical intervention plus achievable benchmark feedback (experimental group; n = 35).Preintervention (1994-1995) to postintervention (1997-1998) changes in the proportion of patients receiving influenza vaccination; foot examination; and each of 3 blood tests measuring glucose control, cholesterol level, and triglyceride level, compared between the 2 groups.The proportion of patients who received influenza vaccine improved from 40% to 58% in the experimental group (P<.001) vs from 40% to 46% in the comparison group (P =.02). Odds ratios (ORs) for patients of achievable benchmark physicians vs comparison physicians who received appropriate care after the intervention, adjusted for preintervention care and nesting of patients within physicians, were 1.57 (95% confidence interval [CI], 1.26-1.96) for influenza vaccination, 1.33 (95% CI, 1.05-1.69) for foot examination, and 1.33 (95% CI, 1.04-1.69) for long-term glucose control measurement. For serum cholesterol and triglycerides, the achievable benchmark effect was statistically significant only after additional adjustment for physician characteristics (OR, 1.40 [95% CI, 1.08-1.82] and OR, 1.40 [95% CI, 1.09-1.79], respectively).Use of achievable benchmarks significantly enhances the effectiveness of physician performance feedback in the setting of a multimodal quality improvement intervention.","Improving quality improvement using achievable benchmarks for physician feedback: a randomized controlled trial."
"104","JAMA.49","NA",11401608,2001,"Performance feedback and benchmarking, common tools for health care improvement, are rarely studied in randomized trials. Achievable Benchmarks of Care (ABCs) are standards of excellence attained by top performers in a peer group and are easily and reproducibly calculated from existing performance data.To evaluate the effectiveness of using achievable benchmarks to enhance typical physician performance feedback and improve care.Group-randomized controlled trial conducted in December 1996, with follow-up through 1998.Seventy community physicians and 2978 fee-for-service Medicare patients with diabetes mellitus who were part of the Ambulatory Care Quality Improvement Project in Alabama.Physicians were randomly assigned to receive a multimodal improvement intervention, including chart review and physician-specific feedback (comparison group; n = 35) or an identical intervention plus achievable benchmark feedback (experimental group; n = 35).Preintervention (1994-1995) to postintervention (1997-1998) changes in the proportion of patients receiving influenza vaccination; foot examination; and each of 3 blood tests measuring glucose control, cholesterol level, and triglyceride level, compared between the 2 groups.The proportion of patients who received influenza vaccine improved from 40% to 58% in the experimental group (P<.001) vs from 40% to 46% in the comparison group (P =.02). Odds ratios (ORs) for patients of achievable benchmark physicians vs comparison physicians who received appropriate care after the intervention, adjusted for preintervention care and nesting of patients within physicians, were 1.57 (95% confidence interval [CI], 1.26-1.96) for influenza vaccination, 1.33 (95% CI, 1.05-1.69) for foot examination, and 1.33 (95% CI, 1.04-1.69) for long-term glucose control measurement. For serum cholesterol and triglycerides, the achievable benchmark effect was statistically significant only after additional adjustment for physician characteristics (OR, 1.40 [95% CI, 1.08-1.82] and OR, 1.40 [95% CI, 1.09-1.79], respectively).Use of achievable benchmarks significantly enhances the effectiveness of physician performance feedback in the setting of a multimodal quality improvement intervention.","Improving quality improvement using achievable benchmarks for physician feedback: a randomized controlled trial."
"105","JAMA.49","NA",11401608,2001,"Performance feedback and benchmarking, common tools for health care improvement, are rarely studied in randomized trials. Achievable Benchmarks of Care (ABCs) are standards of excellence attained by top performers in a peer group and are easily and reproducibly calculated from existing performance data.To evaluate the effectiveness of using achievable benchmarks to enhance typical physician performance feedback and improve care.Group-randomized controlled trial conducted in December 1996, with follow-up through 1998.Seventy community physicians and 2978 fee-for-service Medicare patients with diabetes mellitus who were part of the Ambulatory Care Quality Improvement Project in Alabama.Physicians were randomly assigned to receive a multimodal improvement intervention, including chart review and physician-specific feedback (comparison group; n = 35) or an identical intervention plus achievable benchmark feedback (experimental group; n = 35).Preintervention (1994-1995) to postintervention (1997-1998) changes in the proportion of patients receiving influenza vaccination; foot examination; and each of 3 blood tests measuring glucose control, cholesterol level, and triglyceride level, compared between the 2 groups.The proportion of patients who received influenza vaccine improved from 40% to 58% in the experimental group (P<.001) vs from 40% to 46% in the comparison group (P =.02). Odds ratios (ORs) for patients of achievable benchmark physicians vs comparison physicians who received appropriate care after the intervention, adjusted for preintervention care and nesting of patients within physicians, were 1.57 (95% confidence interval [CI], 1.26-1.96) for influenza vaccination, 1.33 (95% CI, 1.05-1.69) for foot examination, and 1.33 (95% CI, 1.04-1.69) for long-term glucose control measurement. For serum cholesterol and triglycerides, the achievable benchmark effect was statistically significant only after additional adjustment for physician characteristics (OR, 1.40 [95% CI, 1.08-1.82] and OR, 1.40 [95% CI, 1.09-1.79], respectively).Use of achievable benchmarks significantly enhances the effectiveness of physician performance feedback in the setting of a multimodal quality improvement intervention.","Improving quality improvement using achievable benchmarks for physician feedback: a randomized controlled trial."
"106","JAMA.49","NA",11401608,2001,"Performance feedback and benchmarking, common tools for health care improvement, are rarely studied in randomized trials. Achievable Benchmarks of Care (ABCs) are standards of excellence attained by top performers in a peer group and are easily and reproducibly calculated from existing performance data.To evaluate the effectiveness of using achievable benchmarks to enhance typical physician performance feedback and improve care.Group-randomized controlled trial conducted in December 1996, with follow-up through 1998.Seventy community physicians and 2978 fee-for-service Medicare patients with diabetes mellitus who were part of the Ambulatory Care Quality Improvement Project in Alabama.Physicians were randomly assigned to receive a multimodal improvement intervention, including chart review and physician-specific feedback (comparison group; n = 35) or an identical intervention plus achievable benchmark feedback (experimental group; n = 35).Preintervention (1994-1995) to postintervention (1997-1998) changes in the proportion of patients receiving influenza vaccination; foot examination; and each of 3 blood tests measuring glucose control, cholesterol level, and triglyceride level, compared between the 2 groups.The proportion of patients who received influenza vaccine improved from 40% to 58% in the experimental group (P<.001) vs from 40% to 46% in the comparison group (P =.02). Odds ratios (ORs) for patients of achievable benchmark physicians vs comparison physicians who received appropriate care after the intervention, adjusted for preintervention care and nesting of patients within physicians, were 1.57 (95% confidence interval [CI], 1.26-1.96) for influenza vaccination, 1.33 (95% CI, 1.05-1.69) for foot examination, and 1.33 (95% CI, 1.04-1.69) for long-term glucose control measurement. For serum cholesterol and triglycerides, the achievable benchmark effect was statistically significant only after additional adjustment for physician characteristics (OR, 1.40 [95% CI, 1.08-1.82] and OR, 1.40 [95% CI, 1.09-1.79], respectively).Use of achievable benchmarks significantly enhances the effectiveness of physician performance feedback in the setting of a multimodal quality improvement intervention.","Improving quality improvement using achievable benchmarks for physician feedback: a randomized controlled trial."
"107","JAMA.84","NA",11401608,2001,"Performance feedback and benchmarking, common tools for health care improvement, are rarely studied in randomized trials. Achievable Benchmarks of Care (ABCs) are standards of excellence attained by top performers in a peer group and are easily and reproducibly calculated from existing performance data.To evaluate the effectiveness of using achievable benchmarks to enhance typical physician performance feedback and improve care.Group-randomized controlled trial conducted in December 1996, with follow-up through 1998.Seventy community physicians and 2978 fee-for-service Medicare patients with diabetes mellitus who were part of the Ambulatory Care Quality Improvement Project in Alabama.Physicians were randomly assigned to receive a multimodal improvement intervention, including chart review and physician-specific feedback (comparison group; n = 35) or an identical intervention plus achievable benchmark feedback (experimental group; n = 35).Preintervention (1994-1995) to postintervention (1997-1998) changes in the proportion of patients receiving influenza vaccination; foot examination; and each of 3 blood tests measuring glucose control, cholesterol level, and triglyceride level, compared between the 2 groups.The proportion of patients who received influenza vaccine improved from 40% to 58% in the experimental group (P<.001) vs from 40% to 46% in the comparison group (P =.02). Odds ratios (ORs) for patients of achievable benchmark physicians vs comparison physicians who received appropriate care after the intervention, adjusted for preintervention care and nesting of patients within physicians, were 1.57 (95% confidence interval [CI], 1.26-1.96) for influenza vaccination, 1.33 (95% CI, 1.05-1.69) for foot examination, and 1.33 (95% CI, 1.04-1.69) for long-term glucose control measurement. For serum cholesterol and triglycerides, the achievable benchmark effect was statistically significant only after additional adjustment for physician characteristics (OR, 1.40 [95% CI, 1.08-1.82] and OR, 1.40 [95% CI, 1.09-1.79], respectively).Use of achievable benchmarks significantly enhances the effectiveness of physician performance feedback in the setting of a multimodal quality improvement intervention.","Improving quality improvement using achievable benchmarks for physician feedback: a randomized controlled trial."
"108","JAMA.3610","0.02",11401611,2001,"Hormone replacement therapy (HRT) is widely considered to reduce fractures, but this belief is based on observational data; evidence from randomized trials is lacking.To conduct a systematic review of all randomized trials of HRT that have reported or collected nonvertebral fracture data but that may not have focused on fracture prevention.The MEDLINE, EMBASE, Science Citation Index, and Cochrane Controlled Trials Register databases were searched from 1997 through 2000 and a search was conducted of all recent systematic reviews to identify older studies. Authors were contacted to establish whether fracture data had been collected but not reported. Researchers in the field and pharmaceutical companies also were contacted to try to identify unpublished studies.Trials were included in which participants had been randomized to at least 12 months of therapy and data on nonvertebral fractures at any other site and due to any cause were available. Of 70 initially identified studies, 22 were included in the analysis.Both investigators extracted data independently and appraised trial quality according to the Jadad scale, which assesses the methods of randomization, concealment allocation, and reporting of withdrawals and dropouts. Disagreements were resolved by discussion.There was an overall 27% reduction in nonvertebral fractures in a pooled analysis (reduction favoring HRT in relative risk [RR], 0.73; 95% confidence interval [CI], 0.56-0.94; P =.02). This effect was greater among women randomized to HRT who had a mean age younger than 60 years (RR, 0.67; 95% CI, 0.46-0.98; P =.03). Among women with a mean age of 60 years or older, there was a reduced effect (RR, 0.88; 95% CI, 0.71-1.08; P =.22). For hip and wrist fractures alone, the effectiveness of HRT appeared more marked (RR, 0.60; 95% CI, 0.40-0.91; P =.02), particularly for women younger than 60 years (RR, 0.45; 95% CI, 0.26-0.79; P =.005).Our meta-analysis of randomized controlled trials of HRT noted a statistically significant reduction in nonvertebral fractures. However, this effect may be attenuated in older women.","Hormone replacement therapy and prevention of nonvertebral fractures: a meta-analysis of randomized trials."
"109","JAMA.3710","0.03",11401611,2001,"Hormone replacement therapy (HRT) is widely considered to reduce fractures, but this belief is based on observational data; evidence from randomized trials is lacking.To conduct a systematic review of all randomized trials of HRT that have reported or collected nonvertebral fracture data but that may not have focused on fracture prevention.The MEDLINE, EMBASE, Science Citation Index, and Cochrane Controlled Trials Register databases were searched from 1997 through 2000 and a search was conducted of all recent systematic reviews to identify older studies. Authors were contacted to establish whether fracture data had been collected but not reported. Researchers in the field and pharmaceutical companies also were contacted to try to identify unpublished studies.Trials were included in which participants had been randomized to at least 12 months of therapy and data on nonvertebral fractures at any other site and due to any cause were available. Of 70 initially identified studies, 22 were included in the analysis.Both investigators extracted data independently and appraised trial quality according to the Jadad scale, which assesses the methods of randomization, concealment allocation, and reporting of withdrawals and dropouts. Disagreements were resolved by discussion.There was an overall 27% reduction in nonvertebral fractures in a pooled analysis (reduction favoring HRT in relative risk [RR], 0.73; 95% confidence interval [CI], 0.56-0.94; P =.02). This effect was greater among women randomized to HRT who had a mean age younger than 60 years (RR, 0.67; 95% CI, 0.46-0.98; P =.03). Among women with a mean age of 60 years or older, there was a reduced effect (RR, 0.88; 95% CI, 0.71-1.08; P =.22). For hip and wrist fractures alone, the effectiveness of HRT appeared more marked (RR, 0.60; 95% CI, 0.40-0.91; P =.02), particularly for women younger than 60 years (RR, 0.45; 95% CI, 0.26-0.79; P =.005).Our meta-analysis of randomized controlled trials of HRT noted a statistically significant reduction in nonvertebral fractures. However, this effect may be attenuated in older women.","Hormone replacement therapy and prevention of nonvertebral fractures: a meta-analysis of randomized trials."
"110","JAMA.3810","0.22",11401611,2001,"Hormone replacement therapy (HRT) is widely considered to reduce fractures, but this belief is based on observational data; evidence from randomized trials is lacking.To conduct a systematic review of all randomized trials of HRT that have reported or collected nonvertebral fracture data but that may not have focused on fracture prevention.The MEDLINE, EMBASE, Science Citation Index, and Cochrane Controlled Trials Register databases were searched from 1997 through 2000 and a search was conducted of all recent systematic reviews to identify older studies. Authors were contacted to establish whether fracture data had been collected but not reported. Researchers in the field and pharmaceutical companies also were contacted to try to identify unpublished studies.Trials were included in which participants had been randomized to at least 12 months of therapy and data on nonvertebral fractures at any other site and due to any cause were available. Of 70 initially identified studies, 22 were included in the analysis.Both investigators extracted data independently and appraised trial quality according to the Jadad scale, which assesses the methods of randomization, concealment allocation, and reporting of withdrawals and dropouts. Disagreements were resolved by discussion.There was an overall 27% reduction in nonvertebral fractures in a pooled analysis (reduction favoring HRT in relative risk [RR], 0.73; 95% confidence interval [CI], 0.56-0.94; P =.02). This effect was greater among women randomized to HRT who had a mean age younger than 60 years (RR, 0.67; 95% CI, 0.46-0.98; P =.03). Among women with a mean age of 60 years or older, there was a reduced effect (RR, 0.88; 95% CI, 0.71-1.08; P =.22). For hip and wrist fractures alone, the effectiveness of HRT appeared more marked (RR, 0.60; 95% CI, 0.40-0.91; P =.02), particularly for women younger than 60 years (RR, 0.45; 95% CI, 0.26-0.79; P =.005).Our meta-analysis of randomized controlled trials of HRT noted a statistically significant reduction in nonvertebral fractures. However, this effect may be attenuated in older women.","Hormone replacement therapy and prevention of nonvertebral fractures: a meta-analysis of randomized trials."
"111","JAMA.3910","0.02",11401611,2001,"Hormone replacement therapy (HRT) is widely considered to reduce fractures, but this belief is based on observational data; evidence from randomized trials is lacking.To conduct a systematic review of all randomized trials of HRT that have reported or collected nonvertebral fracture data but that may not have focused on fracture prevention.The MEDLINE, EMBASE, Science Citation Index, and Cochrane Controlled Trials Register databases were searched from 1997 through 2000 and a search was conducted of all recent systematic reviews to identify older studies. Authors were contacted to establish whether fracture data had been collected but not reported. Researchers in the field and pharmaceutical companies also were contacted to try to identify unpublished studies.Trials were included in which participants had been randomized to at least 12 months of therapy and data on nonvertebral fractures at any other site and due to any cause were available. Of 70 initially identified studies, 22 were included in the analysis.Both investigators extracted data independently and appraised trial quality according to the Jadad scale, which assesses the methods of randomization, concealment allocation, and reporting of withdrawals and dropouts. Disagreements were resolved by discussion.There was an overall 27% reduction in nonvertebral fractures in a pooled analysis (reduction favoring HRT in relative risk [RR], 0.73; 95% confidence interval [CI], 0.56-0.94; P =.02). This effect was greater among women randomized to HRT who had a mean age younger than 60 years (RR, 0.67; 95% CI, 0.46-0.98; P =.03). Among women with a mean age of 60 years or older, there was a reduced effect (RR, 0.88; 95% CI, 0.71-1.08; P =.22). For hip and wrist fractures alone, the effectiveness of HRT appeared more marked (RR, 0.60; 95% CI, 0.40-0.91; P =.02), particularly for women younger than 60 years (RR, 0.45; 95% CI, 0.26-0.79; P =.005).Our meta-analysis of randomized controlled trials of HRT noted a statistically significant reduction in nonvertebral fractures. However, this effect may be attenuated in older women.","Hormone replacement therapy and prevention of nonvertebral fractures: a meta-analysis of randomized trials."
"112","JAMA.4010","0.005",11401611,2001,"Hormone replacement therapy (HRT) is widely considered to reduce fractures, but this belief is based on observational data; evidence from randomized trials is lacking.To conduct a systematic review of all randomized trials of HRT that have reported or collected nonvertebral fracture data but that may not have focused on fracture prevention.The MEDLINE, EMBASE, Science Citation Index, and Cochrane Controlled Trials Register databases were searched from 1997 through 2000 and a search was conducted of all recent systematic reviews to identify older studies. Authors were contacted to establish whether fracture data had been collected but not reported. Researchers in the field and pharmaceutical companies also were contacted to try to identify unpublished studies.Trials were included in which participants had been randomized to at least 12 months of therapy and data on nonvertebral fractures at any other site and due to any cause were available. Of 70 initially identified studies, 22 were included in the analysis.Both investigators extracted data independently and appraised trial quality according to the Jadad scale, which assesses the methods of randomization, concealment allocation, and reporting of withdrawals and dropouts. Disagreements were resolved by discussion.There was an overall 27% reduction in nonvertebral fractures in a pooled analysis (reduction favoring HRT in relative risk [RR], 0.73; 95% confidence interval [CI], 0.56-0.94; P =.02). This effect was greater among women randomized to HRT who had a mean age younger than 60 years (RR, 0.67; 95% CI, 0.46-0.98; P =.03). Among women with a mean age of 60 years or older, there was a reduced effect (RR, 0.88; 95% CI, 0.71-1.08; P =.22). For hip and wrist fractures alone, the effectiveness of HRT appeared more marked (RR, 0.60; 95% CI, 0.40-0.91; P =.02), particularly for women younger than 60 years (RR, 0.45; 95% CI, 0.26-0.79; P =.005).Our meta-analysis of randomized controlled trials of HRT noted a statistically significant reduction in nonvertebral fractures. However, this effect may be attenuated in older women.","Hormone replacement therapy and prevention of nonvertebral fractures: a meta-analysis of randomized trials."
"113","JAMA.2410","NA",11427138,2001,"Herpes simplex virus type 2 (HSV-2) is one of the most common sexually transmitted infections in the United States. No prospective study has shown the ability of condoms to reduce transmission of HSV-2.To evaluate risk factors for HSV-2 acquisition and efficacy of condoms in prevention of HSV-2 transmission.Analysis of data from a randomized, double-blind, placebo-controlled trial conducted December 13, 1993, to June 28, 1996, of an ineffective candidate HSV-2 vaccine with 18 months of follow-up.Eighteen clinical trial centers in the United States.A total of 528 monogamous couples discordant for HSV-2 infection, including an HSV-2-susceptible population of 261 men and 267 women.Acquisition of HSV-2 infection by susceptible partners, compared with those remaining free of HSV-2 with regard to demographic characteristics, sexual activity, and condom use.Twenty-six women (9.7%) vs 5 men (1.9%) acquired HSV-2, for a rate per 10 000 sex acts (episodes of sexual intercourse) of 8.9 vs 1.5, respectively (P<.001). In multivariable analysis, younger age (adjusted hazard ratio [HR] per 5 years, 1.57; 95% confidence interval [CI], 1.22-2.04), seropositivity for HSV-1 and HSV-2 vs HSV-2 alone in the source partner (adjusted HR, 2.34; 95% CI, 1.14-4.82), and more frequent sexual activity (adjusted HR per additional sex act per week, 1.10; 95% CI, 1.01-1.19) were associated with higher risk of HSV-2 acquisition. Condom use during more than 25% of sex acts was associated with protection against HSV-2 acquisition for women (adjusted HR, 0.085; 95% CI, 0.01-0.67) but not for men (adjusted HR, 2.02; 95% CI, 0.32-12.50). Risk of HSV-2 transmission declined from 8.5 per 100 person-years in the initial 150-day interval to 0.9 per 100 person-years in the final 150-day interval (P =.002 for trend), concurrent with a decrease in sexual activity and proportion of sex acts occurring when the source partner had genital lesions.Condom use offers significant protection against HSV-2 infection in susceptible women. Changes in sexual behavior, correlated with counseling about avoiding sex when a partner has lesions, were associated with reduction in HSV-2 acquisition over time. These data suggest that identification of discordant couples can reduce transmission of HSV-2, especially for heterosexual couples in which the male partner has HSV-2 infection.","Effect of condoms on reducing the transmission of herpes simplex virus type 2 from men to women."
"114","JAMA.2410","NA",11427138,2001,"Herpes simplex virus type 2 (HSV-2) is one of the most common sexually transmitted infections in the United States. No prospective study has shown the ability of condoms to reduce transmission of HSV-2.To evaluate risk factors for HSV-2 acquisition and efficacy of condoms in prevention of HSV-2 transmission.Analysis of data from a randomized, double-blind, placebo-controlled trial conducted December 13, 1993, to June 28, 1996, of an ineffective candidate HSV-2 vaccine with 18 months of follow-up.Eighteen clinical trial centers in the United States.A total of 528 monogamous couples discordant for HSV-2 infection, including an HSV-2-susceptible population of 261 men and 267 women.Acquisition of HSV-2 infection by susceptible partners, compared with those remaining free of HSV-2 with regard to demographic characteristics, sexual activity, and condom use.Twenty-six women (9.7%) vs 5 men (1.9%) acquired HSV-2, for a rate per 10 000 sex acts (episodes of sexual intercourse) of 8.9 vs 1.5, respectively (P<.001). In multivariable analysis, younger age (adjusted hazard ratio [HR] per 5 years, 1.57; 95% confidence interval [CI], 1.22-2.04), seropositivity for HSV-1 and HSV-2 vs HSV-2 alone in the source partner (adjusted HR, 2.34; 95% CI, 1.14-4.82), and more frequent sexual activity (adjusted HR per additional sex act per week, 1.10; 95% CI, 1.01-1.19) were associated with higher risk of HSV-2 acquisition. Condom use during more than 25% of sex acts was associated with protection against HSV-2 acquisition for women (adjusted HR, 0.085; 95% CI, 0.01-0.67) but not for men (adjusted HR, 2.02; 95% CI, 0.32-12.50). Risk of HSV-2 transmission declined from 8.5 per 100 person-years in the initial 150-day interval to 0.9 per 100 person-years in the final 150-day interval (P =.002 for trend), concurrent with a decrease in sexual activity and proportion of sex acts occurring when the source partner had genital lesions.Condom use offers significant protection against HSV-2 infection in susceptible women. Changes in sexual behavior, correlated with counseling about avoiding sex when a partner has lesions, were associated with reduction in HSV-2 acquisition over time. These data suggest that identification of discordant couples can reduce transmission of HSV-2, especially for heterosexual couples in which the male partner has HSV-2 infection.","Effect of condoms on reducing the transmission of herpes simplex virus type 2 from men to women."
"115","JAMA.2410","NA",11427138,2001,"Herpes simplex virus type 2 (HSV-2) is one of the most common sexually transmitted infections in the United States. No prospective study has shown the ability of condoms to reduce transmission of HSV-2.To evaluate risk factors for HSV-2 acquisition and efficacy of condoms in prevention of HSV-2 transmission.Analysis of data from a randomized, double-blind, placebo-controlled trial conducted December 13, 1993, to June 28, 1996, of an ineffective candidate HSV-2 vaccine with 18 months of follow-up.Eighteen clinical trial centers in the United States.A total of 528 monogamous couples discordant for HSV-2 infection, including an HSV-2-susceptible population of 261 men and 267 women.Acquisition of HSV-2 infection by susceptible partners, compared with those remaining free of HSV-2 with regard to demographic characteristics, sexual activity, and condom use.Twenty-six women (9.7%) vs 5 men (1.9%) acquired HSV-2, for a rate per 10 000 sex acts (episodes of sexual intercourse) of 8.9 vs 1.5, respectively (P<.001). In multivariable analysis, younger age (adjusted hazard ratio [HR] per 5 years, 1.57; 95% confidence interval [CI], 1.22-2.04), seropositivity for HSV-1 and HSV-2 vs HSV-2 alone in the source partner (adjusted HR, 2.34; 95% CI, 1.14-4.82), and more frequent sexual activity (adjusted HR per additional sex act per week, 1.10; 95% CI, 1.01-1.19) were associated with higher risk of HSV-2 acquisition. Condom use during more than 25% of sex acts was associated with protection against HSV-2 acquisition for women (adjusted HR, 0.085; 95% CI, 0.01-0.67) but not for men (adjusted HR, 2.02; 95% CI, 0.32-12.50). Risk of HSV-2 transmission declined from 8.5 per 100 person-years in the initial 150-day interval to 0.9 per 100 person-years in the final 150-day interval (P =.002 for trend), concurrent with a decrease in sexual activity and proportion of sex acts occurring when the source partner had genital lesions.Condom use offers significant protection against HSV-2 infection in susceptible women. Changes in sexual behavior, correlated with counseling about avoiding sex when a partner has lesions, were associated with reduction in HSV-2 acquisition over time. These data suggest that identification of discordant couples can reduce transmission of HSV-2, especially for heterosexual couples in which the male partner has HSV-2 infection.","Effect of condoms on reducing the transmission of herpes simplex virus type 2 from men to women."
"116","JAMA.2410","NA",11427138,2001,"Herpes simplex virus type 2 (HSV-2) is one of the most common sexually transmitted infections in the United States. No prospective study has shown the ability of condoms to reduce transmission of HSV-2.To evaluate risk factors for HSV-2 acquisition and efficacy of condoms in prevention of HSV-2 transmission.Analysis of data from a randomized, double-blind, placebo-controlled trial conducted December 13, 1993, to June 28, 1996, of an ineffective candidate HSV-2 vaccine with 18 months of follow-up.Eighteen clinical trial centers in the United States.A total of 528 monogamous couples discordant for HSV-2 infection, including an HSV-2-susceptible population of 261 men and 267 women.Acquisition of HSV-2 infection by susceptible partners, compared with those remaining free of HSV-2 with regard to demographic characteristics, sexual activity, and condom use.Twenty-six women (9.7%) vs 5 men (1.9%) acquired HSV-2, for a rate per 10 000 sex acts (episodes of sexual intercourse) of 8.9 vs 1.5, respectively (P<.001). In multivariable analysis, younger age (adjusted hazard ratio [HR] per 5 years, 1.57; 95% confidence interval [CI], 1.22-2.04), seropositivity for HSV-1 and HSV-2 vs HSV-2 alone in the source partner (adjusted HR, 2.34; 95% CI, 1.14-4.82), and more frequent sexual activity (adjusted HR per additional sex act per week, 1.10; 95% CI, 1.01-1.19) were associated with higher risk of HSV-2 acquisition. Condom use during more than 25% of sex acts was associated with protection against HSV-2 acquisition for women (adjusted HR, 0.085; 95% CI, 0.01-0.67) but not for men (adjusted HR, 2.02; 95% CI, 0.32-12.50). Risk of HSV-2 transmission declined from 8.5 per 100 person-years in the initial 150-day interval to 0.9 per 100 person-years in the final 150-day interval (P =.002 for trend), concurrent with a decrease in sexual activity and proportion of sex acts occurring when the source partner had genital lesions.Condom use offers significant protection against HSV-2 infection in susceptible women. Changes in sexual behavior, correlated with counseling about avoiding sex when a partner has lesions, were associated with reduction in HSV-2 acquisition over time. These data suggest that identification of discordant couples can reduce transmission of HSV-2, especially for heterosexual couples in which the male partner has HSV-2 infection.","Effect of condoms on reducing the transmission of herpes simplex virus type 2 from men to women."
"117","JAMA.3510","NA",11427138,2001,"Herpes simplex virus type 2 (HSV-2) is one of the most common sexually transmitted infections in the United States. No prospective study has shown the ability of condoms to reduce transmission of HSV-2.To evaluate risk factors for HSV-2 acquisition and efficacy of condoms in prevention of HSV-2 transmission.Analysis of data from a randomized, double-blind, placebo-controlled trial conducted December 13, 1993, to June 28, 1996, of an ineffective candidate HSV-2 vaccine with 18 months of follow-up.Eighteen clinical trial centers in the United States.A total of 528 monogamous couples discordant for HSV-2 infection, including an HSV-2-susceptible population of 261 men and 267 women.Acquisition of HSV-2 infection by susceptible partners, compared with those remaining free of HSV-2 with regard to demographic characteristics, sexual activity, and condom use.Twenty-six women (9.7%) vs 5 men (1.9%) acquired HSV-2, for a rate per 10 000 sex acts (episodes of sexual intercourse) of 8.9 vs 1.5, respectively (P<.001). In multivariable analysis, younger age (adjusted hazard ratio [HR] per 5 years, 1.57; 95% confidence interval [CI], 1.22-2.04), seropositivity for HSV-1 and HSV-2 vs HSV-2 alone in the source partner (adjusted HR, 2.34; 95% CI, 1.14-4.82), and more frequent sexual activity (adjusted HR per additional sex act per week, 1.10; 95% CI, 1.01-1.19) were associated with higher risk of HSV-2 acquisition. Condom use during more than 25% of sex acts was associated with protection against HSV-2 acquisition for women (adjusted HR, 0.085; 95% CI, 0.01-0.67) but not for men (adjusted HR, 2.02; 95% CI, 0.32-12.50). Risk of HSV-2 transmission declined from 8.5 per 100 person-years in the initial 150-day interval to 0.9 per 100 person-years in the final 150-day interval (P =.002 for trend), concurrent with a decrease in sexual activity and proportion of sex acts occurring when the source partner had genital lesions.Condom use offers significant protection against HSV-2 infection in susceptible women. Changes in sexual behavior, correlated with counseling about avoiding sex when a partner has lesions, were associated with reduction in HSV-2 acquisition over time. These data suggest that identification of discordant couples can reduce transmission of HSV-2, especially for heterosexual couples in which the male partner has HSV-2 infection.","Effect of condoms on reducing the transmission of herpes simplex virus type 2 from men to women."
"118","JAMA.82","0.05",11427141,2001,"Most deaths in the United States occur among older persons who have 1 or more disabling conditions. As a result, many deaths are preceded by an extended period during which family members provide care to their disabled relative.To better understand the effect of bereavement on family caregivers by examining predeath vs postdeath changes in self-reported and objective health outcomes among elderly persons providing varying levels of care prior to their spouse's death.Prospective, population-based cohort study conducted in 4 US communities between 1993 and 1998.One hundred twenty-nine individuals aged 66 to 96 years whose spouse died during an average 4-year follow-up. Individuals were classified as noncaregivers (n = 40), caregivers who reported no strain (n = 37), or strained caregivers (n = 52).Changes in depression symptoms (assessed by the 10-item Center for Epidemiological Studies-Depression [CES-D] scale), antidepressant medication use, 6 health risk behaviors, and weight among the 3 groups of participants.Controlling for age, sex, race, education, prevalent cardiovascular disease at baseline, and interval between predeath and postdeath assessments, CES-D scores remained high but did not change among strained caregivers (9.44 vs 9.19; P =.76), while these scores increased for both noncaregivers (4.74 vs 8.25; F(1,116) = 14.33; P<.001) and nonstrained caregivers (4.94 vs 7.13; F(1,116) = 4.35; P =.04). Noncaregivers were significantly more likely to be using nontricyclic antidepressant medications following the death than the nonstrained caregiver group (odds ratio [OR], 12.85; 95% confidence interval [CI], 1.02-162.13; P =.05). The strained caregiver group experienced significant improvement in health risk behaviors following the death of their spouse (1.47 vs 0.66 behaviors; F(1,118) = 20.23; P<.001), while the noncaregiver and nonstrained caregiver groups showed little change (0.27 vs 0.27 [P =.99] and 0.46 vs 0.27 [P =.39] behaviors, respectively). Noncaregivers experienced significant weight loss following the death (149.1 vs 145.3 lb [67.1 vs 65.4 kg]; F(1,101) = 8.12; P =.005), while the strained and nonstrained caregiving groups did not show significant weight change (156.2 vs 155.2 lb [70.3 vs 69.8 kg] [P =.41] and 156.2 vs 154.0 lb [70.3 vs 69.3 kg] [P =.12], respectively).These data indicate that the impact of losing one's spouse among older persons varies as a function of the caregiving experiences that precede the death. Among individuals who are already strained prior to the death of their spouse, the death itself does not increase their level of distress. Instead, they show reductions in health risk behaviors. Among noncaregivers, losing one's spouse results in increased depression and weight loss.","Involvement in caregiving and adjustment to death of a spouse: findings from the caregiver health effects study."
"119","American Journal of Epidemiology.11","0.42",11447044,2001,"This study sought to determine the association between nearly lethal suicide attempts and exposure to the suicidal behavior of parents, relatives, friends, or acquaintances and to accounts of suicide in the media. The authors conducted a population-based case-control study in Houston, Texas, from November 1992 through July 1995. They interviewed 153 victims of attempted suicide aged 13--34 years who had been treated at emergency departments in Houston and a random sample of 513 control subjects. After controlling for potentially confounding variables, the authors found that exposure to the suicidal behavior of a parent (adjusted OR = 1.5; 95% CI: 0.6, 3.6; p = 0.42) or a nonparent relative (adjusted OR = 1.2; 95% CI: 0.7, 2.0; p = 0.55) was not significantly associated with nearly lethal suicide attempts. Both exposure to the suicidal behavior of a friend or acquaintance (adjusted OR = 0.6; 95% CI: 0.4, 1.0; p = 0.05) and exposure to accounts of suicidal behavior in the media (adjusted OR = 0.2; 95% CI: 0.1, 0.3; p = 0.00) were associated with a lower risk of nearly lethal suicide attempts. Exposure to accounts of suicidal behavior in the media and, to a lesser extent, exposure to the suicidal behavior of friends or acquaintances may be protective for nearly lethal suicide attempts, but further research is needed to better understand the mechanisms underlying these findings.","Is suicide contagious? A study of the relation between exposure to the suicidal behavior of others and nearly lethal suicide attempts."
"120","American Journal of Epidemiology.12","0.55",11447044,2001,"This study sought to determine the association between nearly lethal suicide attempts and exposure to the suicidal behavior of parents, relatives, friends, or acquaintances and to accounts of suicide in the media. The authors conducted a population-based case-control study in Houston, Texas, from November 1992 through July 1995. They interviewed 153 victims of attempted suicide aged 13--34 years who had been treated at emergency departments in Houston and a random sample of 513 control subjects. After controlling for potentially confounding variables, the authors found that exposure to the suicidal behavior of a parent (adjusted OR = 1.5; 95% CI: 0.6, 3.6; p = 0.42) or a nonparent relative (adjusted OR = 1.2; 95% CI: 0.7, 2.0; p = 0.55) was not significantly associated with nearly lethal suicide attempts. Both exposure to the suicidal behavior of a friend or acquaintance (adjusted OR = 0.6; 95% CI: 0.4, 1.0; p = 0.05) and exposure to accounts of suicidal behavior in the media (adjusted OR = 0.2; 95% CI: 0.1, 0.3; p = 0.00) were associated with a lower risk of nearly lethal suicide attempts. Exposure to accounts of suicidal behavior in the media and, to a lesser extent, exposure to the suicidal behavior of friends or acquaintances may be protective for nearly lethal suicide attempts, but further research is needed to better understand the mechanisms underlying these findings.","Is suicide contagious? A study of the relation between exposure to the suicidal behavior of others and nearly lethal suicide attempts."
"121","American Journal of Epidemiology.13","0.05",11447044,2001,"This study sought to determine the association between nearly lethal suicide attempts and exposure to the suicidal behavior of parents, relatives, friends, or acquaintances and to accounts of suicide in the media. The authors conducted a population-based case-control study in Houston, Texas, from November 1992 through July 1995. They interviewed 153 victims of attempted suicide aged 13--34 years who had been treated at emergency departments in Houston and a random sample of 513 control subjects. After controlling for potentially confounding variables, the authors found that exposure to the suicidal behavior of a parent (adjusted OR = 1.5; 95% CI: 0.6, 3.6; p = 0.42) or a nonparent relative (adjusted OR = 1.2; 95% CI: 0.7, 2.0; p = 0.55) was not significantly associated with nearly lethal suicide attempts. Both exposure to the suicidal behavior of a friend or acquaintance (adjusted OR = 0.6; 95% CI: 0.4, 1.0; p = 0.05) and exposure to accounts of suicidal behavior in the media (adjusted OR = 0.2; 95% CI: 0.1, 0.3; p = 0.00) were associated with a lower risk of nearly lethal suicide attempts. Exposure to accounts of suicidal behavior in the media and, to a lesser extent, exposure to the suicidal behavior of friends or acquaintances may be protective for nearly lethal suicide attempts, but further research is needed to better understand the mechanisms underlying these findings.","Is suicide contagious? A study of the relation between exposure to the suicidal behavior of others and nearly lethal suicide attempts."
"122","American Journal of Epidemiology.14","0",11447044,2001,"This study sought to determine the association between nearly lethal suicide attempts and exposure to the suicidal behavior of parents, relatives, friends, or acquaintances and to accounts of suicide in the media. The authors conducted a population-based case-control study in Houston, Texas, from November 1992 through July 1995. They interviewed 153 victims of attempted suicide aged 13--34 years who had been treated at emergency departments in Houston and a random sample of 513 control subjects. After controlling for potentially confounding variables, the authors found that exposure to the suicidal behavior of a parent (adjusted OR = 1.5; 95% CI: 0.6, 3.6; p = 0.42) or a nonparent relative (adjusted OR = 1.2; 95% CI: 0.7, 2.0; p = 0.55) was not significantly associated with nearly lethal suicide attempts. Both exposure to the suicidal behavior of a friend or acquaintance (adjusted OR = 0.6; 95% CI: 0.4, 1.0; p = 0.05) and exposure to accounts of suicidal behavior in the media (adjusted OR = 0.2; 95% CI: 0.1, 0.3; p = 0.00) were associated with a lower risk of nearly lethal suicide attempts. Exposure to accounts of suicidal behavior in the media and, to a lesser extent, exposure to the suicidal behavior of friends or acquaintances may be protective for nearly lethal suicide attempts, but further research is needed to better understand the mechanisms underlying these findings.","Is suicide contagious? A study of the relation between exposure to the suicidal behavior of others and nearly lethal suicide attempts."
"123","Lancet.170","0.003",11476835,2001,"Asthma places huge demands on health-care services, and its prevalence is increasing. Reduction of exposure to environmental allergens could offer a realistic chance for primary prevention. Our aim was to ascertain whether or not living in a low-allergen environment reduces the risk of asthma and atopic diseases in infants.We assigned infants to four risk groups according to parental atopic status. We enrolled 291 high-risk couples (both parents atopic, no pets) into a prospective, prenatally randomised, cohort study, and allocated them to environmental manipulation, in which measures to reduce prenatal and postnatal allergen exposure were undertaken (active HRA) (n=145) or no intervention (control HRC) (n=146). Two further prospective groups were studied: 161 high-risk infants with pets in the home (HRP group) and 168 low-risk infants, whose parents were both non-atopic (LR group). The main outcome measures were signs and symptoms of atopic disease at 1 year of age.103 families dropped out or were lost to follow up. At age 1 year we followed-up 133 HRA, 118 HRC, 140 HRP, and 126 LR infants. Children in the HRA group were less likely to have respiratory symptoms during the first year of life than those in the HRC group. The most pronounced differences were in the relative risks for severe wheeze with shortness of breath (relative risk 0.44 [95% CI 0.20-1.00]), prescribed medication for the treatment of wheezy attacks (0.58 [0.36-0.95]), and wheezing after vigorous playing, crying, or exertion (0.18 [0.04-0.79]). Probability of respiratory symptoms in HRC and HRP infants was similar, whereas it was much lower in the LR than in the HRC group. Cat ownership was significantly associated with sensitisation to cats (24.6 [3.04-199.05]; p=0.003).Environmental manipulation reduces some respiratory symptoms in the first year of life in high-risk infants. Further follow up is needed, however, to ascertain whether living in a low-allergen environment reduces allergy and asthma in later life.","Effect of environmental manipulation in pregnancy and early life on respiratory symptoms and atopy during first year of life: a randomised trial."
"124","JAMA.41","0.001",11495620,2001,"Whether venous catheterization at the femoral site is associated with an increased risk of complications compared with that at the subclavian site is debated.To compare mechanical, infectious, and thrombotic complications of femoral and subclavian venous catheterization.Concealed, randomized controlled clinical trial conducted between December 1997 and July 2000 at 8 intensive care units (ICUs) in France.Two hundred eighty-nine adult patients receiving a first central venous catheter.Patients were randomly assigned to undergo central venous catheterization at the femoral site (n = 145) or subclavian site (n = 144).Rate and severity of mechanical, infectious, and thrombotic complications, compared by catheterization site in 289, 270, and 223 patients, respectively.Femoral catheterization was associated with a higher incidence rate of overall infectious complications (19.8% vs 4.5%; P<.001; incidence density of 20 vs 3.7 per 1000 catheter-days) and of major infectious complications (clinical sepsis with or without bloodstream infection, 4.4% vs 1.5%; P =.07; incidence density of 4.5 vs 1.2 per 1000 catheter-days), as well as of overall thrombotic complications (21.5% vs 1.9%; P<.001) and complete thrombosis of the vessel (6% vs 0%; P =.01); rates of overall and major mechanical complications were similar between the 2 groups (17.3% vs 18.8 %; P =.74 and 1.4% vs 2.8%; P =.44, respectively). Risk factors for mechanical complications were duration of insertion (odds ratio [OR], 1.05; 95% confidence interval [CI], 1.03-1.08 per additional minute; P<.001); insertion in 2 of the centers (OR, 4.52; 95% CI, 1.81-11.23; P =.001); and insertion during the night (OR, 2.06; 95% CI, 1.04-4.08; P =.03). The only factor associated with infectious complications was femoral catheterization (hazard ratio [HR], 4.83; 95% CI, 1.96-11.93; P<.001); antibiotic administration via the catheter decreased risk of infectious complications (HR, 0.41; 95% CI, 0.18-0.93; P =.03). Femoral catheterization was the only risk factor for thrombotic complications (OR, 14.42; 95% CI, 3.33-62.57; P<.001).Femoral venous catheterization is associated with a greater risk of infectious and thrombotic complications than subclavian catheterization in ICU patients.","Complications of femoral and subclavian venous catheterization in critically ill patients: a randomized controlled trial."
"125","JAMA.42","0.001",11495620,2001,"Whether venous catheterization at the femoral site is associated with an increased risk of complications compared with that at the subclavian site is debated.To compare mechanical, infectious, and thrombotic complications of femoral and subclavian venous catheterization.Concealed, randomized controlled clinical trial conducted between December 1997 and July 2000 at 8 intensive care units (ICUs) in France.Two hundred eighty-nine adult patients receiving a first central venous catheter.Patients were randomly assigned to undergo central venous catheterization at the femoral site (n = 145) or subclavian site (n = 144).Rate and severity of mechanical, infectious, and thrombotic complications, compared by catheterization site in 289, 270, and 223 patients, respectively.Femoral catheterization was associated with a higher incidence rate of overall infectious complications (19.8% vs 4.5%; P<.001; incidence density of 20 vs 3.7 per 1000 catheter-days) and of major infectious complications (clinical sepsis with or without bloodstream infection, 4.4% vs 1.5%; P =.07; incidence density of 4.5 vs 1.2 per 1000 catheter-days), as well as of overall thrombotic complications (21.5% vs 1.9%; P<.001) and complete thrombosis of the vessel (6% vs 0%; P =.01); rates of overall and major mechanical complications were similar between the 2 groups (17.3% vs 18.8 %; P =.74 and 1.4% vs 2.8%; P =.44, respectively). Risk factors for mechanical complications were duration of insertion (odds ratio [OR], 1.05; 95% confidence interval [CI], 1.03-1.08 per additional minute; P<.001); insertion in 2 of the centers (OR, 4.52; 95% CI, 1.81-11.23; P =.001); and insertion during the night (OR, 2.06; 95% CI, 1.04-4.08; P =.03). The only factor associated with infectious complications was femoral catheterization (hazard ratio [HR], 4.83; 95% CI, 1.96-11.93; P<.001); antibiotic administration via the catheter decreased risk of infectious complications (HR, 0.41; 95% CI, 0.18-0.93; P =.03). Femoral catheterization was the only risk factor for thrombotic complications (OR, 14.42; 95% CI, 3.33-62.57; P<.001).Femoral venous catheterization is associated with a greater risk of infectious and thrombotic complications than subclavian catheterization in ICU patients.","Complications of femoral and subclavian venous catheterization in critically ill patients: a randomized controlled trial."
"126","JAMA.43","0.001",11495620,2001,"Whether venous catheterization at the femoral site is associated with an increased risk of complications compared with that at the subclavian site is debated.To compare mechanical, infectious, and thrombotic complications of femoral and subclavian venous catheterization.Concealed, randomized controlled clinical trial conducted between December 1997 and July 2000 at 8 intensive care units (ICUs) in France.Two hundred eighty-nine adult patients receiving a first central venous catheter.Patients were randomly assigned to undergo central venous catheterization at the femoral site (n = 145) or subclavian site (n = 144).Rate and severity of mechanical, infectious, and thrombotic complications, compared by catheterization site in 289, 270, and 223 patients, respectively.Femoral catheterization was associated with a higher incidence rate of overall infectious complications (19.8% vs 4.5%; P<.001; incidence density of 20 vs 3.7 per 1000 catheter-days) and of major infectious complications (clinical sepsis with or without bloodstream infection, 4.4% vs 1.5%; P =.07; incidence density of 4.5 vs 1.2 per 1000 catheter-days), as well as of overall thrombotic complications (21.5% vs 1.9%; P<.001) and complete thrombosis of the vessel (6% vs 0%; P =.01); rates of overall and major mechanical complications were similar between the 2 groups (17.3% vs 18.8 %; P =.74 and 1.4% vs 2.8%; P =.44, respectively). Risk factors for mechanical complications were duration of insertion (odds ratio [OR], 1.05; 95% confidence interval [CI], 1.03-1.08 per additional minute; P<.001); insertion in 2 of the centers (OR, 4.52; 95% CI, 1.81-11.23; P =.001); and insertion during the night (OR, 2.06; 95% CI, 1.04-4.08; P =.03). The only factor associated with infectious complications was femoral catheterization (hazard ratio [HR], 4.83; 95% CI, 1.96-11.93; P<.001); antibiotic administration via the catheter decreased risk of infectious complications (HR, 0.41; 95% CI, 0.18-0.93; P =.03). Femoral catheterization was the only risk factor for thrombotic complications (OR, 14.42; 95% CI, 3.33-62.57; P<.001).Femoral venous catheterization is associated with a greater risk of infectious and thrombotic complications than subclavian catheterization in ICU patients.","Complications of femoral and subclavian venous catheterization in critically ill patients: a randomized controlled trial."
"127","JAMA.44","0.001",11495620,2001,"Whether venous catheterization at the femoral site is associated with an increased risk of complications compared with that at the subclavian site is debated.To compare mechanical, infectious, and thrombotic complications of femoral and subclavian venous catheterization.Concealed, randomized controlled clinical trial conducted between December 1997 and July 2000 at 8 intensive care units (ICUs) in France.Two hundred eighty-nine adult patients receiving a first central venous catheter.Patients were randomly assigned to undergo central venous catheterization at the femoral site (n = 145) or subclavian site (n = 144).Rate and severity of mechanical, infectious, and thrombotic complications, compared by catheterization site in 289, 270, and 223 patients, respectively.Femoral catheterization was associated with a higher incidence rate of overall infectious complications (19.8% vs 4.5%; P<.001; incidence density of 20 vs 3.7 per 1000 catheter-days) and of major infectious complications (clinical sepsis with or without bloodstream infection, 4.4% vs 1.5%; P =.07; incidence density of 4.5 vs 1.2 per 1000 catheter-days), as well as of overall thrombotic complications (21.5% vs 1.9%; P<.001) and complete thrombosis of the vessel (6% vs 0%; P =.01); rates of overall and major mechanical complications were similar between the 2 groups (17.3% vs 18.8 %; P =.74 and 1.4% vs 2.8%; P =.44, respectively). Risk factors for mechanical complications were duration of insertion (odds ratio [OR], 1.05; 95% confidence interval [CI], 1.03-1.08 per additional minute; P<.001); insertion in 2 of the centers (OR, 4.52; 95% CI, 1.81-11.23; P =.001); and insertion during the night (OR, 2.06; 95% CI, 1.04-4.08; P =.03). The only factor associated with infectious complications was femoral catheterization (hazard ratio [HR], 4.83; 95% CI, 1.96-11.93; P<.001); antibiotic administration via the catheter decreased risk of infectious complications (HR, 0.41; 95% CI, 0.18-0.93; P =.03). Femoral catheterization was the only risk factor for thrombotic complications (OR, 14.42; 95% CI, 3.33-62.57; P<.001).Femoral venous catheterization is associated with a greater risk of infectious and thrombotic complications than subclavian catheterization in ICU patients.","Complications of femoral and subclavian venous catheterization in critically ill patients: a randomized controlled trial."
"128","JAMA.78","0.03",11495620,2001,"Whether venous catheterization at the femoral site is associated with an increased risk of complications compared with that at the subclavian site is debated.To compare mechanical, infectious, and thrombotic complications of femoral and subclavian venous catheterization.Concealed, randomized controlled clinical trial conducted between December 1997 and July 2000 at 8 intensive care units (ICUs) in France.Two hundred eighty-nine adult patients receiving a first central venous catheter.Patients were randomly assigned to undergo central venous catheterization at the femoral site (n = 145) or subclavian site (n = 144).Rate and severity of mechanical, infectious, and thrombotic complications, compared by catheterization site in 289, 270, and 223 patients, respectively.Femoral catheterization was associated with a higher incidence rate of overall infectious complications (19.8% vs 4.5%; P<.001; incidence density of 20 vs 3.7 per 1000 catheter-days) and of major infectious complications (clinical sepsis with or without bloodstream infection, 4.4% vs 1.5%; P =.07; incidence density of 4.5 vs 1.2 per 1000 catheter-days), as well as of overall thrombotic complications (21.5% vs 1.9%; P<.001) and complete thrombosis of the vessel (6% vs 0%; P =.01); rates of overall and major mechanical complications were similar between the 2 groups (17.3% vs 18.8 %; P =.74 and 1.4% vs 2.8%; P =.44, respectively). Risk factors for mechanical complications were duration of insertion (odds ratio [OR], 1.05; 95% confidence interval [CI], 1.03-1.08 per additional minute; P<.001); insertion in 2 of the centers (OR, 4.52; 95% CI, 1.81-11.23; P =.001); and insertion during the night (OR, 2.06; 95% CI, 1.04-4.08; P =.03). The only factor associated with infectious complications was femoral catheterization (hazard ratio [HR], 4.83; 95% CI, 1.96-11.93; P<.001); antibiotic administration via the catheter decreased risk of infectious complications (HR, 0.41; 95% CI, 0.18-0.93; P =.03). Femoral catheterization was the only risk factor for thrombotic complications (OR, 14.42; 95% CI, 3.33-62.57; P<.001).Femoral venous catheterization is associated with a greater risk of infectious and thrombotic complications than subclavian catheterization in ICU patients.","Complications of femoral and subclavian venous catheterization in critically ill patients: a randomized controlled trial."
"129","JAMA.79","0.03",11495620,2001,"Whether venous catheterization at the femoral site is associated with an increased risk of complications compared with that at the subclavian site is debated.To compare mechanical, infectious, and thrombotic complications of femoral and subclavian venous catheterization.Concealed, randomized controlled clinical trial conducted between December 1997 and July 2000 at 8 intensive care units (ICUs) in France.Two hundred eighty-nine adult patients receiving a first central venous catheter.Patients were randomly assigned to undergo central venous catheterization at the femoral site (n = 145) or subclavian site (n = 144).Rate and severity of mechanical, infectious, and thrombotic complications, compared by catheterization site in 289, 270, and 223 patients, respectively.Femoral catheterization was associated with a higher incidence rate of overall infectious complications (19.8% vs 4.5%; P<.001; incidence density of 20 vs 3.7 per 1000 catheter-days) and of major infectious complications (clinical sepsis with or without bloodstream infection, 4.4% vs 1.5%; P =.07; incidence density of 4.5 vs 1.2 per 1000 catheter-days), as well as of overall thrombotic complications (21.5% vs 1.9%; P<.001) and complete thrombosis of the vessel (6% vs 0%; P =.01); rates of overall and major mechanical complications were similar between the 2 groups (17.3% vs 18.8 %; P =.74 and 1.4% vs 2.8%; P =.44, respectively). Risk factors for mechanical complications were duration of insertion (odds ratio [OR], 1.05; 95% confidence interval [CI], 1.03-1.08 per additional minute; P<.001); insertion in 2 of the centers (OR, 4.52; 95% CI, 1.81-11.23; P =.001); and insertion during the night (OR, 2.06; 95% CI, 1.04-4.08; P =.03). The only factor associated with infectious complications was femoral catheterization (hazard ratio [HR], 4.83; 95% CI, 1.96-11.93; P<.001); antibiotic administration via the catheter decreased risk of infectious complications (HR, 0.41; 95% CI, 0.18-0.93; P =.03). Femoral catheterization was the only risk factor for thrombotic complications (OR, 14.42; 95% CI, 3.33-62.57; P<.001).Femoral venous catheterization is associated with a greater risk of infectious and thrombotic complications than subclavian catheterization in ICU patients.","Complications of femoral and subclavian venous catheterization in critically ill patients: a randomized controlled trial."
"130","JAMA.70","0.002",11509060,2001,"Atherosclerosis is a process with inflammatory features and selective cyclooxygenase 2 (COX-2) inhibitors may potentially have antiatherogenic effects by virtue of inhibiting inflammation. However, by decreasing vasodilatory and antiaggregatory prostacyclin production, COX-2 antagonists may lead to increased prothrombotic activity. To define the cardiovascular effects of COX-2 inhibitors when used for arthritis and musculoskeletal pain in patients without coronary artery disease, we performed a MEDLINE search to identify all English-language articles on use of COX-2 inhibitors published between 1998 and February 2001. We also reviewed relevant submissions to the US Food and Drug Administration by pharmaceutical companies. Our search yielded 2 major randomized trials, the Vioxx Gastrointestinal Outcomes Research Study (VIGOR; 8076 patients) and the Celecoxib Long-term Arthritis Safety Study (CLASS; 8059 patients), as well as 2 smaller trials with approximately 1000 patients each. The results from VIGOR showed that the relative risk of developing a confirmed adjudicated thrombotic cardiovascular event (myocardial infarction, unstable angina, cardiac thrombus, resuscitated cardiac arrest, sudden or unexplained death, ischemic stroke, and transient ischemic attacks) with rofecoxib treatment compared with naproxen was 2.38 (95% confidence interval, 1.39-4.00; P =.002). There was no significant difference in cardiovascular event (myocardial infarction, stroke, and death) rates between celecoxib and nonsteroidal anti-inflammatory agents in CLASS. The annualized myocardial infarction rates for COX-2 inhibitors in both VIGOR and CLASS were significantly higher than that in the placebo group of a recent meta-analysis of 23 407 patients in primary prevention trials (0.52%): 0.74% with rofecoxib (P =.04 compared with the placebo group of the meta-analysis) and 0.80% with celecoxib (P =.02 compared with the placebo group of the meta-analysis). The available data raise a cautionary flag about the risk of cardiovascular events with COX-2 inhibitors. Further prospective trial evaluation may characterize and determine the magnitude of the risk.","Risk of cardiovascular events associated with selective COX-2 inhibitors."
"131","JAMA.1810","0.001",11559263,2001,"Although aspirin has been shown to reduce cardiovascular morbidity and short-term mortality following acute myocardial infarction, the association between its use and long-term all-cause mortality has not been well defined.To determine whether aspirin is associated with a mortality benefit in stable patients with known or suspected coronary disease and to identify patient characteristics that predict the maximum absolute mortality benefit from aspirin.Prospective, nonrandomized, observational cohort study conducted between 1990 and 1998 at an academic medical institution, with a median follow-up of 3.1 years.Of 6174 consecutive adults undergoing stress echocardiography for evaluation of known or suspected coronary disease, 2310 (37%) were taking aspirin. Patients with significant valvular disease or documented contraindication to aspirin use, including peptic ulcer disease, renal insufficiency, and use of nonsteroidal anti-inflammatory drugs, were excluded.All-cause mortality according to aspirin use.During 3.1 years of follow-up, 276 patients (4.5%) died. In a simple univariable analysis, there was no association between aspirin use and mortality (4.5% vs 4.5%). However, after adjustment for age, sex, standard cardiovascular risk factors, use of other medications, coronary disease history, ejection fraction, exercise capacity, heart rate recovery, and echocardiographic ischemia, aspirin use was associated with reduced mortality (hazard ratio [HR], 0.67; 95% confidence interval [CI], 0.51-0.87; P =.002). In further analysis using matching by propensity score, 1351 patients who were taking aspirin were at lower risk for death than 1351 patients not using aspirin (4% vs 8%, respectively; HR, 0.53; 95% CI, 0.38-0.74; P =.002). After adjusting for the propensity for using aspirin, as well as other possible confounders and interactions, aspirin use remained associated with a lower risk for death (adjusted HR, 0.56; 95% CI, 0.40-0.78; P<.001). The patient characteristics associated with the most aspirin-related reductions in mortality were older age, known coronary artery disease, and impaired exercise capacity.Aspirin use among patients undergoing stress echocardiography was independently associated with reduced long-term all-cause mortality, particularly among older patients, those with known coronary artery disease, and those with impaired exercise capacity.","Aspirin use and all-cause mortality among patients being evaluated for known or suspected coronary artery disease: A propensity analysis."
"132","JAMA.2610","0.002",11559263,2001,"Although aspirin has been shown to reduce cardiovascular morbidity and short-term mortality following acute myocardial infarction, the association between its use and long-term all-cause mortality has not been well defined.To determine whether aspirin is associated with a mortality benefit in stable patients with known or suspected coronary disease and to identify patient characteristics that predict the maximum absolute mortality benefit from aspirin.Prospective, nonrandomized, observational cohort study conducted between 1990 and 1998 at an academic medical institution, with a median follow-up of 3.1 years.Of 6174 consecutive adults undergoing stress echocardiography for evaluation of known or suspected coronary disease, 2310 (37%) were taking aspirin. Patients with significant valvular disease or documented contraindication to aspirin use, including peptic ulcer disease, renal insufficiency, and use of nonsteroidal anti-inflammatory drugs, were excluded.All-cause mortality according to aspirin use.During 3.1 years of follow-up, 276 patients (4.5%) died. In a simple univariable analysis, there was no association between aspirin use and mortality (4.5% vs 4.5%). However, after adjustment for age, sex, standard cardiovascular risk factors, use of other medications, coronary disease history, ejection fraction, exercise capacity, heart rate recovery, and echocardiographic ischemia, aspirin use was associated with reduced mortality (hazard ratio [HR], 0.67; 95% confidence interval [CI], 0.51-0.87; P =.002). In further analysis using matching by propensity score, 1351 patients who were taking aspirin were at lower risk for death than 1351 patients not using aspirin (4% vs 8%, respectively; HR, 0.53; 95% CI, 0.38-0.74; P =.002). After adjusting for the propensity for using aspirin, as well as other possible confounders and interactions, aspirin use remained associated with a lower risk for death (adjusted HR, 0.56; 95% CI, 0.40-0.78; P<.001). The patient characteristics associated with the most aspirin-related reductions in mortality were older age, known coronary artery disease, and impaired exercise capacity.Aspirin use among patients undergoing stress echocardiography was independently associated with reduced long-term all-cause mortality, particularly among older patients, those with known coronary artery disease, and those with impaired exercise capacity.","Aspirin use and all-cause mortality among patients being evaluated for known or suspected coronary artery disease: A propensity analysis."
"133","JAMA.2710","0.002",11559263,2001,"Although aspirin has been shown to reduce cardiovascular morbidity and short-term mortality following acute myocardial infarction, the association between its use and long-term all-cause mortality has not been well defined.To determine whether aspirin is associated with a mortality benefit in stable patients with known or suspected coronary disease and to identify patient characteristics that predict the maximum absolute mortality benefit from aspirin.Prospective, nonrandomized, observational cohort study conducted between 1990 and 1998 at an academic medical institution, with a median follow-up of 3.1 years.Of 6174 consecutive adults undergoing stress echocardiography for evaluation of known or suspected coronary disease, 2310 (37%) were taking aspirin. Patients with significant valvular disease or documented contraindication to aspirin use, including peptic ulcer disease, renal insufficiency, and use of nonsteroidal anti-inflammatory drugs, were excluded.All-cause mortality according to aspirin use.During 3.1 years of follow-up, 276 patients (4.5%) died. In a simple univariable analysis, there was no association between aspirin use and mortality (4.5% vs 4.5%). However, after adjustment for age, sex, standard cardiovascular risk factors, use of other medications, coronary disease history, ejection fraction, exercise capacity, heart rate recovery, and echocardiographic ischemia, aspirin use was associated with reduced mortality (hazard ratio [HR], 0.67; 95% confidence interval [CI], 0.51-0.87; P =.002). In further analysis using matching by propensity score, 1351 patients who were taking aspirin were at lower risk for death than 1351 patients not using aspirin (4% vs 8%, respectively; HR, 0.53; 95% CI, 0.38-0.74; P =.002). After adjusting for the propensity for using aspirin, as well as other possible confounders and interactions, aspirin use remained associated with a lower risk for death (adjusted HR, 0.56; 95% CI, 0.40-0.78; P<.001). The patient characteristics associated with the most aspirin-related reductions in mortality were older age, known coronary artery disease, and impaired exercise capacity.Aspirin use among patients undergoing stress echocardiography was independently associated with reduced long-term all-cause mortality, particularly among older patients, those with known coronary artery disease, and those with impaired exercise capacity.","Aspirin use and all-cause mortality among patients being evaluated for known or suspected coronary artery disease: A propensity analysis."
"134","JAMA.38","0.001",11559288,2001,"The Physician Shortage Area Program (PSAP) of Jefferson Medical College (Philadelphia, Pa) is one of a small number of medical school programs that addresses the shortage of rural primary care physicians. However, little is known regarding why these programs work.To identify factors independently predictive of rural primary care supply and retention and to determine which components of the PSAP lead to its outcomes.Retrospective cohort study.A total of 3414 Jefferson Medical College graduates from the classes of 1978-1993, including 220 PSAP graduates.Rural primary care practice and retention in 1999 as predicted by 19 previously collected variables. Twelve variables were available for all classes; 7 variables were collected only for 1978-1982 graduates.Freshman-year plan for family practice, being in the PSAP, having a National Health Service Corps scholarship, male sex, and taking an elective senior family practice rural preceptorship (the only factor not available at entrance to medical school) were independently predictive of physicians practicing rural primary care. For 1978-1982 graduates, growing up in a rural area was the only additionally collected independent predictor of rural primary care (odds ratio [OR], 4.0; 95% CI, 2.1-7.6; P<.001). Participation in the PSAP was the only independent predictive factor of retention for all classes (OR, 4.7; 95% CI, 2.0-11.2; P<.001). Among PSAP graduates, taking a senior rural preceptorship was independently predictive of rural primary care (OR, 2.5; 95% CI, 1.3-4.7; P =.004). However, non-PSAP graduates with 2 key selection characteristics of PSAP students (having grown up in a rural area and freshman-year plans for family practice) were 78% as likely as PSAP graduates to be rural primary care physicians, and 75% as likely to remain, suggesting that the admissions component of the PSAP is the most important reason for its success. In fact, few graduates without either of these factors were rural primary care physicians (1.8%).Medical educators and policy makers can have the greatest impact on the supply and retention of rural primary care physicians by developing programs to increase the number of medical school matriculants with background and career plans that make them most likely to pursue these career goals. Curricular experiences and other factors can further increase these outcomes, especially by supporting those already likely to become rural primary care physicians.","Critical factors for designing programs to increase the supply and retention of rural primary care physicians."
"135","JAMA.39","0.001",11559288,2001,"The Physician Shortage Area Program (PSAP) of Jefferson Medical College (Philadelphia, Pa) is one of a small number of medical school programs that addresses the shortage of rural primary care physicians. However, little is known regarding why these programs work.To identify factors independently predictive of rural primary care supply and retention and to determine which components of the PSAP lead to its outcomes.Retrospective cohort study.A total of 3414 Jefferson Medical College graduates from the classes of 1978-1993, including 220 PSAP graduates.Rural primary care practice and retention in 1999 as predicted by 19 previously collected variables. Twelve variables were available for all classes; 7 variables were collected only for 1978-1982 graduates.Freshman-year plan for family practice, being in the PSAP, having a National Health Service Corps scholarship, male sex, and taking an elective senior family practice rural preceptorship (the only factor not available at entrance to medical school) were independently predictive of physicians practicing rural primary care. For 1978-1982 graduates, growing up in a rural area was the only additionally collected independent predictor of rural primary care (odds ratio [OR], 4.0; 95% CI, 2.1-7.6; P<.001). Participation in the PSAP was the only independent predictive factor of retention for all classes (OR, 4.7; 95% CI, 2.0-11.2; P<.001). Among PSAP graduates, taking a senior rural preceptorship was independently predictive of rural primary care (OR, 2.5; 95% CI, 1.3-4.7; P =.004). However, non-PSAP graduates with 2 key selection characteristics of PSAP students (having grown up in a rural area and freshman-year plans for family practice) were 78% as likely as PSAP graduates to be rural primary care physicians, and 75% as likely to remain, suggesting that the admissions component of the PSAP is the most important reason for its success. In fact, few graduates without either of these factors were rural primary care physicians (1.8%).Medical educators and policy makers can have the greatest impact on the supply and retention of rural primary care physicians by developing programs to increase the number of medical school matriculants with background and career plans that make them most likely to pursue these career goals. Curricular experiences and other factors can further increase these outcomes, especially by supporting those already likely to become rural primary care physicians.","Critical factors for designing programs to increase the supply and retention of rural primary care physicians."
"136","JAMA.69","0.004",11559288,2001,"The Physician Shortage Area Program (PSAP) of Jefferson Medical College (Philadelphia, Pa) is one of a small number of medical school programs that addresses the shortage of rural primary care physicians. However, little is known regarding why these programs work.To identify factors independently predictive of rural primary care supply and retention and to determine which components of the PSAP lead to its outcomes.Retrospective cohort study.A total of 3414 Jefferson Medical College graduates from the classes of 1978-1993, including 220 PSAP graduates.Rural primary care practice and retention in 1999 as predicted by 19 previously collected variables. Twelve variables were available for all classes; 7 variables were collected only for 1978-1982 graduates.Freshman-year plan for family practice, being in the PSAP, having a National Health Service Corps scholarship, male sex, and taking an elective senior family practice rural preceptorship (the only factor not available at entrance to medical school) were independently predictive of physicians practicing rural primary care. For 1978-1982 graduates, growing up in a rural area was the only additionally collected independent predictor of rural primary care (odds ratio [OR], 4.0; 95% CI, 2.1-7.6; P<.001). Participation in the PSAP was the only independent predictive factor of retention for all classes (OR, 4.7; 95% CI, 2.0-11.2; P<.001). Among PSAP graduates, taking a senior rural preceptorship was independently predictive of rural primary care (OR, 2.5; 95% CI, 1.3-4.7; P =.004). However, non-PSAP graduates with 2 key selection characteristics of PSAP students (having grown up in a rural area and freshman-year plans for family practice) were 78% as likely as PSAP graduates to be rural primary care physicians, and 75% as likely to remain, suggesting that the admissions component of the PSAP is the most important reason for its success. In fact, few graduates without either of these factors were rural primary care physicians (1.8%).Medical educators and policy makers can have the greatest impact on the supply and retention of rural primary care physicians by developing programs to increase the number of medical school matriculants with background and career plans that make them most likely to pursue these career goals. Curricular experiences and other factors can further increase these outcomes, especially by supporting those already likely to become rural primary care physicians.","Critical factors for designing programs to increase the supply and retention of rural primary care physicians."
"137","JAMA.64","NA",11594896,2001,"The prevalence of medical disorders is high among substance abuse patients, yet medical services are seldom provided in coordination with substance abuse treatment.To examine differences in treatment outcomes and costs between integrated and independent models of medical and substance abuse care as well as the effect of integrated care in a subgroup of patients with substance abuse-related medical conditions (SAMCs).Randomized controlled trial conducted between April 1997 and December 1998.Adult men and women (n = 592) who were admitted to a large health maintenance organization chemical dependency program in Sacramento, Calif.Patients were randomly assigned to receive treatment through an integrated model, in which primary health care was included within the addiction treatment program (n = 285), or an independent treatment-as-usual model, in which primary care and substance abuse treatment were provided separately (n = 307). Both programs were group based and lasted 8 weeks, with 10 months of aftercare available.Abstinence outcomes, treatment utilization, and costs 6 months after randomization.Both groups showed improvement on all drug and alcohol measures. Overall, there were no differences in total abstinence rates between the integrated care and independent care groups (68% vs 63%, P =.18). For patients without SAMCs, there were also no differences in abstinence rates (integrated care, 66% vs independent care, 73%; P =.23) and there was a slight but nonsignificant trend of higher costs for the integrated care group ($367.96 vs $324.09, P =.19). However, patients with SAMCs (n = 341) were more likely to be abstinent in the integrated care group than the independent care group (69% vs 55%, P =.006; odds ratio [OR], 1.90; 95% confidence interval [CI], 1.22-2.97). This was true for both those with medical (OR, 3.38; 95% CI, 1.68-6.80) and psychiatric (OR, 2.10; 95% CI, 1.04-4.25) SAMCs. Patients with SAMCs had a slight but nonsignificant trend of higher costs in the integrated care group ($470.81 vs $427.95, P =.14). The incremental cost-effectiveness ratio per additional abstinent patient with an SAMC in the integrated care group was $1581.Individuals with SAMCs benefit from integrated medical and substance abuse treatment, and such an approach can be cost-effective. These findings are relevant given the high prevalence and cost of medical conditions among substance abuse patients, new developments in medications for addiction, and recent legislation on parity of substance abuse with other medical benefits.","Integrating primary medical care with addiction treatment: a randomized controlled trial."
"138","JAMA.65","NA",11594896,2001,"The prevalence of medical disorders is high among substance abuse patients, yet medical services are seldom provided in coordination with substance abuse treatment.To examine differences in treatment outcomes and costs between integrated and independent models of medical and substance abuse care as well as the effect of integrated care in a subgroup of patients with substance abuse-related medical conditions (SAMCs).Randomized controlled trial conducted between April 1997 and December 1998.Adult men and women (n = 592) who were admitted to a large health maintenance organization chemical dependency program in Sacramento, Calif.Patients were randomly assigned to receive treatment through an integrated model, in which primary health care was included within the addiction treatment program (n = 285), or an independent treatment-as-usual model, in which primary care and substance abuse treatment were provided separately (n = 307). Both programs were group based and lasted 8 weeks, with 10 months of aftercare available.Abstinence outcomes, treatment utilization, and costs 6 months after randomization.Both groups showed improvement on all drug and alcohol measures. Overall, there were no differences in total abstinence rates between the integrated care and independent care groups (68% vs 63%, P =.18). For patients without SAMCs, there were also no differences in abstinence rates (integrated care, 66% vs independent care, 73%; P =.23) and there was a slight but nonsignificant trend of higher costs for the integrated care group ($367.96 vs $324.09, P =.19). However, patients with SAMCs (n = 341) were more likely to be abstinent in the integrated care group than the independent care group (69% vs 55%, P =.006; odds ratio [OR], 1.90; 95% confidence interval [CI], 1.22-2.97). This was true for both those with medical (OR, 3.38; 95% CI, 1.68-6.80) and psychiatric (OR, 2.10; 95% CI, 1.04-4.25) SAMCs. Patients with SAMCs had a slight but nonsignificant trend of higher costs in the integrated care group ($470.81 vs $427.95, P =.14). The incremental cost-effectiveness ratio per additional abstinent patient with an SAMC in the integrated care group was $1581.Individuals with SAMCs benefit from integrated medical and substance abuse treatment, and such an approach can be cost-effective. These findings are relevant given the high prevalence and cost of medical conditions among substance abuse patients, new developments in medications for addiction, and recent legislation on parity of substance abuse with other medical benefits.","Integrating primary medical care with addiction treatment: a randomized controlled trial."
"139","JAMA.67","0.006",11594896,2001,"The prevalence of medical disorders is high among substance abuse patients, yet medical services are seldom provided in coordination with substance abuse treatment.To examine differences in treatment outcomes and costs between integrated and independent models of medical and substance abuse care as well as the effect of integrated care in a subgroup of patients with substance abuse-related medical conditions (SAMCs).Randomized controlled trial conducted between April 1997 and December 1998.Adult men and women (n = 592) who were admitted to a large health maintenance organization chemical dependency program in Sacramento, Calif.Patients were randomly assigned to receive treatment through an integrated model, in which primary health care was included within the addiction treatment program (n = 285), or an independent treatment-as-usual model, in which primary care and substance abuse treatment were provided separately (n = 307). Both programs were group based and lasted 8 weeks, with 10 months of aftercare available.Abstinence outcomes, treatment utilization, and costs 6 months after randomization.Both groups showed improvement on all drug and alcohol measures. Overall, there were no differences in total abstinence rates between the integrated care and independent care groups (68% vs 63%, P =.18). For patients without SAMCs, there were also no differences in abstinence rates (integrated care, 66% vs independent care, 73%; P =.23) and there was a slight but nonsignificant trend of higher costs for the integrated care group ($367.96 vs $324.09, P =.19). However, patients with SAMCs (n = 341) were more likely to be abstinent in the integrated care group than the independent care group (69% vs 55%, P =.006; odds ratio [OR], 1.90; 95% confidence interval [CI], 1.22-2.97). This was true for both those with medical (OR, 3.38; 95% CI, 1.68-6.80) and psychiatric (OR, 2.10; 95% CI, 1.04-4.25) SAMCs. Patients with SAMCs had a slight but nonsignificant trend of higher costs in the integrated care group ($470.81 vs $427.95, P =.14). The incremental cost-effectiveness ratio per additional abstinent patient with an SAMC in the integrated care group was $1581.Individuals with SAMCs benefit from integrated medical and substance abuse treatment, and such an approach can be cost-effective. These findings are relevant given the high prevalence and cost of medical conditions among substance abuse patients, new developments in medications for addiction, and recent legislation on parity of substance abuse with other medical benefits.","Integrating primary medical care with addiction treatment: a randomized controlled trial."
"140","JAMA.36","NA",11594898,2001,"Cost-sharing in US prescription drug coverage plans for elderly persons varies widely. Evaluation of prescription drug use among elderly persons by type of health insurance could provide useful information for designing a Medicare drug program.To determine use of effective cardiovascular drugs among elderly persons with coronary heart disease (CHD) by type of health insurance.Cross-sectional evaluation of 1908 community-dwelling adults, aged 66 years or older, with a history of CHD or myocardial infarction from the 1997 Medicare Current Beneficiary Survey, a nationally representative sample of Medicare beneficiaries.Use of 3-hydroxy-3-methylglutaryl coenzyme A reductase inhibitors (statins), beta-blockers, and nitrates, and out-of-pocket expenditures for prescription drugs, stratified by type of health insurance: Medicare without drug coverage (Medicare only or self-purchased supplemental insurance) or with drug coverage (Medicaid, other public program, Medigap, health maintenance organization, or employer-sponsored plan).Statin use ranged from 4.1% in Medicare patients with no drug coverage to 27.4% in patients with employer-sponsored drug coverage (P<.001). Less variation between these 2 types occurred for beta-blockers (20.7% vs 36.1%; P =.003) and nitrates (20.4% vs 38.0%; P =.005). In multivariate analyses, statin use remained significantly lower for patients with Medicare only (odds ratio [OR], 0.16; 95% confidence interval [CI], 0.05-0.49) and beta-blocker use was lower for Medicaid patients (OR, 0.55; 95% CI, 0.34-0.88) vs those with employer-sponsored coverage. Nitrate use occurred less frequently in persons lacking drug coverage (patients with Medicare only, P =.049; patients with supplemental insurance without drug coverage, P =.03). Patients with Medicare only spent a much larger fraction of income on prescription drugs compared with those with employer-sponsored drug coverage (7.9% vs 1.7%; adjusted P<.001).Elderly Medicare beneficiaries with CHD who lack drug coverage have disproportionately large drug expenditures and lower use rates of statins, a class of relatively expensive drugs that improve survival.","Supplemental insurance and use of effective cardiovascular drugs among elderly medicare beneficiaries with coronary heart disease."
"141","JAMA.37","NA",11594898,2001,"Cost-sharing in US prescription drug coverage plans for elderly persons varies widely. Evaluation of prescription drug use among elderly persons by type of health insurance could provide useful information for designing a Medicare drug program.To determine use of effective cardiovascular drugs among elderly persons with coronary heart disease (CHD) by type of health insurance.Cross-sectional evaluation of 1908 community-dwelling adults, aged 66 years or older, with a history of CHD or myocardial infarction from the 1997 Medicare Current Beneficiary Survey, a nationally representative sample of Medicare beneficiaries.Use of 3-hydroxy-3-methylglutaryl coenzyme A reductase inhibitors (statins), beta-blockers, and nitrates, and out-of-pocket expenditures for prescription drugs, stratified by type of health insurance: Medicare without drug coverage (Medicare only or self-purchased supplemental insurance) or with drug coverage (Medicaid, other public program, Medigap, health maintenance organization, or employer-sponsored plan).Statin use ranged from 4.1% in Medicare patients with no drug coverage to 27.4% in patients with employer-sponsored drug coverage (P<.001). Less variation between these 2 types occurred for beta-blockers (20.7% vs 36.1%; P =.003) and nitrates (20.4% vs 38.0%; P =.005). In multivariate analyses, statin use remained significantly lower for patients with Medicare only (odds ratio [OR], 0.16; 95% confidence interval [CI], 0.05-0.49) and beta-blocker use was lower for Medicaid patients (OR, 0.55; 95% CI, 0.34-0.88) vs those with employer-sponsored coverage. Nitrate use occurred less frequently in persons lacking drug coverage (patients with Medicare only, P =.049; patients with supplemental insurance without drug coverage, P =.03). Patients with Medicare only spent a much larger fraction of income on prescription drugs compared with those with employer-sponsored drug coverage (7.9% vs 1.7%; adjusted P<.001).Elderly Medicare beneficiaries with CHD who lack drug coverage have disproportionately large drug expenditures and lower use rates of statins, a class of relatively expensive drugs that improve survival.","Supplemental insurance and use of effective cardiovascular drugs among elderly medicare beneficiaries with coronary heart disease."
"142","JAMA.35","NA",11667935,2001,"Since publication in 1994 of guidelines for management of peptic ulcer disease (PUD), trends in physician practice and outcomes related to guideline application have not been evaluated.To describe changes in process of care that occurred in a quality improvement program for patients hospitalized with PUD and to evaluate associations between in-hospital treatment of PUD and 1-year rehospitalization for PUD and mortality in a subset of these patients.Cohort study of 4292 sequential Medicare beneficiaries hospitalized at acute care hospitals with a principal diagnosis of PUD in 5 states (Colorado, Georgia, Connecticut, Oklahoma, and Virginia) in 1995 (baseline) and 1997 (remeasurement); outcomes were evaluated for 752 patients in Colorado.Changes in rates of screening for Helicobacter pylori infection, treatment for H pylori infection, screening for nonsteroidal anti-inflammatory drug (NSAID) use, counseling about NSAID use; outcomes included rehospitalization for PUD and all-cause mortality within 1 year of discharge in Colorado.Screening for H pylori infection increased significantly (12%-19% increase; P<.001) in each of the 5 states. Treatment of H pylori infection increased in each state and was significantly increased for the entire group of hospitalizations examined (8% increase overall; P =.001). Despite increased screening, detection of H pylori infection was less frequent than expected in every state, (13%-24%) and did not increase in any state. Screening for and counseling about NSAIDs did not significantly increase overall or in any state. In the Colorado cohort, the proportion of patients rehospitalized was unchanged in 1995 (8.9%) and 1997 (6.8%), and 124 patients (16%) in the combined 1995 and 1997 cohorts died within 1 year. Treatment for H pylori was not associated with a reduction in rehospitalization within 1 year (adjusted odds ratio [OR], 1.24; 95% confidence interval [CI], 0.65-2.36) or with a reduction in mortality (adjusted OR, 1.08; 95% CI, 0.68-1.71). Counseling about NSAID use was associated with a decrease in risk of 1-year rehospitalization for PUD (adjusted OR, 0.47; 95% CI, 0.22-0.99) and risk of all-cause mortality (adjusted OR, 0.44; 95% CI, 0.26-0.75).This quality improvement program for elderly patients with PUD resulted in increased screening for H pylori and increased treatment of H pylori infection but no change in counseling about NSAID use. However, with the low prevalence of H pylori detected, treatment of H pylori infection was not associated with a reduction in repeat hospitalization for PUD or subsequent mortality, whereas counseling about the risks of using NSAIDs was associated with a reduction in the risk of both outcomes.","Process of care and outcomes for elderly patients hospitalized with peptic ulcer disease: results from a quality improvement project."
"143","JAMA.36","NA",11667935,2001,"Since publication in 1994 of guidelines for management of peptic ulcer disease (PUD), trends in physician practice and outcomes related to guideline application have not been evaluated.To describe changes in process of care that occurred in a quality improvement program for patients hospitalized with PUD and to evaluate associations between in-hospital treatment of PUD and 1-year rehospitalization for PUD and mortality in a subset of these patients.Cohort study of 4292 sequential Medicare beneficiaries hospitalized at acute care hospitals with a principal diagnosis of PUD in 5 states (Colorado, Georgia, Connecticut, Oklahoma, and Virginia) in 1995 (baseline) and 1997 (remeasurement); outcomes were evaluated for 752 patients in Colorado.Changes in rates of screening for Helicobacter pylori infection, treatment for H pylori infection, screening for nonsteroidal anti-inflammatory drug (NSAID) use, counseling about NSAID use; outcomes included rehospitalization for PUD and all-cause mortality within 1 year of discharge in Colorado.Screening for H pylori infection increased significantly (12%-19% increase; P<.001) in each of the 5 states. Treatment of H pylori infection increased in each state and was significantly increased for the entire group of hospitalizations examined (8% increase overall; P =.001). Despite increased screening, detection of H pylori infection was less frequent than expected in every state, (13%-24%) and did not increase in any state. Screening for and counseling about NSAIDs did not significantly increase overall or in any state. In the Colorado cohort, the proportion of patients rehospitalized was unchanged in 1995 (8.9%) and 1997 (6.8%), and 124 patients (16%) in the combined 1995 and 1997 cohorts died within 1 year. Treatment for H pylori was not associated with a reduction in rehospitalization within 1 year (adjusted odds ratio [OR], 1.24; 95% confidence interval [CI], 0.65-2.36) or with a reduction in mortality (adjusted OR, 1.08; 95% CI, 0.68-1.71). Counseling about NSAID use was associated with a decrease in risk of 1-year rehospitalization for PUD (adjusted OR, 0.47; 95% CI, 0.22-0.99) and risk of all-cause mortality (adjusted OR, 0.44; 95% CI, 0.26-0.75).This quality improvement program for elderly patients with PUD resulted in increased screening for H pylori and increased treatment of H pylori infection but no change in counseling about NSAID use. However, with the low prevalence of H pylori detected, treatment of H pylori infection was not associated with a reduction in repeat hospitalization for PUD or subsequent mortality, whereas counseling about the risks of using NSAIDs was associated with a reduction in the risk of both outcomes.","Process of care and outcomes for elderly patients hospitalized with peptic ulcer disease: results from a quality improvement project."
"144","JAMA.36","NA",11667935,2001,"Since publication in 1994 of guidelines for management of peptic ulcer disease (PUD), trends in physician practice and outcomes related to guideline application have not been evaluated.To describe changes in process of care that occurred in a quality improvement program for patients hospitalized with PUD and to evaluate associations between in-hospital treatment of PUD and 1-year rehospitalization for PUD and mortality in a subset of these patients.Cohort study of 4292 sequential Medicare beneficiaries hospitalized at acute care hospitals with a principal diagnosis of PUD in 5 states (Colorado, Georgia, Connecticut, Oklahoma, and Virginia) in 1995 (baseline) and 1997 (remeasurement); outcomes were evaluated for 752 patients in Colorado.Changes in rates of screening for Helicobacter pylori infection, treatment for H pylori infection, screening for nonsteroidal anti-inflammatory drug (NSAID) use, counseling about NSAID use; outcomes included rehospitalization for PUD and all-cause mortality within 1 year of discharge in Colorado.Screening for H pylori infection increased significantly (12%-19% increase; P<.001) in each of the 5 states. Treatment of H pylori infection increased in each state and was significantly increased for the entire group of hospitalizations examined (8% increase overall; P =.001). Despite increased screening, detection of H pylori infection was less frequent than expected in every state, (13%-24%) and did not increase in any state. Screening for and counseling about NSAIDs did not significantly increase overall or in any state. In the Colorado cohort, the proportion of patients rehospitalized was unchanged in 1995 (8.9%) and 1997 (6.8%), and 124 patients (16%) in the combined 1995 and 1997 cohorts died within 1 year. Treatment for H pylori was not associated with a reduction in rehospitalization within 1 year (adjusted odds ratio [OR], 1.24; 95% confidence interval [CI], 0.65-2.36) or with a reduction in mortality (adjusted OR, 1.08; 95% CI, 0.68-1.71). Counseling about NSAID use was associated with a decrease in risk of 1-year rehospitalization for PUD (adjusted OR, 0.47; 95% CI, 0.22-0.99) and risk of all-cause mortality (adjusted OR, 0.44; 95% CI, 0.26-0.75).This quality improvement program for elderly patients with PUD resulted in increased screening for H pylori and increased treatment of H pylori infection but no change in counseling about NSAID use. However, with the low prevalence of H pylori detected, treatment of H pylori infection was not associated with a reduction in repeat hospitalization for PUD or subsequent mortality, whereas counseling about the risks of using NSAIDs was associated with a reduction in the risk of both outcomes.","Process of care and outcomes for elderly patients hospitalized with peptic ulcer disease: results from a quality improvement project."
"145","JAMA.59","NA",11667935,2001,"Since publication in 1994 of guidelines for management of peptic ulcer disease (PUD), trends in physician practice and outcomes related to guideline application have not been evaluated.To describe changes in process of care that occurred in a quality improvement program for patients hospitalized with PUD and to evaluate associations between in-hospital treatment of PUD and 1-year rehospitalization for PUD and mortality in a subset of these patients.Cohort study of 4292 sequential Medicare beneficiaries hospitalized at acute care hospitals with a principal diagnosis of PUD in 5 states (Colorado, Georgia, Connecticut, Oklahoma, and Virginia) in 1995 (baseline) and 1997 (remeasurement); outcomes were evaluated for 752 patients in Colorado.Changes in rates of screening for Helicobacter pylori infection, treatment for H pylori infection, screening for nonsteroidal anti-inflammatory drug (NSAID) use, counseling about NSAID use; outcomes included rehospitalization for PUD and all-cause mortality within 1 year of discharge in Colorado.Screening for H pylori infection increased significantly (12%-19% increase; P<.001) in each of the 5 states. Treatment of H pylori infection increased in each state and was significantly increased for the entire group of hospitalizations examined (8% increase overall; P =.001). Despite increased screening, detection of H pylori infection was less frequent than expected in every state, (13%-24%) and did not increase in any state. Screening for and counseling about NSAIDs did not significantly increase overall or in any state. In the Colorado cohort, the proportion of patients rehospitalized was unchanged in 1995 (8.9%) and 1997 (6.8%), and 124 patients (16%) in the combined 1995 and 1997 cohorts died within 1 year. Treatment for H pylori was not associated with a reduction in rehospitalization within 1 year (adjusted odds ratio [OR], 1.24; 95% confidence interval [CI], 0.65-2.36) or with a reduction in mortality (adjusted OR, 1.08; 95% CI, 0.68-1.71). Counseling about NSAID use was associated with a decrease in risk of 1-year rehospitalization for PUD (adjusted OR, 0.47; 95% CI, 0.22-0.99) and risk of all-cause mortality (adjusted OR, 0.44; 95% CI, 0.26-0.75).This quality improvement program for elderly patients with PUD resulted in increased screening for H pylori and increased treatment of H pylori infection but no change in counseling about NSAID use. However, with the low prevalence of H pylori detected, treatment of H pylori infection was not associated with a reduction in repeat hospitalization for PUD or subsequent mortality, whereas counseling about the risks of using NSAIDs was associated with a reduction in the risk of both outcomes.","Process of care and outcomes for elderly patients hospitalized with peptic ulcer disease: results from a quality improvement project."
"146","JAMA.34","NA",11667936,2001,"The long-term effect of policies restricting contact between residents and pharmaceutical company representatives (PCRs) during internal medicine training is unknown. The McMaster University Department of Medicine in Hamilton, Ontario, implemented a policy restricting PCR contact with trainees in 1992, whereas the Department of Medicine at the University of Toronto, Toronto, Ontario, has no such policy.To determine if the presence of a restrictive policy and the frequency of contact with PCRs during internal medicine training predict attitudes and behavior several years after completion of training.Retrospective analysis of the attitudes and behavior of 3 cohorts of physicians: University of Toronto trainees, prepolicy McMaster trainees, and postpolicy McMaster trainees. Surveys were mailed to 242 former University of Toronto and 57 former McMaster trainees who completed their internal medicine training between 1990 and 1996, with response rates of 163 (67%) and 42 (74%), respectively.Physician attitude, assessed by a question about the perceived helpfulness of PCR information, and behavior, assessed by whether physicians met with PCRs in the office and the frequency of contacts with PCRs (current contact score, consisting of conversations with PCRs, PCR-sponsored events attended, gifts, honoraria, and consulting fees received).In both the unadjusted and multiple regression analyses, postpolicy McMaster trainees were less likely to find information from PCRs beneficial in guiding their practice compared with Toronto and prepolicy McMaster trainees, with unadjusted odds ratios (ORs) of 0.44 (95% confidence interval [CI], 0.20-0.94) and 0.39 (95% CI, 0.13-1.22), respectively. All 3 groups were equally likely to report that they met with PCRs in their office in the past year (88%). Postpolicy McMaster trainees had a lower current contact score compared with Toronto (9.3 vs 10.9; P =.04) and prepolicy McMaster trainees (9.3 vs 10.8; P =.18). In multiple regression models, greater frequency of contact with PCRs during training was a predictor of increased perceived benefit of PCR information (OR, 1.29; 95% CI, 1.13-1.47) and was positively correlated with the current contact score (partial r = 0.49; P<.001). Number of PCR-sponsored rounds attended during training was not a consistent predictor of attitudes or behavior.Policies restricting PCR access to internal medicine trainees and the amount of contact during residency appear to affect future attitudes and behavior of physicians.","Effect of restricting contact between pharmaceutical company representatives and internal medicine residents on posttraining attitudes and behavior."
"147","JAMA.57","NA",11667936,2001,"The long-term effect of policies restricting contact between residents and pharmaceutical company representatives (PCRs) during internal medicine training is unknown. The McMaster University Department of Medicine in Hamilton, Ontario, implemented a policy restricting PCR contact with trainees in 1992, whereas the Department of Medicine at the University of Toronto, Toronto, Ontario, has no such policy.To determine if the presence of a restrictive policy and the frequency of contact with PCRs during internal medicine training predict attitudes and behavior several years after completion of training.Retrospective analysis of the attitudes and behavior of 3 cohorts of physicians: University of Toronto trainees, prepolicy McMaster trainees, and postpolicy McMaster trainees. Surveys were mailed to 242 former University of Toronto and 57 former McMaster trainees who completed their internal medicine training between 1990 and 1996, with response rates of 163 (67%) and 42 (74%), respectively.Physician attitude, assessed by a question about the perceived helpfulness of PCR information, and behavior, assessed by whether physicians met with PCRs in the office and the frequency of contacts with PCRs (current contact score, consisting of conversations with PCRs, PCR-sponsored events attended, gifts, honoraria, and consulting fees received).In both the unadjusted and multiple regression analyses, postpolicy McMaster trainees were less likely to find information from PCRs beneficial in guiding their practice compared with Toronto and prepolicy McMaster trainees, with unadjusted odds ratios (ORs) of 0.44 (95% confidence interval [CI], 0.20-0.94) and 0.39 (95% CI, 0.13-1.22), respectively. All 3 groups were equally likely to report that they met with PCRs in their office in the past year (88%). Postpolicy McMaster trainees had a lower current contact score compared with Toronto (9.3 vs 10.9; P =.04) and prepolicy McMaster trainees (9.3 vs 10.8; P =.18). In multiple regression models, greater frequency of contact with PCRs during training was a predictor of increased perceived benefit of PCR information (OR, 1.29; 95% CI, 1.13-1.47) and was positively correlated with the current contact score (partial r = 0.49; P<.001). Number of PCR-sponsored rounds attended during training was not a consistent predictor of attitudes or behavior.Policies restricting PCR access to internal medicine trainees and the amount of contact during residency appear to affect future attitudes and behavior of physicians.","Effect of restricting contact between pharmaceutical company representatives and internal medicine residents on posttraining attitudes and behavior."
"148","JAMA.58","NA",11667936,2001,"The long-term effect of policies restricting contact between residents and pharmaceutical company representatives (PCRs) during internal medicine training is unknown. The McMaster University Department of Medicine in Hamilton, Ontario, implemented a policy restricting PCR contact with trainees in 1992, whereas the Department of Medicine at the University of Toronto, Toronto, Ontario, has no such policy.To determine if the presence of a restrictive policy and the frequency of contact with PCRs during internal medicine training predict attitudes and behavior several years after completion of training.Retrospective analysis of the attitudes and behavior of 3 cohorts of physicians: University of Toronto trainees, prepolicy McMaster trainees, and postpolicy McMaster trainees. Surveys were mailed to 242 former University of Toronto and 57 former McMaster trainees who completed their internal medicine training between 1990 and 1996, with response rates of 163 (67%) and 42 (74%), respectively.Physician attitude, assessed by a question about the perceived helpfulness of PCR information, and behavior, assessed by whether physicians met with PCRs in the office and the frequency of contacts with PCRs (current contact score, consisting of conversations with PCRs, PCR-sponsored events attended, gifts, honoraria, and consulting fees received).In both the unadjusted and multiple regression analyses, postpolicy McMaster trainees were less likely to find information from PCRs beneficial in guiding their practice compared with Toronto and prepolicy McMaster trainees, with unadjusted odds ratios (ORs) of 0.44 (95% confidence interval [CI], 0.20-0.94) and 0.39 (95% CI, 0.13-1.22), respectively. All 3 groups were equally likely to report that they met with PCRs in their office in the past year (88%). Postpolicy McMaster trainees had a lower current contact score compared with Toronto (9.3 vs 10.9; P =.04) and prepolicy McMaster trainees (9.3 vs 10.8; P =.18). In multiple regression models, greater frequency of contact with PCRs during training was a predictor of increased perceived benefit of PCR information (OR, 1.29; 95% CI, 1.13-1.47) and was positively correlated with the current contact score (partial r = 0.49; P<.001). Number of PCR-sponsored rounds attended during training was not a consistent predictor of attitudes or behavior.Policies restricting PCR access to internal medicine trainees and the amount of contact during residency appear to affect future attitudes and behavior of physicians.","Effect of restricting contact between pharmaceutical company representatives and internal medicine residents on posttraining attitudes and behavior."
"149","American Journal of Epidemiology.210","0.031",11682370,2001,"The authors evaluated whether early enrollment affects the significance of the results and the time to completion and publication of randomized controlled trials. Seventy-seven efficacy randomized controlled trials (total enrollment, 28,992 patients) initiated by the Acquired Immunodeficiency Syndrome Clinical Trials Group between 1986 and 1996 were evaluated. After adjustment for target sample size, for each 10-fold increase in the first-month accrual, the odds of a trial reaching statistically significant results increased 2.8-fold (p = 0.040). The relative enrollment during the first month over target sample size (hazard ratio (HR) = 1.40 per 10 percent increase, p = 0.004) and masking (HR = 1.78 for double-blind vs. single or unblinded studies, p = 0.031) were the major predictors of faster completion. Rapid early accrual (HR = 1.09 per 10 additional patients accrued the first month, p = 0.011) and statistical significance in favor of an experimental arm (HR = 2.47, p = 0.004) independently predicted faster publication. Early enrollment is a strong predictor of whether a study will reach formal statistical significance, and it can offer predictive information on the time needed to complete the study and publish its findings. Ongoing unpublished studies and their enrollment rates may need to be considered when interpreting the accumulated evidence.","Effect of early patient enrollment on the time to completion and publication of randomized controlled trials."
"150","American Journal of Epidemiology.310","0.011",11682370,2001,"The authors evaluated whether early enrollment affects the significance of the results and the time to completion and publication of randomized controlled trials. Seventy-seven efficacy randomized controlled trials (total enrollment, 28,992 patients) initiated by the Acquired Immunodeficiency Syndrome Clinical Trials Group between 1986 and 1996 were evaluated. After adjustment for target sample size, for each 10-fold increase in the first-month accrual, the odds of a trial reaching statistically significant results increased 2.8-fold (p = 0.040). The relative enrollment during the first month over target sample size (hazard ratio (HR) = 1.40 per 10 percent increase, p = 0.004) and masking (HR = 1.78 for double-blind vs. single or unblinded studies, p = 0.031) were the major predictors of faster completion. Rapid early accrual (HR = 1.09 per 10 additional patients accrued the first month, p = 0.011) and statistical significance in favor of an experimental arm (HR = 2.47, p = 0.004) independently predicted faster publication. Early enrollment is a strong predictor of whether a study will reach formal statistical significance, and it can offer predictive information on the time needed to complete the study and publish its findings. Ongoing unpublished studies and their enrollment rates may need to be considered when interpreting the accumulated evidence.","Effect of early patient enrollment on the time to completion and publication of randomized controlled trials."
"151","American Journal of Epidemiology.410","0.004",11682370,2001,"The authors evaluated whether early enrollment affects the significance of the results and the time to completion and publication of randomized controlled trials. Seventy-seven efficacy randomized controlled trials (total enrollment, 28,992 patients) initiated by the Acquired Immunodeficiency Syndrome Clinical Trials Group between 1986 and 1996 were evaluated. After adjustment for target sample size, for each 10-fold increase in the first-month accrual, the odds of a trial reaching statistically significant results increased 2.8-fold (p = 0.040). The relative enrollment during the first month over target sample size (hazard ratio (HR) = 1.40 per 10 percent increase, p = 0.004) and masking (HR = 1.78 for double-blind vs. single or unblinded studies, p = 0.031) were the major predictors of faster completion. Rapid early accrual (HR = 1.09 per 10 additional patients accrued the first month, p = 0.011) and statistical significance in favor of an experimental arm (HR = 2.47, p = 0.004) independently predicted faster publication. Early enrollment is a strong predictor of whether a study will reach formal statistical significance, and it can offer predictive information on the time needed to complete the study and publish its findings. Ongoing unpublished studies and their enrollment rates may need to be considered when interpreting the accumulated evidence.","Effect of early patient enrollment on the time to completion and publication of randomized controlled trials."
"152","JAMA.32","NA",11694155,2001,"Myeloperoxidase (MPO), a leukocyte enzyme that promotes oxidation of lipoproteins in atheroma, has been proposed as a possible mediator of atherosclerosis.To determine the association between MPO levels and prevalence of coronary artery disease (CAD).Case-control study conducted from July to September 2000 in a US tertiary care referral center, including 158 patients with established CAD (cases) and 175 patients without angiographically significant CAD (controls).Association of MPO levels per milligram of neutrophil protein (leukocyte-MPO) and MPO levels per milliliter of blood (blood-MPO) with CAD risk.Leukocyte- and blood-MPO levels were both significantly greater in patients with CAD than in controls (P<.001). In multivariable models adjusting for traditional cardiovascular risk factors, Framingham risk score, and white blood cell counts, MPO levels were significantly associated with presence of CAD, with an OR of 11.9 (95% CI, 5.5-25.5) for the highest vs lowest quartiles of leukocyte-MPO and an OR of 20.4 (95% CI, 8.9-47.2) for the highest vs lowest quartiles of blood-MPO.Elevated levels of leukocyte- and blood-MPO are associated with the presence of CAD. These findings support a potential role for MPO as an inflammatory marker in CAD and may have implications for atherosclerosis diagnosis and risk assessment.","Association between myeloperoxidase levels and risk of coronary artery disease."
"153","JAMA.33","NA",11694155,2001,"Myeloperoxidase (MPO), a leukocyte enzyme that promotes oxidation of lipoproteins in atheroma, has been proposed as a possible mediator of atherosclerosis.To determine the association between MPO levels and prevalence of coronary artery disease (CAD).Case-control study conducted from July to September 2000 in a US tertiary care referral center, including 158 patients with established CAD (cases) and 175 patients without angiographically significant CAD (controls).Association of MPO levels per milligram of neutrophil protein (leukocyte-MPO) and MPO levels per milliliter of blood (blood-MPO) with CAD risk.Leukocyte- and blood-MPO levels were both significantly greater in patients with CAD than in controls (P<.001). In multivariable models adjusting for traditional cardiovascular risk factors, Framingham risk score, and white blood cell counts, MPO levels were significantly associated with presence of CAD, with an OR of 11.9 (95% CI, 5.5-25.5) for the highest vs lowest quartiles of leukocyte-MPO and an OR of 20.4 (95% CI, 8.9-47.2) for the highest vs lowest quartiles of blood-MPO.Elevated levels of leukocyte- and blood-MPO are associated with the presence of CAD. These findings support a potential role for MPO as an inflammatory marker in CAD and may have implications for atherosclerosis diagnosis and risk assessment.","Association between myeloperoxidase levels and risk of coronary artery disease."
"154","JAMA.30","NA",11712935,2001,"Cardiac troponins I (cTnI) and T (cTnT) are useful for assessing prognosis in patients with unstable angina and non-ST-segment elevation myocardial infarction (UA/NSTEMI). However, the use of cardiac troponins for predicting benefit of an invasive vs conservative strategy in this patient population is not clear.To prospectively test whether an early invasive strategy provides greater benefit than a conservative strategy in acute coronary syndrome patients with elevated baseline troponin levels.Prospective, randomized trial conducted from December 1997 to June 2000.One hundred sixty-nine community and tertiary care hospitals in 9 countries.A total of 2220 patients with acute coronary syndrome were enrolled. Baseline troponin level data were available for analysis in 1821, and 1780 completed the 6-month follow-up.Patients were randomly assigned to receive (1) an early invasive strategy of coronary angiography between 4 and 48 hours after randomization and revascularization when feasible based on coronary anatomy (n = 1114) or (2) a conservative strategy of medical treatment and, if stable, predischarge exercise tolerance testing (n = 1106). Conservative strategy patients underwent coronary angiography and revascularization only if they manifested recurrent ischemia at rest or on provocative testing.Composite end point of death, MI, or rehospitalization for acute coronary syndrome at 6 months.Patients with a cTnI level of 0.1 ng/mL or more (n = 1087) experienced a significant reduction in the primary end point with the invasive vs conservative strategy (15.3% vs 25.0%; odds ratio [OR], 0.54; 95% confidence interval [CI], 0.40-0.73). Patients with cTnI levels of less than 0.1 ng/mL had no detectable benefit from early invasive management (16.0% vs 12.4%; OR, 1.4; 95% CI, 0.89-2.05; P<.001 for interaction). The benefit of invasive vs conservative management through 30 days was evident even among patients with low-level (0.1-0.4 ng/mL) cTnI elevation (4.4% vs 16.5%; OR, 0.24; 95% CI, 0.08-0.69). Directionally similar results were observed with cTnT.In patients with clinically documented acute coronary syndrome who are treated with glycoprotein IIb/IIIa inhibitors, even small elevations in cTnI and cTnT identify high-risk patients who derive a large clinical benefit from an early invasive strategy.","Ability of minor elevations of troponins I and T to predict benefit from an early invasive strategy in patients with unstable angina and non-ST elevation myocardial infarction: results from a randomized trial."
"155","JAMA.31","NA",11712935,2001,"Cardiac troponins I (cTnI) and T (cTnT) are useful for assessing prognosis in patients with unstable angina and non-ST-segment elevation myocardial infarction (UA/NSTEMI). However, the use of cardiac troponins for predicting benefit of an invasive vs conservative strategy in this patient population is not clear.To prospectively test whether an early invasive strategy provides greater benefit than a conservative strategy in acute coronary syndrome patients with elevated baseline troponin levels.Prospective, randomized trial conducted from December 1997 to June 2000.One hundred sixty-nine community and tertiary care hospitals in 9 countries.A total of 2220 patients with acute coronary syndrome were enrolled. Baseline troponin level data were available for analysis in 1821, and 1780 completed the 6-month follow-up.Patients were randomly assigned to receive (1) an early invasive strategy of coronary angiography between 4 and 48 hours after randomization and revascularization when feasible based on coronary anatomy (n = 1114) or (2) a conservative strategy of medical treatment and, if stable, predischarge exercise tolerance testing (n = 1106). Conservative strategy patients underwent coronary angiography and revascularization only if they manifested recurrent ischemia at rest or on provocative testing.Composite end point of death, MI, or rehospitalization for acute coronary syndrome at 6 months.Patients with a cTnI level of 0.1 ng/mL or more (n = 1087) experienced a significant reduction in the primary end point with the invasive vs conservative strategy (15.3% vs 25.0%; odds ratio [OR], 0.54; 95% confidence interval [CI], 0.40-0.73). Patients with cTnI levels of less than 0.1 ng/mL had no detectable benefit from early invasive management (16.0% vs 12.4%; OR, 1.4; 95% CI, 0.89-2.05; P<.001 for interaction). The benefit of invasive vs conservative management through 30 days was evident even among patients with low-level (0.1-0.4 ng/mL) cTnI elevation (4.4% vs 16.5%; OR, 0.24; 95% CI, 0.08-0.69). Directionally similar results were observed with cTnT.In patients with clinically documented acute coronary syndrome who are treated with glycoprotein IIb/IIIa inhibitors, even small elevations in cTnI and cTnT identify high-risk patients who derive a large clinical benefit from an early invasive strategy.","Ability of minor elevations of troponins I and T to predict benefit from an early invasive strategy in patients with unstable angina and non-ST elevation myocardial infarction: results from a randomized trial."
"156","JAMA.32","NA",11712935,2001,"Cardiac troponins I (cTnI) and T (cTnT) are useful for assessing prognosis in patients with unstable angina and non-ST-segment elevation myocardial infarction (UA/NSTEMI). However, the use of cardiac troponins for predicting benefit of an invasive vs conservative strategy in this patient population is not clear.To prospectively test whether an early invasive strategy provides greater benefit than a conservative strategy in acute coronary syndrome patients with elevated baseline troponin levels.Prospective, randomized trial conducted from December 1997 to June 2000.One hundred sixty-nine community and tertiary care hospitals in 9 countries.A total of 2220 patients with acute coronary syndrome were enrolled. Baseline troponin level data were available for analysis in 1821, and 1780 completed the 6-month follow-up.Patients were randomly assigned to receive (1) an early invasive strategy of coronary angiography between 4 and 48 hours after randomization and revascularization when feasible based on coronary anatomy (n = 1114) or (2) a conservative strategy of medical treatment and, if stable, predischarge exercise tolerance testing (n = 1106). Conservative strategy patients underwent coronary angiography and revascularization only if they manifested recurrent ischemia at rest or on provocative testing.Composite end point of death, MI, or rehospitalization for acute coronary syndrome at 6 months.Patients with a cTnI level of 0.1 ng/mL or more (n = 1087) experienced a significant reduction in the primary end point with the invasive vs conservative strategy (15.3% vs 25.0%; odds ratio [OR], 0.54; 95% confidence interval [CI], 0.40-0.73). Patients with cTnI levels of less than 0.1 ng/mL had no detectable benefit from early invasive management (16.0% vs 12.4%; OR, 1.4; 95% CI, 0.89-2.05; P<.001 for interaction). The benefit of invasive vs conservative management through 30 days was evident even among patients with low-level (0.1-0.4 ng/mL) cTnI elevation (4.4% vs 16.5%; OR, 0.24; 95% CI, 0.08-0.69). Directionally similar results were observed with cTnT.In patients with clinically documented acute coronary syndrome who are treated with glycoprotein IIb/IIIa inhibitors, even small elevations in cTnI and cTnT identify high-risk patients who derive a large clinical benefit from an early invasive strategy.","Ability of minor elevations of troponins I and T to predict benefit from an early invasive strategy in patients with unstable angina and non-ST elevation myocardial infarction: results from a randomized trial."
"157","JAMA.55","NA",11730445,2001,"Despite the public alarm following a series of high-profile school shootings that occurred in the United States during the late 1990s, little is known about the actual incidence and characteristics of school-associated violent deaths.To describe recent trends and features of school-associated violent deaths in the United States.Population-based surveillance study of data collected from media databases, state and local agencies, and police and school officials for July 1, 1994, through June 30, 1999. A case was defined as a homicide, suicide, legal intervention, or unintentional firearm-related death of a student or nonstudent in which the fatal injury occurred (1) on the campus of a public or private elementary or secondary school, (2) while the victim was on the way to or from such a school, or (3) while the victim was attending or traveling to or from an official school-sponsored event.National estimates of risk of school-associated violent death; national trends in school-associated violent deaths; common features of these events; and potential risk factors for perpetration and victimization.Between 1994 and 1999, 220 events resulting in 253 deaths were identified; 202 events involved 1 death and 18 involved multiple deaths (median, 2 deaths per multiple-victim event). Of the 220 events, 172 were homicides, 30 were suicides, 11 were homicide-suicides, 5 were legal intervention deaths, and 2 were unintentional firearm-related deaths. Students accounted for 172 (68.0%) of these deaths, resulting in an estimated average annual incidence of 0.068 per 100 000 students. Between 1992 and 1999, the rate of single-victim student homicides decreased significantly (P =.03); however, homicide rates for students killed in multiple-victim events increased (P =.047). Most events occurred around the start of the school day, the lunch period, or the end of the school day. For 120 (54.5%) of the incidents, respondents reported that a note, threat, or other action potentially indicating risk for violence occurred prior to the event. Homicide offenders were more likely than homicide victims to have expressed some form of suicidal behavior prior to the event (odds ratio [OR], 6.96; 95% confidence interval [CI], 1.96-24.65) and been bullied by their peers (OR, 2.57; 95% CI, 1.12-5.92).Although school-associated violent deaths remain rare events, they have occurred often enough to allow for the detection of patterns and the identification of potential risk factors. This information may help schools respond to this problem.","School-associated violent deaths in the United States, 1994-1999."
"158","JAMA.56","NA",11730445,2001,"Despite the public alarm following a series of high-profile school shootings that occurred in the United States during the late 1990s, little is known about the actual incidence and characteristics of school-associated violent deaths.To describe recent trends and features of school-associated violent deaths in the United States.Population-based surveillance study of data collected from media databases, state and local agencies, and police and school officials for July 1, 1994, through June 30, 1999. A case was defined as a homicide, suicide, legal intervention, or unintentional firearm-related death of a student or nonstudent in which the fatal injury occurred (1) on the campus of a public or private elementary or secondary school, (2) while the victim was on the way to or from such a school, or (3) while the victim was attending or traveling to or from an official school-sponsored event.National estimates of risk of school-associated violent death; national trends in school-associated violent deaths; common features of these events; and potential risk factors for perpetration and victimization.Between 1994 and 1999, 220 events resulting in 253 deaths were identified; 202 events involved 1 death and 18 involved multiple deaths (median, 2 deaths per multiple-victim event). Of the 220 events, 172 were homicides, 30 were suicides, 11 were homicide-suicides, 5 were legal intervention deaths, and 2 were unintentional firearm-related deaths. Students accounted for 172 (68.0%) of these deaths, resulting in an estimated average annual incidence of 0.068 per 100 000 students. Between 1992 and 1999, the rate of single-victim student homicides decreased significantly (P =.03); however, homicide rates for students killed in multiple-victim events increased (P =.047). Most events occurred around the start of the school day, the lunch period, or the end of the school day. For 120 (54.5%) of the incidents, respondents reported that a note, threat, or other action potentially indicating risk for violence occurred prior to the event. Homicide offenders were more likely than homicide victims to have expressed some form of suicidal behavior prior to the event (odds ratio [OR], 6.96; 95% confidence interval [CI], 1.96-24.65) and been bullied by their peers (OR, 2.57; 95% CI, 1.12-5.92).Although school-associated violent deaths remain rare events, they have occurred often enough to allow for the detection of patterns and the identification of potential risk factors. This information may help schools respond to this problem.","School-associated violent deaths in the United States, 1994-1999."
"159","JAMA.111","NA",11779261,2002,"Little is known about genetic susceptibility to cigarette smoke in relation to adverse pregnancy outcomes.To investigate whether the association between maternal cigarette smoking and infant birth weight differs by polymorphisms of 2 maternal metabolic genes: CYP1A1 and GSTT1.Case-control study conducted in 1998-2000 among 741 mothers (174 ever smokers and 567 never smokers) who delivered singleton live births at Boston Medical Center. A total of 207 cases were preterm or low-birth-weight infants and 534 were non-low-birth-weight, full-term infants (control).Birth weight, gestation, fetal growth by smoking status and CYP1A1 MspI (AA vs Aa and aa, where Aa and aa were combined because of small numbers of aa and similar results), and GSTT1 (present vs absent) genotypes.Without consideration of genotype, continuous maternal smoking during pregnancy was associated with a mean reduction of 377 g (SE, 89 g) in birth weight (odds ratio [OR], 2.1; 95% confidence interval [CI], 1.2-3.7). When CYP1A1 genotype was considered, the estimated reduction in birth weight was 252 g (SE, 111 g) for the AA genotype group (n = 75; OR, 1.3; 95% CI, 0.6-2.6), but was 520 g (SE, 124 g) for the Aa/aa genotype group (n = 43 for Aa, n = 6 for aa; OR, 3.2; 95% CI, 1.6-6.4). When GSTT1 genotype was considered, the estimated reduction in birth weight was 285 g (SE, 99 g) (OR, 1.7; 95% CI, 0.9-3.2) and 642 g (SE, 154 g) (OR, 3.5; 95% CI, 1.5-8.3) for the present and absent genotype groups, respectively. When both CYP1A1 and GSTT1 genotypes were considered, the greatest reduction in birth weight was found among smoking mothers with the CYP1A1 Aa/aa and GSTT1 absent genotypes (-1285 g; SE, 234 g; P<.001). Among never smokers, genotype did not independently confer an adverse effect. A similar pattern emerged in analyses stratified by maternal ethnicity and in analyses for gestation.In our study, maternal CYP1A1 and GSTT1 genotypes modified the association between maternal cigarette smoking and infant birth weight, suggesting an interaction between metabolic genes and cigarette smoking.","Maternal cigarette smoking, metabolic gene polymorphism, and infant birth weight."
"160","JAMA.112","NA",11779261,2002,"Little is known about genetic susceptibility to cigarette smoke in relation to adverse pregnancy outcomes.To investigate whether the association between maternal cigarette smoking and infant birth weight differs by polymorphisms of 2 maternal metabolic genes: CYP1A1 and GSTT1.Case-control study conducted in 1998-2000 among 741 mothers (174 ever smokers and 567 never smokers) who delivered singleton live births at Boston Medical Center. A total of 207 cases were preterm or low-birth-weight infants and 534 were non-low-birth-weight, full-term infants (control).Birth weight, gestation, fetal growth by smoking status and CYP1A1 MspI (AA vs Aa and aa, where Aa and aa were combined because of small numbers of aa and similar results), and GSTT1 (present vs absent) genotypes.Without consideration of genotype, continuous maternal smoking during pregnancy was associated with a mean reduction of 377 g (SE, 89 g) in birth weight (odds ratio [OR], 2.1; 95% confidence interval [CI], 1.2-3.7). When CYP1A1 genotype was considered, the estimated reduction in birth weight was 252 g (SE, 111 g) for the AA genotype group (n = 75; OR, 1.3; 95% CI, 0.6-2.6), but was 520 g (SE, 124 g) for the Aa/aa genotype group (n = 43 for Aa, n = 6 for aa; OR, 3.2; 95% CI, 1.6-6.4). When GSTT1 genotype was considered, the estimated reduction in birth weight was 285 g (SE, 99 g) (OR, 1.7; 95% CI, 0.9-3.2) and 642 g (SE, 154 g) (OR, 3.5; 95% CI, 1.5-8.3) for the present and absent genotype groups, respectively. When both CYP1A1 and GSTT1 genotypes were considered, the greatest reduction in birth weight was found among smoking mothers with the CYP1A1 Aa/aa and GSTT1 absent genotypes (-1285 g; SE, 234 g; P<.001). Among never smokers, genotype did not independently confer an adverse effect. A similar pattern emerged in analyses stratified by maternal ethnicity and in analyses for gestation.In our study, maternal CYP1A1 and GSTT1 genotypes modified the association between maternal cigarette smoking and infant birth weight, suggesting an interaction between metabolic genes and cigarette smoking.","Maternal cigarette smoking, metabolic gene polymorphism, and infant birth weight."
"161","JAMA.113","NA",11779261,2002,"Little is known about genetic susceptibility to cigarette smoke in relation to adverse pregnancy outcomes.To investigate whether the association between maternal cigarette smoking and infant birth weight differs by polymorphisms of 2 maternal metabolic genes: CYP1A1 and GSTT1.Case-control study conducted in 1998-2000 among 741 mothers (174 ever smokers and 567 never smokers) who delivered singleton live births at Boston Medical Center. A total of 207 cases were preterm or low-birth-weight infants and 534 were non-low-birth-weight, full-term infants (control).Birth weight, gestation, fetal growth by smoking status and CYP1A1 MspI (AA vs Aa and aa, where Aa and aa were combined because of small numbers of aa and similar results), and GSTT1 (present vs absent) genotypes.Without consideration of genotype, continuous maternal smoking during pregnancy was associated with a mean reduction of 377 g (SE, 89 g) in birth weight (odds ratio [OR], 2.1; 95% confidence interval [CI], 1.2-3.7). When CYP1A1 genotype was considered, the estimated reduction in birth weight was 252 g (SE, 111 g) for the AA genotype group (n = 75; OR, 1.3; 95% CI, 0.6-2.6), but was 520 g (SE, 124 g) for the Aa/aa genotype group (n = 43 for Aa, n = 6 for aa; OR, 3.2; 95% CI, 1.6-6.4). When GSTT1 genotype was considered, the estimated reduction in birth weight was 285 g (SE, 99 g) (OR, 1.7; 95% CI, 0.9-3.2) and 642 g (SE, 154 g) (OR, 3.5; 95% CI, 1.5-8.3) for the present and absent genotype groups, respectively. When both CYP1A1 and GSTT1 genotypes were considered, the greatest reduction in birth weight was found among smoking mothers with the CYP1A1 Aa/aa and GSTT1 absent genotypes (-1285 g; SE, 234 g; P<.001). Among never smokers, genotype did not independently confer an adverse effect. A similar pattern emerged in analyses stratified by maternal ethnicity and in analyses for gestation.In our study, maternal CYP1A1 and GSTT1 genotypes modified the association between maternal cigarette smoking and infant birth weight, suggesting an interaction between metabolic genes and cigarette smoking.","Maternal cigarette smoking, metabolic gene polymorphism, and infant birth weight."
"162","JAMA.114","NA",11779261,2002,"Little is known about genetic susceptibility to cigarette smoke in relation to adverse pregnancy outcomes.To investigate whether the association between maternal cigarette smoking and infant birth weight differs by polymorphisms of 2 maternal metabolic genes: CYP1A1 and GSTT1.Case-control study conducted in 1998-2000 among 741 mothers (174 ever smokers and 567 never smokers) who delivered singleton live births at Boston Medical Center. A total of 207 cases were preterm or low-birth-weight infants and 534 were non-low-birth-weight, full-term infants (control).Birth weight, gestation, fetal growth by smoking status and CYP1A1 MspI (AA vs Aa and aa, where Aa and aa were combined because of small numbers of aa and similar results), and GSTT1 (present vs absent) genotypes.Without consideration of genotype, continuous maternal smoking during pregnancy was associated with a mean reduction of 377 g (SE, 89 g) in birth weight (odds ratio [OR], 2.1; 95% confidence interval [CI], 1.2-3.7). When CYP1A1 genotype was considered, the estimated reduction in birth weight was 252 g (SE, 111 g) for the AA genotype group (n = 75; OR, 1.3; 95% CI, 0.6-2.6), but was 520 g (SE, 124 g) for the Aa/aa genotype group (n = 43 for Aa, n = 6 for aa; OR, 3.2; 95% CI, 1.6-6.4). When GSTT1 genotype was considered, the estimated reduction in birth weight was 285 g (SE, 99 g) (OR, 1.7; 95% CI, 0.9-3.2) and 642 g (SE, 154 g) (OR, 3.5; 95% CI, 1.5-8.3) for the present and absent genotype groups, respectively. When both CYP1A1 and GSTT1 genotypes were considered, the greatest reduction in birth weight was found among smoking mothers with the CYP1A1 Aa/aa and GSTT1 absent genotypes (-1285 g; SE, 234 g; P<.001). Among never smokers, genotype did not independently confer an adverse effect. A similar pattern emerged in analyses stratified by maternal ethnicity and in analyses for gestation.In our study, maternal CYP1A1 and GSTT1 genotypes modified the association between maternal cigarette smoking and infant birth weight, suggesting an interaction between metabolic genes and cigarette smoking.","Maternal cigarette smoking, metabolic gene polymorphism, and infant birth weight."
"163","JAMA.115","NA",11779261,2002,"Little is known about genetic susceptibility to cigarette smoke in relation to adverse pregnancy outcomes.To investigate whether the association between maternal cigarette smoking and infant birth weight differs by polymorphisms of 2 maternal metabolic genes: CYP1A1 and GSTT1.Case-control study conducted in 1998-2000 among 741 mothers (174 ever smokers and 567 never smokers) who delivered singleton live births at Boston Medical Center. A total of 207 cases were preterm or low-birth-weight infants and 534 were non-low-birth-weight, full-term infants (control).Birth weight, gestation, fetal growth by smoking status and CYP1A1 MspI (AA vs Aa and aa, where Aa and aa were combined because of small numbers of aa and similar results), and GSTT1 (present vs absent) genotypes.Without consideration of genotype, continuous maternal smoking during pregnancy was associated with a mean reduction of 377 g (SE, 89 g) in birth weight (odds ratio [OR], 2.1; 95% confidence interval [CI], 1.2-3.7). When CYP1A1 genotype was considered, the estimated reduction in birth weight was 252 g (SE, 111 g) for the AA genotype group (n = 75; OR, 1.3; 95% CI, 0.6-2.6), but was 520 g (SE, 124 g) for the Aa/aa genotype group (n = 43 for Aa, n = 6 for aa; OR, 3.2; 95% CI, 1.6-6.4). When GSTT1 genotype was considered, the estimated reduction in birth weight was 285 g (SE, 99 g) (OR, 1.7; 95% CI, 0.9-3.2) and 642 g (SE, 154 g) (OR, 3.5; 95% CI, 1.5-8.3) for the present and absent genotype groups, respectively. When both CYP1A1 and GSTT1 genotypes were considered, the greatest reduction in birth weight was found among smoking mothers with the CYP1A1 Aa/aa and GSTT1 absent genotypes (-1285 g; SE, 234 g; P<.001). Among never smokers, genotype did not independently confer an adverse effect. A similar pattern emerged in analyses stratified by maternal ethnicity and in analyses for gestation.In our study, maternal CYP1A1 and GSTT1 genotypes modified the association between maternal cigarette smoking and infant birth weight, suggesting an interaction between metabolic genes and cigarette smoking.","Maternal cigarette smoking, metabolic gene polymorphism, and infant birth weight."
"164","JAMA.112","0.001",11790214,2002,"The outcome of patients receiving mechanical ventilation for particular indications has been studied, but the outcome in a large number of unselected, heterogeneous patients has not been reported.To determine the survival of patients receiving mechanical ventilation and the relative importance of factors influencing survival.Prospective cohort of consecutive adult patients admitted to 361 intensive care units who received mechanical ventilation for more than 12 hours between March 1, 1998, and March 31, 1998. Data were collected on each patient at initiation of mechanical ventilation and daily throughout the course of mechanical ventilation for up to 28 days.All-cause mortality during intensive care unit stay.Of the 15 757 patients admitted, a total of 5183 (33%) received mechanical ventilation for a mean (SD) duration of 5.9 (7.2) days. The mean (SD) length of stay in the intensive care unit was 11.2 (13.7) days. Overall mortality rate in the intensive care unit was 30.7% (1590 patients) for the entire population, 52% (120) in patients who received ventilation because of acute respiratory distress syndrome, and 22% (115) in patients who received ventilation for an exacerbation of chronic obstructive pulmonary disease. Survival of unselected patients receiving mechanical ventilation for more than 12 hours was 69%. The main conditions independently associated with increased mortality were (1) factors present at the start of mechanical ventilation (odds ratio [OR], 2.98; 95% confidence interval [CI], 2.44-3.63; P<.001 for coma), (2) factors related to patient management (OR, 3.67; 95% CI, 2.02-6.66; P<.001 for plateau airway pressure >35 cm H(2)O), and (3) developments occurring over the course of mechanical ventilation (OR, 8.71; 95% CI, 5.44-13.94; P<.001 for ratio of PaO(2) to fraction of inspired oxygen <100).Survival among mechanically ventilated patients depends not only on the factors present at the start of mechanical ventilation, but also on the development of complications and patient management in the intensive care unit.","Characteristics and outcomes in adult patients receiving mechanical ventilation: a 28-day international study."
"165","JAMA.113","0.001",11790214,2002,"The outcome of patients receiving mechanical ventilation for particular indications has been studied, but the outcome in a large number of unselected, heterogeneous patients has not been reported.To determine the survival of patients receiving mechanical ventilation and the relative importance of factors influencing survival.Prospective cohort of consecutive adult patients admitted to 361 intensive care units who received mechanical ventilation for more than 12 hours between March 1, 1998, and March 31, 1998. Data were collected on each patient at initiation of mechanical ventilation and daily throughout the course of mechanical ventilation for up to 28 days.All-cause mortality during intensive care unit stay.Of the 15 757 patients admitted, a total of 5183 (33%) received mechanical ventilation for a mean (SD) duration of 5.9 (7.2) days. The mean (SD) length of stay in the intensive care unit was 11.2 (13.7) days. Overall mortality rate in the intensive care unit was 30.7% (1590 patients) for the entire population, 52% (120) in patients who received ventilation because of acute respiratory distress syndrome, and 22% (115) in patients who received ventilation for an exacerbation of chronic obstructive pulmonary disease. Survival of unselected patients receiving mechanical ventilation for more than 12 hours was 69%. The main conditions independently associated with increased mortality were (1) factors present at the start of mechanical ventilation (odds ratio [OR], 2.98; 95% confidence interval [CI], 2.44-3.63; P<.001 for coma), (2) factors related to patient management (OR, 3.67; 95% CI, 2.02-6.66; P<.001 for plateau airway pressure >35 cm H(2)O), and (3) developments occurring over the course of mechanical ventilation (OR, 8.71; 95% CI, 5.44-13.94; P<.001 for ratio of PaO(2) to fraction of inspired oxygen <100).Survival among mechanically ventilated patients depends not only on the factors present at the start of mechanical ventilation, but also on the development of complications and patient management in the intensive care unit.","Characteristics and outcomes in adult patients receiving mechanical ventilation: a 28-day international study."
"166","JAMA.114","0.001",11790214,2002,"The outcome of patients receiving mechanical ventilation for particular indications has been studied, but the outcome in a large number of unselected, heterogeneous patients has not been reported.To determine the survival of patients receiving mechanical ventilation and the relative importance of factors influencing survival.Prospective cohort of consecutive adult patients admitted to 361 intensive care units who received mechanical ventilation for more than 12 hours between March 1, 1998, and March 31, 1998. Data were collected on each patient at initiation of mechanical ventilation and daily throughout the course of mechanical ventilation for up to 28 days.All-cause mortality during intensive care unit stay.Of the 15 757 patients admitted, a total of 5183 (33%) received mechanical ventilation for a mean (SD) duration of 5.9 (7.2) days. The mean (SD) length of stay in the intensive care unit was 11.2 (13.7) days. Overall mortality rate in the intensive care unit was 30.7% (1590 patients) for the entire population, 52% (120) in patients who received ventilation because of acute respiratory distress syndrome, and 22% (115) in patients who received ventilation for an exacerbation of chronic obstructive pulmonary disease. Survival of unselected patients receiving mechanical ventilation for more than 12 hours was 69%. The main conditions independently associated with increased mortality were (1) factors present at the start of mechanical ventilation (odds ratio [OR], 2.98; 95% confidence interval [CI], 2.44-3.63; P<.001 for coma), (2) factors related to patient management (OR, 3.67; 95% CI, 2.02-6.66; P<.001 for plateau airway pressure >35 cm H(2)O), and (3) developments occurring over the course of mechanical ventilation (OR, 8.71; 95% CI, 5.44-13.94; P<.001 for ratio of PaO(2) to fraction of inspired oxygen <100).Survival among mechanically ventilated patients depends not only on the factors present at the start of mechanical ventilation, but also on the development of complications and patient management in the intensive care unit.","Characteristics and outcomes in adult patients receiving mechanical ventilation: a 28-day international study."
"167","JAMA.841","0.001",11829701,2002,"In the Enhanced Suppression of the Platelet IIb/IIIa Receptor with Integrilin Therapy (ESPRIT) trial, treatment with eptifibatide, a platelet glycoprotein IIb/IIIa integrin blocker, was found to reduce the ischemic complications of nonurgent coronary stent implantation at 48 hours and 30 days.To determine whether eptifibatide treatment continues to provide durable, long-term benefit after coronary stent intervention.The ESPRIT trial was a randomized, double-blind, placebo-controlled, parallel-group, crossover-permitted trial conducted from June 1999 through February 2000 at 92 tertiary care centers in the United States and Canada.A total of 2064 patients scheduled to undergo nonurgent percutaneous coronary intervention with stent implantation.Patients were randomly assigned to receive placebo (n = 1024) or eptifibatide (two 180-microg/kg boluses, 10 minutes apart, with a continuous infusion of 2.0 microg/kg per minute; n = 1040), started immediately before stent implantation and continued for 18 to 24 hours. Patients also received aspirin, heparin, and a thienopyridine.Composite rates of death or myocardial infarction (MI) and death, infarction, or target vessel revascularization during the 12 months after enrollment.Complete follow-up data were available for 988 patients given eptifibatide (95.0%) and 976 patients given placebo (95.3%). By 12 months, the composite of death or MI had occurred in 8.0% of eptifibatide-treated patients and in 12.4% of placebo-treated patients (hazard ratio [HR], 0.63; 95% confidence interval [CI], 0.48-0.83; P =.001). The composite rate of death, MI, or target vessel revascularization was 17.5% in eptifibatide-treated patients vs 22.1% in placebo-treated patients (HR, 0.76; 95% CI, 0.63-0.93; P =.007).Long-term outcomes of nonurgent coronary stent implantation appear to be improved through blockade of the platelet glycoprotein IIb/IIIa integrin with eptifibatide.","Long-term efficacy of platelet glycoprotein IIb/IIIa integrin blockade with eptifibatide in coronary stent intervention."
"168","JAMA.851","0.007",11829701,2002,"In the Enhanced Suppression of the Platelet IIb/IIIa Receptor with Integrilin Therapy (ESPRIT) trial, treatment with eptifibatide, a platelet glycoprotein IIb/IIIa integrin blocker, was found to reduce the ischemic complications of nonurgent coronary stent implantation at 48 hours and 30 days.To determine whether eptifibatide treatment continues to provide durable, long-term benefit after coronary stent intervention.The ESPRIT trial was a randomized, double-blind, placebo-controlled, parallel-group, crossover-permitted trial conducted from June 1999 through February 2000 at 92 tertiary care centers in the United States and Canada.A total of 2064 patients scheduled to undergo nonurgent percutaneous coronary intervention with stent implantation.Patients were randomly assigned to receive placebo (n = 1024) or eptifibatide (two 180-microg/kg boluses, 10 minutes apart, with a continuous infusion of 2.0 microg/kg per minute; n = 1040), started immediately before stent implantation and continued for 18 to 24 hours. Patients also received aspirin, heparin, and a thienopyridine.Composite rates of death or myocardial infarction (MI) and death, infarction, or target vessel revascularization during the 12 months after enrollment.Complete follow-up data were available for 988 patients given eptifibatide (95.0%) and 976 patients given placebo (95.3%). By 12 months, the composite of death or MI had occurred in 8.0% of eptifibatide-treated patients and in 12.4% of placebo-treated patients (hazard ratio [HR], 0.63; 95% confidence interval [CI], 0.48-0.83; P =.001). The composite rate of death, MI, or target vessel revascularization was 17.5% in eptifibatide-treated patients vs 22.1% in placebo-treated patients (HR, 0.76; 95% CI, 0.63-0.93; P =.007).Long-term outcomes of nonurgent coronary stent implantation appear to be improved through blockade of the platelet glycoprotein IIb/IIIa integrin with eptifibatide.","Long-term efficacy of platelet glycoprotein IIb/IIIa integrin blockade with eptifibatide in coronary stent intervention."
"169","American Journal of Epidemiology.29","NA",11882528,2002,"Acute myelogenous leukemia (AML) is a heterogeneous disease with distinct histologic subtypes likely to have distinct risk factors. The authors examined smoking and the risk of adult AML by French-American-British (FAB) subtype in a Los Angeles County, California, population-based case-control study of 412 cases diagnosed between 1987 and 1994 and 412 matched controls. Consistent with previous studies, smoking was not a substantial risk factor for AML overall (odds ratio (OR) = 1.2, 95% confidence interval (CI): 0.9, 1.6). However, increased risk was observed for FAB subtype M2 (OR = 2.3, 95% CI: 1.1, 4.4), particularly for subjects aged 60-75 years (OR = 3.3, 95% CI: 1.1, 10.0). For M2, significant dose-response was associated with total years smoked (p = 0.02), cigarettes per day (p = 0.007), and product filter status (filtered vs. nonfiltered; p = 0.03). The authors estimate that 42% (standard error = 13%) of M2 cases are attributable to smoking. There were no or weak associations between smoking and increased AML risk for other FAB subtypes. The finding by this study of an association between smoking and FAB subtype M2 confirms a previously published report and suggests that earlier findings of no or weak smoking-AML associations may have been due to lack of subtype-specific analysis.","Smoking and risk of acute myeloid leukemia: results from a Los Angeles County case-control study."
"170","American Journal of Epidemiology.30","NA",11882528,2002,"Acute myelogenous leukemia (AML) is a heterogeneous disease with distinct histologic subtypes likely to have distinct risk factors. The authors examined smoking and the risk of adult AML by French-American-British (FAB) subtype in a Los Angeles County, California, population-based case-control study of 412 cases diagnosed between 1987 and 1994 and 412 matched controls. Consistent with previous studies, smoking was not a substantial risk factor for AML overall (odds ratio (OR) = 1.2, 95% confidence interval (CI): 0.9, 1.6). However, increased risk was observed for FAB subtype M2 (OR = 2.3, 95% CI: 1.1, 4.4), particularly for subjects aged 60-75 years (OR = 3.3, 95% CI: 1.1, 10.0). For M2, significant dose-response was associated with total years smoked (p = 0.02), cigarettes per day (p = 0.007), and product filter status (filtered vs. nonfiltered; p = 0.03). The authors estimate that 42% (standard error = 13%) of M2 cases are attributable to smoking. There were no or weak associations between smoking and increased AML risk for other FAB subtypes. The finding by this study of an association between smoking and FAB subtype M2 confirms a previously published report and suggests that earlier findings of no or weak smoking-AML associations may have been due to lack of subtype-specific analysis.","Smoking and risk of acute myeloid leukemia: results from a Los Angeles County case-control study."
"171","American Journal of Epidemiology.31","NA",11882528,2002,"Acute myelogenous leukemia (AML) is a heterogeneous disease with distinct histologic subtypes likely to have distinct risk factors. The authors examined smoking and the risk of adult AML by French-American-British (FAB) subtype in a Los Angeles County, California, population-based case-control study of 412 cases diagnosed between 1987 and 1994 and 412 matched controls. Consistent with previous studies, smoking was not a substantial risk factor for AML overall (odds ratio (OR) = 1.2, 95% confidence interval (CI): 0.9, 1.6). However, increased risk was observed for FAB subtype M2 (OR = 2.3, 95% CI: 1.1, 4.4), particularly for subjects aged 60-75 years (OR = 3.3, 95% CI: 1.1, 10.0). For M2, significant dose-response was associated with total years smoked (p = 0.02), cigarettes per day (p = 0.007), and product filter status (filtered vs. nonfiltered; p = 0.03). The authors estimate that 42% (standard error = 13%) of M2 cases are attributable to smoking. There were no or weak associations between smoking and increased AML risk for other FAB subtypes. The finding by this study of an association between smoking and FAB subtype M2 confirms a previously published report and suggests that earlier findings of no or weak smoking-AML associations may have been due to lack of subtype-specific analysis.","Smoking and risk of acute myeloid leukemia: results from a Los Angeles County case-control study."
"172","JAMA.110","NA",11886321,2002,"Human herpesvirus 8 (HHV-8) infection causes Kaposi sarcoma and lymphoproliferative disorders in immunosuppressed adults. Its manifestations in immunocompetent hosts are unknown.To determine whether HHV-8 primary infection is symptomatic in immunocompetent children and to identify the epidemiological and virological correlates of HHV-8 infection.Prospective cohort study conducted in the pediatric emergency department of a hospital in Alexandria, Egypt, between December 1, 1999, and April 30, 2000.Eighty-six children aged 1 to 4 years who were evaluated for a febrile syndrome of undetermined origin.Serological assay and polymerase chain reaction of blood and saliva samples for HHV-8. Information on potential risk factors for HHV-8 infection was also collected.Thirty-six children (41.9%) were seropositive; HHV-8 DNA sequences were detected in 14 (38.9%) of these 36 children (detected in saliva in 11 of 14). Significant associations were found between HHV-8 infection and close contact with at least 2 other children in the community (36 of 63 vs 6 of 23 for <2 children; adjusted odds ratio [OR], 3.50; 95% confidence interval [CI], 1.11-12.22) and admission to the emergency department in December or January (28 of 47 vs 14 of 39 for February-April; adjusted OR, 3.15; 95% CI, 1.23-8.58). Six children had suspected primary HHV-8 infection; all but 1 had a febrile cutaneous craniocaudal maculopapular rash, which was more common among these children (5 of 6 vs 10 of 75; P<.001). For 3 of these 6 children, a second blood sample was obtained after the convalescence phase, and all 3 seroconverted for HHV-8.Primary infection with HHV-8 may be associated with a febrile maculopapular skin rash among immunocompetent children. The finding of HHV-8 DNA sequences in saliva supports the hypothesis that transmission through saliva is the main mode of transmission in the pediatric age group.","Primary human herpesvirus 8 infection in immunocompetent children."
"173","JAMA.111","NA",11886321,2002,"Human herpesvirus 8 (HHV-8) infection causes Kaposi sarcoma and lymphoproliferative disorders in immunosuppressed adults. Its manifestations in immunocompetent hosts are unknown.To determine whether HHV-8 primary infection is symptomatic in immunocompetent children and to identify the epidemiological and virological correlates of HHV-8 infection.Prospective cohort study conducted in the pediatric emergency department of a hospital in Alexandria, Egypt, between December 1, 1999, and April 30, 2000.Eighty-six children aged 1 to 4 years who were evaluated for a febrile syndrome of undetermined origin.Serological assay and polymerase chain reaction of blood and saliva samples for HHV-8. Information on potential risk factors for HHV-8 infection was also collected.Thirty-six children (41.9%) were seropositive; HHV-8 DNA sequences were detected in 14 (38.9%) of these 36 children (detected in saliva in 11 of 14). Significant associations were found between HHV-8 infection and close contact with at least 2 other children in the community (36 of 63 vs 6 of 23 for <2 children; adjusted odds ratio [OR], 3.50; 95% confidence interval [CI], 1.11-12.22) and admission to the emergency department in December or January (28 of 47 vs 14 of 39 for February-April; adjusted OR, 3.15; 95% CI, 1.23-8.58). Six children had suspected primary HHV-8 infection; all but 1 had a febrile cutaneous craniocaudal maculopapular rash, which was more common among these children (5 of 6 vs 10 of 75; P<.001). For 3 of these 6 children, a second blood sample was obtained after the convalescence phase, and all 3 seroconverted for HHV-8.Primary infection with HHV-8 may be associated with a febrile maculopapular skin rash among immunocompetent children. The finding of HHV-8 DNA sequences in saliva supports the hypothesis that transmission through saliva is the main mode of transmission in the pediatric age group.","Primary human herpesvirus 8 infection in immunocompetent children."
"174","American Journal of Epidemiology.26","NA",11914190,2002,"Some reports indicate that exposure to specific polychlorinated biphenyl (PCB) congeners is related to breast cancer risk. The authors recruited participants in a case-control study from October 1994 to March 1997 to assess the relation between breast cancer risk and concentrations of 14 PCB congeners measured in plasma lipids by high-resolution gas chromatography. Participants were incident cases of breast cancer (n = 314) and controls (n = 523) from the Quebec City region (Canada). Compared with controls, cases had significantly higher concentrations of PCB 99 (p = 0.02), PCB 118 (p = 0.03), and PCB 156 (p = 0.006). Associations were found between breast cancer risk and either PCB 118 (odds ratio (OR) = 1.60, 95% confidence interval (CI): 1.01, 2.53; fourth vs. first quartile) or PCB 156 (OR = 1.80, 95% CI: 1.11, 2.94; fourth vs. first quartile) concentration. Breast cancer risk was also associated with a total concentration of the three mono-ortho-substituted congeners 105, 118, and 156 expressed as 2,3,7,8-tetrachlorodibenzo-p-dioxin toxic equivalents (OR = 2.02, 95% CI: 1.24, 3.28; fourth vs. first quartile). These results suggest that exposure to dioxin-like PCBs increases breast cancer risk. Alternatively, the results may be explained by differences between cases and controls regarding metabolic pathways involved in the biotransformation of both mono-ortho PCBs and estrogens.","Plasma concentrations of polychlorinated biphenyls and the risk of breast cancer: a congener-specific analysis."
"175","American Journal of Epidemiology.27","NA",11914190,2002,"Some reports indicate that exposure to specific polychlorinated biphenyl (PCB) congeners is related to breast cancer risk. The authors recruited participants in a case-control study from October 1994 to March 1997 to assess the relation between breast cancer risk and concentrations of 14 PCB congeners measured in plasma lipids by high-resolution gas chromatography. Participants were incident cases of breast cancer (n = 314) and controls (n = 523) from the Quebec City region (Canada). Compared with controls, cases had significantly higher concentrations of PCB 99 (p = 0.02), PCB 118 (p = 0.03), and PCB 156 (p = 0.006). Associations were found between breast cancer risk and either PCB 118 (odds ratio (OR) = 1.60, 95% confidence interval (CI): 1.01, 2.53; fourth vs. first quartile) or PCB 156 (OR = 1.80, 95% CI: 1.11, 2.94; fourth vs. first quartile) concentration. Breast cancer risk was also associated with a total concentration of the three mono-ortho-substituted congeners 105, 118, and 156 expressed as 2,3,7,8-tetrachlorodibenzo-p-dioxin toxic equivalents (OR = 2.02, 95% CI: 1.24, 3.28; fourth vs. first quartile). These results suggest that exposure to dioxin-like PCBs increases breast cancer risk. Alternatively, the results may be explained by differences between cases and controls regarding metabolic pathways involved in the biotransformation of both mono-ortho PCBs and estrogens.","Plasma concentrations of polychlorinated biphenyls and the risk of breast cancer: a congener-specific analysis."
"176","American Journal of Epidemiology.28","NA",11914190,2002,"Some reports indicate that exposure to specific polychlorinated biphenyl (PCB) congeners is related to breast cancer risk. The authors recruited participants in a case-control study from October 1994 to March 1997 to assess the relation between breast cancer risk and concentrations of 14 PCB congeners measured in plasma lipids by high-resolution gas chromatography. Participants were incident cases of breast cancer (n = 314) and controls (n = 523) from the Quebec City region (Canada). Compared with controls, cases had significantly higher concentrations of PCB 99 (p = 0.02), PCB 118 (p = 0.03), and PCB 156 (p = 0.006). Associations were found between breast cancer risk and either PCB 118 (odds ratio (OR) = 1.60, 95% confidence interval (CI): 1.01, 2.53; fourth vs. first quartile) or PCB 156 (OR = 1.80, 95% CI: 1.11, 2.94; fourth vs. first quartile) concentration. Breast cancer risk was also associated with a total concentration of the three mono-ortho-substituted congeners 105, 118, and 156 expressed as 2,3,7,8-tetrachlorodibenzo-p-dioxin toxic equivalents (OR = 2.02, 95% CI: 1.24, 3.28; fourth vs. first quartile). These results suggest that exposure to dioxin-like PCBs increases breast cancer risk. Alternatively, the results may be explained by differences between cases and controls regarding metabolic pathways involved in the biotransformation of both mono-ortho PCBs and estrogens.","Plasma concentrations of polychlorinated biphenyls and the risk of breast cancer: a congener-specific analysis."
"177","JAMA.140","NA",11926892,2002,"A genetic variant in alpha-adducin has been associated with renal sodium reabsorption and salt-sensitive hypertension. Whether this genetic variant modifies the effect of diuretic therapy on the incidence of myocardial infarction (MI) and stroke is unknown.To estimate the interaction between alpha-adducin and diuretic therapy on the risk of MI or stroke. Specifically, we hypothesized that in participants with treated hypertension, the risk of MI or stroke associated with diuretic use would be lower in carriers of the adducin variant than in carriers of the adducin wild-type genotype.Population-based case-control study of patients enrolled in a health maintenance organization, treated pharmacologically for hypertension, and genotyped as homozygous carriers of the adducin wild-type genotype or carriers of 1 or 2 copies of the Trp460 variant allele. Cases had a first nonfatal MI (n = 206) or stroke (n = 117) between January 1995 and December 1998. Controls (n = 715) were a stratified random sample of pharmacologically treated hypertensive patients who were matched to MI cases by age, sex, and calendar year.Risk of the combined outcome of first nonfatal MI or stroke.The adducin variant was present in more than one third of the participants. Among the 653 carriers of the adducin wild-type genotype, diuretic therapy was not associated with the risk of MI or stroke (odds ratio [OR], 1.09; 95% confidence interval [CI], 0.78-1.52). Among the 385 carriers of the adducin variant allele, diuretic therapy was associated with a lower risk of the combined outcome of MI and stroke than other antihypertensive therapies (OR, 0.49; 95% CI, 0.32-0.77). The OR in carriers of the adducin variant was less than half of the OR in carriers of the wild-type genotype (P =.005). The case-control synergy index (SI) was 0.45 (95% CI, 0.26-0.79) for the combined outcome of MI and stroke. The point estimates of the diuretic-adducin interaction were similar in separate analyses of MI (SI, 0.41; 95% CI, 0.21-0.80) and stroke (SI, 0.53; 95% CI, 0.24-1.19). The diuretic-adducin interaction was not confounded by traditional cardiovascular risk factors, was specific to diuretic therapy but not present for other major antihypertensive drug classes, and did not differ substantially between subgroups defined by age, sex, race, diabetes, and history of cardiovascular disease.In carriers of the adducin variant, diuretic therapy was associated with a lower risk of combined MI or stroke than other antihypertensive therapies. If these findings are confirmed in other studies, this large subgroup of the hypertensive population may be especially likely to benefit from low-dose diuretic therapy.","Diuretic therapy, the alpha-adducin gene variant, and the risk of myocardial infarction or stroke in persons with treated hypertension."
"178","JAMA.141","NA",11926892,2002,"A genetic variant in alpha-adducin has been associated with renal sodium reabsorption and salt-sensitive hypertension. Whether this genetic variant modifies the effect of diuretic therapy on the incidence of myocardial infarction (MI) and stroke is unknown.To estimate the interaction between alpha-adducin and diuretic therapy on the risk of MI or stroke. Specifically, we hypothesized that in participants with treated hypertension, the risk of MI or stroke associated with diuretic use would be lower in carriers of the adducin variant than in carriers of the adducin wild-type genotype.Population-based case-control study of patients enrolled in a health maintenance organization, treated pharmacologically for hypertension, and genotyped as homozygous carriers of the adducin wild-type genotype or carriers of 1 or 2 copies of the Trp460 variant allele. Cases had a first nonfatal MI (n = 206) or stroke (n = 117) between January 1995 and December 1998. Controls (n = 715) were a stratified random sample of pharmacologically treated hypertensive patients who were matched to MI cases by age, sex, and calendar year.Risk of the combined outcome of first nonfatal MI or stroke.The adducin variant was present in more than one third of the participants. Among the 653 carriers of the adducin wild-type genotype, diuretic therapy was not associated with the risk of MI or stroke (odds ratio [OR], 1.09; 95% confidence interval [CI], 0.78-1.52). Among the 385 carriers of the adducin variant allele, diuretic therapy was associated with a lower risk of the combined outcome of MI and stroke than other antihypertensive therapies (OR, 0.49; 95% CI, 0.32-0.77). The OR in carriers of the adducin variant was less than half of the OR in carriers of the wild-type genotype (P =.005). The case-control synergy index (SI) was 0.45 (95% CI, 0.26-0.79) for the combined outcome of MI and stroke. The point estimates of the diuretic-adducin interaction were similar in separate analyses of MI (SI, 0.41; 95% CI, 0.21-0.80) and stroke (SI, 0.53; 95% CI, 0.24-1.19). The diuretic-adducin interaction was not confounded by traditional cardiovascular risk factors, was specific to diuretic therapy but not present for other major antihypertensive drug classes, and did not differ substantially between subgroups defined by age, sex, race, diabetes, and history of cardiovascular disease.In carriers of the adducin variant, diuretic therapy was associated with a lower risk of combined MI or stroke than other antihypertensive therapies. If these findings are confirmed in other studies, this large subgroup of the hypertensive population may be especially likely to benefit from low-dose diuretic therapy.","Diuretic therapy, the alpha-adducin gene variant, and the risk of myocardial infarction or stroke in persons with treated hypertension."
"179","JAMA.5910","NA",11926893,2002,"Warfarin is a commonly used anticoagulant that requires careful clinical management to balance the risks of overanticoagulation and bleeding with those of underanticoagulation and clotting. The principal enzyme involved in warfarin metabolism is CYP2C9, and 2 relatively common variant forms with reduced activity have been identified, CYP2C9*2 and CYP2C9*3. Patients with these genetic variants have been shown to require lower maintenance doses of warfarin, but a direct association between CYP2C9 genotype and anticoagulation status or bleeding risk has not been established.To determine if CYP2C9*2 and CYP2C9*3 variants are associated with overanticoagulation and bleeding events during warfarin therapy.Retrospective cohort study conducted at 2 anticoagulation clinics based in Seattle, Wash.Two hundred patients receiving long-term warfarin therapy for various indications during April 3, 1990, to May 31, 2001. Only patients with a complete history of warfarin exposure were included.Anticoagulation status, measured by time to therapeutic international normalized ratio (INR), rate of above-range INRs, and time to stable warfarin dosing; and time to serious or life-threatening bleeding events.Among 185 patients with analyzable data, 58 (31.4%) had at least 1 variant CYP2C9 allele and 127 (68.6%) had the wild-type (*1/*1) genotype. Mean maintenance dose varied significantly among the 6 genotype groups (*1/*1 [n = 127], *1/*2 [n = 28], *1/*3 [n = 18], *2/*2 [n = 4], *2/*3 [n = 3], *3/*3 [n = 5]) (by Kruskall-Wallis test, chi(2)(5) = 37.348; P<.001). Compared with patients with the wild-type genotype, patients with at least 1 variant allele had an increased risk of above-range INRs (hazard ratio [HR], 1.40; 95% confidence interval [CI], 1.03-1.90). The variant group also required more time to achieve stable dosing (HR, 0.65; 95% CI, 0.45-0.94), with a median difference of 95 days (P =.004). In addition, although numbers were small for some genotypes, representing potentially unstable estimates, patients with a variant genotype had a significantly increased risk of a serious or life-threatening bleeding event (HR, 2.39; 95% CI, 1.18-4.86).The results of our study suggest that the CYP2C9*2 and CYP2C9*3 polymorphisms are associated with an increased risk of overanticoagulation and of bleeding events among patients in a warfarin anticoagulation clinic setting, although small numbers in some cases would suggest the need for caution in interpretation. Screening for CYP2C9 variants may allow clinicians to develop dosing protocols and surveillance techniques to reduce the risk of adverse drug reactions in patients receiving warfarin.","Association between CYP2C9 genetic variants and anticoagulation-related outcomes during warfarin therapy."
"180","JAMA.5911","NA",11926893,2002,"Warfarin is a commonly used anticoagulant that requires careful clinical management to balance the risks of overanticoagulation and bleeding with those of underanticoagulation and clotting. The principal enzyme involved in warfarin metabolism is CYP2C9, and 2 relatively common variant forms with reduced activity have been identified, CYP2C9*2 and CYP2C9*3. Patients with these genetic variants have been shown to require lower maintenance doses of warfarin, but a direct association between CYP2C9 genotype and anticoagulation status or bleeding risk has not been established.To determine if CYP2C9*2 and CYP2C9*3 variants are associated with overanticoagulation and bleeding events during warfarin therapy.Retrospective cohort study conducted at 2 anticoagulation clinics based in Seattle, Wash.Two hundred patients receiving long-term warfarin therapy for various indications during April 3, 1990, to May 31, 2001. Only patients with a complete history of warfarin exposure were included.Anticoagulation status, measured by time to therapeutic international normalized ratio (INR), rate of above-range INRs, and time to stable warfarin dosing; and time to serious or life-threatening bleeding events.Among 185 patients with analyzable data, 58 (31.4%) had at least 1 variant CYP2C9 allele and 127 (68.6%) had the wild-type (*1/*1) genotype. Mean maintenance dose varied significantly among the 6 genotype groups (*1/*1 [n = 127], *1/*2 [n = 28], *1/*3 [n = 18], *2/*2 [n = 4], *2/*3 [n = 3], *3/*3 [n = 5]) (by Kruskall-Wallis test, chi(2)(5) = 37.348; P<.001). Compared with patients with the wild-type genotype, patients with at least 1 variant allele had an increased risk of above-range INRs (hazard ratio [HR], 1.40; 95% confidence interval [CI], 1.03-1.90). The variant group also required more time to achieve stable dosing (HR, 0.65; 95% CI, 0.45-0.94), with a median difference of 95 days (P =.004). In addition, although numbers were small for some genotypes, representing potentially unstable estimates, patients with a variant genotype had a significantly increased risk of a serious or life-threatening bleeding event (HR, 2.39; 95% CI, 1.18-4.86).The results of our study suggest that the CYP2C9*2 and CYP2C9*3 polymorphisms are associated with an increased risk of overanticoagulation and of bleeding events among patients in a warfarin anticoagulation clinic setting, although small numbers in some cases would suggest the need for caution in interpretation. Screening for CYP2C9 variants may allow clinicians to develop dosing protocols and surveillance techniques to reduce the risk of adverse drug reactions in patients receiving warfarin.","Association between CYP2C9 genetic variants and anticoagulation-related outcomes during warfarin therapy."
"181","JAMA.831","NA",11926893,2002,"Warfarin is a commonly used anticoagulant that requires careful clinical management to balance the risks of overanticoagulation and bleeding with those of underanticoagulation and clotting. The principal enzyme involved in warfarin metabolism is CYP2C9, and 2 relatively common variant forms with reduced activity have been identified, CYP2C9*2 and CYP2C9*3. Patients with these genetic variants have been shown to require lower maintenance doses of warfarin, but a direct association between CYP2C9 genotype and anticoagulation status or bleeding risk has not been established.To determine if CYP2C9*2 and CYP2C9*3 variants are associated with overanticoagulation and bleeding events during warfarin therapy.Retrospective cohort study conducted at 2 anticoagulation clinics based in Seattle, Wash.Two hundred patients receiving long-term warfarin therapy for various indications during April 3, 1990, to May 31, 2001. Only patients with a complete history of warfarin exposure were included.Anticoagulation status, measured by time to therapeutic international normalized ratio (INR), rate of above-range INRs, and time to stable warfarin dosing; and time to serious or life-threatening bleeding events.Among 185 patients with analyzable data, 58 (31.4%) had at least 1 variant CYP2C9 allele and 127 (68.6%) had the wild-type (*1/*1) genotype. Mean maintenance dose varied significantly among the 6 genotype groups (*1/*1 [n = 127], *1/*2 [n = 28], *1/*3 [n = 18], *2/*2 [n = 4], *2/*3 [n = 3], *3/*3 [n = 5]) (by Kruskall-Wallis test, chi(2)(5) = 37.348; P<.001). Compared with patients with the wild-type genotype, patients with at least 1 variant allele had an increased risk of above-range INRs (hazard ratio [HR], 1.40; 95% confidence interval [CI], 1.03-1.90). The variant group also required more time to achieve stable dosing (HR, 0.65; 95% CI, 0.45-0.94), with a median difference of 95 days (P =.004). In addition, although numbers were small for some genotypes, representing potentially unstable estimates, patients with a variant genotype had a significantly increased risk of a serious or life-threatening bleeding event (HR, 2.39; 95% CI, 1.18-4.86).The results of our study suggest that the CYP2C9*2 and CYP2C9*3 polymorphisms are associated with an increased risk of overanticoagulation and of bleeding events among patients in a warfarin anticoagulation clinic setting, although small numbers in some cases would suggest the need for caution in interpretation. Screening for CYP2C9 variants may allow clinicians to develop dosing protocols and surveillance techniques to reduce the risk of adverse drug reactions in patients receiving warfarin.","Association between CYP2C9 genetic variants and anticoagulation-related outcomes during warfarin therapy."
"182","American Journal of Epidemiology.19","NA",11943691,2002,"A reduced risk for Parkinson's disease (PD) among cigarette smokers has been observed consistently during the past 30 years. Recent evidence suggests that caffeine may also be protective. Findings are presented regarding associations of PD with smoking, caffeine intake, and alcohol consumption from a case-control study conducted in western Washington State in 1992-2000. Incident PD cases (n = 210) and controls (n = 347), frequency matched on gender and age were identified from enrollees of the Group Health Cooperative health maintenance organization. Exposure data were obtained by in-person questionnaires. Ever having smoked cigarettes was associated with a reduced risk of PD (odds ratio (OR) = 0.5, 95% confidence interval (CI): 0.4, 0.8). A stronger relation was found among current smokers (OR = 0.3, 95% CI: 0.1, 0.7) than among ex-smokers (OR = 0.6, 95% CI: 0.4, 0.9), and there was an inverse gradient with pack-years smoked (trend p < 0.001). No associations were detected for coffee consumption or total caffeine intake or for alcohol consumption. However, reduced risks were observed for consumption of 2 cups/day or more of tea (OR = 0.4, 95% CI: 0.2, 0.9) and two or more cola drinks/day (OR = 0.6, 95% CI: 0.3, 1.4). The associations for tea and cola drinks were not confounded by smoking or coffee consumption.","Parkinson's disease risks associated with cigarette smoking, alcohol consumption, and caffeine intake."
"183","American Journal of Epidemiology.20","NA",11943691,2002,"A reduced risk for Parkinson's disease (PD) among cigarette smokers has been observed consistently during the past 30 years. Recent evidence suggests that caffeine may also be protective. Findings are presented regarding associations of PD with smoking, caffeine intake, and alcohol consumption from a case-control study conducted in western Washington State in 1992-2000. Incident PD cases (n = 210) and controls (n = 347), frequency matched on gender and age were identified from enrollees of the Group Health Cooperative health maintenance organization. Exposure data were obtained by in-person questionnaires. Ever having smoked cigarettes was associated with a reduced risk of PD (odds ratio (OR) = 0.5, 95% confidence interval (CI): 0.4, 0.8). A stronger relation was found among current smokers (OR = 0.3, 95% CI: 0.1, 0.7) than among ex-smokers (OR = 0.6, 95% CI: 0.4, 0.9), and there was an inverse gradient with pack-years smoked (trend p < 0.001). No associations were detected for coffee consumption or total caffeine intake or for alcohol consumption. However, reduced risks were observed for consumption of 2 cups/day or more of tea (OR = 0.4, 95% CI: 0.2, 0.9) and two or more cola drinks/day (OR = 0.6, 95% CI: 0.3, 1.4). The associations for tea and cola drinks were not confounded by smoking or coffee consumption.","Parkinson's disease risks associated with cigarette smoking, alcohol consumption, and caffeine intake."
"184","American Journal of Epidemiology.21","NA",11943691,2002,"A reduced risk for Parkinson's disease (PD) among cigarette smokers has been observed consistently during the past 30 years. Recent evidence suggests that caffeine may also be protective. Findings are presented regarding associations of PD with smoking, caffeine intake, and alcohol consumption from a case-control study conducted in western Washington State in 1992-2000. Incident PD cases (n = 210) and controls (n = 347), frequency matched on gender and age were identified from enrollees of the Group Health Cooperative health maintenance organization. Exposure data were obtained by in-person questionnaires. Ever having smoked cigarettes was associated with a reduced risk of PD (odds ratio (OR) = 0.5, 95% confidence interval (CI): 0.4, 0.8). A stronger relation was found among current smokers (OR = 0.3, 95% CI: 0.1, 0.7) than among ex-smokers (OR = 0.6, 95% CI: 0.4, 0.9), and there was an inverse gradient with pack-years smoked (trend p < 0.001). No associations were detected for coffee consumption or total caffeine intake or for alcohol consumption. However, reduced risks were observed for consumption of 2 cups/day or more of tea (OR = 0.4, 95% CI: 0.2, 0.9) and two or more cola drinks/day (OR = 0.6, 95% CI: 0.3, 1.4). The associations for tea and cola drinks were not confounded by smoking or coffee consumption.","Parkinson's disease risks associated with cigarette smoking, alcohol consumption, and caffeine intake."
"185","American Journal of Epidemiology.22","NA",11943691,2002,"A reduced risk for Parkinson's disease (PD) among cigarette smokers has been observed consistently during the past 30 years. Recent evidence suggests that caffeine may also be protective. Findings are presented regarding associations of PD with smoking, caffeine intake, and alcohol consumption from a case-control study conducted in western Washington State in 1992-2000. Incident PD cases (n = 210) and controls (n = 347), frequency matched on gender and age were identified from enrollees of the Group Health Cooperative health maintenance organization. Exposure data were obtained by in-person questionnaires. Ever having smoked cigarettes was associated with a reduced risk of PD (odds ratio (OR) = 0.5, 95% confidence interval (CI): 0.4, 0.8). A stronger relation was found among current smokers (OR = 0.3, 95% CI: 0.1, 0.7) than among ex-smokers (OR = 0.6, 95% CI: 0.4, 0.9), and there was an inverse gradient with pack-years smoked (trend p < 0.001). No associations were detected for coffee consumption or total caffeine intake or for alcohol consumption. However, reduced risks were observed for consumption of 2 cups/day or more of tea (OR = 0.4, 95% CI: 0.2, 0.9) and two or more cola drinks/day (OR = 0.6, 95% CI: 0.3, 1.4). The associations for tea and cola drinks were not confounded by smoking or coffee consumption.","Parkinson's disease risks associated with cigarette smoking, alcohol consumption, and caffeine intake."
"186","American Journal of Epidemiology.23","NA",11943691,2002,"A reduced risk for Parkinson's disease (PD) among cigarette smokers has been observed consistently during the past 30 years. Recent evidence suggests that caffeine may also be protective. Findings are presented regarding associations of PD with smoking, caffeine intake, and alcohol consumption from a case-control study conducted in western Washington State in 1992-2000. Incident PD cases (n = 210) and controls (n = 347), frequency matched on gender and age were identified from enrollees of the Group Health Cooperative health maintenance organization. Exposure data were obtained by in-person questionnaires. Ever having smoked cigarettes was associated with a reduced risk of PD (odds ratio (OR) = 0.5, 95% confidence interval (CI): 0.4, 0.8). A stronger relation was found among current smokers (OR = 0.3, 95% CI: 0.1, 0.7) than among ex-smokers (OR = 0.6, 95% CI: 0.4, 0.9), and there was an inverse gradient with pack-years smoked (trend p < 0.001). No associations were detected for coffee consumption or total caffeine intake or for alcohol consumption. However, reduced risks were observed for consumption of 2 cups/day or more of tea (OR = 0.4, 95% CI: 0.2, 0.9) and two or more cola drinks/day (OR = 0.6, 95% CI: 0.3, 1.4). The associations for tea and cola drinks were not confounded by smoking or coffee consumption.","Parkinson's disease risks associated with cigarette smoking, alcohol consumption, and caffeine intake."
"187","JAMA.110","NA",11966384,2002,"Illness and hospitalization often trigger functional decline among older persons. Home care services implemented for functional decline provide an opportunity to intervene to improve outcomes.To compare functional status and the likelihood of remaining at home for persons receiving restorative care vs usual home care.Intervention using prospective individual matching conducted between November 1, 1998, and April 30, 2000. Six offices of a home care agency in Connecticut were used. One branch office served as the restorative care unit and the other 5 served as usual care offices.Patients receiving home care through the restorative care office who were 65 years or older; in receipt of Medicare-covered home care lasting at least 7 days; with absence of severe cognitive impairment; and not terminal, bedridden, or requiring total care were matched with patients from 1 of the usual care offices. The matching factors included age, sex, race, baseline self-care function, cognitive status, whether hospitalization preceded the home care episode, and date of the home care episode. Of the 712 eligible restorative care patients, 691 (97%) were matched with a usual care patient.Restorative care, provided by the home care agency nursing, therapy, and home health aide staff, was based on principles from geriatric medicine, nursing, rehabilitation, and goal attainment.Remaining at home, functional status at completion of the home care episode, and duration and intensity of home care episode.Compared with usual care, and after adjusting for baseline characteristics and other factors, restorative care was associated with a greater likelihood of remaining at home (82% vs 71%; odds ratio [OR], 1.99; 95% confidence interval [CI], 1.47-2.69) and a reduced likelihood of visiting an emergency department (10% vs 20%; OR, 0.44; 95% CI, 0.32-0.61). Home care episodes were shorter (mean [SD], 24.8 [26.8] days vs 34.3 [44.2] days; S = -17 821; P<.001). Restorative care patients had better mean (SD) scores than usual care patients in self-care (11.0 [2.1] vs 10.7 [2.5]; P =.07 after adjustment), home management (9.5 [2.9] vs 9.2 [3.0]; P =.05 after adjustment), and mobility (3.3 [0.8] vs 3.2 [0.9]; P =.02 after adjustment).This trial suggests that reorganizing the structure and goals of home care can enhance health outcomes of older patients without increasing health care utilization.","Evaluation of restorative care vs usual care for older adults receiving an acute episode of home care."
"188","JAMA.133","NA",11966384,2002,"Illness and hospitalization often trigger functional decline among older persons. Home care services implemented for functional decline provide an opportunity to intervene to improve outcomes.To compare functional status and the likelihood of remaining at home for persons receiving restorative care vs usual home care.Intervention using prospective individual matching conducted between November 1, 1998, and April 30, 2000. Six offices of a home care agency in Connecticut were used. One branch office served as the restorative care unit and the other 5 served as usual care offices.Patients receiving home care through the restorative care office who were 65 years or older; in receipt of Medicare-covered home care lasting at least 7 days; with absence of severe cognitive impairment; and not terminal, bedridden, or requiring total care were matched with patients from 1 of the usual care offices. The matching factors included age, sex, race, baseline self-care function, cognitive status, whether hospitalization preceded the home care episode, and date of the home care episode. Of the 712 eligible restorative care patients, 691 (97%) were matched with a usual care patient.Restorative care, provided by the home care agency nursing, therapy, and home health aide staff, was based on principles from geriatric medicine, nursing, rehabilitation, and goal attainment.Remaining at home, functional status at completion of the home care episode, and duration and intensity of home care episode.Compared with usual care, and after adjusting for baseline characteristics and other factors, restorative care was associated with a greater likelihood of remaining at home (82% vs 71%; odds ratio [OR], 1.99; 95% confidence interval [CI], 1.47-2.69) and a reduced likelihood of visiting an emergency department (10% vs 20%; OR, 0.44; 95% CI, 0.32-0.61). Home care episodes were shorter (mean [SD], 24.8 [26.8] days vs 34.3 [44.2] days; S = -17 821; P<.001). Restorative care patients had better mean (SD) scores than usual care patients in self-care (11.0 [2.1] vs 10.7 [2.5]; P =.07 after adjustment), home management (9.5 [2.9] vs 9.2 [3.0]; P =.05 after adjustment), and mobility (3.3 [0.8] vs 3.2 [0.9]; P =.02 after adjustment).This trial suggests that reorganizing the structure and goals of home care can enhance health outcomes of older patients without increasing health care utilization.","Evaluation of restorative care vs usual care for older adults receiving an acute episode of home care."
"189","JAMA.107","NA",11980522,2002,"beta-Blockade therapy has recently been shown to convey a survival benefit in preoperative noncardiac vascular surgical settings. The effect of preoperative beta-blocker therapy on coronary artery bypass graft surgery (CABG) outcomes has not been assessed.To examine patterns of use of preoperative beta-blockers in patients undergoing isolated CABG and to determine whether use of beta-blockers is associated with lower operative mortality and morbidity.Observational study using the Society of Thoracic Surgeons National Adult Cardiac Surgery Database (NCD) to assess beta-blocker use and outcomes among 629 877 patients undergoing isolated CABG between 1996 and 1999 at 497 US and Canadian sites.Influence of beta-blockers on operative mortality, examined using both direct risk adjustment and a matched-pairs analysis based on propensity for preoperative beta-blocker therapy.From 1996 to 1999, overall use of preoperative beta-blockers increased from 50% to 60% in the NCD (P<.001 for time trend). Major predictors of use included recent myocardial infarction; hypertension; worse angina; younger age; better left ventricular systolic function; and absence of congestive heart failure, chronic lung disease, and diabetes. Patients who received beta-blockers had lower mortality than those who did not (unadjusted 30-day mortality, 2.8% vs 3.4%; odds ratio [OR], 0.80; 95% confidence interval [CI], 0.78-0.82). Preoperative beta-blocker use remained associated with slightly lower mortality after adjusting for patient risk and center effects using both risk adjustment (OR, 0.94; 95% CI, 0.91-0.97) and treatment propensity matching (OR, 0.97; 95% CI, 0.93-1.00). Procedural complications also tended to be lower among treated patients. This treatment advantage was seen among the majority of patient subgroups, including women; elderly persons; and those with chronic lung disease, diabetes, or moderately depressed ventricular function. Among patients with a left ventricular ejection fraction of less than 30%, however, preoperative beta-blocker therapy was associated with a trend toward a higher mortality rate (OR, 1.13; 95% CI, 0.96-1.33; P =.23).In this large North American observational analysis, preoperative beta-blocker therapy was associated with a small but consistent survival benefit for patients undergoing CABG, except among patients with a left ventricular ejection fraction of less than 30%. This analysis further suggests that preoperative beta-blocker therapy may be a useful process measure for CABG quality improvement assessment.","Preoperative beta-blocker use and mortality and morbidity following CABG surgery in North America."
"190","JAMA.108","NA",11980522,2002,"beta-Blockade therapy has recently been shown to convey a survival benefit in preoperative noncardiac vascular surgical settings. The effect of preoperative beta-blocker therapy on coronary artery bypass graft surgery (CABG) outcomes has not been assessed.To examine patterns of use of preoperative beta-blockers in patients undergoing isolated CABG and to determine whether use of beta-blockers is associated with lower operative mortality and morbidity.Observational study using the Society of Thoracic Surgeons National Adult Cardiac Surgery Database (NCD) to assess beta-blocker use and outcomes among 629 877 patients undergoing isolated CABG between 1996 and 1999 at 497 US and Canadian sites.Influence of beta-blockers on operative mortality, examined using both direct risk adjustment and a matched-pairs analysis based on propensity for preoperative beta-blocker therapy.From 1996 to 1999, overall use of preoperative beta-blockers increased from 50% to 60% in the NCD (P<.001 for time trend). Major predictors of use included recent myocardial infarction; hypertension; worse angina; younger age; better left ventricular systolic function; and absence of congestive heart failure, chronic lung disease, and diabetes. Patients who received beta-blockers had lower mortality than those who did not (unadjusted 30-day mortality, 2.8% vs 3.4%; odds ratio [OR], 0.80; 95% confidence interval [CI], 0.78-0.82). Preoperative beta-blocker use remained associated with slightly lower mortality after adjusting for patient risk and center effects using both risk adjustment (OR, 0.94; 95% CI, 0.91-0.97) and treatment propensity matching (OR, 0.97; 95% CI, 0.93-1.00). Procedural complications also tended to be lower among treated patients. This treatment advantage was seen among the majority of patient subgroups, including women; elderly persons; and those with chronic lung disease, diabetes, or moderately depressed ventricular function. Among patients with a left ventricular ejection fraction of less than 30%, however, preoperative beta-blocker therapy was associated with a trend toward a higher mortality rate (OR, 1.13; 95% CI, 0.96-1.33; P =.23).In this large North American observational analysis, preoperative beta-blocker therapy was associated with a small but consistent survival benefit for patients undergoing CABG, except among patients with a left ventricular ejection fraction of less than 30%. This analysis further suggests that preoperative beta-blocker therapy may be a useful process measure for CABG quality improvement assessment.","Preoperative beta-blocker use and mortality and morbidity following CABG surgery in North America."
"191","JAMA.109","NA",11980522,2002,"beta-Blockade therapy has recently been shown to convey a survival benefit in preoperative noncardiac vascular surgical settings. The effect of preoperative beta-blocker therapy on coronary artery bypass graft surgery (CABG) outcomes has not been assessed.To examine patterns of use of preoperative beta-blockers in patients undergoing isolated CABG and to determine whether use of beta-blockers is associated with lower operative mortality and morbidity.Observational study using the Society of Thoracic Surgeons National Adult Cardiac Surgery Database (NCD) to assess beta-blocker use and outcomes among 629 877 patients undergoing isolated CABG between 1996 and 1999 at 497 US and Canadian sites.Influence of beta-blockers on operative mortality, examined using both direct risk adjustment and a matched-pairs analysis based on propensity for preoperative beta-blocker therapy.From 1996 to 1999, overall use of preoperative beta-blockers increased from 50% to 60% in the NCD (P<.001 for time trend). Major predictors of use included recent myocardial infarction; hypertension; worse angina; younger age; better left ventricular systolic function; and absence of congestive heart failure, chronic lung disease, and diabetes. Patients who received beta-blockers had lower mortality than those who did not (unadjusted 30-day mortality, 2.8% vs 3.4%; odds ratio [OR], 0.80; 95% confidence interval [CI], 0.78-0.82). Preoperative beta-blocker use remained associated with slightly lower mortality after adjusting for patient risk and center effects using both risk adjustment (OR, 0.94; 95% CI, 0.91-0.97) and treatment propensity matching (OR, 0.97; 95% CI, 0.93-1.00). Procedural complications also tended to be lower among treated patients. This treatment advantage was seen among the majority of patient subgroups, including women; elderly persons; and those with chronic lung disease, diabetes, or moderately depressed ventricular function. Among patients with a left ventricular ejection fraction of less than 30%, however, preoperative beta-blocker therapy was associated with a trend toward a higher mortality rate (OR, 1.13; 95% CI, 0.96-1.33; P =.23).In this large North American observational analysis, preoperative beta-blocker therapy was associated with a small but consistent survival benefit for patients undergoing CABG, except among patients with a left ventricular ejection fraction of less than 30%. This analysis further suggests that preoperative beta-blocker therapy may be a useful process measure for CABG quality improvement assessment.","Preoperative beta-blocker use and mortality and morbidity following CABG surgery in North America."
"192","JAMA.132","0.23",11980522,2002,"beta-Blockade therapy has recently been shown to convey a survival benefit in preoperative noncardiac vascular surgical settings. The effect of preoperative beta-blocker therapy on coronary artery bypass graft surgery (CABG) outcomes has not been assessed.To examine patterns of use of preoperative beta-blockers in patients undergoing isolated CABG and to determine whether use of beta-blockers is associated with lower operative mortality and morbidity.Observational study using the Society of Thoracic Surgeons National Adult Cardiac Surgery Database (NCD) to assess beta-blocker use and outcomes among 629 877 patients undergoing isolated CABG between 1996 and 1999 at 497 US and Canadian sites.Influence of beta-blockers on operative mortality, examined using both direct risk adjustment and a matched-pairs analysis based on propensity for preoperative beta-blocker therapy.From 1996 to 1999, overall use of preoperative beta-blockers increased from 50% to 60% in the NCD (P<.001 for time trend). Major predictors of use included recent myocardial infarction; hypertension; worse angina; younger age; better left ventricular systolic function; and absence of congestive heart failure, chronic lung disease, and diabetes. Patients who received beta-blockers had lower mortality than those who did not (unadjusted 30-day mortality, 2.8% vs 3.4%; odds ratio [OR], 0.80; 95% confidence interval [CI], 0.78-0.82). Preoperative beta-blocker use remained associated with slightly lower mortality after adjusting for patient risk and center effects using both risk adjustment (OR, 0.94; 95% CI, 0.91-0.97) and treatment propensity matching (OR, 0.97; 95% CI, 0.93-1.00). Procedural complications also tended to be lower among treated patients. This treatment advantage was seen among the majority of patient subgroups, including women; elderly persons; and those with chronic lung disease, diabetes, or moderately depressed ventricular function. Among patients with a left ventricular ejection fraction of less than 30%, however, preoperative beta-blocker therapy was associated with a trend toward a higher mortality rate (OR, 1.13; 95% CI, 0.96-1.33; P =.23).In this large North American observational analysis, preoperative beta-blocker therapy was associated with a small but consistent survival benefit for patients undergoing CABG, except among patients with a left ventricular ejection fraction of less than 30%. This analysis further suggests that preoperative beta-blocker therapy may be a useful process measure for CABG quality improvement assessment.","Preoperative beta-blocker use and mortality and morbidity following CABG surgery in North America."
"193","American Journal of Epidemiology.24","0.09",12034581,2002,"Epidemiologic studies investigating the relation between individual carotenoids and risk of prostate cancer have produced inconsistent results. To further explore these associations and to search for reasons prostate cancer incidence is over 50% higher in US Blacks than Whites, the authors analyzed the serum levels of individual carotenoids in 209 cases and 228 controls in a US multicenter, population-based case-control study (1986-1989) that included comparable numbers of Black men and White men aged 40-79 years. Lycopene was inversely associated with prostate cancer risk (comparing highest with lowest quartiles, odds ratio (OR) = 0.65, 95% confidence interval (CI): 0.36, 1.15; test for trend, p = 0.09), particularly for aggressive disease (comparing extreme quartiles, OR = 0.37, 95% CI: 0.15, 0.94; test for trend, p = 0.04). Other carotenoids were positively associated with risk. For all carotenoids, patterns were similar for Blacks and Whites. However, in both the controls and the Third National Health and Nutrition Examination Survey, serum lycopene concentrations were significantly lower in Blacks than in Whites, raising the possibility that differences in lycopene exposure may contribute to the racial disparity in incidence. In conclusion, the results, though not statistically significant, suggest that serum lycopene is inversely related to prostate cancer risk in US Blacks and Whites.","Serum lycopene, other serum carotenoids, and risk of prostate cancer in US Blacks and Whites."
"194","American Journal of Epidemiology.25","0.04",12034581,2002,"Epidemiologic studies investigating the relation between individual carotenoids and risk of prostate cancer have produced inconsistent results. To further explore these associations and to search for reasons prostate cancer incidence is over 50% higher in US Blacks than Whites, the authors analyzed the serum levels of individual carotenoids in 209 cases and 228 controls in a US multicenter, population-based case-control study (1986-1989) that included comparable numbers of Black men and White men aged 40-79 years. Lycopene was inversely associated with prostate cancer risk (comparing highest with lowest quartiles, odds ratio (OR) = 0.65, 95% confidence interval (CI): 0.36, 1.15; test for trend, p = 0.09), particularly for aggressive disease (comparing extreme quartiles, OR = 0.37, 95% CI: 0.15, 0.94; test for trend, p = 0.04). Other carotenoids were positively associated with risk. For all carotenoids, patterns were similar for Blacks and Whites. However, in both the controls and the Third National Health and Nutrition Examination Survey, serum lycopene concentrations were significantly lower in Blacks than in Whites, raising the possibility that differences in lycopene exposure may contribute to the racial disparity in incidence. In conclusion, the results, though not statistically significant, suggest that serum lycopene is inversely related to prostate cancer risk in US Blacks and Whites.","Serum lycopene, other serum carotenoids, and risk of prostate cancer in US Blacks and Whites."
"195","JAMA.107","NA",12038913,2002,"To determine author perception of peer review and association between quality of review and author satisfaction.Survey between May 1999 and October 2000 of 897 corresponding authors of manuscripts under consideration by the Annals of Emergency Medicine and had received final editorial decisions during the study period. A total of 576 authors (64%) returned the survey. Using a 5-point Likert scale, the survey assessed differences in satisfaction between authors whose manuscripts were accepted, reviewed and rejected, and rejected without full review. The association of author satisfaction with editor's assessment of review quality, publication decision, author sex, specialty, and publication experience were also assessed.Overall mean (SD) satisfaction score, indicated by agreement with ""My experience with the review process will make me more likely to submit to Annals in the future,"" was 3.1 (1.0) and was significantly higher among authors of accepted papers (3.7 [0.9]) than among either group of rejected papers (rejected/reviewed, 2.8 [1.0]; rejected/no review, 3.0 [0.9]; P.05). Authors whose manuscripts were reviewed and rejected were the least satisfied with the time to decision (rejected/reviewed, 3.0 [1.2] vs accepted, 3.7 [1.0] and rejected/no review, 3.9 [0.9]; P<.05). Those whose papers were rejected without review were the least satisfied with the letter explaining the editorial decision (rejected/no review, 2.8 [1.2] vs accepted, 4.2 [0.7] and rejected/reviewed, 3.1 [1.2]; P<.05). Among respondents whose manuscripts underwent full review (accepted and rejected/reviewed), overall satisfaction was highly associated with acceptance of the manuscript for publication (odds ratio [OR], 6.12; 95% confidence interval [CI], 3.43-10.91) but not with quality rating of reviews (OR, 1.26; 95% CI, 0.84-1.90).Contributor satisfaction with peer review was modest. Authors of rejected manuscripts were dissatisfied with the time to decision and communication from the editor. Author satisfaction is associated with acceptance but not with review quality.","Author perception of peer review: impact of review quality and acceptance on satisfaction."
"196","JAMA.108","NA",12038913,2002,"To determine author perception of peer review and association between quality of review and author satisfaction.Survey between May 1999 and October 2000 of 897 corresponding authors of manuscripts under consideration by the Annals of Emergency Medicine and had received final editorial decisions during the study period. A total of 576 authors (64%) returned the survey. Using a 5-point Likert scale, the survey assessed differences in satisfaction between authors whose manuscripts were accepted, reviewed and rejected, and rejected without full review. The association of author satisfaction with editor's assessment of review quality, publication decision, author sex, specialty, and publication experience were also assessed.Overall mean (SD) satisfaction score, indicated by agreement with ""My experience with the review process will make me more likely to submit to Annals in the future,"" was 3.1 (1.0) and was significantly higher among authors of accepted papers (3.7 [0.9]) than among either group of rejected papers (rejected/reviewed, 2.8 [1.0]; rejected/no review, 3.0 [0.9]; P.05). Authors whose manuscripts were reviewed and rejected were the least satisfied with the time to decision (rejected/reviewed, 3.0 [1.2] vs accepted, 3.7 [1.0] and rejected/no review, 3.9 [0.9]; P<.05). Those whose papers were rejected without review were the least satisfied with the letter explaining the editorial decision (rejected/no review, 2.8 [1.2] vs accepted, 4.2 [0.7] and rejected/reviewed, 3.1 [1.2]; P<.05). Among respondents whose manuscripts underwent full review (accepted and rejected/reviewed), overall satisfaction was highly associated with acceptance of the manuscript for publication (odds ratio [OR], 6.12; 95% confidence interval [CI], 3.43-10.91) but not with quality rating of reviews (OR, 1.26; 95% CI, 0.84-1.90).Contributor satisfaction with peer review was modest. Authors of rejected manuscripts were dissatisfied with the time to decision and communication from the editor. Author satisfaction is associated with acceptance but not with review quality.","Author perception of peer review: impact of review quality and acceptance on satisfaction."
"197","JAMA.106","0.001",12095381,2002,"Management of antiretroviral treatment failure in patients receiving protease inhibitor (PI)-containing regimens is a therapeutic challenge.To assess whether adding a second PI improves antiviral efficacy of a 4-drug combination in patients with virologic failure while taking a PI-containing regimen.Multicenter, randomized, 4-arm trial, double-blind and placebo-controlled for second PI, conducted between October 1998 and April 2000, for which there was a 24-week primary analysis with extension to 48 weeks.Thirty-one participating AIDS (acquired immunodeficiency syndrome) Clinical Trials Units in the United States.A total of 481 human immunodeficiency virus (HIV)-infected persons with prior exposure to a maximum of 3 PIs and viral load above 1000 copies/mL.Selectively randomized assignment (per prior PI exposure) to saquinavir (n = 116); indinavir (n = 69); nelfinavir (n = 139); or placebo twice per day (n = 157); in combination with amprenavir, abacavir, efavirenz, and adefovir dipivoxil.Primary efficacy analysis involved the proportion with viral load below 200 copies/mL at 24 weeks. Other measures were changes in viral load and CD4 cell count from baseline, adverse events, and HIV drug susceptibility.Of 481 patients, 148 (31%) had a viral load below 200 copies/mL at week 24. The proportions of patients with a viral load below 200 copies/mL in the saquinavir, indinavir, nelfinavir, and placebo arms were 34% (40/116), 36% (25/69), 34% (47/139), and 23% (36/157), respectively. The proportion in the combined dual-PI arms was higher than in the amprenavir-plus-placebo arm (35% [112/324] vs 23% [36/157], respectively; P =.002). Overall, a higher proportion of nonnucleoside reverse transcriptase inhibitor (NNRTI)-naive patients had a viral load below 200 copies/mL compared with NNRTI-experienced patients (43% [115/270] vs 16% [33/211], respectively; P<.001). Baseline HIV-1 hypersusceptibility to efavirenz (< or = 0.4-fold difference in susceptibility compared with reference virus) was associated with suppression of viral load at 24 weeks to below 200 copies/mL (odds ratio [OR], 3.49; 95% confidence interval [CI], 1.62-7.33; P =.001), and more than 10-fold reduction in efavirenz susceptibility, with less likelihood of suppression at 24 weeks (OR, 0.28; 95% CI, 0.09-0.87; P =.03).In this study of antiretroviral-experienced patients with advanced immunodeficiency, viral load suppression to below 200 copies/mL was achieved in 31% of patients with regimens containing 4 or 5 new drugs. Use of 2 PIs, being naive to NNRTIs, and baseline hypersusceptibility to efavirenz were associated with a favorable outcome.","Dual vs single protease inhibitor therapy following antiretroviral treatment failure: a randomized trial."
"198","JAMA.130","0.03",12095381,2002,"Management of antiretroviral treatment failure in patients receiving protease inhibitor (PI)-containing regimens is a therapeutic challenge.To assess whether adding a second PI improves antiviral efficacy of a 4-drug combination in patients with virologic failure while taking a PI-containing regimen.Multicenter, randomized, 4-arm trial, double-blind and placebo-controlled for second PI, conducted between October 1998 and April 2000, for which there was a 24-week primary analysis with extension to 48 weeks.Thirty-one participating AIDS (acquired immunodeficiency syndrome) Clinical Trials Units in the United States.A total of 481 human immunodeficiency virus (HIV)-infected persons with prior exposure to a maximum of 3 PIs and viral load above 1000 copies/mL.Selectively randomized assignment (per prior PI exposure) to saquinavir (n = 116); indinavir (n = 69); nelfinavir (n = 139); or placebo twice per day (n = 157); in combination with amprenavir, abacavir, efavirenz, and adefovir dipivoxil.Primary efficacy analysis involved the proportion with viral load below 200 copies/mL at 24 weeks. Other measures were changes in viral load and CD4 cell count from baseline, adverse events, and HIV drug susceptibility.Of 481 patients, 148 (31%) had a viral load below 200 copies/mL at week 24. The proportions of patients with a viral load below 200 copies/mL in the saquinavir, indinavir, nelfinavir, and placebo arms were 34% (40/116), 36% (25/69), 34% (47/139), and 23% (36/157), respectively. The proportion in the combined dual-PI arms was higher than in the amprenavir-plus-placebo arm (35% [112/324] vs 23% [36/157], respectively; P =.002). Overall, a higher proportion of nonnucleoside reverse transcriptase inhibitor (NNRTI)-naive patients had a viral load below 200 copies/mL compared with NNRTI-experienced patients (43% [115/270] vs 16% [33/211], respectively; P<.001). Baseline HIV-1 hypersusceptibility to efavirenz (< or = 0.4-fold difference in susceptibility compared with reference virus) was associated with suppression of viral load at 24 weeks to below 200 copies/mL (odds ratio [OR], 3.49; 95% confidence interval [CI], 1.62-7.33; P =.001), and more than 10-fold reduction in efavirenz susceptibility, with less likelihood of suppression at 24 weeks (OR, 0.28; 95% CI, 0.09-0.87; P =.03).In this study of antiretroviral-experienced patients with advanced immunodeficiency, viral load suppression to below 200 copies/mL was achieved in 31% of patients with regimens containing 4 or 5 new drugs. Use of 2 PIs, being naive to NNRTIs, and baseline hypersusceptibility to efavirenz were associated with a favorable outcome.","Dual vs single protease inhibitor therapy following antiretroviral treatment failure: a randomized trial."
"199","JAMA.125","0.05",12132978,2002,"Health literacy is a measure of patients' ability to read, comprehend, and act on medical instructions. Poor health literacy is common among racial and ethnic minorities, elderly persons, and patients with chronic conditions, particularly in public-sector settings. Little is known about the extent to which health literacy affects clinical health outcomes.To examine the association between health literacy and diabetes outcomes among patients with type 2 diabetes.Cross-sectional observational study of 408 English- and Spanish-speaking patients who were older than 30 years and had type 2 diabetes identified from the clinical database of 2 primary care clinics of a university-affiliated public hospital in San Francisco, Calif. Participants were enrolled and completed questionnaires between June and December 2000. We assessed patients' health literacy by using the short-form Test of Functional Health Literacy in Adults (s-TOFHLA) in English or Spanish.Most recent hemoglobin A(1c) (HbA(1c)) level. Patients were classified as having tight glycemic control if their HbA(1c) was in the lowest quartile and poor control if it was in the highest quartile. We also measured the presence of self-reported diabetes complications.After adjusting for patients' sociodemographic characteristics, depressive symptoms, social support, treatment regimen, and years with diabetes, for each 1-point decrement in s-TOFHLA score, the HbA(1c) value increased by 0.02 (P =.02). Patients with inadequate health literacy were less likely than patients with adequate health literacy to achieve tight glycemic control (HbA(1c) < or = 7.2%; adjusted odds ratio [OR], 0.57; 95% confidence interval [CI], 0.32-1.00; P =.05) and were more likely to have poor glycemic control (HbA(1c) > or = 9.5%; adjusted OR, 2.03; 95% CI, 1.11-3.73; P =.02) and to report having retinopathy (adjusted OR, 2.33; 95% CI, 1.19-4.57; P =.01).Among primary care patients with type 2 diabetes, inadequate health literacy is independently associated with worse glycemic control and higher rates of retinopathy. Inadequate health literacy may contribute to the disproportionate burden of diabetes-related problems among disadvantaged populations. Efforts should focus on developing and evaluating interventions to improve diabetes outcomes among patients with inadequate health literacy.","Association of health literacy with diabetes outcomes."
"200","JAMA.126","0.02",12132978,2002,"Health literacy is a measure of patients' ability to read, comprehend, and act on medical instructions. Poor health literacy is common among racial and ethnic minorities, elderly persons, and patients with chronic conditions, particularly in public-sector settings. Little is known about the extent to which health literacy affects clinical health outcomes.To examine the association between health literacy and diabetes outcomes among patients with type 2 diabetes.Cross-sectional observational study of 408 English- and Spanish-speaking patients who were older than 30 years and had type 2 diabetes identified from the clinical database of 2 primary care clinics of a university-affiliated public hospital in San Francisco, Calif. Participants were enrolled and completed questionnaires between June and December 2000. We assessed patients' health literacy by using the short-form Test of Functional Health Literacy in Adults (s-TOFHLA) in English or Spanish.Most recent hemoglobin A(1c) (HbA(1c)) level. Patients were classified as having tight glycemic control if their HbA(1c) was in the lowest quartile and poor control if it was in the highest quartile. We also measured the presence of self-reported diabetes complications.After adjusting for patients' sociodemographic characteristics, depressive symptoms, social support, treatment regimen, and years with diabetes, for each 1-point decrement in s-TOFHLA score, the HbA(1c) value increased by 0.02 (P =.02). Patients with inadequate health literacy were less likely than patients with adequate health literacy to achieve tight glycemic control (HbA(1c) < or = 7.2%; adjusted odds ratio [OR], 0.57; 95% confidence interval [CI], 0.32-1.00; P =.05) and were more likely to have poor glycemic control (HbA(1c) > or = 9.5%; adjusted OR, 2.03; 95% CI, 1.11-3.73; P =.02) and to report having retinopathy (adjusted OR, 2.33; 95% CI, 1.19-4.57; P =.01).Among primary care patients with type 2 diabetes, inadequate health literacy is independently associated with worse glycemic control and higher rates of retinopathy. Inadequate health literacy may contribute to the disproportionate burden of diabetes-related problems among disadvantaged populations. Efforts should focus on developing and evaluating interventions to improve diabetes outcomes among patients with inadequate health literacy.","Association of health literacy with diabetes outcomes."
"201","JAMA.127","0.01",12132978,2002,"Health literacy is a measure of patients' ability to read, comprehend, and act on medical instructions. Poor health literacy is common among racial and ethnic minorities, elderly persons, and patients with chronic conditions, particularly in public-sector settings. Little is known about the extent to which health literacy affects clinical health outcomes.To examine the association between health literacy and diabetes outcomes among patients with type 2 diabetes.Cross-sectional observational study of 408 English- and Spanish-speaking patients who were older than 30 years and had type 2 diabetes identified from the clinical database of 2 primary care clinics of a university-affiliated public hospital in San Francisco, Calif. Participants were enrolled and completed questionnaires between June and December 2000. We assessed patients' health literacy by using the short-form Test of Functional Health Literacy in Adults (s-TOFHLA) in English or Spanish.Most recent hemoglobin A(1c) (HbA(1c)) level. Patients were classified as having tight glycemic control if their HbA(1c) was in the lowest quartile and poor control if it was in the highest quartile. We also measured the presence of self-reported diabetes complications.After adjusting for patients' sociodemographic characteristics, depressive symptoms, social support, treatment regimen, and years with diabetes, for each 1-point decrement in s-TOFHLA score, the HbA(1c) value increased by 0.02 (P =.02). Patients with inadequate health literacy were less likely than patients with adequate health literacy to achieve tight glycemic control (HbA(1c) < or = 7.2%; adjusted odds ratio [OR], 0.57; 95% confidence interval [CI], 0.32-1.00; P =.05) and were more likely to have poor glycemic control (HbA(1c) > or = 9.5%; adjusted OR, 2.03; 95% CI, 1.11-3.73; P =.02) and to report having retinopathy (adjusted OR, 2.33; 95% CI, 1.19-4.57; P =.01).Among primary care patients with type 2 diabetes, inadequate health literacy is independently associated with worse glycemic control and higher rates of retinopathy. Inadequate health literacy may contribute to the disproportionate burden of diabetes-related problems among disadvantaged populations. Efforts should focus on developing and evaluating interventions to improve diabetes outcomes among patients with inadequate health literacy.","Association of health literacy with diabetes outcomes."
"202","American Journal of Epidemiology.19","0.01",12142256,2002,"Congress enacted the Americans with Disabilities Act (ADA) to provide persons living with the human immunodeficiency virus (HIV) and other vulnerable populations with legal means of redress against discrimination, yet virtually nothing is known about how the intended beneficiaries have used these protections. This study aimed to describe the epidemiology of ADA charges alleging employment-related discrimination due to HIV and to investigate the charge-filing behavior of workers with HIV. Using a national database of all HIV discrimination charges filed since the inception of the ADA in 1991, the author described respondent employers, issues in dispute, and outcomes of charges. Next, he used multivariate regression analyses to compare the sociodemographic characteristics of charge filers with those of a nationally representative baseline sample of workers with HIV. Of the 3,520 HIV discrimination charges filed through 1999, 18.0% had merit and 14.1% received monetary compensation. Workers who were female (odds ratio (OR) = 0.79, p < 0.01), aged less than 25 years (OR = 0.36, p < 0.01), and aged 25-34 years (OR = 0.77, p < 0.01) filed disproportionately fewer charges. Controlling for underlying rates of discrimination in the baseline population magnified this ""underclaiming"" among young workers. The findings should help to target dissemination and support activities, designed to help workers take advantage of antidiscrimination protections, at the subgroups of workers who need them most.","Charges of human immunodeficiency virus discrimination in the workplace: the Americans with Disabilities Act in action."
"203","American Journal of Epidemiology.20","0.01",12142256,2002,"Congress enacted the Americans with Disabilities Act (ADA) to provide persons living with the human immunodeficiency virus (HIV) and other vulnerable populations with legal means of redress against discrimination, yet virtually nothing is known about how the intended beneficiaries have used these protections. This study aimed to describe the epidemiology of ADA charges alleging employment-related discrimination due to HIV and to investigate the charge-filing behavior of workers with HIV. Using a national database of all HIV discrimination charges filed since the inception of the ADA in 1991, the author described respondent employers, issues in dispute, and outcomes of charges. Next, he used multivariate regression analyses to compare the sociodemographic characteristics of charge filers with those of a nationally representative baseline sample of workers with HIV. Of the 3,520 HIV discrimination charges filed through 1999, 18.0% had merit and 14.1% received monetary compensation. Workers who were female (odds ratio (OR) = 0.79, p < 0.01), aged less than 25 years (OR = 0.36, p < 0.01), and aged 25-34 years (OR = 0.77, p < 0.01) filed disproportionately fewer charges. Controlling for underlying rates of discrimination in the baseline population magnified this ""underclaiming"" among young workers. The findings should help to target dissemination and support activities, designed to help workers take advantage of antidiscrimination protections, at the subgroups of workers who need them most.","Charges of human immunodeficiency virus discrimination in the workplace: the Americans with Disabilities Act in action."
"204","American Journal of Epidemiology.21","0.01",12142256,2002,"Congress enacted the Americans with Disabilities Act (ADA) to provide persons living with the human immunodeficiency virus (HIV) and other vulnerable populations with legal means of redress against discrimination, yet virtually nothing is known about how the intended beneficiaries have used these protections. This study aimed to describe the epidemiology of ADA charges alleging employment-related discrimination due to HIV and to investigate the charge-filing behavior of workers with HIV. Using a national database of all HIV discrimination charges filed since the inception of the ADA in 1991, the author described respondent employers, issues in dispute, and outcomes of charges. Next, he used multivariate regression analyses to compare the sociodemographic characteristics of charge filers with those of a nationally representative baseline sample of workers with HIV. Of the 3,520 HIV discrimination charges filed through 1999, 18.0% had merit and 14.1% received monetary compensation. Workers who were female (odds ratio (OR) = 0.79, p < 0.01), aged less than 25 years (OR = 0.36, p < 0.01), and aged 25-34 years (OR = 0.77, p < 0.01) filed disproportionately fewer charges. Controlling for underlying rates of discrimination in the baseline population magnified this ""underclaiming"" among young workers. The findings should help to target dissemination and support activities, designed to help workers take advantage of antidiscrimination protections, at the subgroups of workers who need them most.","Charges of human immunodeficiency virus discrimination in the workplace: the Americans with Disabilities Act in action."
"205","JAMA.104","0.001",12190368,2002,"Postmenopausal hormone replacement therapy (HRT) has been shown to elevate C-reactive protein (CRP) levels. Several inflammatory biomarkers, including CRP, are associated with increased cardiovascular risk. However, whether the effect of HRT on CRP represents a clinical hazard is unknown.To assess the association between baseline levels of CRP and interleukin 6 (IL-6) and incident coronary heart disease (CHD) and to examine the relationship between baseline use of HRT, CRP, and IL-6 levels as they relate to subsequent vascular risk.Prospective, nested case-control study of postmenopausal women, forming part of the Women's Health Initiative, a large, nationwide, observational study. Among 75 343 women with no history of cardiovascular disease or cancer, 304 women who developed incident CHD were defined as cases and matched by age, smoking status, ethnicity, and follow-up time with 304 study participants who remained event free during a median observation period of 2.9 years.Incidence of first myocardial infarction or death from CHD.Median baseline levels of CRP (0.33 vs 0.25 mg/dL; interquartile range [IQR], 0.14-0.71 vs 0.10-0.47; P<.001) and IL-6 (1.81 vs 1.47 pg/mL; IQR, 1.30-2.75 vs 1.05-2.15; P<.001) were significantly higher among cases compared with controls. In matched analyses, the odds ratio (OR) for incident CHD in the highest vs lowest quartile was 2.3 for CRP (95% confidence interval [CI], 1.4-3.7; P for trend =.002) and 3.3 for IL-6 (95% CI, 2.0-5.5; P for trend <.001). After additional adjustment for lipid and nonlipid risk factors, both inflammatory markers were significantly associated with a 2-fold increase in odds for CHD events. As anticipated, current use of HRT was associated with significantly elevated median CRP levels. However, there was no association between HRT and IL-6. In analyses comparing individuals with comparable baseline levels of either CRP or IL-6, those taking or not taking HRT had similar CHD ORs. In analyses stratified by HRT, we observed a positively graded relationship between plasma CRP levels and the OR for CHD among both users and nonusers of HRT across the full spectrum of baseline CRP.These prospective findings indicate that CRP and IL-6 independently predict vascular events among apparently healthy postmenopausal women and that HRT increases CRP. However, use or nonuse of HRT had less importance as a predictor of cardiovascular risk than did baseline levels of either CRP or IL-6.","Inflammatory biomarkers, hormone replacement therapy, and incident coronary heart disease: prospective analysis from the Women's Health Initiative observational study."
"206","JAMA.105","0.002",12190368,2002,"Postmenopausal hormone replacement therapy (HRT) has been shown to elevate C-reactive protein (CRP) levels. Several inflammatory biomarkers, including CRP, are associated with increased cardiovascular risk. However, whether the effect of HRT on CRP represents a clinical hazard is unknown.To assess the association between baseline levels of CRP and interleukin 6 (IL-6) and incident coronary heart disease (CHD) and to examine the relationship between baseline use of HRT, CRP, and IL-6 levels as they relate to subsequent vascular risk.Prospective, nested case-control study of postmenopausal women, forming part of the Women's Health Initiative, a large, nationwide, observational study. Among 75 343 women with no history of cardiovascular disease or cancer, 304 women who developed incident CHD were defined as cases and matched by age, smoking status, ethnicity, and follow-up time with 304 study participants who remained event free during a median observation period of 2.9 years.Incidence of first myocardial infarction or death from CHD.Median baseline levels of CRP (0.33 vs 0.25 mg/dL; interquartile range [IQR], 0.14-0.71 vs 0.10-0.47; P<.001) and IL-6 (1.81 vs 1.47 pg/mL; IQR, 1.30-2.75 vs 1.05-2.15; P<.001) were significantly higher among cases compared with controls. In matched analyses, the odds ratio (OR) for incident CHD in the highest vs lowest quartile was 2.3 for CRP (95% confidence interval [CI], 1.4-3.7; P for trend =.002) and 3.3 for IL-6 (95% CI, 2.0-5.5; P for trend <.001). After additional adjustment for lipid and nonlipid risk factors, both inflammatory markers were significantly associated with a 2-fold increase in odds for CHD events. As anticipated, current use of HRT was associated with significantly elevated median CRP levels. However, there was no association between HRT and IL-6. In analyses comparing individuals with comparable baseline levels of either CRP or IL-6, those taking or not taking HRT had similar CHD ORs. In analyses stratified by HRT, we observed a positively graded relationship between plasma CRP levels and the OR for CHD among both users and nonusers of HRT across the full spectrum of baseline CRP.These prospective findings indicate that CRP and IL-6 independently predict vascular events among apparently healthy postmenopausal women and that HRT increases CRP. However, use or nonuse of HRT had less importance as a predictor of cardiovascular risk than did baseline levels of either CRP or IL-6.","Inflammatory biomarkers, hormone replacement therapy, and incident coronary heart disease: prospective analysis from the Women's Health Initiative observational study."
"207","JAMA.5610","0.001",12350190,2002,"It is not known whether patient outcomes are enhanced by effective pharmacist-patient interactions.To assess the effectiveness of a pharmaceutical care program for patients with asthma or chronic obstructive pulmonary disease (COPD).Randomized controlled trial conducted at 36 community drugstores in Indianapolis, Ind. We enrolled 1113 participants with active COPD or asthma from July 1998 to December 1999. Outcomes were assessed in 947 (85.1%) participants at 6 months and 898 (80.7%) at 12 months.The pharmaceutical care program (n = 447) provided pharmacists with recent patient-specific clinical data (peak expiratory flow rates [PEFRs], emergency department [ED] visits, hospitalizations, and medication compliance), training, customized patient educational materials, and resources to facilitate program implementation. The PEFR monitoring control group (n = 363) received a peak flow meter, instructions about its use, and monthly calls to elicit PEFRs. However, PEFR data were not provided to the pharmacist. Patients in the usual care group (n = 303) received neither peak flow meters nor instructions in their use; during monthly telephone interviews, PEFR rates were not elicited. Pharmacists in both control groups had a training session but received no components of the pharmaceutical care intervention.Peak expiratory flow rates, breathing-related ED or hospital visits, health-related quality of life (HRQOL), medication compliance, and patient satisfaction.At 12 months, patients receiving pharmaceutical care had significantly higher peak flow rates than the usual care group (P =.02) but not than PEFR monitoring controls (P =.28). There were no significant between-group differences in medication compliance or HRQOL. Asthma patients receiving pharmaceutical care had significantly more breathing-related ED or hospital visits than the usual care group (odds ratio, 2.16; 95% confidence interval, 1.76-2.63; P<.001). Patients receiving pharmaceutical care were more satisfied with their pharmacist than the usual care group (P =.03) and the PEFR monitoring group (P =.001) and were more satisfied with their health care than the usual care group at 6 months only (P =.01). Despite ample opportunities to implement the program, pharmacists accessed patient-specific data only about half of the time and documented actions about half of the time that records were accessed.This pharmaceutical care program increased patients' PEFRs compared with usual care but provided little benefit compared with peak flow monitoring alone. Pharmaceutical care increased patient satisfaction but also increased the amount of breathing-related medical care sought.","Effectiveness of pharmacist care for patients with reactive airways disease: a randomized controlled trial."
"208","JAMA.101","0.001",12350191,2002,"Child maltreatment is a significant problem within US society, and minority children have higher rates of substantiated maltreatment than do white children. However, it is unclear whether minority children are abused more frequently than whites or whether their cases are more likely to be reported.To determine whether there are racial differences in the evaluation and Child Protective Services (CPS) reporting of young children hospitalized for fractures.Retrospective chart review conducted at an urban US academic children's hospital among 388 children younger than 3 years hospitalized for treatment of an acute primary skull or long-bone fracture between 1994 and 2000. Children with perpetrator-admitted child abuse, metabolic bone disease, birth trauma, or injury caused by vehicular crash were excluded.Ordering of skeletal surveys and filing reports of suspected abuse.Reports of suspected abuse were filed for 22.5% of white and 52.9% of minority children (P<.001). Abusive injuries, as determined by expert review, were more common among minority children than among white children (27.6% vs 12.5%; P<.001). Minority children aged at least 12 months to 3 years (toddlers) were significantly more likely to have a skeletal survey performed compared with their white counterparts, even after controlling for insurance status, independent expert determination of likelihood of abuse, and appropriateness of performing a skeletal survey (adjusted odds ratio [OR], 8.75; 95% confidence interval [CI], 3.48-22.03; P<.001). This group of children was also more likely to be reported to CPS compared with white toddlers, even after controlling for insurance status and likelihood of abuse (adjusted OR, 4.32; 95% CI, 1.63-11.43; P =.003). By likelihood of abuse, differential ordering of skeletal surveys and reporting of suspected abuse were most pronounced for children at least 12 months old with accidental injuries; however, differences were also noted among toddlers with indeterminate injuries but not among infants or toddlers with abusive injuries. Minority children at least 12 months old with accidental injuries were more than 3 times more likely than their white counterparts to be reported for suspected abuse (for children with Medicaid or no insurance, relative risk [RR], 3.08; 95% CI, 1.37-4.80; for children with private insurance, RR, 3.74; 95% CI, 1.46-6.01).While minority children had higher rates of abusive fractures in our sample, they were also more likely to be evaluated and reported for suspected abuse, even after controlling for the likelihood of abusive injury. This suggests that racial differences do exist in the evaluation and reporting of pediatric fractures for child abuse, particularly in toddlers with accidental injuries.","Racial differences in the evaluation of pediatric fractures for physical abuse."
"209","JAMA.102","NA",12350191,2002,"Child maltreatment is a significant problem within US society, and minority children have higher rates of substantiated maltreatment than do white children. However, it is unclear whether minority children are abused more frequently than whites or whether their cases are more likely to be reported.To determine whether there are racial differences in the evaluation and Child Protective Services (CPS) reporting of young children hospitalized for fractures.Retrospective chart review conducted at an urban US academic children's hospital among 388 children younger than 3 years hospitalized for treatment of an acute primary skull or long-bone fracture between 1994 and 2000. Children with perpetrator-admitted child abuse, metabolic bone disease, birth trauma, or injury caused by vehicular crash were excluded.Ordering of skeletal surveys and filing reports of suspected abuse.Reports of suspected abuse were filed for 22.5% of white and 52.9% of minority children (P<.001). Abusive injuries, as determined by expert review, were more common among minority children than among white children (27.6% vs 12.5%; P<.001). Minority children aged at least 12 months to 3 years (toddlers) were significantly more likely to have a skeletal survey performed compared with their white counterparts, even after controlling for insurance status, independent expert determination of likelihood of abuse, and appropriateness of performing a skeletal survey (adjusted odds ratio [OR], 8.75; 95% confidence interval [CI], 3.48-22.03; P<.001). This group of children was also more likely to be reported to CPS compared with white toddlers, even after controlling for insurance status and likelihood of abuse (adjusted OR, 4.32; 95% CI, 1.63-11.43; P =.003). By likelihood of abuse, differential ordering of skeletal surveys and reporting of suspected abuse were most pronounced for children at least 12 months old with accidental injuries; however, differences were also noted among toddlers with indeterminate injuries but not among infants or toddlers with abusive injuries. Minority children at least 12 months old with accidental injuries were more than 3 times more likely than their white counterparts to be reported for suspected abuse (for children with Medicaid or no insurance, relative risk [RR], 3.08; 95% CI, 1.37-4.80; for children with private insurance, RR, 3.74; 95% CI, 1.46-6.01).While minority children had higher rates of abusive fractures in our sample, they were also more likely to be evaluated and reported for suspected abuse, even after controlling for the likelihood of abusive injury. This suggests that racial differences do exist in the evaluation and reporting of pediatric fractures for child abuse, particularly in toddlers with accidental injuries.","Racial differences in the evaluation of pediatric fractures for physical abuse."
"210","JAMA.103","NA",12350191,2002,"Child maltreatment is a significant problem within US society, and minority children have higher rates of substantiated maltreatment than do white children. However, it is unclear whether minority children are abused more frequently than whites or whether their cases are more likely to be reported.To determine whether there are racial differences in the evaluation and Child Protective Services (CPS) reporting of young children hospitalized for fractures.Retrospective chart review conducted at an urban US academic children's hospital among 388 children younger than 3 years hospitalized for treatment of an acute primary skull or long-bone fracture between 1994 and 2000. Children with perpetrator-admitted child abuse, metabolic bone disease, birth trauma, or injury caused by vehicular crash were excluded.Ordering of skeletal surveys and filing reports of suspected abuse.Reports of suspected abuse were filed for 22.5% of white and 52.9% of minority children (P<.001). Abusive injuries, as determined by expert review, were more common among minority children than among white children (27.6% vs 12.5%; P<.001). Minority children aged at least 12 months to 3 years (toddlers) were significantly more likely to have a skeletal survey performed compared with their white counterparts, even after controlling for insurance status, independent expert determination of likelihood of abuse, and appropriateness of performing a skeletal survey (adjusted odds ratio [OR], 8.75; 95% confidence interval [CI], 3.48-22.03; P<.001). This group of children was also more likely to be reported to CPS compared with white toddlers, even after controlling for insurance status and likelihood of abuse (adjusted OR, 4.32; 95% CI, 1.63-11.43; P =.003). By likelihood of abuse, differential ordering of skeletal surveys and reporting of suspected abuse were most pronounced for children at least 12 months old with accidental injuries; however, differences were also noted among toddlers with indeterminate injuries but not among infants or toddlers with abusive injuries. Minority children at least 12 months old with accidental injuries were more than 3 times more likely than their white counterparts to be reported for suspected abuse (for children with Medicaid or no insurance, relative risk [RR], 3.08; 95% CI, 1.37-4.80; for children with private insurance, RR, 3.74; 95% CI, 1.46-6.01).While minority children had higher rates of abusive fractures in our sample, they were also more likely to be evaluated and reported for suspected abuse, even after controlling for the likelihood of abusive injury. This suggests that racial differences do exist in the evaluation and reporting of pediatric fractures for child abuse, particularly in toddlers with accidental injuries.","Racial differences in the evaluation of pediatric fractures for physical abuse."
"211","JAMA.119","0.003",12350191,2002,"Child maltreatment is a significant problem within US society, and minority children have higher rates of substantiated maltreatment than do white children. However, it is unclear whether minority children are abused more frequently than whites or whether their cases are more likely to be reported.To determine whether there are racial differences in the evaluation and Child Protective Services (CPS) reporting of young children hospitalized for fractures.Retrospective chart review conducted at an urban US academic children's hospital among 388 children younger than 3 years hospitalized for treatment of an acute primary skull or long-bone fracture between 1994 and 2000. Children with perpetrator-admitted child abuse, metabolic bone disease, birth trauma, or injury caused by vehicular crash were excluded.Ordering of skeletal surveys and filing reports of suspected abuse.Reports of suspected abuse were filed for 22.5% of white and 52.9% of minority children (P<.001). Abusive injuries, as determined by expert review, were more common among minority children than among white children (27.6% vs 12.5%; P<.001). Minority children aged at least 12 months to 3 years (toddlers) were significantly more likely to have a skeletal survey performed compared with their white counterparts, even after controlling for insurance status, independent expert determination of likelihood of abuse, and appropriateness of performing a skeletal survey (adjusted odds ratio [OR], 8.75; 95% confidence interval [CI], 3.48-22.03; P<.001). This group of children was also more likely to be reported to CPS compared with white toddlers, even after controlling for insurance status and likelihood of abuse (adjusted OR, 4.32; 95% CI, 1.63-11.43; P =.003). By likelihood of abuse, differential ordering of skeletal surveys and reporting of suspected abuse were most pronounced for children at least 12 months old with accidental injuries; however, differences were also noted among toddlers with indeterminate injuries but not among infants or toddlers with abusive injuries. Minority children at least 12 months old with accidental injuries were more than 3 times more likely than their white counterparts to be reported for suspected abuse (for children with Medicaid or no insurance, relative risk [RR], 3.08; 95% CI, 1.37-4.80; for children with private insurance, RR, 3.74; 95% CI, 1.46-6.01).While minority children had higher rates of abusive fractures in our sample, they were also more likely to be evaluated and reported for suspected abuse, even after controlling for the likelihood of abusive injury. This suggests that racial differences do exist in the evaluation and reporting of pediatric fractures for child abuse, particularly in toddlers with accidental injuries.","Racial differences in the evaluation of pediatric fractures for physical abuse."
"212","JAMA.97","0.001",12377084,2002,"Certificate of need regulation was designed to control health care costs by preventing health care facilities from expanding unnecessarily. While there have been several studies investigating whether these regulations have affected health care investment, few have evaluated the relationship between certificate of need regulation and quality of care.To compare risk-adjusted mortality and hospital volumes for coronary artery bypass graft (CABG) surgery in states with and without certificate of need regulation.Retrospective cohort study of 911 407 Medicare beneficiaries aged 65 years or older, who underwent CABG surgery between 1994 and 1999 in 1063 US hospitals.States (and the District of Columbia) with continuous (n = 27), none (n = 18), or intermittent (n = 6) certificate of need regulation; mortality (in-hospital or within 30 days of CABG surgery) rates; and mean annual hospital volumes for CABG surgery.Unadjusted mortality was 5.1% in states without certificate of need regulation compared with 4.4% in states with continuous regulation, and 4.3% in states with intermittent certificate of need regulation (P<.001 for each comparison). Adjusting for demographic and clinical factors, mortality remained higher in states without certificate of need regulation compared with states with continuous certificate of need regulation (odds ratio [OR], 1.22; 95% confidence interval [CI], 1.15-1.28; P<.001). Using the same groups for comparison, the mean annual hospital volume for CABG surgery was 84% lower in states without certificate of need regulation (104 vs 191; P<.001) and more patients underwent CABG surgery in low-volume hospitals (<100 procedures annually) (30% vs 10% for states with continuous certificate of need programs; P<.001). Following the repeal of certificate of need regulation in states categorized as intermittent, the percentage of patients undergoing CABG surgery in low-volume hospitals tripled.Mortality rates for Medicare patients undergoing CABG surgery were higher in states without certificate of need regulation. Repeal of certificate of need regulations during the study period was associated with declines in hospital volume for CABG surgery.","Mortality in Medicare beneficiaries following coronary artery bypass graft surgery in states with and without certificate of need regulation."
"213","JAMA.5309","0.99",12413372,2002,"Among patients with acute myocardial infarction, combination reperfusion therapy with a platelet glycoprotein IIb/IIIa receptor inhibitor (abciximab) and a half dose of a plasminogen activator (reteplase) did not significantly reduce mortality at 30 days compared with a full dose of reteplase. Rates of nonfatal ischemic complications were significantly diminished.To determine if the beneficial effects of abciximab and reteplase (combination therapy) on early nonfatal complications would translate into a reduction in the risk of death by 1 year.One-year follow-up of a randomized controlled trial (Global Use of Strategies To Open Coronary Arteries [GUSTO] V). Of 16 588 patients who had been treated in 820 community and referral hospitals in 20 countries between July 1999 and February 2001, mortality data were available for 16 453 (99.2%).Patients were randomly assigned to receive (intravenously) a standard dose of reteplase (two 10-U boluses, 30 minutes apart) or the combination of a standard dose of abciximab (0.25 mg/kg bolus, 0.125 microg/kg per minute infusion [maximum 10 micro g/min for 12 hours]) and a half dose of reteplase (two 5-U boluses, 30 minutes apart).One-year all-cause mortality rates.All-cause mortality at 1 year occurred in 692 (8.38%) of 8260 patients in the reteplase group and 698 (8.38%) of the 8328 patients in the combination therapy group (hazard ratio [HR], 1.00; 95% confidence interval [CI], 0.90-1.11; P>.99). Reinfarction within the first 7 days occurred in 3.5% of patients in the reteplase group and 2.3% of patients in the combination therapy group, and was significantly associated with 1-year mortality (22.6% in patients with reinfarction vs 8.0% in patients without reinfarction; HR, 3.08; 95% CI, 2.53-3.75; P<.001). However, treatment assignment did not significantly influence time of mortality regardless of reinfarction status.Combination therapy (abciximab and reteplase) did not reduce mortality over 1 year compared with fibrinolytic therapy with reteplase alone.","Mortality at 1 year with combination platelet glycoprotein IIb/IIIa inhibition and reduced-dose fibrinolytic therapy vs conventional fibrinolytic therapy for acute myocardial infarction: GUSTO V randomized trial."
"214","JAMA.5310","0.001",12413372,2002,"Among patients with acute myocardial infarction, combination reperfusion therapy with a platelet glycoprotein IIb/IIIa receptor inhibitor (abciximab) and a half dose of a plasminogen activator (reteplase) did not significantly reduce mortality at 30 days compared with a full dose of reteplase. Rates of nonfatal ischemic complications were significantly diminished.To determine if the beneficial effects of abciximab and reteplase (combination therapy) on early nonfatal complications would translate into a reduction in the risk of death by 1 year.One-year follow-up of a randomized controlled trial (Global Use of Strategies To Open Coronary Arteries [GUSTO] V). Of 16 588 patients who had been treated in 820 community and referral hospitals in 20 countries between July 1999 and February 2001, mortality data were available for 16 453 (99.2%).Patients were randomly assigned to receive (intravenously) a standard dose of reteplase (two 10-U boluses, 30 minutes apart) or the combination of a standard dose of abciximab (0.25 mg/kg bolus, 0.125 microg/kg per minute infusion [maximum 10 micro g/min for 12 hours]) and a half dose of reteplase (two 5-U boluses, 30 minutes apart).One-year all-cause mortality rates.All-cause mortality at 1 year occurred in 692 (8.38%) of 8260 patients in the reteplase group and 698 (8.38%) of the 8328 patients in the combination therapy group (hazard ratio [HR], 1.00; 95% confidence interval [CI], 0.90-1.11; P>.99). Reinfarction within the first 7 days occurred in 3.5% of patients in the reteplase group and 2.3% of patients in the combination therapy group, and was significantly associated with 1-year mortality (22.6% in patients with reinfarction vs 8.0% in patients without reinfarction; HR, 3.08; 95% CI, 2.53-3.75; P<.001). However, treatment assignment did not significantly influence time of mortality regardless of reinfarction status.Combination therapy (abciximab and reteplase) did not reduce mortality over 1 year compared with fibrinolytic therapy with reteplase alone.","Mortality at 1 year with combination platelet glycoprotein IIb/IIIa inhibition and reduced-dose fibrinolytic therapy vs conventional fibrinolytic therapy for acute myocardial infarction: GUSTO V randomized trial."
"215","JAMA.6110","NA",12435256,2002,"Hormone replacement therapy (HRT) and antioxidant vitamins are widely used for secondary prevention in postmenopausal women with coronary disease, but no clinical trials have demonstrated benefit to support their use.To determine whether HRT or antioxidant vitamin supplements, alone or in combination, influence the progression of coronary artery disease in postmenopausal women, as measured by serial quantitative coronary angiography.The Women's Angiographic Vitamin and Estrogen (WAVE) Trial, a randomized, double-blind trial of 423 postmenopausal women with at least one 15% to 75% coronary stenosis at baseline coronary angiography. The trial was conducted from July 1997 to January 2002 in 7 clinical centers in the United States and Canada.Patients were randomly assigned in a 2 x 2 factorial design to receive either 0.625 mg/d of conjugated equine estrogen (plus 2.5 mg/d of medroxyprogesterone acetate for women who had not had a hysterectomy), or matching placebo, and 400 IU of vitamin E twice daily plus 500 mg of vitamin C twice daily, or placebo.Annualized mean (SD) change in minimum lumen diameter (MLD) from baseline to concluding angiogram of all qualifying coronary lesions averaged for each patient. Patients with intercurrent death or myocardial infarction (MI) were imputed the worst rank of angiographic outcome.The mean (SD) interval between angiograms was 2.8 (0.9) years. Coronary progression, measured in mean (SD) change, worsened with HRT by 0.047 (0.15) mm/y and by 0.024 (0.15) mm/y with HRT placebo (P =.17); and for antioxidant vitamins by 0.044 (0.15) mm/y and with vitamin placebo by 0.028 (0.15) mm/y (P =.32). When patients with intercurrent death or MI were included, the primary outcome showed an increased risk for women in the active HRT group (P =.045), and suggested an increased risk in the active vitamin group (P =.09). Fourteen patients died in the HRT group and 8 in the HRT placebo group (hazard ratio [HR], 1.8; 95% confidence interval [CI], 0.75-4.3), and 16 in the vitamin group and 6 in the vitamin placebo group (HR, 2.8; 95% CI, 1.1-7.2). Death, nonfatal MI, or stroke occurred in 26 HRT patients vs 15 HRT controls (HR, 1.9; 95% CI, 0.97-3.6) and in 26 vitamin patients and 18 vitamin controls (HR, 1.5; 95% CI, 0.80-2.9). There was no interaction between the 2 treatment interventions.In postmenopausal women with coronary disease, neither HRT nor antioxidant vitamin supplements provide cardiovascular benefit. Instead, a potential for harm was suggested with each treatment.","Effects of hormone replacement therapy and antioxidant vitamin supplements on coronary atherosclerosis in postmenopausal women: a randomized controlled trial."
"216","JAMA.6210","NA",12435256,2002,"Hormone replacement therapy (HRT) and antioxidant vitamins are widely used for secondary prevention in postmenopausal women with coronary disease, but no clinical trials have demonstrated benefit to support their use.To determine whether HRT or antioxidant vitamin supplements, alone or in combination, influence the progression of coronary artery disease in postmenopausal women, as measured by serial quantitative coronary angiography.The Women's Angiographic Vitamin and Estrogen (WAVE) Trial, a randomized, double-blind trial of 423 postmenopausal women with at least one 15% to 75% coronary stenosis at baseline coronary angiography. The trial was conducted from July 1997 to January 2002 in 7 clinical centers in the United States and Canada.Patients were randomly assigned in a 2 x 2 factorial design to receive either 0.625 mg/d of conjugated equine estrogen (plus 2.5 mg/d of medroxyprogesterone acetate for women who had not had a hysterectomy), or matching placebo, and 400 IU of vitamin E twice daily plus 500 mg of vitamin C twice daily, or placebo.Annualized mean (SD) change in minimum lumen diameter (MLD) from baseline to concluding angiogram of all qualifying coronary lesions averaged for each patient. Patients with intercurrent death or myocardial infarction (MI) were imputed the worst rank of angiographic outcome.The mean (SD) interval between angiograms was 2.8 (0.9) years. Coronary progression, measured in mean (SD) change, worsened with HRT by 0.047 (0.15) mm/y and by 0.024 (0.15) mm/y with HRT placebo (P =.17); and for antioxidant vitamins by 0.044 (0.15) mm/y and with vitamin placebo by 0.028 (0.15) mm/y (P =.32). When patients with intercurrent death or MI were included, the primary outcome showed an increased risk for women in the active HRT group (P =.045), and suggested an increased risk in the active vitamin group (P =.09). Fourteen patients died in the HRT group and 8 in the HRT placebo group (hazard ratio [HR], 1.8; 95% confidence interval [CI], 0.75-4.3), and 16 in the vitamin group and 6 in the vitamin placebo group (HR, 2.8; 95% CI, 1.1-7.2). Death, nonfatal MI, or stroke occurred in 26 HRT patients vs 15 HRT controls (HR, 1.9; 95% CI, 0.97-3.6) and in 26 vitamin patients and 18 vitamin controls (HR, 1.5; 95% CI, 0.80-2.9). There was no interaction between the 2 treatment interventions.In postmenopausal women with coronary disease, neither HRT nor antioxidant vitamin supplements provide cardiovascular benefit. Instead, a potential for harm was suggested with each treatment.","Effects of hormone replacement therapy and antioxidant vitamin supplements on coronary atherosclerosis in postmenopausal women: a randomized controlled trial."
"217","JAMA.638","NA",12435256,2002,"Hormone replacement therapy (HRT) and antioxidant vitamins are widely used for secondary prevention in postmenopausal women with coronary disease, but no clinical trials have demonstrated benefit to support their use.To determine whether HRT or antioxidant vitamin supplements, alone or in combination, influence the progression of coronary artery disease in postmenopausal women, as measured by serial quantitative coronary angiography.The Women's Angiographic Vitamin and Estrogen (WAVE) Trial, a randomized, double-blind trial of 423 postmenopausal women with at least one 15% to 75% coronary stenosis at baseline coronary angiography. The trial was conducted from July 1997 to January 2002 in 7 clinical centers in the United States and Canada.Patients were randomly assigned in a 2 x 2 factorial design to receive either 0.625 mg/d of conjugated equine estrogen (plus 2.5 mg/d of medroxyprogesterone acetate for women who had not had a hysterectomy), or matching placebo, and 400 IU of vitamin E twice daily plus 500 mg of vitamin C twice daily, or placebo.Annualized mean (SD) change in minimum lumen diameter (MLD) from baseline to concluding angiogram of all qualifying coronary lesions averaged for each patient. Patients with intercurrent death or myocardial infarction (MI) were imputed the worst rank of angiographic outcome.The mean (SD) interval between angiograms was 2.8 (0.9) years. Coronary progression, measured in mean (SD) change, worsened with HRT by 0.047 (0.15) mm/y and by 0.024 (0.15) mm/y with HRT placebo (P =.17); and for antioxidant vitamins by 0.044 (0.15) mm/y and with vitamin placebo by 0.028 (0.15) mm/y (P =.32). When patients with intercurrent death or MI were included, the primary outcome showed an increased risk for women in the active HRT group (P =.045), and suggested an increased risk in the active vitamin group (P =.09). Fourteen patients died in the HRT group and 8 in the HRT placebo group (hazard ratio [HR], 1.8; 95% confidence interval [CI], 0.75-4.3), and 16 in the vitamin group and 6 in the vitamin placebo group (HR, 2.8; 95% CI, 1.1-7.2). Death, nonfatal MI, or stroke occurred in 26 HRT patients vs 15 HRT controls (HR, 1.9; 95% CI, 0.97-3.6) and in 26 vitamin patients and 18 vitamin controls (HR, 1.5; 95% CI, 0.80-2.9). There was no interaction between the 2 treatment interventions.In postmenopausal women with coronary disease, neither HRT nor antioxidant vitamin supplements provide cardiovascular benefit. Instead, a potential for harm was suggested with each treatment.","Effects of hormone replacement therapy and antioxidant vitamin supplements on coronary atherosclerosis in postmenopausal women: a randomized controlled trial."
"218","JAMA.641","NA",12435256,2002,"Hormone replacement therapy (HRT) and antioxidant vitamins are widely used for secondary prevention in postmenopausal women with coronary disease, but no clinical trials have demonstrated benefit to support their use.To determine whether HRT or antioxidant vitamin supplements, alone or in combination, influence the progression of coronary artery disease in postmenopausal women, as measured by serial quantitative coronary angiography.The Women's Angiographic Vitamin and Estrogen (WAVE) Trial, a randomized, double-blind trial of 423 postmenopausal women with at least one 15% to 75% coronary stenosis at baseline coronary angiography. The trial was conducted from July 1997 to January 2002 in 7 clinical centers in the United States and Canada.Patients were randomly assigned in a 2 x 2 factorial design to receive either 0.625 mg/d of conjugated equine estrogen (plus 2.5 mg/d of medroxyprogesterone acetate for women who had not had a hysterectomy), or matching placebo, and 400 IU of vitamin E twice daily plus 500 mg of vitamin C twice daily, or placebo.Annualized mean (SD) change in minimum lumen diameter (MLD) from baseline to concluding angiogram of all qualifying coronary lesions averaged for each patient. Patients with intercurrent death or myocardial infarction (MI) were imputed the worst rank of angiographic outcome.The mean (SD) interval between angiograms was 2.8 (0.9) years. Coronary progression, measured in mean (SD) change, worsened with HRT by 0.047 (0.15) mm/y and by 0.024 (0.15) mm/y with HRT placebo (P =.17); and for antioxidant vitamins by 0.044 (0.15) mm/y and with vitamin placebo by 0.028 (0.15) mm/y (P =.32). When patients with intercurrent death or MI were included, the primary outcome showed an increased risk for women in the active HRT group (P =.045), and suggested an increased risk in the active vitamin group (P =.09). Fourteen patients died in the HRT group and 8 in the HRT placebo group (hazard ratio [HR], 1.8; 95% confidence interval [CI], 0.75-4.3), and 16 in the vitamin group and 6 in the vitamin placebo group (HR, 2.8; 95% CI, 1.1-7.2). Death, nonfatal MI, or stroke occurred in 26 HRT patients vs 15 HRT controls (HR, 1.9; 95% CI, 0.97-3.6) and in 26 vitamin patients and 18 vitamin controls (HR, 1.5; 95% CI, 0.80-2.9). There was no interaction between the 2 treatment interventions.In postmenopausal women with coronary disease, neither HRT nor antioxidant vitamin supplements provide cardiovascular benefit. Instead, a potential for harm was suggested with each treatment.","Effects of hormone replacement therapy and antioxidant vitamin supplements on coronary atherosclerosis in postmenopausal women: a randomized controlled trial."
"219","JAMA.4706","NA",12435257,2002,"Patients with nonvalvular atrial fibrillation (AF) have an increased risk of stroke and other vascular events.To compare the risk of vascular and bleeding events in patients with nonvalvular AF treated with vitamin K -inhibiting oral anticoagulants or acetylsalicylic acid (aspirin).Pooled analysis of patient-level data from 6 published, randomized clinical trials.A total of 4052 patients with AF randomly assigned to receive therapeutic doses of oral anticoagulant or aspirin with or without low-dose oral anticoagulants.Ischemic and hemorrhagic stroke, other cardiovascular events, all-cause death, and major bleeding events. Person-year incidence rates were calculated to provide crude comparisons. Relative efficacy was assessed using proportional hazards modeling stratified by study. The variation of the oral anticoagulant's relative effect by pertinent patient factors was explored with interaction terms. All analyses were conducted using the intention-to-treat principle.Patients receiving oral anticoagulant and aspirin were balanced for important prognostic factors. There was no significant heterogeneity between trials in the relative efficacy of oral anticoagulant vs aspirin for any outcome. Patients receiving oral anticoagulant were significantly less likely to experience any stroke (2.4 vs 4.5 events per 100 patient-years; hazard ratio [HR], 0.55; 95% confidence interval [CI], 0.43-0.71), ischemic stroke (HR, 0.48; 95% CI, 0.37-0.63), or cardiovascular events (HR, 0.71; 95% CI, 0.59-0.85) but were more likely to experience major bleeding (2.2 vs 1.3 events per 100 patient-years; HR, 1.71; 95% CI, 1.21-2.41). The reduction in ischemic stroke risk was similar in patients with paroxysmal AF (1.5 vs 4.7 events per 100 patient-years; HR, 0.32; 95% CI, 0.16-0.61; P<.001). Treating 1000 patients with AF for 1 year with oral anticoagulant rather than aspirin would prevent 23 ischemic strokes while causing 9 additional major bleeds. Overall all-cause survival did not differ but appeared to improve for oral anticoagulant patients 3 years after therapy was started.Compared with aspirin, oral anticoagulant significantly decreases the risk of all strokes, ischemic strokes, and cardiovascular events for patients with nonvalvular chronic or paroxysmal AF but modestly increases the absolute risk of major bleeding. The balance of benefits and risks varies by patient subgroup.","Oral anticoagulants vs aspirin in nonvalvular atrial fibrillation: an individual patient meta-analysis."
"220","JAMA.4707","NA",12435257,2002,"Patients with nonvalvular atrial fibrillation (AF) have an increased risk of stroke and other vascular events.To compare the risk of vascular and bleeding events in patients with nonvalvular AF treated with vitamin K -inhibiting oral anticoagulants or acetylsalicylic acid (aspirin).Pooled analysis of patient-level data from 6 published, randomized clinical trials.A total of 4052 patients with AF randomly assigned to receive therapeutic doses of oral anticoagulant or aspirin with or without low-dose oral anticoagulants.Ischemic and hemorrhagic stroke, other cardiovascular events, all-cause death, and major bleeding events. Person-year incidence rates were calculated to provide crude comparisons. Relative efficacy was assessed using proportional hazards modeling stratified by study. The variation of the oral anticoagulant's relative effect by pertinent patient factors was explored with interaction terms. All analyses were conducted using the intention-to-treat principle.Patients receiving oral anticoagulant and aspirin were balanced for important prognostic factors. There was no significant heterogeneity between trials in the relative efficacy of oral anticoagulant vs aspirin for any outcome. Patients receiving oral anticoagulant were significantly less likely to experience any stroke (2.4 vs 4.5 events per 100 patient-years; hazard ratio [HR], 0.55; 95% confidence interval [CI], 0.43-0.71), ischemic stroke (HR, 0.48; 95% CI, 0.37-0.63), or cardiovascular events (HR, 0.71; 95% CI, 0.59-0.85) but were more likely to experience major bleeding (2.2 vs 1.3 events per 100 patient-years; HR, 1.71; 95% CI, 1.21-2.41). The reduction in ischemic stroke risk was similar in patients with paroxysmal AF (1.5 vs 4.7 events per 100 patient-years; HR, 0.32; 95% CI, 0.16-0.61; P<.001). Treating 1000 patients with AF for 1 year with oral anticoagulant rather than aspirin would prevent 23 ischemic strokes while causing 9 additional major bleeds. Overall all-cause survival did not differ but appeared to improve for oral anticoagulant patients 3 years after therapy was started.Compared with aspirin, oral anticoagulant significantly decreases the risk of all strokes, ischemic strokes, and cardiovascular events for patients with nonvalvular chronic or paroxysmal AF but modestly increases the absolute risk of major bleeding. The balance of benefits and risks varies by patient subgroup.","Oral anticoagulants vs aspirin in nonvalvular atrial fibrillation: an individual patient meta-analysis."
"221","JAMA.4708","NA",12435257,2002,"Patients with nonvalvular atrial fibrillation (AF) have an increased risk of stroke and other vascular events.To compare the risk of vascular and bleeding events in patients with nonvalvular AF treated with vitamin K -inhibiting oral anticoagulants or acetylsalicylic acid (aspirin).Pooled analysis of patient-level data from 6 published, randomized clinical trials.A total of 4052 patients with AF randomly assigned to receive therapeutic doses of oral anticoagulant or aspirin with or without low-dose oral anticoagulants.Ischemic and hemorrhagic stroke, other cardiovascular events, all-cause death, and major bleeding events. Person-year incidence rates were calculated to provide crude comparisons. Relative efficacy was assessed using proportional hazards modeling stratified by study. The variation of the oral anticoagulant's relative effect by pertinent patient factors was explored with interaction terms. All analyses were conducted using the intention-to-treat principle.Patients receiving oral anticoagulant and aspirin were balanced for important prognostic factors. There was no significant heterogeneity between trials in the relative efficacy of oral anticoagulant vs aspirin for any outcome. Patients receiving oral anticoagulant were significantly less likely to experience any stroke (2.4 vs 4.5 events per 100 patient-years; hazard ratio [HR], 0.55; 95% confidence interval [CI], 0.43-0.71), ischemic stroke (HR, 0.48; 95% CI, 0.37-0.63), or cardiovascular events (HR, 0.71; 95% CI, 0.59-0.85) but were more likely to experience major bleeding (2.2 vs 1.3 events per 100 patient-years; HR, 1.71; 95% CI, 1.21-2.41). The reduction in ischemic stroke risk was similar in patients with paroxysmal AF (1.5 vs 4.7 events per 100 patient-years; HR, 0.32; 95% CI, 0.16-0.61; P<.001). Treating 1000 patients with AF for 1 year with oral anticoagulant rather than aspirin would prevent 23 ischemic strokes while causing 9 additional major bleeds. Overall all-cause survival did not differ but appeared to improve for oral anticoagulant patients 3 years after therapy was started.Compared with aspirin, oral anticoagulant significantly decreases the risk of all strokes, ischemic strokes, and cardiovascular events for patients with nonvalvular chronic or paroxysmal AF but modestly increases the absolute risk of major bleeding. The balance of benefits and risks varies by patient subgroup.","Oral anticoagulants vs aspirin in nonvalvular atrial fibrillation: an individual patient meta-analysis."
"222","JAMA.4709","NA",12435257,2002,"Patients with nonvalvular atrial fibrillation (AF) have an increased risk of stroke and other vascular events.To compare the risk of vascular and bleeding events in patients with nonvalvular AF treated with vitamin K -inhibiting oral anticoagulants or acetylsalicylic acid (aspirin).Pooled analysis of patient-level data from 6 published, randomized clinical trials.A total of 4052 patients with AF randomly assigned to receive therapeutic doses of oral anticoagulant or aspirin with or without low-dose oral anticoagulants.Ischemic and hemorrhagic stroke, other cardiovascular events, all-cause death, and major bleeding events. Person-year incidence rates were calculated to provide crude comparisons. Relative efficacy was assessed using proportional hazards modeling stratified by study. The variation of the oral anticoagulant's relative effect by pertinent patient factors was explored with interaction terms. All analyses were conducted using the intention-to-treat principle.Patients receiving oral anticoagulant and aspirin were balanced for important prognostic factors. There was no significant heterogeneity between trials in the relative efficacy of oral anticoagulant vs aspirin for any outcome. Patients receiving oral anticoagulant were significantly less likely to experience any stroke (2.4 vs 4.5 events per 100 patient-years; hazard ratio [HR], 0.55; 95% confidence interval [CI], 0.43-0.71), ischemic stroke (HR, 0.48; 95% CI, 0.37-0.63), or cardiovascular events (HR, 0.71; 95% CI, 0.59-0.85) but were more likely to experience major bleeding (2.2 vs 1.3 events per 100 patient-years; HR, 1.71; 95% CI, 1.21-2.41). The reduction in ischemic stroke risk was similar in patients with paroxysmal AF (1.5 vs 4.7 events per 100 patient-years; HR, 0.32; 95% CI, 0.16-0.61; P<.001). Treating 1000 patients with AF for 1 year with oral anticoagulant rather than aspirin would prevent 23 ischemic strokes while causing 9 additional major bleeds. Overall all-cause survival did not differ but appeared to improve for oral anticoagulant patients 3 years after therapy was started.Compared with aspirin, oral anticoagulant significantly decreases the risk of all strokes, ischemic strokes, and cardiovascular events for patients with nonvalvular chronic or paroxysmal AF but modestly increases the absolute risk of major bleeding. The balance of benefits and risks varies by patient subgroup.","Oral anticoagulants vs aspirin in nonvalvular atrial fibrillation: an individual patient meta-analysis."
"223","JAMA.4710","0.001",12435257,2002,"Patients with nonvalvular atrial fibrillation (AF) have an increased risk of stroke and other vascular events.To compare the risk of vascular and bleeding events in patients with nonvalvular AF treated with vitamin K -inhibiting oral anticoagulants or acetylsalicylic acid (aspirin).Pooled analysis of patient-level data from 6 published, randomized clinical trials.A total of 4052 patients with AF randomly assigned to receive therapeutic doses of oral anticoagulant or aspirin with or without low-dose oral anticoagulants.Ischemic and hemorrhagic stroke, other cardiovascular events, all-cause death, and major bleeding events. Person-year incidence rates were calculated to provide crude comparisons. Relative efficacy was assessed using proportional hazards modeling stratified by study. The variation of the oral anticoagulant's relative effect by pertinent patient factors was explored with interaction terms. All analyses were conducted using the intention-to-treat principle.Patients receiving oral anticoagulant and aspirin were balanced for important prognostic factors. There was no significant heterogeneity between trials in the relative efficacy of oral anticoagulant vs aspirin for any outcome. Patients receiving oral anticoagulant were significantly less likely to experience any stroke (2.4 vs 4.5 events per 100 patient-years; hazard ratio [HR], 0.55; 95% confidence interval [CI], 0.43-0.71), ischemic stroke (HR, 0.48; 95% CI, 0.37-0.63), or cardiovascular events (HR, 0.71; 95% CI, 0.59-0.85) but were more likely to experience major bleeding (2.2 vs 1.3 events per 100 patient-years; HR, 1.71; 95% CI, 1.21-2.41). The reduction in ischemic stroke risk was similar in patients with paroxysmal AF (1.5 vs 4.7 events per 100 patient-years; HR, 0.32; 95% CI, 0.16-0.61; P<.001). Treating 1000 patients with AF for 1 year with oral anticoagulant rather than aspirin would prevent 23 ischemic strokes while causing 9 additional major bleeds. Overall all-cause survival did not differ but appeared to improve for oral anticoagulant patients 3 years after therapy was started.Compared with aspirin, oral anticoagulant significantly decreases the risk of all strokes, ischemic strokes, and cardiovascular events for patients with nonvalvular chronic or paroxysmal AF but modestly increases the absolute risk of major bleeding. The balance of benefits and risks varies by patient subgroup.","Oral anticoagulants vs aspirin in nonvalvular atrial fibrillation: an individual patient meta-analysis."
"224","JAMA.91","0.001",12472325,2002,"Few depressed older adults receive effective treatment in primary care settings.To determine the effectiveness of the Improving Mood-Promoting Access to Collaborative Treatment (IMPACT) collaborative care management program for late-life depression.Randomized controlled trial with recruitment from July 1999 to August 2001.Eighteen primary care clinics from 8 health care organizations in 5 states.A total of 1801 patients aged 60 years or older with major depression (17%), dysthymic disorder (30%), or both (53%).Patients were randomly assigned to the IMPACT intervention (n = 906) or to usual care (n = 895). Intervention patients had access for up to 12 months to a depression care manager who was supervised by a psychiatrist and a primary care expert and who offered education, care management, and support of antidepressant management by the patient's primary care physician or a brief psychotherapy for depression, Problem Solving Treatment in Primary Care.Assessments at baseline and at 3, 6, and 12 months for depression, depression treatments, satisfaction with care, functional impairment, and quality of life.At 12 months, 45% of intervention patients had a 50% or greater reduction in depressive symptoms from baseline compared with 19% of usual care participants (odds ratio [OR], 3.45; 95% confidence interval [CI], 2.71-4.38; P<.001). Intervention patients also experienced greater rates of depression treatment (OR, 2.98; 95% CI, 2.34-3.79; P<.001), more satisfaction with depression care (OR, 3.38; 95% CI, 2.66-4.30; P<.001), lower depression severity (range, 0-4; between-group difference, -0.4; 95% CI, -0.46 to -0.33; P<.001), less functional impairment (range, 0-10; between-group difference, -0.91; 95% CI, -1.19 to -0.64; P<.001), and greater quality of life (range, 0-10; between-group difference, 0.56; 95% CI, 0.32-0.79; P<.001) than participants assigned to the usual care group.The IMPACT collaborative care model appears to be feasible and significantly more effective than usual care for depression in a wide range of primary care practices.","Collaborative care management of late-life depression in the primary care setting: a randomized controlled trial."
"225","JAMA.92","0.001",12472325,2002,"Few depressed older adults receive effective treatment in primary care settings.To determine the effectiveness of the Improving Mood-Promoting Access to Collaborative Treatment (IMPACT) collaborative care management program for late-life depression.Randomized controlled trial with recruitment from July 1999 to August 2001.Eighteen primary care clinics from 8 health care organizations in 5 states.A total of 1801 patients aged 60 years or older with major depression (17%), dysthymic disorder (30%), or both (53%).Patients were randomly assigned to the IMPACT intervention (n = 906) or to usual care (n = 895). Intervention patients had access for up to 12 months to a depression care manager who was supervised by a psychiatrist and a primary care expert and who offered education, care management, and support of antidepressant management by the patient's primary care physician or a brief psychotherapy for depression, Problem Solving Treatment in Primary Care.Assessments at baseline and at 3, 6, and 12 months for depression, depression treatments, satisfaction with care, functional impairment, and quality of life.At 12 months, 45% of intervention patients had a 50% or greater reduction in depressive symptoms from baseline compared with 19% of usual care participants (odds ratio [OR], 3.45; 95% confidence interval [CI], 2.71-4.38; P<.001). Intervention patients also experienced greater rates of depression treatment (OR, 2.98; 95% CI, 2.34-3.79; P<.001), more satisfaction with depression care (OR, 3.38; 95% CI, 2.66-4.30; P<.001), lower depression severity (range, 0-4; between-group difference, -0.4; 95% CI, -0.46 to -0.33; P<.001), less functional impairment (range, 0-10; between-group difference, -0.91; 95% CI, -1.19 to -0.64; P<.001), and greater quality of life (range, 0-10; between-group difference, 0.56; 95% CI, 0.32-0.79; P<.001) than participants assigned to the usual care group.The IMPACT collaborative care model appears to be feasible and significantly more effective than usual care for depression in a wide range of primary care practices.","Collaborative care management of late-life depression in the primary care setting: a randomized controlled trial."
"226","JAMA.93","0.001",12472325,2002,"Few depressed older adults receive effective treatment in primary care settings.To determine the effectiveness of the Improving Mood-Promoting Access to Collaborative Treatment (IMPACT) collaborative care management program for late-life depression.Randomized controlled trial with recruitment from July 1999 to August 2001.Eighteen primary care clinics from 8 health care organizations in 5 states.A total of 1801 patients aged 60 years or older with major depression (17%), dysthymic disorder (30%), or both (53%).Patients were randomly assigned to the IMPACT intervention (n = 906) or to usual care (n = 895). Intervention patients had access for up to 12 months to a depression care manager who was supervised by a psychiatrist and a primary care expert and who offered education, care management, and support of antidepressant management by the patient's primary care physician or a brief psychotherapy for depression, Problem Solving Treatment in Primary Care.Assessments at baseline and at 3, 6, and 12 months for depression, depression treatments, satisfaction with care, functional impairment, and quality of life.At 12 months, 45% of intervention patients had a 50% or greater reduction in depressive symptoms from baseline compared with 19% of usual care participants (odds ratio [OR], 3.45; 95% confidence interval [CI], 2.71-4.38; P<.001). Intervention patients also experienced greater rates of depression treatment (OR, 2.98; 95% CI, 2.34-3.79; P<.001), more satisfaction with depression care (OR, 3.38; 95% CI, 2.66-4.30; P<.001), lower depression severity (range, 0-4; between-group difference, -0.4; 95% CI, -0.46 to -0.33; P<.001), less functional impairment (range, 0-10; between-group difference, -0.91; 95% CI, -1.19 to -0.64; P<.001), and greater quality of life (range, 0-10; between-group difference, 0.56; 95% CI, 0.32-0.79; P<.001) than participants assigned to the usual care group.The IMPACT collaborative care model appears to be feasible and significantly more effective than usual care for depression in a wide range of primary care practices.","Collaborative care management of late-life depression in the primary care setting: a randomized controlled trial."
"227","JAMA.115","NA",12472328,2002,"Although electrophysiologic and histologic neuromuscular abnormalities are common in intensive care unit (ICU) patients, the clinical incidence of ICU-acquired neuromuscular disorders in patients recovering from severe illness remains unknown.To assess the clinical incidence, risk factors, and outcomes of ICU-acquired paresis (ICUAP) during recovery from critical illness in the ICU and to determine the electrophysiologic and histologic patterns in patients with ICUAP.Prospective cohort study conducted from March 1999 to June 2000.Three medical and 2 surgical ICUs in 4 hospitals in France.All consecutive ICU patients without preexisting neuromuscular disease who underwent mechanical ventilation for 7 or more days were screened daily for awakening. The first day a patient was considered awake was day 1. Patients with severe muscle weakness on day 7 were considered to have ICUAP.Incidence and duration of ICUAP, risk factors for ICUAP, and comparative duration of mechanical ventilation between ICUAP and control patients.Among the 95 patients who achieved satisfactory awakening, the incidence of ICUAP was 25.3% (95% confidence interval [CI], 16.9%-35.2%). All ICUAP patients had a sensorimotor axonopathy, and all patients who underwent a muscle biopsy had specific muscle involvement not related to nerve involvement. The median duration of ICUAP after day 1 was 21 days. Mean (SD) duration of mechanical ventilation after day 1 was significantly longer in patients with ICUAP compared with those without (18.2 [36.3] vs 7.6 [19.2] days; P =.03). Independent predictors of ICUAP were female sex (odds ratio [OR], 4.66; 95% CI, 1.19-18.30), the number of days with dysfunction of 2 or more organs (OR, 1.28; 95% CI, 1.11-1.49), duration of mechanical ventilation (OR, 1.10; 95% CI, 1.00-1.22), and administration of corticosteroids (OR, 14.90; 95% CI, 3.20-69.80) before day 1.Identified using simple bedside clinical criteria, ICUAP was frequent during recovery from critical illness and was associated with a prolonged duration of mechanical ventilation. Our findings suggest an important role of corticosteroids in the development of ICUAP.","Paresis acquired in the intensive care unit: a prospective multicenter study."
"228","JAMA.116","NA",12472328,2002,"Although electrophysiologic and histologic neuromuscular abnormalities are common in intensive care unit (ICU) patients, the clinical incidence of ICU-acquired neuromuscular disorders in patients recovering from severe illness remains unknown.To assess the clinical incidence, risk factors, and outcomes of ICU-acquired paresis (ICUAP) during recovery from critical illness in the ICU and to determine the electrophysiologic and histologic patterns in patients with ICUAP.Prospective cohort study conducted from March 1999 to June 2000.Three medical and 2 surgical ICUs in 4 hospitals in France.All consecutive ICU patients without preexisting neuromuscular disease who underwent mechanical ventilation for 7 or more days were screened daily for awakening. The first day a patient was considered awake was day 1. Patients with severe muscle weakness on day 7 were considered to have ICUAP.Incidence and duration of ICUAP, risk factors for ICUAP, and comparative duration of mechanical ventilation between ICUAP and control patients.Among the 95 patients who achieved satisfactory awakening, the incidence of ICUAP was 25.3% (95% confidence interval [CI], 16.9%-35.2%). All ICUAP patients had a sensorimotor axonopathy, and all patients who underwent a muscle biopsy had specific muscle involvement not related to nerve involvement. The median duration of ICUAP after day 1 was 21 days. Mean (SD) duration of mechanical ventilation after day 1 was significantly longer in patients with ICUAP compared with those without (18.2 [36.3] vs 7.6 [19.2] days; P =.03). Independent predictors of ICUAP were female sex (odds ratio [OR], 4.66; 95% CI, 1.19-18.30), the number of days with dysfunction of 2 or more organs (OR, 1.28; 95% CI, 1.11-1.49), duration of mechanical ventilation (OR, 1.10; 95% CI, 1.00-1.22), and administration of corticosteroids (OR, 14.90; 95% CI, 3.20-69.80) before day 1.Identified using simple bedside clinical criteria, ICUAP was frequent during recovery from critical illness and was associated with a prolonged duration of mechanical ventilation. Our findings suggest an important role of corticosteroids in the development of ICUAP.","Paresis acquired in the intensive care unit: a prospective multicenter study."
"229","JAMA.117","NA",12472328,2002,"Although electrophysiologic and histologic neuromuscular abnormalities are common in intensive care unit (ICU) patients, the clinical incidence of ICU-acquired neuromuscular disorders in patients recovering from severe illness remains unknown.To assess the clinical incidence, risk factors, and outcomes of ICU-acquired paresis (ICUAP) during recovery from critical illness in the ICU and to determine the electrophysiologic and histologic patterns in patients with ICUAP.Prospective cohort study conducted from March 1999 to June 2000.Three medical and 2 surgical ICUs in 4 hospitals in France.All consecutive ICU patients without preexisting neuromuscular disease who underwent mechanical ventilation for 7 or more days were screened daily for awakening. The first day a patient was considered awake was day 1. Patients with severe muscle weakness on day 7 were considered to have ICUAP.Incidence and duration of ICUAP, risk factors for ICUAP, and comparative duration of mechanical ventilation between ICUAP and control patients.Among the 95 patients who achieved satisfactory awakening, the incidence of ICUAP was 25.3% (95% confidence interval [CI], 16.9%-35.2%). All ICUAP patients had a sensorimotor axonopathy, and all patients who underwent a muscle biopsy had specific muscle involvement not related to nerve involvement. The median duration of ICUAP after day 1 was 21 days. Mean (SD) duration of mechanical ventilation after day 1 was significantly longer in patients with ICUAP compared with those without (18.2 [36.3] vs 7.6 [19.2] days; P =.03). Independent predictors of ICUAP were female sex (odds ratio [OR], 4.66; 95% CI, 1.19-18.30), the number of days with dysfunction of 2 or more organs (OR, 1.28; 95% CI, 1.11-1.49), duration of mechanical ventilation (OR, 1.10; 95% CI, 1.00-1.22), and administration of corticosteroids (OR, 14.90; 95% CI, 3.20-69.80) before day 1.Identified using simple bedside clinical criteria, ICUAP was frequent during recovery from critical illness and was associated with a prolonged duration of mechanical ventilation. Our findings suggest an important role of corticosteroids in the development of ICUAP.","Paresis acquired in the intensive care unit: a prospective multicenter study."
"230","JAMA.118","NA",12472328,2002,"Although electrophysiologic and histologic neuromuscular abnormalities are common in intensive care unit (ICU) patients, the clinical incidence of ICU-acquired neuromuscular disorders in patients recovering from severe illness remains unknown.To assess the clinical incidence, risk factors, and outcomes of ICU-acquired paresis (ICUAP) during recovery from critical illness in the ICU and to determine the electrophysiologic and histologic patterns in patients with ICUAP.Prospective cohort study conducted from March 1999 to June 2000.Three medical and 2 surgical ICUs in 4 hospitals in France.All consecutive ICU patients without preexisting neuromuscular disease who underwent mechanical ventilation for 7 or more days were screened daily for awakening. The first day a patient was considered awake was day 1. Patients with severe muscle weakness on day 7 were considered to have ICUAP.Incidence and duration of ICUAP, risk factors for ICUAP, and comparative duration of mechanical ventilation between ICUAP and control patients.Among the 95 patients who achieved satisfactory awakening, the incidence of ICUAP was 25.3% (95% confidence interval [CI], 16.9%-35.2%). All ICUAP patients had a sensorimotor axonopathy, and all patients who underwent a muscle biopsy had specific muscle involvement not related to nerve involvement. The median duration of ICUAP after day 1 was 21 days. Mean (SD) duration of mechanical ventilation after day 1 was significantly longer in patients with ICUAP compared with those without (18.2 [36.3] vs 7.6 [19.2] days; P =.03). Independent predictors of ICUAP were female sex (odds ratio [OR], 4.66; 95% CI, 1.19-18.30), the number of days with dysfunction of 2 or more organs (OR, 1.28; 95% CI, 1.11-1.49), duration of mechanical ventilation (OR, 1.10; 95% CI, 1.00-1.22), and administration of corticosteroids (OR, 14.90; 95% CI, 3.20-69.80) before day 1.Identified using simple bedside clinical criteria, ICUAP was frequent during recovery from critical illness and was associated with a prolonged duration of mechanical ventilation. Our findings suggest an important role of corticosteroids in the development of ICUAP.","Paresis acquired in the intensive care unit: a prospective multicenter study."
"231","JAMA.88","NA",12495392,2002,"Women who present with acute coronary syndromes (ACSs) have different characteristics than men. Reports have conflicted about whether different outcomes exist for women with use of a routine invasive management strategy. However, these studies were performed prior to the widespread use of platelet glycoprotein IIb/IIIa inhibitors and intracoronary stents.To determine sex differences in baseline characteristics and outcomes in ACS and whether women benefit from a contemporary early invasive management strategy.Prospective analysis of women and men enrolled in the TACTICS-TIMI 18 randomized trial, conducted December 1997 to December 1999 in 169 centers in 9 countries in North America and Europe, with follow-up at 1 and 6 months.A total of 2220 patients (757 women and 1463 men) with ACS.All patients received aspirin, 325 mg/d; intravenous unfractionated heparin; and tirofiban for 48 hours or until revascularization, with tirofiban administered for at least 12 hours after percutaneous coronary revascularization. Patients assigned to the early invasive strategy (n = 1114) underwent coronary angiography 4 to 48 hours after randomization and revascularization when appropriate. Patients assigned to the early conservative strategy (n = 1106) were treated medically and underwent coronary angiography and appropriate revascularization only if they met specified criteria.Baseline characteristics and the primary composite end point of death, myocardial infarction, or rehospitalization for ACS at 6 months in women and men assigned to early invasive vs conservative management.Women were older and more frequently had hypertension (P<.001 for both). Women less frequently had previous myocardial infarction, coronary artery bypass grafting, and elevations in cardiac markers (P<.001 for all), but there was no difference in distribution of TIMI risk scores (P =.76). Angiography and intervention rates were similar, but women had less severe coronary artery disease, including no critical lesions in 17% of women vs 9% of men (P<.001). Women had a 28% odds reduction in the primary end point with an early invasive strategy (adjusted odds ratio [OR], 0.72; 95% confidence interval [CI], 0.47-1.11), similar to the benefit in men (adjusted OR, 0.64; 95% CI, 0.47-0.88; P =.60 for sex interaction). When adjusted for baseline characteristics, the benefit of invasive therapy in women with elevated troponin T levels was further enhanced (adjusted OR, 0.47; 95% CI, 0.26-0.83).Despite differences between women and men in baseline characteristics, the benefit of an early invasive strategy incorporating tirofiban and intracoronary stents was similar in women and men and was enhanced in women presenting with markers of increased risk.","Benefit of an early invasive management strategy in women with acute coronary syndromes."
"232","JAMA.89","NA",12495392,2002,"Women who present with acute coronary syndromes (ACSs) have different characteristics than men. Reports have conflicted about whether different outcomes exist for women with use of a routine invasive management strategy. However, these studies were performed prior to the widespread use of platelet glycoprotein IIb/IIIa inhibitors and intracoronary stents.To determine sex differences in baseline characteristics and outcomes in ACS and whether women benefit from a contemporary early invasive management strategy.Prospective analysis of women and men enrolled in the TACTICS-TIMI 18 randomized trial, conducted December 1997 to December 1999 in 169 centers in 9 countries in North America and Europe, with follow-up at 1 and 6 months.A total of 2220 patients (757 women and 1463 men) with ACS.All patients received aspirin, 325 mg/d; intravenous unfractionated heparin; and tirofiban for 48 hours or until revascularization, with tirofiban administered for at least 12 hours after percutaneous coronary revascularization. Patients assigned to the early invasive strategy (n = 1114) underwent coronary angiography 4 to 48 hours after randomization and revascularization when appropriate. Patients assigned to the early conservative strategy (n = 1106) were treated medically and underwent coronary angiography and appropriate revascularization only if they met specified criteria.Baseline characteristics and the primary composite end point of death, myocardial infarction, or rehospitalization for ACS at 6 months in women and men assigned to early invasive vs conservative management.Women were older and more frequently had hypertension (P<.001 for both). Women less frequently had previous myocardial infarction, coronary artery bypass grafting, and elevations in cardiac markers (P<.001 for all), but there was no difference in distribution of TIMI risk scores (P =.76). Angiography and intervention rates were similar, but women had less severe coronary artery disease, including no critical lesions in 17% of women vs 9% of men (P<.001). Women had a 28% odds reduction in the primary end point with an early invasive strategy (adjusted odds ratio [OR], 0.72; 95% confidence interval [CI], 0.47-1.11), similar to the benefit in men (adjusted OR, 0.64; 95% CI, 0.47-0.88; P =.60 for sex interaction). When adjusted for baseline characteristics, the benefit of invasive therapy in women with elevated troponin T levels was further enhanced (adjusted OR, 0.47; 95% CI, 0.26-0.83).Despite differences between women and men in baseline characteristics, the benefit of an early invasive strategy incorporating tirofiban and intracoronary stents was similar in women and men and was enhanced in women presenting with markers of increased risk.","Benefit of an early invasive management strategy in women with acute coronary syndromes."
"233","JAMA.117","0.6",12495392,2002,"Women who present with acute coronary syndromes (ACSs) have different characteristics than men. Reports have conflicted about whether different outcomes exist for women with use of a routine invasive management strategy. However, these studies were performed prior to the widespread use of platelet glycoprotein IIb/IIIa inhibitors and intracoronary stents.To determine sex differences in baseline characteristics and outcomes in ACS and whether women benefit from a contemporary early invasive management strategy.Prospective analysis of women and men enrolled in the TACTICS-TIMI 18 randomized trial, conducted December 1997 to December 1999 in 169 centers in 9 countries in North America and Europe, with follow-up at 1 and 6 months.A total of 2220 patients (757 women and 1463 men) with ACS.All patients received aspirin, 325 mg/d; intravenous unfractionated heparin; and tirofiban for 48 hours or until revascularization, with tirofiban administered for at least 12 hours after percutaneous coronary revascularization. Patients assigned to the early invasive strategy (n = 1114) underwent coronary angiography 4 to 48 hours after randomization and revascularization when appropriate. Patients assigned to the early conservative strategy (n = 1106) were treated medically and underwent coronary angiography and appropriate revascularization only if they met specified criteria.Baseline characteristics and the primary composite end point of death, myocardial infarction, or rehospitalization for ACS at 6 months in women and men assigned to early invasive vs conservative management.Women were older and more frequently had hypertension (P<.001 for both). Women less frequently had previous myocardial infarction, coronary artery bypass grafting, and elevations in cardiac markers (P<.001 for all), but there was no difference in distribution of TIMI risk scores (P =.76). Angiography and intervention rates were similar, but women had less severe coronary artery disease, including no critical lesions in 17% of women vs 9% of men (P<.001). Women had a 28% odds reduction in the primary end point with an early invasive strategy (adjusted odds ratio [OR], 0.72; 95% confidence interval [CI], 0.47-1.11), similar to the benefit in men (adjusted OR, 0.64; 95% CI, 0.47-0.88; P =.60 for sex interaction). When adjusted for baseline characteristics, the benefit of invasive therapy in women with elevated troponin T levels was further enhanced (adjusted OR, 0.47; 95% CI, 0.26-0.83).Despite differences between women and men in baseline characteristics, the benefit of an early invasive strategy incorporating tirofiban and intracoronary stents was similar in women and men and was enhanced in women presenting with markers of increased risk.","Benefit of an early invasive management strategy in women with acute coronary syndromes."
"234","Lancet.241","0.97",12504395,2002,"Results of observational studies suggest that hormone replacement therapy (HRT) could reduce the risk of coronary heart disease (CHD), but those of randomised trials do not indicate a lower risk in women who use oestrogen plus progestagen. The aim of this study was to ascertain whether or not unopposed oestrogen reduces the risk of further cardiac events in postmenopausal women who survive a first myocardial infarction.The study was a randomised, blinded, placebo controlled, secondary prevention trial of postmenopausal women, age 50-69 years (n=1017) who had survived a first myocardial infarction. Individuals were recruited from 35 hospitals in England and Wales. Women received either one tablet of oestradiol valerate (2 mg; n=513) or placebo (n=504), daily for 2 years. Primary outcomes were reinfarction or cardiac death, and all-cause mortality. Analyses were by intention-to-treat. Secondary outcomes were uterine bleeding, endometrial cancer, stroke or other embolic events, and fractures.Frequency of reinfarction or cardiac death did not differ between treatment groups at 24 months (rate ratio 0.99, 95% CI 0.70-1.41, p=0.97). Similarly, the reduction in all-cause mortality between those who took oestrogen and those on placebo was not significant (0.79, 0.50-1.27, p=0.34). The relative risk of any death (0.56, 0.23-1.33) and cardiac death (0.33, 0.11-1.01) was lowest at 3 months post-recruitment.Oestradiol valerate does not reduce the overall risk of further cardiac events in postmenopausal women who have survived a myocardial infarction.","Oestrogen therapy for prevention of reinfarction in postmenopausal women: a randomised placebo controlled trial."
"235","Lancet.310","0.34",12504395,2002,"Results of observational studies suggest that hormone replacement therapy (HRT) could reduce the risk of coronary heart disease (CHD), but those of randomised trials do not indicate a lower risk in women who use oestrogen plus progestagen. The aim of this study was to ascertain whether or not unopposed oestrogen reduces the risk of further cardiac events in postmenopausal women who survive a first myocardial infarction.The study was a randomised, blinded, placebo controlled, secondary prevention trial of postmenopausal women, age 50-69 years (n=1017) who had survived a first myocardial infarction. Individuals were recruited from 35 hospitals in England and Wales. Women received either one tablet of oestradiol valerate (2 mg; n=513) or placebo (n=504), daily for 2 years. Primary outcomes were reinfarction or cardiac death, and all-cause mortality. Analyses were by intention-to-treat. Secondary outcomes were uterine bleeding, endometrial cancer, stroke or other embolic events, and fractures.Frequency of reinfarction or cardiac death did not differ between treatment groups at 24 months (rate ratio 0.99, 95% CI 0.70-1.41, p=0.97). Similarly, the reduction in all-cause mortality between those who took oestrogen and those on placebo was not significant (0.79, 0.50-1.27, p=0.34). The relative risk of any death (0.56, 0.23-1.33) and cardiac death (0.33, 0.11-1.01) was lowest at 3 months post-recruitment.Oestradiol valerate does not reduce the overall risk of further cardiac events in postmenopausal women who have survived a myocardial infarction.","Oestrogen therapy for prevention of reinfarction in postmenopausal women: a randomised placebo controlled trial."
"236","JAMA.213","0.047",12517231,2003,"Neonatal herpes most commonly results from fetal exposure to infected maternal genital secretions at the time of delivery. The risk of transmission from mother to infant as it relates to maternal herpes simplex virus (HSV) serologic status and exposure to HSV in the maternal genital tract at the time of labor has not been quantified. Furthermore, no data exist on whether cesarean delivery, the standard of care for women with genital herpes lesions at the time of delivery, reduces HSV transmission.To determine the effects of viral shedding, maternal HSV serologic status, and delivery route on the risk of transmission of HSV from mother to infant.Prospective cohort of pregnant women enrolled between January 1982 and December 1999.A university medical center, a US Army medical center, and 5 community hospitals in Washington State.A total of 58 362 pregnant women, of whom 40 023 had HSV cultures obtained from the cervix and external genitalia and 31 663 had serum samples tested for HSV.Rates of neonatal HSV infection.Among the 202 women from whom HSV was isolated at the time of labor, 10 (5%) had neonates with HSV infection (odds ratio [OR], 346; 95% confidence interval [CI], 125-956 for neonatal herpes when HSV was isolated vs not isolated). Cesarean delivery significantly reduced the HSV transmission rate among women from whom HSV was isolated (1 [1.2%] of 85 cesarean vs 9 [7.7%] of 117 vaginal; OR, 0.14; 95% CI, 0.02-1.08; P =.047). Other risk factors for neonatal HSV included first-episode infection (OR, 33.1; 95% CI, 6.5-168), HSV isolation from the cervix (OR, 32.6; 95% CI, 4.1-260), HSV-1 vs HSV-2 isolation at the time of labor (OR, 16.5; 95% CI, 4.1-65), invasive monitoring (OR, 6.8; 95% CI, 1.4-32), delivery before 38 weeks (OR, 4.4; 95% CI, 1.2-16), and maternal age less than 21 years (OR, 4.1; 95% CI, 1.1-15). Neonatal HSV infection rates per 100 000 live births were 54 (95% CI, 19.8-118) among HSV-seronegative women, 26 (95% CI, 9.3-56) among women who were HSV-1-seropositive only, and 22 (95% CI, 4.4-64) among all HSV-2-seropositive women.Neonatal HSV infection rates can be reduced by preventing maternal acquisition of genital HSV-1 and HSV-2 infection near term. It can also be reduced by cesarean delivery and limiting the use of invasive monitors among women shedding HSV at the time of labor.","Effect of serologic status and cesarean delivery on transmission rates of herpes simplex virus from mother to infant."
"237","JAMA.212","NA",12597754,2003,"It has been suggested that BCG vaccination may protect against development of allergic diseases, particularly when given just after birth. BCG vaccination was given routinely to all infants in Greenland until 1990, when it was withdrawn from the vaccination program. Whether this resulted in an increased prevalence of atopy in children born after the stop of BCG vaccination is unknown.To determine whether BCG vaccination and age at BCG vaccination are associated with development of atopy.Cross-sectional study among schoolchildren aged 8 to 16 years in 4 towns on the northwest coast of Greenland. Participants had a blood sample drawn and information on BCG vaccination was obtained during 2 periods, November 1998 and November 2001. A total of 1686 children (79% of available children) participated, 1575 of whom had complete information on vaccination status. Atopy was defined as a positive test result in an assay that tests for IgE specific against the most common inhalant allergens in serum.Odds ratio (OR) of atopy in BCG-vaccinated compared with unvaccinated children and OR according to age at vaccination.The risk of atopy was the same in BCG-vaccinated compared with unvaccinated children after adjustment for confounders (OR, 1.03; 95% confidence interval, 0.72-1.48). The risk of atopy in BCG-vaccinated children was not associated with age at vaccination (P =.17).BCG vaccination administered to infants is not associated with reduced risk of development of atopy.","BCG vaccination and risk of atopy."
"238","American Journal of Epidemiology.38","NA",12615610,2003,"Whether caffeine consumption during pregnancy represents a fetal hazard remains uncertain. The authors report on a large prospective study designed to examine this question. In 1996-2000, 2,291 mothers with singleton livebirths in Connecticut and Massachusetts were evaluated after their first prenatal visit and were questioned about caffeine consumption and important confounding factors. Urine samples were provided to analyze urinary caffeine, cotinine, and creatinine levels. Mothers were followed throughout pregnancy to monitor changes in consumption. Pregnancy outcomes were obtained from medical records. Self-reports of caffeine consumption in the first and third trimesters were not associated with intrauterine growth retardation, low birth weight, or preterm delivery. For every 1 mg/g creatinine increase in urinary caffeine, risk of intrauterine growth retardation was essentially unchanged (odds ratio (OR) = 0.96, 95% confidence interval (CI): 0.85, 1.08). In contrast, a 0.005 mg/g creatinine increase in urinary cotinine significantly increased risk (OR = 1.003, 95% CI: 1.001, 1.005). Mean birth weight was reduced by reported caffeine consumption (-28 g per 100 mg of caffeine consumed daily, 95% CI: -0.10, -0.46, p = 0.001) but not mean gestational age. Decaffeinated coffee did not increase risk for any perinatal outcome. This small decrease in birth weight, observed for maternal caffeine consumption, is unlikely to be clinically important except for women consuming >/=600 mg of caffeine daily (approximately six 10-ounce (1 ounce = 28.3 g) cups of coffee).","Association of maternal caffeine consumption with decrements in fetal growth."
"239","American Journal of Epidemiology.39","NA",12615610,2003,"Whether caffeine consumption during pregnancy represents a fetal hazard remains uncertain. The authors report on a large prospective study designed to examine this question. In 1996-2000, 2,291 mothers with singleton livebirths in Connecticut and Massachusetts were evaluated after their first prenatal visit and were questioned about caffeine consumption and important confounding factors. Urine samples were provided to analyze urinary caffeine, cotinine, and creatinine levels. Mothers were followed throughout pregnancy to monitor changes in consumption. Pregnancy outcomes were obtained from medical records. Self-reports of caffeine consumption in the first and third trimesters were not associated with intrauterine growth retardation, low birth weight, or preterm delivery. For every 1 mg/g creatinine increase in urinary caffeine, risk of intrauterine growth retardation was essentially unchanged (odds ratio (OR) = 0.96, 95% confidence interval (CI): 0.85, 1.08). In contrast, a 0.005 mg/g creatinine increase in urinary cotinine significantly increased risk (OR = 1.003, 95% CI: 1.001, 1.005). Mean birth weight was reduced by reported caffeine consumption (-28 g per 100 mg of caffeine consumed daily, 95% CI: -0.10, -0.46, p = 0.001) but not mean gestational age. Decaffeinated coffee did not increase risk for any perinatal outcome. This small decrease in birth weight, observed for maternal caffeine consumption, is unlikely to be clinically important except for women consuming >/=600 mg of caffeine daily (approximately six 10-ounce (1 ounce = 28.3 g) cups of coffee).","Association of maternal caffeine consumption with decrements in fetal growth."
"240","JAMA.1181","0.001",12622581,2003,"The risk-benefit ratio of invasive vs medical management of elderly patients with symptomatic chronic coronary artery disease (CAD) is unclear. The Trial of Invasive versus Medical therapy in Elderly patients (TIME) recently showed early benefits in quality of life from invasive therapy in patients aged 75 years or older, although with a certain excess in mortality.To assess the long-term value of invasive vs medical management of chronic CAD in elderly adults in terms of quality of life and prevention of major adverse cardiac events.One-year follow-up analysis of TIME, a prospective randomized trial with enrollment between February 1996 and November 2000.A total of 282 patients with Canadian Cardiac Society class 2 or higher angina despite treatment with 2 or more anti-anginal drugs who survived for the first 6 months after enrollment in TIME (mean age, 80 years [range, 75-91 years]; 42% women), enrolled at 14 centers in Switzerland.Participants were randomly assigned to undergo coronary angiography followed by revascularization (if feasible) (n = 140 surviving 6 months) or to receive optimized medical therapy (n = 142 surviving 6 months).Quality of life, assessed by standardized questionnaire; major adverse cardiac events (death, nonfatal myocardial infarction, or hospitalization for acute coronary syndrome) after 1 year.After 1 year, improvements in angina and quality of life persisted for both therapies compared with baseline, but the early difference favoring invasive therapy disappeared. Among invasive therapy patients, later hospitalization with revascularization was much less likely (10% vs 46%; hazard ratio [HR], 0.19; 95% confidence interval [CI], 0.11-0.32; P<.001). However, 1-year mortality (11.1% for invasive; 8.1% for medical; HR, 1.51; 95% CI, 0.72-3.16; P =.28) and death or nonfatal myocardial infarction rates (17.0% for invasive; 19.6% for medical; HR, 0.90; 95% CI, 0.53-1.53; P =.71) were not significantly different. Overall major adverse cardiac event rates were higher for medical patients after 6 months (49.3% vs 19.0% for invasive; P<.001), a difference which increased to 64.2% vs 25.5% after 12 months (P<.001).In contrast with differences in early results, 1-year outcomes in elderly patients with chronic angina are similar with regard to symptoms, quality of life, and death or nonfatal infarction with invasive vs optimized medical strategies based on this intention-to-treat analysis. The invasive approach carries an early intervention risk, while medical management poses an almost 50% chance of later hospitalization and revascularization.","Outcome of elderly patients with chronic symptomatic coronary artery disease with an invasive vs optimized medical treatment strategy: one-year results of the randomized TIME trial."
"241","JAMA.1511","0.28",12622581,2003,"The risk-benefit ratio of invasive vs medical management of elderly patients with symptomatic chronic coronary artery disease (CAD) is unclear. The Trial of Invasive versus Medical therapy in Elderly patients (TIME) recently showed early benefits in quality of life from invasive therapy in patients aged 75 years or older, although with a certain excess in mortality.To assess the long-term value of invasive vs medical management of chronic CAD in elderly adults in terms of quality of life and prevention of major adverse cardiac events.One-year follow-up analysis of TIME, a prospective randomized trial with enrollment between February 1996 and November 2000.A total of 282 patients with Canadian Cardiac Society class 2 or higher angina despite treatment with 2 or more anti-anginal drugs who survived for the first 6 months after enrollment in TIME (mean age, 80 years [range, 75-91 years]; 42% women), enrolled at 14 centers in Switzerland.Participants were randomly assigned to undergo coronary angiography followed by revascularization (if feasible) (n = 140 surviving 6 months) or to receive optimized medical therapy (n = 142 surviving 6 months).Quality of life, assessed by standardized questionnaire; major adverse cardiac events (death, nonfatal myocardial infarction, or hospitalization for acute coronary syndrome) after 1 year.After 1 year, improvements in angina and quality of life persisted for both therapies compared with baseline, but the early difference favoring invasive therapy disappeared. Among invasive therapy patients, later hospitalization with revascularization was much less likely (10% vs 46%; hazard ratio [HR], 0.19; 95% confidence interval [CI], 0.11-0.32; P<.001). However, 1-year mortality (11.1% for invasive; 8.1% for medical; HR, 1.51; 95% CI, 0.72-3.16; P =.28) and death or nonfatal myocardial infarction rates (17.0% for invasive; 19.6% for medical; HR, 0.90; 95% CI, 0.53-1.53; P =.71) were not significantly different. Overall major adverse cardiac event rates were higher for medical patients after 6 months (49.3% vs 19.0% for invasive; P<.001), a difference which increased to 64.2% vs 25.5% after 12 months (P<.001).In contrast with differences in early results, 1-year outcomes in elderly patients with chronic angina are similar with regard to symptoms, quality of life, and death or nonfatal infarction with invasive vs optimized medical strategies based on this intention-to-treat analysis. The invasive approach carries an early intervention risk, while medical management poses an almost 50% chance of later hospitalization and revascularization.","Outcome of elderly patients with chronic symptomatic coronary artery disease with an invasive vs optimized medical treatment strategy: one-year results of the randomized TIME trial."
"242","JAMA.1521","0.71",12622581,2003,"The risk-benefit ratio of invasive vs medical management of elderly patients with symptomatic chronic coronary artery disease (CAD) is unclear. The Trial of Invasive versus Medical therapy in Elderly patients (TIME) recently showed early benefits in quality of life from invasive therapy in patients aged 75 years or older, although with a certain excess in mortality.To assess the long-term value of invasive vs medical management of chronic CAD in elderly adults in terms of quality of life and prevention of major adverse cardiac events.One-year follow-up analysis of TIME, a prospective randomized trial with enrollment between February 1996 and November 2000.A total of 282 patients with Canadian Cardiac Society class 2 or higher angina despite treatment with 2 or more anti-anginal drugs who survived for the first 6 months after enrollment in TIME (mean age, 80 years [range, 75-91 years]; 42% women), enrolled at 14 centers in Switzerland.Participants were randomly assigned to undergo coronary angiography followed by revascularization (if feasible) (n = 140 surviving 6 months) or to receive optimized medical therapy (n = 142 surviving 6 months).Quality of life, assessed by standardized questionnaire; major adverse cardiac events (death, nonfatal myocardial infarction, or hospitalization for acute coronary syndrome) after 1 year.After 1 year, improvements in angina and quality of life persisted for both therapies compared with baseline, but the early difference favoring invasive therapy disappeared. Among invasive therapy patients, later hospitalization with revascularization was much less likely (10% vs 46%; hazard ratio [HR], 0.19; 95% confidence interval [CI], 0.11-0.32; P<.001). However, 1-year mortality (11.1% for invasive; 8.1% for medical; HR, 1.51; 95% CI, 0.72-3.16; P =.28) and death or nonfatal myocardial infarction rates (17.0% for invasive; 19.6% for medical; HR, 0.90; 95% CI, 0.53-1.53; P =.71) were not significantly different. Overall major adverse cardiac event rates were higher for medical patients after 6 months (49.3% vs 19.0% for invasive; P<.001), a difference which increased to 64.2% vs 25.5% after 12 months (P<.001).In contrast with differences in early results, 1-year outcomes in elderly patients with chronic angina are similar with regard to symptoms, quality of life, and death or nonfatal infarction with invasive vs optimized medical strategies based on this intention-to-treat analysis. The invasive approach carries an early intervention risk, while medical management poses an almost 50% chance of later hospitalization and revascularization.","Outcome of elderly patients with chronic symptomatic coronary artery disease with an invasive vs optimized medical treatment strategy: one-year results of the randomized TIME trial."
"243","JAMA.209","0.04",12636461,2003,"Defibrillation as soon as possible is standard treatment for patients with ventricular fibrillation. A nonrandomized study indicates that after a few minutes of ventricular fibrillation, delaying defibrillation to give cardiopulmonary resuscitation (CPR) first might improve the outcome.To determine the effects of CPR before defibrillation on outcome in patients with ventricular fibrillation and with response times either up to or longer than 5 minutes.Randomized trial of 200 patients with out-of-hospital ventricular fibrillation in Oslo, Norway, between June 1998 and May 2001. Patients received either standard care with immediate defibrillation (n = 96) or CPR first with 3 minutes of basic CPR by ambulance personnel prior to defibrillation (n = 104). If initial defibrillation was unsuccessful, the standard group received 1 minute of CPR before additional defibrillation attempts compared with 3 minutes in the CPR first group.Primary end point was survival to hospital discharge. Secondary end points were hospital admission with return of spontaneous circulation (ROSC), 1-year survival, and neurological outcome. A prespecified analysis examined subgroups with response times either up to or longer than 5 minutes.In the standard group, 14 (15%) of 96 patients survived to hospital discharge vs 23 (22%) of 104 in the CPR first group (P =.17). There were no differences in ROSC rates between the standard group (56% [58/104]) and the CPR first group (46% [44/96]; P =.16); or in 1-year survival (20% [21/104] and 15% [14/96], respectively; P =.30). In subgroup analysis for patients with ambulance response times of either up to 5 minutes or shorter, there were no differences in any outcome variables between the CPR first group (n = 40) and the standard group (n = 41). For patients with response intervals of longer than 5 minutes, more patients achieved ROSC in the CPR first group (58% [37/64]) compared with the standard group (38% [21/55]; odds ratio [OR], 2.22; 95% confidence interval [CI], 1.06-4.63; P =.04); survival to hospital discharge (22% [14/64] vs 4% [2/55]; OR, 7.42; 95% CI, 1.61-34.3; P =.006); and 1-year survival (20% [13/64] vs 4% [2/55]; OR, 6.76; 95% CI, 1.42-31.4; P =.01). Thirty-three (89%) of 37 patients who survived to hospital discharge had no or minor reductions in neurological status with no difference between the groups.Compared with standard care for ventricular fibrillation, CPR first prior to defibrillation offered no advantage in improving outcomes for this entire study population or for patients with ambulance response times shorter than 5 minutes. However, the patients with ventricular fibrillation and ambulance response intervals longer than 5 minutes had better outcomes with CPR first before defibrillation was attempted. These results require confirmation in additional randomized trials.","Delaying defibrillation to give basic cardiopulmonary resuscitation to patients with out-of-hospital ventricular fibrillation: a randomized trial."
"244","JAMA.210","0.006",12636461,2003,"Defibrillation as soon as possible is standard treatment for patients with ventricular fibrillation. A nonrandomized study indicates that after a few minutes of ventricular fibrillation, delaying defibrillation to give cardiopulmonary resuscitation (CPR) first might improve the outcome.To determine the effects of CPR before defibrillation on outcome in patients with ventricular fibrillation and with response times either up to or longer than 5 minutes.Randomized trial of 200 patients with out-of-hospital ventricular fibrillation in Oslo, Norway, between June 1998 and May 2001. Patients received either standard care with immediate defibrillation (n = 96) or CPR first with 3 minutes of basic CPR by ambulance personnel prior to defibrillation (n = 104). If initial defibrillation was unsuccessful, the standard group received 1 minute of CPR before additional defibrillation attempts compared with 3 minutes in the CPR first group.Primary end point was survival to hospital discharge. Secondary end points were hospital admission with return of spontaneous circulation (ROSC), 1-year survival, and neurological outcome. A prespecified analysis examined subgroups with response times either up to or longer than 5 minutes.In the standard group, 14 (15%) of 96 patients survived to hospital discharge vs 23 (22%) of 104 in the CPR first group (P =.17). There were no differences in ROSC rates between the standard group (56% [58/104]) and the CPR first group (46% [44/96]; P =.16); or in 1-year survival (20% [21/104] and 15% [14/96], respectively; P =.30). In subgroup analysis for patients with ambulance response times of either up to 5 minutes or shorter, there were no differences in any outcome variables between the CPR first group (n = 40) and the standard group (n = 41). For patients with response intervals of longer than 5 minutes, more patients achieved ROSC in the CPR first group (58% [37/64]) compared with the standard group (38% [21/55]; odds ratio [OR], 2.22; 95% confidence interval [CI], 1.06-4.63; P =.04); survival to hospital discharge (22% [14/64] vs 4% [2/55]; OR, 7.42; 95% CI, 1.61-34.3; P =.006); and 1-year survival (20% [13/64] vs 4% [2/55]; OR, 6.76; 95% CI, 1.42-31.4; P =.01). Thirty-three (89%) of 37 patients who survived to hospital discharge had no or minor reductions in neurological status with no difference between the groups.Compared with standard care for ventricular fibrillation, CPR first prior to defibrillation offered no advantage in improving outcomes for this entire study population or for patients with ambulance response times shorter than 5 minutes. However, the patients with ventricular fibrillation and ambulance response intervals longer than 5 minutes had better outcomes with CPR first before defibrillation was attempted. These results require confirmation in additional randomized trials.","Delaying defibrillation to give basic cardiopulmonary resuscitation to patients with out-of-hospital ventricular fibrillation: a randomized trial."
"245","JAMA.211","0.01",12636461,2003,"Defibrillation as soon as possible is standard treatment for patients with ventricular fibrillation. A nonrandomized study indicates that after a few minutes of ventricular fibrillation, delaying defibrillation to give cardiopulmonary resuscitation (CPR) first might improve the outcome.To determine the effects of CPR before defibrillation on outcome in patients with ventricular fibrillation and with response times either up to or longer than 5 minutes.Randomized trial of 200 patients with out-of-hospital ventricular fibrillation in Oslo, Norway, between June 1998 and May 2001. Patients received either standard care with immediate defibrillation (n = 96) or CPR first with 3 minutes of basic CPR by ambulance personnel prior to defibrillation (n = 104). If initial defibrillation was unsuccessful, the standard group received 1 minute of CPR before additional defibrillation attempts compared with 3 minutes in the CPR first group.Primary end point was survival to hospital discharge. Secondary end points were hospital admission with return of spontaneous circulation (ROSC), 1-year survival, and neurological outcome. A prespecified analysis examined subgroups with response times either up to or longer than 5 minutes.In the standard group, 14 (15%) of 96 patients survived to hospital discharge vs 23 (22%) of 104 in the CPR first group (P =.17). There were no differences in ROSC rates between the standard group (56% [58/104]) and the CPR first group (46% [44/96]; P =.16); or in 1-year survival (20% [21/104] and 15% [14/96], respectively; P =.30). In subgroup analysis for patients with ambulance response times of either up to 5 minutes or shorter, there were no differences in any outcome variables between the CPR first group (n = 40) and the standard group (n = 41). For patients with response intervals of longer than 5 minutes, more patients achieved ROSC in the CPR first group (58% [37/64]) compared with the standard group (38% [21/55]; odds ratio [OR], 2.22; 95% confidence interval [CI], 1.06-4.63; P =.04); survival to hospital discharge (22% [14/64] vs 4% [2/55]; OR, 7.42; 95% CI, 1.61-34.3; P =.006); and 1-year survival (20% [13/64] vs 4% [2/55]; OR, 6.76; 95% CI, 1.42-31.4; P =.01). Thirty-three (89%) of 37 patients who survived to hospital discharge had no or minor reductions in neurological status with no difference between the groups.Compared with standard care for ventricular fibrillation, CPR first prior to defibrillation offered no advantage in improving outcomes for this entire study population or for patients with ambulance response times shorter than 5 minutes. However, the patients with ventricular fibrillation and ambulance response intervals longer than 5 minutes had better outcomes with CPR first before defibrillation was attempted. These results require confirmation in additional randomized trials.","Delaying defibrillation to give basic cardiopulmonary resuscitation to patients with out-of-hospital ventricular fibrillation: a randomized trial."
"246","JAMA.174","NA",12684360,2003,"One in 7 US children and adolescents is obese, yet little is known about their health-related quality of life (QOL).To examine the health-related QOL of obese children and adolescents compared with children and adolescents who are healthy or those diagnosed as having cancer.Cross-sectional study of 106 children and adolescents (57 males) between the ages of 5 and 18 years (mean [SD], 12.1 [3] years), who had been referred to an academic children's hospital for evaluation of obesity between January and June 2002. Children and adolescents had a mean (SD) body mass index (BMI) of 34.7 (9.3) and BMI z score of 2.6 (0.5).Child self-report and parent proxy report using a pediatric QOL inventory generic core scale (range, 0-100). The inventory was administered by an interviewer for children aged 5 through 7 years. Scores were compared with previously published scores for healthy children and adolescents and children and adolescents diagnosed as having cancer.Compared with healthy children and adolescents, obese children and adolescents reported significantly (P<.001) lower health-related QOL in all domains (mean [SD] total score, 67 [16.3] for obese children and adolescents; 83 [14.8] for healthy children and adolescents). Obese children and adolescents were more likely to have impaired health-related QOL than healthy children and adolescents (odds ratio [OR], 5.5; 95% confidence interval [CI], 3.4-8.7) and were similar to children and adolescents diagnosed as having cancer (OR, 1.3; 95% CI, 0.8-2.3). Children and adolescents with obstructive sleep apnea reported a significantly lower health-related QOL total score (mean [SD], 53.8 [13.3]) than obese children and adolescents without obstructive sleep apnea (mean [SD], 67.9 [16.2]). For parent proxy report, the child or adolescent's BMI z score was significantly inversely correlated with total score (r = -0.246; P =.01), physical functioning (r = -0.263; P<.01), social functioning (r = -0.347; P<.001), and psychosocial functioning (r = -0.209; P =.03).Severely obese children and adolescents have lower health-related QOL than children and adolescents who are healthy and similar QOL as those diagnosed as having cancer. Physicians, parents, and teachers need to be informed of the risk for impaired health-related QOL among obese children and adolescents to target interventions that could enhance health outcomes.","Health-related quality of life of severely obese children and adolescents."
"247","JAMA.175","NA",12684360,2003,"One in 7 US children and adolescents is obese, yet little is known about their health-related quality of life (QOL).To examine the health-related QOL of obese children and adolescents compared with children and adolescents who are healthy or those diagnosed as having cancer.Cross-sectional study of 106 children and adolescents (57 males) between the ages of 5 and 18 years (mean [SD], 12.1 [3] years), who had been referred to an academic children's hospital for evaluation of obesity between January and June 2002. Children and adolescents had a mean (SD) body mass index (BMI) of 34.7 (9.3) and BMI z score of 2.6 (0.5).Child self-report and parent proxy report using a pediatric QOL inventory generic core scale (range, 0-100). The inventory was administered by an interviewer for children aged 5 through 7 years. Scores were compared with previously published scores for healthy children and adolescents and children and adolescents diagnosed as having cancer.Compared with healthy children and adolescents, obese children and adolescents reported significantly (P<.001) lower health-related QOL in all domains (mean [SD] total score, 67 [16.3] for obese children and adolescents; 83 [14.8] for healthy children and adolescents). Obese children and adolescents were more likely to have impaired health-related QOL than healthy children and adolescents (odds ratio [OR], 5.5; 95% confidence interval [CI], 3.4-8.7) and were similar to children and adolescents diagnosed as having cancer (OR, 1.3; 95% CI, 0.8-2.3). Children and adolescents with obstructive sleep apnea reported a significantly lower health-related QOL total score (mean [SD], 53.8 [13.3]) than obese children and adolescents without obstructive sleep apnea (mean [SD], 67.9 [16.2]). For parent proxy report, the child or adolescent's BMI z score was significantly inversely correlated with total score (r = -0.246; P =.01), physical functioning (r = -0.263; P<.01), social functioning (r = -0.347; P<.001), and psychosocial functioning (r = -0.209; P =.03).Severely obese children and adolescents have lower health-related QOL than children and adolescents who are healthy and similar QOL as those diagnosed as having cancer. Physicians, parents, and teachers need to be informed of the risk for impaired health-related QOL among obese children and adolescents to target interventions that could enhance health outcomes.","Health-related quality of life of severely obese children and adolescents."
"248","JAMA.200","NA",12697796,2003,"A number of countries have implemented a policy of universal leukoreduction of their blood supply, but the potential role of leukoreduction in decreasing postoperative mortality and infection is unclear.To evaluate clinical outcomes following adoption of a national universal prestorage leukoreduction program for blood transfusions.Retrospective before-and-after cohort study conducted from August 1998 to August 2000 in 23 academic and community hospitals throughout Canada, enrolling 14 786 patients who received red blood cell transfusions following cardiac surgery or repair of hip fracture, or who required intensive care following a surgical intervention or multiple trauma.Universal prestorage leukoreduction program introduced by 2 Canadian blood agencies. A total of 6982 patients were enrolled during the control period and 7804 patients were enrolled following prestorage leukoreduction.All-cause in-hospital mortality and serious nosocomial infections (pneumonia, bacteremia, septic shock, all surgical site infections) occurring after first transfusion and at least 2 days after index procedure or intensive care unit admission. Secondary outcomes included rates of posttransfusion fever and antibiotic use.Unadjusted in-hospital mortality rates were significantly lower following the introduction of leukoreduction compared with the control period (6.19% vs 7.03%, respectively; P =.04). Compared with the control period, the adjusted odds of death following leukoreduction were reduced (odds ratio [OR], 0.87; 95% confidence interval [CI], 0.75-0.99), but serious nosocomial infections did not decrease (adjusted OR, 0.97; 95% CI, 0.87-1.09). The frequency of posttransfusion fevers decreased significantly following leukoreduction (adjusted OR, 0.86; 95% CI, 0.79-0.94), as did antibiotic use (adjusted OR, 0.90; 95% CI, 0.82-0.99).A national universal leukoreduction program is potentially associated with decreased mortality as well as decreased fever episodes and antibiotic use after red blood cell transfusion in high-risk patients.","Clinical outcomes following institution of the Canadian universal leukoreduction program for red blood cell transfusions."
"249","JAMA.201","NA",12697796,2003,"A number of countries have implemented a policy of universal leukoreduction of their blood supply, but the potential role of leukoreduction in decreasing postoperative mortality and infection is unclear.To evaluate clinical outcomes following adoption of a national universal prestorage leukoreduction program for blood transfusions.Retrospective before-and-after cohort study conducted from August 1998 to August 2000 in 23 academic and community hospitals throughout Canada, enrolling 14 786 patients who received red blood cell transfusions following cardiac surgery or repair of hip fracture, or who required intensive care following a surgical intervention or multiple trauma.Universal prestorage leukoreduction program introduced by 2 Canadian blood agencies. A total of 6982 patients were enrolled during the control period and 7804 patients were enrolled following prestorage leukoreduction.All-cause in-hospital mortality and serious nosocomial infections (pneumonia, bacteremia, septic shock, all surgical site infections) occurring after first transfusion and at least 2 days after index procedure or intensive care unit admission. Secondary outcomes included rates of posttransfusion fever and antibiotic use.Unadjusted in-hospital mortality rates were significantly lower following the introduction of leukoreduction compared with the control period (6.19% vs 7.03%, respectively; P =.04). Compared with the control period, the adjusted odds of death following leukoreduction were reduced (odds ratio [OR], 0.87; 95% confidence interval [CI], 0.75-0.99), but serious nosocomial infections did not decrease (adjusted OR, 0.97; 95% CI, 0.87-1.09). The frequency of posttransfusion fevers decreased significantly following leukoreduction (adjusted OR, 0.86; 95% CI, 0.79-0.94), as did antibiotic use (adjusted OR, 0.90; 95% CI, 0.82-0.99).A national universal leukoreduction program is potentially associated with decreased mortality as well as decreased fever episodes and antibiotic use after red blood cell transfusion in high-risk patients.","Clinical outcomes following institution of the Canadian universal leukoreduction program for red blood cell transfusions."
"250","JAMA.202","NA",12697796,2003,"A number of countries have implemented a policy of universal leukoreduction of their blood supply, but the potential role of leukoreduction in decreasing postoperative mortality and infection is unclear.To evaluate clinical outcomes following adoption of a national universal prestorage leukoreduction program for blood transfusions.Retrospective before-and-after cohort study conducted from August 1998 to August 2000 in 23 academic and community hospitals throughout Canada, enrolling 14 786 patients who received red blood cell transfusions following cardiac surgery or repair of hip fracture, or who required intensive care following a surgical intervention or multiple trauma.Universal prestorage leukoreduction program introduced by 2 Canadian blood agencies. A total of 6982 patients were enrolled during the control period and 7804 patients were enrolled following prestorage leukoreduction.All-cause in-hospital mortality and serious nosocomial infections (pneumonia, bacteremia, septic shock, all surgical site infections) occurring after first transfusion and at least 2 days after index procedure or intensive care unit admission. Secondary outcomes included rates of posttransfusion fever and antibiotic use.Unadjusted in-hospital mortality rates were significantly lower following the introduction of leukoreduction compared with the control period (6.19% vs 7.03%, respectively; P =.04). Compared with the control period, the adjusted odds of death following leukoreduction were reduced (odds ratio [OR], 0.87; 95% confidence interval [CI], 0.75-0.99), but serious nosocomial infections did not decrease (adjusted OR, 0.97; 95% CI, 0.87-1.09). The frequency of posttransfusion fevers decreased significantly following leukoreduction (adjusted OR, 0.86; 95% CI, 0.79-0.94), as did antibiotic use (adjusted OR, 0.90; 95% CI, 0.82-0.99).A national universal leukoreduction program is potentially associated with decreased mortality as well as decreased fever episodes and antibiotic use after red blood cell transfusion in high-risk patients.","Clinical outcomes following institution of the Canadian universal leukoreduction program for red blood cell transfusions."
"251","JAMA.203","NA",12697796,2003,"A number of countries have implemented a policy of universal leukoreduction of their blood supply, but the potential role of leukoreduction in decreasing postoperative mortality and infection is unclear.To evaluate clinical outcomes following adoption of a national universal prestorage leukoreduction program for blood transfusions.Retrospective before-and-after cohort study conducted from August 1998 to August 2000 in 23 academic and community hospitals throughout Canada, enrolling 14 786 patients who received red blood cell transfusions following cardiac surgery or repair of hip fracture, or who required intensive care following a surgical intervention or multiple trauma.Universal prestorage leukoreduction program introduced by 2 Canadian blood agencies. A total of 6982 patients were enrolled during the control period and 7804 patients were enrolled following prestorage leukoreduction.All-cause in-hospital mortality and serious nosocomial infections (pneumonia, bacteremia, septic shock, all surgical site infections) occurring after first transfusion and at least 2 days after index procedure or intensive care unit admission. Secondary outcomes included rates of posttransfusion fever and antibiotic use.Unadjusted in-hospital mortality rates were significantly lower following the introduction of leukoreduction compared with the control period (6.19% vs 7.03%, respectively; P =.04). Compared with the control period, the adjusted odds of death following leukoreduction were reduced (odds ratio [OR], 0.87; 95% confidence interval [CI], 0.75-0.99), but serious nosocomial infections did not decrease (adjusted OR, 0.97; 95% CI, 0.87-1.09). The frequency of posttransfusion fevers decreased significantly following leukoreduction (adjusted OR, 0.86; 95% CI, 0.79-0.94), as did antibiotic use (adjusted OR, 0.90; 95% CI, 0.82-0.99).A national universal leukoreduction program is potentially associated with decreased mortality as well as decreased fever episodes and antibiotic use after red blood cell transfusion in high-risk patients.","Clinical outcomes following institution of the Canadian universal leukoreduction program for red blood cell transfusions."
"252","JAMA.1500","NA",12697798,2003,"Several randomized controlled trials have been performed to examine the effectiveness of external hip protectors in reducing the incidence of hip fractures, but the results are controversial.To examine the effectiveness of hip protectors in reducing the incidence of hip fractures in an elderly high-risk population.Randomized controlled trial of elderly persons aged 70 years or older, who have low bone density, and are at high risk for falls. Participants lived in apartment houses for the elderly, homes for the elderly, and nursing homes in Amsterdam and surrounding areas in the Netherlands. They were enrolled in the study between March 1999 and March 2001; the mean follow-up was 69.6 weeks. Of the 830 persons who were screened, 561 persons were enrolled.External hip protector. Both groups received written information on bone health and risk factors for falls.Time to first hip fracture. Survival analysis was used to include all participants for the time they participated.In the intervention group, 18 hip fractures occurred vs 20 in the control group. Four hip fractures in the intervention group occurred while an individual was wearing a hip protector. At least 4 hip fractures in the intervention group occurred late at night or early in the morning. Both in univariate analysis (log-rank P =.86) and in multivariate analysis (hazard ratio [HR], 1.05; 95% confidence interval [CI], 0.55-2.03), no statistically significant difference between the intervention group and control group was found with regard to time to first hip fracture. In addition, the per protocol analysis in compliant participants did not show a statistically significant difference between the groups (HR, 0.77; 95% CI, 0.25-2.38).The hip protector studied was not effective in preventing hip fractures.","Prevention of hip fractures by external hip protectors: a randomized controlled trial."
"253","JAMA.1501","NA",12697798,2003,"Several randomized controlled trials have been performed to examine the effectiveness of external hip protectors in reducing the incidence of hip fractures, but the results are controversial.To examine the effectiveness of hip protectors in reducing the incidence of hip fractures in an elderly high-risk population.Randomized controlled trial of elderly persons aged 70 years or older, who have low bone density, and are at high risk for falls. Participants lived in apartment houses for the elderly, homes for the elderly, and nursing homes in Amsterdam and surrounding areas in the Netherlands. They were enrolled in the study between March 1999 and March 2001; the mean follow-up was 69.6 weeks. Of the 830 persons who were screened, 561 persons were enrolled.External hip protector. Both groups received written information on bone health and risk factors for falls.Time to first hip fracture. Survival analysis was used to include all participants for the time they participated.In the intervention group, 18 hip fractures occurred vs 20 in the control group. Four hip fractures in the intervention group occurred while an individual was wearing a hip protector. At least 4 hip fractures in the intervention group occurred late at night or early in the morning. Both in univariate analysis (log-rank P =.86) and in multivariate analysis (hazard ratio [HR], 1.05; 95% confidence interval [CI], 0.55-2.03), no statistically significant difference between the intervention group and control group was found with regard to time to first hip fracture. In addition, the per protocol analysis in compliant participants did not show a statistically significant difference between the groups (HR, 0.77; 95% CI, 0.25-2.38).The hip protector studied was not effective in preventing hip fractures.","Prevention of hip fractures by external hip protectors: a randomized controlled trial."
"254","JAMA.1481","0.77",12709465,2003,"Hypertensive patients are often given a calcium antagonist to reduce cardiovascular disease risk, but the benefit compared with other drug classes is controversial.To determine whether initial therapy with controlled-onset extended-release (COER) verapamil is equivalent to a physician's choice of atenolol or hydrochlorothiazide in preventing cardiovascular disease.Double-blind, randomized clinical trial conducted at 661 centers in 15 countries. A total of 16 602 participants diagnosed as having hypertension and who had 1 or more additional risk factors for cardiovascular disease were enrolled between September 1996 and December 1998 and followed up until December 31, 2000. After a mean of 3 years of follow-up, the sponsor closed the study before unblinding the results.Initially, 8241 participants received 180 mg of COER verapamil and 8361 received either 50 mg of atenolol or 12.5 mg of hydrochlorothiazide. Other drugs (eg, diuretic, beta-blocker, or an angiotensin-converting enzyme inhibitor) could be added in specified sequence if needed.First occurrence of stroke, myocardial infarction, or cardiovascular disease-related death.Systolic and diastolic blood pressure were reduced by 13.6 mm Hg and 7.8 mm Hg for participants assigned to the COER verapamil group and by 13.5 and 7.1 mm Hg for partcipants assigned to the atenolol or hydrochlorothiazide group. There were 364 primary cardiovascular disease-related events that occurred in the COER verapamil group vs 365 in atenolol or hydrochlorothiazide group (hazard ratio [HR], 1.02; 95% confidence interval [CI], 0.88-1.18; P =.77). For fatal or nonfatal stroke, the HR was 1.15 (95% CI, 0.90-1.48); for fatal or nonfatal myocardial infarction, 0.82 (95% CI, 0.65-1.03); and for cardiovascular disease-related death, 1.09 (95% CI, 0.87-1.37). The HR was 1.05 (95% CI, 0.95-1.16) for any prespecified cardiovascular disease-related event and 1.08 (95% CI, 0.93-1.26) for all-cause mortality. Nonstroke hemorrhage was more common with participants in the COER-verapamil group (n = 118) compared with the atenolol or hydrochlorothiazide group (n = 79) (HR, 1.54 [95% CI, 1.16-2.04]; P =.003). More cardiovascular disease-related events occurred between 6 AM and noon in both the COER verapamil (99/277) and atenolol or hydrochlorothiazide (88/274) groups; HR, 1.15 (95% CI, 0.86-1.53).The CONVINCE trial did not demonstrate equivalence of a COER verapamil-based antihypertensive regimen compared with a regimen beginning with a diuretic or beta-blocker. When considered in the context of other trials of calcium antagonists, these data indicate that the effectiveness of calcium-channel therapy in reducing cardiovascular disease is similar but not better than diuretic or beta-blocker treatment.","Principal results of the Controlled Onset Verapamil Investigation of Cardiovascular End Points (CONVINCE) trial."
"255","JAMA.1491","0.003",12709465,2003,"Hypertensive patients are often given a calcium antagonist to reduce cardiovascular disease risk, but the benefit compared with other drug classes is controversial.To determine whether initial therapy with controlled-onset extended-release (COER) verapamil is equivalent to a physician's choice of atenolol or hydrochlorothiazide in preventing cardiovascular disease.Double-blind, randomized clinical trial conducted at 661 centers in 15 countries. A total of 16 602 participants diagnosed as having hypertension and who had 1 or more additional risk factors for cardiovascular disease were enrolled between September 1996 and December 1998 and followed up until December 31, 2000. After a mean of 3 years of follow-up, the sponsor closed the study before unblinding the results.Initially, 8241 participants received 180 mg of COER verapamil and 8361 received either 50 mg of atenolol or 12.5 mg of hydrochlorothiazide. Other drugs (eg, diuretic, beta-blocker, or an angiotensin-converting enzyme inhibitor) could be added in specified sequence if needed.First occurrence of stroke, myocardial infarction, or cardiovascular disease-related death.Systolic and diastolic blood pressure were reduced by 13.6 mm Hg and 7.8 mm Hg for participants assigned to the COER verapamil group and by 13.5 and 7.1 mm Hg for partcipants assigned to the atenolol or hydrochlorothiazide group. There were 364 primary cardiovascular disease-related events that occurred in the COER verapamil group vs 365 in atenolol or hydrochlorothiazide group (hazard ratio [HR], 1.02; 95% confidence interval [CI], 0.88-1.18; P =.77). For fatal or nonfatal stroke, the HR was 1.15 (95% CI, 0.90-1.48); for fatal or nonfatal myocardial infarction, 0.82 (95% CI, 0.65-1.03); and for cardiovascular disease-related death, 1.09 (95% CI, 0.87-1.37). The HR was 1.05 (95% CI, 0.95-1.16) for any prespecified cardiovascular disease-related event and 1.08 (95% CI, 0.93-1.26) for all-cause mortality. Nonstroke hemorrhage was more common with participants in the COER-verapamil group (n = 118) compared with the atenolol or hydrochlorothiazide group (n = 79) (HR, 1.54 [95% CI, 1.16-2.04]; P =.003). More cardiovascular disease-related events occurred between 6 AM and noon in both the COER verapamil (99/277) and atenolol or hydrochlorothiazide (88/274) groups; HR, 1.15 (95% CI, 0.86-1.53).The CONVINCE trial did not demonstrate equivalence of a COER verapamil-based antihypertensive regimen compared with a regimen beginning with a diuretic or beta-blocker. When considered in the context of other trials of calcium antagonists, these data indicate that the effectiveness of calcium-channel therapy in reducing cardiovascular disease is similar but not better than diuretic or beta-blocker treatment.","Principal results of the Controlled Onset Verapamil Investigation of Cardiovascular End Points (CONVINCE) trial."
"256","JAMA.1491","NA",12709465,2003,"Hypertensive patients are often given a calcium antagonist to reduce cardiovascular disease risk, but the benefit compared with other drug classes is controversial.To determine whether initial therapy with controlled-onset extended-release (COER) verapamil is equivalent to a physician's choice of atenolol or hydrochlorothiazide in preventing cardiovascular disease.Double-blind, randomized clinical trial conducted at 661 centers in 15 countries. A total of 16 602 participants diagnosed as having hypertension and who had 1 or more additional risk factors for cardiovascular disease were enrolled between September 1996 and December 1998 and followed up until December 31, 2000. After a mean of 3 years of follow-up, the sponsor closed the study before unblinding the results.Initially, 8241 participants received 180 mg of COER verapamil and 8361 received either 50 mg of atenolol or 12.5 mg of hydrochlorothiazide. Other drugs (eg, diuretic, beta-blocker, or an angiotensin-converting enzyme inhibitor) could be added in specified sequence if needed.First occurrence of stroke, myocardial infarction, or cardiovascular disease-related death.Systolic and diastolic blood pressure were reduced by 13.6 mm Hg and 7.8 mm Hg for participants assigned to the COER verapamil group and by 13.5 and 7.1 mm Hg for partcipants assigned to the atenolol or hydrochlorothiazide group. There were 364 primary cardiovascular disease-related events that occurred in the COER verapamil group vs 365 in atenolol or hydrochlorothiazide group (hazard ratio [HR], 1.02; 95% confidence interval [CI], 0.88-1.18; P =.77). For fatal or nonfatal stroke, the HR was 1.15 (95% CI, 0.90-1.48); for fatal or nonfatal myocardial infarction, 0.82 (95% CI, 0.65-1.03); and for cardiovascular disease-related death, 1.09 (95% CI, 0.87-1.37). The HR was 1.05 (95% CI, 0.95-1.16) for any prespecified cardiovascular disease-related event and 1.08 (95% CI, 0.93-1.26) for all-cause mortality. Nonstroke hemorrhage was more common with participants in the COER-verapamil group (n = 118) compared with the atenolol or hydrochlorothiazide group (n = 79) (HR, 1.54 [95% CI, 1.16-2.04]; P =.003). More cardiovascular disease-related events occurred between 6 AM and noon in both the COER verapamil (99/277) and atenolol or hydrochlorothiazide (88/274) groups; HR, 1.15 (95% CI, 0.86-1.53).The CONVINCE trial did not demonstrate equivalence of a COER verapamil-based antihypertensive regimen compared with a regimen beginning with a diuretic or beta-blocker. When considered in the context of other trials of calcium antagonists, these data indicate that the effectiveness of calcium-channel therapy in reducing cardiovascular disease is similar but not better than diuretic or beta-blocker treatment.","Principal results of the Controlled Onset Verapamil Investigation of Cardiovascular End Points (CONVINCE) trial."
"257","JAMA.1491","NA",12709465,2003,"Hypertensive patients are often given a calcium antagonist to reduce cardiovascular disease risk, but the benefit compared with other drug classes is controversial.To determine whether initial therapy with controlled-onset extended-release (COER) verapamil is equivalent to a physician's choice of atenolol or hydrochlorothiazide in preventing cardiovascular disease.Double-blind, randomized clinical trial conducted at 661 centers in 15 countries. A total of 16 602 participants diagnosed as having hypertension and who had 1 or more additional risk factors for cardiovascular disease were enrolled between September 1996 and December 1998 and followed up until December 31, 2000. After a mean of 3 years of follow-up, the sponsor closed the study before unblinding the results.Initially, 8241 participants received 180 mg of COER verapamil and 8361 received either 50 mg of atenolol or 12.5 mg of hydrochlorothiazide. Other drugs (eg, diuretic, beta-blocker, or an angiotensin-converting enzyme inhibitor) could be added in specified sequence if needed.First occurrence of stroke, myocardial infarction, or cardiovascular disease-related death.Systolic and diastolic blood pressure were reduced by 13.6 mm Hg and 7.8 mm Hg for participants assigned to the COER verapamil group and by 13.5 and 7.1 mm Hg for partcipants assigned to the atenolol or hydrochlorothiazide group. There were 364 primary cardiovascular disease-related events that occurred in the COER verapamil group vs 365 in atenolol or hydrochlorothiazide group (hazard ratio [HR], 1.02; 95% confidence interval [CI], 0.88-1.18; P =.77). For fatal or nonfatal stroke, the HR was 1.15 (95% CI, 0.90-1.48); for fatal or nonfatal myocardial infarction, 0.82 (95% CI, 0.65-1.03); and for cardiovascular disease-related death, 1.09 (95% CI, 0.87-1.37). The HR was 1.05 (95% CI, 0.95-1.16) for any prespecified cardiovascular disease-related event and 1.08 (95% CI, 0.93-1.26) for all-cause mortality. Nonstroke hemorrhage was more common with participants in the COER-verapamil group (n = 118) compared with the atenolol or hydrochlorothiazide group (n = 79) (HR, 1.54 [95% CI, 1.16-2.04]; P =.003). More cardiovascular disease-related events occurred between 6 AM and noon in both the COER verapamil (99/277) and atenolol or hydrochlorothiazide (88/274) groups; HR, 1.15 (95% CI, 0.86-1.53).The CONVINCE trial did not demonstrate equivalence of a COER verapamil-based antihypertensive regimen compared with a regimen beginning with a diuretic or beta-blocker. When considered in the context of other trials of calcium antagonists, these data indicate that the effectiveness of calcium-channel therapy in reducing cardiovascular disease is similar but not better than diuretic or beta-blocker treatment.","Principal results of the Controlled Onset Verapamil Investigation of Cardiovascular End Points (CONVINCE) trial."
"258","JAMA.1491","NA",12709465,2003,"Hypertensive patients are often given a calcium antagonist to reduce cardiovascular disease risk, but the benefit compared with other drug classes is controversial.To determine whether initial therapy with controlled-onset extended-release (COER) verapamil is equivalent to a physician's choice of atenolol or hydrochlorothiazide in preventing cardiovascular disease.Double-blind, randomized clinical trial conducted at 661 centers in 15 countries. A total of 16 602 participants diagnosed as having hypertension and who had 1 or more additional risk factors for cardiovascular disease were enrolled between September 1996 and December 1998 and followed up until December 31, 2000. After a mean of 3 years of follow-up, the sponsor closed the study before unblinding the results.Initially, 8241 participants received 180 mg of COER verapamil and 8361 received either 50 mg of atenolol or 12.5 mg of hydrochlorothiazide. Other drugs (eg, diuretic, beta-blocker, or an angiotensin-converting enzyme inhibitor) could be added in specified sequence if needed.First occurrence of stroke, myocardial infarction, or cardiovascular disease-related death.Systolic and diastolic blood pressure were reduced by 13.6 mm Hg and 7.8 mm Hg for participants assigned to the COER verapamil group and by 13.5 and 7.1 mm Hg for partcipants assigned to the atenolol or hydrochlorothiazide group. There were 364 primary cardiovascular disease-related events that occurred in the COER verapamil group vs 365 in atenolol or hydrochlorothiazide group (hazard ratio [HR], 1.02; 95% confidence interval [CI], 0.88-1.18; P =.77). For fatal or nonfatal stroke, the HR was 1.15 (95% CI, 0.90-1.48); for fatal or nonfatal myocardial infarction, 0.82 (95% CI, 0.65-1.03); and for cardiovascular disease-related death, 1.09 (95% CI, 0.87-1.37). The HR was 1.05 (95% CI, 0.95-1.16) for any prespecified cardiovascular disease-related event and 1.08 (95% CI, 0.93-1.26) for all-cause mortality. Nonstroke hemorrhage was more common with participants in the COER-verapamil group (n = 118) compared with the atenolol or hydrochlorothiazide group (n = 79) (HR, 1.54 [95% CI, 1.16-2.04]; P =.003). More cardiovascular disease-related events occurred between 6 AM and noon in both the COER verapamil (99/277) and atenolol or hydrochlorothiazide (88/274) groups; HR, 1.15 (95% CI, 0.86-1.53).The CONVINCE trial did not demonstrate equivalence of a COER verapamil-based antihypertensive regimen compared with a regimen beginning with a diuretic or beta-blocker. When considered in the context of other trials of calcium antagonists, these data indicate that the effectiveness of calcium-channel therapy in reducing cardiovascular disease is similar but not better than diuretic or beta-blocker treatment.","Principal results of the Controlled Onset Verapamil Investigation of Cardiovascular End Points (CONVINCE) trial."
"259","JAMA.1491","NA",12709465,2003,"Hypertensive patients are often given a calcium antagonist to reduce cardiovascular disease risk, but the benefit compared with other drug classes is controversial.To determine whether initial therapy with controlled-onset extended-release (COER) verapamil is equivalent to a physician's choice of atenolol or hydrochlorothiazide in preventing cardiovascular disease.Double-blind, randomized clinical trial conducted at 661 centers in 15 countries. A total of 16 602 participants diagnosed as having hypertension and who had 1 or more additional risk factors for cardiovascular disease were enrolled between September 1996 and December 1998 and followed up until December 31, 2000. After a mean of 3 years of follow-up, the sponsor closed the study before unblinding the results.Initially, 8241 participants received 180 mg of COER verapamil and 8361 received either 50 mg of atenolol or 12.5 mg of hydrochlorothiazide. Other drugs (eg, diuretic, beta-blocker, or an angiotensin-converting enzyme inhibitor) could be added in specified sequence if needed.First occurrence of stroke, myocardial infarction, or cardiovascular disease-related death.Systolic and diastolic blood pressure were reduced by 13.6 mm Hg and 7.8 mm Hg for participants assigned to the COER verapamil group and by 13.5 and 7.1 mm Hg for partcipants assigned to the atenolol or hydrochlorothiazide group. There were 364 primary cardiovascular disease-related events that occurred in the COER verapamil group vs 365 in atenolol or hydrochlorothiazide group (hazard ratio [HR], 1.02; 95% confidence interval [CI], 0.88-1.18; P =.77). For fatal or nonfatal stroke, the HR was 1.15 (95% CI, 0.90-1.48); for fatal or nonfatal myocardial infarction, 0.82 (95% CI, 0.65-1.03); and for cardiovascular disease-related death, 1.09 (95% CI, 0.87-1.37). The HR was 1.05 (95% CI, 0.95-1.16) for any prespecified cardiovascular disease-related event and 1.08 (95% CI, 0.93-1.26) for all-cause mortality. Nonstroke hemorrhage was more common with participants in the COER-verapamil group (n = 118) compared with the atenolol or hydrochlorothiazide group (n = 79) (HR, 1.54 [95% CI, 1.16-2.04]; P =.003). More cardiovascular disease-related events occurred between 6 AM and noon in both the COER verapamil (99/277) and atenolol or hydrochlorothiazide (88/274) groups; HR, 1.15 (95% CI, 0.86-1.53).The CONVINCE trial did not demonstrate equivalence of a COER verapamil-based antihypertensive regimen compared with a regimen beginning with a diuretic or beta-blocker. When considered in the context of other trials of calcium antagonists, these data indicate that the effectiveness of calcium-channel therapy in reducing cardiovascular disease is similar but not better than diuretic or beta-blocker treatment.","Principal results of the Controlled Onset Verapamil Investigation of Cardiovascular End Points (CONVINCE) trial."
"260","JAMA.1491","NA",12709465,2003,"Hypertensive patients are often given a calcium antagonist to reduce cardiovascular disease risk, but the benefit compared with other drug classes is controversial.To determine whether initial therapy with controlled-onset extended-release (COER) verapamil is equivalent to a physician's choice of atenolol or hydrochlorothiazide in preventing cardiovascular disease.Double-blind, randomized clinical trial conducted at 661 centers in 15 countries. A total of 16 602 participants diagnosed as having hypertension and who had 1 or more additional risk factors for cardiovascular disease were enrolled between September 1996 and December 1998 and followed up until December 31, 2000. After a mean of 3 years of follow-up, the sponsor closed the study before unblinding the results.Initially, 8241 participants received 180 mg of COER verapamil and 8361 received either 50 mg of atenolol or 12.5 mg of hydrochlorothiazide. Other drugs (eg, diuretic, beta-blocker, or an angiotensin-converting enzyme inhibitor) could be added in specified sequence if needed.First occurrence of stroke, myocardial infarction, or cardiovascular disease-related death.Systolic and diastolic blood pressure were reduced by 13.6 mm Hg and 7.8 mm Hg for participants assigned to the COER verapamil group and by 13.5 and 7.1 mm Hg for partcipants assigned to the atenolol or hydrochlorothiazide group. There were 364 primary cardiovascular disease-related events that occurred in the COER verapamil group vs 365 in atenolol or hydrochlorothiazide group (hazard ratio [HR], 1.02; 95% confidence interval [CI], 0.88-1.18; P =.77). For fatal or nonfatal stroke, the HR was 1.15 (95% CI, 0.90-1.48); for fatal or nonfatal myocardial infarction, 0.82 (95% CI, 0.65-1.03); and for cardiovascular disease-related death, 1.09 (95% CI, 0.87-1.37). The HR was 1.05 (95% CI, 0.95-1.16) for any prespecified cardiovascular disease-related event and 1.08 (95% CI, 0.93-1.26) for all-cause mortality. Nonstroke hemorrhage was more common with participants in the COER-verapamil group (n = 118) compared with the atenolol or hydrochlorothiazide group (n = 79) (HR, 1.54 [95% CI, 1.16-2.04]; P =.003). More cardiovascular disease-related events occurred between 6 AM and noon in both the COER verapamil (99/277) and atenolol or hydrochlorothiazide (88/274) groups; HR, 1.15 (95% CI, 0.86-1.53).The CONVINCE trial did not demonstrate equivalence of a COER verapamil-based antihypertensive regimen compared with a regimen beginning with a diuretic or beta-blocker. When considered in the context of other trials of calcium antagonists, these data indicate that the effectiveness of calcium-channel therapy in reducing cardiovascular disease is similar but not better than diuretic or beta-blocker treatment.","Principal results of the Controlled Onset Verapamil Investigation of Cardiovascular End Points (CONVINCE) trial."
"261","JAMA.1141","NA",12734135,2003,"For most patients aged 65 years or older with cancer, hospice services are uniformly covered by Medicare. Hospice care is believed to improve care for patients at the end of life. However, few patients use hospice and others enroll too late to maximize the benefits of hospice services.Because type of insurance may affect use, we examined whether patients with Medicare managed care insurance enrolled in hospice earlier and had longer hospice stays than patients with Medicare fee-for-service (FFS) insurance.Retrospective analysis of the last year of life using the Linked Medicare-Tumor Registry Database in 1 of 9 Surveillance, Epidemiology, and End Results program coverage areas.A total of 260 090 Medicare beneficiaries aged 66 years or older diagnosed with first primary lung (n = 62 117), colorectal (n = 57 260), prostate (n = 59 826), female breast (n = 37 609), bladder (n = 19 598), pancreatic (n = 11 378), gastric (n = 9599), or liver (n = 2703) cancer between January 1, 1973, and December 31, 1996, and who died between January 1, 1988, and December 31, 1998.Time from diagnosis to hospice entry and hospice length of stay for patients enrolled in FFS vs managed care plans after adjusting for patient demographics, tumor registry, year of hospice entry, and type and cancer stage.Of the 260 090 patients, most were men (59%), white (85%), and enrolled in FFS (89.7%). Only 54 937 patients (21.1%) received hospice care before death. Hospice use varied by type of primary cancer ranging from 31.8% of patients with pancreatic cancer to 15.6% with bladder cancer. Managed care patients were more likely to use hospice than FFS patients (32.4% vs 19.8%, P<.001). Among hospice patients, median (interquartile range) length of stay was longer for managed care vs FFS patients (32 days [11-82] vs 25 days [9-66], P<.001). After adjustment, managed care patients had higher rates of hospice enrollment (adjusted hazard ratio [HR], 1.38; 95% CI, 1.35-1.42) and had a longer length of stay (adjusted HR, 0.91; 95% CI, 0.88-0.94) vs FFS patients. Managed care patients were less likely to enroll in hospice within 7 days of their death (18.6% vs 22.6%, P<.001) and somewhat more likely to enroll in hospice more than 180 days before death (7.8% vs 6.1%, P<.001); the results for each of the 8 cancer diagnoses were similar. Hospice enrollment and length of stay among managed care vs FFS patients differed significantly by region.Medicare beneficiaries enrolled in managed care had consistently higher rates of hospice use and significantly longer hospice stays than those enrolled in FFS. Although these differences may reflect patient and family preferences, our findings raise the possibility that some managed care plans are more successful at facilitating or encouraging hospice use for patients dying with cancer.","Hospice use among Medicare managed care and fee-for-service patients dying with cancer."
"262","JAMA.1151","NA",12734135,2003,"For most patients aged 65 years or older with cancer, hospice services are uniformly covered by Medicare. Hospice care is believed to improve care for patients at the end of life. However, few patients use hospice and others enroll too late to maximize the benefits of hospice services.Because type of insurance may affect use, we examined whether patients with Medicare managed care insurance enrolled in hospice earlier and had longer hospice stays than patients with Medicare fee-for-service (FFS) insurance.Retrospective analysis of the last year of life using the Linked Medicare-Tumor Registry Database in 1 of 9 Surveillance, Epidemiology, and End Results program coverage areas.A total of 260 090 Medicare beneficiaries aged 66 years or older diagnosed with first primary lung (n = 62 117), colorectal (n = 57 260), prostate (n = 59 826), female breast (n = 37 609), bladder (n = 19 598), pancreatic (n = 11 378), gastric (n = 9599), or liver (n = 2703) cancer between January 1, 1973, and December 31, 1996, and who died between January 1, 1988, and December 31, 1998.Time from diagnosis to hospice entry and hospice length of stay for patients enrolled in FFS vs managed care plans after adjusting for patient demographics, tumor registry, year of hospice entry, and type and cancer stage.Of the 260 090 patients, most were men (59%), white (85%), and enrolled in FFS (89.7%). Only 54 937 patients (21.1%) received hospice care before death. Hospice use varied by type of primary cancer ranging from 31.8% of patients with pancreatic cancer to 15.6% with bladder cancer. Managed care patients were more likely to use hospice than FFS patients (32.4% vs 19.8%, P<.001). Among hospice patients, median (interquartile range) length of stay was longer for managed care vs FFS patients (32 days [11-82] vs 25 days [9-66], P<.001). After adjustment, managed care patients had higher rates of hospice enrollment (adjusted hazard ratio [HR], 1.38; 95% CI, 1.35-1.42) and had a longer length of stay (adjusted HR, 0.91; 95% CI, 0.88-0.94) vs FFS patients. Managed care patients were less likely to enroll in hospice within 7 days of their death (18.6% vs 22.6%, P<.001) and somewhat more likely to enroll in hospice more than 180 days before death (7.8% vs 6.1%, P<.001); the results for each of the 8 cancer diagnoses were similar. Hospice enrollment and length of stay among managed care vs FFS patients differed significantly by region.Medicare beneficiaries enrolled in managed care had consistently higher rates of hospice use and significantly longer hospice stays than those enrolled in FFS. Although these differences may reflect patient and family preferences, our findings raise the possibility that some managed care plans are more successful at facilitating or encouraging hospice use for patients dying with cancer.","Hospice use among Medicare managed care and fee-for-service patients dying with cancer."
"263","JAMA.171","NA",12746362,2003,"Clinicians have observed various patterns of functional decline at the end of life, but few empirical data have tested these patterns in large populations.To determine if functional decline differs among 4 types of illness trajectories: sudden death, cancer death, death from organ failure, and frailty.Cohort analysis of data from 4 US regions in the prospective, longitudinal Established Populations for Epidemiologic Studies of the Elderly (EPESE) study. Of the 14 456 participants aged 65 years or older who provided interviews at baseline (1981-1987), 4871 died during the first 6 years of follow-up; 4190 (86%) of these provided interviews within 1 year before dying. These decedents were evenly distributed in 12 cohorts based on the number of months between the final interview and death.Self- or proxy-reported physical function (performance of 7 activities of daily living [ADLs]) within 1 year prior to death; predicted ADL dependency prior to death.Mean function declined across the 12 cohorts, simulating individual decline in the final year of life. Sudden death decedents were highly functional even in the last month before death (mean [95% confidence interval [CI]] numbers of ADL dependencies: 0.69 [0.19-1.19] at 12 months before death vs 1.22 [0.59-1.85] at the final month of life, P =.20); cancer decedents were highly functional early in their final year but markedly more disabled 3 months prior to death (0.77 [0.30-1.24] vs 4.09 [3.37-4.81], P<.001); organ failure decedents experienced a fluctuating pattern of decline, with substantially poorer function during the last 3 months before death (2.10 [1.49-2.70] vs 3.66 [2.94-4.38], P<.001); and frail decedents were relatively more disabled in the final year and especially dependent during the last month (2.92 [2.24-3.60] vs 5.84 [5.33-6.35], P<.001). After controlling for age, sex, race, education, marital status, interval between final interview and death, and other demographic differences, frail decedents were more than 8 times more likely than sudden death decedents to be ADL dependent (OR, 8.32 [95% CI, 6.46-10.73); cancer decedents, one and a half times more likely (OR, 1.57 [95% CI, 1.25-1.96]); and organ failure decedents, 3 times more likely (OR, 3.00 [95% CI, 2.39-3.77]).Trajectories of functional decline at the end of life are quite variable. Differentiating among expected trajectories and related needs would help shape tailored strategies and better programs of care prior to death.","Patterns of functional decline at the end of life."
"264","JAMA.172","NA",12746362,2003,"Clinicians have observed various patterns of functional decline at the end of life, but few empirical data have tested these patterns in large populations.To determine if functional decline differs among 4 types of illness trajectories: sudden death, cancer death, death from organ failure, and frailty.Cohort analysis of data from 4 US regions in the prospective, longitudinal Established Populations for Epidemiologic Studies of the Elderly (EPESE) study. Of the 14 456 participants aged 65 years or older who provided interviews at baseline (1981-1987), 4871 died during the first 6 years of follow-up; 4190 (86%) of these provided interviews within 1 year before dying. These decedents were evenly distributed in 12 cohorts based on the number of months between the final interview and death.Self- or proxy-reported physical function (performance of 7 activities of daily living [ADLs]) within 1 year prior to death; predicted ADL dependency prior to death.Mean function declined across the 12 cohorts, simulating individual decline in the final year of life. Sudden death decedents were highly functional even in the last month before death (mean [95% confidence interval [CI]] numbers of ADL dependencies: 0.69 [0.19-1.19] at 12 months before death vs 1.22 [0.59-1.85] at the final month of life, P =.20); cancer decedents were highly functional early in their final year but markedly more disabled 3 months prior to death (0.77 [0.30-1.24] vs 4.09 [3.37-4.81], P<.001); organ failure decedents experienced a fluctuating pattern of decline, with substantially poorer function during the last 3 months before death (2.10 [1.49-2.70] vs 3.66 [2.94-4.38], P<.001); and frail decedents were relatively more disabled in the final year and especially dependent during the last month (2.92 [2.24-3.60] vs 5.84 [5.33-6.35], P<.001). After controlling for age, sex, race, education, marital status, interval between final interview and death, and other demographic differences, frail decedents were more than 8 times more likely than sudden death decedents to be ADL dependent (OR, 8.32 [95% CI, 6.46-10.73); cancer decedents, one and a half times more likely (OR, 1.57 [95% CI, 1.25-1.96]); and organ failure decedents, 3 times more likely (OR, 3.00 [95% CI, 2.39-3.77]).Trajectories of functional decline at the end of life are quite variable. Differentiating among expected trajectories and related needs would help shape tailored strategies and better programs of care prior to death.","Patterns of functional decline at the end of life."
"265","JAMA.173","NA",12746362,2003,"Clinicians have observed various patterns of functional decline at the end of life, but few empirical data have tested these patterns in large populations.To determine if functional decline differs among 4 types of illness trajectories: sudden death, cancer death, death from organ failure, and frailty.Cohort analysis of data from 4 US regions in the prospective, longitudinal Established Populations for Epidemiologic Studies of the Elderly (EPESE) study. Of the 14 456 participants aged 65 years or older who provided interviews at baseline (1981-1987), 4871 died during the first 6 years of follow-up; 4190 (86%) of these provided interviews within 1 year before dying. These decedents were evenly distributed in 12 cohorts based on the number of months between the final interview and death.Self- or proxy-reported physical function (performance of 7 activities of daily living [ADLs]) within 1 year prior to death; predicted ADL dependency prior to death.Mean function declined across the 12 cohorts, simulating individual decline in the final year of life. Sudden death decedents were highly functional even in the last month before death (mean [95% confidence interval [CI]] numbers of ADL dependencies: 0.69 [0.19-1.19] at 12 months before death vs 1.22 [0.59-1.85] at the final month of life, P =.20); cancer decedents were highly functional early in their final year but markedly more disabled 3 months prior to death (0.77 [0.30-1.24] vs 4.09 [3.37-4.81], P<.001); organ failure decedents experienced a fluctuating pattern of decline, with substantially poorer function during the last 3 months before death (2.10 [1.49-2.70] vs 3.66 [2.94-4.38], P<.001); and frail decedents were relatively more disabled in the final year and especially dependent during the last month (2.92 [2.24-3.60] vs 5.84 [5.33-6.35], P<.001). After controlling for age, sex, race, education, marital status, interval between final interview and death, and other demographic differences, frail decedents were more than 8 times more likely than sudden death decedents to be ADL dependent (OR, 8.32 [95% CI, 6.46-10.73); cancer decedents, one and a half times more likely (OR, 1.57 [95% CI, 1.25-1.96]); and organ failure decedents, 3 times more likely (OR, 3.00 [95% CI, 2.39-3.77]).Trajectories of functional decline at the end of life are quite variable. Differentiating among expected trajectories and related needs would help shape tailored strategies and better programs of care prior to death.","Patterns of functional decline at the end of life."
"266","JAMA.170","0.001",12746363,2003,"Although cancers occur with increased frequency in children with human immunodeficiency virus (HIV) infection, the specific clinical, immunological, and viral risk factors for malignancy have not been identified.To identify risk factors for malignancy among HIV-infected children.Design, Setting, andA multicenter case-control study of children with HIV at 26 institutions participating in the Pediatric Oncology Group. Forty-three case patients with a new malignancy and 74 control patients without a malignancy were matched based on the duration of their infection. Patients were enrolled between January 1992 and July 1998.Clinical and laboratory factors assessed as putative risk factors included demographic characteristics, HIV characteristics, prior antiretroviral treatment, and CD4 cell count. Coviral infections with Epstein-Barr virus (EBV), cytomegalovirus, and human herpesvirus 6 were assessed by semiquantitative polymerase chain reaction assays and serological testing.Case malignancy diagnoses included 28 non-Hodgkin lymphoma, 4 B-cell acute lymphoblastic leukemia, 1 Hodgkin disease, 8 leiomyosarcoma, 1 hepatoblastoma, and 1 schwannoma. Epstein-Barr virus viral load of more than 50 viral genome copies per 105 peripheral blood mononuclear cells was strongly associated with cancer risk but only for children with CD4 cell counts of at least 200/ microL (odds ratio [OR], 11.33; 95% confidence interval [CI], 2.09-65.66, P<.001). High EBV viral load was not associated with cancer for children with CD4 cell counts of less than 200/ microL (OR, 1.12; 95% CI, 0.13-9.62; P =.99). Zidovudine antiretroviral therapy did not confer a significant protective effect for either the high (OR, 0.81; 95% CI, 0.22-3.09; P =.77) or the low CD4 cell count groups (OR, 0.27; 95% CI, 0.04-1.46; P =.16). The route of HIV infection was not associated with increased cancer risk.Route of infection, demographic characteristics, and zidovudine use were not associated with the development of malignancy in HIV-infected children. High viral burden with EBV was associated with the development of malignancy in HIV-infected children although the effect was modified by CD4 cell count. The pathogenesis of HIV-related pediatric malignancies remains unclear and other contributing risk factors can be elucidated only through further study.","Risk factors for pediatric human immunodeficiency virus-related malignancy."
"267","JAMA.194","0.99",12746363,2003,"Although cancers occur with increased frequency in children with human immunodeficiency virus (HIV) infection, the specific clinical, immunological, and viral risk factors for malignancy have not been identified.To identify risk factors for malignancy among HIV-infected children.Design, Setting, andA multicenter case-control study of children with HIV at 26 institutions participating in the Pediatric Oncology Group. Forty-three case patients with a new malignancy and 74 control patients without a malignancy were matched based on the duration of their infection. Patients were enrolled between January 1992 and July 1998.Clinical and laboratory factors assessed as putative risk factors included demographic characteristics, HIV characteristics, prior antiretroviral treatment, and CD4 cell count. Coviral infections with Epstein-Barr virus (EBV), cytomegalovirus, and human herpesvirus 6 were assessed by semiquantitative polymerase chain reaction assays and serological testing.Case malignancy diagnoses included 28 non-Hodgkin lymphoma, 4 B-cell acute lymphoblastic leukemia, 1 Hodgkin disease, 8 leiomyosarcoma, 1 hepatoblastoma, and 1 schwannoma. Epstein-Barr virus viral load of more than 50 viral genome copies per 105 peripheral blood mononuclear cells was strongly associated with cancer risk but only for children with CD4 cell counts of at least 200/ microL (odds ratio [OR], 11.33; 95% confidence interval [CI], 2.09-65.66, P<.001). High EBV viral load was not associated with cancer for children with CD4 cell counts of less than 200/ microL (OR, 1.12; 95% CI, 0.13-9.62; P =.99). Zidovudine antiretroviral therapy did not confer a significant protective effect for either the high (OR, 0.81; 95% CI, 0.22-3.09; P =.77) or the low CD4 cell count groups (OR, 0.27; 95% CI, 0.04-1.46; P =.16). The route of HIV infection was not associated with increased cancer risk.Route of infection, demographic characteristics, and zidovudine use were not associated with the development of malignancy in HIV-infected children. High viral burden with EBV was associated with the development of malignancy in HIV-infected children although the effect was modified by CD4 cell count. The pathogenesis of HIV-related pediatric malignancies remains unclear and other contributing risk factors can be elucidated only through further study.","Risk factors for pediatric human immunodeficiency virus-related malignancy."
"268","JAMA.195","0.77",12746363,2003,"Although cancers occur with increased frequency in children with human immunodeficiency virus (HIV) infection, the specific clinical, immunological, and viral risk factors for malignancy have not been identified.To identify risk factors for malignancy among HIV-infected children.Design, Setting, andA multicenter case-control study of children with HIV at 26 institutions participating in the Pediatric Oncology Group. Forty-three case patients with a new malignancy and 74 control patients without a malignancy were matched based on the duration of their infection. Patients were enrolled between January 1992 and July 1998.Clinical and laboratory factors assessed as putative risk factors included demographic characteristics, HIV characteristics, prior antiretroviral treatment, and CD4 cell count. Coviral infections with Epstein-Barr virus (EBV), cytomegalovirus, and human herpesvirus 6 were assessed by semiquantitative polymerase chain reaction assays and serological testing.Case malignancy diagnoses included 28 non-Hodgkin lymphoma, 4 B-cell acute lymphoblastic leukemia, 1 Hodgkin disease, 8 leiomyosarcoma, 1 hepatoblastoma, and 1 schwannoma. Epstein-Barr virus viral load of more than 50 viral genome copies per 105 peripheral blood mononuclear cells was strongly associated with cancer risk but only for children with CD4 cell counts of at least 200/ microL (odds ratio [OR], 11.33; 95% confidence interval [CI], 2.09-65.66, P<.001). High EBV viral load was not associated with cancer for children with CD4 cell counts of less than 200/ microL (OR, 1.12; 95% CI, 0.13-9.62; P =.99). Zidovudine antiretroviral therapy did not confer a significant protective effect for either the high (OR, 0.81; 95% CI, 0.22-3.09; P =.77) or the low CD4 cell count groups (OR, 0.27; 95% CI, 0.04-1.46; P =.16). The route of HIV infection was not associated with increased cancer risk.Route of infection, demographic characteristics, and zidovudine use were not associated with the development of malignancy in HIV-infected children. High viral burden with EBV was associated with the development of malignancy in HIV-infected children although the effect was modified by CD4 cell count. The pathogenesis of HIV-related pediatric malignancies remains unclear and other contributing risk factors can be elucidated only through further study.","Risk factors for pediatric human immunodeficiency virus-related malignancy."
"269","JAMA.196","0.16",12746363,2003,"Although cancers occur with increased frequency in children with human immunodeficiency virus (HIV) infection, the specific clinical, immunological, and viral risk factors for malignancy have not been identified.To identify risk factors for malignancy among HIV-infected children.Design, Setting, andA multicenter case-control study of children with HIV at 26 institutions participating in the Pediatric Oncology Group. Forty-three case patients with a new malignancy and 74 control patients without a malignancy were matched based on the duration of their infection. Patients were enrolled between January 1992 and July 1998.Clinical and laboratory factors assessed as putative risk factors included demographic characteristics, HIV characteristics, prior antiretroviral treatment, and CD4 cell count. Coviral infections with Epstein-Barr virus (EBV), cytomegalovirus, and human herpesvirus 6 were assessed by semiquantitative polymerase chain reaction assays and serological testing.Case malignancy diagnoses included 28 non-Hodgkin lymphoma, 4 B-cell acute lymphoblastic leukemia, 1 Hodgkin disease, 8 leiomyosarcoma, 1 hepatoblastoma, and 1 schwannoma. Epstein-Barr virus viral load of more than 50 viral genome copies per 105 peripheral blood mononuclear cells was strongly associated with cancer risk but only for children with CD4 cell counts of at least 200/ microL (odds ratio [OR], 11.33; 95% confidence interval [CI], 2.09-65.66, P<.001). High EBV viral load was not associated with cancer for children with CD4 cell counts of less than 200/ microL (OR, 1.12; 95% CI, 0.13-9.62; P =.99). Zidovudine antiretroviral therapy did not confer a significant protective effect for either the high (OR, 0.81; 95% CI, 0.22-3.09; P =.77) or the low CD4 cell count groups (OR, 0.27; 95% CI, 0.04-1.46; P =.16). The route of HIV infection was not associated with increased cancer risk.Route of infection, demographic characteristics, and zidovudine use were not associated with the development of malignancy in HIV-infected children. High viral burden with EBV was associated with the development of malignancy in HIV-infected children although the effect was modified by CD4 cell count. The pathogenesis of HIV-related pediatric malignancies remains unclear and other contributing risk factors can be elucidated only through further study.","Risk factors for pediatric human immunodeficiency virus-related malignancy."
"270","JAMA.1461","0.01",12771112,2003,"Postmenopausal women have a greater risk than men of developing Alzheimer disease, but studies of the effects of estrogen therapy on Alzheimer disease have been inconsistent. On July 8, 2002, the study drugs, estrogen plus progestin, in the Women's Health Initiative (WHI) trial were discontinued because of certain increased health risks in women receiving combined hormone therapy.To evaluate the effect of estrogen plus progestin on the incidence of dementia and mild cognitive impairment compared with placebo.The Women's Health Initiative Memory Study (WHIMS), a randomized, double-blind, placebo-controlled clinical trial, began enrolling participants from the Women's Health Initiative (WHI) estrogen plus progestin trial in May 1996. Of the 4894 eligible participants of the WHI study, 4532 (92.6%) postmenopausal women free of probable dementia, aged 65 years or older, and recruited from 39 of 40 WHI clinical centers were enrolled in the WHIMS.Participants received either 1 daily tablet of 0.625 mg of conjugated equine estrogen plus 2.5 mg of medroxyprogesterone acetate (n = 2229), or a matching placebo (n = 2303).Incidence of probable dementia (primary outcome) and mild cognitive impairment (secondary outcome) were identified through a structured clinical assessment.The mean (SD) time between the date of randomization into WHI and the last Modified Mini-Mental State Examination (3MSE) for all WHIMS participants was 4.05 (1.19) years. Overall, 61 women were diagnosed with probable dementia, 40 (66%) in the estrogen plus progestin group compared with 21 (34%) in the placebo group. The hazard ratio (HR) for probable dementia was 2.05 (95% confidence interval [CI], 1.21-3.48; 45 vs 22 per 10 000 person-years; P =.01). This increased risk would result in an additional 23 cases of dementia per 10 000 women per year. Alzheimer disease was the most common classification of dementia in both study groups. Treatment effects on mild cognitive impairment did not differ between groups (HR, 1.07; 95% CI, 0.74-1.55; 63 vs 59 cases per 10 000 person-years; P =.72).Estrogen plus progestin therapy increased the risk for probable dementia in postmenopausal women aged 65 years or older. In addition, estrogen plus progestin therapy did not prevent mild cognitive impairment in these women. These findings, coupled with previously reported WHI data, support the conclusion that the risks of estrogen plus progestin outweigh the benefits.","Estrogen plus progestin and the incidence of dementia and mild cognitive impairment in postmenopausal women: the Women's Health Initiative Memory Study: a randomized controlled trial."
"271","JAMA.1471","0.72",12771112,2003,"Postmenopausal women have a greater risk than men of developing Alzheimer disease, but studies of the effects of estrogen therapy on Alzheimer disease have been inconsistent. On July 8, 2002, the study drugs, estrogen plus progestin, in the Women's Health Initiative (WHI) trial were discontinued because of certain increased health risks in women receiving combined hormone therapy.To evaluate the effect of estrogen plus progestin on the incidence of dementia and mild cognitive impairment compared with placebo.The Women's Health Initiative Memory Study (WHIMS), a randomized, double-blind, placebo-controlled clinical trial, began enrolling participants from the Women's Health Initiative (WHI) estrogen plus progestin trial in May 1996. Of the 4894 eligible participants of the WHI study, 4532 (92.6%) postmenopausal women free of probable dementia, aged 65 years or older, and recruited from 39 of 40 WHI clinical centers were enrolled in the WHIMS.Participants received either 1 daily tablet of 0.625 mg of conjugated equine estrogen plus 2.5 mg of medroxyprogesterone acetate (n = 2229), or a matching placebo (n = 2303).Incidence of probable dementia (primary outcome) and mild cognitive impairment (secondary outcome) were identified through a structured clinical assessment.The mean (SD) time between the date of randomization into WHI and the last Modified Mini-Mental State Examination (3MSE) for all WHIMS participants was 4.05 (1.19) years. Overall, 61 women were diagnosed with probable dementia, 40 (66%) in the estrogen plus progestin group compared with 21 (34%) in the placebo group. The hazard ratio (HR) for probable dementia was 2.05 (95% confidence interval [CI], 1.21-3.48; 45 vs 22 per 10 000 person-years; P =.01). This increased risk would result in an additional 23 cases of dementia per 10 000 women per year. Alzheimer disease was the most common classification of dementia in both study groups. Treatment effects on mild cognitive impairment did not differ between groups (HR, 1.07; 95% CI, 0.74-1.55; 63 vs 59 cases per 10 000 person-years; P =.72).Estrogen plus progestin therapy increased the risk for probable dementia in postmenopausal women aged 65 years or older. In addition, estrogen plus progestin therapy did not prevent mild cognitive impairment in these women. These findings, coupled with previously reported WHI data, support the conclusion that the risks of estrogen plus progestin outweigh the benefits.","Estrogen plus progestin and the incidence of dementia and mild cognitive impairment in postmenopausal women: the Women's Health Initiative Memory Study: a randomized controlled trial."
"272","JAMA.1431","NA",12783915,2003,"Prior to 1997, home health agencies (HHAs) were reimbursed on a fee-for-service basis and had incentives to provide more services. The 1997 Balanced Budget Act (BBA) reduced payments for home care services to help control Medicare spending.To examine the length of stay in home care before and after the 1997 BBA.Cross-sectional study of home care patients in the 1996 and 1998 National Home and Hospice Care Surveys, which surveyed 1053 HHAs in 1996 and 1088 HHAs in 1998.Nationally representative random sample of home care patients with Medicare coverage in 1996 (4127 patients) and 1998 (4051 patients).Length of stay in home care (based on the number of days a patient was enrolled in home care services).From 1996 to 1998, unadjusted median length of stay decreased by 16 days for all home care patients (60-44 days, P =.002). The decrease affected for-profit HHAs more than not-for-profit HHAs (111-55 days [51% decrease, P =.002] vs 46-36 days [22% decrease, P =.042]). In a Cox proportional hazards model of time to discharge from home care, post-BBA year (1998) was associated with a shorter length of stay in home care (adjusted hazard ratio [aHR] for home care discharge, 1.39 [95% confidence interval [CI], 1.19-1.61]), and for-profit status was associated with a longer length of stay in home care (aHR, 0.82 [95% CI, 0.71-0.94]) after adjusting for patient demographics, diagnoses, and functional status.After the 1997 BBA, length of stay in home care decreased among Medicare patients, particularly among those receiving care from for-profit HHAs.","Length of stay in home care before and after the 1997 Balanced Budget Act."
"273","JAMA.1441","NA",12783915,2003,"Prior to 1997, home health agencies (HHAs) were reimbursed on a fee-for-service basis and had incentives to provide more services. The 1997 Balanced Budget Act (BBA) reduced payments for home care services to help control Medicare spending.To examine the length of stay in home care before and after the 1997 BBA.Cross-sectional study of home care patients in the 1996 and 1998 National Home and Hospice Care Surveys, which surveyed 1053 HHAs in 1996 and 1088 HHAs in 1998.Nationally representative random sample of home care patients with Medicare coverage in 1996 (4127 patients) and 1998 (4051 patients).Length of stay in home care (based on the number of days a patient was enrolled in home care services).From 1996 to 1998, unadjusted median length of stay decreased by 16 days for all home care patients (60-44 days, P =.002). The decrease affected for-profit HHAs more than not-for-profit HHAs (111-55 days [51% decrease, P =.002] vs 46-36 days [22% decrease, P =.042]). In a Cox proportional hazards model of time to discharge from home care, post-BBA year (1998) was associated with a shorter length of stay in home care (adjusted hazard ratio [aHR] for home care discharge, 1.39 [95% confidence interval [CI], 1.19-1.61]), and for-profit status was associated with a longer length of stay in home care (aHR, 0.82 [95% CI, 0.71-0.94]) after adjusting for patient demographics, diagnoses, and functional status.After the 1997 BBA, length of stay in home care decreased among Medicare patients, particularly among those receiving care from for-profit HHAs.","Length of stay in home care before and after the 1997 Balanced Budget Act."
"274","JAMA.169","0.001",12799403,2003,"Increases in neonatal mortality for infants born on the weekend were last noted several decades ago. Although the current health care environment has raised concern about the adequacy of weekend care, there have been no contemporary evaluations of daily patterns of births, obstetric intervention, and case mix-adjusted neonatal mortality.To compare the neonatal mortality of infants born on weekdays and weekends.Case series of 1 615 041 live births (weight >or=500 g) in California between 1995-1997 to determine patterns of births, cesarean deliveries, and neonatal deaths. Analyses were stratified by birth weight and delivery method. To assess the role of weekend differences in case mix, observed and birth weight-adjusted odds ratios (ORs) for increased weekend mortality were estimated using logistic regression.Birth weight-adjusted neonatal mortality.There was a 17.5% decrease in births on weekends, accompanied by a decrease in the proportion of cesarean deliveries from 22% on weekdays to 16% on weekends. Weekend decreases in births were least pronounced in smaller infants, resulting in a weekend concentration of high-mortality, very low-birth-weight (<1500 g) births. Observed neonatal mortality increased from 2.80 per 1000 weekday births to 3.12 per 1000 weekend births (OR, 1.12; 95% confidence interval [CI], 1.05-1.19; P =.001) for all births, and from 4.94 to 6.85 (OR, 1.39; 95% CI, 1.25-1.55; P<.001) for cesarean deliveries. After adjusting for birth weight, the increased odds of death for infants born on the weekend were no longer significant.The provision of optimal care regardless of the day of week is an important goal for perinatal medicine. Comparing the neonatal mortality of infants born on weekdays and weekends provides a straightforward assessment of this goal. After controlling for birth weight, we found no evidence that the quality of perinatal care in California was compromised during the weekend.","Neonatal mortality in weekend vs weekday births."
"275","JAMA.193","0.001",12799403,2003,"Increases in neonatal mortality for infants born on the weekend were last noted several decades ago. Although the current health care environment has raised concern about the adequacy of weekend care, there have been no contemporary evaluations of daily patterns of births, obstetric intervention, and case mix-adjusted neonatal mortality.To compare the neonatal mortality of infants born on weekdays and weekends.Case series of 1 615 041 live births (weight >or=500 g) in California between 1995-1997 to determine patterns of births, cesarean deliveries, and neonatal deaths. Analyses were stratified by birth weight and delivery method. To assess the role of weekend differences in case mix, observed and birth weight-adjusted odds ratios (ORs) for increased weekend mortality were estimated using logistic regression.Birth weight-adjusted neonatal mortality.There was a 17.5% decrease in births on weekends, accompanied by a decrease in the proportion of cesarean deliveries from 22% on weekdays to 16% on weekends. Weekend decreases in births were least pronounced in smaller infants, resulting in a weekend concentration of high-mortality, very low-birth-weight (<1500 g) births. Observed neonatal mortality increased from 2.80 per 1000 weekday births to 3.12 per 1000 weekend births (OR, 1.12; 95% confidence interval [CI], 1.05-1.19; P =.001) for all births, and from 4.94 to 6.85 (OR, 1.39; 95% CI, 1.25-1.55; P<.001) for cesarean deliveries. After adjusting for birth weight, the increased odds of death for infants born on the weekend were no longer significant.The provision of optimal care regardless of the day of week is an important goal for perinatal medicine. Comparing the neonatal mortality of infants born on weekdays and weekends provides a straightforward assessment of this goal. After controlling for birth weight, we found no evidence that the quality of perinatal care in California was compromised during the weekend.","Neonatal mortality in weekend vs weekday births."
"276","Lancet.1610","0.016",12801735,2003,"Controversy exists as to whether neoadjuvant chemotherapy improves survival in patients with invasive bladder cancer, despite randomised controlled trials of more than 3000 patients. We undertook a systematic review and meta-analysis to assess the effect of such treatment on survival in patients with this disease.We analysed updated data for 2688 individual patients from ten available randomised trials.Platinum-based combination chemotherapy showed a significant benefit to overall survival (combined hazard ratio [HR] 0.87 [95% CI 0.78-0.98, p=0.016]; 13% reduction in risk of death; 5% absolute benefit at 5 years [1-7]; overall survival increased from 45% to 50%). This effect was observed irrespective of the type of local treatment, and did not vary between subgroups of patients. The HR for all trials, including those using single-agent cisplatin, tended to favour neoadjuvant chemotherapy (HR=0.91, 95% CI 0.83-1.01) although this tendency was not significant (p=0.084). Although platinum based combination chemotherapy was beneficial, there was no evidence to support the use of single-agent platinum; indeed, there was a significant difference in the effect between these groups of trials (p=0.044).This improvement in survival encourages the use of platinum-based combination chemotherapy for patients with invasive bladder cancer.","Neoadjuvant chemotherapy in invasive bladder cancer: a systematic review and meta-analysis."
"277","Lancet.1710","NA",12801735,2003,"Controversy exists as to whether neoadjuvant chemotherapy improves survival in patients with invasive bladder cancer, despite randomised controlled trials of more than 3000 patients. We undertook a systematic review and meta-analysis to assess the effect of such treatment on survival in patients with this disease.We analysed updated data for 2688 individual patients from ten available randomised trials.Platinum-based combination chemotherapy showed a significant benefit to overall survival (combined hazard ratio [HR] 0.87 [95% CI 0.78-0.98, p=0.016]; 13% reduction in risk of death; 5% absolute benefit at 5 years [1-7]; overall survival increased from 45% to 50%). This effect was observed irrespective of the type of local treatment, and did not vary between subgroups of patients. The HR for all trials, including those using single-agent cisplatin, tended to favour neoadjuvant chemotherapy (HR=0.91, 95% CI 0.83-1.01) although this tendency was not significant (p=0.084). Although platinum based combination chemotherapy was beneficial, there was no evidence to support the use of single-agent platinum; indeed, there was a significant difference in the effect between these groups of trials (p=0.044).This improvement in survival encourages the use of platinum-based combination chemotherapy for patients with invasive bladder cancer.","Neoadjuvant chemotherapy in invasive bladder cancer: a systematic review and meta-analysis."
"278","JAMA.1101","0.001",12824205,2003,"The Women's Health Initiative trial of combined estrogen plus progestin was stopped early when overall health risks, including invasive breast cancer, exceeded benefits. Outstanding issues not previously addressed include characteristics of breast cancers observed among women using hormones and whether diagnosis may be influenced by hormone effects on mammography.To determine the relationship among estrogen plus progestin use, breast cancer characteristics, and mammography recommendations.Following a comprehensive breast cancer risk assessment, 16 608 postmenopausal women aged 50 to 79 years with an intact uterus were randomly assigned to receive combined conjugated equine estrogens (0.625 mg/d) plus medroxyprogesterone acetate (2.5 mg/d) or placebo from 1993 to 1998 at 40 clinical centers. Screening mammography and clinical breast examinations were performed at baseline and yearly thereafter.Breast cancer number and characteristics, and frequency of abnormal mammograms by estrogen plus progestin exposure.In intent-to-treat analyses, estrogen plus progestin increased total (245 vs 185 cases; hazard ratio [HR], 1.24; weighted P<.001) and invasive (199 vs 150 cases; HR, 1.24; weighted P =.003) breast cancers compared with placebo. The invasive breast cancers diagnosed in the estrogen plus progestin group were similar in histology and grade but were larger (mean [SD], 1.7 cm [1.1] vs 1.5 cm [0.9], respectively; P =.04) and were at more advanced stage (regional/metastatic 25.4% vs 16.0%, respectively; P =.04) compared with those diagnosed in the placebo group. After 1 year, the percentage of women with abnormal mammograms was substantially greater in the estrogen plus progestin group (716 [9.4%] of 7656) compared with placebo group (398 [5.4%] of 7310; P<.001), a pattern which continued for the study duration.Relatively short-term combined estrogen plus progestin use increases incident breast cancers, which are diagnosed at a more advanced stage compared with placebo use, and also substantially increases the percentage of women with abnormal mammograms. These results suggest estrogen plus progestin may stimulate breast cancer growth and hinder breast cancer diagnosis.","Influence of estrogen plus progestin on breast cancer and mammography in healthy postmenopausal women: the Women's Health Initiative Randomized Trial."
"279","JAMA.1401","0.003",12824205,2003,"The Women's Health Initiative trial of combined estrogen plus progestin was stopped early when overall health risks, including invasive breast cancer, exceeded benefits. Outstanding issues not previously addressed include characteristics of breast cancers observed among women using hormones and whether diagnosis may be influenced by hormone effects on mammography.To determine the relationship among estrogen plus progestin use, breast cancer characteristics, and mammography recommendations.Following a comprehensive breast cancer risk assessment, 16 608 postmenopausal women aged 50 to 79 years with an intact uterus were randomly assigned to receive combined conjugated equine estrogens (0.625 mg/d) plus medroxyprogesterone acetate (2.5 mg/d) or placebo from 1993 to 1998 at 40 clinical centers. Screening mammography and clinical breast examinations were performed at baseline and yearly thereafter.Breast cancer number and characteristics, and frequency of abnormal mammograms by estrogen plus progestin exposure.In intent-to-treat analyses, estrogen plus progestin increased total (245 vs 185 cases; hazard ratio [HR], 1.24; weighted P<.001) and invasive (199 vs 150 cases; HR, 1.24; weighted P =.003) breast cancers compared with placebo. The invasive breast cancers diagnosed in the estrogen plus progestin group were similar in histology and grade but were larger (mean [SD], 1.7 cm [1.1] vs 1.5 cm [0.9], respectively; P =.04) and were at more advanced stage (regional/metastatic 25.4% vs 16.0%, respectively; P =.04) compared with those diagnosed in the placebo group. After 1 year, the percentage of women with abnormal mammograms was substantially greater in the estrogen plus progestin group (716 [9.4%] of 7656) compared with placebo group (398 [5.4%] of 7310; P<.001), a pattern which continued for the study duration.Relatively short-term combined estrogen plus progestin use increases incident breast cancers, which are diagnosed at a more advanced stage compared with placebo use, and also substantially increases the percentage of women with abnormal mammograms. These results suggest estrogen plus progestin may stimulate breast cancer growth and hinder breast cancer diagnosis.","Influence of estrogen plus progestin on breast cancer and mammography in healthy postmenopausal women: the Women's Health Initiative Randomized Trial."
"280","JAMA.166","NA",12837713,2003,"Gastroesophageal reflux and obesity are both increasing in prevalence. The scientific evidence for an association between these conditions is sparse and contradictory. A difference between sexes concerning this relation has been proposed.To evaluate the relation between body mass and gastroesophageal reflux symptoms and determine how this relation is influenced by female sex hormones.Population-based, cross-sectional, case-control study.Two consecutive public health surveys within the county of Nord-Trondelag, Norway, conducted in 1984-1986 and 1995-1997.Among 65 363 adult participants in the second survey, 3113 individuals who reported severe heartburn or regurgitation during the last 12 months were defined as cases, whereas 39 872 persons without reflux symptoms were defined as controls.Risk of reflux, estimated using multivariate logistic regression, with odds ratios (ORs) and 95% confidence intervals (CIs) as measures of association.There was a dose-response association between increasing body mass index (BMI) and reflux symptoms in both sexes (P for trend <.001), with a significantly stronger association in women (P<.001). Compared with those with a BMI less than 25, the risk of reflux was increased significantly among severely obese (BMI >35) men(OR, 3.3; 95% CI, 2.4-4.7) and women (OR, 6.3; 95% CI, 4.9-8.0). The association between BMI and reflux symptoms was stronger among premenopausal women compared with postmenopausal women (P<.001), although use of postmenopausal hormone therapy increased the strength of the association (P<.001). Reduction in BMI was associated with decreased risk of reflux symptoms.There is a significant association between body mass and symptoms of gastroesophageal reflux. The association is stronger among women, especially premenopausally, and use of hormone therapy strengthens the association, suggesting that estrogens may play an important role in the etiology of reflux disease.","Obesity and estrogen as risk factors for gastroesophageal reflux symptoms."
"281","JAMA.167","NA",12837713,2003,"Gastroesophageal reflux and obesity are both increasing in prevalence. The scientific evidence for an association between these conditions is sparse and contradictory. A difference between sexes concerning this relation has been proposed.To evaluate the relation between body mass and gastroesophageal reflux symptoms and determine how this relation is influenced by female sex hormones.Population-based, cross-sectional, case-control study.Two consecutive public health surveys within the county of Nord-Trondelag, Norway, conducted in 1984-1986 and 1995-1997.Among 65 363 adult participants in the second survey, 3113 individuals who reported severe heartburn or regurgitation during the last 12 months were defined as cases, whereas 39 872 persons without reflux symptoms were defined as controls.Risk of reflux, estimated using multivariate logistic regression, with odds ratios (ORs) and 95% confidence intervals (CIs) as measures of association.There was a dose-response association between increasing body mass index (BMI) and reflux symptoms in both sexes (P for trend <.001), with a significantly stronger association in women (P<.001). Compared with those with a BMI less than 25, the risk of reflux was increased significantly among severely obese (BMI >35) men(OR, 3.3; 95% CI, 2.4-4.7) and women (OR, 6.3; 95% CI, 4.9-8.0). The association between BMI and reflux symptoms was stronger among premenopausal women compared with postmenopausal women (P<.001), although use of postmenopausal hormone therapy increased the strength of the association (P<.001). Reduction in BMI was associated with decreased risk of reflux symptoms.There is a significant association between body mass and symptoms of gastroesophageal reflux. The association is stronger among women, especially premenopausally, and use of hormone therapy strengthens the association, suggesting that estrogens may play an important role in the etiology of reflux disease.","Obesity and estrogen as risk factors for gastroesophageal reflux symptoms."
"282","JAMA.159","0.001",12851276,2003,"Little is known regarding the extent to which patient-reported health status, including symptom burden, physical limitation, and quality of life, is determined by psychosocial vs physiological factors among patients with chronic disease.To compare the contributions of depressive symptoms and measures of cardiac function to the health status of patients with coronary artery disease.Cross-sectional study of 1024 adults with stable coronary artery disease recruited from outpatient clinics in the San Francisco Bay Area between September 2000 and December 2002. Main Measures Measurement of depressive symptoms using the Patient Health Questionnaire (PHQ); assessment of cardiac function by measuring left ventricular ejection fraction on echocardiography, exercise capacity on treadmill testing, and ischemia on stress echocardiography; and measurement of a range of health status outcomes, including symptom burden, physical limitation, and quality of life, using the Seattle Angina Questionnaire. Participants were also asked to rate their overall health as excellent, very good, good, fair, or poor.Of the 1024 participants, 201 (20%) had depressive symptoms (PHQ score > or =10). Participants with depressive symptoms were more likely than those without depressive symptoms to report at least mild symptom burden (60% vs 33%; P<.001), mild physical limitation (73% vs 40%; P<.001), mildly diminished quality of life (67% vs 31%; P<.001), and fair or poor overall health (66% vs 30%; P<.001). In multivariate analyses adjusting for measures of cardiac function and other patient characteristics, depressive symptoms were strongly associated with greater symptom burden (odds ratio [OR], 1.8; 95% confidence interval [CI], 1.3-2.7; P =.002), greater physical limitation (OR, 3.1; 95% CI, 2.1-4.6; P<.001), worse quality of life (OR, 3.1; 95% CI, 2.2-4.6; P<.001), and worse overall health (OR, 2.0; 95% CI, 1.3-2.9; P<.001). Although decreased exercise capacity was associated with worse health status, left ventricular ejection fraction and ischemia were not.Among patients with coronary disease, depressive symptoms are strongly associated with patient-reported health status, including symptom burden, physical limitation, quality of life, and overall health. Conversely, 2 traditional measures of cardiac function-ejection fraction and ischemia-are not. Efforts to improve health status should include assessment and treatment of depressive symptoms.","Depressive symptoms and health-related quality of life: the Heart and Soul Study."
"283","JAMA.160","0.001",12851276,2003,"Little is known regarding the extent to which patient-reported health status, including symptom burden, physical limitation, and quality of life, is determined by psychosocial vs physiological factors among patients with chronic disease.To compare the contributions of depressive symptoms and measures of cardiac function to the health status of patients with coronary artery disease.Cross-sectional study of 1024 adults with stable coronary artery disease recruited from outpatient clinics in the San Francisco Bay Area between September 2000 and December 2002. Main Measures Measurement of depressive symptoms using the Patient Health Questionnaire (PHQ); assessment of cardiac function by measuring left ventricular ejection fraction on echocardiography, exercise capacity on treadmill testing, and ischemia on stress echocardiography; and measurement of a range of health status outcomes, including symptom burden, physical limitation, and quality of life, using the Seattle Angina Questionnaire. Participants were also asked to rate their overall health as excellent, very good, good, fair, or poor.Of the 1024 participants, 201 (20%) had depressive symptoms (PHQ score > or =10). Participants with depressive symptoms were more likely than those without depressive symptoms to report at least mild symptom burden (60% vs 33%; P<.001), mild physical limitation (73% vs 40%; P<.001), mildly diminished quality of life (67% vs 31%; P<.001), and fair or poor overall health (66% vs 30%; P<.001). In multivariate analyses adjusting for measures of cardiac function and other patient characteristics, depressive symptoms were strongly associated with greater symptom burden (odds ratio [OR], 1.8; 95% confidence interval [CI], 1.3-2.7; P =.002), greater physical limitation (OR, 3.1; 95% CI, 2.1-4.6; P<.001), worse quality of life (OR, 3.1; 95% CI, 2.2-4.6; P<.001), and worse overall health (OR, 2.0; 95% CI, 1.3-2.9; P<.001). Although decreased exercise capacity was associated with worse health status, left ventricular ejection fraction and ischemia were not.Among patients with coronary disease, depressive symptoms are strongly associated with patient-reported health status, including symptom burden, physical limitation, quality of life, and overall health. Conversely, 2 traditional measures of cardiac function-ejection fraction and ischemia-are not. Efforts to improve health status should include assessment and treatment of depressive symptoms.","Depressive symptoms and health-related quality of life: the Heart and Soul Study."
"284","JAMA.161","0.001",12851276,2003,"Little is known regarding the extent to which patient-reported health status, including symptom burden, physical limitation, and quality of life, is determined by psychosocial vs physiological factors among patients with chronic disease.To compare the contributions of depressive symptoms and measures of cardiac function to the health status of patients with coronary artery disease.Cross-sectional study of 1024 adults with stable coronary artery disease recruited from outpatient clinics in the San Francisco Bay Area between September 2000 and December 2002. Main Measures Measurement of depressive symptoms using the Patient Health Questionnaire (PHQ); assessment of cardiac function by measuring left ventricular ejection fraction on echocardiography, exercise capacity on treadmill testing, and ischemia on stress echocardiography; and measurement of a range of health status outcomes, including symptom burden, physical limitation, and quality of life, using the Seattle Angina Questionnaire. Participants were also asked to rate their overall health as excellent, very good, good, fair, or poor.Of the 1024 participants, 201 (20%) had depressive symptoms (PHQ score > or =10). Participants with depressive symptoms were more likely than those without depressive symptoms to report at least mild symptom burden (60% vs 33%; P<.001), mild physical limitation (73% vs 40%; P<.001), mildly diminished quality of life (67% vs 31%; P<.001), and fair or poor overall health (66% vs 30%; P<.001). In multivariate analyses adjusting for measures of cardiac function and other patient characteristics, depressive symptoms were strongly associated with greater symptom burden (odds ratio [OR], 1.8; 95% confidence interval [CI], 1.3-2.7; P =.002), greater physical limitation (OR, 3.1; 95% CI, 2.1-4.6; P<.001), worse quality of life (OR, 3.1; 95% CI, 2.2-4.6; P<.001), and worse overall health (OR, 2.0; 95% CI, 1.3-2.9; P<.001). Although decreased exercise capacity was associated with worse health status, left ventricular ejection fraction and ischemia were not.Among patients with coronary disease, depressive symptoms are strongly associated with patient-reported health status, including symptom burden, physical limitation, quality of life, and overall health. Conversely, 2 traditional measures of cardiac function-ejection fraction and ischemia-are not. Efforts to improve health status should include assessment and treatment of depressive symptoms.","Depressive symptoms and health-related quality of life: the Heart and Soul Study."
"285","JAMA.192","0.002",12851276,2003,"Little is known regarding the extent to which patient-reported health status, including symptom burden, physical limitation, and quality of life, is determined by psychosocial vs physiological factors among patients with chronic disease.To compare the contributions of depressive symptoms and measures of cardiac function to the health status of patients with coronary artery disease.Cross-sectional study of 1024 adults with stable coronary artery disease recruited from outpatient clinics in the San Francisco Bay Area between September 2000 and December 2002. Main Measures Measurement of depressive symptoms using the Patient Health Questionnaire (PHQ); assessment of cardiac function by measuring left ventricular ejection fraction on echocardiography, exercise capacity on treadmill testing, and ischemia on stress echocardiography; and measurement of a range of health status outcomes, including symptom burden, physical limitation, and quality of life, using the Seattle Angina Questionnaire. Participants were also asked to rate their overall health as excellent, very good, good, fair, or poor.Of the 1024 participants, 201 (20%) had depressive symptoms (PHQ score > or =10). Participants with depressive symptoms were more likely than those without depressive symptoms to report at least mild symptom burden (60% vs 33%; P<.001), mild physical limitation (73% vs 40%; P<.001), mildly diminished quality of life (67% vs 31%; P<.001), and fair or poor overall health (66% vs 30%; P<.001). In multivariate analyses adjusting for measures of cardiac function and other patient characteristics, depressive symptoms were strongly associated with greater symptom burden (odds ratio [OR], 1.8; 95% confidence interval [CI], 1.3-2.7; P =.002), greater physical limitation (OR, 3.1; 95% CI, 2.1-4.6; P<.001), worse quality of life (OR, 3.1; 95% CI, 2.2-4.6; P<.001), and worse overall health (OR, 2.0; 95% CI, 1.3-2.9; P<.001). Although decreased exercise capacity was associated with worse health status, left ventricular ejection fraction and ischemia were not.Among patients with coronary disease, depressive symptoms are strongly associated with patient-reported health status, including symptom burden, physical limitation, quality of life, and overall health. Conversely, 2 traditional measures of cardiac function-ejection fraction and ischemia-are not. Efforts to improve health status should include assessment and treatment of depressive symptoms.","Depressive symptoms and health-related quality of life: the Heart and Soul Study."
"286","JAMA.1311","0.03",12876091,2003,"The worldwide explosive increase in type 2 diabetes mellitus and its cardiovascular morbidity are becoming major health concerns.To evaluate the effect of decreasing postprandial hyperglycemia with acarbose, an alpha-glucosidase inhibitor, on the risk of cardiovascular disease and hypertension in patients with impaired glucose tolerance (IGT).International, multicenter double-blind, placebo-controlled, randomized trial, undertaken in hospitals in Canada, Germany, Austria, Norway, Denmark, Sweden, Finland, Israel, and Spain from July 1998 through August 2001. A total of 1429 patients with IGT were randomized with 61 patients (4%) excluded because they did not have IGT or had no postrandomization data, leaving 1368 patients for a modified intent-to-treat analysis. Both men (49%) and women (51%) participated with a mean (SD) age of 54.5 (7.9) years and body mass index of 30.9 (4.2). These patients were followed up for a mean (SD) of 3.3 (1.2) years.Patients with IGT were randomized to receive either placebo (n = 715) or 100 mg of acarbose 3 times a day (n = 714).The development of major cardiovascular events (coronary heart disease, cardiovascular death, congestive heart failure, cerebrovascular event, and peripheral vascular disease) and hypertension (> or =140/90 mm Hg).Three hundred forty-one patients (24%) discontinued their participation prematurely, 211 in the acarbose-treated group and 130 in the placebo group; these patients were also followed up for outcome parameters. Decreasing postprandial hyperglycemia with acarbose was associated with a 49% relative risk reduction in the development of cardiovascular events (hazard ratio [HR], 0.51; 95% confidence interval [CI]; 0.28-0.95; P =.03) and a 2.5% absolute risk reduction. Among cardiovascular events, the major reduction was in the risk of myocardial infarction (HR, 0.09; 95% CI, 0.01-0.72; P =.02). Acarbose was also associated with a 34% relative risk reduction in the incidence of new cases of hypertension (HR, 0.66; 95% CI, 0.49-0.89; P =.006) and a 5.3% absolute risk reduction. Even after adjusting for major risk factors, the reduction in the risk of cardiovascular events (HR, 0.47; 95% CI, 0.24-0.90; P =.02) and hypertension (HR, 0.62; 95% CI, 0.45-0.86; P =.004) associated with acarbose treatment was still statistically significant.This study suggests that treating IGT patients with acarbose is associated with a significant reduction in the risk of cardiovascular disease and hypertension.","Acarbose treatment and the risk of cardiovascular disease and hypertension in patients with impaired glucose tolerance: the STOP-NIDDM trial."
"287","JAMA.1321","0.02",12876091,2003,"The worldwide explosive increase in type 2 diabetes mellitus and its cardiovascular morbidity are becoming major health concerns.To evaluate the effect of decreasing postprandial hyperglycemia with acarbose, an alpha-glucosidase inhibitor, on the risk of cardiovascular disease and hypertension in patients with impaired glucose tolerance (IGT).International, multicenter double-blind, placebo-controlled, randomized trial, undertaken in hospitals in Canada, Germany, Austria, Norway, Denmark, Sweden, Finland, Israel, and Spain from July 1998 through August 2001. A total of 1429 patients with IGT were randomized with 61 patients (4%) excluded because they did not have IGT or had no postrandomization data, leaving 1368 patients for a modified intent-to-treat analysis. Both men (49%) and women (51%) participated with a mean (SD) age of 54.5 (7.9) years and body mass index of 30.9 (4.2). These patients were followed up for a mean (SD) of 3.3 (1.2) years.Patients with IGT were randomized to receive either placebo (n = 715) or 100 mg of acarbose 3 times a day (n = 714).The development of major cardiovascular events (coronary heart disease, cardiovascular death, congestive heart failure, cerebrovascular event, and peripheral vascular disease) and hypertension (> or =140/90 mm Hg).Three hundred forty-one patients (24%) discontinued their participation prematurely, 211 in the acarbose-treated group and 130 in the placebo group; these patients were also followed up for outcome parameters. Decreasing postprandial hyperglycemia with acarbose was associated with a 49% relative risk reduction in the development of cardiovascular events (hazard ratio [HR], 0.51; 95% confidence interval [CI]; 0.28-0.95; P =.03) and a 2.5% absolute risk reduction. Among cardiovascular events, the major reduction was in the risk of myocardial infarction (HR, 0.09; 95% CI, 0.01-0.72; P =.02). Acarbose was also associated with a 34% relative risk reduction in the incidence of new cases of hypertension (HR, 0.66; 95% CI, 0.49-0.89; P =.006) and a 5.3% absolute risk reduction. Even after adjusting for major risk factors, the reduction in the risk of cardiovascular events (HR, 0.47; 95% CI, 0.24-0.90; P =.02) and hypertension (HR, 0.62; 95% CI, 0.45-0.86; P =.004) associated with acarbose treatment was still statistically significant.This study suggests that treating IGT patients with acarbose is associated with a significant reduction in the risk of cardiovascular disease and hypertension.","Acarbose treatment and the risk of cardiovascular disease and hypertension in patients with impaired glucose tolerance: the STOP-NIDDM trial."
"288","JAMA.1331","0.006",12876091,2003,"The worldwide explosive increase in type 2 diabetes mellitus and its cardiovascular morbidity are becoming major health concerns.To evaluate the effect of decreasing postprandial hyperglycemia with acarbose, an alpha-glucosidase inhibitor, on the risk of cardiovascular disease and hypertension in patients with impaired glucose tolerance (IGT).International, multicenter double-blind, placebo-controlled, randomized trial, undertaken in hospitals in Canada, Germany, Austria, Norway, Denmark, Sweden, Finland, Israel, and Spain from July 1998 through August 2001. A total of 1429 patients with IGT were randomized with 61 patients (4%) excluded because they did not have IGT or had no postrandomization data, leaving 1368 patients for a modified intent-to-treat analysis. Both men (49%) and women (51%) participated with a mean (SD) age of 54.5 (7.9) years and body mass index of 30.9 (4.2). These patients were followed up for a mean (SD) of 3.3 (1.2) years.Patients with IGT were randomized to receive either placebo (n = 715) or 100 mg of acarbose 3 times a day (n = 714).The development of major cardiovascular events (coronary heart disease, cardiovascular death, congestive heart failure, cerebrovascular event, and peripheral vascular disease) and hypertension (> or =140/90 mm Hg).Three hundred forty-one patients (24%) discontinued their participation prematurely, 211 in the acarbose-treated group and 130 in the placebo group; these patients were also followed up for outcome parameters. Decreasing postprandial hyperglycemia with acarbose was associated with a 49% relative risk reduction in the development of cardiovascular events (hazard ratio [HR], 0.51; 95% confidence interval [CI]; 0.28-0.95; P =.03) and a 2.5% absolute risk reduction. Among cardiovascular events, the major reduction was in the risk of myocardial infarction (HR, 0.09; 95% CI, 0.01-0.72; P =.02). Acarbose was also associated with a 34% relative risk reduction in the incidence of new cases of hypertension (HR, 0.66; 95% CI, 0.49-0.89; P =.006) and a 5.3% absolute risk reduction. Even after adjusting for major risk factors, the reduction in the risk of cardiovascular events (HR, 0.47; 95% CI, 0.24-0.90; P =.02) and hypertension (HR, 0.62; 95% CI, 0.45-0.86; P =.004) associated with acarbose treatment was still statistically significant.This study suggests that treating IGT patients with acarbose is associated with a significant reduction in the risk of cardiovascular disease and hypertension.","Acarbose treatment and the risk of cardiovascular disease and hypertension in patients with impaired glucose tolerance: the STOP-NIDDM trial."
"289","JAMA.1341","0.02",12876091,2003,"The worldwide explosive increase in type 2 diabetes mellitus and its cardiovascular morbidity are becoming major health concerns.To evaluate the effect of decreasing postprandial hyperglycemia with acarbose, an alpha-glucosidase inhibitor, on the risk of cardiovascular disease and hypertension in patients with impaired glucose tolerance (IGT).International, multicenter double-blind, placebo-controlled, randomized trial, undertaken in hospitals in Canada, Germany, Austria, Norway, Denmark, Sweden, Finland, Israel, and Spain from July 1998 through August 2001. A total of 1429 patients with IGT were randomized with 61 patients (4%) excluded because they did not have IGT or had no postrandomization data, leaving 1368 patients for a modified intent-to-treat analysis. Both men (49%) and women (51%) participated with a mean (SD) age of 54.5 (7.9) years and body mass index of 30.9 (4.2). These patients were followed up for a mean (SD) of 3.3 (1.2) years.Patients with IGT were randomized to receive either placebo (n = 715) or 100 mg of acarbose 3 times a day (n = 714).The development of major cardiovascular events (coronary heart disease, cardiovascular death, congestive heart failure, cerebrovascular event, and peripheral vascular disease) and hypertension (> or =140/90 mm Hg).Three hundred forty-one patients (24%) discontinued their participation prematurely, 211 in the acarbose-treated group and 130 in the placebo group; these patients were also followed up for outcome parameters. Decreasing postprandial hyperglycemia with acarbose was associated with a 49% relative risk reduction in the development of cardiovascular events (hazard ratio [HR], 0.51; 95% confidence interval [CI]; 0.28-0.95; P =.03) and a 2.5% absolute risk reduction. Among cardiovascular events, the major reduction was in the risk of myocardial infarction (HR, 0.09; 95% CI, 0.01-0.72; P =.02). Acarbose was also associated with a 34% relative risk reduction in the incidence of new cases of hypertension (HR, 0.66; 95% CI, 0.49-0.89; P =.006) and a 5.3% absolute risk reduction. Even after adjusting for major risk factors, the reduction in the risk of cardiovascular events (HR, 0.47; 95% CI, 0.24-0.90; P =.02) and hypertension (HR, 0.62; 95% CI, 0.45-0.86; P =.004) associated with acarbose treatment was still statistically significant.This study suggests that treating IGT patients with acarbose is associated with a significant reduction in the risk of cardiovascular disease and hypertension.","Acarbose treatment and the risk of cardiovascular disease and hypertension in patients with impaired glucose tolerance: the STOP-NIDDM trial."
"290","JAMA.1351","0.004",12876091,2003,"The worldwide explosive increase in type 2 diabetes mellitus and its cardiovascular morbidity are becoming major health concerns.To evaluate the effect of decreasing postprandial hyperglycemia with acarbose, an alpha-glucosidase inhibitor, on the risk of cardiovascular disease and hypertension in patients with impaired glucose tolerance (IGT).International, multicenter double-blind, placebo-controlled, randomized trial, undertaken in hospitals in Canada, Germany, Austria, Norway, Denmark, Sweden, Finland, Israel, and Spain from July 1998 through August 2001. A total of 1429 patients with IGT were randomized with 61 patients (4%) excluded because they did not have IGT or had no postrandomization data, leaving 1368 patients for a modified intent-to-treat analysis. Both men (49%) and women (51%) participated with a mean (SD) age of 54.5 (7.9) years and body mass index of 30.9 (4.2). These patients were followed up for a mean (SD) of 3.3 (1.2) years.Patients with IGT were randomized to receive either placebo (n = 715) or 100 mg of acarbose 3 times a day (n = 714).The development of major cardiovascular events (coronary heart disease, cardiovascular death, congestive heart failure, cerebrovascular event, and peripheral vascular disease) and hypertension (> or =140/90 mm Hg).Three hundred forty-one patients (24%) discontinued their participation prematurely, 211 in the acarbose-treated group and 130 in the placebo group; these patients were also followed up for outcome parameters. Decreasing postprandial hyperglycemia with acarbose was associated with a 49% relative risk reduction in the development of cardiovascular events (hazard ratio [HR], 0.51; 95% confidence interval [CI]; 0.28-0.95; P =.03) and a 2.5% absolute risk reduction. Among cardiovascular events, the major reduction was in the risk of myocardial infarction (HR, 0.09; 95% CI, 0.01-0.72; P =.02). Acarbose was also associated with a 34% relative risk reduction in the incidence of new cases of hypertension (HR, 0.66; 95% CI, 0.49-0.89; P =.006) and a 5.3% absolute risk reduction. Even after adjusting for major risk factors, the reduction in the risk of cardiovascular events (HR, 0.47; 95% CI, 0.24-0.90; P =.02) and hypertension (HR, 0.62; 95% CI, 0.45-0.86; P =.004) associated with acarbose treatment was still statistically significant.This study suggests that treating IGT patients with acarbose is associated with a significant reduction in the risk of cardiovascular disease and hypertension.","Acarbose treatment and the risk of cardiovascular disease and hypertension in patients with impaired glucose tolerance: the STOP-NIDDM trial."
"291","Lancet.510","1.00E-04",12927427,2003,"Current use of hormone-replacement therapy (HRT) increases the incidence of breast cancer. The Million Women Study was set up to investigate the effects of specific types of HRT on incident and fatal breast cancer.1084110 UK women aged 50-64 years were recruited into the Million Women Study between 1996 and 2001, provided information about their use of HRT and other personal details, and were followed up for cancer incidence and death.Half the women had used HRT; 9364 incident invasive breast cancers and 637 breast cancer deaths were registered after an average of 2.6 and 4.1 years of follow-up, respectively. Current users of HRT at recruitment were more likely than never users to develop breast cancer (adjusted relative risk 1.66 [95% CI 1.58-1.75], p<0.0001) and die from it (1.22 [1.00-1.48], p=0.05). Past users of HRT were, however, not at an increased risk of incident or fatal disease (1.01 [0.94-1.09] and 1.05 [0.82-1.34], respectively). Incidence was significantly increased for current users of preparations containing oestrogen only (1.30 [1.21-1.40], p<0.0001), oestrogen-progestagen (2.00 [1.88-2.12], p<0.0001), and tibolone (1.45 [1.25-1.68], p<0.0001), but the magnitude of the associated risk was substantially greater for oestrogen-progestagen than for other types of HRT (p<0.0001). Results varied little between specific oestrogens and progestagens or their doses; or between continuous and sequential regimens. The relative risks were significantly increased separately for oral, transdermal, and implanted oestrogen-only formulations (1.32 [1.21-1.45]; 1.24 [1.11-1.39]; and 1.65 [1.26-2.16], respectively; all p<0.0001). In current users of each type of HRT the risk of breast cancer increased with increasing total duration of use. 10 years' use of HRT is estimated to result in five (95% CI 3-7) additional breast cancers per 1000 users of oestrogen-only preparations and 19 (15-23) additional cancers per 1000 users of oestrogen-progestagen combinations. Use of HRT by women aged 50-64 years in the UK over the past decade has resulted in an estimated 20000 extra breast cancers, 15000 associated with oestrogen-progestagen; the extra deaths cannot yet be reliably estimated.Current use of HRT is associated with an increased risk of incident and fatal breast cancer; the effect is substantially greater for oestrogen-progestagen combinations than for other types of HRT.","Breast cancer and hormone-replacement therapy in the Million Women Study."
"292","Lancet.610","1.00E-04",12927427,2003,"Current use of hormone-replacement therapy (HRT) increases the incidence of breast cancer. The Million Women Study was set up to investigate the effects of specific types of HRT on incident and fatal breast cancer.1084110 UK women aged 50-64 years were recruited into the Million Women Study between 1996 and 2001, provided information about their use of HRT and other personal details, and were followed up for cancer incidence and death.Half the women had used HRT; 9364 incident invasive breast cancers and 637 breast cancer deaths were registered after an average of 2.6 and 4.1 years of follow-up, respectively. Current users of HRT at recruitment were more likely than never users to develop breast cancer (adjusted relative risk 1.66 [95% CI 1.58-1.75], p<0.0001) and die from it (1.22 [1.00-1.48], p=0.05). Past users of HRT were, however, not at an increased risk of incident or fatal disease (1.01 [0.94-1.09] and 1.05 [0.82-1.34], respectively). Incidence was significantly increased for current users of preparations containing oestrogen only (1.30 [1.21-1.40], p<0.0001), oestrogen-progestagen (2.00 [1.88-2.12], p<0.0001), and tibolone (1.45 [1.25-1.68], p<0.0001), but the magnitude of the associated risk was substantially greater for oestrogen-progestagen than for other types of HRT (p<0.0001). Results varied little between specific oestrogens and progestagens or their doses; or between continuous and sequential regimens. The relative risks were significantly increased separately for oral, transdermal, and implanted oestrogen-only formulations (1.32 [1.21-1.45]; 1.24 [1.11-1.39]; and 1.65 [1.26-2.16], respectively; all p<0.0001). In current users of each type of HRT the risk of breast cancer increased with increasing total duration of use. 10 years' use of HRT is estimated to result in five (95% CI 3-7) additional breast cancers per 1000 users of oestrogen-only preparations and 19 (15-23) additional cancers per 1000 users of oestrogen-progestagen combinations. Use of HRT by women aged 50-64 years in the UK over the past decade has resulted in an estimated 20000 extra breast cancers, 15000 associated with oestrogen-progestagen; the extra deaths cannot yet be reliably estimated.Current use of HRT is associated with an increased risk of incident and fatal breast cancer; the effect is substantially greater for oestrogen-progestagen combinations than for other types of HRT.","Breast cancer and hormone-replacement therapy in the Million Women Study."
"293","Lancet.710","1.00E-04",12927427,2003,"Current use of hormone-replacement therapy (HRT) increases the incidence of breast cancer. The Million Women Study was set up to investigate the effects of specific types of HRT on incident and fatal breast cancer.1084110 UK women aged 50-64 years were recruited into the Million Women Study between 1996 and 2001, provided information about their use of HRT and other personal details, and were followed up for cancer incidence and death.Half the women had used HRT; 9364 incident invasive breast cancers and 637 breast cancer deaths were registered after an average of 2.6 and 4.1 years of follow-up, respectively. Current users of HRT at recruitment were more likely than never users to develop breast cancer (adjusted relative risk 1.66 [95% CI 1.58-1.75], p<0.0001) and die from it (1.22 [1.00-1.48], p=0.05). Past users of HRT were, however, not at an increased risk of incident or fatal disease (1.01 [0.94-1.09] and 1.05 [0.82-1.34], respectively). Incidence was significantly increased for current users of preparations containing oestrogen only (1.30 [1.21-1.40], p<0.0001), oestrogen-progestagen (2.00 [1.88-2.12], p<0.0001), and tibolone (1.45 [1.25-1.68], p<0.0001), but the magnitude of the associated risk was substantially greater for oestrogen-progestagen than for other types of HRT (p<0.0001). Results varied little between specific oestrogens and progestagens or their doses; or between continuous and sequential regimens. The relative risks were significantly increased separately for oral, transdermal, and implanted oestrogen-only formulations (1.32 [1.21-1.45]; 1.24 [1.11-1.39]; and 1.65 [1.26-2.16], respectively; all p<0.0001). In current users of each type of HRT the risk of breast cancer increased with increasing total duration of use. 10 years' use of HRT is estimated to result in five (95% CI 3-7) additional breast cancers per 1000 users of oestrogen-only preparations and 19 (15-23) additional cancers per 1000 users of oestrogen-progestagen combinations. Use of HRT by women aged 50-64 years in the UK over the past decade has resulted in an estimated 20000 extra breast cancers, 15000 associated with oestrogen-progestagen; the extra deaths cannot yet be reliably estimated.Current use of HRT is associated with an increased risk of incident and fatal breast cancer; the effect is substantially greater for oestrogen-progestagen combinations than for other types of HRT.","Breast cancer and hormone-replacement therapy in the Million Women Study."
"294","Lancet.810","1.00E-04",12927427,2003,"Current use of hormone-replacement therapy (HRT) increases the incidence of breast cancer. The Million Women Study was set up to investigate the effects of specific types of HRT on incident and fatal breast cancer.1084110 UK women aged 50-64 years were recruited into the Million Women Study between 1996 and 2001, provided information about their use of HRT and other personal details, and were followed up for cancer incidence and death.Half the women had used HRT; 9364 incident invasive breast cancers and 637 breast cancer deaths were registered after an average of 2.6 and 4.1 years of follow-up, respectively. Current users of HRT at recruitment were more likely than never users to develop breast cancer (adjusted relative risk 1.66 [95% CI 1.58-1.75], p<0.0001) and die from it (1.22 [1.00-1.48], p=0.05). Past users of HRT were, however, not at an increased risk of incident or fatal disease (1.01 [0.94-1.09] and 1.05 [0.82-1.34], respectively). Incidence was significantly increased for current users of preparations containing oestrogen only (1.30 [1.21-1.40], p<0.0001), oestrogen-progestagen (2.00 [1.88-2.12], p<0.0001), and tibolone (1.45 [1.25-1.68], p<0.0001), but the magnitude of the associated risk was substantially greater for oestrogen-progestagen than for other types of HRT (p<0.0001). Results varied little between specific oestrogens and progestagens or their doses; or between continuous and sequential regimens. The relative risks were significantly increased separately for oral, transdermal, and implanted oestrogen-only formulations (1.32 [1.21-1.45]; 1.24 [1.11-1.39]; and 1.65 [1.26-2.16], respectively; all p<0.0001). In current users of each type of HRT the risk of breast cancer increased with increasing total duration of use. 10 years' use of HRT is estimated to result in five (95% CI 3-7) additional breast cancers per 1000 users of oestrogen-only preparations and 19 (15-23) additional cancers per 1000 users of oestrogen-progestagen combinations. Use of HRT by women aged 50-64 years in the UK over the past decade has resulted in an estimated 20000 extra breast cancers, 15000 associated with oestrogen-progestagen; the extra deaths cannot yet be reliably estimated.Current use of HRT is associated with an increased risk of incident and fatal breast cancer; the effect is substantially greater for oestrogen-progestagen combinations than for other types of HRT.","Breast cancer and hormone-replacement therapy in the Million Women Study."
"295","Lancet.910","1.00E-04",12927427,2003,"Current use of hormone-replacement therapy (HRT) increases the incidence of breast cancer. The Million Women Study was set up to investigate the effects of specific types of HRT on incident and fatal breast cancer.1084110 UK women aged 50-64 years were recruited into the Million Women Study between 1996 and 2001, provided information about their use of HRT and other personal details, and were followed up for cancer incidence and death.Half the women had used HRT; 9364 incident invasive breast cancers and 637 breast cancer deaths were registered after an average of 2.6 and 4.1 years of follow-up, respectively. Current users of HRT at recruitment were more likely than never users to develop breast cancer (adjusted relative risk 1.66 [95% CI 1.58-1.75], p<0.0001) and die from it (1.22 [1.00-1.48], p=0.05). Past users of HRT were, however, not at an increased risk of incident or fatal disease (1.01 [0.94-1.09] and 1.05 [0.82-1.34], respectively). Incidence was significantly increased for current users of preparations containing oestrogen only (1.30 [1.21-1.40], p<0.0001), oestrogen-progestagen (2.00 [1.88-2.12], p<0.0001), and tibolone (1.45 [1.25-1.68], p<0.0001), but the magnitude of the associated risk was substantially greater for oestrogen-progestagen than for other types of HRT (p<0.0001). Results varied little between specific oestrogens and progestagens or their doses; or between continuous and sequential regimens. The relative risks were significantly increased separately for oral, transdermal, and implanted oestrogen-only formulations (1.32 [1.21-1.45]; 1.24 [1.11-1.39]; and 1.65 [1.26-2.16], respectively; all p<0.0001). In current users of each type of HRT the risk of breast cancer increased with increasing total duration of use. 10 years' use of HRT is estimated to result in five (95% CI 3-7) additional breast cancers per 1000 users of oestrogen-only preparations and 19 (15-23) additional cancers per 1000 users of oestrogen-progestagen combinations. Use of HRT by women aged 50-64 years in the UK over the past decade has resulted in an estimated 20000 extra breast cancers, 15000 associated with oestrogen-progestagen; the extra deaths cannot yet be reliably estimated.Current use of HRT is associated with an increased risk of incident and fatal breast cancer; the effect is substantially greater for oestrogen-progestagen combinations than for other types of HRT.","Breast cancer and hormone-replacement therapy in the Million Women Study."
"296","Lancet.911","1.00E-04",12927427,2003,"Current use of hormone-replacement therapy (HRT) increases the incidence of breast cancer. The Million Women Study was set up to investigate the effects of specific types of HRT on incident and fatal breast cancer.1084110 UK women aged 50-64 years were recruited into the Million Women Study between 1996 and 2001, provided information about their use of HRT and other personal details, and were followed up for cancer incidence and death.Half the women had used HRT; 9364 incident invasive breast cancers and 637 breast cancer deaths were registered after an average of 2.6 and 4.1 years of follow-up, respectively. Current users of HRT at recruitment were more likely than never users to develop breast cancer (adjusted relative risk 1.66 [95% CI 1.58-1.75], p<0.0001) and die from it (1.22 [1.00-1.48], p=0.05). Past users of HRT were, however, not at an increased risk of incident or fatal disease (1.01 [0.94-1.09] and 1.05 [0.82-1.34], respectively). Incidence was significantly increased for current users of preparations containing oestrogen only (1.30 [1.21-1.40], p<0.0001), oestrogen-progestagen (2.00 [1.88-2.12], p<0.0001), and tibolone (1.45 [1.25-1.68], p<0.0001), but the magnitude of the associated risk was substantially greater for oestrogen-progestagen than for other types of HRT (p<0.0001). Results varied little between specific oestrogens and progestagens or their doses; or between continuous and sequential regimens. The relative risks were significantly increased separately for oral, transdermal, and implanted oestrogen-only formulations (1.32 [1.21-1.45]; 1.24 [1.11-1.39]; and 1.65 [1.26-2.16], respectively; all p<0.0001). In current users of each type of HRT the risk of breast cancer increased with increasing total duration of use. 10 years' use of HRT is estimated to result in five (95% CI 3-7) additional breast cancers per 1000 users of oestrogen-only preparations and 19 (15-23) additional cancers per 1000 users of oestrogen-progestagen combinations. Use of HRT by women aged 50-64 years in the UK over the past decade has resulted in an estimated 20000 extra breast cancers, 15000 associated with oestrogen-progestagen; the extra deaths cannot yet be reliably estimated.Current use of HRT is associated with an increased risk of incident and fatal breast cancer; the effect is substantially greater for oestrogen-progestagen combinations than for other types of HRT.","Breast cancer and hormone-replacement therapy in the Million Women Study."
"297","Lancet.1010","1.00E-04",12927427,2003,"Current use of hormone-replacement therapy (HRT) increases the incidence of breast cancer. The Million Women Study was set up to investigate the effects of specific types of HRT on incident and fatal breast cancer.1084110 UK women aged 50-64 years were recruited into the Million Women Study between 1996 and 2001, provided information about their use of HRT and other personal details, and were followed up for cancer incidence and death.Half the women had used HRT; 9364 incident invasive breast cancers and 637 breast cancer deaths were registered after an average of 2.6 and 4.1 years of follow-up, respectively. Current users of HRT at recruitment were more likely than never users to develop breast cancer (adjusted relative risk 1.66 [95% CI 1.58-1.75], p<0.0001) and die from it (1.22 [1.00-1.48], p=0.05). Past users of HRT were, however, not at an increased risk of incident or fatal disease (1.01 [0.94-1.09] and 1.05 [0.82-1.34], respectively). Incidence was significantly increased for current users of preparations containing oestrogen only (1.30 [1.21-1.40], p<0.0001), oestrogen-progestagen (2.00 [1.88-2.12], p<0.0001), and tibolone (1.45 [1.25-1.68], p<0.0001), but the magnitude of the associated risk was substantially greater for oestrogen-progestagen than for other types of HRT (p<0.0001). Results varied little between specific oestrogens and progestagens or their doses; or between continuous and sequential regimens. The relative risks were significantly increased separately for oral, transdermal, and implanted oestrogen-only formulations (1.32 [1.21-1.45]; 1.24 [1.11-1.39]; and 1.65 [1.26-2.16], respectively; all p<0.0001). In current users of each type of HRT the risk of breast cancer increased with increasing total duration of use. 10 years' use of HRT is estimated to result in five (95% CI 3-7) additional breast cancers per 1000 users of oestrogen-only preparations and 19 (15-23) additional cancers per 1000 users of oestrogen-progestagen combinations. Use of HRT by women aged 50-64 years in the UK over the past decade has resulted in an estimated 20000 extra breast cancers, 15000 associated with oestrogen-progestagen; the extra deaths cannot yet be reliably estimated.Current use of HRT is associated with an increased risk of incident and fatal breast cancer; the effect is substantially greater for oestrogen-progestagen combinations than for other types of HRT.","Breast cancer and hormone-replacement therapy in the Million Women Study."
"298","Lancet.1510","0.05",12927427,2003,"Current use of hormone-replacement therapy (HRT) increases the incidence of breast cancer. The Million Women Study was set up to investigate the effects of specific types of HRT on incident and fatal breast cancer.1084110 UK women aged 50-64 years were recruited into the Million Women Study between 1996 and 2001, provided information about their use of HRT and other personal details, and were followed up for cancer incidence and death.Half the women had used HRT; 9364 incident invasive breast cancers and 637 breast cancer deaths were registered after an average of 2.6 and 4.1 years of follow-up, respectively. Current users of HRT at recruitment were more likely than never users to develop breast cancer (adjusted relative risk 1.66 [95% CI 1.58-1.75], p<0.0001) and die from it (1.22 [1.00-1.48], p=0.05). Past users of HRT were, however, not at an increased risk of incident or fatal disease (1.01 [0.94-1.09] and 1.05 [0.82-1.34], respectively). Incidence was significantly increased for current users of preparations containing oestrogen only (1.30 [1.21-1.40], p<0.0001), oestrogen-progestagen (2.00 [1.88-2.12], p<0.0001), and tibolone (1.45 [1.25-1.68], p<0.0001), but the magnitude of the associated risk was substantially greater for oestrogen-progestagen than for other types of HRT (p<0.0001). Results varied little between specific oestrogens and progestagens or their doses; or between continuous and sequential regimens. The relative risks were significantly increased separately for oral, transdermal, and implanted oestrogen-only formulations (1.32 [1.21-1.45]; 1.24 [1.11-1.39]; and 1.65 [1.26-2.16], respectively; all p<0.0001). In current users of each type of HRT the risk of breast cancer increased with increasing total duration of use. 10 years' use of HRT is estimated to result in five (95% CI 3-7) additional breast cancers per 1000 users of oestrogen-only preparations and 19 (15-23) additional cancers per 1000 users of oestrogen-progestagen combinations. Use of HRT by women aged 50-64 years in the UK over the past decade has resulted in an estimated 20000 extra breast cancers, 15000 associated with oestrogen-progestagen; the extra deaths cannot yet be reliably estimated.Current use of HRT is associated with an increased risk of incident and fatal breast cancer; the effect is substantially greater for oestrogen-progestagen combinations than for other types of HRT.","Breast cancer and hormone-replacement therapy in the Million Women Study."
"299","American Journal of Epidemiology.34","NA",12936898,2003,"Data from a large population-based case-control study conducted in the San Francisco Bay Area between 1994 and 2001 were analyzed to examine the association between pancreatic cancer and history of allergic conditions. Pancreatic cancer cases (n = 532) had to be 21-85 years of age and were identified using rapid case ascertainment. Random digit dialing and Health Care Financing Administration lists (age, > or = 65 years) were used to obtain 1,701 controls who were frequency-matched to cases by sex and age within 5 years. In-person interviews were conducted and detailed allergy history data were obtained for all participants. Prior history of any allergy was associated with a reduced risk estimate for pancreatic cancer (odds ratio (OR) = 0.77, 95% confidence interval (CI): 0.63, 0.95). Inverse associations were observed for common allergens, including house dust (OR = 0.72, 95% CI: 0.54, 0.94), cats (OR = 0.59, 95% CI: 0.41, 0.85), plants (OR = 0.77, 95% CI: 0.62, 0.96), and mold (OR = 0.49, 95% CI: 0.32, 0.75), and for all allergic symptoms, although some confidence intervals included unity. Trends were observed for decreased risks associated with increasing number of allergies (p = 0.0006) and severity of allergic symptoms (p = 0.003). These results provide support for the plausibility that immune function in relation to allergies may play a role in the etiology of pancreatic cancer.","Prior history of allergies and pancreatic cancer in the San Francisco Bay area."
"300","American Journal of Epidemiology.35","NA",12936898,2003,"Data from a large population-based case-control study conducted in the San Francisco Bay Area between 1994 and 2001 were analyzed to examine the association between pancreatic cancer and history of allergic conditions. Pancreatic cancer cases (n = 532) had to be 21-85 years of age and were identified using rapid case ascertainment. Random digit dialing and Health Care Financing Administration lists (age, > or = 65 years) were used to obtain 1,701 controls who were frequency-matched to cases by sex and age within 5 years. In-person interviews were conducted and detailed allergy history data were obtained for all participants. Prior history of any allergy was associated with a reduced risk estimate for pancreatic cancer (odds ratio (OR) = 0.77, 95% confidence interval (CI): 0.63, 0.95). Inverse associations were observed for common allergens, including house dust (OR = 0.72, 95% CI: 0.54, 0.94), cats (OR = 0.59, 95% CI: 0.41, 0.85), plants (OR = 0.77, 95% CI: 0.62, 0.96), and mold (OR = 0.49, 95% CI: 0.32, 0.75), and for all allergic symptoms, although some confidence intervals included unity. Trends were observed for decreased risks associated with increasing number of allergies (p = 0.0006) and severity of allergic symptoms (p = 0.003). These results provide support for the plausibility that immune function in relation to allergies may play a role in the etiology of pancreatic cancer.","Prior history of allergies and pancreatic cancer in the San Francisco Bay area."
"301","American Journal of Epidemiology.36","NA",12936898,2003,"Data from a large population-based case-control study conducted in the San Francisco Bay Area between 1994 and 2001 were analyzed to examine the association between pancreatic cancer and history of allergic conditions. Pancreatic cancer cases (n = 532) had to be 21-85 years of age and were identified using rapid case ascertainment. Random digit dialing and Health Care Financing Administration lists (age, > or = 65 years) were used to obtain 1,701 controls who were frequency-matched to cases by sex and age within 5 years. In-person interviews were conducted and detailed allergy history data were obtained for all participants. Prior history of any allergy was associated with a reduced risk estimate for pancreatic cancer (odds ratio (OR) = 0.77, 95% confidence interval (CI): 0.63, 0.95). Inverse associations were observed for common allergens, including house dust (OR = 0.72, 95% CI: 0.54, 0.94), cats (OR = 0.59, 95% CI: 0.41, 0.85), plants (OR = 0.77, 95% CI: 0.62, 0.96), and mold (OR = 0.49, 95% CI: 0.32, 0.75), and for all allergic symptoms, although some confidence intervals included unity. Trends were observed for decreased risks associated with increasing number of allergies (p = 0.0006) and severity of allergic symptoms (p = 0.003). These results provide support for the plausibility that immune function in relation to allergies may play a role in the etiology of pancreatic cancer.","Prior history of allergies and pancreatic cancer in the San Francisco Bay area."
"302","American Journal of Epidemiology.37","NA",12936898,2003,"Data from a large population-based case-control study conducted in the San Francisco Bay Area between 1994 and 2001 were analyzed to examine the association between pancreatic cancer and history of allergic conditions. Pancreatic cancer cases (n = 532) had to be 21-85 years of age and were identified using rapid case ascertainment. Random digit dialing and Health Care Financing Administration lists (age, > or = 65 years) were used to obtain 1,701 controls who were frequency-matched to cases by sex and age within 5 years. In-person interviews were conducted and detailed allergy history data were obtained for all participants. Prior history of any allergy was associated with a reduced risk estimate for pancreatic cancer (odds ratio (OR) = 0.77, 95% confidence interval (CI): 0.63, 0.95). Inverse associations were observed for common allergens, including house dust (OR = 0.72, 95% CI: 0.54, 0.94), cats (OR = 0.59, 95% CI: 0.41, 0.85), plants (OR = 0.77, 95% CI: 0.62, 0.96), and mold (OR = 0.49, 95% CI: 0.32, 0.75), and for all allergic symptoms, although some confidence intervals included unity. Trends were observed for decreased risks associated with increasing number of allergies (p = 0.0006) and severity of allergic symptoms (p = 0.003). These results provide support for the plausibility that immune function in relation to allergies may play a role in the etiology of pancreatic cancer.","Prior history of allergies and pancreatic cancer in the San Francisco Bay area."
"303","American Journal of Epidemiology.38","NA",12936898,2003,"Data from a large population-based case-control study conducted in the San Francisco Bay Area between 1994 and 2001 were analyzed to examine the association between pancreatic cancer and history of allergic conditions. Pancreatic cancer cases (n = 532) had to be 21-85 years of age and were identified using rapid case ascertainment. Random digit dialing and Health Care Financing Administration lists (age, > or = 65 years) were used to obtain 1,701 controls who were frequency-matched to cases by sex and age within 5 years. In-person interviews were conducted and detailed allergy history data were obtained for all participants. Prior history of any allergy was associated with a reduced risk estimate for pancreatic cancer (odds ratio (OR) = 0.77, 95% confidence interval (CI): 0.63, 0.95). Inverse associations were observed for common allergens, including house dust (OR = 0.72, 95% CI: 0.54, 0.94), cats (OR = 0.59, 95% CI: 0.41, 0.85), plants (OR = 0.77, 95% CI: 0.62, 0.96), and mold (OR = 0.49, 95% CI: 0.32, 0.75), and for all allergic symptoms, although some confidence intervals included unity. Trends were observed for decreased risks associated with increasing number of allergies (p = 0.0006) and severity of allergic symptoms (p = 0.003). These results provide support for the plausibility that immune function in relation to allergies may play a role in the etiology of pancreatic cancer.","Prior history of allergies and pancreatic cancer in the San Francisco Bay area."
"304","American Journal of Epidemiology.35","0.05",12936900,2003,"In a 1994-1998 cross-sectional study of a multiethnic sample of 2,211 men and women in San Diego, California, the authors estimated prevalence of the major manifestations of chronic venous disease: spider veins, varicose veins, trophic changes, and edema by visual inspection; superficial and deep functional disease (reflux or obstruction) by duplex ultrasonography; and venous thrombotic events based on history. Venous disease increased with age, and, compared with Hispanics, African Americans, and Asians, non-Hispanic Whites had more disease. Spider veins, varicose veins, superficial functional disease, and superficial thrombotic events were more common in women than men (odds ratio (OR) = 5.4, OR = 2.2, OR = 1.9, and OR = 1.9, respectively; p < 0.05), but trophic changes and deep functional disease were less common in women (OR = 0.7 for both; p < 0.05). Visible (varicose veins or trophic changes) and functional (superficial or deep) disease were closely linked; 92.0% of legs were concordant and 8.0% discordant. For legs evidencing both trophic changes and deep functional disease, the age-adjusted prevalences of edema, superficial events, and deep events were 48.2%, 11.3%, and 24.6%, respectively, compared with 1.7%, 0.6%, and 1.3% for legs visibly and functionally normal. However, visible disease did not invariably predict functional disease, or vice versa, and venous thrombotic events occurred in the absence of either.","Chronic venous disease in an ethnically diverse population: the San Diego Population Study."
"305","American Journal of Epidemiology.36","0.05",12936900,2003,"In a 1994-1998 cross-sectional study of a multiethnic sample of 2,211 men and women in San Diego, California, the authors estimated prevalence of the major manifestations of chronic venous disease: spider veins, varicose veins, trophic changes, and edema by visual inspection; superficial and deep functional disease (reflux or obstruction) by duplex ultrasonography; and venous thrombotic events based on history. Venous disease increased with age, and, compared with Hispanics, African Americans, and Asians, non-Hispanic Whites had more disease. Spider veins, varicose veins, superficial functional disease, and superficial thrombotic events were more common in women than men (odds ratio (OR) = 5.4, OR = 2.2, OR = 1.9, and OR = 1.9, respectively; p < 0.05), but trophic changes and deep functional disease were less common in women (OR = 0.7 for both; p < 0.05). Visible (varicose veins or trophic changes) and functional (superficial or deep) disease were closely linked; 92.0% of legs were concordant and 8.0% discordant. For legs evidencing both trophic changes and deep functional disease, the age-adjusted prevalences of edema, superficial events, and deep events were 48.2%, 11.3%, and 24.6%, respectively, compared with 1.7%, 0.6%, and 1.3% for legs visibly and functionally normal. However, visible disease did not invariably predict functional disease, or vice versa, and venous thrombotic events occurred in the absence of either.","Chronic venous disease in an ethnically diverse population: the San Diego Population Study."
"306","American Journal of Epidemiology.37","0.05",12936900,2003,"In a 1994-1998 cross-sectional study of a multiethnic sample of 2,211 men and women in San Diego, California, the authors estimated prevalence of the major manifestations of chronic venous disease: spider veins, varicose veins, trophic changes, and edema by visual inspection; superficial and deep functional disease (reflux or obstruction) by duplex ultrasonography; and venous thrombotic events based on history. Venous disease increased with age, and, compared with Hispanics, African Americans, and Asians, non-Hispanic Whites had more disease. Spider veins, varicose veins, superficial functional disease, and superficial thrombotic events were more common in women than men (odds ratio (OR) = 5.4, OR = 2.2, OR = 1.9, and OR = 1.9, respectively; p < 0.05), but trophic changes and deep functional disease were less common in women (OR = 0.7 for both; p < 0.05). Visible (varicose veins or trophic changes) and functional (superficial or deep) disease were closely linked; 92.0% of legs were concordant and 8.0% discordant. For legs evidencing both trophic changes and deep functional disease, the age-adjusted prevalences of edema, superficial events, and deep events were 48.2%, 11.3%, and 24.6%, respectively, compared with 1.7%, 0.6%, and 1.3% for legs visibly and functionally normal. However, visible disease did not invariably predict functional disease, or vice versa, and venous thrombotic events occurred in the absence of either.","Chronic venous disease in an ethnically diverse population: the San Diego Population Study."
"307","American Journal of Epidemiology.38","0.05",12936900,2003,"In a 1994-1998 cross-sectional study of a multiethnic sample of 2,211 men and women in San Diego, California, the authors estimated prevalence of the major manifestations of chronic venous disease: spider veins, varicose veins, trophic changes, and edema by visual inspection; superficial and deep functional disease (reflux or obstruction) by duplex ultrasonography; and venous thrombotic events based on history. Venous disease increased with age, and, compared with Hispanics, African Americans, and Asians, non-Hispanic Whites had more disease. Spider veins, varicose veins, superficial functional disease, and superficial thrombotic events were more common in women than men (odds ratio (OR) = 5.4, OR = 2.2, OR = 1.9, and OR = 1.9, respectively; p < 0.05), but trophic changes and deep functional disease were less common in women (OR = 0.7 for both; p < 0.05). Visible (varicose veins or trophic changes) and functional (superficial or deep) disease were closely linked; 92.0% of legs were concordant and 8.0% discordant. For legs evidencing both trophic changes and deep functional disease, the age-adjusted prevalences of edema, superficial events, and deep events were 48.2%, 11.3%, and 24.6%, respectively, compared with 1.7%, 0.6%, and 1.3% for legs visibly and functionally normal. However, visible disease did not invariably predict functional disease, or vice versa, and venous thrombotic events occurred in the absence of either.","Chronic venous disease in an ethnically diverse population: the San Diego Population Study."
"308","American Journal of Epidemiology.36","0.05",12936900,2003,"In a 1994-1998 cross-sectional study of a multiethnic sample of 2,211 men and women in San Diego, California, the authors estimated prevalence of the major manifestations of chronic venous disease: spider veins, varicose veins, trophic changes, and edema by visual inspection; superficial and deep functional disease (reflux or obstruction) by duplex ultrasonography; and venous thrombotic events based on history. Venous disease increased with age, and, compared with Hispanics, African Americans, and Asians, non-Hispanic Whites had more disease. Spider veins, varicose veins, superficial functional disease, and superficial thrombotic events were more common in women than men (odds ratio (OR) = 5.4, OR = 2.2, OR = 1.9, and OR = 1.9, respectively; p < 0.05), but trophic changes and deep functional disease were less common in women (OR = 0.7 for both; p < 0.05). Visible (varicose veins or trophic changes) and functional (superficial or deep) disease were closely linked; 92.0% of legs were concordant and 8.0% discordant. For legs evidencing both trophic changes and deep functional disease, the age-adjusted prevalences of edema, superficial events, and deep events were 48.2%, 11.3%, and 24.6%, respectively, compared with 1.7%, 0.6%, and 1.3% for legs visibly and functionally normal. However, visible disease did not invariably predict functional disease, or vice versa, and venous thrombotic events occurred in the absence of either.","Chronic venous disease in an ethnically diverse population: the San Diego Population Study."
"309","Lancet.1310","0.001",12944059,2003,"Studies that have shown clinical depression to be a risk factor for cardiac events after coronary artery bypass graft (CABG) surgery have had small sample sizes, short follow-up, and have not had adequate power to assess mortality. We sought to assess whether depression is associated with an increased risk of mortality.We assessed 817 patients undergoing CABG at Duke University Medical Center between May, 1989, and May, 2001. Patients completed the Center for Epidemiological Studies-Depression (CES-D) scale before surgery, 6 months after CABG, and were followed-up for up to 12 years.In 817 patients there were 122 deaths (15%) in a mean follow-up of 5.2 years. 310 patients (38%) met the criterion for depression (CES-D > or =16): 213 (26%) for mild depression (CES-D 16-26) and 97 (12%) for moderate to severe depression (CES-D > or =27). Survival analyses, controlling for age, sex, number of grafts, diabetes, smoking, left ventricular ejection fraction, and previous myocardial infarction, showed that patients with moderate to severe depression at baseline (adjusted hazard ratio [HR] 2.4, [95% CI 1.4-4.0]; p=0.001) and mild or moderate to severe depression that persisted from baseline to 6 months (adjusted HR 2.2, [1.2-4.2]; p=0.015) had higher rates of death than did those with no depression.Despite advances in surgical and medical management of patients after CABG, depression is an important independent predictor of death after CABG and should be carefully monitored and treated if necessary.","Depression as a risk factor for mortality after coronary artery bypass surgery."
"310","Lancet.1410","0.015",12944059,2003,"Studies that have shown clinical depression to be a risk factor for cardiac events after coronary artery bypass graft (CABG) surgery have had small sample sizes, short follow-up, and have not had adequate power to assess mortality. We sought to assess whether depression is associated with an increased risk of mortality.We assessed 817 patients undergoing CABG at Duke University Medical Center between May, 1989, and May, 2001. Patients completed the Center for Epidemiological Studies-Depression (CES-D) scale before surgery, 6 months after CABG, and were followed-up for up to 12 years.In 817 patients there were 122 deaths (15%) in a mean follow-up of 5.2 years. 310 patients (38%) met the criterion for depression (CES-D > or =16): 213 (26%) for mild depression (CES-D 16-26) and 97 (12%) for moderate to severe depression (CES-D > or =27). Survival analyses, controlling for age, sex, number of grafts, diabetes, smoking, left ventricular ejection fraction, and previous myocardial infarction, showed that patients with moderate to severe depression at baseline (adjusted hazard ratio [HR] 2.4, [95% CI 1.4-4.0]; p=0.001) and mild or moderate to severe depression that persisted from baseline to 6 months (adjusted HR 2.2, [1.2-4.2]; p=0.015) had higher rates of death than did those with no depression.Despite advances in surgical and medical management of patients after CABG, depression is an important independent predictor of death after CABG and should be carefully monitored and treated if necessary.","Depression as a risk factor for mortality after coronary artery bypass surgery."
"311","JAMA.150","0.001",14506117,2003,"Adult survivors of childhood cancer are at risk for medical and psychosocial sequelae that may adversely affect their health status.To compare the health status of adult survivors of childhood cancer and siblings and to identify factors associated with adverse outcomes.Health status was assessed in 9535 adult participants of the Childhood Cancer Survivor Study, a cohort of long-term survivors of childhood cancer who were diagnosed between 1970 and 1986. A randomly selected cohort of the survivors' siblings (n = 2916) served as a comparison group.Six health status domains were assessed: general health, mental health, functional status, activity limitations, cancer-related pain, and cancer-related anxiety/fears. The first 4 domains were assessed in the control group.Survivors were significantly more likely to report adverse general health (odds ratio [OR], 2.5; 95% confidence interval [CI], 2.1-3.0; P<.001), mental health (OR, 1.8; 95% CI, 1.6-2.1; P<.001), activity limitations (OR, 2.7; 95% CI, 2.3-3.3; P<.001), and functional impairment (OR, 5.2; 95% CI, 4.1-6.6; P<.001), compared with siblings. Forty-four percent of survivors reported at least 1 adversely affected health status domain. Sociodemographic factors associated with reporting at least 1 adverse health status domain included being female (OR, 1.4; 95% CI, 1.3-1.6; P<.001), lower level of educational attainment (OR, 2.0; 95% CI, 1.8-2.2; P<.001), and annual income less than 20 000 dollars (OR, 1.8; 95% CI, 1.6-2.1; P<.001). Relative to those survivors with childhood leukemia, an increased risk was observed for at least 1 adverse health status domain among those with bone tumors (OR, 2.1; 95% CI, 1.8-2.5; P<.001), central nervous system tumors (OR, 1.7; 95% CI, 1.5-2.0; P<.001), and sarcomas (OR, 1.2; 95% CI, 1.1-1.5; P =.01).Clinicians caring for adult survivors of childhood cancer should be aware of the substantial risk for adverse health status, especially among females, those with low educational attainment, and those with low household incomes.","Health status of adult long-term survivors of childhood cancer: a report from the Childhood Cancer Survivor Study."
"312","JAMA.151","0.001",14506117,2003,"Adult survivors of childhood cancer are at risk for medical and psychosocial sequelae that may adversely affect their health status.To compare the health status of adult survivors of childhood cancer and siblings and to identify factors associated with adverse outcomes.Health status was assessed in 9535 adult participants of the Childhood Cancer Survivor Study, a cohort of long-term survivors of childhood cancer who were diagnosed between 1970 and 1986. A randomly selected cohort of the survivors' siblings (n = 2916) served as a comparison group.Six health status domains were assessed: general health, mental health, functional status, activity limitations, cancer-related pain, and cancer-related anxiety/fears. The first 4 domains were assessed in the control group.Survivors were significantly more likely to report adverse general health (odds ratio [OR], 2.5; 95% confidence interval [CI], 2.1-3.0; P<.001), mental health (OR, 1.8; 95% CI, 1.6-2.1; P<.001), activity limitations (OR, 2.7; 95% CI, 2.3-3.3; P<.001), and functional impairment (OR, 5.2; 95% CI, 4.1-6.6; P<.001), compared with siblings. Forty-four percent of survivors reported at least 1 adversely affected health status domain. Sociodemographic factors associated with reporting at least 1 adverse health status domain included being female (OR, 1.4; 95% CI, 1.3-1.6; P<.001), lower level of educational attainment (OR, 2.0; 95% CI, 1.8-2.2; P<.001), and annual income less than 20 000 dollars (OR, 1.8; 95% CI, 1.6-2.1; P<.001). Relative to those survivors with childhood leukemia, an increased risk was observed for at least 1 adverse health status domain among those with bone tumors (OR, 2.1; 95% CI, 1.8-2.5; P<.001), central nervous system tumors (OR, 1.7; 95% CI, 1.5-2.0; P<.001), and sarcomas (OR, 1.2; 95% CI, 1.1-1.5; P =.01).Clinicians caring for adult survivors of childhood cancer should be aware of the substantial risk for adverse health status, especially among females, those with low educational attainment, and those with low household incomes.","Health status of adult long-term survivors of childhood cancer: a report from the Childhood Cancer Survivor Study."
"313","JAMA.152","0.001",14506117,2003,"Adult survivors of childhood cancer are at risk for medical and psychosocial sequelae that may adversely affect their health status.To compare the health status of adult survivors of childhood cancer and siblings and to identify factors associated with adverse outcomes.Health status was assessed in 9535 adult participants of the Childhood Cancer Survivor Study, a cohort of long-term survivors of childhood cancer who were diagnosed between 1970 and 1986. A randomly selected cohort of the survivors' siblings (n = 2916) served as a comparison group.Six health status domains were assessed: general health, mental health, functional status, activity limitations, cancer-related pain, and cancer-related anxiety/fears. The first 4 domains were assessed in the control group.Survivors were significantly more likely to report adverse general health (odds ratio [OR], 2.5; 95% confidence interval [CI], 2.1-3.0; P<.001), mental health (OR, 1.8; 95% CI, 1.6-2.1; P<.001), activity limitations (OR, 2.7; 95% CI, 2.3-3.3; P<.001), and functional impairment (OR, 5.2; 95% CI, 4.1-6.6; P<.001), compared with siblings. Forty-four percent of survivors reported at least 1 adversely affected health status domain. Sociodemographic factors associated with reporting at least 1 adverse health status domain included being female (OR, 1.4; 95% CI, 1.3-1.6; P<.001), lower level of educational attainment (OR, 2.0; 95% CI, 1.8-2.2; P<.001), and annual income less than 20 000 dollars (OR, 1.8; 95% CI, 1.6-2.1; P<.001). Relative to those survivors with childhood leukemia, an increased risk was observed for at least 1 adverse health status domain among those with bone tumors (OR, 2.1; 95% CI, 1.8-2.5; P<.001), central nervous system tumors (OR, 1.7; 95% CI, 1.5-2.0; P<.001), and sarcomas (OR, 1.2; 95% CI, 1.1-1.5; P =.01).Clinicians caring for adult survivors of childhood cancer should be aware of the substantial risk for adverse health status, especially among females, those with low educational attainment, and those with low household incomes.","Health status of adult long-term survivors of childhood cancer: a report from the Childhood Cancer Survivor Study."
"314","JAMA.153","0.001",14506117,2003,"Adult survivors of childhood cancer are at risk for medical and psychosocial sequelae that may adversely affect their health status.To compare the health status of adult survivors of childhood cancer and siblings and to identify factors associated with adverse outcomes.Health status was assessed in 9535 adult participants of the Childhood Cancer Survivor Study, a cohort of long-term survivors of childhood cancer who were diagnosed between 1970 and 1986. A randomly selected cohort of the survivors' siblings (n = 2916) served as a comparison group.Six health status domains were assessed: general health, mental health, functional status, activity limitations, cancer-related pain, and cancer-related anxiety/fears. The first 4 domains were assessed in the control group.Survivors were significantly more likely to report adverse general health (odds ratio [OR], 2.5; 95% confidence interval [CI], 2.1-3.0; P<.001), mental health (OR, 1.8; 95% CI, 1.6-2.1; P<.001), activity limitations (OR, 2.7; 95% CI, 2.3-3.3; P<.001), and functional impairment (OR, 5.2; 95% CI, 4.1-6.6; P<.001), compared with siblings. Forty-four percent of survivors reported at least 1 adversely affected health status domain. Sociodemographic factors associated with reporting at least 1 adverse health status domain included being female (OR, 1.4; 95% CI, 1.3-1.6; P<.001), lower level of educational attainment (OR, 2.0; 95% CI, 1.8-2.2; P<.001), and annual income less than 20 000 dollars (OR, 1.8; 95% CI, 1.6-2.1; P<.001). Relative to those survivors with childhood leukemia, an increased risk was observed for at least 1 adverse health status domain among those with bone tumors (OR, 2.1; 95% CI, 1.8-2.5; P<.001), central nervous system tumors (OR, 1.7; 95% CI, 1.5-2.0; P<.001), and sarcomas (OR, 1.2; 95% CI, 1.1-1.5; P =.01).Clinicians caring for adult survivors of childhood cancer should be aware of the substantial risk for adverse health status, especially among females, those with low educational attainment, and those with low household incomes.","Health status of adult long-term survivors of childhood cancer: a report from the Childhood Cancer Survivor Study."
"315","JAMA.154","0.001",14506117,2003,"Adult survivors of childhood cancer are at risk for medical and psychosocial sequelae that may adversely affect their health status.To compare the health status of adult survivors of childhood cancer and siblings and to identify factors associated with adverse outcomes.Health status was assessed in 9535 adult participants of the Childhood Cancer Survivor Study, a cohort of long-term survivors of childhood cancer who were diagnosed between 1970 and 1986. A randomly selected cohort of the survivors' siblings (n = 2916) served as a comparison group.Six health status domains were assessed: general health, mental health, functional status, activity limitations, cancer-related pain, and cancer-related anxiety/fears. The first 4 domains were assessed in the control group.Survivors were significantly more likely to report adverse general health (odds ratio [OR], 2.5; 95% confidence interval [CI], 2.1-3.0; P<.001), mental health (OR, 1.8; 95% CI, 1.6-2.1; P<.001), activity limitations (OR, 2.7; 95% CI, 2.3-3.3; P<.001), and functional impairment (OR, 5.2; 95% CI, 4.1-6.6; P<.001), compared with siblings. Forty-four percent of survivors reported at least 1 adversely affected health status domain. Sociodemographic factors associated with reporting at least 1 adverse health status domain included being female (OR, 1.4; 95% CI, 1.3-1.6; P<.001), lower level of educational attainment (OR, 2.0; 95% CI, 1.8-2.2; P<.001), and annual income less than 20 000 dollars (OR, 1.8; 95% CI, 1.6-2.1; P<.001). Relative to those survivors with childhood leukemia, an increased risk was observed for at least 1 adverse health status domain among those with bone tumors (OR, 2.1; 95% CI, 1.8-2.5; P<.001), central nervous system tumors (OR, 1.7; 95% CI, 1.5-2.0; P<.001), and sarcomas (OR, 1.2; 95% CI, 1.1-1.5; P =.01).Clinicians caring for adult survivors of childhood cancer should be aware of the substantial risk for adverse health status, especially among females, those with low educational attainment, and those with low household incomes.","Health status of adult long-term survivors of childhood cancer: a report from the Childhood Cancer Survivor Study."
"316","JAMA.155","0.001",14506117,2003,"Adult survivors of childhood cancer are at risk for medical and psychosocial sequelae that may adversely affect their health status.To compare the health status of adult survivors of childhood cancer and siblings and to identify factors associated with adverse outcomes.Health status was assessed in 9535 adult participants of the Childhood Cancer Survivor Study, a cohort of long-term survivors of childhood cancer who were diagnosed between 1970 and 1986. A randomly selected cohort of the survivors' siblings (n = 2916) served as a comparison group.Six health status domains were assessed: general health, mental health, functional status, activity limitations, cancer-related pain, and cancer-related anxiety/fears. The first 4 domains were assessed in the control group.Survivors were significantly more likely to report adverse general health (odds ratio [OR], 2.5; 95% confidence interval [CI], 2.1-3.0; P<.001), mental health (OR, 1.8; 95% CI, 1.6-2.1; P<.001), activity limitations (OR, 2.7; 95% CI, 2.3-3.3; P<.001), and functional impairment (OR, 5.2; 95% CI, 4.1-6.6; P<.001), compared with siblings. Forty-four percent of survivors reported at least 1 adversely affected health status domain. Sociodemographic factors associated with reporting at least 1 adverse health status domain included being female (OR, 1.4; 95% CI, 1.3-1.6; P<.001), lower level of educational attainment (OR, 2.0; 95% CI, 1.8-2.2; P<.001), and annual income less than 20 000 dollars (OR, 1.8; 95% CI, 1.6-2.1; P<.001). Relative to those survivors with childhood leukemia, an increased risk was observed for at least 1 adverse health status domain among those with bone tumors (OR, 2.1; 95% CI, 1.8-2.5; P<.001), central nervous system tumors (OR, 1.7; 95% CI, 1.5-2.0; P<.001), and sarcomas (OR, 1.2; 95% CI, 1.1-1.5; P =.01).Clinicians caring for adult survivors of childhood cancer should be aware of the substantial risk for adverse health status, especially among females, those with low educational attainment, and those with low household incomes.","Health status of adult long-term survivors of childhood cancer: a report from the Childhood Cancer Survivor Study."
"317","JAMA.156","0.001",14506117,2003,"Adult survivors of childhood cancer are at risk for medical and psychosocial sequelae that may adversely affect their health status.To compare the health status of adult survivors of childhood cancer and siblings and to identify factors associated with adverse outcomes.Health status was assessed in 9535 adult participants of the Childhood Cancer Survivor Study, a cohort of long-term survivors of childhood cancer who were diagnosed between 1970 and 1986. A randomly selected cohort of the survivors' siblings (n = 2916) served as a comparison group.Six health status domains were assessed: general health, mental health, functional status, activity limitations, cancer-related pain, and cancer-related anxiety/fears. The first 4 domains were assessed in the control group.Survivors were significantly more likely to report adverse general health (odds ratio [OR], 2.5; 95% confidence interval [CI], 2.1-3.0; P<.001), mental health (OR, 1.8; 95% CI, 1.6-2.1; P<.001), activity limitations (OR, 2.7; 95% CI, 2.3-3.3; P<.001), and functional impairment (OR, 5.2; 95% CI, 4.1-6.6; P<.001), compared with siblings. Forty-four percent of survivors reported at least 1 adversely affected health status domain. Sociodemographic factors associated with reporting at least 1 adverse health status domain included being female (OR, 1.4; 95% CI, 1.3-1.6; P<.001), lower level of educational attainment (OR, 2.0; 95% CI, 1.8-2.2; P<.001), and annual income less than 20 000 dollars (OR, 1.8; 95% CI, 1.6-2.1; P<.001). Relative to those survivors with childhood leukemia, an increased risk was observed for at least 1 adverse health status domain among those with bone tumors (OR, 2.1; 95% CI, 1.8-2.5; P<.001), central nervous system tumors (OR, 1.7; 95% CI, 1.5-2.0; P<.001), and sarcomas (OR, 1.2; 95% CI, 1.1-1.5; P =.01).Clinicians caring for adult survivors of childhood cancer should be aware of the substantial risk for adverse health status, especially among females, those with low educational attainment, and those with low household incomes.","Health status of adult long-term survivors of childhood cancer: a report from the Childhood Cancer Survivor Study."
"318","JAMA.157","0.001",14506117,2003,"Adult survivors of childhood cancer are at risk for medical and psychosocial sequelae that may adversely affect their health status.To compare the health status of adult survivors of childhood cancer and siblings and to identify factors associated with adverse outcomes.Health status was assessed in 9535 adult participants of the Childhood Cancer Survivor Study, a cohort of long-term survivors of childhood cancer who were diagnosed between 1970 and 1986. A randomly selected cohort of the survivors' siblings (n = 2916) served as a comparison group.Six health status domains were assessed: general health, mental health, functional status, activity limitations, cancer-related pain, and cancer-related anxiety/fears. The first 4 domains were assessed in the control group.Survivors were significantly more likely to report adverse general health (odds ratio [OR], 2.5; 95% confidence interval [CI], 2.1-3.0; P<.001), mental health (OR, 1.8; 95% CI, 1.6-2.1; P<.001), activity limitations (OR, 2.7; 95% CI, 2.3-3.3; P<.001), and functional impairment (OR, 5.2; 95% CI, 4.1-6.6; P<.001), compared with siblings. Forty-four percent of survivors reported at least 1 adversely affected health status domain. Sociodemographic factors associated with reporting at least 1 adverse health status domain included being female (OR, 1.4; 95% CI, 1.3-1.6; P<.001), lower level of educational attainment (OR, 2.0; 95% CI, 1.8-2.2; P<.001), and annual income less than 20 000 dollars (OR, 1.8; 95% CI, 1.6-2.1; P<.001). Relative to those survivors with childhood leukemia, an increased risk was observed for at least 1 adverse health status domain among those with bone tumors (OR, 2.1; 95% CI, 1.8-2.5; P<.001), central nervous system tumors (OR, 1.7; 95% CI, 1.5-2.0; P<.001), and sarcomas (OR, 1.2; 95% CI, 1.1-1.5; P =.01).Clinicians caring for adult survivors of childhood cancer should be aware of the substantial risk for adverse health status, especially among females, those with low educational attainment, and those with low household incomes.","Health status of adult long-term survivors of childhood cancer: a report from the Childhood Cancer Survivor Study."
"319","JAMA.158","0.001",14506117,2003,"Adult survivors of childhood cancer are at risk for medical and psychosocial sequelae that may adversely affect their health status.To compare the health status of adult survivors of childhood cancer and siblings and to identify factors associated with adverse outcomes.Health status was assessed in 9535 adult participants of the Childhood Cancer Survivor Study, a cohort of long-term survivors of childhood cancer who were diagnosed between 1970 and 1986. A randomly selected cohort of the survivors' siblings (n = 2916) served as a comparison group.Six health status domains were assessed: general health, mental health, functional status, activity limitations, cancer-related pain, and cancer-related anxiety/fears. The first 4 domains were assessed in the control group.Survivors were significantly more likely to report adverse general health (odds ratio [OR], 2.5; 95% confidence interval [CI], 2.1-3.0; P<.001), mental health (OR, 1.8; 95% CI, 1.6-2.1; P<.001), activity limitations (OR, 2.7; 95% CI, 2.3-3.3; P<.001), and functional impairment (OR, 5.2; 95% CI, 4.1-6.6; P<.001), compared with siblings. Forty-four percent of survivors reported at least 1 adversely affected health status domain. Sociodemographic factors associated with reporting at least 1 adverse health status domain included being female (OR, 1.4; 95% CI, 1.3-1.6; P<.001), lower level of educational attainment (OR, 2.0; 95% CI, 1.8-2.2; P<.001), and annual income less than 20 000 dollars (OR, 1.8; 95% CI, 1.6-2.1; P<.001). Relative to those survivors with childhood leukemia, an increased risk was observed for at least 1 adverse health status domain among those with bone tumors (OR, 2.1; 95% CI, 1.8-2.5; P<.001), central nervous system tumors (OR, 1.7; 95% CI, 1.5-2.0; P<.001), and sarcomas (OR, 1.2; 95% CI, 1.1-1.5; P =.01).Clinicians caring for adult survivors of childhood cancer should be aware of the substantial risk for adverse health status, especially among females, those with low educational attainment, and those with low household incomes.","Health status of adult long-term survivors of childhood cancer: a report from the Childhood Cancer Survivor Study."
"320","JAMA.191","0.01",14506117,2003,"Adult survivors of childhood cancer are at risk for medical and psychosocial sequelae that may adversely affect their health status.To compare the health status of adult survivors of childhood cancer and siblings and to identify factors associated with adverse outcomes.Health status was assessed in 9535 adult participants of the Childhood Cancer Survivor Study, a cohort of long-term survivors of childhood cancer who were diagnosed between 1970 and 1986. A randomly selected cohort of the survivors' siblings (n = 2916) served as a comparison group.Six health status domains were assessed: general health, mental health, functional status, activity limitations, cancer-related pain, and cancer-related anxiety/fears. The first 4 domains were assessed in the control group.Survivors were significantly more likely to report adverse general health (odds ratio [OR], 2.5; 95% confidence interval [CI], 2.1-3.0; P<.001), mental health (OR, 1.8; 95% CI, 1.6-2.1; P<.001), activity limitations (OR, 2.7; 95% CI, 2.3-3.3; P<.001), and functional impairment (OR, 5.2; 95% CI, 4.1-6.6; P<.001), compared with siblings. Forty-four percent of survivors reported at least 1 adversely affected health status domain. Sociodemographic factors associated with reporting at least 1 adverse health status domain included being female (OR, 1.4; 95% CI, 1.3-1.6; P<.001), lower level of educational attainment (OR, 2.0; 95% CI, 1.8-2.2; P<.001), and annual income less than 20 000 dollars (OR, 1.8; 95% CI, 1.6-2.1; P<.001). Relative to those survivors with childhood leukemia, an increased risk was observed for at least 1 adverse health status domain among those with bone tumors (OR, 2.1; 95% CI, 1.8-2.5; P<.001), central nervous system tumors (OR, 1.7; 95% CI, 1.5-2.0; P<.001), and sarcomas (OR, 1.2; 95% CI, 1.1-1.5; P =.01).Clinicians caring for adult survivors of childhood cancer should be aware of the substantial risk for adverse health status, especially among females, those with low educational attainment, and those with low household incomes.","Health status of adult long-term survivors of childhood cancer: a report from the Childhood Cancer Survivor Study."
"321","JAMA.1061","0.001",14506119,2003,"The value of exercise testing in women has been questioned.To determine the prognostic value of exercise testing in a population-based cohort of asymptomatic women followed up for 20 years.Near-maximal Bruce-protocol treadmill test data from the Lipid Research Clinics Prevalence Study (1972-1976) with follow-up through 1995.A total of 2994 asymptomatic North American women, aged 30 to 80 years, without known cardiovascular disease.Cardiovascular and all-cause mortality.There were 427 (14%) deaths during 20 years of follow-up, of which 147 were due to cardiovascular causes. Low exercise capacity, low heart rate recovery (HRR), and not achieving target heart rate were independently associated with increased all-cause and cardiovascular mortality. There was no increased cardiovascular death risk for exercise-induced ST-segment depression (age-adjusted hazard ratio, 1.02; 95% confidence interval [CI], 0.57-1.80; P =.96). The age-adjusted hazard ratio for cardiovascular death for every metabolic equivalent (MET) decrement in exercise capacity was 1.20 (95% CI, 1.18-1.30; P<.001); for every 10 beats per minute decrement in HRR, the hazard ratio was 1.36 (95% CI, 1.19-1.55; P<.001). After adjusting for multiple other risk factors, women who were below the median for both exercise capacity and HRR had a 3.5-fold increased risk of cardiovascular death (95% CI, 1.57-7.86; P =.002) compared with those above the median for both variables. Among women with low risk Framingham scores, those with below median levels of both exercise capacity and HRR had significantly increased risk compared with women who had above median levels of these 2 exercise variables, 44.5 and 3.5 cardiovascular deaths per 10 000 person-years, respectively (hazard ratio for cardiovascular death, 12.93; 95% CI, 5.62-29.73; P<.001).The prognostic value of exercise testing in asymptomatic women derives not from electrocardiographic ischemia but from fitness-related variables.","Ability of exercise testing to predict cardiovascular and all-cause death in asymptomatic women: a 20-year follow-up of the lipid research clinics prevalence study."
"322","JAMA.1071","0.001",14506119,2003,"The value of exercise testing in women has been questioned.To determine the prognostic value of exercise testing in a population-based cohort of asymptomatic women followed up for 20 years.Near-maximal Bruce-protocol treadmill test data from the Lipid Research Clinics Prevalence Study (1972-1976) with follow-up through 1995.A total of 2994 asymptomatic North American women, aged 30 to 80 years, without known cardiovascular disease.Cardiovascular and all-cause mortality.There were 427 (14%) deaths during 20 years of follow-up, of which 147 were due to cardiovascular causes. Low exercise capacity, low heart rate recovery (HRR), and not achieving target heart rate were independently associated with increased all-cause and cardiovascular mortality. There was no increased cardiovascular death risk for exercise-induced ST-segment depression (age-adjusted hazard ratio, 1.02; 95% confidence interval [CI], 0.57-1.80; P =.96). The age-adjusted hazard ratio for cardiovascular death for every metabolic equivalent (MET) decrement in exercise capacity was 1.20 (95% CI, 1.18-1.30; P<.001); for every 10 beats per minute decrement in HRR, the hazard ratio was 1.36 (95% CI, 1.19-1.55; P<.001). After adjusting for multiple other risk factors, women who were below the median for both exercise capacity and HRR had a 3.5-fold increased risk of cardiovascular death (95% CI, 1.57-7.86; P =.002) compared with those above the median for both variables. Among women with low risk Framingham scores, those with below median levels of both exercise capacity and HRR had significantly increased risk compared with women who had above median levels of these 2 exercise variables, 44.5 and 3.5 cardiovascular deaths per 10 000 person-years, respectively (hazard ratio for cardiovascular death, 12.93; 95% CI, 5.62-29.73; P<.001).The prognostic value of exercise testing in asymptomatic women derives not from electrocardiographic ischemia but from fitness-related variables.","Ability of exercise testing to predict cardiovascular and all-cause death in asymptomatic women: a 20-year follow-up of the lipid research clinics prevalence study."
"323","JAMA.1081","0.001",14506119,2003,"The value of exercise testing in women has been questioned.To determine the prognostic value of exercise testing in a population-based cohort of asymptomatic women followed up for 20 years.Near-maximal Bruce-protocol treadmill test data from the Lipid Research Clinics Prevalence Study (1972-1976) with follow-up through 1995.A total of 2994 asymptomatic North American women, aged 30 to 80 years, without known cardiovascular disease.Cardiovascular and all-cause mortality.There were 427 (14%) deaths during 20 years of follow-up, of which 147 were due to cardiovascular causes. Low exercise capacity, low heart rate recovery (HRR), and not achieving target heart rate were independently associated with increased all-cause and cardiovascular mortality. There was no increased cardiovascular death risk for exercise-induced ST-segment depression (age-adjusted hazard ratio, 1.02; 95% confidence interval [CI], 0.57-1.80; P =.96). The age-adjusted hazard ratio for cardiovascular death for every metabolic equivalent (MET) decrement in exercise capacity was 1.20 (95% CI, 1.18-1.30; P<.001); for every 10 beats per minute decrement in HRR, the hazard ratio was 1.36 (95% CI, 1.19-1.55; P<.001). After adjusting for multiple other risk factors, women who were below the median for both exercise capacity and HRR had a 3.5-fold increased risk of cardiovascular death (95% CI, 1.57-7.86; P =.002) compared with those above the median for both variables. Among women with low risk Framingham scores, those with below median levels of both exercise capacity and HRR had significantly increased risk compared with women who had above median levels of these 2 exercise variables, 44.5 and 3.5 cardiovascular deaths per 10 000 person-years, respectively (hazard ratio for cardiovascular death, 12.93; 95% CI, 5.62-29.73; P<.001).The prognostic value of exercise testing in asymptomatic women derives not from electrocardiographic ischemia but from fitness-related variables.","Ability of exercise testing to predict cardiovascular and all-cause death in asymptomatic women: a 20-year follow-up of the lipid research clinics prevalence study."
"324","JAMA.1291","0.96",14506119,2003,"The value of exercise testing in women has been questioned.To determine the prognostic value of exercise testing in a population-based cohort of asymptomatic women followed up for 20 years.Near-maximal Bruce-protocol treadmill test data from the Lipid Research Clinics Prevalence Study (1972-1976) with follow-up through 1995.A total of 2994 asymptomatic North American women, aged 30 to 80 years, without known cardiovascular disease.Cardiovascular and all-cause mortality.There were 427 (14%) deaths during 20 years of follow-up, of which 147 were due to cardiovascular causes. Low exercise capacity, low heart rate recovery (HRR), and not achieving target heart rate were independently associated with increased all-cause and cardiovascular mortality. There was no increased cardiovascular death risk for exercise-induced ST-segment depression (age-adjusted hazard ratio, 1.02; 95% confidence interval [CI], 0.57-1.80; P =.96). The age-adjusted hazard ratio for cardiovascular death for every metabolic equivalent (MET) decrement in exercise capacity was 1.20 (95% CI, 1.18-1.30; P<.001); for every 10 beats per minute decrement in HRR, the hazard ratio was 1.36 (95% CI, 1.19-1.55; P<.001). After adjusting for multiple other risk factors, women who were below the median for both exercise capacity and HRR had a 3.5-fold increased risk of cardiovascular death (95% CI, 1.57-7.86; P =.002) compared with those above the median for both variables. Among women with low risk Framingham scores, those with below median levels of both exercise capacity and HRR had significantly increased risk compared with women who had above median levels of these 2 exercise variables, 44.5 and 3.5 cardiovascular deaths per 10 000 person-years, respectively (hazard ratio for cardiovascular death, 12.93; 95% CI, 5.62-29.73; P<.001).The prognostic value of exercise testing in asymptomatic women derives not from electrocardiographic ischemia but from fitness-related variables.","Ability of exercise testing to predict cardiovascular and all-cause death in asymptomatic women: a 20-year follow-up of the lipid research clinics prevalence study."
"325","JAMA.1301","0.002",14506119,2003,"The value of exercise testing in women has been questioned.To determine the prognostic value of exercise testing in a population-based cohort of asymptomatic women followed up for 20 years.Near-maximal Bruce-protocol treadmill test data from the Lipid Research Clinics Prevalence Study (1972-1976) with follow-up through 1995.A total of 2994 asymptomatic North American women, aged 30 to 80 years, without known cardiovascular disease.Cardiovascular and all-cause mortality.There were 427 (14%) deaths during 20 years of follow-up, of which 147 were due to cardiovascular causes. Low exercise capacity, low heart rate recovery (HRR), and not achieving target heart rate were independently associated with increased all-cause and cardiovascular mortality. There was no increased cardiovascular death risk for exercise-induced ST-segment depression (age-adjusted hazard ratio, 1.02; 95% confidence interval [CI], 0.57-1.80; P =.96). The age-adjusted hazard ratio for cardiovascular death for every metabolic equivalent (MET) decrement in exercise capacity was 1.20 (95% CI, 1.18-1.30; P<.001); for every 10 beats per minute decrement in HRR, the hazard ratio was 1.36 (95% CI, 1.19-1.55; P<.001). After adjusting for multiple other risk factors, women who were below the median for both exercise capacity and HRR had a 3.5-fold increased risk of cardiovascular death (95% CI, 1.57-7.86; P =.002) compared with those above the median for both variables. Among women with low risk Framingham scores, those with below median levels of both exercise capacity and HRR had significantly increased risk compared with women who had above median levels of these 2 exercise variables, 44.5 and 3.5 cardiovascular deaths per 10 000 person-years, respectively (hazard ratio for cardiovascular death, 12.93; 95% CI, 5.62-29.73; P<.001).The prognostic value of exercise testing in asymptomatic women derives not from electrocardiographic ischemia but from fitness-related variables.","Ability of exercise testing to predict cardiovascular and all-cause death in asymptomatic women: a 20-year follow-up of the lipid research clinics prevalence study."
"326","JAMA.1048","NA",14519707,2003,"In the Women's Health Initiative trial of estrogen-plus-progestin therapy, women assigned to active treatment had fewer fractures.To test the hypothesis that the relative risk reduction of estrogen plus progestin on fractures differs according to risk factors for fractures.Randomized controlled trial (September 1993-July 2002) in which 16 608 postmenopausal women aged 50 to 79 years with an intact uterus at baseline were recruited at 40 US clinical centers and followed up for an average of 5.6 years.Women were randomly assigned to receive conjugated equine estrogen, 0.625 mg/d, plus medroxyprogesterone acetate, 2.5 mg/d, in 1 tablet (n = 8506) or placebo (n = 8102).All confirmed osteoporotic fracture events that occurred from enrollment to discontinuation of the trial (July 7, 2002); bone mineral density (BMD), measured in a subset of women (n = 1024) at baseline and years 1 and 3; and a global index, developed to summarize the balance of risks and benefits to test whether the risk-benefit profile differed across tertiles of fracture risk.Seven hundred thirty-three women (8.6%) in the estrogen-plus-progestin group and 896 women (11.1%) in the placebo group experienced a fracture (hazard ratio [HR], 0.76; 95% confidence interval [CI], 0.69-0.83). The effect did not differ in women stratified by age, body mass index, smoking status, history of falls, personal and family history of fracture, total calcium intake, past use of hormone therapy, BMD, or summary fracture risk score. Total hip BMD increased 3.7% after 3 years of treatment with estrogen plus progestin compared with 0.14% in the placebo group (P<.001). The HR for the global index was similar across tertiles of the fracture risk scale (lowest fracture risk tertile, HR, 1.20; 95% CI, 0.93-1.58; middle tertile, HR, 1.23; 95% CI, 1.04-1.46; highest tertile, HR, 1.03; 95% CI, 0.88-1.24) (P for interaction =.54).This study demonstrates that estrogen plus progestin increases BMD and reduces the risk of fracture in healthy postmenopausal women. The decreased risk of fracture attributed to estrogen plus progestin appeared to be present in all subgroups of women examined. When considering the effects of hormone therapy on other important disease outcomes in a global model, there was no net benefit, even in women considered to be at high risk of fracture.","Effects of estrogen plus progestin on risk of fracture and bone mineral density: the Women's Health Initiative randomized trial."
"327","JAMA.1049","NA",14519707,2003,"In the Women's Health Initiative trial of estrogen-plus-progestin therapy, women assigned to active treatment had fewer fractures.To test the hypothesis that the relative risk reduction of estrogen plus progestin on fractures differs according to risk factors for fractures.Randomized controlled trial (September 1993-July 2002) in which 16 608 postmenopausal women aged 50 to 79 years with an intact uterus at baseline were recruited at 40 US clinical centers and followed up for an average of 5.6 years.Women were randomly assigned to receive conjugated equine estrogen, 0.625 mg/d, plus medroxyprogesterone acetate, 2.5 mg/d, in 1 tablet (n = 8506) or placebo (n = 8102).All confirmed osteoporotic fracture events that occurred from enrollment to discontinuation of the trial (July 7, 2002); bone mineral density (BMD), measured in a subset of women (n = 1024) at baseline and years 1 and 3; and a global index, developed to summarize the balance of risks and benefits to test whether the risk-benefit profile differed across tertiles of fracture risk.Seven hundred thirty-three women (8.6%) in the estrogen-plus-progestin group and 896 women (11.1%) in the placebo group experienced a fracture (hazard ratio [HR], 0.76; 95% confidence interval [CI], 0.69-0.83). The effect did not differ in women stratified by age, body mass index, smoking status, history of falls, personal and family history of fracture, total calcium intake, past use of hormone therapy, BMD, or summary fracture risk score. Total hip BMD increased 3.7% after 3 years of treatment with estrogen plus progestin compared with 0.14% in the placebo group (P<.001). The HR for the global index was similar across tertiles of the fracture risk scale (lowest fracture risk tertile, HR, 1.20; 95% CI, 0.93-1.58; middle tertile, HR, 1.23; 95% CI, 1.04-1.46; highest tertile, HR, 1.03; 95% CI, 0.88-1.24) (P for interaction =.54).This study demonstrates that estrogen plus progestin increases BMD and reduces the risk of fracture in healthy postmenopausal women. The decreased risk of fracture attributed to estrogen plus progestin appeared to be present in all subgroups of women examined. When considering the effects of hormone therapy on other important disease outcomes in a global model, there was no net benefit, even in women considered to be at high risk of fracture.","Effects of estrogen plus progestin on risk of fracture and bone mineral density: the Women's Health Initiative randomized trial."
"328","JAMA.1050","NA",14519707,2003,"In the Women's Health Initiative trial of estrogen-plus-progestin therapy, women assigned to active treatment had fewer fractures.To test the hypothesis that the relative risk reduction of estrogen plus progestin on fractures differs according to risk factors for fractures.Randomized controlled trial (September 1993-July 2002) in which 16 608 postmenopausal women aged 50 to 79 years with an intact uterus at baseline were recruited at 40 US clinical centers and followed up for an average of 5.6 years.Women were randomly assigned to receive conjugated equine estrogen, 0.625 mg/d, plus medroxyprogesterone acetate, 2.5 mg/d, in 1 tablet (n = 8506) or placebo (n = 8102).All confirmed osteoporotic fracture events that occurred from enrollment to discontinuation of the trial (July 7, 2002); bone mineral density (BMD), measured in a subset of women (n = 1024) at baseline and years 1 and 3; and a global index, developed to summarize the balance of risks and benefits to test whether the risk-benefit profile differed across tertiles of fracture risk.Seven hundred thirty-three women (8.6%) in the estrogen-plus-progestin group and 896 women (11.1%) in the placebo group experienced a fracture (hazard ratio [HR], 0.76; 95% confidence interval [CI], 0.69-0.83). The effect did not differ in women stratified by age, body mass index, smoking status, history of falls, personal and family history of fracture, total calcium intake, past use of hormone therapy, BMD, or summary fracture risk score. Total hip BMD increased 3.7% after 3 years of treatment with estrogen plus progestin compared with 0.14% in the placebo group (P<.001). The HR for the global index was similar across tertiles of the fracture risk scale (lowest fracture risk tertile, HR, 1.20; 95% CI, 0.93-1.58; middle tertile, HR, 1.23; 95% CI, 1.04-1.46; highest tertile, HR, 1.03; 95% CI, 0.88-1.24) (P for interaction =.54).This study demonstrates that estrogen plus progestin increases BMD and reduces the risk of fracture in healthy postmenopausal women. The decreased risk of fracture attributed to estrogen plus progestin appeared to be present in all subgroups of women examined. When considering the effects of hormone therapy on other important disease outcomes in a global model, there was no net benefit, even in women considered to be at high risk of fracture.","Effects of estrogen plus progestin on risk of fracture and bone mineral density: the Women's Health Initiative randomized trial."
"329","JAMA.1051","NA",14519707,2003,"In the Women's Health Initiative trial of estrogen-plus-progestin therapy, women assigned to active treatment had fewer fractures.To test the hypothesis that the relative risk reduction of estrogen plus progestin on fractures differs according to risk factors for fractures.Randomized controlled trial (September 1993-July 2002) in which 16 608 postmenopausal women aged 50 to 79 years with an intact uterus at baseline were recruited at 40 US clinical centers and followed up for an average of 5.6 years.Women were randomly assigned to receive conjugated equine estrogen, 0.625 mg/d, plus medroxyprogesterone acetate, 2.5 mg/d, in 1 tablet (n = 8506) or placebo (n = 8102).All confirmed osteoporotic fracture events that occurred from enrollment to discontinuation of the trial (July 7, 2002); bone mineral density (BMD), measured in a subset of women (n = 1024) at baseline and years 1 and 3; and a global index, developed to summarize the balance of risks and benefits to test whether the risk-benefit profile differed across tertiles of fracture risk.Seven hundred thirty-three women (8.6%) in the estrogen-plus-progestin group and 896 women (11.1%) in the placebo group experienced a fracture (hazard ratio [HR], 0.76; 95% confidence interval [CI], 0.69-0.83). The effect did not differ in women stratified by age, body mass index, smoking status, history of falls, personal and family history of fracture, total calcium intake, past use of hormone therapy, BMD, or summary fracture risk score. Total hip BMD increased 3.7% after 3 years of treatment with estrogen plus progestin compared with 0.14% in the placebo group (P<.001). The HR for the global index was similar across tertiles of the fracture risk scale (lowest fracture risk tertile, HR, 1.20; 95% CI, 0.93-1.58; middle tertile, HR, 1.23; 95% CI, 1.04-1.46; highest tertile, HR, 1.03; 95% CI, 0.88-1.24) (P for interaction =.54).This study demonstrates that estrogen plus progestin increases BMD and reduces the risk of fracture in healthy postmenopausal women. The decreased risk of fracture attributed to estrogen plus progestin appeared to be present in all subgroups of women examined. When considering the effects of hormone therapy on other important disease outcomes in a global model, there was no net benefit, even in women considered to be at high risk of fracture.","Effects of estrogen plus progestin on risk of fracture and bone mineral density: the Women's Health Initiative randomized trial."
"330","JAMA.1040","NA",14519708,2003,"The effects of continuous combined hormone therapy on gynecologic cancers have not been investigated previously in a randomized trial setting.To determine the possible associations of estrogen plus progestin on gynecologic cancers and related diagnostic procedures.Randomized, double-blind, placebo-controlled trial of 16 608 postmenopausal women, who had not had a hysterectomy at baseline and who had been recruited from 40 US clinical centers between September 1993 and October 1998 (average follow-up, 5.6 years).One tablet per day containing 0.625 mg of conjugated equine estrogens plus 2.5 mg of medroxyprogesterone acetate (n = 8506) or placebo (n = 8102).Incident invasive cancer of the ovary and endometrium.In 5.6 years of follow-up, there were 32 cases of invasive ovarian cancer, 58 cases of endometrial cancer, 1 case of nonendometrial uterine cancer, 13 cases of cervical cancer, and 7 cases of other gynecologic cancers. The hazard ratio (HR) for invasive ovarian cancer in women assigned to estrogen plus progestin compared with placebo was 1.58 (95% confidence interval [CI], 0.77-3.24). The HR for endometrial cancer was 0.81 (95% CI, 0.48-1.36). No appreciable differences were found in the distributions of tumor histology, stage, or grade for either cancer site. The incidence of other gynecologic cancers was low and did not differ by randomization assignment. More women taking estrogen plus progestin required endometrial biopsies (33% vs 6%; P<.001).This randomized trial suggests that continuous combined estrogen plus progestin therapy may increase the risk of ovarian cancer while producing endometrial cancer rates similar to placebo. The increased burden of endometrial biopsies required to assess vaginal bleeding further limits the acceptability of this regimen. These data provide additional support for caution in the use of continuous combined hormones.","Effects of estrogen plus progestin on gynecologic cancers and associated diagnostic procedures: the Women's Health Initiative randomized trial."
"331","JAMA.1041","NA",14519708,2003,"The effects of continuous combined hormone therapy on gynecologic cancers have not been investigated previously in a randomized trial setting.To determine the possible associations of estrogen plus progestin on gynecologic cancers and related diagnostic procedures.Randomized, double-blind, placebo-controlled trial of 16 608 postmenopausal women, who had not had a hysterectomy at baseline and who had been recruited from 40 US clinical centers between September 1993 and October 1998 (average follow-up, 5.6 years).One tablet per day containing 0.625 mg of conjugated equine estrogens plus 2.5 mg of medroxyprogesterone acetate (n = 8506) or placebo (n = 8102).Incident invasive cancer of the ovary and endometrium.In 5.6 years of follow-up, there were 32 cases of invasive ovarian cancer, 58 cases of endometrial cancer, 1 case of nonendometrial uterine cancer, 13 cases of cervical cancer, and 7 cases of other gynecologic cancers. The hazard ratio (HR) for invasive ovarian cancer in women assigned to estrogen plus progestin compared with placebo was 1.58 (95% confidence interval [CI], 0.77-3.24). The HR for endometrial cancer was 0.81 (95% CI, 0.48-1.36). No appreciable differences were found in the distributions of tumor histology, stage, or grade for either cancer site. The incidence of other gynecologic cancers was low and did not differ by randomization assignment. More women taking estrogen plus progestin required endometrial biopsies (33% vs 6%; P<.001).This randomized trial suggests that continuous combined estrogen plus progestin therapy may increase the risk of ovarian cancer while producing endometrial cancer rates similar to placebo. The increased burden of endometrial biopsies required to assess vaginal bleeding further limits the acceptability of this regimen. These data provide additional support for caution in the use of continuous combined hormones.","Effects of estrogen plus progestin on gynecologic cancers and associated diagnostic procedures: the Women's Health Initiative randomized trial."
"332","JAMA.148","0.001",14559955,2003,"Exercise training for patients with Alzheimer disease combined with teaching caregivers how to manage behavioral problems may help decrease the frailty and behavioral impairment that are often prevalent in patients with Alzheimer disease.To determine whether a home-based exercise program combined with caregiver training in behavioral management techniques would reduce functional dependence and delay institutionalization among patients with Alzheimer disease.Randomized controlled trial of 153 community-dwelling patients meeting National Institute of Neurological and Communicative Diseases and Stroke/Alzheimer Disease and Related Disorders Association criteria for Alzheimer disease, conducted between June 1994 and April 1999.Patient-caregiver dyads were randomly assigned to the combined exercise and caregiver training program, Reducing Disability in Alzheimer Disease (RDAD), or to routine medical care (RMC). The RDAD program was conducted in the patients' home over 3 months.Physical health and function (36-item Short-Form Health Survey's [SF-36] physical functioning and physical role functioning subscales and Sickness Impact Profile's Mobility subscale), and affective status (Hamilton Depression Rating Scale and Cornell Depression Scale for Depression in Dementia).At 3 months, in comparison with the routine care patients, more patients in the RDAD group exercised at least 60 min/wk (odds ratio [OR], 2.82; 95% confidence interval [CI], 1.25-6.39; P =.01) and had fewer days of restricted activity (OR, 3.10; 95% CI, 1.08-8.95; P<.001). Patients in the RDAD group also had improved scores for physical role functioning compared with worse scores for patients in the RMC group (mean difference, 19.29; 95% CI, 8.75-29.83; P<.001). Patients in the RDAD group had improved Cornell Depression Scale for Depression in Dementia scores while the patients in the RMC group had worse scores (mean difference, -1.03; 95% CI, -0.17 to -1.91; P =.02). At 2 years, the RDAD patients continued to have better physical role functioning scores than the RMC patients (mean difference, 10.89; 95% CI, 3.62-18.16; P =.003) and showed a trend (19% vs 50%) for less institutionalization due to behavioral disturbance. For patients with higher depression scores at baseline, those in the RDAD group improved significantly more at 3 months on the Hamilton Depression Rating Scale (mean difference, 2.21; 95% CI, 0.22-4.20; P =.04) and maintained that improvement at 24 months (mean difference, 2.14; 95% CI, 0.14-4.17; P =.04).Exercise training combined with teaching caregivers behavioral management techniques improved physical health and depression in patients with Alzheimer disease.","Exercise plus behavioral management in patients with Alzheimer disease: a randomized controlled trial."
"333","JAMA.186","0.01",14559955,2003,"Exercise training for patients with Alzheimer disease combined with teaching caregivers how to manage behavioral problems may help decrease the frailty and behavioral impairment that are often prevalent in patients with Alzheimer disease.To determine whether a home-based exercise program combined with caregiver training in behavioral management techniques would reduce functional dependence and delay institutionalization among patients with Alzheimer disease.Randomized controlled trial of 153 community-dwelling patients meeting National Institute of Neurological and Communicative Diseases and Stroke/Alzheimer Disease and Related Disorders Association criteria for Alzheimer disease, conducted between June 1994 and April 1999.Patient-caregiver dyads were randomly assigned to the combined exercise and caregiver training program, Reducing Disability in Alzheimer Disease (RDAD), or to routine medical care (RMC). The RDAD program was conducted in the patients' home over 3 months.Physical health and function (36-item Short-Form Health Survey's [SF-36] physical functioning and physical role functioning subscales and Sickness Impact Profile's Mobility subscale), and affective status (Hamilton Depression Rating Scale and Cornell Depression Scale for Depression in Dementia).At 3 months, in comparison with the routine care patients, more patients in the RDAD group exercised at least 60 min/wk (odds ratio [OR], 2.82; 95% confidence interval [CI], 1.25-6.39; P =.01) and had fewer days of restricted activity (OR, 3.10; 95% CI, 1.08-8.95; P<.001). Patients in the RDAD group also had improved scores for physical role functioning compared with worse scores for patients in the RMC group (mean difference, 19.29; 95% CI, 8.75-29.83; P<.001). Patients in the RDAD group had improved Cornell Depression Scale for Depression in Dementia scores while the patients in the RMC group had worse scores (mean difference, -1.03; 95% CI, -0.17 to -1.91; P =.02). At 2 years, the RDAD patients continued to have better physical role functioning scores than the RMC patients (mean difference, 10.89; 95% CI, 3.62-18.16; P =.003) and showed a trend (19% vs 50%) for less institutionalization due to behavioral disturbance. For patients with higher depression scores at baseline, those in the RDAD group improved significantly more at 3 months on the Hamilton Depression Rating Scale (mean difference, 2.21; 95% CI, 0.22-4.20; P =.04) and maintained that improvement at 24 months (mean difference, 2.14; 95% CI, 0.14-4.17; P =.04).Exercise training combined with teaching caregivers behavioral management techniques improved physical health and depression in patients with Alzheimer disease.","Exercise plus behavioral management in patients with Alzheimer disease: a randomized controlled trial."
"334","JAMA.961","0.001",14570953,2003,"In acute myocardial infarction, the presence and severity of heart failure at the time of initial presentation have been formally categorized by the Killip classification. Although well studied in ST-elevation myocardial infarction, the prognostic importance of Killip classification in non-ST-elevation acute coronary syndromes is not well established.To determine the prognostic importance of physical examination for heart failure analyzed according to Killip classification in non-ST-elevation acute coronary syndromes and to understand its predictive value relative to other variables.From April 2001 to September 2003, We analyzed information from 26 090 patients with non-ST-elevation acute coronary syndromes enrolled in the GUSTO IIb, PURSUIT, PARAGON A, and PARAGON B trials. Demographic information was categorized by Killip class. Killip classes III and IV were combined into 1 category. Multivariate Cox proportional hazard models were developed to determine the prognostic importance of Killip classification in comparison with other variables.Association between Killip classification and all-cause mortality at 30 days and 6 months.Patients in Killip class II (n = 2513) and III/IV (n = 390) were older than those in Killip class I (n = 23 187), with higher rates of diabetes, prior myocardial infarction, ST depression, and elevated cardiac enzymes (all P<.001). Higher Killip class was associated with higher mortality at 30 days (2.8% in Killip class I vs 8.8% in class II vs 14.4% in class III/IV; P<.001) and 6 months (5.0% vs 14.7% vs 23.0%, respectively; P<.001). Patients with Killip class II, III, or IV constituted 11% of the overall population but accounted for approximately 30% of the deaths at both time points. In multivariate analysis, Killip class III/IV was the most powerful predictor of mortality at 30 days (hazard ratio [HR], 2.35; 95% confidence interval [CI], 1.69-3.26; P<.001) and 6 months (HR, 2.12; 95% CI, 1.63-2.75; P<.001). Killip class II was predictive of mortality at 30 days (HR, 1.73; 95% CI, 1.44-2.09; P<.001) and 6 months (HR, 1.52; 95% CI, 1.31-1.76; P<.001). Five factors-age, Killip classification, heart rate, systolic blood pressure, and ST depression-provided more than 70% of the prognostic information for 30-day and 6-month mortality.Killip classification is a powerful independent predictor of all-cause mortality in patients with non-ST-elevation acute coronary syndromes. Age, Killip classification, heart rate, systolic blood pressure, and ST depression should receive particular attention in the initial assessment of these patients.","Prognostic importance of physical examination for heart failure in non-ST-elevation acute coronary syndromes: the enduring value of Killip classification."
"335","JAMA.971","0.001",14570953,2003,"In acute myocardial infarction, the presence and severity of heart failure at the time of initial presentation have been formally categorized by the Killip classification. Although well studied in ST-elevation myocardial infarction, the prognostic importance of Killip classification in non-ST-elevation acute coronary syndromes is not well established.To determine the prognostic importance of physical examination for heart failure analyzed according to Killip classification in non-ST-elevation acute coronary syndromes and to understand its predictive value relative to other variables.From April 2001 to September 2003, We analyzed information from 26 090 patients with non-ST-elevation acute coronary syndromes enrolled in the GUSTO IIb, PURSUIT, PARAGON A, and PARAGON B trials. Demographic information was categorized by Killip class. Killip classes III and IV were combined into 1 category. Multivariate Cox proportional hazard models were developed to determine the prognostic importance of Killip classification in comparison with other variables.Association between Killip classification and all-cause mortality at 30 days and 6 months.Patients in Killip class II (n = 2513) and III/IV (n = 390) were older than those in Killip class I (n = 23 187), with higher rates of diabetes, prior myocardial infarction, ST depression, and elevated cardiac enzymes (all P<.001). Higher Killip class was associated with higher mortality at 30 days (2.8% in Killip class I vs 8.8% in class II vs 14.4% in class III/IV; P<.001) and 6 months (5.0% vs 14.7% vs 23.0%, respectively; P<.001). Patients with Killip class II, III, or IV constituted 11% of the overall population but accounted for approximately 30% of the deaths at both time points. In multivariate analysis, Killip class III/IV was the most powerful predictor of mortality at 30 days (hazard ratio [HR], 2.35; 95% confidence interval [CI], 1.69-3.26; P<.001) and 6 months (HR, 2.12; 95% CI, 1.63-2.75; P<.001). Killip class II was predictive of mortality at 30 days (HR, 1.73; 95% CI, 1.44-2.09; P<.001) and 6 months (HR, 1.52; 95% CI, 1.31-1.76; P<.001). Five factors-age, Killip classification, heart rate, systolic blood pressure, and ST depression-provided more than 70% of the prognostic information for 30-day and 6-month mortality.Killip classification is a powerful independent predictor of all-cause mortality in patients with non-ST-elevation acute coronary syndromes. Age, Killip classification, heart rate, systolic blood pressure, and ST depression should receive particular attention in the initial assessment of these patients.","Prognostic importance of physical examination for heart failure in non-ST-elevation acute coronary syndromes: the enduring value of Killip classification."
"336","JAMA.981","0.001",14570953,2003,"In acute myocardial infarction, the presence and severity of heart failure at the time of initial presentation have been formally categorized by the Killip classification. Although well studied in ST-elevation myocardial infarction, the prognostic importance of Killip classification in non-ST-elevation acute coronary syndromes is not well established.To determine the prognostic importance of physical examination for heart failure analyzed according to Killip classification in non-ST-elevation acute coronary syndromes and to understand its predictive value relative to other variables.From April 2001 to September 2003, We analyzed information from 26 090 patients with non-ST-elevation acute coronary syndromes enrolled in the GUSTO IIb, PURSUIT, PARAGON A, and PARAGON B trials. Demographic information was categorized by Killip class. Killip classes III and IV were combined into 1 category. Multivariate Cox proportional hazard models were developed to determine the prognostic importance of Killip classification in comparison with other variables.Association between Killip classification and all-cause mortality at 30 days and 6 months.Patients in Killip class II (n = 2513) and III/IV (n = 390) were older than those in Killip class I (n = 23 187), with higher rates of diabetes, prior myocardial infarction, ST depression, and elevated cardiac enzymes (all P<.001). Higher Killip class was associated with higher mortality at 30 days (2.8% in Killip class I vs 8.8% in class II vs 14.4% in class III/IV; P<.001) and 6 months (5.0% vs 14.7% vs 23.0%, respectively; P<.001). Patients with Killip class II, III, or IV constituted 11% of the overall population but accounted for approximately 30% of the deaths at both time points. In multivariate analysis, Killip class III/IV was the most powerful predictor of mortality at 30 days (hazard ratio [HR], 2.35; 95% confidence interval [CI], 1.69-3.26; P<.001) and 6 months (HR, 2.12; 95% CI, 1.63-2.75; P<.001). Killip class II was predictive of mortality at 30 days (HR, 1.73; 95% CI, 1.44-2.09; P<.001) and 6 months (HR, 1.52; 95% CI, 1.31-1.76; P<.001). Five factors-age, Killip classification, heart rate, systolic blood pressure, and ST depression-provided more than 70% of the prognostic information for 30-day and 6-month mortality.Killip classification is a powerful independent predictor of all-cause mortality in patients with non-ST-elevation acute coronary syndromes. Age, Killip classification, heart rate, systolic blood pressure, and ST depression should receive particular attention in the initial assessment of these patients.","Prognostic importance of physical examination for heart failure in non-ST-elevation acute coronary syndromes: the enduring value of Killip classification."
"337","JAMA.991","0.001",14570953,2003,"In acute myocardial infarction, the presence and severity of heart failure at the time of initial presentation have been formally categorized by the Killip classification. Although well studied in ST-elevation myocardial infarction, the prognostic importance of Killip classification in non-ST-elevation acute coronary syndromes is not well established.To determine the prognostic importance of physical examination for heart failure analyzed according to Killip classification in non-ST-elevation acute coronary syndromes and to understand its predictive value relative to other variables.From April 2001 to September 2003, We analyzed information from 26 090 patients with non-ST-elevation acute coronary syndromes enrolled in the GUSTO IIb, PURSUIT, PARAGON A, and PARAGON B trials. Demographic information was categorized by Killip class. Killip classes III and IV were combined into 1 category. Multivariate Cox proportional hazard models were developed to determine the prognostic importance of Killip classification in comparison with other variables.Association between Killip classification and all-cause mortality at 30 days and 6 months.Patients in Killip class II (n = 2513) and III/IV (n = 390) were older than those in Killip class I (n = 23 187), with higher rates of diabetes, prior myocardial infarction, ST depression, and elevated cardiac enzymes (all P<.001). Higher Killip class was associated with higher mortality at 30 days (2.8% in Killip class I vs 8.8% in class II vs 14.4% in class III/IV; P<.001) and 6 months (5.0% vs 14.7% vs 23.0%, respectively; P<.001). Patients with Killip class II, III, or IV constituted 11% of the overall population but accounted for approximately 30% of the deaths at both time points. In multivariate analysis, Killip class III/IV was the most powerful predictor of mortality at 30 days (hazard ratio [HR], 2.35; 95% confidence interval [CI], 1.69-3.26; P<.001) and 6 months (HR, 2.12; 95% CI, 1.63-2.75; P<.001). Killip class II was predictive of mortality at 30 days (HR, 1.73; 95% CI, 1.44-2.09; P<.001) and 6 months (HR, 1.52; 95% CI, 1.31-1.76; P<.001). Five factors-age, Killip classification, heart rate, systolic blood pressure, and ST depression-provided more than 70% of the prognostic information for 30-day and 6-month mortality.Killip classification is a powerful independent predictor of all-cause mortality in patients with non-ST-elevation acute coronary syndromes. Age, Killip classification, heart rate, systolic blood pressure, and ST depression should receive particular attention in the initial assessment of these patients.","Prognostic importance of physical examination for heart failure in non-ST-elevation acute coronary syndromes: the enduring value of Killip classification."
"338","Lancet.1110","0.06",14575971,2003,"Highly active antiretroviral therapy (HAART) was introduced in 1997. We aimed to assess the continuing effect of this treatment on survival and progression to AIDS after HIV-1 seroconversion.We used Cox models to estimate the effect of calendar year on time to AIDS and death in 22 cohorts of people from Europe, Australia, and Canada who had seroconverted. Retrospective and prospective data were used. We compared the effects of age at seroconversion, exposure category, sex, and presentation during acute HIV-1 infection pre-1997 (pre-HAART), in 1997-98 (limited use of HAART), and 1999-2001 (widespread use of HAART).Of 7740 seroconverters, 2000 (26%) had died. Compared with pre-1997 data, the hazard ratio (HR) for death fell sharply to 0.47 [95% CI 0.39-0.56] in 1997, dropping further to 0.16 [0.12-0.22] in 2001. Correspondingly, the proportion of person-time on HAART increased from 22% in 1997 to 57% in 2001. By contrast with the pre-HAART era, injecting drug users had significantly higher mortality in 1999-2001 than did men infected through sex with men (HR 4.28 [2.86-6.41]). However, whereas pre-1997 the risk of AIDS was higher in those aged 45 years or older at seroconversion than in people who were 16-24 years (2.03 [1.67-2.47]), in 1999-2001 there was little evidence of a difference in risk by age (HR=1.17 [0.60-2.30]; interaction p=0.06). No such attenuation in the effect of age on survival was observed (p=0.63).Predicted survival for people with HIV-1 has continued to increase, since the introduction of HAART; however, the importance of age and exposure category as determinants of progression seems to have changed.","Determinants of survival following HIV-1 seroconversion after the introduction of HAART."
"339","Lancet.1207","NA",14575971,2003,"Highly active antiretroviral therapy (HAART) was introduced in 1997. We aimed to assess the continuing effect of this treatment on survival and progression to AIDS after HIV-1 seroconversion.We used Cox models to estimate the effect of calendar year on time to AIDS and death in 22 cohorts of people from Europe, Australia, and Canada who had seroconverted. Retrospective and prospective data were used. We compared the effects of age at seroconversion, exposure category, sex, and presentation during acute HIV-1 infection pre-1997 (pre-HAART), in 1997-98 (limited use of HAART), and 1999-2001 (widespread use of HAART).Of 7740 seroconverters, 2000 (26%) had died. Compared with pre-1997 data, the hazard ratio (HR) for death fell sharply to 0.47 [95% CI 0.39-0.56] in 1997, dropping further to 0.16 [0.12-0.22] in 2001. Correspondingly, the proportion of person-time on HAART increased from 22% in 1997 to 57% in 2001. By contrast with the pre-HAART era, injecting drug users had significantly higher mortality in 1999-2001 than did men infected through sex with men (HR 4.28 [2.86-6.41]). However, whereas pre-1997 the risk of AIDS was higher in those aged 45 years or older at seroconversion than in people who were 16-24 years (2.03 [1.67-2.47]), in 1999-2001 there was little evidence of a difference in risk by age (HR=1.17 [0.60-2.30]; interaction p=0.06). No such attenuation in the effect of age on survival was observed (p=0.63).Predicted survival for people with HIV-1 has continued to increase, since the introduction of HAART; however, the importance of age and exposure category as determinants of progression seems to have changed.","Determinants of survival following HIV-1 seroconversion after the introduction of HAART."
"340","Lancet.1208","NA",14575971,2003,"Highly active antiretroviral therapy (HAART) was introduced in 1997. We aimed to assess the continuing effect of this treatment on survival and progression to AIDS after HIV-1 seroconversion.We used Cox models to estimate the effect of calendar year on time to AIDS and death in 22 cohorts of people from Europe, Australia, and Canada who had seroconverted. Retrospective and prospective data were used. We compared the effects of age at seroconversion, exposure category, sex, and presentation during acute HIV-1 infection pre-1997 (pre-HAART), in 1997-98 (limited use of HAART), and 1999-2001 (widespread use of HAART).Of 7740 seroconverters, 2000 (26%) had died. Compared with pre-1997 data, the hazard ratio (HR) for death fell sharply to 0.47 [95% CI 0.39-0.56] in 1997, dropping further to 0.16 [0.12-0.22] in 2001. Correspondingly, the proportion of person-time on HAART increased from 22% in 1997 to 57% in 2001. By contrast with the pre-HAART era, injecting drug users had significantly higher mortality in 1999-2001 than did men infected through sex with men (HR 4.28 [2.86-6.41]). However, whereas pre-1997 the risk of AIDS was higher in those aged 45 years or older at seroconversion than in people who were 16-24 years (2.03 [1.67-2.47]), in 1999-2001 there was little evidence of a difference in risk by age (HR=1.17 [0.60-2.30]; interaction p=0.06). No such attenuation in the effect of age on survival was observed (p=0.63).Predicted survival for people with HIV-1 has continued to increase, since the introduction of HAART; however, the importance of age and exposure category as determinants of progression seems to have changed.","Determinants of survival following HIV-1 seroconversion after the introduction of HAART."
"341","Lancet.1209","NA",14575971,2003,"Highly active antiretroviral therapy (HAART) was introduced in 1997. We aimed to assess the continuing effect of this treatment on survival and progression to AIDS after HIV-1 seroconversion.We used Cox models to estimate the effect of calendar year on time to AIDS and death in 22 cohorts of people from Europe, Australia, and Canada who had seroconverted. Retrospective and prospective data were used. We compared the effects of age at seroconversion, exposure category, sex, and presentation during acute HIV-1 infection pre-1997 (pre-HAART), in 1997-98 (limited use of HAART), and 1999-2001 (widespread use of HAART).Of 7740 seroconverters, 2000 (26%) had died. Compared with pre-1997 data, the hazard ratio (HR) for death fell sharply to 0.47 [95% CI 0.39-0.56] in 1997, dropping further to 0.16 [0.12-0.22] in 2001. Correspondingly, the proportion of person-time on HAART increased from 22% in 1997 to 57% in 2001. By contrast with the pre-HAART era, injecting drug users had significantly higher mortality in 1999-2001 than did men infected through sex with men (HR 4.28 [2.86-6.41]). However, whereas pre-1997 the risk of AIDS was higher in those aged 45 years or older at seroconversion than in people who were 16-24 years (2.03 [1.67-2.47]), in 1999-2001 there was little evidence of a difference in risk by age (HR=1.17 [0.60-2.30]; interaction p=0.06). No such attenuation in the effect of age on survival was observed (p=0.63).Predicted survival for people with HIV-1 has continued to increase, since the introduction of HAART; however, the importance of age and exposure category as determinants of progression seems to have changed.","Determinants of survival following HIV-1 seroconversion after the introduction of HAART."
"342","Lancet.1210","NA",14575971,2003,"Highly active antiretroviral therapy (HAART) was introduced in 1997. We aimed to assess the continuing effect of this treatment on survival and progression to AIDS after HIV-1 seroconversion.We used Cox models to estimate the effect of calendar year on time to AIDS and death in 22 cohorts of people from Europe, Australia, and Canada who had seroconverted. Retrospective and prospective data were used. We compared the effects of age at seroconversion, exposure category, sex, and presentation during acute HIV-1 infection pre-1997 (pre-HAART), in 1997-98 (limited use of HAART), and 1999-2001 (widespread use of HAART).Of 7740 seroconverters, 2000 (26%) had died. Compared with pre-1997 data, the hazard ratio (HR) for death fell sharply to 0.47 [95% CI 0.39-0.56] in 1997, dropping further to 0.16 [0.12-0.22] in 2001. Correspondingly, the proportion of person-time on HAART increased from 22% in 1997 to 57% in 2001. By contrast with the pre-HAART era, injecting drug users had significantly higher mortality in 1999-2001 than did men infected through sex with men (HR 4.28 [2.86-6.41]). However, whereas pre-1997 the risk of AIDS was higher in those aged 45 years or older at seroconversion than in people who were 16-24 years (2.03 [1.67-2.47]), in 1999-2001 there was little evidence of a difference in risk by age (HR=1.17 [0.60-2.30]; interaction p=0.06). No such attenuation in the effect of age on survival was observed (p=0.63).Predicted survival for people with HIV-1 has continued to increase, since the introduction of HAART; however, the importance of age and exposure category as determinants of progression seems to have changed.","Determinants of survival following HIV-1 seroconversion after the introduction of HAART."
"343","JAMA.142","0.001",14625335,2003,"A predictive model of mortality in heart failure may be useful for clinicians to improve communication with and care of hospitalized patients.To identify predictors of mortality and to develop and to validate a model using information available at hospital presentation.Retrospective study of 4031 community-based patients presenting with heart failure at multiple hospitals in Ontario, Canada (2624 patients in the derivation cohort from 1999-2001 and 1407 patients in the validation cohort from 1997-1999), who had been identified as part of the Enhanced Feedback for Effective Cardiac Treatment (EFFECT) study.All-cause 30-day and 1-year mortality.The mortality rates for the derivation cohort and validation cohort, respectively, were 8.9% and 8.2% in hospital, 10.7% and 10.4% at 30 days, and 32.9% and 30.5% at 1 year. Multivariable predictors of mortality at both 30 days and 1 year included older age, lower systolic blood pressure, higher respiratory rate, higher urea nitrogen level (all P<.001), and hyponatremia (P<.01). Comorbid conditions associated with mortality included cerebrovascular disease (30-day mortality odds ratio [OR], 1.43; 95% confidence interval [CI], 1.03-1.98; P =.03), chronic obstructive pulmonary disease (OR, 1.66; 95% CI, 1.22-2.27; P =.002), hepatic cirrhosis (OR, 3.22; 95% CI, 1.08-9.65; P =.04), dementia (OR, 2.54; 95% CI, 1.77-3.65; P<.001), and cancer (OR, 1.86; 95% CI, 1.28-2.70; P =.001). A risk index stratified the risk of death and identified low- and high-risk individuals. Patients with very low-risk scores (< or =60) had a mortality rate of 0.4% at 30 days and 7.8% at 1 year. Patients with very high-risk scores (>150) had a mortality rate of 59.0% at 30 days and 78.8% at 1 year. Patients with higher 1-year risk scores had reduced survival at all times up to 1 year (log-rank, P<.001). For the derivation cohort, the area under the receiver operating characteristic curve for the model was 0.80 for 30-day mortality and 0.77 for 1-year mortality. Predicted mortality rates in the validation cohort closely matched observed rates across the entire spectrum of risk.Among community-based heart failure patients, factors identifiable within hours of hospital presentation predicted mortality risk at 30 days and 1 year. The externally validated predictive index may assist clinicians in estimating heart failure mortality risk and in providing quantitative guidance for decision making in heart failure care.","Predicting mortality among patients hospitalized for heart failure: derivation and validation of a clinical model."
"344","JAMA.144","0.001",14625335,2003,"A predictive model of mortality in heart failure may be useful for clinicians to improve communication with and care of hospitalized patients.To identify predictors of mortality and to develop and to validate a model using information available at hospital presentation.Retrospective study of 4031 community-based patients presenting with heart failure at multiple hospitals in Ontario, Canada (2624 patients in the derivation cohort from 1999-2001 and 1407 patients in the validation cohort from 1997-1999), who had been identified as part of the Enhanced Feedback for Effective Cardiac Treatment (EFFECT) study.All-cause 30-day and 1-year mortality.The mortality rates for the derivation cohort and validation cohort, respectively, were 8.9% and 8.2% in hospital, 10.7% and 10.4% at 30 days, and 32.9% and 30.5% at 1 year. Multivariable predictors of mortality at both 30 days and 1 year included older age, lower systolic blood pressure, higher respiratory rate, higher urea nitrogen level (all P<.001), and hyponatremia (P<.01). Comorbid conditions associated with mortality included cerebrovascular disease (30-day mortality odds ratio [OR], 1.43; 95% confidence interval [CI], 1.03-1.98; P =.03), chronic obstructive pulmonary disease (OR, 1.66; 95% CI, 1.22-2.27; P =.002), hepatic cirrhosis (OR, 3.22; 95% CI, 1.08-9.65; P =.04), dementia (OR, 2.54; 95% CI, 1.77-3.65; P<.001), and cancer (OR, 1.86; 95% CI, 1.28-2.70; P =.001). A risk index stratified the risk of death and identified low- and high-risk individuals. Patients with very low-risk scores (< or =60) had a mortality rate of 0.4% at 30 days and 7.8% at 1 year. Patients with very high-risk scores (>150) had a mortality rate of 59.0% at 30 days and 78.8% at 1 year. Patients with higher 1-year risk scores had reduced survival at all times up to 1 year (log-rank, P<.001). For the derivation cohort, the area under the receiver operating characteristic curve for the model was 0.80 for 30-day mortality and 0.77 for 1-year mortality. Predicted mortality rates in the validation cohort closely matched observed rates across the entire spectrum of risk.Among community-based heart failure patients, factors identifiable within hours of hospital presentation predicted mortality risk at 30 days and 1 year. The externally validated predictive index may assist clinicians in estimating heart failure mortality risk and in providing quantitative guidance for decision making in heart failure care.","Predicting mortality among patients hospitalized for heart failure: derivation and validation of a clinical model."
"345","JAMA.182","0.03",14625335,2003,"A predictive model of mortality in heart failure may be useful for clinicians to improve communication with and care of hospitalized patients.To identify predictors of mortality and to develop and to validate a model using information available at hospital presentation.Retrospective study of 4031 community-based patients presenting with heart failure at multiple hospitals in Ontario, Canada (2624 patients in the derivation cohort from 1999-2001 and 1407 patients in the validation cohort from 1997-1999), who had been identified as part of the Enhanced Feedback for Effective Cardiac Treatment (EFFECT) study.All-cause 30-day and 1-year mortality.The mortality rates for the derivation cohort and validation cohort, respectively, were 8.9% and 8.2% in hospital, 10.7% and 10.4% at 30 days, and 32.9% and 30.5% at 1 year. Multivariable predictors of mortality at both 30 days and 1 year included older age, lower systolic blood pressure, higher respiratory rate, higher urea nitrogen level (all P<.001), and hyponatremia (P<.01). Comorbid conditions associated with mortality included cerebrovascular disease (30-day mortality odds ratio [OR], 1.43; 95% confidence interval [CI], 1.03-1.98; P =.03), chronic obstructive pulmonary disease (OR, 1.66; 95% CI, 1.22-2.27; P =.002), hepatic cirrhosis (OR, 3.22; 95% CI, 1.08-9.65; P =.04), dementia (OR, 2.54; 95% CI, 1.77-3.65; P<.001), and cancer (OR, 1.86; 95% CI, 1.28-2.70; P =.001). A risk index stratified the risk of death and identified low- and high-risk individuals. Patients with very low-risk scores (< or =60) had a mortality rate of 0.4% at 30 days and 7.8% at 1 year. Patients with very high-risk scores (>150) had a mortality rate of 59.0% at 30 days and 78.8% at 1 year. Patients with higher 1-year risk scores had reduced survival at all times up to 1 year (log-rank, P<.001). For the derivation cohort, the area under the receiver operating characteristic curve for the model was 0.80 for 30-day mortality and 0.77 for 1-year mortality. Predicted mortality rates in the validation cohort closely matched observed rates across the entire spectrum of risk.Among community-based heart failure patients, factors identifiable within hours of hospital presentation predicted mortality risk at 30 days and 1 year. The externally validated predictive index may assist clinicians in estimating heart failure mortality risk and in providing quantitative guidance for decision making in heart failure care.","Predicting mortality among patients hospitalized for heart failure: derivation and validation of a clinical model."
"346","JAMA.183","0.002",14625335,2003,"A predictive model of mortality in heart failure may be useful for clinicians to improve communication with and care of hospitalized patients.To identify predictors of mortality and to develop and to validate a model using information available at hospital presentation.Retrospective study of 4031 community-based patients presenting with heart failure at multiple hospitals in Ontario, Canada (2624 patients in the derivation cohort from 1999-2001 and 1407 patients in the validation cohort from 1997-1999), who had been identified as part of the Enhanced Feedback for Effective Cardiac Treatment (EFFECT) study.All-cause 30-day and 1-year mortality.The mortality rates for the derivation cohort and validation cohort, respectively, were 8.9% and 8.2% in hospital, 10.7% and 10.4% at 30 days, and 32.9% and 30.5% at 1 year. Multivariable predictors of mortality at both 30 days and 1 year included older age, lower systolic blood pressure, higher respiratory rate, higher urea nitrogen level (all P<.001), and hyponatremia (P<.01). Comorbid conditions associated with mortality included cerebrovascular disease (30-day mortality odds ratio [OR], 1.43; 95% confidence interval [CI], 1.03-1.98; P =.03), chronic obstructive pulmonary disease (OR, 1.66; 95% CI, 1.22-2.27; P =.002), hepatic cirrhosis (OR, 3.22; 95% CI, 1.08-9.65; P =.04), dementia (OR, 2.54; 95% CI, 1.77-3.65; P<.001), and cancer (OR, 1.86; 95% CI, 1.28-2.70; P =.001). A risk index stratified the risk of death and identified low- and high-risk individuals. Patients with very low-risk scores (< or =60) had a mortality rate of 0.4% at 30 days and 7.8% at 1 year. Patients with very high-risk scores (>150) had a mortality rate of 59.0% at 30 days and 78.8% at 1 year. Patients with higher 1-year risk scores had reduced survival at all times up to 1 year (log-rank, P<.001). For the derivation cohort, the area under the receiver operating characteristic curve for the model was 0.80 for 30-day mortality and 0.77 for 1-year mortality. Predicted mortality rates in the validation cohort closely matched observed rates across the entire spectrum of risk.Among community-based heart failure patients, factors identifiable within hours of hospital presentation predicted mortality risk at 30 days and 1 year. The externally validated predictive index may assist clinicians in estimating heart failure mortality risk and in providing quantitative guidance for decision making in heart failure care.","Predicting mortality among patients hospitalized for heart failure: derivation and validation of a clinical model."
"347","JAMA.184","0.04",14625335,2003,"A predictive model of mortality in heart failure may be useful for clinicians to improve communication with and care of hospitalized patients.To identify predictors of mortality and to develop and to validate a model using information available at hospital presentation.Retrospective study of 4031 community-based patients presenting with heart failure at multiple hospitals in Ontario, Canada (2624 patients in the derivation cohort from 1999-2001 and 1407 patients in the validation cohort from 1997-1999), who had been identified as part of the Enhanced Feedback for Effective Cardiac Treatment (EFFECT) study.All-cause 30-day and 1-year mortality.The mortality rates for the derivation cohort and validation cohort, respectively, were 8.9% and 8.2% in hospital, 10.7% and 10.4% at 30 days, and 32.9% and 30.5% at 1 year. Multivariable predictors of mortality at both 30 days and 1 year included older age, lower systolic blood pressure, higher respiratory rate, higher urea nitrogen level (all P<.001), and hyponatremia (P<.01). Comorbid conditions associated with mortality included cerebrovascular disease (30-day mortality odds ratio [OR], 1.43; 95% confidence interval [CI], 1.03-1.98; P =.03), chronic obstructive pulmonary disease (OR, 1.66; 95% CI, 1.22-2.27; P =.002), hepatic cirrhosis (OR, 3.22; 95% CI, 1.08-9.65; P =.04), dementia (OR, 2.54; 95% CI, 1.77-3.65; P<.001), and cancer (OR, 1.86; 95% CI, 1.28-2.70; P =.001). A risk index stratified the risk of death and identified low- and high-risk individuals. Patients with very low-risk scores (< or =60) had a mortality rate of 0.4% at 30 days and 7.8% at 1 year. Patients with very high-risk scores (>150) had a mortality rate of 59.0% at 30 days and 78.8% at 1 year. Patients with higher 1-year risk scores had reduced survival at all times up to 1 year (log-rank, P<.001). For the derivation cohort, the area under the receiver operating characteristic curve for the model was 0.80 for 30-day mortality and 0.77 for 1-year mortality. Predicted mortality rates in the validation cohort closely matched observed rates across the entire spectrum of risk.Among community-based heart failure patients, factors identifiable within hours of hospital presentation predicted mortality risk at 30 days and 1 year. The externally validated predictive index may assist clinicians in estimating heart failure mortality risk and in providing quantitative guidance for decision making in heart failure care.","Predicting mortality among patients hospitalized for heart failure: derivation and validation of a clinical model."
"348","JAMA.181","0.001",14645309,2003,"Half of all cases of cerebral palsy (CP) occur in term infants, for whom risk factors have not been clearly defined. Recent studies suggest a possible role of chorioamnionitis.To determine whether clinical chorioamnionitis increases the risk of CP in term and near-term infants.Case-control study nested within a cohort of 231 582 singleton infants born at 36 or more weeks' gestation between January 1, 1991, and December 31, 1998, in the Kaiser Permanente Medical Care Program, a managed care organization providing care for more than 3 million residents of northern California. Case patients were identified from electronic records and confirmed by chart review by a child neurologist, and comprised all children with moderate to severe spastic or dyskinetic CP not due to postnatal brain injury or developmental abnormalities (n = 109). Controls (n = 218) were randomly selected from the study population.Association between clinical chorioamnionitis and increased risk of CP in term and near-term infants.Most CP cases had hemiparesis (40%) or quadriparesis (38%); 87% had been diagnosed by a neurologist and 83% had undergone neuroimaging. Chorioamnionitis, considered present if a treating physician made a diagnosis of chorioamnionitis or endometritis clinically, was noted in 14% of cases and 4% of controls (odds ratio [OR], 3.8; 95% confidence interval [CI], 1.5-10.1; P =.001). Independent risk factors identified in multiple logistic regression included chorioamnionitis (OR, 4.1; 95% CI, 1.6-10.1), intrauterine growth restriction (OR, 4.0; 95% CI, 1.3-12.0), maternal black ethnicity (OR, 3.6; 95% CI, 1.4-9.3), maternal age older than 25 years (OR, 2.6; 95% CI, 1.3-5.2), and nulliparity (OR, 1.8; 95% CI, 1.0-3.0). The population-attributable fraction of chorioamnionitis for CP is 11%.Our data suggest that chorioamnionitis is an independent risk factor for CP among term and near-term infants.","Chorioamnionitis and cerebral palsy in term and near-term infants."
"349","American Journal of Epidemiology.33","0.05",14652299,2003,"Gestational diabetes and pregnancy-induced hypertension are common, and their relation is not well understood. The authors conducted a population-based case-control study using 1992-1998 Washington State birth certificate and hospital discharge records to investigate this relation. Consecutive cases of pregnancy-induced hypertension were divided into four groups based on International Classification of Diseases, Ninth Revision codes: eclampsia (n=154), severe preeclampsia (n=1,180), mild preeclampsia (n=5,468), and gestational hypertension (n=8,943). Cases were compared with controls who did not have pregnancy-induced hypertension (n=47,237). Gestational diabetes was more common in each case group (3.9% in eclamptics, 4.5% in severe preeclamptics, and 4.4% in both mild preeclamptics and those with gestational hypertension) than in controls (2.7%). After adjustment for body mass index, age, ethnicity, parity, and prenatal care, gestational diabetes was associated with increased risk of severe preeclampsia (odds ratio (OR)=1.5, 95% confidence interval (CI): 1.1, 2.1), mild preeclampsia (OR=1.5, 95% CI: 1.3, 1.8), and gestational hypertension (OR=1.4, 95% CI: 1.2, 1.6). Gestational diabetes was more strongly associated with pregnancy-induced hypertension among women who received less prenatal care (OR=4.2 for eclampsia and OR=3.1 for severe preeclampsia, p<0.05 for both) and among Black women (OR for eclampsia and preeclampsia together=3.9, p<0.05).","Association between gestational diabetes and pregnancy-induced hypertension."
"350","American Journal of Epidemiology.34","0.05",14652299,2003,"Gestational diabetes and pregnancy-induced hypertension are common, and their relation is not well understood. The authors conducted a population-based case-control study using 1992-1998 Washington State birth certificate and hospital discharge records to investigate this relation. Consecutive cases of pregnancy-induced hypertension were divided into four groups based on International Classification of Diseases, Ninth Revision codes: eclampsia (n=154), severe preeclampsia (n=1,180), mild preeclampsia (n=5,468), and gestational hypertension (n=8,943). Cases were compared with controls who did not have pregnancy-induced hypertension (n=47,237). Gestational diabetes was more common in each case group (3.9% in eclamptics, 4.5% in severe preeclamptics, and 4.4% in both mild preeclamptics and those with gestational hypertension) than in controls (2.7%). After adjustment for body mass index, age, ethnicity, parity, and prenatal care, gestational diabetes was associated with increased risk of severe preeclampsia (odds ratio (OR)=1.5, 95% confidence interval (CI): 1.1, 2.1), mild preeclampsia (OR=1.5, 95% CI: 1.3, 1.8), and gestational hypertension (OR=1.4, 95% CI: 1.2, 1.6). Gestational diabetes was more strongly associated with pregnancy-induced hypertension among women who received less prenatal care (OR=4.2 for eclampsia and OR=3.1 for severe preeclampsia, p<0.05 for both) and among Black women (OR for eclampsia and preeclampsia together=3.9, p<0.05).","Association between gestational diabetes and pregnancy-induced hypertension."
"351","American Journal of Epidemiology.34","NA",14652299,2003,"Gestational diabetes and pregnancy-induced hypertension are common, and their relation is not well understood. The authors conducted a population-based case-control study using 1992-1998 Washington State birth certificate and hospital discharge records to investigate this relation. Consecutive cases of pregnancy-induced hypertension were divided into four groups based on International Classification of Diseases, Ninth Revision codes: eclampsia (n=154), severe preeclampsia (n=1,180), mild preeclampsia (n=5,468), and gestational hypertension (n=8,943). Cases were compared with controls who did not have pregnancy-induced hypertension (n=47,237). Gestational diabetes was more common in each case group (3.9% in eclamptics, 4.5% in severe preeclamptics, and 4.4% in both mild preeclamptics and those with gestational hypertension) than in controls (2.7%). After adjustment for body mass index, age, ethnicity, parity, and prenatal care, gestational diabetes was associated with increased risk of severe preeclampsia (odds ratio (OR)=1.5, 95% confidence interval (CI): 1.1, 2.1), mild preeclampsia (OR=1.5, 95% CI: 1.3, 1.8), and gestational hypertension (OR=1.4, 95% CI: 1.2, 1.6). Gestational diabetes was more strongly associated with pregnancy-induced hypertension among women who received less prenatal care (OR=4.2 for eclampsia and OR=3.1 for severe preeclampsia, p<0.05 for both) and among Black women (OR for eclampsia and preeclampsia together=3.9, p<0.05).","Association between gestational diabetes and pregnancy-induced hypertension."
"352","American Journal of Epidemiology.34","NA",14652299,2003,"Gestational diabetes and pregnancy-induced hypertension are common, and their relation is not well understood. The authors conducted a population-based case-control study using 1992-1998 Washington State birth certificate and hospital discharge records to investigate this relation. Consecutive cases of pregnancy-induced hypertension were divided into four groups based on International Classification of Diseases, Ninth Revision codes: eclampsia (n=154), severe preeclampsia (n=1,180), mild preeclampsia (n=5,468), and gestational hypertension (n=8,943). Cases were compared with controls who did not have pregnancy-induced hypertension (n=47,237). Gestational diabetes was more common in each case group (3.9% in eclamptics, 4.5% in severe preeclamptics, and 4.4% in both mild preeclamptics and those with gestational hypertension) than in controls (2.7%). After adjustment for body mass index, age, ethnicity, parity, and prenatal care, gestational diabetes was associated with increased risk of severe preeclampsia (odds ratio (OR)=1.5, 95% confidence interval (CI): 1.1, 2.1), mild preeclampsia (OR=1.5, 95% CI: 1.3, 1.8), and gestational hypertension (OR=1.4, 95% CI: 1.2, 1.6). Gestational diabetes was more strongly associated with pregnancy-induced hypertension among women who received less prenatal care (OR=4.2 for eclampsia and OR=3.1 for severe preeclampsia, p<0.05 for both) and among Black women (OR for eclampsia and preeclampsia together=3.9, p<0.05).","Association between gestational diabetes and pregnancy-induced hypertension."
"353","American Journal of Epidemiology.34","NA",14652299,2003,"Gestational diabetes and pregnancy-induced hypertension are common, and their relation is not well understood. The authors conducted a population-based case-control study using 1992-1998 Washington State birth certificate and hospital discharge records to investigate this relation. Consecutive cases of pregnancy-induced hypertension were divided into four groups based on International Classification of Diseases, Ninth Revision codes: eclampsia (n=154), severe preeclampsia (n=1,180), mild preeclampsia (n=5,468), and gestational hypertension (n=8,943). Cases were compared with controls who did not have pregnancy-induced hypertension (n=47,237). Gestational diabetes was more common in each case group (3.9% in eclamptics, 4.5% in severe preeclamptics, and 4.4% in both mild preeclamptics and those with gestational hypertension) than in controls (2.7%). After adjustment for body mass index, age, ethnicity, parity, and prenatal care, gestational diabetes was associated with increased risk of severe preeclampsia (odds ratio (OR)=1.5, 95% confidence interval (CI): 1.1, 2.1), mild preeclampsia (OR=1.5, 95% CI: 1.3, 1.8), and gestational hypertension (OR=1.4, 95% CI: 1.2, 1.6). Gestational diabetes was more strongly associated with pregnancy-induced hypertension among women who received less prenatal care (OR=4.2 for eclampsia and OR=3.1 for severe preeclampsia, p<0.05 for both) and among Black women (OR for eclampsia and preeclampsia together=3.9, p<0.05).","Association between gestational diabetes and pregnancy-induced hypertension."
"354","JAMA.175","NA",14665660,2003,"Randomized controlled trials have shown that the use of noninvasive ventilation (NIV) reduces the need for endotracheal intubation and invasive mechanical ventilation and reduces complication rates and mortality in selected groups of patients. But whether these benefits translate to a clinical setting is unclear.To evaluate longitudinally the routine implementation of NIV and its effect on patients admitted to the intensive care unit (ICU) with acute exacerbation of chronic obstructive pulmonary disease (COPD) or severe cardiogenic pulmonary edema (CPE).Retrospective, observational cohort study using prospectively collected data from January 1, 1994, through December 31, 2001.A 26-bed medical intensive care unit (ICU) of a French university referral hospital.A cohort of 479 consecutive patients ventilated for acute exacerbation of COPD or CPE.The ICU mortality and incidence rates of ICU-acquired infections.A significant increase in NIV use and a concomitant decrease in mortality and ICU-acquired infection rates were observed over the study years. With adjustment for relevant covariates and propensity scores, NIV was identified as an independent factor linked with a reduced risk of death in the cohort (odds ratio [OR], 0.37; 95% confidence interval [CI], 0.18-0.78), whereas a high severity score on admission (OR, 1.05; 95% CI, 1.01-1.10) and the occurrence of a nosocomial infection (OR, 3.08; 95% CI, 1.62-5.84) were independently associated with death. Rates of ICU-acquired pneumonia decreased from 20% in 1994 to 8% in 2001 (P =.04).Implementing routine use of NIV in critically ill patients with acute exacerbation of COPD or severe CPE was associated with improved survival and reduction of nosocomial infections.","Secular trends in nosocomial infections and mortality associated with noninvasive ventilation in patients with exacerbation of COPD and pulmonary edema."
"355","JAMA.176","NA",14665660,2003,"Randomized controlled trials have shown that the use of noninvasive ventilation (NIV) reduces the need for endotracheal intubation and invasive mechanical ventilation and reduces complication rates and mortality in selected groups of patients. But whether these benefits translate to a clinical setting is unclear.To evaluate longitudinally the routine implementation of NIV and its effect on patients admitted to the intensive care unit (ICU) with acute exacerbation of chronic obstructive pulmonary disease (COPD) or severe cardiogenic pulmonary edema (CPE).Retrospective, observational cohort study using prospectively collected data from January 1, 1994, through December 31, 2001.A 26-bed medical intensive care unit (ICU) of a French university referral hospital.A cohort of 479 consecutive patients ventilated for acute exacerbation of COPD or CPE.The ICU mortality and incidence rates of ICU-acquired infections.A significant increase in NIV use and a concomitant decrease in mortality and ICU-acquired infection rates were observed over the study years. With adjustment for relevant covariates and propensity scores, NIV was identified as an independent factor linked with a reduced risk of death in the cohort (odds ratio [OR], 0.37; 95% confidence interval [CI], 0.18-0.78), whereas a high severity score on admission (OR, 1.05; 95% CI, 1.01-1.10) and the occurrence of a nosocomial infection (OR, 3.08; 95% CI, 1.62-5.84) were independently associated with death. Rates of ICU-acquired pneumonia decreased from 20% in 1994 to 8% in 2001 (P =.04).Implementing routine use of NIV in critically ill patients with acute exacerbation of COPD or severe CPE was associated with improved survival and reduction of nosocomial infections.","Secular trends in nosocomial infections and mortality associated with noninvasive ventilation in patients with exacerbation of COPD and pulmonary edema."
"356","JAMA.177","NA",14665660,2003,"Randomized controlled trials have shown that the use of noninvasive ventilation (NIV) reduces the need for endotracheal intubation and invasive mechanical ventilation and reduces complication rates and mortality in selected groups of patients. But whether these benefits translate to a clinical setting is unclear.To evaluate longitudinally the routine implementation of NIV and its effect on patients admitted to the intensive care unit (ICU) with acute exacerbation of chronic obstructive pulmonary disease (COPD) or severe cardiogenic pulmonary edema (CPE).Retrospective, observational cohort study using prospectively collected data from January 1, 1994, through December 31, 2001.A 26-bed medical intensive care unit (ICU) of a French university referral hospital.A cohort of 479 consecutive patients ventilated for acute exacerbation of COPD or CPE.The ICU mortality and incidence rates of ICU-acquired infections.A significant increase in NIV use and a concomitant decrease in mortality and ICU-acquired infection rates were observed over the study years. With adjustment for relevant covariates and propensity scores, NIV was identified as an independent factor linked with a reduced risk of death in the cohort (odds ratio [OR], 0.37; 95% confidence interval [CI], 0.18-0.78), whereas a high severity score on admission (OR, 1.05; 95% CI, 1.01-1.10) and the occurrence of a nosocomial infection (OR, 3.08; 95% CI, 1.62-5.84) were independently associated with death. Rates of ICU-acquired pneumonia decreased from 20% in 1994 to 8% in 2001 (P =.04).Implementing routine use of NIV in critically ill patients with acute exacerbation of COPD or severe CPE was associated with improved survival and reduction of nosocomial infections.","Secular trends in nosocomial infections and mortality associated with noninvasive ventilation in patients with exacerbation of COPD and pulmonary edema."
"357","JAMA.881","0.001",14679272,2003,"Low cardiorespiratory fitness is an established risk factor for cardiovascular and total mortality; however, mechanisms responsible for these associations are uncertain.To test whether low fitness, estimated by short duration on a maximal treadmill test, predicted the development of cardiovascular disease risk factors and whether improving fitness (increase in treadmill test duration between examinations) was associated with risk reduction.Population-based longitudinal cohort study of men and women 18 to 30 years of age in the Coronary Artery Risk Development in Young Adults (CARDIA) study. Participants who completed the treadmill examination according to the Balke protocol at baseline were followed up from 1985-1986 to 2000-2001. A subset of participants (n = 2478) repeated the exercise test in 1992-1993.Incident type 2 diabetes, hypertension, the metabolic syndrome (defined according to National Cholesterol Education Program Adult Treatment Panel III), and hypercholesterolemia (low-density lipoprotein cholesterol > or =160 mg/dL [4.14 mmol/L]).During the 15-year study period, the rates of incident diabetes, hypertension, the metabolic syndrome, and hypercholesterolemia were 2.8, 13.0, 10.2, and 11.7 per 1000 person-years, respectively. After adjustment for age, race, sex, smoking, and family history of diabetes, hypertension, or premature myocardial infarction, participants with low fitness (<20th percentile) were 3- to 6-fold more likely to develop diabetes, hypertension, and the metabolic syndrome than participants with high fitness (> or =60th percentile), all P<.001. Adjusting for baseline body mass index diminished the strength of these associations to 2-fold (all P<.001). In contrast, the association between low fitness and hypercholesterolemia was modest (hazard ratio [HR], 1.4; 95% confidence interval [CI], 1.1-1.7; P =.02) and attenuated to marginal significance after body mass index adjustment (P =.13). Improved fitness over 7 years was associated with a reduced risk of developing diabetes (HR, 0.4; 95% CI, 0.2-1.0; P =.04) and the metabolic syndrome (HR, 0.5; 95% CI, 0.3-0.7; P<.001), but the strength and significance of these associations was reduced after accounting for changes in weight.Poor fitness in young adults is associated with the development of cardiovascular disease risk factors. These associations involve obesity and may be modified by improving fitness.","Cardiorespiratory fitness in young adulthood and the development of cardiovascular disease risk factors."
"358","JAMA.1241","0.02",14679272,2003,"Low cardiorespiratory fitness is an established risk factor for cardiovascular and total mortality; however, mechanisms responsible for these associations are uncertain.To test whether low fitness, estimated by short duration on a maximal treadmill test, predicted the development of cardiovascular disease risk factors and whether improving fitness (increase in treadmill test duration between examinations) was associated with risk reduction.Population-based longitudinal cohort study of men and women 18 to 30 years of age in the Coronary Artery Risk Development in Young Adults (CARDIA) study. Participants who completed the treadmill examination according to the Balke protocol at baseline were followed up from 1985-1986 to 2000-2001. A subset of participants (n = 2478) repeated the exercise test in 1992-1993.Incident type 2 diabetes, hypertension, the metabolic syndrome (defined according to National Cholesterol Education Program Adult Treatment Panel III), and hypercholesterolemia (low-density lipoprotein cholesterol > or =160 mg/dL [4.14 mmol/L]).During the 15-year study period, the rates of incident diabetes, hypertension, the metabolic syndrome, and hypercholesterolemia were 2.8, 13.0, 10.2, and 11.7 per 1000 person-years, respectively. After adjustment for age, race, sex, smoking, and family history of diabetes, hypertension, or premature myocardial infarction, participants with low fitness (<20th percentile) were 3- to 6-fold more likely to develop diabetes, hypertension, and the metabolic syndrome than participants with high fitness (> or =60th percentile), all P<.001. Adjusting for baseline body mass index diminished the strength of these associations to 2-fold (all P<.001). In contrast, the association between low fitness and hypercholesterolemia was modest (hazard ratio [HR], 1.4; 95% confidence interval [CI], 1.1-1.7; P =.02) and attenuated to marginal significance after body mass index adjustment (P =.13). Improved fitness over 7 years was associated with a reduced risk of developing diabetes (HR, 0.4; 95% CI, 0.2-1.0; P =.04) and the metabolic syndrome (HR, 0.5; 95% CI, 0.3-0.7; P<.001), but the strength and significance of these associations was reduced after accounting for changes in weight.Poor fitness in young adults is associated with the development of cardiovascular disease risk factors. These associations involve obesity and may be modified by improving fitness.","Cardiorespiratory fitness in young adulthood and the development of cardiovascular disease risk factors."
"359","JAMA.1261","0.04",14679272,2003,"Low cardiorespiratory fitness is an established risk factor for cardiovascular and total mortality; however, mechanisms responsible for these associations are uncertain.To test whether low fitness, estimated by short duration on a maximal treadmill test, predicted the development of cardiovascular disease risk factors and whether improving fitness (increase in treadmill test duration between examinations) was associated with risk reduction.Population-based longitudinal cohort study of men and women 18 to 30 years of age in the Coronary Artery Risk Development in Young Adults (CARDIA) study. Participants who completed the treadmill examination according to the Balke protocol at baseline were followed up from 1985-1986 to 2000-2001. A subset of participants (n = 2478) repeated the exercise test in 1992-1993.Incident type 2 diabetes, hypertension, the metabolic syndrome (defined according to National Cholesterol Education Program Adult Treatment Panel III), and hypercholesterolemia (low-density lipoprotein cholesterol > or =160 mg/dL [4.14 mmol/L]).During the 15-year study period, the rates of incident diabetes, hypertension, the metabolic syndrome, and hypercholesterolemia were 2.8, 13.0, 10.2, and 11.7 per 1000 person-years, respectively. After adjustment for age, race, sex, smoking, and family history of diabetes, hypertension, or premature myocardial infarction, participants with low fitness (<20th percentile) were 3- to 6-fold more likely to develop diabetes, hypertension, and the metabolic syndrome than participants with high fitness (> or =60th percentile), all P<.001. Adjusting for baseline body mass index diminished the strength of these associations to 2-fold (all P<.001). In contrast, the association between low fitness and hypercholesterolemia was modest (hazard ratio [HR], 1.4; 95% confidence interval [CI], 1.1-1.7; P =.02) and attenuated to marginal significance after body mass index adjustment (P =.13). Improved fitness over 7 years was associated with a reduced risk of developing diabetes (HR, 0.4; 95% CI, 0.2-1.0; P =.04) and the metabolic syndrome (HR, 0.5; 95% CI, 0.3-0.7; P<.001), but the strength and significance of these associations was reduced after accounting for changes in weight.Poor fitness in young adults is associated with the development of cardiovascular disease risk factors. These associations involve obesity and may be modified by improving fitness.","Cardiorespiratory fitness in young adulthood and the development of cardiovascular disease risk factors."
"360","JAMA.871","0.02",14693873,2003,"Complicated, left-sided native valve endocarditis causes significant morbidity and mortality in adults. The presumed benefits of valve surgery remain unproven due to lack of randomized controlled trials.To determine whether valve surgery is associated with reduced mortality in adults with complicated, left-sided native valve endocarditis.Retrospective, observational cohort study conducted from January 1990 to January 2000 at 7 Connecticut hospitals. Propensity analyses were used to control for bias in treatment assignment and prognostic imbalances.Of the 513 adults with complicated, left-sided native valve endocarditis, 230 (45%) underwent valve surgery and 283 (55%) received medical therapy alone.All-cause mortality at 6 months after baseline.In the 6-month period after baseline, 131 patients (26%) died. In unadjusted analyses, valve surgery was associated with reduced mortality (16% vs 33%; hazard ratio [HR], 0.43; 95% confidence interval [CI], 0.29-0.63; P<.001). After adjustment for baseline variables associated with mortality (including hospital site, comorbidity, congestive heart failure, microbial etiology, immunocompromised state, abnormal mental status, and refractory infection), valve surgery remained associated with reduced mortality (adjusted HR, 0.35; 95% CI, 0.23-0.54; P<.02). In further analyses of 218 patients matched by propensity scores, valve surgery remained associated with reduced mortality (15% vs 28%; HR, 0.45; 95% CI, 0.23-0.86; P =.01). After additional adjustment for variables that contribute to heterogeneity and confounding within the propensity-matched group, surgical therapy remained significantly associated with a lower mortality (HR, 0.40; 95% CI, 0.18-0.91; P =.03). In this propensity-matched group, patients with moderate to severe congestive heart failure showed the greatest reduction in mortality with valve surgery (14% vs 51%; HR, 0.22; 95% CI, 0.09-0.53; P =.001).Valve surgery for patients with complicated, left-sided native valve endocarditis was independently associated with reduced 6-month mortality after adjustment for both baseline variables associated with the propensity to undergo valve surgery and baseline variables associated with mortality. The reduced mortality was particularly evident among patients with moderate to severe congestive heart failure.","Impact of valve surgery on 6-month mortality in adults with complicated, left-sided native valve endocarditis: a propensity analysis."
"361","JAMA.1211","0.01",14693873,2003,"Complicated, left-sided native valve endocarditis causes significant morbidity and mortality in adults. The presumed benefits of valve surgery remain unproven due to lack of randomized controlled trials.To determine whether valve surgery is associated with reduced mortality in adults with complicated, left-sided native valve endocarditis.Retrospective, observational cohort study conducted from January 1990 to January 2000 at 7 Connecticut hospitals. Propensity analyses were used to control for bias in treatment assignment and prognostic imbalances.Of the 513 adults with complicated, left-sided native valve endocarditis, 230 (45%) underwent valve surgery and 283 (55%) received medical therapy alone.All-cause mortality at 6 months after baseline.In the 6-month period after baseline, 131 patients (26%) died. In unadjusted analyses, valve surgery was associated with reduced mortality (16% vs 33%; hazard ratio [HR], 0.43; 95% confidence interval [CI], 0.29-0.63; P<.001). After adjustment for baseline variables associated with mortality (including hospital site, comorbidity, congestive heart failure, microbial etiology, immunocompromised state, abnormal mental status, and refractory infection), valve surgery remained associated with reduced mortality (adjusted HR, 0.35; 95% CI, 0.23-0.54; P<.02). In further analyses of 218 patients matched by propensity scores, valve surgery remained associated with reduced mortality (15% vs 28%; HR, 0.45; 95% CI, 0.23-0.86; P =.01). After additional adjustment for variables that contribute to heterogeneity and confounding within the propensity-matched group, surgical therapy remained significantly associated with a lower mortality (HR, 0.40; 95% CI, 0.18-0.91; P =.03). In this propensity-matched group, patients with moderate to severe congestive heart failure showed the greatest reduction in mortality with valve surgery (14% vs 51%; HR, 0.22; 95% CI, 0.09-0.53; P =.001).Valve surgery for patients with complicated, left-sided native valve endocarditis was independently associated with reduced 6-month mortality after adjustment for both baseline variables associated with the propensity to undergo valve surgery and baseline variables associated with mortality. The reduced mortality was particularly evident among patients with moderate to severe congestive heart failure.","Impact of valve surgery on 6-month mortality in adults with complicated, left-sided native valve endocarditis: a propensity analysis."
"362","JAMA.1221","0.03",14693873,2003,"Complicated, left-sided native valve endocarditis causes significant morbidity and mortality in adults. The presumed benefits of valve surgery remain unproven due to lack of randomized controlled trials.To determine whether valve surgery is associated with reduced mortality in adults with complicated, left-sided native valve endocarditis.Retrospective, observational cohort study conducted from January 1990 to January 2000 at 7 Connecticut hospitals. Propensity analyses were used to control for bias in treatment assignment and prognostic imbalances.Of the 513 adults with complicated, left-sided native valve endocarditis, 230 (45%) underwent valve surgery and 283 (55%) received medical therapy alone.All-cause mortality at 6 months after baseline.In the 6-month period after baseline, 131 patients (26%) died. In unadjusted analyses, valve surgery was associated with reduced mortality (16% vs 33%; hazard ratio [HR], 0.43; 95% confidence interval [CI], 0.29-0.63; P<.001). After adjustment for baseline variables associated with mortality (including hospital site, comorbidity, congestive heart failure, microbial etiology, immunocompromised state, abnormal mental status, and refractory infection), valve surgery remained associated with reduced mortality (adjusted HR, 0.35; 95% CI, 0.23-0.54; P<.02). In further analyses of 218 patients matched by propensity scores, valve surgery remained associated with reduced mortality (15% vs 28%; HR, 0.45; 95% CI, 0.23-0.86; P =.01). After additional adjustment for variables that contribute to heterogeneity and confounding within the propensity-matched group, surgical therapy remained significantly associated with a lower mortality (HR, 0.40; 95% CI, 0.18-0.91; P =.03). In this propensity-matched group, patients with moderate to severe congestive heart failure showed the greatest reduction in mortality with valve surgery (14% vs 51%; HR, 0.22; 95% CI, 0.09-0.53; P =.001).Valve surgery for patients with complicated, left-sided native valve endocarditis was independently associated with reduced 6-month mortality after adjustment for both baseline variables associated with the propensity to undergo valve surgery and baseline variables associated with mortality. The reduced mortality was particularly evident among patients with moderate to severe congestive heart failure.","Impact of valve surgery on 6-month mortality in adults with complicated, left-sided native valve endocarditis: a propensity analysis."
"363","JAMA.1231","0.001",14693873,2003,"Complicated, left-sided native valve endocarditis causes significant morbidity and mortality in adults. The presumed benefits of valve surgery remain unproven due to lack of randomized controlled trials.To determine whether valve surgery is associated with reduced mortality in adults with complicated, left-sided native valve endocarditis.Retrospective, observational cohort study conducted from January 1990 to January 2000 at 7 Connecticut hospitals. Propensity analyses were used to control for bias in treatment assignment and prognostic imbalances.Of the 513 adults with complicated, left-sided native valve endocarditis, 230 (45%) underwent valve surgery and 283 (55%) received medical therapy alone.All-cause mortality at 6 months after baseline.In the 6-month period after baseline, 131 patients (26%) died. In unadjusted analyses, valve surgery was associated with reduced mortality (16% vs 33%; hazard ratio [HR], 0.43; 95% confidence interval [CI], 0.29-0.63; P<.001). After adjustment for baseline variables associated with mortality (including hospital site, comorbidity, congestive heart failure, microbial etiology, immunocompromised state, abnormal mental status, and refractory infection), valve surgery remained associated with reduced mortality (adjusted HR, 0.35; 95% CI, 0.23-0.54; P<.02). In further analyses of 218 patients matched by propensity scores, valve surgery remained associated with reduced mortality (15% vs 28%; HR, 0.45; 95% CI, 0.23-0.86; P =.01). After additional adjustment for variables that contribute to heterogeneity and confounding within the propensity-matched group, surgical therapy remained significantly associated with a lower mortality (HR, 0.40; 95% CI, 0.18-0.91; P =.03). In this propensity-matched group, patients with moderate to severe congestive heart failure showed the greatest reduction in mortality with valve surgery (14% vs 51%; HR, 0.22; 95% CI, 0.09-0.53; P =.001).Valve surgery for patients with complicated, left-sided native valve endocarditis was independently associated with reduced 6-month mortality after adjustment for both baseline variables associated with the propensity to undergo valve surgery and baseline variables associated with mortality. The reduced mortality was particularly evident among patients with moderate to severe congestive heart failure.","Impact of valve surgery on 6-month mortality in adults with complicated, left-sided native valve endocarditis: a propensity analysis."
"364","JAMA.1231","0.001",14693873,2003,"Complicated, left-sided native valve endocarditis causes significant morbidity and mortality in adults. The presumed benefits of valve surgery remain unproven due to lack of randomized controlled trials.To determine whether valve surgery is associated with reduced mortality in adults with complicated, left-sided native valve endocarditis.Retrospective, observational cohort study conducted from January 1990 to January 2000 at 7 Connecticut hospitals. Propensity analyses were used to control for bias in treatment assignment and prognostic imbalances.Of the 513 adults with complicated, left-sided native valve endocarditis, 230 (45%) underwent valve surgery and 283 (55%) received medical therapy alone.All-cause mortality at 6 months after baseline.In the 6-month period after baseline, 131 patients (26%) died. In unadjusted analyses, valve surgery was associated with reduced mortality (16% vs 33%; hazard ratio [HR], 0.43; 95% confidence interval [CI], 0.29-0.63; P<.001). After adjustment for baseline variables associated with mortality (including hospital site, comorbidity, congestive heart failure, microbial etiology, immunocompromised state, abnormal mental status, and refractory infection), valve surgery remained associated with reduced mortality (adjusted HR, 0.35; 95% CI, 0.23-0.54; P<.02). In further analyses of 218 patients matched by propensity scores, valve surgery remained associated with reduced mortality (15% vs 28%; HR, 0.45; 95% CI, 0.23-0.86; P =.01). After additional adjustment for variables that contribute to heterogeneity and confounding within the propensity-matched group, surgical therapy remained significantly associated with a lower mortality (HR, 0.40; 95% CI, 0.18-0.91; P =.03). In this propensity-matched group, patients with moderate to severe congestive heart failure showed the greatest reduction in mortality with valve surgery (14% vs 51%; HR, 0.22; 95% CI, 0.09-0.53; P =.001).Valve surgery for patients with complicated, left-sided native valve endocarditis was independently associated with reduced 6-month mortality after adjustment for both baseline variables associated with the propensity to undergo valve surgery and baseline variables associated with mortality. The reduced mortality was particularly evident among patients with moderate to severe congestive heart failure.","Impact of valve surgery on 6-month mortality in adults with complicated, left-sided native valve endocarditis: a propensity analysis."
"365","JAMA.1781","0.001",14722144,2004,"Although chronic Helicobacter pylori infection is associated with gastric cancer, the effect of H pylori treatment on prevention of gastric cancer development in chronic carriers is unknown.To determine whether treatment of H pylori infection reduces the incidence of gastric cancer.Prospective, randomized, placebo-controlled, population-based primary prevention study of 1630 healthy carriers of H pylori infection from Fujian Province, China, recruited in July 1994 and followed up until January 2002. A total of 988 participants did not have precancerous lesions (gastric atrophy, intestinal metaplasia, or gastric dysplasia) on study entry.Patients were randomly assigned to receive H pylori eradication treatment: a 2-week course of omeprazole, 20 mg, a combination product of amoxicillin and clavulanate potassium, 750 mg, and metronidazole, 400 mg, all twice daily (n = 817); or placebo (n = 813).The primary outcome measure was incidence of gastric cancer during follow-up, compared between H pylori eradication and placebo groups. The secondary outcome measure was incidence of gastric cancer in patients with or without precancerous lesions, compared between the 2 groups.Among the 18 new cases of gastric cancers that developed, no overall reduction was observed in participants who received H pylori eradication treatment (n = 7) compared with those who did not (n = 11) (P =.33). In a subgroup of patients with no precancerous lesions on presentation, no patient developed gastric cancer during a follow-up of 7.5 years after H pylori eradication treatment compared with those who received placebo (0 vs 6; P =.02). Smoking (hazard ratio [HR], 6.2; 95% confidence interval [CI], 2.3-16.5; P<.001) and older age (HR, 1.10; 95% CI, 1.05-1.15; P<.001) were independent risk factors for the development of gastric cancer in this cohort.We found that the incidence of gastric cancer development at the population level was similar between participants receiving H pylori eradication treatment and those receiving placebo during a period of 7.5 years in a high-risk region of China. In the subgroup of H pylori carriers without precancerous lesions, eradication of H pylori significantly decreased the development of gastric cancer. Further studies to investigate the role of H pylori eradication in participants with precancerous lesions are warranted.","Helicobacter pylori eradication to prevent gastric cancer in a high-risk region of China: a randomized controlled trial."
"366","JAMA.1791","0.001",14722144,2004,"Although chronic Helicobacter pylori infection is associated with gastric cancer, the effect of H pylori treatment on prevention of gastric cancer development in chronic carriers is unknown.To determine whether treatment of H pylori infection reduces the incidence of gastric cancer.Prospective, randomized, placebo-controlled, population-based primary prevention study of 1630 healthy carriers of H pylori infection from Fujian Province, China, recruited in July 1994 and followed up until January 2002. A total of 988 participants did not have precancerous lesions (gastric atrophy, intestinal metaplasia, or gastric dysplasia) on study entry.Patients were randomly assigned to receive H pylori eradication treatment: a 2-week course of omeprazole, 20 mg, a combination product of amoxicillin and clavulanate potassium, 750 mg, and metronidazole, 400 mg, all twice daily (n = 817); or placebo (n = 813).The primary outcome measure was incidence of gastric cancer during follow-up, compared between H pylori eradication and placebo groups. The secondary outcome measure was incidence of gastric cancer in patients with or without precancerous lesions, compared between the 2 groups.Among the 18 new cases of gastric cancers that developed, no overall reduction was observed in participants who received H pylori eradication treatment (n = 7) compared with those who did not (n = 11) (P =.33). In a subgroup of patients with no precancerous lesions on presentation, no patient developed gastric cancer during a follow-up of 7.5 years after H pylori eradication treatment compared with those who received placebo (0 vs 6; P =.02). Smoking (hazard ratio [HR], 6.2; 95% confidence interval [CI], 2.3-16.5; P<.001) and older age (HR, 1.10; 95% CI, 1.05-1.15; P<.001) were independent risk factors for the development of gastric cancer in this cohort.We found that the incidence of gastric cancer development at the population level was similar between participants receiving H pylori eradication treatment and those receiving placebo during a period of 7.5 years in a high-risk region of China. In the subgroup of H pylori carriers without precancerous lesions, eradication of H pylori significantly decreased the development of gastric cancer. Further studies to investigate the role of H pylori eradication in participants with precancerous lesions are warranted.","Helicobacter pylori eradication to prevent gastric cancer in a high-risk region of China: a randomized controlled trial."
"367","JAMA.259","0.004",14722145,2004,"There have been recent calls for using hospital procedural volume as a quality indicator for coronary artery bypass graft (CABG) surgery, but further research into analysis and policy implication is needed before hospital procedural volume is accepted as a standard quality metric.To examine the contemporary association between hospital CABG procedure volume and outcome in a large national clinical database.Observational analysis of 267 089 isolated CABG procedures performed at 439 US hospitals participating in the Society of Thoracic Surgeons National Cardiac Database between January 1, 2000, and December 31, 2001.Association between hospital CABG procedural volume and all-cause operative mortality (in-hospital or 30-day, whichever was longer).The median (interquartile range) annual hospital-isolated CABG volume was 253 (165-417) procedures, with 82% of centers performing fewer than 500 procedures per year. The overall operative mortality was 2.66%. After adjusting for patient risk and clustering effects, rates of operative mortality decreased with increasing hospital CABG volume (0.07% for every 100 additional CABG procedures; adjusted odds ratio [OR], 0.98; 95% confidence interval [CI], 0.96-0.99; P =.004). While the association between volume and outcome was statistically significant overall, this association was not observed in patients younger than 65 years or in those at low operative risk and was confounded by surgeon volume. The ability of hospital volume to discriminate those centers with significantly better or worse mortality was limited due to the wide variability in risk-adjusted mortality among hospitals with similar volume. Closure of up to 100 of the lowest-volume centers (ie, those performing < or =150 CABG procedures/year) was estimated to avert fewer than 50 of 7110 (<1% of total) CABG-related deaths.In contemporary practice, hospital procedural volume is only modestly associated with CABG outcomes and therefore may not be an adequate quality metric for CABG surgery.","Procedural volume as a marker of quality for CABG surgery."
"368","JAMA.234","0.001",14722146,2004,"Evidence-based selective referral strategies are being used by an increasing number of insurers to ensure that medical care is provided by high-quality providers. In the absence of direct-quality measures based on patient outcomes, the standards currently in place for many conditions rely on indirect-quality measures such as patient volume.To assess the potential usefulness of volume as a quality indicator for very low-birth-weight (VLBW) infants and compare volume with other potential indicators based on readily available hospital characteristics and patient outcomes.A retrospective study of 94 110 VLBW infants weighing 501 to 1500 g born in 332 Vermont Oxford Network hospitals with neonatal intensive care units between January 1, 1995, and December 31, 2000.Mortality among VLBW infants prior to discharge home; detailed case-mix adjustment was performed by using patient characteristics available immediately after birth.In hospitals with less than 50 annual admissions of VLBW infants, an additional 10 admissions were associated with an 11% reduction in mortality (95% confidence interval [CI], 5%-16%; P<.001). The annual volume of admissions only explained 9% of the variation across hospitals in mortality rates, and other readily available hospital characteristics explained an additional 7%. Historical volume was not significantly related to mortality rates in 1999-2000, implying that volume cannot prospectively identify high-quality providers. In contrast, hospitals in the lowest mortality quintile between 1995 and 1998 were found to have significantly lower mortality rates in 1999-2000 (odds ratio [OR], 0.64; 95% CI, 0.55-0.76; P<.001) and hospitals in the highest mortality quintile between 1995 and 1998 had significantly higher mortality rates in 1999-2000 (OR, 1.37; 95% CI, 1.16-1.64; P<.001). The percentage of hospital-level variation in mortality in 1999-2000 that was forecasted by the highest and lowest quintiles based on patient mortality was 34% compared with only 1% for the highest and lowest quintiles of volume.Referral of VLBW infants based on indirect-quality indicators such as patient volume may be minimally effective. Direct measures based on patient outcomes are more useful quality indicators for the purposes of selective referral, as they are better predictors of future mortality rates among providers and could save more lives.","Indirect vs direct hospital quality indicators for very low-birth-weight infants."
"369","JAMA.235","0.001",14722146,2004,"Evidence-based selective referral strategies are being used by an increasing number of insurers to ensure that medical care is provided by high-quality providers. In the absence of direct-quality measures based on patient outcomes, the standards currently in place for many conditions rely on indirect-quality measures such as patient volume.To assess the potential usefulness of volume as a quality indicator for very low-birth-weight (VLBW) infants and compare volume with other potential indicators based on readily available hospital characteristics and patient outcomes.A retrospective study of 94 110 VLBW infants weighing 501 to 1500 g born in 332 Vermont Oxford Network hospitals with neonatal intensive care units between January 1, 1995, and December 31, 2000.Mortality among VLBW infants prior to discharge home; detailed case-mix adjustment was performed by using patient characteristics available immediately after birth.In hospitals with less than 50 annual admissions of VLBW infants, an additional 10 admissions were associated with an 11% reduction in mortality (95% confidence interval [CI], 5%-16%; P<.001). The annual volume of admissions only explained 9% of the variation across hospitals in mortality rates, and other readily available hospital characteristics explained an additional 7%. Historical volume was not significantly related to mortality rates in 1999-2000, implying that volume cannot prospectively identify high-quality providers. In contrast, hospitals in the lowest mortality quintile between 1995 and 1998 were found to have significantly lower mortality rates in 1999-2000 (odds ratio [OR], 0.64; 95% CI, 0.55-0.76; P<.001) and hospitals in the highest mortality quintile between 1995 and 1998 had significantly higher mortality rates in 1999-2000 (OR, 1.37; 95% CI, 1.16-1.64; P<.001). The percentage of hospital-level variation in mortality in 1999-2000 that was forecasted by the highest and lowest quintiles based on patient mortality was 34% compared with only 1% for the highest and lowest quintiles of volume.Referral of VLBW infants based on indirect-quality indicators such as patient volume may be minimally effective. Direct measures based on patient outcomes are more useful quality indicators for the purposes of selective referral, as they are better predictors of future mortality rates among providers and could save more lives.","Indirect vs direct hospital quality indicators for very low-birth-weight infants."
"370","JAMA.1771","0.001",14722147,2004,"Guidelines advise that all adults undergo coronary heart disease (CHD) risk assessment to guide preventive treatment intensity. Although the Framingham Risk Score (FRS) is often recommended for this, it has been suggested that risk assessment may be improved by additional tests such as coronary artery calcium scoring (CACS).To determine whether CACS assessment combined with FRS in asymptomatic adults provides prognostic information superior to either method alone and whether the combined approach can more accurately guide primary preventive strategies in patients with CHD risk factors.Prospective observational population-based study, of 1461 asymptomatic adults with coronary risk factors. Participants with at least 1 coronary risk factor (>45 years) underwent computed tomography (CT) examination, were screened between 1990-1992, were contacted yearly for up to 8.5 years after CT scan, and were assessed for CHD. This analysis included 1312 participants with CACS results; excluded were 269 participants with diabetes and 14 participants with either missing data or had a coronary event before CACS was performed.Nonfatal myocardial infarction (MI) or CHD death.During a median of 7.0 years of follow-up, 84 patients experienced MI or CHD death; 70 patients died of any cause. There were 291 (28%) participants with an FRS of more than 20% and 221 (21%) with a CACS of more than 300. Compared with an FRS of less than 10%, an FRS of more than 20% predicted the risk of MI or CHD death (hazard ratio [HR], 14.3; 95% confidence interval [CI]; 2.0-104; P =.009). Compared with a CACS of zero, a CACS of more than 300 was predictive (HR, 3.9; 95% CI, 2.1-7.3; P<.001). Across categories of FRS, CACS was predictive of risk among patients with an FRS higher than 10% (P<.001) but not with an FRS less than 10%.These data support the hypothesis that high CACS can modify predicted risk obtained from FRS alone, especially among patients in the intermediate-risk category in whom clinical decision making is most uncertain.","Coronary artery calcium score combined with Framingham score for risk prediction in asymptomatic individuals."
"371","JAMA.2281","0.009",14722147,2004,"Guidelines advise that all adults undergo coronary heart disease (CHD) risk assessment to guide preventive treatment intensity. Although the Framingham Risk Score (FRS) is often recommended for this, it has been suggested that risk assessment may be improved by additional tests such as coronary artery calcium scoring (CACS).To determine whether CACS assessment combined with FRS in asymptomatic adults provides prognostic information superior to either method alone and whether the combined approach can more accurately guide primary preventive strategies in patients with CHD risk factors.Prospective observational population-based study, of 1461 asymptomatic adults with coronary risk factors. Participants with at least 1 coronary risk factor (>45 years) underwent computed tomography (CT) examination, were screened between 1990-1992, were contacted yearly for up to 8.5 years after CT scan, and were assessed for CHD. This analysis included 1312 participants with CACS results; excluded were 269 participants with diabetes and 14 participants with either missing data or had a coronary event before CACS was performed.Nonfatal myocardial infarction (MI) or CHD death.During a median of 7.0 years of follow-up, 84 patients experienced MI or CHD death; 70 patients died of any cause. There were 291 (28%) participants with an FRS of more than 20% and 221 (21%) with a CACS of more than 300. Compared with an FRS of less than 10%, an FRS of more than 20% predicted the risk of MI or CHD death (hazard ratio [HR], 14.3; 95% confidence interval [CI]; 2.0-104; P =.009). Compared with a CACS of zero, a CACS of more than 300 was predictive (HR, 3.9; 95% CI, 2.1-7.3; P<.001). Across categories of FRS, CACS was predictive of risk among patients with an FRS higher than 10% (P<.001) but not with an FRS less than 10%.These data support the hypothesis that high CACS can modify predicted risk obtained from FRS alone, especially among patients in the intermediate-risk category in whom clinical decision making is most uncertain.","Coronary artery calcium score combined with Framingham score for risk prediction in asymptomatic individuals."
"372","Lancet.23","0.06",14738791,2004,"Despite available treatment with intravenous immunoglobulin (IVIg), morbidity and mortality are considerable in patients with Guillain-Barr syndrome (GBS). Our aim was to assess whether methylprednisolone, when taken with IVIg, improves outcome when compared with IVIg alone.We did a double-blind, placebo-controlled, multicentre, randomised study, to which we enrolled patients who were unable to walk independently and who had been treated within 14 days after onset of weakness with IVIg (0.4 g/kg bodyweight per day) for 5 days. We assigned 233 individuals to receive either intravenous methylprednisolone (500 mg per day; n=116) or placebo (n=117) for 5 days within 48 h of administration of first dose of IVIg. Because age is an important prognostic factor, we split treatment groups into two age-groups-ie, younger than age 50 years, or 50 years and older. Our primary outcome was an improvement from baseline in GBS disability score of one or more grades 4 weeks after randomisation. Analysis was by intention to treat.We analysed 225 patients. GBS disability scores increased by one grade or more in 68% (76 of 112) of patients in the methylprednisolone group and in 56% (63 of 113) of controls (odds ratio [OR] 1.68, 95% CI 0.97-2.88; p=0.06). After adjustment for age and degree of disability at entry, treatment OR was 1.89 (95% CI 1.07-3.35; p=0.03). Side-effects did not differ greatly between groups.We noted no significant difference between treatment with methylprednisolone and IVIg and IVIg alone. Because of the relevance of prognostic factors and the limited side-effects of methylprednisolone, the potential importance of combination treatment with the drug and IVIg, however, warrants further investigation.","Effect of methylprednisolone when added to standard treatment with intravenous immunoglobulin for Guillain-Barr syndrome: randomised trial."
"373","Lancet.24","0.03",14738791,2004,"Despite available treatment with intravenous immunoglobulin (IVIg), morbidity and mortality are considerable in patients with Guillain-Barr syndrome (GBS). Our aim was to assess whether methylprednisolone, when taken with IVIg, improves outcome when compared with IVIg alone.We did a double-blind, placebo-controlled, multicentre, randomised study, to which we enrolled patients who were unable to walk independently and who had been treated within 14 days after onset of weakness with IVIg (0.4 g/kg bodyweight per day) for 5 days. We assigned 233 individuals to receive either intravenous methylprednisolone (500 mg per day; n=116) or placebo (n=117) for 5 days within 48 h of administration of first dose of IVIg. Because age is an important prognostic factor, we split treatment groups into two age-groups-ie, younger than age 50 years, or 50 years and older. Our primary outcome was an improvement from baseline in GBS disability score of one or more grades 4 weeks after randomisation. Analysis was by intention to treat.We analysed 225 patients. GBS disability scores increased by one grade or more in 68% (76 of 112) of patients in the methylprednisolone group and in 56% (63 of 113) of controls (odds ratio [OR] 1.68, 95% CI 0.97-2.88; p=0.06). After adjustment for age and degree of disability at entry, treatment OR was 1.89 (95% CI 1.07-3.35; p=0.03). Side-effects did not differ greatly between groups.We noted no significant difference between treatment with methylprednisolone and IVIg and IVIg alone. Because of the relevance of prognostic factors and the limited side-effects of methylprednisolone, the potential importance of combination treatment with the drug and IVIg, however, warrants further investigation.","Effect of methylprednisolone when added to standard treatment with intravenous immunoglobulin for Guillain-Barr syndrome: randomised trial."
"374","JAMA.258","0.02",14747499,2004,"Clinical series have suggested an increased prevalence of cerebral infarction and white matter lesions (WMLs) in migraine patients. It is not known whether these lesions are prevalent in the general migraine population.To compare the prevalence of brain infarcts and WMLs in migraine cases and controls from the general population and to identify migraine characteristics associated with these lesions.Cross-sectional, prevalence study of population-based sample of Dutch adults aged 30 to 60 years.Randomly selected patients with migraine with aura (n = 161), patients with migraine without aura (n = 134), and controls (n = 140), who were frequency matched to cases for age, sex, and place of residence. Nearly 50% of the cases had not been previously diagnosed by a physician.Brain magnetic resonance images were evaluated for infarcts, by location and vascular supply territory, and for periventricular WMLs (PVWMLs) and deep WMLs (DWMLs). The odds ratios (ORs) and 95% confidence intervals (CIs) of these brain lesions compared with controls were examined by migraine subtype (with or without aura) and monthly attack frequency (<1 attack, > or =1 attack), controlling for cardiovascular risk factors and use of vasoconstrictor migraine agents. All participants underwent a standard neurological examination.No participants reported a history of stroke or transient ischemic attack or had relevant abnormalities at standard neurological examination. We found no significant difference between patients with migraine and controls in overall infarct prevalence (8.1% vs 5.0%). However, in the cerebellar region of the posterior circulation territory, patients with migraine had a higher prevalence of infarct than controls (5.4% vs 0.7%; P =.02; adjusted OR, 7.1; 95% CI, 0.9-55). The adjusted OR for posterior infarct varied by migraine subtype and attack frequency. The adjusted OR was 13.7 (95% CI, 1.7-112) for patients with migraine with aura compared with controls. In patients with migraine with a frequency of attacks of 1 or more per month, the adjusted OR was 9.3 (95% CI, 1.1-76). The highest risk was in patients with migraine with aura with 1 attack or more per month (OR, 15.8; 95% CI, 1.8-140). Among women, the risk for high DWML load (top 20th percentile of the distribution of DWML load vs lower 80th percentile) was increased in patients with migraine compared with controls (OR, 2.1; 95% CI, 1.0-4.1); this risk increased with attack frequency (highest in those with > or =1 attack per month: OR, 2.6; 95% CI, 1.2-5.7) but was similar in patients with migraine with or without aura. In men, controls and patients with migraine did not differ in the prevalence of DWMLs. There was no association between severity of PVWMLs and migraine, irrespective of sex or migraine frequency or subtype.These population-based findings suggest that some patients with migraine with and without aura are at increased risk for subclinical lesions in certain brain areas.","Migraine as a risk factor for subclinical brain lesions."
"375","JAMA.258","NA",14747499,2004,"Clinical series have suggested an increased prevalence of cerebral infarction and white matter lesions (WMLs) in migraine patients. It is not known whether these lesions are prevalent in the general migraine population.To compare the prevalence of brain infarcts and WMLs in migraine cases and controls from the general population and to identify migraine characteristics associated with these lesions.Cross-sectional, prevalence study of population-based sample of Dutch adults aged 30 to 60 years.Randomly selected patients with migraine with aura (n = 161), patients with migraine without aura (n = 134), and controls (n = 140), who were frequency matched to cases for age, sex, and place of residence. Nearly 50% of the cases had not been previously diagnosed by a physician.Brain magnetic resonance images were evaluated for infarcts, by location and vascular supply territory, and for periventricular WMLs (PVWMLs) and deep WMLs (DWMLs). The odds ratios (ORs) and 95% confidence intervals (CIs) of these brain lesions compared with controls were examined by migraine subtype (with or without aura) and monthly attack frequency (<1 attack, > or =1 attack), controlling for cardiovascular risk factors and use of vasoconstrictor migraine agents. All participants underwent a standard neurological examination.No participants reported a history of stroke or transient ischemic attack or had relevant abnormalities at standard neurological examination. We found no significant difference between patients with migraine and controls in overall infarct prevalence (8.1% vs 5.0%). However, in the cerebellar region of the posterior circulation territory, patients with migraine had a higher prevalence of infarct than controls (5.4% vs 0.7%; P =.02; adjusted OR, 7.1; 95% CI, 0.9-55). The adjusted OR for posterior infarct varied by migraine subtype and attack frequency. The adjusted OR was 13.7 (95% CI, 1.7-112) for patients with migraine with aura compared with controls. In patients with migraine with a frequency of attacks of 1 or more per month, the adjusted OR was 9.3 (95% CI, 1.1-76). The highest risk was in patients with migraine with aura with 1 attack or more per month (OR, 15.8; 95% CI, 1.8-140). Among women, the risk for high DWML load (top 20th percentile of the distribution of DWML load vs lower 80th percentile) was increased in patients with migraine compared with controls (OR, 2.1; 95% CI, 1.0-4.1); this risk increased with attack frequency (highest in those with > or =1 attack per month: OR, 2.6; 95% CI, 1.2-5.7) but was similar in patients with migraine with or without aura. In men, controls and patients with migraine did not differ in the prevalence of DWMLs. There was no association between severity of PVWMLs and migraine, irrespective of sex or migraine frequency or subtype.These population-based findings suggest that some patients with migraine with and without aura are at increased risk for subclinical lesions in certain brain areas.","Migraine as a risk factor for subclinical brain lesions."
"376","JAMA.258","NA",14747499,2004,"Clinical series have suggested an increased prevalence of cerebral infarction and white matter lesions (WMLs) in migraine patients. It is not known whether these lesions are prevalent in the general migraine population.To compare the prevalence of brain infarcts and WMLs in migraine cases and controls from the general population and to identify migraine characteristics associated with these lesions.Cross-sectional, prevalence study of population-based sample of Dutch adults aged 30 to 60 years.Randomly selected patients with migraine with aura (n = 161), patients with migraine without aura (n = 134), and controls (n = 140), who were frequency matched to cases for age, sex, and place of residence. Nearly 50% of the cases had not been previously diagnosed by a physician.Brain magnetic resonance images were evaluated for infarcts, by location and vascular supply territory, and for periventricular WMLs (PVWMLs) and deep WMLs (DWMLs). The odds ratios (ORs) and 95% confidence intervals (CIs) of these brain lesions compared with controls were examined by migraine subtype (with or without aura) and monthly attack frequency (<1 attack, > or =1 attack), controlling for cardiovascular risk factors and use of vasoconstrictor migraine agents. All participants underwent a standard neurological examination.No participants reported a history of stroke or transient ischemic attack or had relevant abnormalities at standard neurological examination. We found no significant difference between patients with migraine and controls in overall infarct prevalence (8.1% vs 5.0%). However, in the cerebellar region of the posterior circulation territory, patients with migraine had a higher prevalence of infarct than controls (5.4% vs 0.7%; P =.02; adjusted OR, 7.1; 95% CI, 0.9-55). The adjusted OR for posterior infarct varied by migraine subtype and attack frequency. The adjusted OR was 13.7 (95% CI, 1.7-112) for patients with migraine with aura compared with controls. In patients with migraine with a frequency of attacks of 1 or more per month, the adjusted OR was 9.3 (95% CI, 1.1-76). The highest risk was in patients with migraine with aura with 1 attack or more per month (OR, 15.8; 95% CI, 1.8-140). Among women, the risk for high DWML load (top 20th percentile of the distribution of DWML load vs lower 80th percentile) was increased in patients with migraine compared with controls (OR, 2.1; 95% CI, 1.0-4.1); this risk increased with attack frequency (highest in those with > or =1 attack per month: OR, 2.6; 95% CI, 1.2-5.7) but was similar in patients with migraine with or without aura. In men, controls and patients with migraine did not differ in the prevalence of DWMLs. There was no association between severity of PVWMLs and migraine, irrespective of sex or migraine frequency or subtype.These population-based findings suggest that some patients with migraine with and without aura are at increased risk for subclinical lesions in certain brain areas.","Migraine as a risk factor for subclinical brain lesions."
"377","JAMA.258","NA",14747499,2004,"Clinical series have suggested an increased prevalence of cerebral infarction and white matter lesions (WMLs) in migraine patients. It is not known whether these lesions are prevalent in the general migraine population.To compare the prevalence of brain infarcts and WMLs in migraine cases and controls from the general population and to identify migraine characteristics associated with these lesions.Cross-sectional, prevalence study of population-based sample of Dutch adults aged 30 to 60 years.Randomly selected patients with migraine with aura (n = 161), patients with migraine without aura (n = 134), and controls (n = 140), who were frequency matched to cases for age, sex, and place of residence. Nearly 50% of the cases had not been previously diagnosed by a physician.Brain magnetic resonance images were evaluated for infarcts, by location and vascular supply territory, and for periventricular WMLs (PVWMLs) and deep WMLs (DWMLs). The odds ratios (ORs) and 95% confidence intervals (CIs) of these brain lesions compared with controls were examined by migraine subtype (with or without aura) and monthly attack frequency (<1 attack, > or =1 attack), controlling for cardiovascular risk factors and use of vasoconstrictor migraine agents. All participants underwent a standard neurological examination.No participants reported a history of stroke or transient ischemic attack or had relevant abnormalities at standard neurological examination. We found no significant difference between patients with migraine and controls in overall infarct prevalence (8.1% vs 5.0%). However, in the cerebellar region of the posterior circulation territory, patients with migraine had a higher prevalence of infarct than controls (5.4% vs 0.7%; P =.02; adjusted OR, 7.1; 95% CI, 0.9-55). The adjusted OR for posterior infarct varied by migraine subtype and attack frequency. The adjusted OR was 13.7 (95% CI, 1.7-112) for patients with migraine with aura compared with controls. In patients with migraine with a frequency of attacks of 1 or more per month, the adjusted OR was 9.3 (95% CI, 1.1-76). The highest risk was in patients with migraine with aura with 1 attack or more per month (OR, 15.8; 95% CI, 1.8-140). Among women, the risk for high DWML load (top 20th percentile of the distribution of DWML load vs lower 80th percentile) was increased in patients with migraine compared with controls (OR, 2.1; 95% CI, 1.0-4.1); this risk increased with attack frequency (highest in those with > or =1 attack per month: OR, 2.6; 95% CI, 1.2-5.7) but was similar in patients with migraine with or without aura. In men, controls and patients with migraine did not differ in the prevalence of DWMLs. There was no association between severity of PVWMLs and migraine, irrespective of sex or migraine frequency or subtype.These population-based findings suggest that some patients with migraine with and without aura are at increased risk for subclinical lesions in certain brain areas.","Migraine as a risk factor for subclinical brain lesions."
"378","JAMA.258","NA",14747499,2004,"Clinical series have suggested an increased prevalence of cerebral infarction and white matter lesions (WMLs) in migraine patients. It is not known whether these lesions are prevalent in the general migraine population.To compare the prevalence of brain infarcts and WMLs in migraine cases and controls from the general population and to identify migraine characteristics associated with these lesions.Cross-sectional, prevalence study of population-based sample of Dutch adults aged 30 to 60 years.Randomly selected patients with migraine with aura (n = 161), patients with migraine without aura (n = 134), and controls (n = 140), who were frequency matched to cases for age, sex, and place of residence. Nearly 50% of the cases had not been previously diagnosed by a physician.Brain magnetic resonance images were evaluated for infarcts, by location and vascular supply territory, and for periventricular WMLs (PVWMLs) and deep WMLs (DWMLs). The odds ratios (ORs) and 95% confidence intervals (CIs) of these brain lesions compared with controls were examined by migraine subtype (with or without aura) and monthly attack frequency (<1 attack, > or =1 attack), controlling for cardiovascular risk factors and use of vasoconstrictor migraine agents. All participants underwent a standard neurological examination.No participants reported a history of stroke or transient ischemic attack or had relevant abnormalities at standard neurological examination. We found no significant difference between patients with migraine and controls in overall infarct prevalence (8.1% vs 5.0%). However, in the cerebellar region of the posterior circulation territory, patients with migraine had a higher prevalence of infarct than controls (5.4% vs 0.7%; P =.02; adjusted OR, 7.1; 95% CI, 0.9-55). The adjusted OR for posterior infarct varied by migraine subtype and attack frequency. The adjusted OR was 13.7 (95% CI, 1.7-112) for patients with migraine with aura compared with controls. In patients with migraine with a frequency of attacks of 1 or more per month, the adjusted OR was 9.3 (95% CI, 1.1-76). The highest risk was in patients with migraine with aura with 1 attack or more per month (OR, 15.8; 95% CI, 1.8-140). Among women, the risk for high DWML load (top 20th percentile of the distribution of DWML load vs lower 80th percentile) was increased in patients with migraine compared with controls (OR, 2.1; 95% CI, 1.0-4.1); this risk increased with attack frequency (highest in those with > or =1 attack per month: OR, 2.6; 95% CI, 1.2-5.7) but was similar in patients with migraine with or without aura. In men, controls and patients with migraine did not differ in the prevalence of DWMLs. There was no association between severity of PVWMLs and migraine, irrespective of sex or migraine frequency or subtype.These population-based findings suggest that some patients with migraine with and without aura are at increased risk for subclinical lesions in certain brain areas.","Migraine as a risk factor for subclinical brain lesions."
"379","JAMA.258","NA",14747499,2004,"Clinical series have suggested an increased prevalence of cerebral infarction and white matter lesions (WMLs) in migraine patients. It is not known whether these lesions are prevalent in the general migraine population.To compare the prevalence of brain infarcts and WMLs in migraine cases and controls from the general population and to identify migraine characteristics associated with these lesions.Cross-sectional, prevalence study of population-based sample of Dutch adults aged 30 to 60 years.Randomly selected patients with migraine with aura (n = 161), patients with migraine without aura (n = 134), and controls (n = 140), who were frequency matched to cases for age, sex, and place of residence. Nearly 50% of the cases had not been previously diagnosed by a physician.Brain magnetic resonance images were evaluated for infarcts, by location and vascular supply territory, and for periventricular WMLs (PVWMLs) and deep WMLs (DWMLs). The odds ratios (ORs) and 95% confidence intervals (CIs) of these brain lesions compared with controls were examined by migraine subtype (with or without aura) and monthly attack frequency (<1 attack, > or =1 attack), controlling for cardiovascular risk factors and use of vasoconstrictor migraine agents. All participants underwent a standard neurological examination.No participants reported a history of stroke or transient ischemic attack or had relevant abnormalities at standard neurological examination. We found no significant difference between patients with migraine and controls in overall infarct prevalence (8.1% vs 5.0%). However, in the cerebellar region of the posterior circulation territory, patients with migraine had a higher prevalence of infarct than controls (5.4% vs 0.7%; P =.02; adjusted OR, 7.1; 95% CI, 0.9-55). The adjusted OR for posterior infarct varied by migraine subtype and attack frequency. The adjusted OR was 13.7 (95% CI, 1.7-112) for patients with migraine with aura compared with controls. In patients with migraine with a frequency of attacks of 1 or more per month, the adjusted OR was 9.3 (95% CI, 1.1-76). The highest risk was in patients with migraine with aura with 1 attack or more per month (OR, 15.8; 95% CI, 1.8-140). Among women, the risk for high DWML load (top 20th percentile of the distribution of DWML load vs lower 80th percentile) was increased in patients with migraine compared with controls (OR, 2.1; 95% CI, 1.0-4.1); this risk increased with attack frequency (highest in those with > or =1 attack per month: OR, 2.6; 95% CI, 1.2-5.7) but was similar in patients with migraine with or without aura. In men, controls and patients with migraine did not differ in the prevalence of DWMLs. There was no association between severity of PVWMLs and migraine, irrespective of sex or migraine frequency or subtype.These population-based findings suggest that some patients with migraine with and without aura are at increased risk for subclinical lesions in certain brain areas.","Migraine as a risk factor for subclinical brain lesions."
"380","JAMA.1721","0.001",14747500,2004,"Experimental data suggest that placental growth factor (PlGF), a member of the vascular endothelial growth factor family, acts as a primary inflammatory instigator of atherosclerotic plaque instability and thus may be useful as a risk-predicting biomarker in patients with acute coronary syndromes (ACS).To determine whether blood levels of PlGF predict risk for death or nonfatal myocardial infarction in patients with acute chest pain.Measurement of PlGF levels as well as levels of markers of myocardial necrosis (troponin T [TnT]), platelet activation (soluble CD40 ligand [sCD40L]), and inflammation (high-sensitivity C-reactive protein [hsCRP]) in an inception cohort of 547 patients with angiographically validated ACS participating in the CAPTURE (c7E3 Fab Anti-Platelet Therapy in Unstable Refractory Angina) trial and in a heterogeneous cohort of 626 patients presenting with acute chest pain to an emergency department in Germany between December 1996 and March 1999.Risk for death or nonfatal myocardial infarction after 30 days.In patients with ACS, elevated PlGF levels (>27.0 ng/L; 40.8% of patients) indicated a markedly increased risk of events at 30 days (14.8% vs 4.9%; unadjusted hazard ratio [HR], 3.34; 95% confidence interval [CI], 1.79-6.24; P<.001). In a multivariable model, elevated levels of TnT (HR, 1.83; 95% CI, 1.05-3.86; P =.03), sCD40L (HR, 2.65; 95% CI, 1.41-4.99; P =.002), and PlGF (HR, 3.03; 95% CI, 1.54-5.95; P<.001) were independent predictors, while elevated hsCRP level was not (HR, 0.98; 95% CI, 0.53-1.98; P =.94). In patients with acute chest pain, elevated levels of PlGF predicted risk (21.2% vs 5.3%) (unadjusted: HR, 4.80; 95% CI, 2.81-8.21; P<.001; adjusted: HR, 3.00; 95% CI, 1.68-5.38; P<.001). Patients negative for all 3 markers (TnT, sCD40L, and PlGF) were at very low cardiac risk (7 days: no event; 30 days: 2.1% event rate).Plasma PlGF levels may be an independent biomarker of adverse outcome in patients with suspected ACS. A single initial measurement of plasma PlGF appears to extend the predictive and prognostic information gained from traditional inflammatory markers.","Prognostic value of placental growth factor in patients with acute chest pain."
"381","JAMA.1731","0.001",14747500,2004,"Experimental data suggest that placental growth factor (PlGF), a member of the vascular endothelial growth factor family, acts as a primary inflammatory instigator of atherosclerotic plaque instability and thus may be useful as a risk-predicting biomarker in patients with acute coronary syndromes (ACS).To determine whether blood levels of PlGF predict risk for death or nonfatal myocardial infarction in patients with acute chest pain.Measurement of PlGF levels as well as levels of markers of myocardial necrosis (troponin T [TnT]), platelet activation (soluble CD40 ligand [sCD40L]), and inflammation (high-sensitivity C-reactive protein [hsCRP]) in an inception cohort of 547 patients with angiographically validated ACS participating in the CAPTURE (c7E3 Fab Anti-Platelet Therapy in Unstable Refractory Angina) trial and in a heterogeneous cohort of 626 patients presenting with acute chest pain to an emergency department in Germany between December 1996 and March 1999.Risk for death or nonfatal myocardial infarction after 30 days.In patients with ACS, elevated PlGF levels (>27.0 ng/L; 40.8% of patients) indicated a markedly increased risk of events at 30 days (14.8% vs 4.9%; unadjusted hazard ratio [HR], 3.34; 95% confidence interval [CI], 1.79-6.24; P<.001). In a multivariable model, elevated levels of TnT (HR, 1.83; 95% CI, 1.05-3.86; P =.03), sCD40L (HR, 2.65; 95% CI, 1.41-4.99; P =.002), and PlGF (HR, 3.03; 95% CI, 1.54-5.95; P<.001) were independent predictors, while elevated hsCRP level was not (HR, 0.98; 95% CI, 0.53-1.98; P =.94). In patients with acute chest pain, elevated levels of PlGF predicted risk (21.2% vs 5.3%) (unadjusted: HR, 4.80; 95% CI, 2.81-8.21; P<.001; adjusted: HR, 3.00; 95% CI, 1.68-5.38; P<.001). Patients negative for all 3 markers (TnT, sCD40L, and PlGF) were at very low cardiac risk (7 days: no event; 30 days: 2.1% event rate).Plasma PlGF levels may be an independent biomarker of adverse outcome in patients with suspected ACS. A single initial measurement of plasma PlGF appears to extend the predictive and prognostic information gained from traditional inflammatory markers.","Prognostic value of placental growth factor in patients with acute chest pain."
"382","JAMA.1741","0.001",14747500,2004,"Experimental data suggest that placental growth factor (PlGF), a member of the vascular endothelial growth factor family, acts as a primary inflammatory instigator of atherosclerotic plaque instability and thus may be useful as a risk-predicting biomarker in patients with acute coronary syndromes (ACS).To determine whether blood levels of PlGF predict risk for death or nonfatal myocardial infarction in patients with acute chest pain.Measurement of PlGF levels as well as levels of markers of myocardial necrosis (troponin T [TnT]), platelet activation (soluble CD40 ligand [sCD40L]), and inflammation (high-sensitivity C-reactive protein [hsCRP]) in an inception cohort of 547 patients with angiographically validated ACS participating in the CAPTURE (c7E3 Fab Anti-Platelet Therapy in Unstable Refractory Angina) trial and in a heterogeneous cohort of 626 patients presenting with acute chest pain to an emergency department in Germany between December 1996 and March 1999.Risk for death or nonfatal myocardial infarction after 30 days.In patients with ACS, elevated PlGF levels (>27.0 ng/L; 40.8% of patients) indicated a markedly increased risk of events at 30 days (14.8% vs 4.9%; unadjusted hazard ratio [HR], 3.34; 95% confidence interval [CI], 1.79-6.24; P<.001). In a multivariable model, elevated levels of TnT (HR, 1.83; 95% CI, 1.05-3.86; P =.03), sCD40L (HR, 2.65; 95% CI, 1.41-4.99; P =.002), and PlGF (HR, 3.03; 95% CI, 1.54-5.95; P<.001) were independent predictors, while elevated hsCRP level was not (HR, 0.98; 95% CI, 0.53-1.98; P =.94). In patients with acute chest pain, elevated levels of PlGF predicted risk (21.2% vs 5.3%) (unadjusted: HR, 4.80; 95% CI, 2.81-8.21; P<.001; adjusted: HR, 3.00; 95% CI, 1.68-5.38; P<.001). Patients negative for all 3 markers (TnT, sCD40L, and PlGF) were at very low cardiac risk (7 days: no event; 30 days: 2.1% event rate).Plasma PlGF levels may be an independent biomarker of adverse outcome in patients with suspected ACS. A single initial measurement of plasma PlGF appears to extend the predictive and prognostic information gained from traditional inflammatory markers.","Prognostic value of placental growth factor in patients with acute chest pain."
"383","JAMA.1751","0.001",14747500,2004,"Experimental data suggest that placental growth factor (PlGF), a member of the vascular endothelial growth factor family, acts as a primary inflammatory instigator of atherosclerotic plaque instability and thus may be useful as a risk-predicting biomarker in patients with acute coronary syndromes (ACS).To determine whether blood levels of PlGF predict risk for death or nonfatal myocardial infarction in patients with acute chest pain.Measurement of PlGF levels as well as levels of markers of myocardial necrosis (troponin T [TnT]), platelet activation (soluble CD40 ligand [sCD40L]), and inflammation (high-sensitivity C-reactive protein [hsCRP]) in an inception cohort of 547 patients with angiographically validated ACS participating in the CAPTURE (c7E3 Fab Anti-Platelet Therapy in Unstable Refractory Angina) trial and in a heterogeneous cohort of 626 patients presenting with acute chest pain to an emergency department in Germany between December 1996 and March 1999.Risk for death or nonfatal myocardial infarction after 30 days.In patients with ACS, elevated PlGF levels (>27.0 ng/L; 40.8% of patients) indicated a markedly increased risk of events at 30 days (14.8% vs 4.9%; unadjusted hazard ratio [HR], 3.34; 95% confidence interval [CI], 1.79-6.24; P<.001). In a multivariable model, elevated levels of TnT (HR, 1.83; 95% CI, 1.05-3.86; P =.03), sCD40L (HR, 2.65; 95% CI, 1.41-4.99; P =.002), and PlGF (HR, 3.03; 95% CI, 1.54-5.95; P<.001) were independent predictors, while elevated hsCRP level was not (HR, 0.98; 95% CI, 0.53-1.98; P =.94). In patients with acute chest pain, elevated levels of PlGF predicted risk (21.2% vs 5.3%) (unadjusted: HR, 4.80; 95% CI, 2.81-8.21; P<.001; adjusted: HR, 3.00; 95% CI, 1.68-5.38; P<.001). Patients negative for all 3 markers (TnT, sCD40L, and PlGF) were at very low cardiac risk (7 days: no event; 30 days: 2.1% event rate).Plasma PlGF levels may be an independent biomarker of adverse outcome in patients with suspected ACS. A single initial measurement of plasma PlGF appears to extend the predictive and prognostic information gained from traditional inflammatory markers.","Prognostic value of placental growth factor in patients with acute chest pain."
"384","JAMA.2251","0.03",14747500,2004,"Experimental data suggest that placental growth factor (PlGF), a member of the vascular endothelial growth factor family, acts as a primary inflammatory instigator of atherosclerotic plaque instability and thus may be useful as a risk-predicting biomarker in patients with acute coronary syndromes (ACS).To determine whether blood levels of PlGF predict risk for death or nonfatal myocardial infarction in patients with acute chest pain.Measurement of PlGF levels as well as levels of markers of myocardial necrosis (troponin T [TnT]), platelet activation (soluble CD40 ligand [sCD40L]), and inflammation (high-sensitivity C-reactive protein [hsCRP]) in an inception cohort of 547 patients with angiographically validated ACS participating in the CAPTURE (c7E3 Fab Anti-Platelet Therapy in Unstable Refractory Angina) trial and in a heterogeneous cohort of 626 patients presenting with acute chest pain to an emergency department in Germany between December 1996 and March 1999.Risk for death or nonfatal myocardial infarction after 30 days.In patients with ACS, elevated PlGF levels (>27.0 ng/L; 40.8% of patients) indicated a markedly increased risk of events at 30 days (14.8% vs 4.9%; unadjusted hazard ratio [HR], 3.34; 95% confidence interval [CI], 1.79-6.24; P<.001). In a multivariable model, elevated levels of TnT (HR, 1.83; 95% CI, 1.05-3.86; P =.03), sCD40L (HR, 2.65; 95% CI, 1.41-4.99; P =.002), and PlGF (HR, 3.03; 95% CI, 1.54-5.95; P<.001) were independent predictors, while elevated hsCRP level was not (HR, 0.98; 95% CI, 0.53-1.98; P =.94). In patients with acute chest pain, elevated levels of PlGF predicted risk (21.2% vs 5.3%) (unadjusted: HR, 4.80; 95% CI, 2.81-8.21; P<.001; adjusted: HR, 3.00; 95% CI, 1.68-5.38; P<.001). Patients negative for all 3 markers (TnT, sCD40L, and PlGF) were at very low cardiac risk (7 days: no event; 30 days: 2.1% event rate).Plasma PlGF levels may be an independent biomarker of adverse outcome in patients with suspected ACS. A single initial measurement of plasma PlGF appears to extend the predictive and prognostic information gained from traditional inflammatory markers.","Prognostic value of placental growth factor in patients with acute chest pain."
"385","JAMA.2261","0.002",14747500,2004,"Experimental data suggest that placental growth factor (PlGF), a member of the vascular endothelial growth factor family, acts as a primary inflammatory instigator of atherosclerotic plaque instability and thus may be useful as a risk-predicting biomarker in patients with acute coronary syndromes (ACS).To determine whether blood levels of PlGF predict risk for death or nonfatal myocardial infarction in patients with acute chest pain.Measurement of PlGF levels as well as levels of markers of myocardial necrosis (troponin T [TnT]), platelet activation (soluble CD40 ligand [sCD40L]), and inflammation (high-sensitivity C-reactive protein [hsCRP]) in an inception cohort of 547 patients with angiographically validated ACS participating in the CAPTURE (c7E3 Fab Anti-Platelet Therapy in Unstable Refractory Angina) trial and in a heterogeneous cohort of 626 patients presenting with acute chest pain to an emergency department in Germany between December 1996 and March 1999.Risk for death or nonfatal myocardial infarction after 30 days.In patients with ACS, elevated PlGF levels (>27.0 ng/L; 40.8% of patients) indicated a markedly increased risk of events at 30 days (14.8% vs 4.9%; unadjusted hazard ratio [HR], 3.34; 95% confidence interval [CI], 1.79-6.24; P<.001). In a multivariable model, elevated levels of TnT (HR, 1.83; 95% CI, 1.05-3.86; P =.03), sCD40L (HR, 2.65; 95% CI, 1.41-4.99; P =.002), and PlGF (HR, 3.03; 95% CI, 1.54-5.95; P<.001) were independent predictors, while elevated hsCRP level was not (HR, 0.98; 95% CI, 0.53-1.98; P =.94). In patients with acute chest pain, elevated levels of PlGF predicted risk (21.2% vs 5.3%) (unadjusted: HR, 4.80; 95% CI, 2.81-8.21; P<.001; adjusted: HR, 3.00; 95% CI, 1.68-5.38; P<.001). Patients negative for all 3 markers (TnT, sCD40L, and PlGF) were at very low cardiac risk (7 days: no event; 30 days: 2.1% event rate).Plasma PlGF levels may be an independent biomarker of adverse outcome in patients with suspected ACS. A single initial measurement of plasma PlGF appears to extend the predictive and prognostic information gained from traditional inflammatory markers.","Prognostic value of placental growth factor in patients with acute chest pain."
"386","JAMA.2271","0.94",14747500,2004,"Experimental data suggest that placental growth factor (PlGF), a member of the vascular endothelial growth factor family, acts as a primary inflammatory instigator of atherosclerotic plaque instability and thus may be useful as a risk-predicting biomarker in patients with acute coronary syndromes (ACS).To determine whether blood levels of PlGF predict risk for death or nonfatal myocardial infarction in patients with acute chest pain.Measurement of PlGF levels as well as levels of markers of myocardial necrosis (troponin T [TnT]), platelet activation (soluble CD40 ligand [sCD40L]), and inflammation (high-sensitivity C-reactive protein [hsCRP]) in an inception cohort of 547 patients with angiographically validated ACS participating in the CAPTURE (c7E3 Fab Anti-Platelet Therapy in Unstable Refractory Angina) trial and in a heterogeneous cohort of 626 patients presenting with acute chest pain to an emergency department in Germany between December 1996 and March 1999.Risk for death or nonfatal myocardial infarction after 30 days.In patients with ACS, elevated PlGF levels (>27.0 ng/L; 40.8% of patients) indicated a markedly increased risk of events at 30 days (14.8% vs 4.9%; unadjusted hazard ratio [HR], 3.34; 95% confidence interval [CI], 1.79-6.24; P<.001). In a multivariable model, elevated levels of TnT (HR, 1.83; 95% CI, 1.05-3.86; P =.03), sCD40L (HR, 2.65; 95% CI, 1.41-4.99; P =.002), and PlGF (HR, 3.03; 95% CI, 1.54-5.95; P<.001) were independent predictors, while elevated hsCRP level was not (HR, 0.98; 95% CI, 0.53-1.98; P =.94). In patients with acute chest pain, elevated levels of PlGF predicted risk (21.2% vs 5.3%) (unadjusted: HR, 4.80; 95% CI, 2.81-8.21; P<.001; adjusted: HR, 3.00; 95% CI, 1.68-5.38; P<.001). Patients negative for all 3 markers (TnT, sCD40L, and PlGF) were at very low cardiac risk (7 days: no event; 30 days: 2.1% event rate).Plasma PlGF levels may be an independent biomarker of adverse outcome in patients with suspected ACS. A single initial measurement of plasma PlGF appears to extend the predictive and prognostic information gained from traditional inflammatory markers.","Prognostic value of placental growth factor in patients with acute chest pain."
"387","JAMA.233","0.001",14762037,2004,"Inflammation may play a role in the pathogenesis of colorectal cancer; however, epidemiological evidence supporting this hypothesis in average-risk persons is sparse.To determine the risk of incident colon and rectal cancer associated with elevated baseline plasma concentrations of C-reactive protein (CRP).Prospective, nested case-control study of a cohort of 22 887 adults (>18 years and Washington County, Maryland, residents) enrolled between May and October 1989 and followed up through December 2000. A total of 172 colorectal cancer cases were identified through linkage with the Washington County and Maryland State Cancer registries. Up to 2 controls (n = 342) were selected from the cohort for each case and matched by age, sex, race, and date of blood draw.Odds ratio (OR) of incident colon and rectal cancer.Plasma CRP concentrations were higher among all colorectal cases combined than controls (median CRP, 2.44 vs 1.94 mg/L; P =.01). The highest concentration was found in persons who subsequently developed colon cancer vs matched controls (median CRP, 2.69 vs 1.97 mg/L; P<.001). Among rectal cancer cases, CRP concentrations were not significantly different from controls (median CRP, 1.79 vs 1.81 mg/L; P =.32). The risk of colon cancer was higher in persons in the highest vs lowest quartile of CRP (OR, 2.55; 95% confidence interval [CI], 1.34-4.88; P for trend =.002). In nonsmokers, the corresponding association was stronger (OR, 3.51; 95% CI, 1.64-7.51; P for trend<.001). A 1-SD increase in log CRP (1.02 mg/L) was associated with an increased risk of colon cancer after adjusting for potential confounders and excluding cases occurring within 2 years of baseline (OR, 1.35; 95% CI, 1.05-1.74) or excluding those with late-stage colon cancer at the time of diagnosis (OR, 1.38; 95% CI, 0.99-1.91).Plasma CRP concentrations are elevated among persons who subsequently develop colon cancer. These data support the hypothesis that inflammation is a risk factor for the development of colon cancer in average-risk individuals.","C-reactive protein and the risk of incident colorectal cancer."
"388","JAMA.256","0.002",14762037,2004,"Inflammation may play a role in the pathogenesis of colorectal cancer; however, epidemiological evidence supporting this hypothesis in average-risk persons is sparse.To determine the risk of incident colon and rectal cancer associated with elevated baseline plasma concentrations of C-reactive protein (CRP).Prospective, nested case-control study of a cohort of 22 887 adults (>18 years and Washington County, Maryland, residents) enrolled between May and October 1989 and followed up through December 2000. A total of 172 colorectal cancer cases were identified through linkage with the Washington County and Maryland State Cancer registries. Up to 2 controls (n = 342) were selected from the cohort for each case and matched by age, sex, race, and date of blood draw.Odds ratio (OR) of incident colon and rectal cancer.Plasma CRP concentrations were higher among all colorectal cases combined than controls (median CRP, 2.44 vs 1.94 mg/L; P =.01). The highest concentration was found in persons who subsequently developed colon cancer vs matched controls (median CRP, 2.69 vs 1.97 mg/L; P<.001). Among rectal cancer cases, CRP concentrations were not significantly different from controls (median CRP, 1.79 vs 1.81 mg/L; P =.32). The risk of colon cancer was higher in persons in the highest vs lowest quartile of CRP (OR, 2.55; 95% confidence interval [CI], 1.34-4.88; P for trend =.002). In nonsmokers, the corresponding association was stronger (OR, 3.51; 95% CI, 1.64-7.51; P for trend<.001). A 1-SD increase in log CRP (1.02 mg/L) was associated with an increased risk of colon cancer after adjusting for potential confounders and excluding cases occurring within 2 years of baseline (OR, 1.35; 95% CI, 1.05-1.74) or excluding those with late-stage colon cancer at the time of diagnosis (OR, 1.38; 95% CI, 0.99-1.91).Plasma CRP concentrations are elevated among persons who subsequently develop colon cancer. These data support the hypothesis that inflammation is a risk factor for the development of colon cancer in average-risk individuals.","C-reactive protein and the risk of incident colorectal cancer."
"389","JAMA.255","0.02",14871913,2004,"C-reactive protein (CRP) is a systemic inflammatory marker associated with risk for cardiovascular disease (CVD). Some risk factors for CVD are associated with age-related macular degeneration (AMD), but the association between CRP and AMD is unknown.To test the hypothesis that elevated CRP levels are associated with an increased risk for AMD.A total of 930 (91%) of 1026 participants at 2 centers in the Age-Related Eye Disease Study (AREDS), a multicenter randomized trial of antioxidant vitamins and minerals, were enrolled in this case-control study. There were 183 individuals without any maculopathy, 200 with mild maculopathy, 325 with intermediate disease, and 222 with advanced AMD (geographic atrophy or neovascular AMD). The AMD status was assessed by standardized grading of fundus photographs, and stored fasting blood specimens drawn between January 1996 and April 1997 were analyzed for high-sensitivity CRP levels.Association between CRP and AMD.The CRP levels were significantly higher among participants with advanced AMD (case patients) than among those with no AMD (controls; median values, 3.4 vs 2.7 mg/L; P =.02). After adjustment for age, sex, and other variables, including smoking and body mass index, CRP levels were significantly associated with the presence of intermediate and advanced stages of AMD. The odds ratio (OR) for the highest vs the lowest quartile of CRP was 1.65 (95% confidence interval [CI], 1.07-2.55; P for trend =.02). The OR for CRP values at or above the 90th percentile (10.6 mg/L) was 1.92 (95% CI, 1.20-3.06), and the OR for CRP values at or above the mean plus 2 SDs (16.8 mg/L) was 2.03 (95% CI, 1.03-4.00). A trend for an increased risk for intermediate and advanced AMD with higher levels of CRP was seen for smokers (OR, 2.16; 95% CI, 1.33-3.49) and those who never smoked (OR, 2.03; 95% CI, 1.19-3.46) with the highest level of CRP.Our results suggest that elevated CRP level is an independent risk factor for AMD and may implicate the role of inflammation in the pathogenesis of AMD.","Association between C-reactive protein and age-related macular degeneration."
"390","JAMA.255",NA,14871913,2004,"C-reactive protein (CRP) is a systemic inflammatory marker associated with risk for cardiovascular disease (CVD). Some risk factors for CVD are associated with age-related macular degeneration (AMD), but the association between CRP and AMD is unknown.To test the hypothesis that elevated CRP levels are associated with an increased risk for AMD.A total of 930 (91%) of 1026 participants at 2 centers in the Age-Related Eye Disease Study (AREDS), a multicenter randomized trial of antioxidant vitamins and minerals, were enrolled in this case-control study. There were 183 individuals without any maculopathy, 200 with mild maculopathy, 325 with intermediate disease, and 222 with advanced AMD (geographic atrophy or neovascular AMD). The AMD status was assessed by standardized grading of fundus photographs, and stored fasting blood specimens drawn between January 1996 and April 1997 were analyzed for high-sensitivity CRP levels.Association between CRP and AMD.The CRP levels were significantly higher among participants with advanced AMD (case patients) than among those with no AMD (controls; median values, 3.4 vs 2.7 mg/L; P =.02). After adjustment for age, sex, and other variables, including smoking and body mass index, CRP levels were significantly associated with the presence of intermediate and advanced stages of AMD. The odds ratio (OR) for the highest vs the lowest quartile of CRP was 1.65 (95% confidence interval [CI], 1.07-2.55; P for trend =.02). The OR for CRP values at or above the 90th percentile (10.6 mg/L) was 1.92 (95% CI, 1.20-3.06), and the OR for CRP values at or above the mean plus 2 SDs (16.8 mg/L) was 2.03 (95% CI, 1.03-4.00). A trend for an increased risk for intermediate and advanced AMD with higher levels of CRP was seen for smokers (OR, 2.16; 95% CI, 1.33-3.49) and those who never smoked (OR, 2.03; 95% CI, 1.19-3.46) with the highest level of CRP.Our results suggest that elevated CRP level is an independent risk factor for AMD and may implicate the role of inflammation in the pathogenesis of AMD.","Association between C-reactive protein and age-related macular degeneration."
"391","JAMA.255",NA,14871913,2004,"C-reactive protein (CRP) is a systemic inflammatory marker associated with risk for cardiovascular disease (CVD). Some risk factors for CVD are associated with age-related macular degeneration (AMD), but the association between CRP and AMD is unknown.To test the hypothesis that elevated CRP levels are associated with an increased risk for AMD.A total of 930 (91%) of 1026 participants at 2 centers in the Age-Related Eye Disease Study (AREDS), a multicenter randomized trial of antioxidant vitamins and minerals, were enrolled in this case-control study. There were 183 individuals without any maculopathy, 200 with mild maculopathy, 325 with intermediate disease, and 222 with advanced AMD (geographic atrophy or neovascular AMD). The AMD status was assessed by standardized grading of fundus photographs, and stored fasting blood specimens drawn between January 1996 and April 1997 were analyzed for high-sensitivity CRP levels.Association between CRP and AMD.The CRP levels were significantly higher among participants with advanced AMD (case patients) than among those with no AMD (controls; median values, 3.4 vs 2.7 mg/L; P =.02). After adjustment for age, sex, and other variables, including smoking and body mass index, CRP levels were significantly associated with the presence of intermediate and advanced stages of AMD. The odds ratio (OR) for the highest vs the lowest quartile of CRP was 1.65 (95% confidence interval [CI], 1.07-2.55; P for trend =.02). The OR for CRP values at or above the 90th percentile (10.6 mg/L) was 1.92 (95% CI, 1.20-3.06), and the OR for CRP values at or above the mean plus 2 SDs (16.8 mg/L) was 2.03 (95% CI, 1.03-4.00). A trend for an increased risk for intermediate and advanced AMD with higher levels of CRP was seen for smokers (OR, 2.16; 95% CI, 1.33-3.49) and those who never smoked (OR, 2.03; 95% CI, 1.19-3.46) with the highest level of CRP.Our results suggest that elevated CRP level is an independent risk factor for AMD and may implicate the role of inflammation in the pathogenesis of AMD.","Association between C-reactive protein and age-related macular degeneration."
"392","JAMA.255",NA,14871913,2004,"C-reactive protein (CRP) is a systemic inflammatory marker associated with risk for cardiovascular disease (CVD). Some risk factors for CVD are associated with age-related macular degeneration (AMD), but the association between CRP and AMD is unknown.To test the hypothesis that elevated CRP levels are associated with an increased risk for AMD.A total of 930 (91%) of 1026 participants at 2 centers in the Age-Related Eye Disease Study (AREDS), a multicenter randomized trial of antioxidant vitamins and minerals, were enrolled in this case-control study. There were 183 individuals without any maculopathy, 200 with mild maculopathy, 325 with intermediate disease, and 222 with advanced AMD (geographic atrophy or neovascular AMD). The AMD status was assessed by standardized grading of fundus photographs, and stored fasting blood specimens drawn between January 1996 and April 1997 were analyzed for high-sensitivity CRP levels.Association between CRP and AMD.The CRP levels were significantly higher among participants with advanced AMD (case patients) than among those with no AMD (controls; median values, 3.4 vs 2.7 mg/L; P =.02). After adjustment for age, sex, and other variables, including smoking and body mass index, CRP levels were significantly associated with the presence of intermediate and advanced stages of AMD. The odds ratio (OR) for the highest vs the lowest quartile of CRP was 1.65 (95% confidence interval [CI], 1.07-2.55; P for trend =.02). The OR for CRP values at or above the 90th percentile (10.6 mg/L) was 1.92 (95% CI, 1.20-3.06), and the OR for CRP values at or above the mean plus 2 SDs (16.8 mg/L) was 2.03 (95% CI, 1.03-4.00). A trend for an increased risk for intermediate and advanced AMD with higher levels of CRP was seen for smokers (OR, 2.16; 95% CI, 1.33-3.49) and those who never smoked (OR, 2.03; 95% CI, 1.19-3.46) with the highest level of CRP.Our results suggest that elevated CRP level is an independent risk factor for AMD and may implicate the role of inflammation in the pathogenesis of AMD.","Association between C-reactive protein and age-related macular degeneration."
"393","JAMA.255",NA,14871913,2004,"C-reactive protein (CRP) is a systemic inflammatory marker associated with risk for cardiovascular disease (CVD). Some risk factors for CVD are associated with age-related macular degeneration (AMD), but the association between CRP and AMD is unknown.To test the hypothesis that elevated CRP levels are associated with an increased risk for AMD.A total of 930 (91%) of 1026 participants at 2 centers in the Age-Related Eye Disease Study (AREDS), a multicenter randomized trial of antioxidant vitamins and minerals, were enrolled in this case-control study. There were 183 individuals without any maculopathy, 200 with mild maculopathy, 325 with intermediate disease, and 222 with advanced AMD (geographic atrophy or neovascular AMD). The AMD status was assessed by standardized grading of fundus photographs, and stored fasting blood specimens drawn between January 1996 and April 1997 were analyzed for high-sensitivity CRP levels.Association between CRP and AMD.The CRP levels were significantly higher among participants with advanced AMD (case patients) than among those with no AMD (controls; median values, 3.4 vs 2.7 mg/L; P =.02). After adjustment for age, sex, and other variables, including smoking and body mass index, CRP levels were significantly associated with the presence of intermediate and advanced stages of AMD. The odds ratio (OR) for the highest vs the lowest quartile of CRP was 1.65 (95% confidence interval [CI], 1.07-2.55; P for trend =.02). The OR for CRP values at or above the 90th percentile (10.6 mg/L) was 1.92 (95% CI, 1.20-3.06), and the OR for CRP values at or above the mean plus 2 SDs (16.8 mg/L) was 2.03 (95% CI, 1.03-4.00). A trend for an increased risk for intermediate and advanced AMD with higher levels of CRP was seen for smokers (OR, 2.16; 95% CI, 1.33-3.49) and those who never smoked (OR, 2.03; 95% CI, 1.19-3.46) with the highest level of CRP.Our results suggest that elevated CRP level is an independent risk factor for AMD and may implicate the role of inflammation in the pathogenesis of AMD.","Association between C-reactive protein and age-related macular degeneration."
"394","American Journal of Epidemiology.50","0.29",15003956,2004,"A C-to-T polymorphism in exon 2 of the cathepsin D gene encoding cathepsin D (CTSD) has been implicated as a risk factor for Alzheimer's disease. The authors performed a meta-analysis of 14 studies (16 comparisons) with CTSD genotyping (3,174 Alzheimer's disease cases and 3,298 controls). Overall, the random effects odds ratio for the T versus the C allele was 1.17 (95% confidence interval (CI): 0.95, 1.44), with some between-study heterogeneity (p < 0.01). There was significant between-study heterogeneity but no evidence of a significant association when the first hypothesis-generating study was excluded from the calculations (odds ratio (OR) = 1.11, 95% CI: 0.91, 1.35; p = 0.29). The summary odds ratio for T carriers versus T noncarriers was similar in subjects carrying or not carrying an apolipoprotein E epsilon4 allele (APOE*4). The increased susceptibility to Alzheimer's disease conferred by APOE*4 carriage tended to be more prominent in the presence of the T allele (random effects OR = 6.07, 95% CI: 4.19, 8.79, and OR = 4.09, 95% CI: 3.15, 5.31, in T carriers and noncarriers, respectively). The meta-analysis shows that the CTSD polymorphism is not a major risk factor for Alzheimer's disease, although a small effect or an enhancement of the APOE*4 effect cannot be excluded.","Meta-analysis of the association of the cathepsin D Ala224Val gene polymorphism with the risk of Alzheimer's disease: a HuGE gene-disease association review."
"395","American Journal of Epidemiology.50","NA",15003956,2004,"A C-to-T polymorphism in exon 2 of the cathepsin D gene encoding cathepsin D (CTSD) has been implicated as a risk factor for Alzheimer's disease. The authors performed a meta-analysis of 14 studies (16 comparisons) with CTSD genotyping (3,174 Alzheimer's disease cases and 3,298 controls). Overall, the random effects odds ratio for the T versus the C allele was 1.17 (95% confidence interval (CI): 0.95, 1.44), with some between-study heterogeneity (p < 0.01). There was significant between-study heterogeneity but no evidence of a significant association when the first hypothesis-generating study was excluded from the calculations (odds ratio (OR) = 1.11, 95% CI: 0.91, 1.35; p = 0.29). The summary odds ratio for T carriers versus T noncarriers was similar in subjects carrying or not carrying an apolipoprotein E epsilon4 allele (APOE*4). The increased susceptibility to Alzheimer's disease conferred by APOE*4 carriage tended to be more prominent in the presence of the T allele (random effects OR = 6.07, 95% CI: 4.19, 8.79, and OR = 4.09, 95% CI: 3.15, 5.31, in T carriers and noncarriers, respectively). The meta-analysis shows that the CTSD polymorphism is not a major risk factor for Alzheimer's disease, although a small effect or an enhancement of the APOE*4 effect cannot be excluded.","Meta-analysis of the association of the cathepsin D Ala224Val gene polymorphism with the risk of Alzheimer's disease: a HuGE gene-disease association review."
"396","American Journal of Epidemiology.50","NA",15003956,2004,"A C-to-T polymorphism in exon 2 of the cathepsin D gene encoding cathepsin D (CTSD) has been implicated as a risk factor for Alzheimer's disease. The authors performed a meta-analysis of 14 studies (16 comparisons) with CTSD genotyping (3,174 Alzheimer's disease cases and 3,298 controls). Overall, the random effects odds ratio for the T versus the C allele was 1.17 (95% confidence interval (CI): 0.95, 1.44), with some between-study heterogeneity (p < 0.01). There was significant between-study heterogeneity but no evidence of a significant association when the first hypothesis-generating study was excluded from the calculations (odds ratio (OR) = 1.11, 95% CI: 0.91, 1.35; p = 0.29). The summary odds ratio for T carriers versus T noncarriers was similar in subjects carrying or not carrying an apolipoprotein E epsilon4 allele (APOE*4). The increased susceptibility to Alzheimer's disease conferred by APOE*4 carriage tended to be more prominent in the presence of the T allele (random effects OR = 6.07, 95% CI: 4.19, 8.79, and OR = 4.09, 95% CI: 3.15, 5.31, in T carriers and noncarriers, respectively). The meta-analysis shows that the CTSD polymorphism is not a major risk factor for Alzheimer's disease, although a small effect or an enhancement of the APOE*4 effect cannot be excluded.","Meta-analysis of the association of the cathepsin D Ala224Val gene polymorphism with the risk of Alzheimer's disease: a HuGE gene-disease association review."
"397","JAMA.1691","0.001",15026399,2004,"Salvage radiotherapy may potentially cure patients with disease recurrence after radical prostatectomy, but previous evidence has suggested that it is ineffective in patients at the highest risk of metastatic disease progression.To delineate patients who may benefit from salvage radiotherapy for prostate cancer recurrence by identifying variables associated with a durable response.Retrospective review of a cohort of 501 patients at 5 US academic tertiary referral centers who received salvage radiotherapy between June 1987 and November 2002 for detectable and increasing prostate-specific antigen (PSA) levels after radical prostatectomy.Disease progression after salvage radiotherapy, defined as a serum PSA value > or =0.1 ng/mL above the postradiotherapy PSA nadir confirmed by a second PSA measurement that was higher than the first by any amount, by a continued increase in PSA level after treatment, or by the initiation of androgen deprivation therapy after treatment.Over a median follow-up of 45 months, 250 patients (50%) experienced disease progression after treatment, 49 (10%) developed distant metastases, 20 (4%) died from prostate cancer, and 21 (4%) died from other or unknown causes. The 4-year progression-free probability (PFP) was 45% (95% confidence interval [CI], 40%-50%). By multivariable analysis, predictors of progression were Gleason score of 8 to 10 (hazard ratio [HR], 2.6; 95% CI, 1.7-4.1; P<.001), preradiotherapy PSA level greater than 2.0 ng/mL (HR, 2.3; 95% CI, 1.7-3.2; P<.001), negative surgical margins (HR, 1.9; 95% CI, 1.4-2.5; P<.001), PSA doubling time (PSADT) of 10 months or less (HR, 1.7; 95% CI, 1.2-2.2; P =.001), and seminal vesicle invasion (HR, 1.4; 95% CI, 1.1-1.9; P =.02). Patients with no adverse features had a 4-year PFP of 77% (95% CI, 64%-91%). When treatment was given for early recurrence (PSA level < or =2.0 ng/mL), patients with Gleason scores of 4 to 7 and a rapid PSADT had a 4-year PFP of 64% (95% CI, 51%-76%) and of 22% (95% CI, 6%-38%) when the surgical margins were positive and negative, respectively. Patients with Gleason scores of 8 to 10, positive margins, and receiving early salvage radiotherapy had a 4-year PFP of 81% (95% CI, 57%-100%) when the PSADT was longer than 10 months and of 37% (95% CI, 16%-58%) when the PSADT was 10 months or less.Gleason score, preradiotherapy PSA level, surgical margins, PSADT, and seminal vesicle invasion are prognostic variables for a durable response to salvage radiotherapy. Selected patients with high-grade disease and/or a rapid PSADT who were previously thought to be destined to develop progressive metastatic disease may achieve a durable response to salvage radiotherapy.","Salvage radiotherapy for recurrent prostate cancer after radical prostatectomy."
"398","JAMA.1701","0.001",15026399,2004,"Salvage radiotherapy may potentially cure patients with disease recurrence after radical prostatectomy, but previous evidence has suggested that it is ineffective in patients at the highest risk of metastatic disease progression.To delineate patients who may benefit from salvage radiotherapy for prostate cancer recurrence by identifying variables associated with a durable response.Retrospective review of a cohort of 501 patients at 5 US academic tertiary referral centers who received salvage radiotherapy between June 1987 and November 2002 for detectable and increasing prostate-specific antigen (PSA) levels after radical prostatectomy.Disease progression after salvage radiotherapy, defined as a serum PSA value > or =0.1 ng/mL above the postradiotherapy PSA nadir confirmed by a second PSA measurement that was higher than the first by any amount, by a continued increase in PSA level after treatment, or by the initiation of androgen deprivation therapy after treatment.Over a median follow-up of 45 months, 250 patients (50%) experienced disease progression after treatment, 49 (10%) developed distant metastases, 20 (4%) died from prostate cancer, and 21 (4%) died from other or unknown causes. The 4-year progression-free probability (PFP) was 45% (95% confidence interval [CI], 40%-50%). By multivariable analysis, predictors of progression were Gleason score of 8 to 10 (hazard ratio [HR], 2.6; 95% CI, 1.7-4.1; P<.001), preradiotherapy PSA level greater than 2.0 ng/mL (HR, 2.3; 95% CI, 1.7-3.2; P<.001), negative surgical margins (HR, 1.9; 95% CI, 1.4-2.5; P<.001), PSA doubling time (PSADT) of 10 months or less (HR, 1.7; 95% CI, 1.2-2.2; P =.001), and seminal vesicle invasion (HR, 1.4; 95% CI, 1.1-1.9; P =.02). Patients with no adverse features had a 4-year PFP of 77% (95% CI, 64%-91%). When treatment was given for early recurrence (PSA level < or =2.0 ng/mL), patients with Gleason scores of 4 to 7 and a rapid PSADT had a 4-year PFP of 64% (95% CI, 51%-76%) and of 22% (95% CI, 6%-38%) when the surgical margins were positive and negative, respectively. Patients with Gleason scores of 8 to 10, positive margins, and receiving early salvage radiotherapy had a 4-year PFP of 81% (95% CI, 57%-100%) when the PSADT was longer than 10 months and of 37% (95% CI, 16%-58%) when the PSADT was 10 months or less.Gleason score, preradiotherapy PSA level, surgical margins, PSADT, and seminal vesicle invasion are prognostic variables for a durable response to salvage radiotherapy. Selected patients with high-grade disease and/or a rapid PSADT who were previously thought to be destined to develop progressive metastatic disease may achieve a durable response to salvage radiotherapy.","Salvage radiotherapy for recurrent prostate cancer after radical prostatectomy."
"399","JAMA.1711","0.001",15026399,2004,"Salvage radiotherapy may potentially cure patients with disease recurrence after radical prostatectomy, but previous evidence has suggested that it is ineffective in patients at the highest risk of metastatic disease progression.To delineate patients who may benefit from salvage radiotherapy for prostate cancer recurrence by identifying variables associated with a durable response.Retrospective review of a cohort of 501 patients at 5 US academic tertiary referral centers who received salvage radiotherapy between June 1987 and November 2002 for detectable and increasing prostate-specific antigen (PSA) levels after radical prostatectomy.Disease progression after salvage radiotherapy, defined as a serum PSA value > or =0.1 ng/mL above the postradiotherapy PSA nadir confirmed by a second PSA measurement that was higher than the first by any amount, by a continued increase in PSA level after treatment, or by the initiation of androgen deprivation therapy after treatment.Over a median follow-up of 45 months, 250 patients (50%) experienced disease progression after treatment, 49 (10%) developed distant metastases, 20 (4%) died from prostate cancer, and 21 (4%) died from other or unknown causes. The 4-year progression-free probability (PFP) was 45% (95% confidence interval [CI], 40%-50%). By multivariable analysis, predictors of progression were Gleason score of 8 to 10 (hazard ratio [HR], 2.6; 95% CI, 1.7-4.1; P<.001), preradiotherapy PSA level greater than 2.0 ng/mL (HR, 2.3; 95% CI, 1.7-3.2; P<.001), negative surgical margins (HR, 1.9; 95% CI, 1.4-2.5; P<.001), PSA doubling time (PSADT) of 10 months or less (HR, 1.7; 95% CI, 1.2-2.2; P =.001), and seminal vesicle invasion (HR, 1.4; 95% CI, 1.1-1.9; P =.02). Patients with no adverse features had a 4-year PFP of 77% (95% CI, 64%-91%). When treatment was given for early recurrence (PSA level < or =2.0 ng/mL), patients with Gleason scores of 4 to 7 and a rapid PSADT had a 4-year PFP of 64% (95% CI, 51%-76%) and of 22% (95% CI, 6%-38%) when the surgical margins were positive and negative, respectively. Patients with Gleason scores of 8 to 10, positive margins, and receiving early salvage radiotherapy had a 4-year PFP of 81% (95% CI, 57%-100%) when the PSADT was longer than 10 months and of 37% (95% CI, 16%-58%) when the PSADT was 10 months or less.Gleason score, preradiotherapy PSA level, surgical margins, PSADT, and seminal vesicle invasion are prognostic variables for a durable response to salvage radiotherapy. Selected patients with high-grade disease and/or a rapid PSADT who were previously thought to be destined to develop progressive metastatic disease may achieve a durable response to salvage radiotherapy.","Salvage radiotherapy for recurrent prostate cancer after radical prostatectomy."
"400","JAMA.2231","0.001",15026399,2004,"Salvage radiotherapy may potentially cure patients with disease recurrence after radical prostatectomy, but previous evidence has suggested that it is ineffective in patients at the highest risk of metastatic disease progression.To delineate patients who may benefit from salvage radiotherapy for prostate cancer recurrence by identifying variables associated with a durable response.Retrospective review of a cohort of 501 patients at 5 US academic tertiary referral centers who received salvage radiotherapy between June 1987 and November 2002 for detectable and increasing prostate-specific antigen (PSA) levels after radical prostatectomy.Disease progression after salvage radiotherapy, defined as a serum PSA value > or =0.1 ng/mL above the postradiotherapy PSA nadir confirmed by a second PSA measurement that was higher than the first by any amount, by a continued increase in PSA level after treatment, or by the initiation of androgen deprivation therapy after treatment.Over a median follow-up of 45 months, 250 patients (50%) experienced disease progression after treatment, 49 (10%) developed distant metastases, 20 (4%) died from prostate cancer, and 21 (4%) died from other or unknown causes. The 4-year progression-free probability (PFP) was 45% (95% confidence interval [CI], 40%-50%). By multivariable analysis, predictors of progression were Gleason score of 8 to 10 (hazard ratio [HR], 2.6; 95% CI, 1.7-4.1; P<.001), preradiotherapy PSA level greater than 2.0 ng/mL (HR, 2.3; 95% CI, 1.7-3.2; P<.001), negative surgical margins (HR, 1.9; 95% CI, 1.4-2.5; P<.001), PSA doubling time (PSADT) of 10 months or less (HR, 1.7; 95% CI, 1.2-2.2; P =.001), and seminal vesicle invasion (HR, 1.4; 95% CI, 1.1-1.9; P =.02). Patients with no adverse features had a 4-year PFP of 77% (95% CI, 64%-91%). When treatment was given for early recurrence (PSA level < or =2.0 ng/mL), patients with Gleason scores of 4 to 7 and a rapid PSADT had a 4-year PFP of 64% (95% CI, 51%-76%) and of 22% (95% CI, 6%-38%) when the surgical margins were positive and negative, respectively. Patients with Gleason scores of 8 to 10, positive margins, and receiving early salvage radiotherapy had a 4-year PFP of 81% (95% CI, 57%-100%) when the PSADT was longer than 10 months and of 37% (95% CI, 16%-58%) when the PSADT was 10 months or less.Gleason score, preradiotherapy PSA level, surgical margins, PSADT, and seminal vesicle invasion are prognostic variables for a durable response to salvage radiotherapy. Selected patients with high-grade disease and/or a rapid PSADT who were previously thought to be destined to develop progressive metastatic disease may achieve a durable response to salvage radiotherapy.","Salvage radiotherapy for recurrent prostate cancer after radical prostatectomy."
"401","JAMA.2241","0.02",15026399,2004,"Salvage radiotherapy may potentially cure patients with disease recurrence after radical prostatectomy, but previous evidence has suggested that it is ineffective in patients at the highest risk of metastatic disease progression.To delineate patients who may benefit from salvage radiotherapy for prostate cancer recurrence by identifying variables associated with a durable response.Retrospective review of a cohort of 501 patients at 5 US academic tertiary referral centers who received salvage radiotherapy between June 1987 and November 2002 for detectable and increasing prostate-specific antigen (PSA) levels after radical prostatectomy.Disease progression after salvage radiotherapy, defined as a serum PSA value > or =0.1 ng/mL above the postradiotherapy PSA nadir confirmed by a second PSA measurement that was higher than the first by any amount, by a continued increase in PSA level after treatment, or by the initiation of androgen deprivation therapy after treatment.Over a median follow-up of 45 months, 250 patients (50%) experienced disease progression after treatment, 49 (10%) developed distant metastases, 20 (4%) died from prostate cancer, and 21 (4%) died from other or unknown causes. The 4-year progression-free probability (PFP) was 45% (95% confidence interval [CI], 40%-50%). By multivariable analysis, predictors of progression were Gleason score of 8 to 10 (hazard ratio [HR], 2.6; 95% CI, 1.7-4.1; P<.001), preradiotherapy PSA level greater than 2.0 ng/mL (HR, 2.3; 95% CI, 1.7-3.2; P<.001), negative surgical margins (HR, 1.9; 95% CI, 1.4-2.5; P<.001), PSA doubling time (PSADT) of 10 months or less (HR, 1.7; 95% CI, 1.2-2.2; P =.001), and seminal vesicle invasion (HR, 1.4; 95% CI, 1.1-1.9; P =.02). Patients with no adverse features had a 4-year PFP of 77% (95% CI, 64%-91%). When treatment was given for early recurrence (PSA level < or =2.0 ng/mL), patients with Gleason scores of 4 to 7 and a rapid PSADT had a 4-year PFP of 64% (95% CI, 51%-76%) and of 22% (95% CI, 6%-38%) when the surgical margins were positive and negative, respectively. Patients with Gleason scores of 8 to 10, positive margins, and receiving early salvage radiotherapy had a 4-year PFP of 81% (95% CI, 57%-100%) when the PSADT was longer than 10 months and of 37% (95% CI, 16%-58%) when the PSADT was 10 months or less.Gleason score, preradiotherapy PSA level, surgical margins, PSADT, and seminal vesicle invasion are prognostic variables for a durable response to salvage radiotherapy. Selected patients with high-grade disease and/or a rapid PSADT who were previously thought to be destined to develop progressive metastatic disease may achieve a durable response to salvage radiotherapy.","Salvage radiotherapy for recurrent prostate cancer after radical prostatectomy."
"402","JAMA.1671","0.001",15082703,2004,"In the intensive care unit (ICU), delirium is a common yet underdiagnosed form of organ dysfunction, and its contribution to patient outcomes is unclear.To determine if delirium is an independent predictor of clinical outcomes, including 6-month mortality and length of stay among ICU patients receiving mechanical ventilation.Prospective cohort study enrolling 275 consecutive mechanically ventilated patients admitted to adult medical and coronary ICUs of a US university-based medical center between February 2000 and May 2001. Patients were followed up for development of delirium over 2158 ICU days using the Confusion Assessment Method for the ICU and the Richmond Agitation-Sedation Scale.Primary outcomes included 6-month mortality, overall hospital length of stay, and length of stay in the post-ICU period. Secondary outcomes were ventilator-free days and cognitive impairment at hospital discharge.Of 275 patients, 51 (18.5%) had persistent coma and died in the hospital. Among the remaining 224 patients, 183 (81.7%) developed delirium at some point during the ICU stay. Baseline demographics including age, comorbidity scores, dementia scores, activities of daily living, severity of illness, and admission diagnoses were similar between those with and without delirium (P>.05 for all). Patients who developed delirium had higher 6-month mortality rates (34% vs 15%, P =.03) and spent 10 days longer in the hospital than those who never developed delirium (P<.001). After adjusting for covariates (including age, severity of illness, comorbid conditions, coma, and use of sedatives or analgesic medications), delirium was independently associated with higher 6-month mortality (adjusted hazard ratio [HR], 3.2; 95% confidence interval [CI], 1.4-7.7; P =.008), and longer hospital stay (adjusted HR, 2.0; 95% CI, 1.4-3.0; P<.001). Delirium in the ICU was also independently associated with a longer post-ICU stay (adjusted HR, 1.6; 95% CI, 1.2-2.3; P =.009), fewer median days alive and without mechanical ventilation (19 [interquartile range, 4-23] vs 24 [19-26]; adjusted P =.03), and a higher incidence of cognitive impairment at hospital discharge (adjusted HR, 9.1; 95% CI, 2.3-35.3; P =.002).Delirium was an independent predictor of higher 6-month mortality and longer hospital stay even after adjusting for relevant covariates including coma, sedatives, and analgesics in patients receiving mechanical ventilation.","Delirium as a predictor of mortality in mechanically ventilated patients in the intensive care unit."
"403","JAMA.2191","0.008",15082703,2004,"In the intensive care unit (ICU), delirium is a common yet underdiagnosed form of organ dysfunction, and its contribution to patient outcomes is unclear.To determine if delirium is an independent predictor of clinical outcomes, including 6-month mortality and length of stay among ICU patients receiving mechanical ventilation.Prospective cohort study enrolling 275 consecutive mechanically ventilated patients admitted to adult medical and coronary ICUs of a US university-based medical center between February 2000 and May 2001. Patients were followed up for development of delirium over 2158 ICU days using the Confusion Assessment Method for the ICU and the Richmond Agitation-Sedation Scale.Primary outcomes included 6-month mortality, overall hospital length of stay, and length of stay in the post-ICU period. Secondary outcomes were ventilator-free days and cognitive impairment at hospital discharge.Of 275 patients, 51 (18.5%) had persistent coma and died in the hospital. Among the remaining 224 patients, 183 (81.7%) developed delirium at some point during the ICU stay. Baseline demographics including age, comorbidity scores, dementia scores, activities of daily living, severity of illness, and admission diagnoses were similar between those with and without delirium (P>.05 for all). Patients who developed delirium had higher 6-month mortality rates (34% vs 15%, P =.03) and spent 10 days longer in the hospital than those who never developed delirium (P<.001). After adjusting for covariates (including age, severity of illness, comorbid conditions, coma, and use of sedatives or analgesic medications), delirium was independently associated with higher 6-month mortality (adjusted hazard ratio [HR], 3.2; 95% confidence interval [CI], 1.4-7.7; P =.008), and longer hospital stay (adjusted HR, 2.0; 95% CI, 1.4-3.0; P<.001). Delirium in the ICU was also independently associated with a longer post-ICU stay (adjusted HR, 1.6; 95% CI, 1.2-2.3; P =.009), fewer median days alive and without mechanical ventilation (19 [interquartile range, 4-23] vs 24 [19-26]; adjusted P =.03), and a higher incidence of cognitive impairment at hospital discharge (adjusted HR, 9.1; 95% CI, 2.3-35.3; P =.002).Delirium was an independent predictor of higher 6-month mortality and longer hospital stay even after adjusting for relevant covariates including coma, sedatives, and analgesics in patients receiving mechanical ventilation.","Delirium as a predictor of mortality in mechanically ventilated patients in the intensive care unit."
"404","JAMA.2201","0.009",15082703,2004,"In the intensive care unit (ICU), delirium is a common yet underdiagnosed form of organ dysfunction, and its contribution to patient outcomes is unclear.To determine if delirium is an independent predictor of clinical outcomes, including 6-month mortality and length of stay among ICU patients receiving mechanical ventilation.Prospective cohort study enrolling 275 consecutive mechanically ventilated patients admitted to adult medical and coronary ICUs of a US university-based medical center between February 2000 and May 2001. Patients were followed up for development of delirium over 2158 ICU days using the Confusion Assessment Method for the ICU and the Richmond Agitation-Sedation Scale.Primary outcomes included 6-month mortality, overall hospital length of stay, and length of stay in the post-ICU period. Secondary outcomes were ventilator-free days and cognitive impairment at hospital discharge.Of 275 patients, 51 (18.5%) had persistent coma and died in the hospital. Among the remaining 224 patients, 183 (81.7%) developed delirium at some point during the ICU stay. Baseline demographics including age, comorbidity scores, dementia scores, activities of daily living, severity of illness, and admission diagnoses were similar between those with and without delirium (P>.05 for all). Patients who developed delirium had higher 6-month mortality rates (34% vs 15%, P =.03) and spent 10 days longer in the hospital than those who never developed delirium (P<.001). After adjusting for covariates (including age, severity of illness, comorbid conditions, coma, and use of sedatives or analgesic medications), delirium was independently associated with higher 6-month mortality (adjusted hazard ratio [HR], 3.2; 95% confidence interval [CI], 1.4-7.7; P =.008), and longer hospital stay (adjusted HR, 2.0; 95% CI, 1.4-3.0; P<.001). Delirium in the ICU was also independently associated with a longer post-ICU stay (adjusted HR, 1.6; 95% CI, 1.2-2.3; P =.009), fewer median days alive and without mechanical ventilation (19 [interquartile range, 4-23] vs 24 [19-26]; adjusted P =.03), and a higher incidence of cognitive impairment at hospital discharge (adjusted HR, 9.1; 95% CI, 2.3-35.3; P =.002).Delirium was an independent predictor of higher 6-month mortality and longer hospital stay even after adjusting for relevant covariates including coma, sedatives, and analgesics in patients receiving mechanical ventilation.","Delirium as a predictor of mortality in mechanically ventilated patients in the intensive care unit."
"405","JAMA.2221","0.002",15082703,2004,"In the intensive care unit (ICU), delirium is a common yet underdiagnosed form of organ dysfunction, and its contribution to patient outcomes is unclear.To determine if delirium is an independent predictor of clinical outcomes, including 6-month mortality and length of stay among ICU patients receiving mechanical ventilation.Prospective cohort study enrolling 275 consecutive mechanically ventilated patients admitted to adult medical and coronary ICUs of a US university-based medical center between February 2000 and May 2001. Patients were followed up for development of delirium over 2158 ICU days using the Confusion Assessment Method for the ICU and the Richmond Agitation-Sedation Scale.Primary outcomes included 6-month mortality, overall hospital length of stay, and length of stay in the post-ICU period. Secondary outcomes were ventilator-free days and cognitive impairment at hospital discharge.Of 275 patients, 51 (18.5%) had persistent coma and died in the hospital. Among the remaining 224 patients, 183 (81.7%) developed delirium at some point during the ICU stay. Baseline demographics including age, comorbidity scores, dementia scores, activities of daily living, severity of illness, and admission diagnoses were similar between those with and without delirium (P>.05 for all). Patients who developed delirium had higher 6-month mortality rates (34% vs 15%, P =.03) and spent 10 days longer in the hospital than those who never developed delirium (P<.001). After adjusting for covariates (including age, severity of illness, comorbid conditions, coma, and use of sedatives or analgesic medications), delirium was independently associated with higher 6-month mortality (adjusted hazard ratio [HR], 3.2; 95% confidence interval [CI], 1.4-7.7; P =.008), and longer hospital stay (adjusted HR, 2.0; 95% CI, 1.4-3.0; P<.001). Delirium in the ICU was also independently associated with a longer post-ICU stay (adjusted HR, 1.6; 95% CI, 1.2-2.3; P =.009), fewer median days alive and without mechanical ventilation (19 [interquartile range, 4-23] vs 24 [19-26]; adjusted P =.03), and a higher incidence of cognitive impairment at hospital discharge (adjusted HR, 9.1; 95% CI, 2.3-35.3; P =.002).Delirium was an independent predictor of higher 6-month mortality and longer hospital stay even after adjusting for relevant covariates including coma, sedatives, and analgesics in patients receiving mechanical ventilation.","Delirium as a predictor of mortality in mechanically ventilated patients in the intensive care unit."
"406","JAMA.251","0.03",15113817,2004,"Both high- and low-dose radiation exposures in women have been associated with low-birth-weight offspring. It is unclear if radiation affects the hypothalamus-pituitary-thyroid axis and thereby indirectly birth weight, or if the radiation directly affects the reproductive organs.To investigate whether antepartum dental radiography is associated with low-birth-weight offspring.A population-based case-control study.Enrollees of a dental insurance plan with live singleton births in Washington State between January 1993 and December 2000. Cases were 1117 women with low-birth-weight infants (<2500 g), of whom 336 were term low-birth-weight infants (1501-2499 g and gestation > or =37 weeks). Four control pregnancies resulting in normal-birth-weight infants (> or =2500 g) were randomly selected for each case (n = 4468).Odds of low birth weight and term low birth weight by dental radiographic dose during gestation.An exposure higher than 0.4 milligray (mGy) during gestation occurred in 21 (1.9%) mothers of low-birth-weight infants and, when compared with women who had no known dental radiography, was associated with an adjusted odds ratio (OR) for a low-birth-weight infant of 2.27 (95% confidence interval [CI], 1.11-4.66, P =.03). Exposure higher than 0.4 mGy occurred in 10 (3%) term low-birth-weight pregnancies and was associated with an adjusted OR for a term low-birth-weight infant of 3.61 (95% CI, 1.46-8.92, P =.005).Dental radiography during pregnancy is associated with low birth weight, specifically with term low birth weight.","Antepartum dental radiography and infant low birth weight."
"407","JAMA.252","0.005",15113817,2004,"Both high- and low-dose radiation exposures in women have been associated with low-birth-weight offspring. It is unclear if radiation affects the hypothalamus-pituitary-thyroid axis and thereby indirectly birth weight, or if the radiation directly affects the reproductive organs.To investigate whether antepartum dental radiography is associated with low-birth-weight offspring.A population-based case-control study.Enrollees of a dental insurance plan with live singleton births in Washington State between January 1993 and December 2000. Cases were 1117 women with low-birth-weight infants (<2500 g), of whom 336 were term low-birth-weight infants (1501-2499 g and gestation > or =37 weeks). Four control pregnancies resulting in normal-birth-weight infants (> or =2500 g) were randomly selected for each case (n = 4468).Odds of low birth weight and term low birth weight by dental radiographic dose during gestation.An exposure higher than 0.4 milligray (mGy) during gestation occurred in 21 (1.9%) mothers of low-birth-weight infants and, when compared with women who had no known dental radiography, was associated with an adjusted odds ratio (OR) for a low-birth-weight infant of 2.27 (95% confidence interval [CI], 1.11-4.66, P =.03). Exposure higher than 0.4 mGy occurred in 10 (3%) term low-birth-weight pregnancies and was associated with an adjusted OR for a term low-birth-weight infant of 3.61 (95% CI, 1.46-8.92, P =.005).Dental radiography during pregnancy is associated with low birth weight, specifically with term low birth weight.","Antepartum dental radiography and infant low birth weight."
"408","JAMA.231","NA",15126437,2004,"Cardiovascular complications following major noncardiac surgery are an important source of perioperative morbidity and mortality. Although lipid-lowering medications are considered a key component in the primary and secondary prevention of cardiovascular disease, their potential benefit during the perioperative period is uncertain.To examine the association between treatment with lipid-lowering medications and in-hospital mortality following major noncardiac surgery.A retrospective cohort study based on hospital discharge and pharmacy records of 780,591 patients aged 18 years or older who underwent major noncardiac surgery from January 1, 2000, to December 31, 2001, at any 1 of 329 hospitals throughout the United States. Only patients who survived through at least the second hospital day were included. Lipid-lowering therapy was defined as use during the first 2 hospital days. Propensity matching was used to adjust for numerous baseline differences.In-hospital mortality.Of the 780,591 patients, 77,082 patients (9.9%) received lipid-lowering therapy perioperatively and 23 100 (2.96%) died during the hospitalization. Treatment with lipid-lowering agents was associated with lower crude mortality (2.13% vs 3.05%, P<.001). In an analysis using matching by propensity score, 1595 patients (2.18%) treated with lipid-lowering medications died compared with 4158 patients (3.15%) who did not receive therapy or in whom treatment was initiated after the second day (P<.001). After adjusting for residual differences in the propensity matched groups using conditional logistic regression, risk of mortality remained lower among treated patients (adjusted odds ratio [OR], 0.62; 95% confidence interval [CI], 0.58-0.67). Based on this adjusted OR, the number needed to treat to prevent a postoperative death in the propensity matched cohort was 85 (95% CI, 77-98) and varied from 186 among patients at lowest risk to 30 among those with a revised cardiac risk index score of 4 or more. In a further analysis using the entire study cohort and adjusting for quintile of propensity, a significant effect of treatment persisted (adjusted OR, 0.71; 95% CI, 0.67-0.75).Treatment with lipid-lowering agents may reduce risk of death following major noncardiac surgery. Clinical trials are required to confirm this observation.","Lipid-lowering therapy and in-hospital mortality following major noncardiac surgery."
"409","JAMA.232","NA",15126437,2004,"Cardiovascular complications following major noncardiac surgery are an important source of perioperative morbidity and mortality. Although lipid-lowering medications are considered a key component in the primary and secondary prevention of cardiovascular disease, their potential benefit during the perioperative period is uncertain.To examine the association between treatment with lipid-lowering medications and in-hospital mortality following major noncardiac surgery.A retrospective cohort study based on hospital discharge and pharmacy records of 780,591 patients aged 18 years or older who underwent major noncardiac surgery from January 1, 2000, to December 31, 2001, at any 1 of 329 hospitals throughout the United States. Only patients who survived through at least the second hospital day were included. Lipid-lowering therapy was defined as use during the first 2 hospital days. Propensity matching was used to adjust for numerous baseline differences.In-hospital mortality.Of the 780,591 patients, 77,082 patients (9.9%) received lipid-lowering therapy perioperatively and 23 100 (2.96%) died during the hospitalization. Treatment with lipid-lowering agents was associated with lower crude mortality (2.13% vs 3.05%, P<.001). In an analysis using matching by propensity score, 1595 patients (2.18%) treated with lipid-lowering medications died compared with 4158 patients (3.15%) who did not receive therapy or in whom treatment was initiated after the second day (P<.001). After adjusting for residual differences in the propensity matched groups using conditional logistic regression, risk of mortality remained lower among treated patients (adjusted odds ratio [OR], 0.62; 95% confidence interval [CI], 0.58-0.67). Based on this adjusted OR, the number needed to treat to prevent a postoperative death in the propensity matched cohort was 85 (95% CI, 77-98) and varied from 186 among patients at lowest risk to 30 among those with a revised cardiac risk index score of 4 or more. In a further analysis using the entire study cohort and adjusting for quintile of propensity, a significant effect of treatment persisted (adjusted OR, 0.71; 95% CI, 0.67-0.75).Treatment with lipid-lowering agents may reduce risk of death following major noncardiac surgery. Clinical trials are required to confirm this observation.","Lipid-lowering therapy and in-hospital mortality following major noncardiac surgery."
"410","JAMA.226","0.001",15187053,2004,"Despite the importance of diversity of cancer trial participants with regard to race, ethnicity, age, and sex, there is little recent information about the representation of these groups in clinical trials.To characterize the representation of racial and ethnic minorities, the elderly, and women in cancer trials sponsored by the National Cancer Institute.Cross-sectional population-based analysis of all participants in therapeutic nonsurgical National Cancer Institute Clinical Trial Cooperative Group breast, colorectal, lung, and prostate cancer clinical trials in 2000 through 2002. In a separate analysis, the ethnic distribution of patients enrolled in 2000 through 2002 was compared with those enrolled in 1996 through 1998, using logistic regression models to estimate the relative risk ratio of enrollment for racial and ethnic minorities to that of white patients during these time periods.Enrollment fraction, defined as the number of trial enrollees divided by the estimated US cancer cases in each race and age subgroup.Cancer research participation varied significantly across racial/ethnic and age groups. Compared with a 1.8% enrollment fraction among white patients, lower enrollment fractions were noted in Hispanic (1.3%; odds ratio [OR] vs whites, 0.72; 95% confidence interval [CI], 0.68-0.77; P<.001) and black (1.3%; OR, 0.71; 95% CI, 0.68-0.74; P<.001) patients. There was a strong relationship between age and enrollment fraction, with trial participants 30 to 64 years of age representing 3.0% of incident cancer patients in that age group, in comparison to 1.3% of 65- to 74-year-old patients and 0.5% of patients 75 years of age and older. This inverse relationship between age and trial enrollment fraction was consistent across racial and ethnic groups. Although the total number of trial participants increased during our study period, the representation of racial and ethnic minorities decreased. In comparison to whites, after adjusting for age, cancer type, and sex, patients enrolled in 2000 through 2002 were 24% less likely to be black (adjusted relative risk ratio, 0.76; 95% CI, 0.65-0.89; P<.001). Men were more likely than women to enroll in colorectal cancer trials (enrollment fractions: 2.1% vs 1.6%, respectively; OR, 1.30; 95% CI, 1.24-1.35; P<.001) and lung cancer trials (enrollment fractions: 0.9% vs 0.7%, respectively; OR, 1.23; 95% CI, 1.16-1.31; P<.001).Enrollment in cancer trials is low for all patient groups. Racial and ethnic minorities, women, and the elderly were less likely to enroll in cooperative group cancer trials than were whites, men, and younger patients, respectively. The proportion of trial participants who are black has declined in recent years.","Participation in cancer clinical trials: race-, sex-, and age-based disparities."
"411","JAMA.227","0.001",15187053,2004,"Despite the importance of diversity of cancer trial participants with regard to race, ethnicity, age, and sex, there is little recent information about the representation of these groups in clinical trials.To characterize the representation of racial and ethnic minorities, the elderly, and women in cancer trials sponsored by the National Cancer Institute.Cross-sectional population-based analysis of all participants in therapeutic nonsurgical National Cancer Institute Clinical Trial Cooperative Group breast, colorectal, lung, and prostate cancer clinical trials in 2000 through 2002. In a separate analysis, the ethnic distribution of patients enrolled in 2000 through 2002 was compared with those enrolled in 1996 through 1998, using logistic regression models to estimate the relative risk ratio of enrollment for racial and ethnic minorities to that of white patients during these time periods.Enrollment fraction, defined as the number of trial enrollees divided by the estimated US cancer cases in each race and age subgroup.Cancer research participation varied significantly across racial/ethnic and age groups. Compared with a 1.8% enrollment fraction among white patients, lower enrollment fractions were noted in Hispanic (1.3%; odds ratio [OR] vs whites, 0.72; 95% confidence interval [CI], 0.68-0.77; P<.001) and black (1.3%; OR, 0.71; 95% CI, 0.68-0.74; P<.001) patients. There was a strong relationship between age and enrollment fraction, with trial participants 30 to 64 years of age representing 3.0% of incident cancer patients in that age group, in comparison to 1.3% of 65- to 74-year-old patients and 0.5% of patients 75 years of age and older. This inverse relationship between age and trial enrollment fraction was consistent across racial and ethnic groups. Although the total number of trial participants increased during our study period, the representation of racial and ethnic minorities decreased. In comparison to whites, after adjusting for age, cancer type, and sex, patients enrolled in 2000 through 2002 were 24% less likely to be black (adjusted relative risk ratio, 0.76; 95% CI, 0.65-0.89; P<.001). Men were more likely than women to enroll in colorectal cancer trials (enrollment fractions: 2.1% vs 1.6%, respectively; OR, 1.30; 95% CI, 1.24-1.35; P<.001) and lung cancer trials (enrollment fractions: 0.9% vs 0.7%, respectively; OR, 1.23; 95% CI, 1.16-1.31; P<.001).Enrollment in cancer trials is low for all patient groups. Racial and ethnic minorities, women, and the elderly were less likely to enroll in cooperative group cancer trials than were whites, men, and younger patients, respectively. The proportion of trial participants who are black has declined in recent years.","Participation in cancer clinical trials: race-, sex-, and age-based disparities."
"412","JAMA.228","0.001",15187053,2004,"Despite the importance of diversity of cancer trial participants with regard to race, ethnicity, age, and sex, there is little recent information about the representation of these groups in clinical trials.To characterize the representation of racial and ethnic minorities, the elderly, and women in cancer trials sponsored by the National Cancer Institute.Cross-sectional population-based analysis of all participants in therapeutic nonsurgical National Cancer Institute Clinical Trial Cooperative Group breast, colorectal, lung, and prostate cancer clinical trials in 2000 through 2002. In a separate analysis, the ethnic distribution of patients enrolled in 2000 through 2002 was compared with those enrolled in 1996 through 1998, using logistic regression models to estimate the relative risk ratio of enrollment for racial and ethnic minorities to that of white patients during these time periods.Enrollment fraction, defined as the number of trial enrollees divided by the estimated US cancer cases in each race and age subgroup.Cancer research participation varied significantly across racial/ethnic and age groups. Compared with a 1.8% enrollment fraction among white patients, lower enrollment fractions were noted in Hispanic (1.3%; odds ratio [OR] vs whites, 0.72; 95% confidence interval [CI], 0.68-0.77; P<.001) and black (1.3%; OR, 0.71; 95% CI, 0.68-0.74; P<.001) patients. There was a strong relationship between age and enrollment fraction, with trial participants 30 to 64 years of age representing 3.0% of incident cancer patients in that age group, in comparison to 1.3% of 65- to 74-year-old patients and 0.5% of patients 75 years of age and older. This inverse relationship between age and trial enrollment fraction was consistent across racial and ethnic groups. Although the total number of trial participants increased during our study period, the representation of racial and ethnic minorities decreased. In comparison to whites, after adjusting for age, cancer type, and sex, patients enrolled in 2000 through 2002 were 24% less likely to be black (adjusted relative risk ratio, 0.76; 95% CI, 0.65-0.89; P<.001). Men were more likely than women to enroll in colorectal cancer trials (enrollment fractions: 2.1% vs 1.6%, respectively; OR, 1.30; 95% CI, 1.24-1.35; P<.001) and lung cancer trials (enrollment fractions: 0.9% vs 0.7%, respectively; OR, 1.23; 95% CI, 1.16-1.31; P<.001).Enrollment in cancer trials is low for all patient groups. Racial and ethnic minorities, women, and the elderly were less likely to enroll in cooperative group cancer trials than were whites, men, and younger patients, respectively. The proportion of trial participants who are black has declined in recent years.","Participation in cancer clinical trials: race-, sex-, and age-based disparities."
"413","JAMA.229","0.001",15187053,2004,"Despite the importance of diversity of cancer trial participants with regard to race, ethnicity, age, and sex, there is little recent information about the representation of these groups in clinical trials.To characterize the representation of racial and ethnic minorities, the elderly, and women in cancer trials sponsored by the National Cancer Institute.Cross-sectional population-based analysis of all participants in therapeutic nonsurgical National Cancer Institute Clinical Trial Cooperative Group breast, colorectal, lung, and prostate cancer clinical trials in 2000 through 2002. In a separate analysis, the ethnic distribution of patients enrolled in 2000 through 2002 was compared with those enrolled in 1996 through 1998, using logistic regression models to estimate the relative risk ratio of enrollment for racial and ethnic minorities to that of white patients during these time periods.Enrollment fraction, defined as the number of trial enrollees divided by the estimated US cancer cases in each race and age subgroup.Cancer research participation varied significantly across racial/ethnic and age groups. Compared with a 1.8% enrollment fraction among white patients, lower enrollment fractions were noted in Hispanic (1.3%; odds ratio [OR] vs whites, 0.72; 95% confidence interval [CI], 0.68-0.77; P<.001) and black (1.3%; OR, 0.71; 95% CI, 0.68-0.74; P<.001) patients. There was a strong relationship between age and enrollment fraction, with trial participants 30 to 64 years of age representing 3.0% of incident cancer patients in that age group, in comparison to 1.3% of 65- to 74-year-old patients and 0.5% of patients 75 years of age and older. This inverse relationship between age and trial enrollment fraction was consistent across racial and ethnic groups. Although the total number of trial participants increased during our study period, the representation of racial and ethnic minorities decreased. In comparison to whites, after adjusting for age, cancer type, and sex, patients enrolled in 2000 through 2002 were 24% less likely to be black (adjusted relative risk ratio, 0.76; 95% CI, 0.65-0.89; P<.001). Men were more likely than women to enroll in colorectal cancer trials (enrollment fractions: 2.1% vs 1.6%, respectively; OR, 1.30; 95% CI, 1.24-1.35; P<.001) and lung cancer trials (enrollment fractions: 0.9% vs 0.7%, respectively; OR, 1.23; 95% CI, 1.16-1.31; P<.001).Enrollment in cancer trials is low for all patient groups. Racial and ethnic minorities, women, and the elderly were less likely to enroll in cooperative group cancer trials than were whites, men, and younger patients, respectively. The proportion of trial participants who are black has declined in recent years.","Participation in cancer clinical trials: race-, sex-, and age-based disparities."
"414","JAMA.230","0.001",15187053,2004,"Despite the importance of diversity of cancer trial participants with regard to race, ethnicity, age, and sex, there is little recent information about the representation of these groups in clinical trials.To characterize the representation of racial and ethnic minorities, the elderly, and women in cancer trials sponsored by the National Cancer Institute.Cross-sectional population-based analysis of all participants in therapeutic nonsurgical National Cancer Institute Clinical Trial Cooperative Group breast, colorectal, lung, and prostate cancer clinical trials in 2000 through 2002. In a separate analysis, the ethnic distribution of patients enrolled in 2000 through 2002 was compared with those enrolled in 1996 through 1998, using logistic regression models to estimate the relative risk ratio of enrollment for racial and ethnic minorities to that of white patients during these time periods.Enrollment fraction, defined as the number of trial enrollees divided by the estimated US cancer cases in each race and age subgroup.Cancer research participation varied significantly across racial/ethnic and age groups. Compared with a 1.8% enrollment fraction among white patients, lower enrollment fractions were noted in Hispanic (1.3%; odds ratio [OR] vs whites, 0.72; 95% confidence interval [CI], 0.68-0.77; P<.001) and black (1.3%; OR, 0.71; 95% CI, 0.68-0.74; P<.001) patients. There was a strong relationship between age and enrollment fraction, with trial participants 30 to 64 years of age representing 3.0% of incident cancer patients in that age group, in comparison to 1.3% of 65- to 74-year-old patients and 0.5% of patients 75 years of age and older. This inverse relationship between age and trial enrollment fraction was consistent across racial and ethnic groups. Although the total number of trial participants increased during our study period, the representation of racial and ethnic minorities decreased. In comparison to whites, after adjusting for age, cancer type, and sex, patients enrolled in 2000 through 2002 were 24% less likely to be black (adjusted relative risk ratio, 0.76; 95% CI, 0.65-0.89; P<.001). Men were more likely than women to enroll in colorectal cancer trials (enrollment fractions: 2.1% vs 1.6%, respectively; OR, 1.30; 95% CI, 1.24-1.35; P<.001) and lung cancer trials (enrollment fractions: 0.9% vs 0.7%, respectively; OR, 1.23; 95% CI, 1.16-1.31; P<.001).Enrollment in cancer trials is low for all patient groups. Racial and ethnic minorities, women, and the elderly were less likely to enroll in cooperative group cancer trials than were whites, men, and younger patients, respectively. The proportion of trial participants who are black has declined in recent years.","Participation in cancer clinical trials: race-, sex-, and age-based disparities."
"415","JAMA.224","0.001",15199036,2004,"Atrial fibrillation (AF) is the most common cardiac dysrhythmia in the United States. Whereas rare cases of familial AF have been reported, it is unknown if AF among unselected individuals is a heritable condition.To determine whether parental AF increases the risk for the development of offspring AF.Prospective cohort study (1983-2002) within the Framingham Heart Study, a population-based epidemiologic study. Participants were 2243 offspring (1165 women, 1078 men) at least 30 years of age and free of AF whose parents had both been evaluated in the original cohort.Development of new-onset AF in the offspring was prospectively examined in association with previously documented parental AF.Among 2243 offspring participants, 681 (30%) had at least 1 parent with documented AF; 70 offspring participants (23 women; mean age, 62 [range, 40-81] years) developed AF in follow-up. Compared with no parental AF, AF in at least 1 parent increased the risk of offspring AF (multivariable-adjusted odds ratio [OR], 1.85; 95% confidence interval [CI], 1.12-3.06; P =.02). These results were stronger when age was limited to younger than 75 years in both parents and offspring (multivariable-adjusted OR, 3.23; 95% CI, 1.87-5.58; P<.001) and when the sample was further limited to those without antecedent myocardial infarction, heart failure, or valve disease (multivariable-adjusted OR, 3.17; 95% CI, 1.71-5.86; P<.001).Parental AF increases the future risk for offspring AF, an observation supporting a genetic susceptibility to developing this dysrhythmia. Further research into the genetic factors predisposing to AF is warranted.","Parental atrial fibrillation as a risk factor for atrial fibrillation in offspring."
"416","JAMA.225","0.001",15199036,2004,"Atrial fibrillation (AF) is the most common cardiac dysrhythmia in the United States. Whereas rare cases of familial AF have been reported, it is unknown if AF among unselected individuals is a heritable condition.To determine whether parental AF increases the risk for the development of offspring AF.Prospective cohort study (1983-2002) within the Framingham Heart Study, a population-based epidemiologic study. Participants were 2243 offspring (1165 women, 1078 men) at least 30 years of age and free of AF whose parents had both been evaluated in the original cohort.Development of new-onset AF in the offspring was prospectively examined in association with previously documented parental AF.Among 2243 offspring participants, 681 (30%) had at least 1 parent with documented AF; 70 offspring participants (23 women; mean age, 62 [range, 40-81] years) developed AF in follow-up. Compared with no parental AF, AF in at least 1 parent increased the risk of offspring AF (multivariable-adjusted odds ratio [OR], 1.85; 95% confidence interval [CI], 1.12-3.06; P =.02). These results were stronger when age was limited to younger than 75 years in both parents and offspring (multivariable-adjusted OR, 3.23; 95% CI, 1.87-5.58; P<.001) and when the sample was further limited to those without antecedent myocardial infarction, heart failure, or valve disease (multivariable-adjusted OR, 3.17; 95% CI, 1.71-5.86; P<.001).Parental AF increases the future risk for offspring AF, an observation supporting a genetic susceptibility to developing this dysrhythmia. Further research into the genetic factors predisposing to AF is warranted.","Parental atrial fibrillation as a risk factor for atrial fibrillation in offspring."
"417","JAMA.250","0.02",15199036,2004,"Atrial fibrillation (AF) is the most common cardiac dysrhythmia in the United States. Whereas rare cases of familial AF have been reported, it is unknown if AF among unselected individuals is a heritable condition.To determine whether parental AF increases the risk for the development of offspring AF.Prospective cohort study (1983-2002) within the Framingham Heart Study, a population-based epidemiologic study. Participants were 2243 offspring (1165 women, 1078 men) at least 30 years of age and free of AF whose parents had both been evaluated in the original cohort.Development of new-onset AF in the offspring was prospectively examined in association with previously documented parental AF.Among 2243 offspring participants, 681 (30%) had at least 1 parent with documented AF; 70 offspring participants (23 women; mean age, 62 [range, 40-81] years) developed AF in follow-up. Compared with no parental AF, AF in at least 1 parent increased the risk of offspring AF (multivariable-adjusted odds ratio [OR], 1.85; 95% confidence interval [CI], 1.12-3.06; P =.02). These results were stronger when age was limited to younger than 75 years in both parents and offspring (multivariable-adjusted OR, 3.23; 95% CI, 1.87-5.58; P<.001) and when the sample was further limited to those without antecedent myocardial infarction, heart failure, or valve disease (multivariable-adjusted OR, 3.17; 95% CI, 1.71-5.86; P<.001).Parental AF increases the future risk for offspring AF, an observation supporting a genetic susceptibility to developing this dysrhythmia. Further research into the genetic factors predisposing to AF is warranted.","Parental atrial fibrillation as a risk factor for atrial fibrillation in offspring."
"418","JAMA.2141","0.005",15213206,2004,"The Women's Health Initiative Memory Study (WHIMS) previously found increased risk for dementia and no effect on mild cognitive impairment (MCI) in women treated with conjugated equine estrogens (CEE) plus medroxyprogesterone acetate (MPA).To determine the effects of CEE alone and CEE plus MPA on incidence of probable dementia and MCI in older women.Randomized, double-blind, placebo-controlled clinical trials of CEE (estrogen-alone trial) or CEE plus MPA (estrogen plus progestin trial) in community-dwelling women aged 65 to 79 years, conducted from June 1995 to July 8, 2002 (estrogen plus progestin; n = 4532), or to February 29, 2004 (estrogen-alone; n = 2947), in 39 of the 40 WHI clinical centers.In the estrogen-alone trial, 1 daily tablet containing either 0.625 mg/d of CEE vs matching placebo; in the estrogen plus progestin trial, 1 daily tablet containing CEE (0.625 mg/d) plus MPA (2.5 mg/d) vs matching placebos.Probable dementia and MCI.In the estrogen-alone trial, 47 participants were diagnosed with probable dementia, of whom 28 were assigned to CEE and 19 to placebo (hazard ratio [HR], 1.49; 95% confidence interval [CI], 0.83-2.66). Incidence rates for probable dementia in the estrogen-alone trial were statistically similar to those in the estrogen plus progestin trial (45 vs 22 per 10 000 person-years for CEE plus MPA vs placebo, respectively; P =.11). When data were pooled per the original WHIMS protocol, the overall HR for probable dementia was 1.76 (95% CI, 1.19-2.60; P =.005). After excluding participants with baseline Modified Mini-Mental State Examination scores at or below the screening cut point, the HR was 1.77 (95% CI, 0.74-4.23; P =.20) in the estrogen-alone trial and 2.19 (95% CI, 1.25-3.84; P =.006) in the pooled trials. In the estrogen-alone trial, 76 participants were diagnosed with MCI in the CEE group vs 58 in the placebo group (HR, 1.34; 95% CI, 0.95-1.89). In the combined trial data, the HR was similar (1.25; 95% CI, 0.97-1.60). In the estrogen-alone trial, 93 participants receiving CEE were diagnosed with either probable dementia or MCI vs 69 receiving placebo (HR, 1.38; 95% CI, 1.01-1.89; P =.04).Estrogen therapy alone did not reduce dementia or MCI incidence and increased the risk for both end points combined. Pooling data for estrogen alone and estrogen plus progestin resulted in increased risks for both end points. Use of hormone therapy to prevent dementia or cognitive decline in women 65 years of age or older is not recommended.","Conjugated equine estrogens and incidence of probable dementia and mild cognitive impairment in postmenopausal women: Women's Health Initiative Memory Study."
"419","JAMA.2151","0.2",15213206,2004,"The Women's Health Initiative Memory Study (WHIMS) previously found increased risk for dementia and no effect on mild cognitive impairment (MCI) in women treated with conjugated equine estrogens (CEE) plus medroxyprogesterone acetate (MPA).To determine the effects of CEE alone and CEE plus MPA on incidence of probable dementia and MCI in older women.Randomized, double-blind, placebo-controlled clinical trials of CEE (estrogen-alone trial) or CEE plus MPA (estrogen plus progestin trial) in community-dwelling women aged 65 to 79 years, conducted from June 1995 to July 8, 2002 (estrogen plus progestin; n = 4532), or to February 29, 2004 (estrogen-alone; n = 2947), in 39 of the 40 WHI clinical centers.In the estrogen-alone trial, 1 daily tablet containing either 0.625 mg/d of CEE vs matching placebo; in the estrogen plus progestin trial, 1 daily tablet containing CEE (0.625 mg/d) plus MPA (2.5 mg/d) vs matching placebos.Probable dementia and MCI.In the estrogen-alone trial, 47 participants were diagnosed with probable dementia, of whom 28 were assigned to CEE and 19 to placebo (hazard ratio [HR], 1.49; 95% confidence interval [CI], 0.83-2.66). Incidence rates for probable dementia in the estrogen-alone trial were statistically similar to those in the estrogen plus progestin trial (45 vs 22 per 10 000 person-years for CEE plus MPA vs placebo, respectively; P =.11). When data were pooled per the original WHIMS protocol, the overall HR for probable dementia was 1.76 (95% CI, 1.19-2.60; P =.005). After excluding participants with baseline Modified Mini-Mental State Examination scores at or below the screening cut point, the HR was 1.77 (95% CI, 0.74-4.23; P =.20) in the estrogen-alone trial and 2.19 (95% CI, 1.25-3.84; P =.006) in the pooled trials. In the estrogen-alone trial, 76 participants were diagnosed with MCI in the CEE group vs 58 in the placebo group (HR, 1.34; 95% CI, 0.95-1.89). In the combined trial data, the HR was similar (1.25; 95% CI, 0.97-1.60). In the estrogen-alone trial, 93 participants receiving CEE were diagnosed with either probable dementia or MCI vs 69 receiving placebo (HR, 1.38; 95% CI, 1.01-1.89; P =.04).Estrogen therapy alone did not reduce dementia or MCI incidence and increased the risk for both end points combined. Pooling data for estrogen alone and estrogen plus progestin resulted in increased risks for both end points. Use of hormone therapy to prevent dementia or cognitive decline in women 65 years of age or older is not recommended.","Conjugated equine estrogens and incidence of probable dementia and mild cognitive impairment in postmenopausal women: Women's Health Initiative Memory Study."
"420","JAMA.2161","0.006",15213206,2004,"The Women's Health Initiative Memory Study (WHIMS) previously found increased risk for dementia and no effect on mild cognitive impairment (MCI) in women treated with conjugated equine estrogens (CEE) plus medroxyprogesterone acetate (MPA).To determine the effects of CEE alone and CEE plus MPA on incidence of probable dementia and MCI in older women.Randomized, double-blind, placebo-controlled clinical trials of CEE (estrogen-alone trial) or CEE plus MPA (estrogen plus progestin trial) in community-dwelling women aged 65 to 79 years, conducted from June 1995 to July 8, 2002 (estrogen plus progestin; n = 4532), or to February 29, 2004 (estrogen-alone; n = 2947), in 39 of the 40 WHI clinical centers.In the estrogen-alone trial, 1 daily tablet containing either 0.625 mg/d of CEE vs matching placebo; in the estrogen plus progestin trial, 1 daily tablet containing CEE (0.625 mg/d) plus MPA (2.5 mg/d) vs matching placebos.Probable dementia and MCI.In the estrogen-alone trial, 47 participants were diagnosed with probable dementia, of whom 28 were assigned to CEE and 19 to placebo (hazard ratio [HR], 1.49; 95% confidence interval [CI], 0.83-2.66). Incidence rates for probable dementia in the estrogen-alone trial were statistically similar to those in the estrogen plus progestin trial (45 vs 22 per 10 000 person-years for CEE plus MPA vs placebo, respectively; P =.11). When data were pooled per the original WHIMS protocol, the overall HR for probable dementia was 1.76 (95% CI, 1.19-2.60; P =.005). After excluding participants with baseline Modified Mini-Mental State Examination scores at or below the screening cut point, the HR was 1.77 (95% CI, 0.74-4.23; P =.20) in the estrogen-alone trial and 2.19 (95% CI, 1.25-3.84; P =.006) in the pooled trials. In the estrogen-alone trial, 76 participants were diagnosed with MCI in the CEE group vs 58 in the placebo group (HR, 1.34; 95% CI, 0.95-1.89). In the combined trial data, the HR was similar (1.25; 95% CI, 0.97-1.60). In the estrogen-alone trial, 93 participants receiving CEE were diagnosed with either probable dementia or MCI vs 69 receiving placebo (HR, 1.38; 95% CI, 1.01-1.89; P =.04).Estrogen therapy alone did not reduce dementia or MCI incidence and increased the risk for both end points combined. Pooling data for estrogen alone and estrogen plus progestin resulted in increased risks for both end points. Use of hormone therapy to prevent dementia or cognitive decline in women 65 years of age or older is not recommended.","Conjugated equine estrogens and incidence of probable dementia and mild cognitive impairment in postmenopausal women: Women's Health Initiative Memory Study."
"421","JAMA.2171","0.04",15213206,2004,"The Women's Health Initiative Memory Study (WHIMS) previously found increased risk for dementia and no effect on mild cognitive impairment (MCI) in women treated with conjugated equine estrogens (CEE) plus medroxyprogesterone acetate (MPA).To determine the effects of CEE alone and CEE plus MPA on incidence of probable dementia and MCI in older women.Randomized, double-blind, placebo-controlled clinical trials of CEE (estrogen-alone trial) or CEE plus MPA (estrogen plus progestin trial) in community-dwelling women aged 65 to 79 years, conducted from June 1995 to July 8, 2002 (estrogen plus progestin; n = 4532), or to February 29, 2004 (estrogen-alone; n = 2947), in 39 of the 40 WHI clinical centers.In the estrogen-alone trial, 1 daily tablet containing either 0.625 mg/d of CEE vs matching placebo; in the estrogen plus progestin trial, 1 daily tablet containing CEE (0.625 mg/d) plus MPA (2.5 mg/d) vs matching placebos.Probable dementia and MCI.In the estrogen-alone trial, 47 participants were diagnosed with probable dementia, of whom 28 were assigned to CEE and 19 to placebo (hazard ratio [HR], 1.49; 95% confidence interval [CI], 0.83-2.66). Incidence rates for probable dementia in the estrogen-alone trial were statistically similar to those in the estrogen plus progestin trial (45 vs 22 per 10 000 person-years for CEE plus MPA vs placebo, respectively; P =.11). When data were pooled per the original WHIMS protocol, the overall HR for probable dementia was 1.76 (95% CI, 1.19-2.60; P =.005). After excluding participants with baseline Modified Mini-Mental State Examination scores at or below the screening cut point, the HR was 1.77 (95% CI, 0.74-4.23; P =.20) in the estrogen-alone trial and 2.19 (95% CI, 1.25-3.84; P =.006) in the pooled trials. In the estrogen-alone trial, 76 participants were diagnosed with MCI in the CEE group vs 58 in the placebo group (HR, 1.34; 95% CI, 0.95-1.89). In the combined trial data, the HR was similar (1.25; 95% CI, 0.97-1.60). In the estrogen-alone trial, 93 participants receiving CEE were diagnosed with either probable dementia or MCI vs 69 receiving placebo (HR, 1.38; 95% CI, 1.01-1.89; P =.04).Estrogen therapy alone did not reduce dementia or MCI incidence and increased the risk for both end points combined. Pooling data for estrogen alone and estrogen plus progestin resulted in increased risks for both end points. Use of hormone therapy to prevent dementia or cognitive decline in women 65 years of age or older is not recommended.","Conjugated equine estrogens and incidence of probable dementia and mild cognitive impairment in postmenopausal women: Women's Health Initiative Memory Study."
"422","JAMA.2171","NA",15213206,2004,"The Women's Health Initiative Memory Study (WHIMS) previously found increased risk for dementia and no effect on mild cognitive impairment (MCI) in women treated with conjugated equine estrogens (CEE) plus medroxyprogesterone acetate (MPA).To determine the effects of CEE alone and CEE plus MPA on incidence of probable dementia and MCI in older women.Randomized, double-blind, placebo-controlled clinical trials of CEE (estrogen-alone trial) or CEE plus MPA (estrogen plus progestin trial) in community-dwelling women aged 65 to 79 years, conducted from June 1995 to July 8, 2002 (estrogen plus progestin; n = 4532), or to February 29, 2004 (estrogen-alone; n = 2947), in 39 of the 40 WHI clinical centers.In the estrogen-alone trial, 1 daily tablet containing either 0.625 mg/d of CEE vs matching placebo; in the estrogen plus progestin trial, 1 daily tablet containing CEE (0.625 mg/d) plus MPA (2.5 mg/d) vs matching placebos.Probable dementia and MCI.In the estrogen-alone trial, 47 participants were diagnosed with probable dementia, of whom 28 were assigned to CEE and 19 to placebo (hazard ratio [HR], 1.49; 95% confidence interval [CI], 0.83-2.66). Incidence rates for probable dementia in the estrogen-alone trial were statistically similar to those in the estrogen plus progestin trial (45 vs 22 per 10 000 person-years for CEE plus MPA vs placebo, respectively; P =.11). When data were pooled per the original WHIMS protocol, the overall HR for probable dementia was 1.76 (95% CI, 1.19-2.60; P =.005). After excluding participants with baseline Modified Mini-Mental State Examination scores at or below the screening cut point, the HR was 1.77 (95% CI, 0.74-4.23; P =.20) in the estrogen-alone trial and 2.19 (95% CI, 1.25-3.84; P =.006) in the pooled trials. In the estrogen-alone trial, 76 participants were diagnosed with MCI in the CEE group vs 58 in the placebo group (HR, 1.34; 95% CI, 0.95-1.89). In the combined trial data, the HR was similar (1.25; 95% CI, 0.97-1.60). In the estrogen-alone trial, 93 participants receiving CEE were diagnosed with either probable dementia or MCI vs 69 receiving placebo (HR, 1.38; 95% CI, 1.01-1.89; P =.04).Estrogen therapy alone did not reduce dementia or MCI incidence and increased the risk for both end points combined. Pooling data for estrogen alone and estrogen plus progestin resulted in increased risks for both end points. Use of hormone therapy to prevent dementia or cognitive decline in women 65 years of age or older is not recommended.","Conjugated equine estrogens and incidence of probable dementia and mild cognitive impairment in postmenopausal women: Women's Health Initiative Memory Study."
"423","JAMA.2171","NA",15213206,2004,"The Women's Health Initiative Memory Study (WHIMS) previously found increased risk for dementia and no effect on mild cognitive impairment (MCI) in women treated with conjugated equine estrogens (CEE) plus medroxyprogesterone acetate (MPA).To determine the effects of CEE alone and CEE plus MPA on incidence of probable dementia and MCI in older women.Randomized, double-blind, placebo-controlled clinical trials of CEE (estrogen-alone trial) or CEE plus MPA (estrogen plus progestin trial) in community-dwelling women aged 65 to 79 years, conducted from June 1995 to July 8, 2002 (estrogen plus progestin; n = 4532), or to February 29, 2004 (estrogen-alone; n = 2947), in 39 of the 40 WHI clinical centers.In the estrogen-alone trial, 1 daily tablet containing either 0.625 mg/d of CEE vs matching placebo; in the estrogen plus progestin trial, 1 daily tablet containing CEE (0.625 mg/d) plus MPA (2.5 mg/d) vs matching placebos.Probable dementia and MCI.In the estrogen-alone trial, 47 participants were diagnosed with probable dementia, of whom 28 were assigned to CEE and 19 to placebo (hazard ratio [HR], 1.49; 95% confidence interval [CI], 0.83-2.66). Incidence rates for probable dementia in the estrogen-alone trial were statistically similar to those in the estrogen plus progestin trial (45 vs 22 per 10 000 person-years for CEE plus MPA vs placebo, respectively; P =.11). When data were pooled per the original WHIMS protocol, the overall HR for probable dementia was 1.76 (95% CI, 1.19-2.60; P =.005). After excluding participants with baseline Modified Mini-Mental State Examination scores at or below the screening cut point, the HR was 1.77 (95% CI, 0.74-4.23; P =.20) in the estrogen-alone trial and 2.19 (95% CI, 1.25-3.84; P =.006) in the pooled trials. In the estrogen-alone trial, 76 participants were diagnosed with MCI in the CEE group vs 58 in the placebo group (HR, 1.34; 95% CI, 0.95-1.89). In the combined trial data, the HR was similar (1.25; 95% CI, 0.97-1.60). In the estrogen-alone trial, 93 participants receiving CEE were diagnosed with either probable dementia or MCI vs 69 receiving placebo (HR, 1.38; 95% CI, 1.01-1.89; P =.04).Estrogen therapy alone did not reduce dementia or MCI incidence and increased the risk for both end points combined. Pooling data for estrogen alone and estrogen plus progestin resulted in increased risks for both end points. Use of hormone therapy to prevent dementia or cognitive decline in women 65 years of age or older is not recommended.","Conjugated equine estrogens and incidence of probable dementia and mild cognitive impairment in postmenopausal women: Women's Health Initiative Memory Study."
"424","American Journal of Epidemiology.41","0.01",15229116,2004,"A case-control study was performed using the records of patients hospitalized for typhoid fever at Dicle University Hospital, Diyarbakir, Turkey, between 1994 and 1998. Case patients with enteric perforation were compared with control patients with typhoid fever but no enteric perforation. Risk factors for perforation were determined using logistic regression modeling. Forty case patients who had surgery because of typhoid enteric perforation were compared with 80 control patients. In univariate analyses, male sex (p = 0.01), age (p = 0.01), leukopenia (p = 0.01), inadequate antimicrobial therapy prior to admission (p = 0.01), and short duration of symptoms (p = 0.01) were significantly associated with perforation. In multivariate analysis, male sex (odds ratio (OR) = 4.39, 95% confidence interval (CI): 1.37, 14.09; p = 0.01), leukopenia (OR = 3.88, 95% CI: 1.46, 10.33; p = 0.04), inadequate treatment prior to admission (OR = 4.58, 95% CI: 1.14, 18.35; p = 0.03), and short duration of symptoms (OR = 1.22, 95% CI: 1.10, 1.35; p = 0.001) were significant predictors of perforation. A short duration of symptoms, inadequate antimicrobial therapy, male sex, and leukopenia are independent risk factors for enteric perforation in patients with typhoid fever.Copyright 2004 Johns Hopkins Bloomberg School of Public Health","Risk factors for enteric perforation in patients with typhoid Fever."
"425","American Journal of Epidemiology.47","0.04",15229116,2004,"A case-control study was performed using the records of patients hospitalized for typhoid fever at Dicle University Hospital, Diyarbakir, Turkey, between 1994 and 1998. Case patients with enteric perforation were compared with control patients with typhoid fever but no enteric perforation. Risk factors for perforation were determined using logistic regression modeling. Forty case patients who had surgery because of typhoid enteric perforation were compared with 80 control patients. In univariate analyses, male sex (p = 0.01), age (p = 0.01), leukopenia (p = 0.01), inadequate antimicrobial therapy prior to admission (p = 0.01), and short duration of symptoms (p = 0.01) were significantly associated with perforation. In multivariate analysis, male sex (odds ratio (OR) = 4.39, 95% confidence interval (CI): 1.37, 14.09; p = 0.01), leukopenia (OR = 3.88, 95% CI: 1.46, 10.33; p = 0.04), inadequate treatment prior to admission (OR = 4.58, 95% CI: 1.14, 18.35; p = 0.03), and short duration of symptoms (OR = 1.22, 95% CI: 1.10, 1.35; p = 0.001) were significant predictors of perforation. A short duration of symptoms, inadequate antimicrobial therapy, male sex, and leukopenia are independent risk factors for enteric perforation in patients with typhoid fever.Copyright 2004 Johns Hopkins Bloomberg School of Public Health","Risk factors for enteric perforation in patients with typhoid Fever."
"426","American Journal of Epidemiology.48","0.03",15229116,2004,"A case-control study was performed using the records of patients hospitalized for typhoid fever at Dicle University Hospital, Diyarbakir, Turkey, between 1994 and 1998. Case patients with enteric perforation were compared with control patients with typhoid fever but no enteric perforation. Risk factors for perforation were determined using logistic regression modeling. Forty case patients who had surgery because of typhoid enteric perforation were compared with 80 control patients. In univariate analyses, male sex (p = 0.01), age (p = 0.01), leukopenia (p = 0.01), inadequate antimicrobial therapy prior to admission (p = 0.01), and short duration of symptoms (p = 0.01) were significantly associated with perforation. In multivariate analysis, male sex (odds ratio (OR) = 4.39, 95% confidence interval (CI): 1.37, 14.09; p = 0.01), leukopenia (OR = 3.88, 95% CI: 1.46, 10.33; p = 0.04), inadequate treatment prior to admission (OR = 4.58, 95% CI: 1.14, 18.35; p = 0.03), and short duration of symptoms (OR = 1.22, 95% CI: 1.10, 1.35; p = 0.001) were significant predictors of perforation. A short duration of symptoms, inadequate antimicrobial therapy, male sex, and leukopenia are independent risk factors for enteric perforation in patients with typhoid fever.Copyright 2004 Johns Hopkins Bloomberg School of Public Health","Risk factors for enteric perforation in patients with typhoid Fever."
"427","American Journal of Epidemiology.49","0.001",15229116,2004,"A case-control study was performed using the records of patients hospitalized for typhoid fever at Dicle University Hospital, Diyarbakir, Turkey, between 1994 and 1998. Case patients with enteric perforation were compared with control patients with typhoid fever but no enteric perforation. Risk factors for perforation were determined using logistic regression modeling. Forty case patients who had surgery because of typhoid enteric perforation were compared with 80 control patients. In univariate analyses, male sex (p = 0.01), age (p = 0.01), leukopenia (p = 0.01), inadequate antimicrobial therapy prior to admission (p = 0.01), and short duration of symptoms (p = 0.01) were significantly associated with perforation. In multivariate analysis, male sex (odds ratio (OR) = 4.39, 95% confidence interval (CI): 1.37, 14.09; p = 0.01), leukopenia (OR = 3.88, 95% CI: 1.46, 10.33; p = 0.04), inadequate treatment prior to admission (OR = 4.58, 95% CI: 1.14, 18.35; p = 0.03), and short duration of symptoms (OR = 1.22, 95% CI: 1.10, 1.35; p = 0.001) were significant predictors of perforation. A short duration of symptoms, inadequate antimicrobial therapy, male sex, and leukopenia are independent risk factors for enteric perforation in patients with typhoid fever.Copyright 2004 Johns Hopkins Bloomberg School of Public Health","Risk factors for enteric perforation in patients with typhoid Fever."
"428","JAMA.222","0.001",15265852,2004,"Glycoprotein IIb/IIIa (Gp IIb/IIIa) inhibitors improve myocardial reperfusion and clinical outcomes of patients undergoing primary percutaneous coronary intervention (PCI), but optimal timing of administration remains unclear. No systematic reviews have comprehensively examined the effects of early vs delayed administration of these agents.To perform a meta-analysis of randomized trials of early (prior to transfer to the catheterization laboratory) vs late (at the time of PCI) intravenous administration of Gp IIb/IIIa inhibitors in acute ST-segment elevation myocardial infarction (STEMI).MEDLINE and the Cochrane Controlled Trials Register search of the literature over the past 10 years; papers presented at major cardiac conferences; consultation with national and international colleagues as well as Gp IIb/IIIa inhibitor drug manufacturers; and text and journal article bibliographies.We examined trials of randomized comparisons between early administration at the point of initial contact (emergency department or ambulance) and late administration (catheterization laboratory) of Gp IIb/IIIa inhibitors in STEMI. Outcome data had to be available on both culprit artery patency evaluated by Thrombolysis in Myocardial Infarction (TIMI) flow grades on admission and mortality. Two authors independently reviewed abstracts or complete articles. Six studies met inclusion criteria. Independent data extraction was performed by 2 reviewers and confirmed by consensus.The 6 trials enrolled 931 STEMI patients treated with abciximab (3 trials) or tirofiban (3 trials) in combination with primary PCI. TIMI grade 2 or 3 flow (41.7% [194/465 vs 29.8% [139/466]) as well as TIMI grade 3 flow (20.3% [84/413] vs 12.2% [51/418]) were significantly more frequent in the early group compared with the late group (odds ratio [OR], 1.69; 95% confidence interval [CI], 1.28-2.22; P<.001; and OR, 1.85; 95% CI, 1.26-2.71; P<.001, respectively). The early administration of Gp IIb/IIIa inhibitors was associated with a 28% reduction of mortality from 4.7% to 3.4%, which was not significant but consistent with similar trends for reinfarction and the composite ischemic end point.In a meta-analysis of 6 randomized trials, early administration of Gp IIb/IIIa inhibitors in STEMI appeared to improve coronary patency with favorable trends for clinical outcomes. These findings are supportive of a strategy of facilitated PCI. Further evaluations in adequately powered large trials are awaited to confirm the clinical benefit of this strategy.","Early vs late administration of glycoprotein IIb/IIIa inhibitors in primary percutaneous coronary intervention of acute ST-segment elevation myocardial infarction: a meta-analysis."
"429","JAMA.223","0.001",15265852,2004,"Glycoprotein IIb/IIIa (Gp IIb/IIIa) inhibitors improve myocardial reperfusion and clinical outcomes of patients undergoing primary percutaneous coronary intervention (PCI), but optimal timing of administration remains unclear. No systematic reviews have comprehensively examined the effects of early vs delayed administration of these agents.To perform a meta-analysis of randomized trials of early (prior to transfer to the catheterization laboratory) vs late (at the time of PCI) intravenous administration of Gp IIb/IIIa inhibitors in acute ST-segment elevation myocardial infarction (STEMI).MEDLINE and the Cochrane Controlled Trials Register search of the literature over the past 10 years; papers presented at major cardiac conferences; consultation with national and international colleagues as well as Gp IIb/IIIa inhibitor drug manufacturers; and text and journal article bibliographies.We examined trials of randomized comparisons between early administration at the point of initial contact (emergency department or ambulance) and late administration (catheterization laboratory) of Gp IIb/IIIa inhibitors in STEMI. Outcome data had to be available on both culprit artery patency evaluated by Thrombolysis in Myocardial Infarction (TIMI) flow grades on admission and mortality. Two authors independently reviewed abstracts or complete articles. Six studies met inclusion criteria. Independent data extraction was performed by 2 reviewers and confirmed by consensus.The 6 trials enrolled 931 STEMI patients treated with abciximab (3 trials) or tirofiban (3 trials) in combination with primary PCI. TIMI grade 2 or 3 flow (41.7% [194/465 vs 29.8% [139/466]) as well as TIMI grade 3 flow (20.3% [84/413] vs 12.2% [51/418]) were significantly more frequent in the early group compared with the late group (odds ratio [OR], 1.69; 95% confidence interval [CI], 1.28-2.22; P<.001; and OR, 1.85; 95% CI, 1.26-2.71; P<.001, respectively). The early administration of Gp IIb/IIIa inhibitors was associated with a 28% reduction of mortality from 4.7% to 3.4%, which was not significant but consistent with similar trends for reinfarction and the composite ischemic end point.In a meta-analysis of 6 randomized trials, early administration of Gp IIb/IIIa inhibitors in STEMI appeared to improve coronary patency with favorable trends for clinical outcomes. These findings are supportive of a strategy of facilitated PCI. Further evaluations in adequately powered large trials are awaited to confirm the clinical benefit of this strategy.","Early vs late administration of glycoprotein IIb/IIIa inhibitors in primary percutaneous coronary intervention of acute ST-segment elevation myocardial infarction: a meta-analysis."
"430","JAMA.218","0.001",15280345,2004,"Randomized trials have demonstrated that adding a drug to a single-agent or to a 2-agent regimen increased the tumor response rate in patients with advanced non-small-cell lung cancer (NSCLC), although its impact on survival remains controversial.To evaluate the clinical benefit of adding a drug to a single-agent or 2-agent chemotherapy regimen in terms of tumor response rate, survival, and toxicity in patients with advanced NSCLC.Data from all randomized controlled trials performed between 1980 and 2001 (published between January 1980 and October 2003) comparing a doublet regimen with a single-agent regimen or comparing a triplet regimen with a doublet regimen in patients with advanced NSCLC. There were no language restrictions. Searches of MEDLINE and EMBASE were performed using the search terms non-small-cell lung carcinoma/drug therapy, adenocarcinoma, large-cell carcinoma, squamous-cell carcinoma, lung, neoplasms, clinical trial phase III, and randomized trial. Manual searches were also performed to find conference proceedings published between January 1982 and October 2003.Two independent investigators reviewed the publications and extracted the data. Pooled odds ratios (ORs) for the objective tumor response rate, 1-year survival rate, and toxicity rate were calculated using the fixed-effect model. Pooled median ratios (MRs) for median survival also were calculated using the fixed-effect model. ORs and MRs lower than unity (<1.0) indicate a benefit of a doublet regimen compared with a single-agent regimen (or a triplet regimen compared with a doublet regimen).Sixty-five trials (13 601 patients) were eligible. In the trials comparing a doublet regimen with a single-agent regimen, a significant increase was observed in tumor response (OR, 0.42; 95% confidence interval [CI], 0.37-0.47; P<.001) and 1-year survival (OR, 0.80; 95% CI, 0.70-0.91; P<.001) in favor of the doublet regimen. The median survival ratio was 0.83 (95% CI, 0.79-0.89; P<.001). An increase also was observed in the tumor response rate (OR, 0.66; 95% CI, 0.58-0.75; P<.001) in favor of the triplet regimen, but not for 1-year survival (OR, 1.01; 95% CI, 0.85-1.21; P =.88). The median survival ratio was 1.00 (95% CI, 0.94-1.06; P =.97).Adding a second drug improved tumor response and survival rate. Adding a third drug had a weaker effect on tumor response and no effect on survival.","Benefits of adding a drug to a single-agent or a 2-agent chemotherapy regimen in advanced non-small-cell lung cancer: a meta-analysis."
"431","JAMA.219","0.001",15280345,2004,"Randomized trials have demonstrated that adding a drug to a single-agent or to a 2-agent regimen increased the tumor response rate in patients with advanced non-small-cell lung cancer (NSCLC), although its impact on survival remains controversial.To evaluate the clinical benefit of adding a drug to a single-agent or 2-agent chemotherapy regimen in terms of tumor response rate, survival, and toxicity in patients with advanced NSCLC.Data from all randomized controlled trials performed between 1980 and 2001 (published between January 1980 and October 2003) comparing a doublet regimen with a single-agent regimen or comparing a triplet regimen with a doublet regimen in patients with advanced NSCLC. There were no language restrictions. Searches of MEDLINE and EMBASE were performed using the search terms non-small-cell lung carcinoma/drug therapy, adenocarcinoma, large-cell carcinoma, squamous-cell carcinoma, lung, neoplasms, clinical trial phase III, and randomized trial. Manual searches were also performed to find conference proceedings published between January 1982 and October 2003.Two independent investigators reviewed the publications and extracted the data. Pooled odds ratios (ORs) for the objective tumor response rate, 1-year survival rate, and toxicity rate were calculated using the fixed-effect model. Pooled median ratios (MRs) for median survival also were calculated using the fixed-effect model. ORs and MRs lower than unity (<1.0) indicate a benefit of a doublet regimen compared with a single-agent regimen (or a triplet regimen compared with a doublet regimen).Sixty-five trials (13 601 patients) were eligible. In the trials comparing a doublet regimen with a single-agent regimen, a significant increase was observed in tumor response (OR, 0.42; 95% confidence interval [CI], 0.37-0.47; P<.001) and 1-year survival (OR, 0.80; 95% CI, 0.70-0.91; P<.001) in favor of the doublet regimen. The median survival ratio was 0.83 (95% CI, 0.79-0.89; P<.001). An increase also was observed in the tumor response rate (OR, 0.66; 95% CI, 0.58-0.75; P<.001) in favor of the triplet regimen, but not for 1-year survival (OR, 1.01; 95% CI, 0.85-1.21; P =.88). The median survival ratio was 1.00 (95% CI, 0.94-1.06; P =.97).Adding a second drug improved tumor response and survival rate. Adding a third drug had a weaker effect on tumor response and no effect on survival.","Benefits of adding a drug to a single-agent or a 2-agent chemotherapy regimen in advanced non-small-cell lung cancer: a meta-analysis."
"432","JAMA.220","0.001",15280345,2004,"Randomized trials have demonstrated that adding a drug to a single-agent or to a 2-agent regimen increased the tumor response rate in patients with advanced non-small-cell lung cancer (NSCLC), although its impact on survival remains controversial.To evaluate the clinical benefit of adding a drug to a single-agent or 2-agent chemotherapy regimen in terms of tumor response rate, survival, and toxicity in patients with advanced NSCLC.Data from all randomized controlled trials performed between 1980 and 2001 (published between January 1980 and October 2003) comparing a doublet regimen with a single-agent regimen or comparing a triplet regimen with a doublet regimen in patients with advanced NSCLC. There were no language restrictions. Searches of MEDLINE and EMBASE were performed using the search terms non-small-cell lung carcinoma/drug therapy, adenocarcinoma, large-cell carcinoma, squamous-cell carcinoma, lung, neoplasms, clinical trial phase III, and randomized trial. Manual searches were also performed to find conference proceedings published between January 1982 and October 2003.Two independent investigators reviewed the publications and extracted the data. Pooled odds ratios (ORs) for the objective tumor response rate, 1-year survival rate, and toxicity rate were calculated using the fixed-effect model. Pooled median ratios (MRs) for median survival also were calculated using the fixed-effect model. ORs and MRs lower than unity (<1.0) indicate a benefit of a doublet regimen compared with a single-agent regimen (or a triplet regimen compared with a doublet regimen).Sixty-five trials (13 601 patients) were eligible. In the trials comparing a doublet regimen with a single-agent regimen, a significant increase was observed in tumor response (OR, 0.42; 95% confidence interval [CI], 0.37-0.47; P<.001) and 1-year survival (OR, 0.80; 95% CI, 0.70-0.91; P<.001) in favor of the doublet regimen. The median survival ratio was 0.83 (95% CI, 0.79-0.89; P<.001). An increase also was observed in the tumor response rate (OR, 0.66; 95% CI, 0.58-0.75; P<.001) in favor of the triplet regimen, but not for 1-year survival (OR, 1.01; 95% CI, 0.85-1.21; P =.88). The median survival ratio was 1.00 (95% CI, 0.94-1.06; P =.97).Adding a second drug improved tumor response and survival rate. Adding a third drug had a weaker effect on tumor response and no effect on survival.","Benefits of adding a drug to a single-agent or a 2-agent chemotherapy regimen in advanced non-small-cell lung cancer: a meta-analysis."
"433","JAMA.221","0.001",15280345,2004,"Randomized trials have demonstrated that adding a drug to a single-agent or to a 2-agent regimen increased the tumor response rate in patients with advanced non-small-cell lung cancer (NSCLC), although its impact on survival remains controversial.To evaluate the clinical benefit of adding a drug to a single-agent or 2-agent chemotherapy regimen in terms of tumor response rate, survival, and toxicity in patients with advanced NSCLC.Data from all randomized controlled trials performed between 1980 and 2001 (published between January 1980 and October 2003) comparing a doublet regimen with a single-agent regimen or comparing a triplet regimen with a doublet regimen in patients with advanced NSCLC. There were no language restrictions. Searches of MEDLINE and EMBASE were performed using the search terms non-small-cell lung carcinoma/drug therapy, adenocarcinoma, large-cell carcinoma, squamous-cell carcinoma, lung, neoplasms, clinical trial phase III, and randomized trial. Manual searches were also performed to find conference proceedings published between January 1982 and October 2003.Two independent investigators reviewed the publications and extracted the data. Pooled odds ratios (ORs) for the objective tumor response rate, 1-year survival rate, and toxicity rate were calculated using the fixed-effect model. Pooled median ratios (MRs) for median survival also were calculated using the fixed-effect model. ORs and MRs lower than unity (<1.0) indicate a benefit of a doublet regimen compared with a single-agent regimen (or a triplet regimen compared with a doublet regimen).Sixty-five trials (13 601 patients) were eligible. In the trials comparing a doublet regimen with a single-agent regimen, a significant increase was observed in tumor response (OR, 0.42; 95% confidence interval [CI], 0.37-0.47; P<.001) and 1-year survival (OR, 0.80; 95% CI, 0.70-0.91; P<.001) in favor of the doublet regimen. The median survival ratio was 0.83 (95% CI, 0.79-0.89; P<.001). An increase also was observed in the tumor response rate (OR, 0.66; 95% CI, 0.58-0.75; P<.001) in favor of the triplet regimen, but not for 1-year survival (OR, 1.01; 95% CI, 0.85-1.21; P =.88). The median survival ratio was 1.00 (95% CI, 0.94-1.06; P =.97).Adding a second drug improved tumor response and survival rate. Adding a third drug had a weaker effect on tumor response and no effect on survival.","Benefits of adding a drug to a single-agent or a 2-agent chemotherapy regimen in advanced non-small-cell lung cancer: a meta-analysis."
"434","JAMA.245","0.88",15280345,2004,"Randomized trials have demonstrated that adding a drug to a single-agent or to a 2-agent regimen increased the tumor response rate in patients with advanced non-small-cell lung cancer (NSCLC), although its impact on survival remains controversial.To evaluate the clinical benefit of adding a drug to a single-agent or 2-agent chemotherapy regimen in terms of tumor response rate, survival, and toxicity in patients with advanced NSCLC.Data from all randomized controlled trials performed between 1980 and 2001 (published between January 1980 and October 2003) comparing a doublet regimen with a single-agent regimen or comparing a triplet regimen with a doublet regimen in patients with advanced NSCLC. There were no language restrictions. Searches of MEDLINE and EMBASE were performed using the search terms non-small-cell lung carcinoma/drug therapy, adenocarcinoma, large-cell carcinoma, squamous-cell carcinoma, lung, neoplasms, clinical trial phase III, and randomized trial. Manual searches were also performed to find conference proceedings published between January 1982 and October 2003.Two independent investigators reviewed the publications and extracted the data. Pooled odds ratios (ORs) for the objective tumor response rate, 1-year survival rate, and toxicity rate were calculated using the fixed-effect model. Pooled median ratios (MRs) for median survival also were calculated using the fixed-effect model. ORs and MRs lower than unity (<1.0) indicate a benefit of a doublet regimen compared with a single-agent regimen (or a triplet regimen compared with a doublet regimen).Sixty-five trials (13 601 patients) were eligible. In the trials comparing a doublet regimen with a single-agent regimen, a significant increase was observed in tumor response (OR, 0.42; 95% confidence interval [CI], 0.37-0.47; P<.001) and 1-year survival (OR, 0.80; 95% CI, 0.70-0.91; P<.001) in favor of the doublet regimen. The median survival ratio was 0.83 (95% CI, 0.79-0.89; P<.001). An increase also was observed in the tumor response rate (OR, 0.66; 95% CI, 0.58-0.75; P<.001) in favor of the triplet regimen, but not for 1-year survival (OR, 1.01; 95% CI, 0.85-1.21; P =.88). The median survival ratio was 1.00 (95% CI, 0.94-1.06; P =.97).Adding a second drug improved tumor response and survival rate. Adding a third drug had a weaker effect on tumor response and no effect on survival.","Benefits of adding a drug to a single-agent or a 2-agent chemotherapy regimen in advanced non-small-cell lung cancer: a meta-analysis."
"435","JAMA.246","0.97",15280345,2004,"Randomized trials have demonstrated that adding a drug to a single-agent or to a 2-agent regimen increased the tumor response rate in patients with advanced non-small-cell lung cancer (NSCLC), although its impact on survival remains controversial.To evaluate the clinical benefit of adding a drug to a single-agent or 2-agent chemotherapy regimen in terms of tumor response rate, survival, and toxicity in patients with advanced NSCLC.Data from all randomized controlled trials performed between 1980 and 2001 (published between January 1980 and October 2003) comparing a doublet regimen with a single-agent regimen or comparing a triplet regimen with a doublet regimen in patients with advanced NSCLC. There were no language restrictions. Searches of MEDLINE and EMBASE were performed using the search terms non-small-cell lung carcinoma/drug therapy, adenocarcinoma, large-cell carcinoma, squamous-cell carcinoma, lung, neoplasms, clinical trial phase III, and randomized trial. Manual searches were also performed to find conference proceedings published between January 1982 and October 2003.Two independent investigators reviewed the publications and extracted the data. Pooled odds ratios (ORs) for the objective tumor response rate, 1-year survival rate, and toxicity rate were calculated using the fixed-effect model. Pooled median ratios (MRs) for median survival also were calculated using the fixed-effect model. ORs and MRs lower than unity (<1.0) indicate a benefit of a doublet regimen compared with a single-agent regimen (or a triplet regimen compared with a doublet regimen).Sixty-five trials (13 601 patients) were eligible. In the trials comparing a doublet regimen with a single-agent regimen, a significant increase was observed in tumor response (OR, 0.42; 95% confidence interval [CI], 0.37-0.47; P<.001) and 1-year survival (OR, 0.80; 95% CI, 0.70-0.91; P<.001) in favor of the doublet regimen. The median survival ratio was 0.83 (95% CI, 0.79-0.89; P<.001). An increase also was observed in the tumor response rate (OR, 0.66; 95% CI, 0.58-0.75; P<.001) in favor of the triplet regimen, but not for 1-year survival (OR, 1.01; 95% CI, 0.85-1.21; P =.88). The median survival ratio was 1.00 (95% CI, 0.94-1.06; P =.97).Adding a second drug improved tumor response and survival rate. Adding a third drug had a weaker effect on tumor response and no effect on survival.","Benefits of adding a drug to a single-agent or a 2-agent chemotherapy regimen in advanced non-small-cell lung cancer: a meta-analysis."
"436","Lancet.203","0.001",15288742,2004,"The borders of Thailand harbour the world's most multidrug resistant Plasmodium falciparum parasites. In 1984 mefloquine was introduced as treatment for uncomplicated falciparum malaria, but substantial resistance developed within 6 years. A combination of artesunate with mefloquine now cures more than 95% of acute infections. For both treatment regimens, the underlying mechanisms of resistance are not known.The relation between polymorphisms in the P falciparum multidrug resistant gene 1 (pfmdr1) and the in-vitro and in-vivo responses to mefloquine were assessed in 618 samples from patients with falciparum malaria studied prospectively over 12 years. pfmdr1 copy number was assessed by a robust real-time PCR assay. Single nucleotide polymorphisms of pfmdr1, P falciparum chloroquine resistance transporter gene (pfcrt) and P falciparum Ca2+ ATPase gene (pfATP6) were assessed by PCR-restriction fragment length polymorphism.Increased copy number of pfmdr1 was the most important determinant of in-vitro and in-vivo resistance to mefloquine, and also to reduced artesunate sensitivity in vitro. In a Cox regression model with control for known confounders, increased pfmdr1 copy number was associated with an attributable hazard ratio (AHR) for treatment failure of 6.3 (95% CI 2.9-13.8, p<0.001) after mefloquine monotherapy and 5.4 (2.0-14.6, p=0.001) after artesunate-mefloquine therapy. Single nucleotide polymorphisms in pfmdr1 were associated with increased mefloquine susceptibility in vitro, but not in vivo.Amplification in pfmdr1 is the main cause of resistance to mefloquine in falciparum malaria.Multidrug resistant P falciparum malaria is common in southeast Asia, but difficult to identify and treat. Genes that encode parasite transport proteins maybe involved in export of drugs and so cause resistance. In this study we show that increase in copy number of pfmdr1, a gene encoding a parasite transport protein, is the best overall predictor of treatment failure with mefloquine. Increase in pfmdr1 copy number predicts failure even after chemotherapy with the highly effective combination of mefloquine and 3 days' artesunate. Monitoring of pfmdr1 copy number will be useful in epidemiological surveys of drug resistance in P falciparum, and potentially for predicting treatment failure in individual patients.","Mefloquine resistance in Plasmodium falciparum and increased pfmdr1 gene copy number."
"437","Lancet.2710","0.001",15288742,2004,"The borders of Thailand harbour the world's most multidrug resistant Plasmodium falciparum parasites. In 1984 mefloquine was introduced as treatment for uncomplicated falciparum malaria, but substantial resistance developed within 6 years. A combination of artesunate with mefloquine now cures more than 95% of acute infections. For both treatment regimens, the underlying mechanisms of resistance are not known.The relation between polymorphisms in the P falciparum multidrug resistant gene 1 (pfmdr1) and the in-vitro and in-vivo responses to mefloquine were assessed in 618 samples from patients with falciparum malaria studied prospectively over 12 years. pfmdr1 copy number was assessed by a robust real-time PCR assay. Single nucleotide polymorphisms of pfmdr1, P falciparum chloroquine resistance transporter gene (pfcrt) and P falciparum Ca2+ ATPase gene (pfATP6) were assessed by PCR-restriction fragment length polymorphism.Increased copy number of pfmdr1 was the most important determinant of in-vitro and in-vivo resistance to mefloquine, and also to reduced artesunate sensitivity in vitro. In a Cox regression model with control for known confounders, increased pfmdr1 copy number was associated with an attributable hazard ratio (AHR) for treatment failure of 6.3 (95% CI 2.9-13.8, p<0.001) after mefloquine monotherapy and 5.4 (2.0-14.6, p=0.001) after artesunate-mefloquine therapy. Single nucleotide polymorphisms in pfmdr1 were associated with increased mefloquine susceptibility in vitro, but not in vivo.Amplification in pfmdr1 is the main cause of resistance to mefloquine in falciparum malaria.Multidrug resistant P falciparum malaria is common in southeast Asia, but difficult to identify and treat. Genes that encode parasite transport proteins maybe involved in export of drugs and so cause resistance. In this study we show that increase in copy number of pfmdr1, a gene encoding a parasite transport protein, is the best overall predictor of treatment failure with mefloquine. Increase in pfmdr1 copy number predicts failure even after chemotherapy with the highly effective combination of mefloquine and 3 days' artesunate. Monitoring of pfmdr1 copy number will be useful in epidemiological surveys of drug resistance in P falciparum, and potentially for predicting treatment failure in individual patients.","Mefloquine resistance in Plasmodium falciparum and increased pfmdr1 gene copy number."
"438","JAMA.2021","0.15",15304466,2004,"In the Randomized Evaluation in PCI Linking Angiomax to Reduced Clinical Events (REPLACE)-2 trial, bivalirudin with provisional glycoprotein IIb/IIIa (Gp IIb/IIIa) inhibition was found to be noninferior to heparin plus planned Gp IIb/IIIa blockade in the prevention of acute ischemic end points and was associated with significantly less bleeding by 30 days after percutaneous coronary intervention (PCI).To determine whether the efficacy of bivalirudin remains comparable with that of heparin plus Gp IIb/IIIa blockade over 6 months and 1 year.Follow-up study to 1 year of a randomized, double-blind trial conducted among 6010 patients undergoing urgent or elective PCI at 233 community or referral hospitals in 9 countries from October 2001 through August 2002.Patients were randomly assigned to receive intravenously bivalirudin (0.75 mg/kg bolus, 1.75 mg/kg per hour for the duration of PCI), with provisional Gp IIb/IIIa inhibition, or to receive heparin (65 U/kg bolus), with planned Gp IIb/IIIa inhibition (abciximab or eptifibatide). Both groups received daily aspirin and a thienopyridine for at least 30 days after PCI.Incidence of death, myocardial infarction, or repeat revascularization by 6 months and death by 12 months after enrollment.At 6 months, death occurred in 1.4% of patients in the heparin plus Gp IIb/IIIa group and in 1.0% of patients in the bivalirudin group (hazard ratio [HR], 0.70; 95% confidence interval [CI], 0.43-1.14; P =.15). Myocardial infarction occurred in 7.4% and 8.2% of patients, respectively (HR, 1.12; 95% CI, 0.93-1.34; P =.24), and repeat revascularization was required in 11.4% and 12.1% of patients, respectively (HR, 1.06; 95% CI, 0.91-1.23; P =.45). By 1 year, death occurred in 2.46% of patients treated with heparin plus Gp IIb/IIIa blockade and in 1.89% of patients treated with bivalirudin (HR, 0.78; 95% CI, 0.55-1.11; P =.16). Nonsignificant trends toward lower 1-year mortality with bivalirudin were present in all patient subgroups analyzed and were of greatest magnitude among high-risk patients.Long-term clinical outcome with bivalirudin and provisional Gp IIb/IIIa blockade is comparable with that of heparin plus planned Gp IIb/IIIa inhibition during contemporary PCI.","Long-term efficacy of bivalirudin and provisional glycoprotein IIb/IIIa blockade vs heparin and planned glycoprotein IIb/IIIa blockade during percutaneous coronary revascularization: REPLACE-2 randomized trial."
"439","JAMA.2031","0.24",15304466,2004,"In the Randomized Evaluation in PCI Linking Angiomax to Reduced Clinical Events (REPLACE)-2 trial, bivalirudin with provisional glycoprotein IIb/IIIa (Gp IIb/IIIa) inhibition was found to be noninferior to heparin plus planned Gp IIb/IIIa blockade in the prevention of acute ischemic end points and was associated with significantly less bleeding by 30 days after percutaneous coronary intervention (PCI).To determine whether the efficacy of bivalirudin remains comparable with that of heparin plus Gp IIb/IIIa blockade over 6 months and 1 year.Follow-up study to 1 year of a randomized, double-blind trial conducted among 6010 patients undergoing urgent or elective PCI at 233 community or referral hospitals in 9 countries from October 2001 through August 2002.Patients were randomly assigned to receive intravenously bivalirudin (0.75 mg/kg bolus, 1.75 mg/kg per hour for the duration of PCI), with provisional Gp IIb/IIIa inhibition, or to receive heparin (65 U/kg bolus), with planned Gp IIb/IIIa inhibition (abciximab or eptifibatide). Both groups received daily aspirin and a thienopyridine for at least 30 days after PCI.Incidence of death, myocardial infarction, or repeat revascularization by 6 months and death by 12 months after enrollment.At 6 months, death occurred in 1.4% of patients in the heparin plus Gp IIb/IIIa group and in 1.0% of patients in the bivalirudin group (hazard ratio [HR], 0.70; 95% confidence interval [CI], 0.43-1.14; P =.15). Myocardial infarction occurred in 7.4% and 8.2% of patients, respectively (HR, 1.12; 95% CI, 0.93-1.34; P =.24), and repeat revascularization was required in 11.4% and 12.1% of patients, respectively (HR, 1.06; 95% CI, 0.91-1.23; P =.45). By 1 year, death occurred in 2.46% of patients treated with heparin plus Gp IIb/IIIa blockade and in 1.89% of patients treated with bivalirudin (HR, 0.78; 95% CI, 0.55-1.11; P =.16). Nonsignificant trends toward lower 1-year mortality with bivalirudin were present in all patient subgroups analyzed and were of greatest magnitude among high-risk patients.Long-term clinical outcome with bivalirudin and provisional Gp IIb/IIIa blockade is comparable with that of heparin plus planned Gp IIb/IIIa inhibition during contemporary PCI.","Long-term efficacy of bivalirudin and provisional glycoprotein IIb/IIIa blockade vs heparin and planned glycoprotein IIb/IIIa blockade during percutaneous coronary revascularization: REPLACE-2 randomized trial."
"440","JAMA.2041","0.45",15304466,2004,"In the Randomized Evaluation in PCI Linking Angiomax to Reduced Clinical Events (REPLACE)-2 trial, bivalirudin with provisional glycoprotein IIb/IIIa (Gp IIb/IIIa) inhibition was found to be noninferior to heparin plus planned Gp IIb/IIIa blockade in the prevention of acute ischemic end points and was associated with significantly less bleeding by 30 days after percutaneous coronary intervention (PCI).To determine whether the efficacy of bivalirudin remains comparable with that of heparin plus Gp IIb/IIIa blockade over 6 months and 1 year.Follow-up study to 1 year of a randomized, double-blind trial conducted among 6010 patients undergoing urgent or elective PCI at 233 community or referral hospitals in 9 countries from October 2001 through August 2002.Patients were randomly assigned to receive intravenously bivalirudin (0.75 mg/kg bolus, 1.75 mg/kg per hour for the duration of PCI), with provisional Gp IIb/IIIa inhibition, or to receive heparin (65 U/kg bolus), with planned Gp IIb/IIIa inhibition (abciximab or eptifibatide). Both groups received daily aspirin and a thienopyridine for at least 30 days after PCI.Incidence of death, myocardial infarction, or repeat revascularization by 6 months and death by 12 months after enrollment.At 6 months, death occurred in 1.4% of patients in the heparin plus Gp IIb/IIIa group and in 1.0% of patients in the bivalirudin group (hazard ratio [HR], 0.70; 95% confidence interval [CI], 0.43-1.14; P =.15). Myocardial infarction occurred in 7.4% and 8.2% of patients, respectively (HR, 1.12; 95% CI, 0.93-1.34; P =.24), and repeat revascularization was required in 11.4% and 12.1% of patients, respectively (HR, 1.06; 95% CI, 0.91-1.23; P =.45). By 1 year, death occurred in 2.46% of patients treated with heparin plus Gp IIb/IIIa blockade and in 1.89% of patients treated with bivalirudin (HR, 0.78; 95% CI, 0.55-1.11; P =.16). Nonsignificant trends toward lower 1-year mortality with bivalirudin were present in all patient subgroups analyzed and were of greatest magnitude among high-risk patients.Long-term clinical outcome with bivalirudin and provisional Gp IIb/IIIa blockade is comparable with that of heparin plus planned Gp IIb/IIIa inhibition during contemporary PCI.","Long-term efficacy of bivalirudin and provisional glycoprotein IIb/IIIa blockade vs heparin and planned glycoprotein IIb/IIIa blockade during percutaneous coronary revascularization: REPLACE-2 randomized trial."
"441","JAMA.2051","0.16",15304466,2004,"In the Randomized Evaluation in PCI Linking Angiomax to Reduced Clinical Events (REPLACE)-2 trial, bivalirudin with provisional glycoprotein IIb/IIIa (Gp IIb/IIIa) inhibition was found to be noninferior to heparin plus planned Gp IIb/IIIa blockade in the prevention of acute ischemic end points and was associated with significantly less bleeding by 30 days after percutaneous coronary intervention (PCI).To determine whether the efficacy of bivalirudin remains comparable with that of heparin plus Gp IIb/IIIa blockade over 6 months and 1 year.Follow-up study to 1 year of a randomized, double-blind trial conducted among 6010 patients undergoing urgent or elective PCI at 233 community or referral hospitals in 9 countries from October 2001 through August 2002.Patients were randomly assigned to receive intravenously bivalirudin (0.75 mg/kg bolus, 1.75 mg/kg per hour for the duration of PCI), with provisional Gp IIb/IIIa inhibition, or to receive heparin (65 U/kg bolus), with planned Gp IIb/IIIa inhibition (abciximab or eptifibatide). Both groups received daily aspirin and a thienopyridine for at least 30 days after PCI.Incidence of death, myocardial infarction, or repeat revascularization by 6 months and death by 12 months after enrollment.At 6 months, death occurred in 1.4% of patients in the heparin plus Gp IIb/IIIa group and in 1.0% of patients in the bivalirudin group (hazard ratio [HR], 0.70; 95% confidence interval [CI], 0.43-1.14; P =.15). Myocardial infarction occurred in 7.4% and 8.2% of patients, respectively (HR, 1.12; 95% CI, 0.93-1.34; P =.24), and repeat revascularization was required in 11.4% and 12.1% of patients, respectively (HR, 1.06; 95% CI, 0.91-1.23; P =.45). By 1 year, death occurred in 2.46% of patients treated with heparin plus Gp IIb/IIIa blockade and in 1.89% of patients treated with bivalirudin (HR, 0.78; 95% CI, 0.55-1.11; P =.16). Nonsignificant trends toward lower 1-year mortality with bivalirudin were present in all patient subgroups analyzed and were of greatest magnitude among high-risk patients.Long-term clinical outcome with bivalirudin and provisional Gp IIb/IIIa blockade is comparable with that of heparin plus planned Gp IIb/IIIa inhibition during contemporary PCI.","Long-term efficacy of bivalirudin and provisional glycoprotein IIb/IIIa blockade vs heparin and planned glycoprotein IIb/IIIa blockade during percutaneous coronary revascularization: REPLACE-2 randomized trial."
"442","JAMA.1971","0.14",15337732,2004,"Limited data are available evaluating how the timing and intensity of statin therapy following an acute coronary syndrome (ACS) event affect clinical outcome.To compare early initiation of an intensive statin regimen with delayed initiation of a less intensive regimen in patients with ACS.International, randomized, double-blind trial of patients with ACS receiving 40 mg/d of simvastatin for 1 month followed by 80 mg/d thereafter (n = 2265) compared with ACS patients receiving placebo for 4 months followed by 20 mg/d of simvastatin (n = 2232), who were enrolled in phase Z of the A to Z trial between December 29, 1999, and January 6, 2003.The primary end point was a composite of cardiovascular death, nonfatal myocardial infarction, readmission for ACS, and stroke. Follow-up was for at least 6 months and up to 24 months.Among the patients in the placebo plus simvastatin group, the median low-density lipoprotein (LDL) cholesterol level achieved while taking placebo was 122 mg/dL (3.16 mmol/L) at 1 month and was 77 mg/dL (1.99 mmol/L) at 8 months while taking 20 mg/d of simvastatin. Among the patients in the simvastatin only group, the median LDL cholesterol level achieved at 1 month while taking 40 mg/d of simvastatin was 68 mg/dL (1.76 mmol/L) and was 63 mg/dL (1.63 mmol/L) at 8 months while taking 80 mg/d of simvastatin. A total of 343 patients (16.7%) in the placebo plus simvastatin group experienced the primary end point compared with 309 (14.4%) in the simvastatin only group (40 mg/80 mg) (hazard ratio [HR], 0.89; 95% confidence interval [CI] 0.76-1.04; P =.14). Cardiovascular death occurred in 109 (5.4%) and 83 (4.1%) patients in the 2 groups (HR, 0.75; 95% CI, 0.57-1.00; P =.05) but no differences were observed in other individual components of the primary end point. No difference was evident during the first 4 months between the groups for the primary end point (HR, 1.01; 95% CI, 0.83-1.25; P =.89), but from 4 months through the end of the study the primary end point was significantly reduced in the simvastatin only group (HR, 0.75; 95% CI, 0.60-0.95; P =.02). Myopathy (creatine kinase >10 times the upper limit of normal associated with muscle symptoms) occurred in 9 patients (0.4%) receiving simvastatin 80 mg/d, in no patients receiving lower doses of simvastatin, and in 1 patient receiving placebo (P =.02).The trial did not achieve the prespecified end point. However, among patients with ACS, the early initiation of an aggressive simvastatin regimen resulted in a favorable trend toward reduction of major cardiovascular events.","Early intensive vs a delayed conservative simvastatin strategy in patients with acute coronary syndromes: phase Z of the A to Z trial."
"443","JAMA.1981","0.05",15337732,2004,"Limited data are available evaluating how the timing and intensity of statin therapy following an acute coronary syndrome (ACS) event affect clinical outcome.To compare early initiation of an intensive statin regimen with delayed initiation of a less intensive regimen in patients with ACS.International, randomized, double-blind trial of patients with ACS receiving 40 mg/d of simvastatin for 1 month followed by 80 mg/d thereafter (n = 2265) compared with ACS patients receiving placebo for 4 months followed by 20 mg/d of simvastatin (n = 2232), who were enrolled in phase Z of the A to Z trial between December 29, 1999, and January 6, 2003.The primary end point was a composite of cardiovascular death, nonfatal myocardial infarction, readmission for ACS, and stroke. Follow-up was for at least 6 months and up to 24 months.Among the patients in the placebo plus simvastatin group, the median low-density lipoprotein (LDL) cholesterol level achieved while taking placebo was 122 mg/dL (3.16 mmol/L) at 1 month and was 77 mg/dL (1.99 mmol/L) at 8 months while taking 20 mg/d of simvastatin. Among the patients in the simvastatin only group, the median LDL cholesterol level achieved at 1 month while taking 40 mg/d of simvastatin was 68 mg/dL (1.76 mmol/L) and was 63 mg/dL (1.63 mmol/L) at 8 months while taking 80 mg/d of simvastatin. A total of 343 patients (16.7%) in the placebo plus simvastatin group experienced the primary end point compared with 309 (14.4%) in the simvastatin only group (40 mg/80 mg) (hazard ratio [HR], 0.89; 95% confidence interval [CI] 0.76-1.04; P =.14). Cardiovascular death occurred in 109 (5.4%) and 83 (4.1%) patients in the 2 groups (HR, 0.75; 95% CI, 0.57-1.00; P =.05) but no differences were observed in other individual components of the primary end point. No difference was evident during the first 4 months between the groups for the primary end point (HR, 1.01; 95% CI, 0.83-1.25; P =.89), but from 4 months through the end of the study the primary end point was significantly reduced in the simvastatin only group (HR, 0.75; 95% CI, 0.60-0.95; P =.02). Myopathy (creatine kinase >10 times the upper limit of normal associated with muscle symptoms) occurred in 9 patients (0.4%) receiving simvastatin 80 mg/d, in no patients receiving lower doses of simvastatin, and in 1 patient receiving placebo (P =.02).The trial did not achieve the prespecified end point. However, among patients with ACS, the early initiation of an aggressive simvastatin regimen resulted in a favorable trend toward reduction of major cardiovascular events.","Early intensive vs a delayed conservative simvastatin strategy in patients with acute coronary syndromes: phase Z of the A to Z trial."
"444","JAMA.1991","0.89",15337732,2004,"Limited data are available evaluating how the timing and intensity of statin therapy following an acute coronary syndrome (ACS) event affect clinical outcome.To compare early initiation of an intensive statin regimen with delayed initiation of a less intensive regimen in patients with ACS.International, randomized, double-blind trial of patients with ACS receiving 40 mg/d of simvastatin for 1 month followed by 80 mg/d thereafter (n = 2265) compared with ACS patients receiving placebo for 4 months followed by 20 mg/d of simvastatin (n = 2232), who were enrolled in phase Z of the A to Z trial between December 29, 1999, and January 6, 2003.The primary end point was a composite of cardiovascular death, nonfatal myocardial infarction, readmission for ACS, and stroke. Follow-up was for at least 6 months and up to 24 months.Among the patients in the placebo plus simvastatin group, the median low-density lipoprotein (LDL) cholesterol level achieved while taking placebo was 122 mg/dL (3.16 mmol/L) at 1 month and was 77 mg/dL (1.99 mmol/L) at 8 months while taking 20 mg/d of simvastatin. Among the patients in the simvastatin only group, the median LDL cholesterol level achieved at 1 month while taking 40 mg/d of simvastatin was 68 mg/dL (1.76 mmol/L) and was 63 mg/dL (1.63 mmol/L) at 8 months while taking 80 mg/d of simvastatin. A total of 343 patients (16.7%) in the placebo plus simvastatin group experienced the primary end point compared with 309 (14.4%) in the simvastatin only group (40 mg/80 mg) (hazard ratio [HR], 0.89; 95% confidence interval [CI] 0.76-1.04; P =.14). Cardiovascular death occurred in 109 (5.4%) and 83 (4.1%) patients in the 2 groups (HR, 0.75; 95% CI, 0.57-1.00; P =.05) but no differences were observed in other individual components of the primary end point. No difference was evident during the first 4 months between the groups for the primary end point (HR, 1.01; 95% CI, 0.83-1.25; P =.89), but from 4 months through the end of the study the primary end point was significantly reduced in the simvastatin only group (HR, 0.75; 95% CI, 0.60-0.95; P =.02). Myopathy (creatine kinase >10 times the upper limit of normal associated with muscle symptoms) occurred in 9 patients (0.4%) receiving simvastatin 80 mg/d, in no patients receiving lower doses of simvastatin, and in 1 patient receiving placebo (P =.02).The trial did not achieve the prespecified end point. However, among patients with ACS, the early initiation of an aggressive simvastatin regimen resulted in a favorable trend toward reduction of major cardiovascular events.","Early intensive vs a delayed conservative simvastatin strategy in patients with acute coronary syndromes: phase Z of the A to Z trial."
"445","JAMA.2001","0.02",15337732,2004,"Limited data are available evaluating how the timing and intensity of statin therapy following an acute coronary syndrome (ACS) event affect clinical outcome.To compare early initiation of an intensive statin regimen with delayed initiation of a less intensive regimen in patients with ACS.International, randomized, double-blind trial of patients with ACS receiving 40 mg/d of simvastatin for 1 month followed by 80 mg/d thereafter (n = 2265) compared with ACS patients receiving placebo for 4 months followed by 20 mg/d of simvastatin (n = 2232), who were enrolled in phase Z of the A to Z trial between December 29, 1999, and January 6, 2003.The primary end point was a composite of cardiovascular death, nonfatal myocardial infarction, readmission for ACS, and stroke. Follow-up was for at least 6 months and up to 24 months.Among the patients in the placebo plus simvastatin group, the median low-density lipoprotein (LDL) cholesterol level achieved while taking placebo was 122 mg/dL (3.16 mmol/L) at 1 month and was 77 mg/dL (1.99 mmol/L) at 8 months while taking 20 mg/d of simvastatin. Among the patients in the simvastatin only group, the median LDL cholesterol level achieved at 1 month while taking 40 mg/d of simvastatin was 68 mg/dL (1.76 mmol/L) and was 63 mg/dL (1.63 mmol/L) at 8 months while taking 80 mg/d of simvastatin. A total of 343 patients (16.7%) in the placebo plus simvastatin group experienced the primary end point compared with 309 (14.4%) in the simvastatin only group (40 mg/80 mg) (hazard ratio [HR], 0.89; 95% confidence interval [CI] 0.76-1.04; P =.14). Cardiovascular death occurred in 109 (5.4%) and 83 (4.1%) patients in the 2 groups (HR, 0.75; 95% CI, 0.57-1.00; P =.05) but no differences were observed in other individual components of the primary end point. No difference was evident during the first 4 months between the groups for the primary end point (HR, 1.01; 95% CI, 0.83-1.25; P =.89), but from 4 months through the end of the study the primary end point was significantly reduced in the simvastatin only group (HR, 0.75; 95% CI, 0.60-0.95; P =.02). Myopathy (creatine kinase >10 times the upper limit of normal associated with muscle symptoms) occurred in 9 patients (0.4%) receiving simvastatin 80 mg/d, in no patients receiving lower doses of simvastatin, and in 1 patient receiving placebo (P =.02).The trial did not achieve the prespecified end point. However, among patients with ACS, the early initiation of an aggressive simvastatin regimen resulted in a favorable trend toward reduction of major cardiovascular events.","Early intensive vs a delayed conservative simvastatin strategy in patients with acute coronary syndromes: phase Z of the A to Z trial."
"446","JAMA.1961","0.01",15339900,2004,"Selection of systemic adjuvant therapies for women diagnosed as having breast cancer is based on risk estimations for cancer recurrence. In such estimations, tumors detected by mammography screening are considered to be associated with a similar risk of recurrence as tumors of similar size found by other methods.To compare the risk of recurrence and survival among women with cancerous tumors detected by mammography screening compared with other methods (outside of screening).Retrospective study comparing clinical, histopathological, and biological features of cancerous tumors detected by mammography screening compared with tumors detected outside of screening. Women diagnosed as having breast cancer in 1991 or 1992 were identified from the Finnish Cancer Registry (n = 2842). The median follow-up time was 9.5 years. Cancer biological variables were analyzed from tumor tissue microarrays using immunohistochemistry or in situ hybridization and included ERBB2, TP53, and MK167 expression and ERBB2 amplification data.Univariate and multivariate analyses of potential risk factors for distant recurrence of breast cancer and 10-year survival.Of the 1983 women with unilateral invasive breast cancer, data on tumor diameter were available for 1918 women. Women with cancerous tumors detected by mammography screening had better estimated 10-year distant disease-free survival than women with tumors found outside of screening (tumor size of < or =10 mm [n = 386] 92% vs 85% [P =.04]; 11-20 mm [n = 808] 88% vs 76% [P<.001]; 21-30 mm [n = 409] 86% vs 63% [P =.008]; >30 mm [n = 315] 68% vs 50% [P =.12], respectively). In a Cox multivariate model that included cancer biological factors, the relative hazard ratio for distant recurrence among women with tumors detected outside of screening (HR, 1.90; 95% confidence interval, 1.15-3.11) was significantly higher than among women with tumors detected by mammography screening (P =.01). Breast cancer diagnosis by mammography screening was an independent prognostic variable reducing the relative HR for distant recurrence. This effect was equal to or greater than the effect of 1-cm decrease in tumor diameter (HR, 1.20; 95% confidence interval, 1.10-1.31).Cancerous tumors detected by mammography screening are associated with a better prognosis than tumors of similar size found outside of screening. The risk of distant metastases is overestimated for women diagnosed as having cancer by mammography screening unless the method of detection is taken into account in risk estimations.","Risk for distant recurrence of breast cancer detected by mammography screening or other methods."
"447","JAMA.1961","NA",15339900,2004,"Selection of systemic adjuvant therapies for women diagnosed as having breast cancer is based on risk estimations for cancer recurrence. In such estimations, tumors detected by mammography screening are considered to be associated with a similar risk of recurrence as tumors of similar size found by other methods.To compare the risk of recurrence and survival among women with cancerous tumors detected by mammography screening compared with other methods (outside of screening).Retrospective study comparing clinical, histopathological, and biological features of cancerous tumors detected by mammography screening compared with tumors detected outside of screening. Women diagnosed as having breast cancer in 1991 or 1992 were identified from the Finnish Cancer Registry (n = 2842). The median follow-up time was 9.5 years. Cancer biological variables were analyzed from tumor tissue microarrays using immunohistochemistry or in situ hybridization and included ERBB2, TP53, and MK167 expression and ERBB2 amplification data.Univariate and multivariate analyses of potential risk factors for distant recurrence of breast cancer and 10-year survival.Of the 1983 women with unilateral invasive breast cancer, data on tumor diameter were available for 1918 women. Women with cancerous tumors detected by mammography screening had better estimated 10-year distant disease-free survival than women with tumors found outside of screening (tumor size of < or =10 mm [n = 386] 92% vs 85% [P =.04]; 11-20 mm [n = 808] 88% vs 76% [P<.001]; 21-30 mm [n = 409] 86% vs 63% [P =.008]; >30 mm [n = 315] 68% vs 50% [P =.12], respectively). In a Cox multivariate model that included cancer biological factors, the relative hazard ratio for distant recurrence among women with tumors detected outside of screening (HR, 1.90; 95% confidence interval, 1.15-3.11) was significantly higher than among women with tumors detected by mammography screening (P =.01). Breast cancer diagnosis by mammography screening was an independent prognostic variable reducing the relative HR for distant recurrence. This effect was equal to or greater than the effect of 1-cm decrease in tumor diameter (HR, 1.20; 95% confidence interval, 1.10-1.31).Cancerous tumors detected by mammography screening are associated with a better prognosis than tumors of similar size found outside of screening. The risk of distant metastases is overestimated for women diagnosed as having cancer by mammography screening unless the method of detection is taken into account in risk estimations.","Risk for distant recurrence of breast cancer detected by mammography screening or other methods."
"448","Lancet.1810","1.00E-04",15351193,2004,"Findings from the National Surgical Adjuvant Breast and Bowel Project B-14 and B-20 trials showed that tamoxifen benefited women with oestrogen-receptor-positive tumours and negative axillary nodes, and that chemotherapy plus tamoxifen was more effective than tamoxifen alone. We present long-term findings from those trials and relate them to age, menopausal status, and tumour oestrogen-receptor concentrations. We also discuss the extent of progress made in the treatment of such patients.B-14 patients were randomly assigned to placebo (n=1453) or tamoxifen (n=1439); B-20 patients to tamoxifen (n=788) or cyclophosphamide, methotrexate, fluorouracil, and tamoxifen (CMFT, n=789). Primary endpoints were recurrence-free survival and overall survival estimated according to patients' age, menopausal status, and tumour oestrogen-receptor concentration. Smoothed recurrence rates were used to measure patterns of recurrence as a continuous function of age.Compared with placebo, tamoxifen benefited women in B-14 through 15 years, irrespective of age, menopausal status, or tumour oestrogen-receptor concentration (hazard ratio [HR] for recurrence-free survival 0.58, 95% CI 0.50-0.67, p<0.0001; HR for overall survival 0.80, 0.71-0.91, p=0.0008). In B-20, the benefit from CMFT over 12 years was greater than that from tamoxifen alone (HR for recurrence-free survival 0.52, 0.39-0.68, p<0.0001; HR for overall survival 0.78, 0.60-1.01, p=0.063). When CMFT was compared with placebo, there were reductions in treatment failure of about 65% in all age-groups.Much benefit has been achieved in treatment of women with oestrogen-receptor-positive tumours and negative nodes. When planning systemic therapy for such patients of all ages, it should be understood that some have tumours with variable concentrations of oestrogen-receptors, a surrogate for other biomarkers associated with tumour growth and response to treatment. Older women tend to have higher tumour oestrogen-receptor concentrations and are more likely to benefit from tamoxifen than from chemotherapy; in younger women, the converse is true. Consequently, the notion that use of tamoxifen or chemotherapy should be based only on age is too restrictive.","Treatment of lymph-node-negative, oestrogen-receptor-positive breast cancer: long-term findings from National Surgical Adjuvant Breast and Bowel Project randomised clinical trials."
"449","Lancet.1910","1.00E-04",15351193,2004,"Findings from the National Surgical Adjuvant Breast and Bowel Project B-14 and B-20 trials showed that tamoxifen benefited women with oestrogen-receptor-positive tumours and negative axillary nodes, and that chemotherapy plus tamoxifen was more effective than tamoxifen alone. We present long-term findings from those trials and relate them to age, menopausal status, and tumour oestrogen-receptor concentrations. We also discuss the extent of progress made in the treatment of such patients.B-14 patients were randomly assigned to placebo (n=1453) or tamoxifen (n=1439); B-20 patients to tamoxifen (n=788) or cyclophosphamide, methotrexate, fluorouracil, and tamoxifen (CMFT, n=789). Primary endpoints were recurrence-free survival and overall survival estimated according to patients' age, menopausal status, and tumour oestrogen-receptor concentration. Smoothed recurrence rates were used to measure patterns of recurrence as a continuous function of age.Compared with placebo, tamoxifen benefited women in B-14 through 15 years, irrespective of age, menopausal status, or tumour oestrogen-receptor concentration (hazard ratio [HR] for recurrence-free survival 0.58, 95% CI 0.50-0.67, p<0.0001; HR for overall survival 0.80, 0.71-0.91, p=0.0008). In B-20, the benefit from CMFT over 12 years was greater than that from tamoxifen alone (HR for recurrence-free survival 0.52, 0.39-0.68, p<0.0001; HR for overall survival 0.78, 0.60-1.01, p=0.063). When CMFT was compared with placebo, there were reductions in treatment failure of about 65% in all age-groups.Much benefit has been achieved in treatment of women with oestrogen-receptor-positive tumours and negative nodes. When planning systemic therapy for such patients of all ages, it should be understood that some have tumours with variable concentrations of oestrogen-receptors, a surrogate for other biomarkers associated with tumour growth and response to treatment. Older women tend to have higher tumour oestrogen-receptor concentrations and are more likely to benefit from tamoxifen than from chemotherapy; in younger women, the converse is true. Consequently, the notion that use of tamoxifen or chemotherapy should be based only on age is too restrictive.","Treatment of lymph-node-negative, oestrogen-receptor-positive breast cancer: long-term findings from National Surgical Adjuvant Breast and Bowel Project randomised clinical trials."
"450","Lancet.258","8.00E-04",15351193,2004,"Findings from the National Surgical Adjuvant Breast and Bowel Project B-14 and B-20 trials showed that tamoxifen benefited women with oestrogen-receptor-positive tumours and negative axillary nodes, and that chemotherapy plus tamoxifen was more effective than tamoxifen alone. We present long-term findings from those trials and relate them to age, menopausal status, and tumour oestrogen-receptor concentrations. We also discuss the extent of progress made in the treatment of such patients.B-14 patients were randomly assigned to placebo (n=1453) or tamoxifen (n=1439); B-20 patients to tamoxifen (n=788) or cyclophosphamide, methotrexate, fluorouracil, and tamoxifen (CMFT, n=789). Primary endpoints were recurrence-free survival and overall survival estimated according to patients' age, menopausal status, and tumour oestrogen-receptor concentration. Smoothed recurrence rates were used to measure patterns of recurrence as a continuous function of age.Compared with placebo, tamoxifen benefited women in B-14 through 15 years, irrespective of age, menopausal status, or tumour oestrogen-receptor concentration (hazard ratio [HR] for recurrence-free survival 0.58, 95% CI 0.50-0.67, p<0.0001; HR for overall survival 0.80, 0.71-0.91, p=0.0008). In B-20, the benefit from CMFT over 12 years was greater than that from tamoxifen alone (HR for recurrence-free survival 0.52, 0.39-0.68, p<0.0001; HR for overall survival 0.78, 0.60-1.01, p=0.063). When CMFT was compared with placebo, there were reductions in treatment failure of about 65% in all age-groups.Much benefit has been achieved in treatment of women with oestrogen-receptor-positive tumours and negative nodes. When planning systemic therapy for such patients of all ages, it should be understood that some have tumours with variable concentrations of oestrogen-receptors, a surrogate for other biomarkers associated with tumour growth and response to treatment. Older women tend to have higher tumour oestrogen-receptor concentrations and are more likely to benefit from tamoxifen than from chemotherapy; in younger women, the converse is true. Consequently, the notion that use of tamoxifen or chemotherapy should be based only on age is too restrictive.","Treatment of lymph-node-negative, oestrogen-receptor-positive breast cancer: long-term findings from National Surgical Adjuvant Breast and Bowel Project randomised clinical trials."
"451","Lancet.261","0.063",15351193,2004,"Findings from the National Surgical Adjuvant Breast and Bowel Project B-14 and B-20 trials showed that tamoxifen benefited women with oestrogen-receptor-positive tumours and negative axillary nodes, and that chemotherapy plus tamoxifen was more effective than tamoxifen alone. We present long-term findings from those trials and relate them to age, menopausal status, and tumour oestrogen-receptor concentrations. We also discuss the extent of progress made in the treatment of such patients.B-14 patients were randomly assigned to placebo (n=1453) or tamoxifen (n=1439); B-20 patients to tamoxifen (n=788) or cyclophosphamide, methotrexate, fluorouracil, and tamoxifen (CMFT, n=789). Primary endpoints were recurrence-free survival and overall survival estimated according to patients' age, menopausal status, and tumour oestrogen-receptor concentration. Smoothed recurrence rates were used to measure patterns of recurrence as a continuous function of age.Compared with placebo, tamoxifen benefited women in B-14 through 15 years, irrespective of age, menopausal status, or tumour oestrogen-receptor concentration (hazard ratio [HR] for recurrence-free survival 0.58, 95% CI 0.50-0.67, p<0.0001; HR for overall survival 0.80, 0.71-0.91, p=0.0008). In B-20, the benefit from CMFT over 12 years was greater than that from tamoxifen alone (HR for recurrence-free survival 0.52, 0.39-0.68, p<0.0001; HR for overall survival 0.78, 0.60-1.01, p=0.063). When CMFT was compared with placebo, there were reductions in treatment failure of about 65% in all age-groups.Much benefit has been achieved in treatment of women with oestrogen-receptor-positive tumours and negative nodes. When planning systemic therapy for such patients of all ages, it should be understood that some have tumours with variable concentrations of oestrogen-receptors, a surrogate for other biomarkers associated with tumour growth and response to treatment. Older women tend to have higher tumour oestrogen-receptor concentrations and are more likely to benefit from tamoxifen than from chemotherapy; in younger women, the converse is true. Consequently, the notion that use of tamoxifen or chemotherapy should be based only on age is too restrictive.","Treatment of lymph-node-negative, oestrogen-receptor-positive breast cancer: long-term findings from National Surgical Adjuvant Breast and Bowel Project randomised clinical trials."
"452","JAMA.216","0.001",15383517,2004,"The usefulness of exercise stress test results and global cardiovascular risk systems for predicting all-cause mortality in asymptomatic individuals seen in clinical settings is unclear.To determine the validity for prediction of all-cause mortality of the Framingham Risk Score and of a recently described European global scoring system Systematic Coronary Risk Evaluation (SCORE) for cardiovascular mortality among asymptomatic individuals evaluated in a clinical setting and to determine the potential prognostic value of exercise stress testing once these baseline risks are known.Prospective cohort study of 3554 asymptomatic adults between the ages of 50 and 75 years who underwent exercise stress testing as part of an executive health program between October 1990 and December 2002; participants were followed up for a mean of 8 years.Global risk based on the Framingham Risk Score and the European SCORE. Prospectively recorded exercise stress test result abnormalities included impaired physical fitness, abnormal heart rate recovery, ventricular ectopy, and ST-segment abnormalities. The primary end point was all-cause mortality.There were 114 deaths. The c-index, which corresponds to receiver operating characteristic curve values, and the Akaike Information Criteria found that the European SCORE was superior to the Framingham Risk Score in estimating global mortality risk. In a multivariable model, independent predictors of death were a higher SCORE (for 1% predicted increase in absolute risk, relative risk [RR], 1.07; 95% confidence interval [CI], 1.04-1.09; P<.001), impaired functional capacity (RR, 2.95; 95% CI, 1.98-4.39; P<.001), and an abnormal heart rate recovery (RR, 1.59; 95%, 1.04-2.41; P =.03). ST-segment depression did not predict mortality. Among patients in the highest tertile from the SCORE, an abnormal exercise stress test result, defined as either impaired functional capacity or an abnormal heart rate recovery, identified a mortality risk of more than 1% per year.Exercise stress testing when combined with the European global risk SCORE may be useful for stratifying risk in asymptomatic individuals in a comprehensive executive health screening program.","Global risk scores and exercise testing for predicting all-cause mortality in a preventive medicine program."
"453","JAMA.217","0.001",15383517,2004,"The usefulness of exercise stress test results and global cardiovascular risk systems for predicting all-cause mortality in asymptomatic individuals seen in clinical settings is unclear.To determine the validity for prediction of all-cause mortality of the Framingham Risk Score and of a recently described European global scoring system Systematic Coronary Risk Evaluation (SCORE) for cardiovascular mortality among asymptomatic individuals evaluated in a clinical setting and to determine the potential prognostic value of exercise stress testing once these baseline risks are known.Prospective cohort study of 3554 asymptomatic adults between the ages of 50 and 75 years who underwent exercise stress testing as part of an executive health program between October 1990 and December 2002; participants were followed up for a mean of 8 years.Global risk based on the Framingham Risk Score and the European SCORE. Prospectively recorded exercise stress test result abnormalities included impaired physical fitness, abnormal heart rate recovery, ventricular ectopy, and ST-segment abnormalities. The primary end point was all-cause mortality.There were 114 deaths. The c-index, which corresponds to receiver operating characteristic curve values, and the Akaike Information Criteria found that the European SCORE was superior to the Framingham Risk Score in estimating global mortality risk. In a multivariable model, independent predictors of death were a higher SCORE (for 1% predicted increase in absolute risk, relative risk [RR], 1.07; 95% confidence interval [CI], 1.04-1.09; P<.001), impaired functional capacity (RR, 2.95; 95% CI, 1.98-4.39; P<.001), and an abnormal heart rate recovery (RR, 1.59; 95%, 1.04-2.41; P =.03). ST-segment depression did not predict mortality. Among patients in the highest tertile from the SCORE, an abnormal exercise stress test result, defined as either impaired functional capacity or an abnormal heart rate recovery, identified a mortality risk of more than 1% per year.Exercise stress testing when combined with the European global risk SCORE may be useful for stratifying risk in asymptomatic individuals in a comprehensive executive health screening program.","Global risk scores and exercise testing for predicting all-cause mortality in a preventive medicine program."
"454","JAMA.244","0.03",15383517,2004,"The usefulness of exercise stress test results and global cardiovascular risk systems for predicting all-cause mortality in asymptomatic individuals seen in clinical settings is unclear.To determine the validity for prediction of all-cause mortality of the Framingham Risk Score and of a recently described European global scoring system Systematic Coronary Risk Evaluation (SCORE) for cardiovascular mortality among asymptomatic individuals evaluated in a clinical setting and to determine the potential prognostic value of exercise stress testing once these baseline risks are known.Prospective cohort study of 3554 asymptomatic adults between the ages of 50 and 75 years who underwent exercise stress testing as part of an executive health program between October 1990 and December 2002; participants were followed up for a mean of 8 years.Global risk based on the Framingham Risk Score and the European SCORE. Prospectively recorded exercise stress test result abnormalities included impaired physical fitness, abnormal heart rate recovery, ventricular ectopy, and ST-segment abnormalities. The primary end point was all-cause mortality.There were 114 deaths. The c-index, which corresponds to receiver operating characteristic curve values, and the Akaike Information Criteria found that the European SCORE was superior to the Framingham Risk Score in estimating global mortality risk. In a multivariable model, independent predictors of death were a higher SCORE (for 1% predicted increase in absolute risk, relative risk [RR], 1.07; 95% confidence interval [CI], 1.04-1.09; P<.001), impaired functional capacity (RR, 2.95; 95% CI, 1.98-4.39; P<.001), and an abnormal heart rate recovery (RR, 1.59; 95%, 1.04-2.41; P =.03). ST-segment depression did not predict mortality. Among patients in the highest tertile from the SCORE, an abnormal exercise stress test result, defined as either impaired functional capacity or an abnormal heart rate recovery, identified a mortality risk of more than 1% per year.Exercise stress testing when combined with the European global risk SCORE may be useful for stratifying risk in asymptomatic individuals in a comprehensive executive health screening program.","Global risk scores and exercise testing for predicting all-cause mortality in a preventive medicine program."
"455","JAMA.1631","NA",15467057,2004,"It is unclear if blood transfusion in anemic patients with acute coronary syndromes is associated with improved survival.To determine the association between blood transfusion and mortality among patients with acute coronary syndromes who develop bleeding, anemia, or both during their hospital course.We analyzed 24,112 enrollees in 3 large international trials of patients with acute coronary syndromes (the GUSTO IIb, PURSUIT, and PARAGON B trials). Patients were grouped according to whether they received a blood transfusion during the hospitalization. The association between transfusion and outcome was assessed using Cox proportional hazards modeling that incorporated transfusion as a time-dependent covariate and the propensity to receive blood, and a landmark analysis.Thirty-day mortality.Of the patients included, 2401 (10.0%) underwent at least 1 blood transfusion during their hospitalization. Patients who underwent transfusion were older and had more comorbid illness at presentation and also had a significantly higher unadjusted rate of 30-day death (8.00% vs 3.08%; P<.001), myocardial infarction (MI) (25.16% vs 8.16%; P<.001), and death/MI (29.24% vs 10.02%; P<.001) compared with patients who did not undergo transfusion. Using Cox proportional hazards modeling that incorporated transfusion as a time-dependent covariate, transfusion was associated with an increased hazard for 30-day death (adjusted hazard ratio [HR], 3.94; 95% confidence interval [CI], 3.26-4.75) and 30-day death/MI (HR, 2.92; 95% CI, 2.55-3.35). In the landmark analysis that included procedures and bleeding events, transfusion was associated with a trend toward increased mortality. The predicted probability of 30-day death was higher with transfusion at nadir hematocrit values above 25%.Blood transfusion in the setting of acute coronary syndromes is associated with higher mortality, and this relationship persists after adjustment for other predictive factors and timing of events. Given the limitations of post hoc analysis of clinical trials data, a randomized trial of transfusion strategies is warranted to resolve the disparity in results between our study and other observational studies. We suggest caution regarding the routine use of blood transfusion to maintain arbitrary hematocrit levels in stable patients with ischemic heart disease.","Relationship of blood transfusion and clinical outcomes in patients with acute coronary syndromes."
"456","JAMA.1641","NA",15467057,2004,"It is unclear if blood transfusion in anemic patients with acute coronary syndromes is associated with improved survival.To determine the association between blood transfusion and mortality among patients with acute coronary syndromes who develop bleeding, anemia, or both during their hospital course.We analyzed 24,112 enrollees in 3 large international trials of patients with acute coronary syndromes (the GUSTO IIb, PURSUIT, and PARAGON B trials). Patients were grouped according to whether they received a blood transfusion during the hospitalization. The association between transfusion and outcome was assessed using Cox proportional hazards modeling that incorporated transfusion as a time-dependent covariate and the propensity to receive blood, and a landmark analysis.Thirty-day mortality.Of the patients included, 2401 (10.0%) underwent at least 1 blood transfusion during their hospitalization. Patients who underwent transfusion were older and had more comorbid illness at presentation and also had a significantly higher unadjusted rate of 30-day death (8.00% vs 3.08%; P<.001), myocardial infarction (MI) (25.16% vs 8.16%; P<.001), and death/MI (29.24% vs 10.02%; P<.001) compared with patients who did not undergo transfusion. Using Cox proportional hazards modeling that incorporated transfusion as a time-dependent covariate, transfusion was associated with an increased hazard for 30-day death (adjusted hazard ratio [HR], 3.94; 95% confidence interval [CI], 3.26-4.75) and 30-day death/MI (HR, 2.92; 95% CI, 2.55-3.35). In the landmark analysis that included procedures and bleeding events, transfusion was associated with a trend toward increased mortality. The predicted probability of 30-day death was higher with transfusion at nadir hematocrit values above 25%.Blood transfusion in the setting of acute coronary syndromes is associated with higher mortality, and this relationship persists after adjustment for other predictive factors and timing of events. Given the limitations of post hoc analysis of clinical trials data, a randomized trial of transfusion strategies is warranted to resolve the disparity in results between our study and other observational studies. We suggest caution regarding the routine use of blood transfusion to maintain arbitrary hematocrit levels in stable patients with ischemic heart disease.","Relationship of blood transfusion and clinical outcomes in patients with acute coronary syndromes."
"457","JAMA.242","0.02",15479936,2004,"Low literacy is an important barrier for patients with diabetes, but interventions to address low literacy have not been well examined.To examine the role of literacy on the effectiveness of a comprehensive disease management program for patients with diabetes.Analysis of the influence of literacy on glycemic control and systolic blood pressure using data from a randomized controlled trial (conducted from February 2001 through April 2003) of a comprehensive diabetes management program. Participants were 217 patients aged 18 years or older with type 2 diabetes and poor glycemic control (glycosylated hemoglobin [HbA1c] levels > or =8.0%) and presenting to a US academic general internal medicine practice.All communication to patients was individualized and delivered to enhance comprehension among patients with low literacy. Intervention patients received intensive disease management from a multidisciplinary team. Control patients received an initial management session and continued with usual care.Achievement of goal HbA1c levels and systolic blood pressure at 12-month follow-up for control and intervention patients stratified by literacy status.Complete 12-month data were available for 193 patients (89%). Among patients with low literacy, intervention patients were more likely than control patients to achieve goal HbA1c levels (< or =7.0%) (42% vs 15%, respectively; adjusted odds ratio [OR], 4.6; 95% confidence interval [CI], 1.3 to 17.2; P = .02). Patients with higher literacy had similar odds of achieving goal HbA1c levels regardless of intervention status (24% vs 23%; adjusted OR, 1.0; 95% CI, 0.4 to 2.5; P = .98). Improvements in systolic blood pressure were similar by literacy status.Literacy may be an important factor for predicting who will benefit from an intervention for diabetes management. A diabetes disease management program that addresses literacy may be particularly beneficial for patients with low literacy, and increasing access to such a program could help reduce health disparities.","Influence of patient literacy on the effectiveness of a primary care-based diabetes disease management program."
"458","JAMA.243","0.98",15479936,2004,"Low literacy is an important barrier for patients with diabetes, but interventions to address low literacy have not been well examined.To examine the role of literacy on the effectiveness of a comprehensive disease management program for patients with diabetes.Analysis of the influence of literacy on glycemic control and systolic blood pressure using data from a randomized controlled trial (conducted from February 2001 through April 2003) of a comprehensive diabetes management program. Participants were 217 patients aged 18 years or older with type 2 diabetes and poor glycemic control (glycosylated hemoglobin [HbA1c] levels > or =8.0%) and presenting to a US academic general internal medicine practice.All communication to patients was individualized and delivered to enhance comprehension among patients with low literacy. Intervention patients received intensive disease management from a multidisciplinary team. Control patients received an initial management session and continued with usual care.Achievement of goal HbA1c levels and systolic blood pressure at 12-month follow-up for control and intervention patients stratified by literacy status.Complete 12-month data were available for 193 patients (89%). Among patients with low literacy, intervention patients were more likely than control patients to achieve goal HbA1c levels (< or =7.0%) (42% vs 15%, respectively; adjusted odds ratio [OR], 4.6; 95% confidence interval [CI], 1.3 to 17.2; P = .02). Patients with higher literacy had similar odds of achieving goal HbA1c levels regardless of intervention status (24% vs 23%; adjusted OR, 1.0; 95% CI, 0.4 to 2.5; P = .98). Improvements in systolic blood pressure were similar by literacy status.Literacy may be an important factor for predicting who will benefit from an intervention for diabetes management. A diabetes disease management program that addresses literacy may be particularly beneficial for patients with low literacy, and increasing access to such a program could help reduce health disparities.","Influence of patient literacy on the effectiveness of a primary care-based diabetes disease management program."
"459","JAMA.214","0.001",15507581,2004,"An ongoing debate focuses on whether institutions should perform percutaneous coronary interventions (PCIs) without an onsite coronary artery bypass graft (CABG) surgery program.To compare patient outcomes following PCI at US institutions performing this procedure without and with onsite cardiac surgery.Medicare hospital (part A) data were used to identify PCIs performed on fee-for-service Medicare enrollees (n = 625,854) aged at least 65 years at acute care facilities between January 1, 1999, and December 1, 2001. Hospitals without and with onsite cardiac surgery were identified based on the presence of claims for CABG surgery. Patients were characterized as undergoing primary/rescue PCI, defined as an emergency procedure performed on the same day of admission for an acute myocardial infarction (MI), vs all other PCIs.Post-PCI CABG surgery and combined in-hospital and 30-day mortality.A total of 178 hospitals performed PCIs without onsite cardiac surgery and 943 hospitals performed PCIs with onsite cardiac surgery. Patients undergoing PCIs in hospitals without onsite cardiac surgery were similar to those with onsite cardiac surgery with respect to age, sex, race, and measurable comorbidities; however, patients undergoing PCIs in hospitals without onsite cardiac surgery were more likely to have a primary/rescue PCI (22.0% vs 5.6%, P < .001). Patients undergoing PCIs in hospitals without cardiac surgery were more likely to die (6.0% vs 3.3%; adjusted odds ratio [OR], 1.29; 95% confidence interval [CI], 1.14-1.47; P < .001). After accounting for baseline differences, mortality for patients with primary/rescue PCI was similar in institutions without and with cardiac surgery (adjusted OR, 0.93; 95% CI, 0.80-1.08; P = .34). However, for the larger non-primary/rescue PCI population, mortality was higher in hospitals without onsite cardiac surgery (adjusted OR, 1.38; 95% CI, 1.14-1.67; P=.001). This increase in mortality was primarily confined to hospitals performing 50 or less Medicare PCIs per year.Percutaneous coronary interventions in hospitals without onsite cardiac surgery are often performed for reasons other than immediate treatment of an MI and are associated with a higher risk of adverse outcomes. Policies aimed at increasing access to primary/rescue PCI through promoting PCI in hospitals without cardiac surgery may inadvertently lead to an overall increase in mortality related to PCI.","Outcomes of percutaneous coronary interventions performed at centers without and with onsite coronary artery bypass graft surgery."
"460","JAMA.215","0.001",15507581,2004,"An ongoing debate focuses on whether institutions should perform percutaneous coronary interventions (PCIs) without an onsite coronary artery bypass graft (CABG) surgery program.To compare patient outcomes following PCI at US institutions performing this procedure without and with onsite cardiac surgery.Medicare hospital (part A) data were used to identify PCIs performed on fee-for-service Medicare enrollees (n = 625,854) aged at least 65 years at acute care facilities between January 1, 1999, and December 1, 2001. Hospitals without and with onsite cardiac surgery were identified based on the presence of claims for CABG surgery. Patients were characterized as undergoing primary/rescue PCI, defined as an emergency procedure performed on the same day of admission for an acute myocardial infarction (MI), vs all other PCIs.Post-PCI CABG surgery and combined in-hospital and 30-day mortality.A total of 178 hospitals performed PCIs without onsite cardiac surgery and 943 hospitals performed PCIs with onsite cardiac surgery. Patients undergoing PCIs in hospitals without onsite cardiac surgery were similar to those with onsite cardiac surgery with respect to age, sex, race, and measurable comorbidities; however, patients undergoing PCIs in hospitals without onsite cardiac surgery were more likely to have a primary/rescue PCI (22.0% vs 5.6%, P < .001). Patients undergoing PCIs in hospitals without cardiac surgery were more likely to die (6.0% vs 3.3%; adjusted odds ratio [OR], 1.29; 95% confidence interval [CI], 1.14-1.47; P < .001). After accounting for baseline differences, mortality for patients with primary/rescue PCI was similar in institutions without and with cardiac surgery (adjusted OR, 0.93; 95% CI, 0.80-1.08; P = .34). However, for the larger non-primary/rescue PCI population, mortality was higher in hospitals without onsite cardiac surgery (adjusted OR, 1.38; 95% CI, 1.14-1.67; P=.001). This increase in mortality was primarily confined to hospitals performing 50 or less Medicare PCIs per year.Percutaneous coronary interventions in hospitals without onsite cardiac surgery are often performed for reasons other than immediate treatment of an MI and are associated with a higher risk of adverse outcomes. Policies aimed at increasing access to primary/rescue PCI through promoting PCI in hospitals without cardiac surgery may inadvertently lead to an overall increase in mortality related to PCI.","Outcomes of percutaneous coronary interventions performed at centers without and with onsite coronary artery bypass graft surgery."
"461","JAMA.239","0.34",15507581,2004,"An ongoing debate focuses on whether institutions should perform percutaneous coronary interventions (PCIs) without an onsite coronary artery bypass graft (CABG) surgery program.To compare patient outcomes following PCI at US institutions performing this procedure without and with onsite cardiac surgery.Medicare hospital (part A) data were used to identify PCIs performed on fee-for-service Medicare enrollees (n = 625,854) aged at least 65 years at acute care facilities between January 1, 1999, and December 1, 2001. Hospitals without and with onsite cardiac surgery were identified based on the presence of claims for CABG surgery. Patients were characterized as undergoing primary/rescue PCI, defined as an emergency procedure performed on the same day of admission for an acute myocardial infarction (MI), vs all other PCIs.Post-PCI CABG surgery and combined in-hospital and 30-day mortality.A total of 178 hospitals performed PCIs without onsite cardiac surgery and 943 hospitals performed PCIs with onsite cardiac surgery. Patients undergoing PCIs in hospitals without onsite cardiac surgery were similar to those with onsite cardiac surgery with respect to age, sex, race, and measurable comorbidities; however, patients undergoing PCIs in hospitals without onsite cardiac surgery were more likely to have a primary/rescue PCI (22.0% vs 5.6%, P < .001). Patients undergoing PCIs in hospitals without cardiac surgery were more likely to die (6.0% vs 3.3%; adjusted odds ratio [OR], 1.29; 95% confidence interval [CI], 1.14-1.47; P < .001). After accounting for baseline differences, mortality for patients with primary/rescue PCI was similar in institutions without and with cardiac surgery (adjusted OR, 0.93; 95% CI, 0.80-1.08; P = .34). However, for the larger non-primary/rescue PCI population, mortality was higher in hospitals without onsite cardiac surgery (adjusted OR, 1.38; 95% CI, 1.14-1.67; P=.001). This increase in mortality was primarily confined to hospitals performing 50 or less Medicare PCIs per year.Percutaneous coronary interventions in hospitals without onsite cardiac surgery are often performed for reasons other than immediate treatment of an MI and are associated with a higher risk of adverse outcomes. Policies aimed at increasing access to primary/rescue PCI through promoting PCI in hospitals without cardiac surgery may inadvertently lead to an overall increase in mortality related to PCI.","Outcomes of percutaneous coronary interventions performed at centers without and with onsite coronary artery bypass graft surgery."
"462","JAMA.1611","0.003",15536108,2004,"The effect of antihypertensive drugs on cardiovascular events in patients with coronary artery disease (CAD) and normal blood pressure remains uncertain.To compare the effects of amlodipine or enalapril vs placebo on cardiovascular events in patients with CAD.Double-blind, randomized, multicenter, 24-month trial (enrollment April 1999-April 2002) comparing amlodipine or enalapril with placebo in 1991 patients with angiographically documented CAD (>20% stenosis by coronary angiography) and diastolic blood pressure <100 mm Hg. A substudy of 274 patients measured atherosclerosis progression by intravascular ultrasound (IVUS).Patients were randomized to receive amlodipine, 10 mg; enalapril, 20 mg; or placebo. IVUS was performed at baseline and study completion.The primary efficacy parameter was incidence of cardiovascular events for amlodipine vs placebo. Other outcomes included comparisons of amlodipine vs enalapril and enalapril vs placebo. Events included cardiovascular death, nonfatal myocardial infarction, resuscitated cardiac arrest, coronary revascularization, hospitalization for angina pectoris, hospitalization for congestive heart failure, fatal or nonfatal stroke or transient ischemic attack, and new diagnosis of peripheral vascular disease. The IVUS end point was change in percent atheroma volume.Baseline blood pressure averaged 129/78 mm Hg for all patients; it increased by 0.7/0.6 mm Hg in the placebo group and decreased by 4.8/2.5 mm Hg and 4.9/2.4 mm Hg in the amlodipine and enalapril groups, respectively (P<.001 for both vs placebo). Cardiovascular events occurred in 151 (23.1%) placebo-treated patients, in 110 (16.6%) amlodipine-treated patients (hazard ratio [HR], 0.69; 95% CI, 0.54-0.88 [P = .003]), and in 136 (20.2%) enalapril-treated patients (HR, 0.85; 95% CI, 0.67-1.07 [P = .16]. Primary end point comparison for enalapril vs amlodipine was not significant (HR, 0.81; 95% CI, 0.63-1.04 [P = .10]). The IVUS substudy showed a trend toward less progression of atherosclerosis in the amlodipine group vs placebo (P = .12), with significantly less progression in the subgroup with systolic blood pressures greater than the mean (P = .02). Compared with baseline, IVUS showed progression in the placebo group (P<.001), a trend toward progression in the enalapril group (P = .08), and no progression in the amlodipine group (P = .31). For the amlodipine group, correlation between blood pressure reduction and progression was r = 0.19, P = .07.Administration of amlodipine to patients with CAD and normal blood pressure resulted in reduced adverse cardiovascular events. Directionally similar, but smaller and nonsignificant, treatment effects were observed with enalapril. For amlodipine, IVUS showed evidence of slowing of atherosclerosis progression.","Effect of antihypertensive agents on cardiovascular events in patients with coronary disease and normal blood pressure: the CAMELOT study: a randomized controlled trial."
"463","JAMA.1621","0.16",15536108,2004,"The effect of antihypertensive drugs on cardiovascular events in patients with coronary artery disease (CAD) and normal blood pressure remains uncertain.To compare the effects of amlodipine or enalapril vs placebo on cardiovascular events in patients with CAD.Double-blind, randomized, multicenter, 24-month trial (enrollment April 1999-April 2002) comparing amlodipine or enalapril with placebo in 1991 patients with angiographically documented CAD (>20% stenosis by coronary angiography) and diastolic blood pressure <100 mm Hg. A substudy of 274 patients measured atherosclerosis progression by intravascular ultrasound (IVUS).Patients were randomized to receive amlodipine, 10 mg; enalapril, 20 mg; or placebo. IVUS was performed at baseline and study completion.The primary efficacy parameter was incidence of cardiovascular events for amlodipine vs placebo. Other outcomes included comparisons of amlodipine vs enalapril and enalapril vs placebo. Events included cardiovascular death, nonfatal myocardial infarction, resuscitated cardiac arrest, coronary revascularization, hospitalization for angina pectoris, hospitalization for congestive heart failure, fatal or nonfatal stroke or transient ischemic attack, and new diagnosis of peripheral vascular disease. The IVUS end point was change in percent atheroma volume.Baseline blood pressure averaged 129/78 mm Hg for all patients; it increased by 0.7/0.6 mm Hg in the placebo group and decreased by 4.8/2.5 mm Hg and 4.9/2.4 mm Hg in the amlodipine and enalapril groups, respectively (P<.001 for both vs placebo). Cardiovascular events occurred in 151 (23.1%) placebo-treated patients, in 110 (16.6%) amlodipine-treated patients (hazard ratio [HR], 0.69; 95% CI, 0.54-0.88 [P = .003]), and in 136 (20.2%) enalapril-treated patients (HR, 0.85; 95% CI, 0.67-1.07 [P = .16]. Primary end point comparison for enalapril vs amlodipine was not significant (HR, 0.81; 95% CI, 0.63-1.04 [P = .10]). The IVUS substudy showed a trend toward less progression of atherosclerosis in the amlodipine group vs placebo (P = .12), with significantly less progression in the subgroup with systolic blood pressures greater than the mean (P = .02). Compared with baseline, IVUS showed progression in the placebo group (P<.001), a trend toward progression in the enalapril group (P = .08), and no progression in the amlodipine group (P = .31). For the amlodipine group, correlation between blood pressure reduction and progression was r = 0.19, P = .07.Administration of amlodipine to patients with CAD and normal blood pressure resulted in reduced adverse cardiovascular events. Directionally similar, but smaller and nonsignificant, treatment effects were observed with enalapril. For amlodipine, IVUS showed evidence of slowing of atherosclerosis progression.","Effect of antihypertensive agents on cardiovascular events in patients with coronary disease and normal blood pressure: the CAMELOT study: a randomized controlled trial."
"464","JAMA.1911","0.1",15536108,2004,"The effect of antihypertensive drugs on cardiovascular events in patients with coronary artery disease (CAD) and normal blood pressure remains uncertain.To compare the effects of amlodipine or enalapril vs placebo on cardiovascular events in patients with CAD.Double-blind, randomized, multicenter, 24-month trial (enrollment April 1999-April 2002) comparing amlodipine or enalapril with placebo in 1991 patients with angiographically documented CAD (>20% stenosis by coronary angiography) and diastolic blood pressure <100 mm Hg. A substudy of 274 patients measured atherosclerosis progression by intravascular ultrasound (IVUS).Patients were randomized to receive amlodipine, 10 mg; enalapril, 20 mg; or placebo. IVUS was performed at baseline and study completion.The primary efficacy parameter was incidence of cardiovascular events for amlodipine vs placebo. Other outcomes included comparisons of amlodipine vs enalapril and enalapril vs placebo. Events included cardiovascular death, nonfatal myocardial infarction, resuscitated cardiac arrest, coronary revascularization, hospitalization for angina pectoris, hospitalization for congestive heart failure, fatal or nonfatal stroke or transient ischemic attack, and new diagnosis of peripheral vascular disease. The IVUS end point was change in percent atheroma volume.Baseline blood pressure averaged 129/78 mm Hg for all patients; it increased by 0.7/0.6 mm Hg in the placebo group and decreased by 4.8/2.5 mm Hg and 4.9/2.4 mm Hg in the amlodipine and enalapril groups, respectively (P<.001 for both vs placebo). Cardiovascular events occurred in 151 (23.1%) placebo-treated patients, in 110 (16.6%) amlodipine-treated patients (hazard ratio [HR], 0.69; 95% CI, 0.54-0.88 [P = .003]), and in 136 (20.2%) enalapril-treated patients (HR, 0.85; 95% CI, 0.67-1.07 [P = .16]. Primary end point comparison for enalapril vs amlodipine was not significant (HR, 0.81; 95% CI, 0.63-1.04 [P = .10]). The IVUS substudy showed a trend toward less progression of atherosclerosis in the amlodipine group vs placebo (P = .12), with significantly less progression in the subgroup with systolic blood pressures greater than the mean (P = .02). Compared with baseline, IVUS showed progression in the placebo group (P<.001), a trend toward progression in the enalapril group (P = .08), and no progression in the amlodipine group (P = .31). For the amlodipine group, correlation between blood pressure reduction and progression was r = 0.19, P = .07.Administration of amlodipine to patients with CAD and normal blood pressure resulted in reduced adverse cardiovascular events. Directionally similar, but smaller and nonsignificant, treatment effects were observed with enalapril. For amlodipine, IVUS showed evidence of slowing of atherosclerosis progression.","Effect of antihypertensive agents on cardiovascular events in patients with coronary disease and normal blood pressure: the CAMELOT study: a randomized controlled trial."
"465","JAMA.1591","0.001",15536112,2004,"Preterm birth and low birth weight are determined, at least in part, during the first trimester of pregnancy. However, it is unknown whether the risk of stillbirth is also determined during the first trimester.To determine whether the risk of antepartum stillbirth varies in relation to circulating markers of placental function measured during the first trimester of pregnancy.Multicenter, prospective cohort study (conducted in Scotland from 1998 through 2000) of 7934 women who had singleton births at or after 24 weeks' gestation, who had blood taken during the first 10 weeks after conception, and who were entered into national registries of births and perinatal deaths.Antepartum stillbirths and stillbirths due to specific causes.There were 8 stillbirths among the 400 women with levels of pregnancy-associated plasma protein A (PAPP-A) in the lowest fifth percentile compared with 17 among the remaining 7534 women (incidence rate per 10,000 women per week of gestation: 13.4 vs 1.4, respectively; hazard ratio [HR], 9.2 [95% confidence interval [CI], 4.0-21.4]; P<.001). When analyzed by cause of stillbirth, low level of PAPP-A was strongly associated with stillbirth due to placental dysfunction, defined as abruption or unexplained stillbirth associated with growth restriction (incidence rate: 11.7 vs 0.3, respectively; HR, 46.0 [95% CI, 11.9-178.0]; P<.001), but was not associated with other causes of stillbirth (incidence rate: 1.7 vs 1.1, respectively; HR, 1.4 [95% CI, 0.2-10.6]; P = .75). There was no relationship between having a low level of PAPP-A and maternal age, ethnicity, parity, height, body mass index, race, or marital status. Adjustment for maternal factors did not attenuate the strength of associations observed. There was no association between maternal circulating levels of the free beta subunit of human chorionic gonadotropin and stillbirth risk.The risk of stillbirth in late pregnancy may be determined by placental function in the first 10 weeks after conception.","First-trimester placentation and the risk of antepartum stillbirth."
"466","JAMA.1601","0.001",15536112,2004,"Preterm birth and low birth weight are determined, at least in part, during the first trimester of pregnancy. However, it is unknown whether the risk of stillbirth is also determined during the first trimester.To determine whether the risk of antepartum stillbirth varies in relation to circulating markers of placental function measured during the first trimester of pregnancy.Multicenter, prospective cohort study (conducted in Scotland from 1998 through 2000) of 7934 women who had singleton births at or after 24 weeks' gestation, who had blood taken during the first 10 weeks after conception, and who were entered into national registries of births and perinatal deaths.Antepartum stillbirths and stillbirths due to specific causes.There were 8 stillbirths among the 400 women with levels of pregnancy-associated plasma protein A (PAPP-A) in the lowest fifth percentile compared with 17 among the remaining 7534 women (incidence rate per 10,000 women per week of gestation: 13.4 vs 1.4, respectively; hazard ratio [HR], 9.2 [95% confidence interval [CI], 4.0-21.4]; P<.001). When analyzed by cause of stillbirth, low level of PAPP-A was strongly associated with stillbirth due to placental dysfunction, defined as abruption or unexplained stillbirth associated with growth restriction (incidence rate: 11.7 vs 0.3, respectively; HR, 46.0 [95% CI, 11.9-178.0]; P<.001), but was not associated with other causes of stillbirth (incidence rate: 1.7 vs 1.1, respectively; HR, 1.4 [95% CI, 0.2-10.6]; P = .75). There was no relationship between having a low level of PAPP-A and maternal age, ethnicity, parity, height, body mass index, race, or marital status. Adjustment for maternal factors did not attenuate the strength of associations observed. There was no association between maternal circulating levels of the free beta subunit of human chorionic gonadotropin and stillbirth risk.The risk of stillbirth in late pregnancy may be determined by placental function in the first 10 weeks after conception.","First-trimester placentation and the risk of antepartum stillbirth."
"467","JAMA.1901","0.75",15536112,2004,"Preterm birth and low birth weight are determined, at least in part, during the first trimester of pregnancy. However, it is unknown whether the risk of stillbirth is also determined during the first trimester.To determine whether the risk of antepartum stillbirth varies in relation to circulating markers of placental function measured during the first trimester of pregnancy.Multicenter, prospective cohort study (conducted in Scotland from 1998 through 2000) of 7934 women who had singleton births at or after 24 weeks' gestation, who had blood taken during the first 10 weeks after conception, and who were entered into national registries of births and perinatal deaths.Antepartum stillbirths and stillbirths due to specific causes.There were 8 stillbirths among the 400 women with levels of pregnancy-associated plasma protein A (PAPP-A) in the lowest fifth percentile compared with 17 among the remaining 7534 women (incidence rate per 10,000 women per week of gestation: 13.4 vs 1.4, respectively; hazard ratio [HR], 9.2 [95% confidence interval [CI], 4.0-21.4]; P<.001). When analyzed by cause of stillbirth, low level of PAPP-A was strongly associated with stillbirth due to placental dysfunction, defined as abruption or unexplained stillbirth associated with growth restriction (incidence rate: 11.7 vs 0.3, respectively; HR, 46.0 [95% CI, 11.9-178.0]; P<.001), but was not associated with other causes of stillbirth (incidence rate: 1.7 vs 1.1, respectively; HR, 1.4 [95% CI, 0.2-10.6]; P = .75). There was no relationship between having a low level of PAPP-A and maternal age, ethnicity, parity, height, body mass index, race, or marital status. Adjustment for maternal factors did not attenuate the strength of associations observed. There was no association between maternal circulating levels of the free beta subunit of human chorionic gonadotropin and stillbirth risk.The risk of stillbirth in late pregnancy may be determined by placental function in the first 10 weeks after conception.","First-trimester placentation and the risk of antepartum stillbirth."
"468","JAMA.1541","0.001",15547161,2004,"Electrocardiographic left ventricular hypertrophy (LVH) is a strong predictor of cardiovascular (CV) morbidity and mortality. However, the predictive value of changes in the magnitude of electrocardiographic LVH criteria during antihypertensive therapy remains unclear.To test the hypothesis that lesser severity of electrocardiographic LVH during antihypertensive treatment is associated with decreased CV morbidity and mortality, independent of blood pressure levels and reduction and treatment modality.Double-blind, randomized, parallel-group study conducted in 1995-2001 among 9193 men and women with hypertension aged 55 through 80 years (mean, 67 years), with electrocardiographic LVH by Cornell voltage-duration product or Sokolow-Lyon voltage criteria and enrolled in the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) study.Losartan- or atenolol-based treatment regimens, with follow-up assessments for at least 4 (mean, 4.8 [SD, 0.9]) years.Composite end point of CV death, myocardial infarction (MI), or stroke in relation to severity of electrocardiographic LVH determined at baseline and on subsequent electrocardiograms obtained at 1 or more annual revisits.Cardiovascular death, nonfatal MI, or stroke occurred in 1096 patients (11.9%). In Cox regression models controlling for treatment type, baseline Framingham risk score, baseline and in-treatment blood pressure, and severity of baseline electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage, less-severe in-treatment LVH by Cornell product and Sokolow-Lyon voltage were associated with 14% and 17% lower rates, respectively, of the composite CV end point (adjusted hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.82-0.90; P<.001 for every 1050-mm x ms [1-SD] decrease in Cornell product; and HR, 0.83; 95% CI, 0.78-0.88; P<.001 for every 10.5-mm [1-SD] decrease in Sokolow-Lyon voltage). In parallel analyses, lower Cornell product and Sokolow-Lyon voltage were each independently associated with lower risks of CV mortality (HR, 0.78; 95% CI, 0.73-0.83; P<.001; and HR, 0.80; 95% CI, 0.73-0.87; P<.001, respectively), MI (HR, 0.90; 95% CI, 0.82-0.98; P=.01; and HR, 0.90; 95% CI, 0.81-1.00; P = .04), and stroke (HR, 0.90; 95% CI, 0.84-0.96; P=.002; and HR, 0.81; 95% CI, 0.75-0.89; P<.001).Less-severe electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage criteria during antihypertensive therapy is associated with lower likelihoods of CV morbidity and mortality, independent of blood pressure lowering and treatment modality in persons with essential hypertension. Antihypertensive therapy targeted at regression or prevention of electrocardiographic LVH may improve prognosis.","Regression of electrocardiographic left ventricular hypertrophy during antihypertensive treatment and the prediction of major cardiovascular events."
"469","JAMA.1551","0.001",15547161,2004,"Electrocardiographic left ventricular hypertrophy (LVH) is a strong predictor of cardiovascular (CV) morbidity and mortality. However, the predictive value of changes in the magnitude of electrocardiographic LVH criteria during antihypertensive therapy remains unclear.To test the hypothesis that lesser severity of electrocardiographic LVH during antihypertensive treatment is associated with decreased CV morbidity and mortality, independent of blood pressure levels and reduction and treatment modality.Double-blind, randomized, parallel-group study conducted in 1995-2001 among 9193 men and women with hypertension aged 55 through 80 years (mean, 67 years), with electrocardiographic LVH by Cornell voltage-duration product or Sokolow-Lyon voltage criteria and enrolled in the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) study.Losartan- or atenolol-based treatment regimens, with follow-up assessments for at least 4 (mean, 4.8 [SD, 0.9]) years.Composite end point of CV death, myocardial infarction (MI), or stroke in relation to severity of electrocardiographic LVH determined at baseline and on subsequent electrocardiograms obtained at 1 or more annual revisits.Cardiovascular death, nonfatal MI, or stroke occurred in 1096 patients (11.9%). In Cox regression models controlling for treatment type, baseline Framingham risk score, baseline and in-treatment blood pressure, and severity of baseline electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage, less-severe in-treatment LVH by Cornell product and Sokolow-Lyon voltage were associated with 14% and 17% lower rates, respectively, of the composite CV end point (adjusted hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.82-0.90; P<.001 for every 1050-mm x ms [1-SD] decrease in Cornell product; and HR, 0.83; 95% CI, 0.78-0.88; P<.001 for every 10.5-mm [1-SD] decrease in Sokolow-Lyon voltage). In parallel analyses, lower Cornell product and Sokolow-Lyon voltage were each independently associated with lower risks of CV mortality (HR, 0.78; 95% CI, 0.73-0.83; P<.001; and HR, 0.80; 95% CI, 0.73-0.87; P<.001, respectively), MI (HR, 0.90; 95% CI, 0.82-0.98; P=.01; and HR, 0.90; 95% CI, 0.81-1.00; P = .04), and stroke (HR, 0.90; 95% CI, 0.84-0.96; P=.002; and HR, 0.81; 95% CI, 0.75-0.89; P<.001).Less-severe electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage criteria during antihypertensive therapy is associated with lower likelihoods of CV morbidity and mortality, independent of blood pressure lowering and treatment modality in persons with essential hypertension. Antihypertensive therapy targeted at regression or prevention of electrocardiographic LVH may improve prognosis.","Regression of electrocardiographic left ventricular hypertrophy during antihypertensive treatment and the prediction of major cardiovascular events."
"470","JAMA.1561","0.001",15547161,2004,"Electrocardiographic left ventricular hypertrophy (LVH) is a strong predictor of cardiovascular (CV) morbidity and mortality. However, the predictive value of changes in the magnitude of electrocardiographic LVH criteria during antihypertensive therapy remains unclear.To test the hypothesis that lesser severity of electrocardiographic LVH during antihypertensive treatment is associated with decreased CV morbidity and mortality, independent of blood pressure levels and reduction and treatment modality.Double-blind, randomized, parallel-group study conducted in 1995-2001 among 9193 men and women with hypertension aged 55 through 80 years (mean, 67 years), with electrocardiographic LVH by Cornell voltage-duration product or Sokolow-Lyon voltage criteria and enrolled in the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) study.Losartan- or atenolol-based treatment regimens, with follow-up assessments for at least 4 (mean, 4.8 [SD, 0.9]) years.Composite end point of CV death, myocardial infarction (MI), or stroke in relation to severity of electrocardiographic LVH determined at baseline and on subsequent electrocardiograms obtained at 1 or more annual revisits.Cardiovascular death, nonfatal MI, or stroke occurred in 1096 patients (11.9%). In Cox regression models controlling for treatment type, baseline Framingham risk score, baseline and in-treatment blood pressure, and severity of baseline electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage, less-severe in-treatment LVH by Cornell product and Sokolow-Lyon voltage were associated with 14% and 17% lower rates, respectively, of the composite CV end point (adjusted hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.82-0.90; P<.001 for every 1050-mm x ms [1-SD] decrease in Cornell product; and HR, 0.83; 95% CI, 0.78-0.88; P<.001 for every 10.5-mm [1-SD] decrease in Sokolow-Lyon voltage). In parallel analyses, lower Cornell product and Sokolow-Lyon voltage were each independently associated with lower risks of CV mortality (HR, 0.78; 95% CI, 0.73-0.83; P<.001; and HR, 0.80; 95% CI, 0.73-0.87; P<.001, respectively), MI (HR, 0.90; 95% CI, 0.82-0.98; P=.01; and HR, 0.90; 95% CI, 0.81-1.00; P = .04), and stroke (HR, 0.90; 95% CI, 0.84-0.96; P=.002; and HR, 0.81; 95% CI, 0.75-0.89; P<.001).Less-severe electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage criteria during antihypertensive therapy is associated with lower likelihoods of CV morbidity and mortality, independent of blood pressure lowering and treatment modality in persons with essential hypertension. Antihypertensive therapy targeted at regression or prevention of electrocardiographic LVH may improve prognosis.","Regression of electrocardiographic left ventricular hypertrophy during antihypertensive treatment and the prediction of major cardiovascular events."
"471","JAMA.1571","0.001",15547161,2004,"Electrocardiographic left ventricular hypertrophy (LVH) is a strong predictor of cardiovascular (CV) morbidity and mortality. However, the predictive value of changes in the magnitude of electrocardiographic LVH criteria during antihypertensive therapy remains unclear.To test the hypothesis that lesser severity of electrocardiographic LVH during antihypertensive treatment is associated with decreased CV morbidity and mortality, independent of blood pressure levels and reduction and treatment modality.Double-blind, randomized, parallel-group study conducted in 1995-2001 among 9193 men and women with hypertension aged 55 through 80 years (mean, 67 years), with electrocardiographic LVH by Cornell voltage-duration product or Sokolow-Lyon voltage criteria and enrolled in the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) study.Losartan- or atenolol-based treatment regimens, with follow-up assessments for at least 4 (mean, 4.8 [SD, 0.9]) years.Composite end point of CV death, myocardial infarction (MI), or stroke in relation to severity of electrocardiographic LVH determined at baseline and on subsequent electrocardiograms obtained at 1 or more annual revisits.Cardiovascular death, nonfatal MI, or stroke occurred in 1096 patients (11.9%). In Cox regression models controlling for treatment type, baseline Framingham risk score, baseline and in-treatment blood pressure, and severity of baseline electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage, less-severe in-treatment LVH by Cornell product and Sokolow-Lyon voltage were associated with 14% and 17% lower rates, respectively, of the composite CV end point (adjusted hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.82-0.90; P<.001 for every 1050-mm x ms [1-SD] decrease in Cornell product; and HR, 0.83; 95% CI, 0.78-0.88; P<.001 for every 10.5-mm [1-SD] decrease in Sokolow-Lyon voltage). In parallel analyses, lower Cornell product and Sokolow-Lyon voltage were each independently associated with lower risks of CV mortality (HR, 0.78; 95% CI, 0.73-0.83; P<.001; and HR, 0.80; 95% CI, 0.73-0.87; P<.001, respectively), MI (HR, 0.90; 95% CI, 0.82-0.98; P=.01; and HR, 0.90; 95% CI, 0.81-1.00; P = .04), and stroke (HR, 0.90; 95% CI, 0.84-0.96; P=.002; and HR, 0.81; 95% CI, 0.75-0.89; P<.001).Less-severe electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage criteria during antihypertensive therapy is associated with lower likelihoods of CV morbidity and mortality, independent of blood pressure lowering and treatment modality in persons with essential hypertension. Antihypertensive therapy targeted at regression or prevention of electrocardiographic LVH may improve prognosis.","Regression of electrocardiographic left ventricular hypertrophy during antihypertensive treatment and the prediction of major cardiovascular events."
"472","JAMA.1581","0.001",15547161,2004,"Electrocardiographic left ventricular hypertrophy (LVH) is a strong predictor of cardiovascular (CV) morbidity and mortality. However, the predictive value of changes in the magnitude of electrocardiographic LVH criteria during antihypertensive therapy remains unclear.To test the hypothesis that lesser severity of electrocardiographic LVH during antihypertensive treatment is associated with decreased CV morbidity and mortality, independent of blood pressure levels and reduction and treatment modality.Double-blind, randomized, parallel-group study conducted in 1995-2001 among 9193 men and women with hypertension aged 55 through 80 years (mean, 67 years), with electrocardiographic LVH by Cornell voltage-duration product or Sokolow-Lyon voltage criteria and enrolled in the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) study.Losartan- or atenolol-based treatment regimens, with follow-up assessments for at least 4 (mean, 4.8 [SD, 0.9]) years.Composite end point of CV death, myocardial infarction (MI), or stroke in relation to severity of electrocardiographic LVH determined at baseline and on subsequent electrocardiograms obtained at 1 or more annual revisits.Cardiovascular death, nonfatal MI, or stroke occurred in 1096 patients (11.9%). In Cox regression models controlling for treatment type, baseline Framingham risk score, baseline and in-treatment blood pressure, and severity of baseline electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage, less-severe in-treatment LVH by Cornell product and Sokolow-Lyon voltage were associated with 14% and 17% lower rates, respectively, of the composite CV end point (adjusted hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.82-0.90; P<.001 for every 1050-mm x ms [1-SD] decrease in Cornell product; and HR, 0.83; 95% CI, 0.78-0.88; P<.001 for every 10.5-mm [1-SD] decrease in Sokolow-Lyon voltage). In parallel analyses, lower Cornell product and Sokolow-Lyon voltage were each independently associated with lower risks of CV mortality (HR, 0.78; 95% CI, 0.73-0.83; P<.001; and HR, 0.80; 95% CI, 0.73-0.87; P<.001, respectively), MI (HR, 0.90; 95% CI, 0.82-0.98; P=.01; and HR, 0.90; 95% CI, 0.81-1.00; P = .04), and stroke (HR, 0.90; 95% CI, 0.84-0.96; P=.002; and HR, 0.81; 95% CI, 0.75-0.89; P<.001).Less-severe electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage criteria during antihypertensive therapy is associated with lower likelihoods of CV morbidity and mortality, independent of blood pressure lowering and treatment modality in persons with essential hypertension. Antihypertensive therapy targeted at regression or prevention of electrocardiographic LVH may improve prognosis.","Regression of electrocardiographic left ventricular hypertrophy during antihypertensive treatment and the prediction of major cardiovascular events."
"473","JAMA.1871","0.01",15547161,2004,"Electrocardiographic left ventricular hypertrophy (LVH) is a strong predictor of cardiovascular (CV) morbidity and mortality. However, the predictive value of changes in the magnitude of electrocardiographic LVH criteria during antihypertensive therapy remains unclear.To test the hypothesis that lesser severity of electrocardiographic LVH during antihypertensive treatment is associated with decreased CV morbidity and mortality, independent of blood pressure levels and reduction and treatment modality.Double-blind, randomized, parallel-group study conducted in 1995-2001 among 9193 men and women with hypertension aged 55 through 80 years (mean, 67 years), with electrocardiographic LVH by Cornell voltage-duration product or Sokolow-Lyon voltage criteria and enrolled in the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) study.Losartan- or atenolol-based treatment regimens, with follow-up assessments for at least 4 (mean, 4.8 [SD, 0.9]) years.Composite end point of CV death, myocardial infarction (MI), or stroke in relation to severity of electrocardiographic LVH determined at baseline and on subsequent electrocardiograms obtained at 1 or more annual revisits.Cardiovascular death, nonfatal MI, or stroke occurred in 1096 patients (11.9%). In Cox regression models controlling for treatment type, baseline Framingham risk score, baseline and in-treatment blood pressure, and severity of baseline electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage, less-severe in-treatment LVH by Cornell product and Sokolow-Lyon voltage were associated with 14% and 17% lower rates, respectively, of the composite CV end point (adjusted hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.82-0.90; P<.001 for every 1050-mm x ms [1-SD] decrease in Cornell product; and HR, 0.83; 95% CI, 0.78-0.88; P<.001 for every 10.5-mm [1-SD] decrease in Sokolow-Lyon voltage). In parallel analyses, lower Cornell product and Sokolow-Lyon voltage were each independently associated with lower risks of CV mortality (HR, 0.78; 95% CI, 0.73-0.83; P<.001; and HR, 0.80; 95% CI, 0.73-0.87; P<.001, respectively), MI (HR, 0.90; 95% CI, 0.82-0.98; P=.01; and HR, 0.90; 95% CI, 0.81-1.00; P = .04), and stroke (HR, 0.90; 95% CI, 0.84-0.96; P=.002; and HR, 0.81; 95% CI, 0.75-0.89; P<.001).Less-severe electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage criteria during antihypertensive therapy is associated with lower likelihoods of CV morbidity and mortality, independent of blood pressure lowering and treatment modality in persons with essential hypertension. Antihypertensive therapy targeted at regression or prevention of electrocardiographic LVH may improve prognosis.","Regression of electrocardiographic left ventricular hypertrophy during antihypertensive treatment and the prediction of major cardiovascular events."
"474","JAMA.1881","0.04",15547161,2004,"Electrocardiographic left ventricular hypertrophy (LVH) is a strong predictor of cardiovascular (CV) morbidity and mortality. However, the predictive value of changes in the magnitude of electrocardiographic LVH criteria during antihypertensive therapy remains unclear.To test the hypothesis that lesser severity of electrocardiographic LVH during antihypertensive treatment is associated with decreased CV morbidity and mortality, independent of blood pressure levels and reduction and treatment modality.Double-blind, randomized, parallel-group study conducted in 1995-2001 among 9193 men and women with hypertension aged 55 through 80 years (mean, 67 years), with electrocardiographic LVH by Cornell voltage-duration product or Sokolow-Lyon voltage criteria and enrolled in the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) study.Losartan- or atenolol-based treatment regimens, with follow-up assessments for at least 4 (mean, 4.8 [SD, 0.9]) years.Composite end point of CV death, myocardial infarction (MI), or stroke in relation to severity of electrocardiographic LVH determined at baseline and on subsequent electrocardiograms obtained at 1 or more annual revisits.Cardiovascular death, nonfatal MI, or stroke occurred in 1096 patients (11.9%). In Cox regression models controlling for treatment type, baseline Framingham risk score, baseline and in-treatment blood pressure, and severity of baseline electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage, less-severe in-treatment LVH by Cornell product and Sokolow-Lyon voltage were associated with 14% and 17% lower rates, respectively, of the composite CV end point (adjusted hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.82-0.90; P<.001 for every 1050-mm x ms [1-SD] decrease in Cornell product; and HR, 0.83; 95% CI, 0.78-0.88; P<.001 for every 10.5-mm [1-SD] decrease in Sokolow-Lyon voltage). In parallel analyses, lower Cornell product and Sokolow-Lyon voltage were each independently associated with lower risks of CV mortality (HR, 0.78; 95% CI, 0.73-0.83; P<.001; and HR, 0.80; 95% CI, 0.73-0.87; P<.001, respectively), MI (HR, 0.90; 95% CI, 0.82-0.98; P=.01; and HR, 0.90; 95% CI, 0.81-1.00; P = .04), and stroke (HR, 0.90; 95% CI, 0.84-0.96; P=.002; and HR, 0.81; 95% CI, 0.75-0.89; P<.001).Less-severe electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage criteria during antihypertensive therapy is associated with lower likelihoods of CV morbidity and mortality, independent of blood pressure lowering and treatment modality in persons with essential hypertension. Antihypertensive therapy targeted at regression or prevention of electrocardiographic LVH may improve prognosis.","Regression of electrocardiographic left ventricular hypertrophy during antihypertensive treatment and the prediction of major cardiovascular events."
"475","JAMA.1891","0.002",15547161,2004,"Electrocardiographic left ventricular hypertrophy (LVH) is a strong predictor of cardiovascular (CV) morbidity and mortality. However, the predictive value of changes in the magnitude of electrocardiographic LVH criteria during antihypertensive therapy remains unclear.To test the hypothesis that lesser severity of electrocardiographic LVH during antihypertensive treatment is associated with decreased CV morbidity and mortality, independent of blood pressure levels and reduction and treatment modality.Double-blind, randomized, parallel-group study conducted in 1995-2001 among 9193 men and women with hypertension aged 55 through 80 years (mean, 67 years), with electrocardiographic LVH by Cornell voltage-duration product or Sokolow-Lyon voltage criteria and enrolled in the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) study.Losartan- or atenolol-based treatment regimens, with follow-up assessments for at least 4 (mean, 4.8 [SD, 0.9]) years.Composite end point of CV death, myocardial infarction (MI), or stroke in relation to severity of electrocardiographic LVH determined at baseline and on subsequent electrocardiograms obtained at 1 or more annual revisits.Cardiovascular death, nonfatal MI, or stroke occurred in 1096 patients (11.9%). In Cox regression models controlling for treatment type, baseline Framingham risk score, baseline and in-treatment blood pressure, and severity of baseline electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage, less-severe in-treatment LVH by Cornell product and Sokolow-Lyon voltage were associated with 14% and 17% lower rates, respectively, of the composite CV end point (adjusted hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.82-0.90; P<.001 for every 1050-mm x ms [1-SD] decrease in Cornell product; and HR, 0.83; 95% CI, 0.78-0.88; P<.001 for every 10.5-mm [1-SD] decrease in Sokolow-Lyon voltage). In parallel analyses, lower Cornell product and Sokolow-Lyon voltage were each independently associated with lower risks of CV mortality (HR, 0.78; 95% CI, 0.73-0.83; P<.001; and HR, 0.80; 95% CI, 0.73-0.87; P<.001, respectively), MI (HR, 0.90; 95% CI, 0.82-0.98; P=.01; and HR, 0.90; 95% CI, 0.81-1.00; P = .04), and stroke (HR, 0.90; 95% CI, 0.84-0.96; P=.002; and HR, 0.81; 95% CI, 0.75-0.89; P<.001).Less-severe electrocardiographic LVH by Cornell product and Sokolow-Lyon voltage criteria during antihypertensive therapy is associated with lower likelihoods of CV morbidity and mortality, independent of blood pressure lowering and treatment modality in persons with essential hypertension. Antihypertensive therapy targeted at regression or prevention of electrocardiographic LVH may improve prognosis.","Regression of electrocardiographic left ventricular hypertrophy during antihypertensive treatment and the prediction of major cardiovascular events."
"476","JAMA.1821","0.009",15547162,2004,"Increased baseline left ventricular (LV) mass predicts cardiovascular (CV) complications of hypertension, but the relation between lower LV mass and outcome during treatment for hypertension is uncertain.To determine whether reduction of LV mass during antihypertensive treatment modifies risk of major CV events independent of blood pressure change.Prospective cohort substudy of the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) randomized clinical trial, conducted from 1995 to 2001. A total of 941 prospectively identified patients aged 55 to 80 years with essential hypertension and electrocardiographic LV hypertrophy had LV mass measured by echocardiography at enrollment in the LIFE trial and thereafter were followed up annually for a mean (SD) of 4.8 (1.0) years for CV events.Composite end point of CV death, fatal or nonfatal myocardial infarction, and fatal or nonfatal stroke.The composite end point occurred in 104 patients (11%). The multivariable Cox regression model showed a strong association between lower in-treatment LV mass index and reduced rate of the composite CV end point (hazard ratio [HR], 0.78 per 1-SD (25.3) decrease in LV mass index; 95% confidence interval [CI], 0.65-0.94; P = .009) over and above that predicted by reduction in blood pressure. There were parallel associations between lower in-treatment LV mass index and lower CV mortality (HR, 0.62; 95% CI, 0.47-0.82; P = .001), stroke (HR, 0.76; 95% CI, 0.60-0.96; P = .02), myocardial infarction (HR, 0.85; 95% CI, 0.62-1.17, P = .33), and all-cause mortality (HR, 0.72; 95% CI, 0.59-0.88, P = .002), independent of systolic blood pressure and assigned treatment. Results were confirmed in analyses adjusting for additional CV risk factors, electrocardiographic changes, or when only considering events after the first year of study treatment.In patients with essential hypertension and baseline electrocardiographic LV hypertrophy, lower LV mass during antihypertensive treatment is associated with lower rates of clinical end points, additional to effects of blood pressure lowering and treatment modality.","Prognostic significance of left ventricular mass change during treatment of hypertension."
"477","JAMA.1831","0.001",15547162,2004,"Increased baseline left ventricular (LV) mass predicts cardiovascular (CV) complications of hypertension, but the relation between lower LV mass and outcome during treatment for hypertension is uncertain.To determine whether reduction of LV mass during antihypertensive treatment modifies risk of major CV events independent of blood pressure change.Prospective cohort substudy of the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) randomized clinical trial, conducted from 1995 to 2001. A total of 941 prospectively identified patients aged 55 to 80 years with essential hypertension and electrocardiographic LV hypertrophy had LV mass measured by echocardiography at enrollment in the LIFE trial and thereafter were followed up annually for a mean (SD) of 4.8 (1.0) years for CV events.Composite end point of CV death, fatal or nonfatal myocardial infarction, and fatal or nonfatal stroke.The composite end point occurred in 104 patients (11%). The multivariable Cox regression model showed a strong association between lower in-treatment LV mass index and reduced rate of the composite CV end point (hazard ratio [HR], 0.78 per 1-SD (25.3) decrease in LV mass index; 95% confidence interval [CI], 0.65-0.94; P = .009) over and above that predicted by reduction in blood pressure. There were parallel associations between lower in-treatment LV mass index and lower CV mortality (HR, 0.62; 95% CI, 0.47-0.82; P = .001), stroke (HR, 0.76; 95% CI, 0.60-0.96; P = .02), myocardial infarction (HR, 0.85; 95% CI, 0.62-1.17, P = .33), and all-cause mortality (HR, 0.72; 95% CI, 0.59-0.88, P = .002), independent of systolic blood pressure and assigned treatment. Results were confirmed in analyses adjusting for additional CV risk factors, electrocardiographic changes, or when only considering events after the first year of study treatment.In patients with essential hypertension and baseline electrocardiographic LV hypertrophy, lower LV mass during antihypertensive treatment is associated with lower rates of clinical end points, additional to effects of blood pressure lowering and treatment modality.","Prognostic significance of left ventricular mass change during treatment of hypertension."
"478","JAMA.1841","0.02",15547162,2004,"Increased baseline left ventricular (LV) mass predicts cardiovascular (CV) complications of hypertension, but the relation between lower LV mass and outcome during treatment for hypertension is uncertain.To determine whether reduction of LV mass during antihypertensive treatment modifies risk of major CV events independent of blood pressure change.Prospective cohort substudy of the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) randomized clinical trial, conducted from 1995 to 2001. A total of 941 prospectively identified patients aged 55 to 80 years with essential hypertension and electrocardiographic LV hypertrophy had LV mass measured by echocardiography at enrollment in the LIFE trial and thereafter were followed up annually for a mean (SD) of 4.8 (1.0) years for CV events.Composite end point of CV death, fatal or nonfatal myocardial infarction, and fatal or nonfatal stroke.The composite end point occurred in 104 patients (11%). The multivariable Cox regression model showed a strong association between lower in-treatment LV mass index and reduced rate of the composite CV end point (hazard ratio [HR], 0.78 per 1-SD (25.3) decrease in LV mass index; 95% confidence interval [CI], 0.65-0.94; P = .009) over and above that predicted by reduction in blood pressure. There were parallel associations between lower in-treatment LV mass index and lower CV mortality (HR, 0.62; 95% CI, 0.47-0.82; P = .001), stroke (HR, 0.76; 95% CI, 0.60-0.96; P = .02), myocardial infarction (HR, 0.85; 95% CI, 0.62-1.17, P = .33), and all-cause mortality (HR, 0.72; 95% CI, 0.59-0.88, P = .002), independent of systolic blood pressure and assigned treatment. Results were confirmed in analyses adjusting for additional CV risk factors, electrocardiographic changes, or when only considering events after the first year of study treatment.In patients with essential hypertension and baseline electrocardiographic LV hypertrophy, lower LV mass during antihypertensive treatment is associated with lower rates of clinical end points, additional to effects of blood pressure lowering and treatment modality.","Prognostic significance of left ventricular mass change during treatment of hypertension."
"479","JAMA.1851","0.33",15547162,2004,"Increased baseline left ventricular (LV) mass predicts cardiovascular (CV) complications of hypertension, but the relation between lower LV mass and outcome during treatment for hypertension is uncertain.To determine whether reduction of LV mass during antihypertensive treatment modifies risk of major CV events independent of blood pressure change.Prospective cohort substudy of the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) randomized clinical trial, conducted from 1995 to 2001. A total of 941 prospectively identified patients aged 55 to 80 years with essential hypertension and electrocardiographic LV hypertrophy had LV mass measured by echocardiography at enrollment in the LIFE trial and thereafter were followed up annually for a mean (SD) of 4.8 (1.0) years for CV events.Composite end point of CV death, fatal or nonfatal myocardial infarction, and fatal or nonfatal stroke.The composite end point occurred in 104 patients (11%). The multivariable Cox regression model showed a strong association between lower in-treatment LV mass index and reduced rate of the composite CV end point (hazard ratio [HR], 0.78 per 1-SD (25.3) decrease in LV mass index; 95% confidence interval [CI], 0.65-0.94; P = .009) over and above that predicted by reduction in blood pressure. There were parallel associations between lower in-treatment LV mass index and lower CV mortality (HR, 0.62; 95% CI, 0.47-0.82; P = .001), stroke (HR, 0.76; 95% CI, 0.60-0.96; P = .02), myocardial infarction (HR, 0.85; 95% CI, 0.62-1.17, P = .33), and all-cause mortality (HR, 0.72; 95% CI, 0.59-0.88, P = .002), independent of systolic blood pressure and assigned treatment. Results were confirmed in analyses adjusting for additional CV risk factors, electrocardiographic changes, or when only considering events after the first year of study treatment.In patients with essential hypertension and baseline electrocardiographic LV hypertrophy, lower LV mass during antihypertensive treatment is associated with lower rates of clinical end points, additional to effects of blood pressure lowering and treatment modality.","Prognostic significance of left ventricular mass change during treatment of hypertension."
"480","JAMA.1861","0.002",15547162,2004,"Increased baseline left ventricular (LV) mass predicts cardiovascular (CV) complications of hypertension, but the relation between lower LV mass and outcome during treatment for hypertension is uncertain.To determine whether reduction of LV mass during antihypertensive treatment modifies risk of major CV events independent of blood pressure change.Prospective cohort substudy of the Losartan Intervention For Endpoint Reduction in Hypertension (LIFE) randomized clinical trial, conducted from 1995 to 2001. A total of 941 prospectively identified patients aged 55 to 80 years with essential hypertension and electrocardiographic LV hypertrophy had LV mass measured by echocardiography at enrollment in the LIFE trial and thereafter were followed up annually for a mean (SD) of 4.8 (1.0) years for CV events.Composite end point of CV death, fatal or nonfatal myocardial infarction, and fatal or nonfatal stroke.The composite end point occurred in 104 patients (11%). The multivariable Cox regression model showed a strong association between lower in-treatment LV mass index and reduced rate of the composite CV end point (hazard ratio [HR], 0.78 per 1-SD (25.3) decrease in LV mass index; 95% confidence interval [CI], 0.65-0.94; P = .009) over and above that predicted by reduction in blood pressure. There were parallel associations between lower in-treatment LV mass index and lower CV mortality (HR, 0.62; 95% CI, 0.47-0.82; P = .001), stroke (HR, 0.76; 95% CI, 0.60-0.96; P = .02), myocardial infarction (HR, 0.85; 95% CI, 0.62-1.17, P = .33), and all-cause mortality (HR, 0.72; 95% CI, 0.59-0.88, P = .002), independent of systolic blood pressure and assigned treatment. Results were confirmed in analyses adjusting for additional CV risk factors, electrocardiographic changes, or when only considering events after the first year of study treatment.In patients with essential hypertension and baseline electrocardiographic LV hypertrophy, lower LV mass during antihypertensive treatment is associated with lower rates of clinical end points, additional to effects of blood pressure lowering and treatment modality.","Prognostic significance of left ventricular mass change during treatment of hypertension."
"481","Lancet.2110","2.00E-04",15555666,2004,"No trials of co-trimoxazole (trimethoprim-sulfamethoxazole) prophylaxis for HIV-infected adults or children have been done in areas with high levels of bacterial resistance to this antibiotic. We aimed to assess the efficacy of daily co-trimoxazole in such an area.We did a double-blind randomised placebo-controlled trial in children aged 1-14 years with clinical features of HIV infection in Zambia. Primary outcomes were mortality and adverse events possibly related to treatment. Analysis was by intention to treat.In October, 2003, the data and safety monitoring committee recommended early stopping of the trial. 541 children had been randomly assigned; seven were subsequently identified as HIV negative and excluded. After median follow-up of 19 months, 74 (28%) children in the co-trimoxazole group and 112 (42%) in the placebo group had died (hazard ratio [HR] 0.57 [95% CI 0.43-0.77], p=0.0002). This benefit applied in children followed up beyond 12 months (n=320, HR 0.48 [0.27-0.84], test for heterogeneity p=0.60) and across all ages (test for heterogeneity p=0.82) and baseline CD4 counts (test for heterogeneity p=0.36). 16 (6%) children in the co-trimoxazole group had grade 3 or 4 adverse events compared with 18 (7%) in the placebo group. These events included rash (one placebo), and a neutrophil count on one occasion less than 0.5x10(9)/L (16 [6%] co-trimoxazole vs seven [3%] placebo, p=0.06). Pneumocystis carinii was identified by immunofluorescence in only one (placebo) of 73 nasopharyngeal aspirates from children with pneumonia.Our results suggest that children of all ages with clinical features of HIV infection should receive co-trimoxazole prophylaxis in resource-poor settings, irrespective of local resistance to this drug.","Co-trimoxazole as prophylaxis against opportunistic infections in HIV-infected Zambian children (CHAP): a double-blind randomised placebo-controlled trial."
"482","Lancet.2210","0.6",15555666,2004,"No trials of co-trimoxazole (trimethoprim-sulfamethoxazole) prophylaxis for HIV-infected adults or children have been done in areas with high levels of bacterial resistance to this antibiotic. We aimed to assess the efficacy of daily co-trimoxazole in such an area.We did a double-blind randomised placebo-controlled trial in children aged 1-14 years with clinical features of HIV infection in Zambia. Primary outcomes were mortality and adverse events possibly related to treatment. Analysis was by intention to treat.In October, 2003, the data and safety monitoring committee recommended early stopping of the trial. 541 children had been randomly assigned; seven were subsequently identified as HIV negative and excluded. After median follow-up of 19 months, 74 (28%) children in the co-trimoxazole group and 112 (42%) in the placebo group had died (hazard ratio [HR] 0.57 [95% CI 0.43-0.77], p=0.0002). This benefit applied in children followed up beyond 12 months (n=320, HR 0.48 [0.27-0.84], test for heterogeneity p=0.60) and across all ages (test for heterogeneity p=0.82) and baseline CD4 counts (test for heterogeneity p=0.36). 16 (6%) children in the co-trimoxazole group had grade 3 or 4 adverse events compared with 18 (7%) in the placebo group. These events included rash (one placebo), and a neutrophil count on one occasion less than 0.5x10(9)/L (16 [6%] co-trimoxazole vs seven [3%] placebo, p=0.06). Pneumocystis carinii was identified by immunofluorescence in only one (placebo) of 73 nasopharyngeal aspirates from children with pneumonia.Our results suggest that children of all ages with clinical features of HIV infection should receive co-trimoxazole prophylaxis in resource-poor settings, irrespective of local resistance to this drug.","Co-trimoxazole as prophylaxis against opportunistic infections in HIV-infected Zambian children (CHAP): a double-blind randomised placebo-controlled trial."
"483","JAMA.1801","0.009",15572717,2004,"Despite the equivocal outcomes of randomized controlled trials, general clinical opinion favors screening and treatment of elderly individuals with subclinical thyroid disorders.To determine whether subclinical thyroid dysfunction should be treated in old age and the long-term impact of thyroid dysfunction on performance and survival in old age.A prospective, observational, population-based follow-up study within the Leiden 85-Plus Study of 87% of a 2-year birth cohort (1912-1914) in the municipality of Leiden, the Netherlands. A total of 599 participants were followed up from age 85 years through age 89 years (mean [SD] follow-up, 3.7 [1.4] years).Complete thyroid status at baseline; disability in daily life, depressive symptoms, cognitive function, and mortality from age 85 years through 89 years.Plasma levels of thyrotropin and free thyroxine were not associated with disability in daily life, depressive symptoms, and cognitive impairment at baseline or during follow-up. Increasing levels of thyrotropin were associated with a lower mortality rate that remained after adjustments were made for baseline disability and health status. The hazard ratio (HR) for mortality per SD increase of 2.71 mIU/L of thyrotropin was 0.77 (95% confidence interval [CI], 0.63-0.94; P = .009). The HR for mortality per SD increase of 0.21 ng/dL (2.67 pmol/L) of free thyroxine increased 1.16-fold (95% CI, 1.04-1.30; P = .009).In the general population of the oldest old, elderly individuals with abnormally high levels of thyrotropin do not experience adverse effects and may have a prolonged life span. However, evidence for not treating elderly individuals can only come from a well-designed, randomized placebo-controlled clinical trial.","Thyroid status, disability and cognitive function, and survival in old age."
"484","JAMA.1811","0.009",15572717,2004,"Despite the equivocal outcomes of randomized controlled trials, general clinical opinion favors screening and treatment of elderly individuals with subclinical thyroid disorders.To determine whether subclinical thyroid dysfunction should be treated in old age and the long-term impact of thyroid dysfunction on performance and survival in old age.A prospective, observational, population-based follow-up study within the Leiden 85-Plus Study of 87% of a 2-year birth cohort (1912-1914) in the municipality of Leiden, the Netherlands. A total of 599 participants were followed up from age 85 years through age 89 years (mean [SD] follow-up, 3.7 [1.4] years).Complete thyroid status at baseline; disability in daily life, depressive symptoms, cognitive function, and mortality from age 85 years through 89 years.Plasma levels of thyrotropin and free thyroxine were not associated with disability in daily life, depressive symptoms, and cognitive impairment at baseline or during follow-up. Increasing levels of thyrotropin were associated with a lower mortality rate that remained after adjustments were made for baseline disability and health status. The hazard ratio (HR) for mortality per SD increase of 2.71 mIU/L of thyrotropin was 0.77 (95% confidence interval [CI], 0.63-0.94; P = .009). The HR for mortality per SD increase of 0.21 ng/dL (2.67 pmol/L) of free thyroxine increased 1.16-fold (95% CI, 1.04-1.30; P = .009).In the general population of the oldest old, elderly individuals with abnormally high levels of thyrotropin do not experience adverse effects and may have a prolonged life span. However, evidence for not treating elderly individuals can only come from a well-designed, randomized placebo-controlled clinical trial.","Thyroid status, disability and cognitive function, and survival in old age."
"485","Lancet.19","0.01",15582059,2004,"The cyclo-oxygenase 2 inhibitor rofecoxib was recently withdrawn because of cardiovascular adverse effects. An increased risk of myocardial infarction had been observed in 2000 in the Vioxx Gastrointestinal Outcomes Research study (VIGOR), but was attributed to cardioprotection of naproxen rather than a cardiotoxic effect of rofecoxib. We used standard and cumulative random-effects meta-analyses of randomised controlled trials and observational studies to establish whether robust evidence on the adverse effects of rofecoxib was available before September, 2004.We searched bibliographic databases and relevant files of the US Food and Drug Administration. We included all randomised controlled trials in patients with chronic musculoskeletal disorders that compared rofecoxib with other non-steroidal anti-inflammatory drugs (NSAIDs) or placebo, and cohort and case-control studies of cardiovascular risk and naproxen. Myocardial infarction was the primary endpoint.We identified 18 randomised controlled trials and 11 observational studies. By the end of 2000 (52 myocardial infarctions, 20742 patients) the relative risk from randomised controlled trials was 2.30 (95% CI 1.22-4.33, p=0.010), and 1 year later (64 events, 21432 patients) it was 2.24 (1.24-4.02, p=0.007). There was little evidence that the relative risk differed depending on the control group (placebo, non-naproxen NSAID, or naproxen; p=0.41) or trial duration (p=0.82). In observational studies, the cardioprotective effect of naproxen was small (combined estimate 0.86 [95% CI 0.75-0.99]) and could not have explained the findings of the VIGOR trial.Our findings indicate that rofecoxib should have been withdrawn several years earlier. The reasons why manufacturer and drug licensing authorities did not continuously monitor and summarise the accumulating evidence need to be clarified.","Risk of cardiovascular events and rofecoxib: cumulative meta-analysis."
"486","Lancet.20","0.007",15582059,2004,"The cyclo-oxygenase 2 inhibitor rofecoxib was recently withdrawn because of cardiovascular adverse effects. An increased risk of myocardial infarction had been observed in 2000 in the Vioxx Gastrointestinal Outcomes Research study (VIGOR), but was attributed to cardioprotection of naproxen rather than a cardiotoxic effect of rofecoxib. We used standard and cumulative random-effects meta-analyses of randomised controlled trials and observational studies to establish whether robust evidence on the adverse effects of rofecoxib was available before September, 2004.We searched bibliographic databases and relevant files of the US Food and Drug Administration. We included all randomised controlled trials in patients with chronic musculoskeletal disorders that compared rofecoxib with other non-steroidal anti-inflammatory drugs (NSAIDs) or placebo, and cohort and case-control studies of cardiovascular risk and naproxen. Myocardial infarction was the primary endpoint.We identified 18 randomised controlled trials and 11 observational studies. By the end of 2000 (52 myocardial infarctions, 20742 patients) the relative risk from randomised controlled trials was 2.30 (95% CI 1.22-4.33, p=0.010), and 1 year later (64 events, 21432 patients) it was 2.24 (1.24-4.02, p=0.007). There was little evidence that the relative risk differed depending on the control group (placebo, non-naproxen NSAID, or naproxen; p=0.41) or trial duration (p=0.82). In observational studies, the cardioprotective effect of naproxen was small (combined estimate 0.86 [95% CI 0.75-0.99]) and could not have explained the findings of the VIGOR trial.Our findings indicate that rofecoxib should have been withdrawn several years earlier. The reasons why manufacturer and drug licensing authorities did not continuously monitor and summarise the accumulating evidence need to be clarified.","Risk of cardiovascular events and rofecoxib: cumulative meta-analysis."
"487","JAMA.237","0.16",15585735,2004,"Low-level lead exposure may increase the risk for a number of chronic age-related diseases. Several studies have documented the presence of lead in lenses with cataract. The intrusion of lead into the lens may alter lens redox status and cause protein conformational changes that decrease lens transparency.To determine the relationship of cumulative lead exposure with the development of cataract.Tibial (cortical) and patellar (trabecular) bone lead levels were measured by K x-ray fluorescence between 1991 and 1999 in a subset of participants in the Normative Aging Study (NAS), a Boston-based longitudinal study of aging in men. Among the first 795 NAS participants to have bone lead levels measured, we reviewed eye examination data (collected routinely every 3-5 years) for the period after the bone lead measurements were taken. We limited the population to men aged 60 years and older who had sufficient eye examination information available (n = 642). Blood lead levels were also measured.Cataract assessment was done while masked to the lead level results. A participant was considered to have cataract if there was documentation for either eye of cataract surgery or a cataract graded clinically as 3+ or higher on a 4-point scale. Odds ratios (ORs) and 95% confidence intervals (CIs) were calculated as estimates of the magnitude and significance of the relationship of lead exposure with cataract, in logistic regression models.The mean age of the study participants was 69 years and cataract was identified in 122 men. The age-adjusted OR (95% CI) for cataract for men in the highest vs lowest quintile of tibia lead level was 2.68 (1.31-5.50). Further adjustment for pack-years of cigarette smoking, diabetes, blood lead levels, and intake of vitamin C, vitamin E, and carotenoids resulted in an OR of 3.19 (95% CI, 1.48-6.90). For patella lead level, there was an increased risk of cataract in the highest vs lowest quintile (OR, 1.88; 95% CI, 0.88-4.02), but the trend was not significant (P = .16). Blood lead levels, more indicative of short-term exposure levels, were not significantly associated with cataract (OR, 0.89; 95% CI, 0.46-1.72; P = .73).These epidemiological data suggest that accumulated lead exposure, such as that commonly experienced by adults in the United States, may be an important unrecognized risk factor for cataract. This research suggests that reduction of lead exposure could help decrease the global burden of cataract.","Accumulated lead exposure and risk of age-related cataract in men."
"488","JAMA.238","0.73",15585735,2004,"Low-level lead exposure may increase the risk for a number of chronic age-related diseases. Several studies have documented the presence of lead in lenses with cataract. The intrusion of lead into the lens may alter lens redox status and cause protein conformational changes that decrease lens transparency.To determine the relationship of cumulative lead exposure with the development of cataract.Tibial (cortical) and patellar (trabecular) bone lead levels were measured by K x-ray fluorescence between 1991 and 1999 in a subset of participants in the Normative Aging Study (NAS), a Boston-based longitudinal study of aging in men. Among the first 795 NAS participants to have bone lead levels measured, we reviewed eye examination data (collected routinely every 3-5 years) for the period after the bone lead measurements were taken. We limited the population to men aged 60 years and older who had sufficient eye examination information available (n = 642). Blood lead levels were also measured.Cataract assessment was done while masked to the lead level results. A participant was considered to have cataract if there was documentation for either eye of cataract surgery or a cataract graded clinically as 3+ or higher on a 4-point scale. Odds ratios (ORs) and 95% confidence intervals (CIs) were calculated as estimates of the magnitude and significance of the relationship of lead exposure with cataract, in logistic regression models.The mean age of the study participants was 69 years and cataract was identified in 122 men. The age-adjusted OR (95% CI) for cataract for men in the highest vs lowest quintile of tibia lead level was 2.68 (1.31-5.50). Further adjustment for pack-years of cigarette smoking, diabetes, blood lead levels, and intake of vitamin C, vitamin E, and carotenoids resulted in an OR of 3.19 (95% CI, 1.48-6.90). For patella lead level, there was an increased risk of cataract in the highest vs lowest quintile (OR, 1.88; 95% CI, 0.88-4.02), but the trend was not significant (P = .16). Blood lead levels, more indicative of short-term exposure levels, were not significantly associated with cataract (OR, 0.89; 95% CI, 0.46-1.72; P = .73).These epidemiological data suggest that accumulated lead exposure, such as that commonly experienced by adults in the United States, may be an important unrecognized risk factor for cataract. This research suggests that reduction of lead exposure could help decrease the global burden of cataract.","Accumulated lead exposure and risk of age-related cataract in men."
"489","JAMA.333","0.93",15632336,2005,"It is estimated that half of unintended pregnancies could be averted if emergency contraception (EC) were easily accessible and used.To evaluate the effect of direct access to EC through pharmacies and advance provision on reproductive health outcomes.A randomized, single-blind, controlled trial (July 2001-June 2003) of 2117 women, ages 15 to 24 years, attending 4 California clinics providing family planning services, who were not desiring pregnancy, using long-term hormonal contraception or requesting EC.Participants were assigned to 1 of the following groups: (1) pharmacy access to EC; (2) advance provision of 3 packs of levonorgestrel EC; or (3) clinic access (control).Primary outcomes were use of EC, pregnancies, and sexually transmitted infections (STIs) assessed at 6 months; secondary outcomes were changes in contraceptive and condom use and sexual behavior.Women in the pharmacy access group were no more likely to use EC (24.2%) than controls (21.0%) (P = .25). Women in the advance provision group (37.4%) were almost twice as likely to use EC than controls (21.0%) (P<.001) even though the frequency of unprotected intercourse was similar (39.8% vs 41.0%, respectively, P = .46). Only half (46.7%) of study participants who had unprotected intercourse used EC over the study period. Eight percent of participants became pregnant and 12% acquired an STI; compared with controls, women in the pharmacy access and advance provision groups did not experience a significant reduction in pregnancy rate (pharmacy access group: adjusted odds ratio [OR], 0.98; 95% confidence interval [CI], 0.58-1.64; P = .93; advance provision group: OR, 1.10; 95% CI, 0.66-1.84, P = .71) or increase in STIs (pharmacy access group: adjusted OR, 1.08, 95% CI, 0.71-1.63, P = .73; advance provision group: OR, 0.94, 95% CI, 0.62-1.44, P = .79). There were no differences in patterns of contraceptive or condom use or sexual behaviors by study group.While removing the requirement to go through pharmacists or clinics to obtain EC increases use, the public health impact may be negligible because of high rates of unprotected intercourse and relative underutilization of the method. Given that there is clear evidence that neither pharmacy access nor advance provision compromises contraceptive or sexual behavior, it seems unreasonable to restrict access to EC to clinics.","Direct access to emergency contraception through pharmacies and effect on unintended pregnancy and STIs: a randomized controlled trial."
"490","JAMA.334","0.71",15632336,2005,"It is estimated that half of unintended pregnancies could be averted if emergency contraception (EC) were easily accessible and used.To evaluate the effect of direct access to EC through pharmacies and advance provision on reproductive health outcomes.A randomized, single-blind, controlled trial (July 2001-June 2003) of 2117 women, ages 15 to 24 years, attending 4 California clinics providing family planning services, who were not desiring pregnancy, using long-term hormonal contraception or requesting EC.Participants were assigned to 1 of the following groups: (1) pharmacy access to EC; (2) advance provision of 3 packs of levonorgestrel EC; or (3) clinic access (control).Primary outcomes were use of EC, pregnancies, and sexually transmitted infections (STIs) assessed at 6 months; secondary outcomes were changes in contraceptive and condom use and sexual behavior.Women in the pharmacy access group were no more likely to use EC (24.2%) than controls (21.0%) (P = .25). Women in the advance provision group (37.4%) were almost twice as likely to use EC than controls (21.0%) (P<.001) even though the frequency of unprotected intercourse was similar (39.8% vs 41.0%, respectively, P = .46). Only half (46.7%) of study participants who had unprotected intercourse used EC over the study period. Eight percent of participants became pregnant and 12% acquired an STI; compared with controls, women in the pharmacy access and advance provision groups did not experience a significant reduction in pregnancy rate (pharmacy access group: adjusted odds ratio [OR], 0.98; 95% confidence interval [CI], 0.58-1.64; P = .93; advance provision group: OR, 1.10; 95% CI, 0.66-1.84, P = .71) or increase in STIs (pharmacy access group: adjusted OR, 1.08, 95% CI, 0.71-1.63, P = .73; advance provision group: OR, 0.94, 95% CI, 0.62-1.44, P = .79). There were no differences in patterns of contraceptive or condom use or sexual behaviors by study group.While removing the requirement to go through pharmacists or clinics to obtain EC increases use, the public health impact may be negligible because of high rates of unprotected intercourse and relative underutilization of the method. Given that there is clear evidence that neither pharmacy access nor advance provision compromises contraceptive or sexual behavior, it seems unreasonable to restrict access to EC to clinics.","Direct access to emergency contraception through pharmacies and effect on unintended pregnancy and STIs: a randomized controlled trial."
"491","JAMA.335","0.73",15632336,2005,"It is estimated that half of unintended pregnancies could be averted if emergency contraception (EC) were easily accessible and used.To evaluate the effect of direct access to EC through pharmacies and advance provision on reproductive health outcomes.A randomized, single-blind, controlled trial (July 2001-June 2003) of 2117 women, ages 15 to 24 years, attending 4 California clinics providing family planning services, who were not desiring pregnancy, using long-term hormonal contraception or requesting EC.Participants were assigned to 1 of the following groups: (1) pharmacy access to EC; (2) advance provision of 3 packs of levonorgestrel EC; or (3) clinic access (control).Primary outcomes were use of EC, pregnancies, and sexually transmitted infections (STIs) assessed at 6 months; secondary outcomes were changes in contraceptive and condom use and sexual behavior.Women in the pharmacy access group were no more likely to use EC (24.2%) than controls (21.0%) (P = .25). Women in the advance provision group (37.4%) were almost twice as likely to use EC than controls (21.0%) (P<.001) even though the frequency of unprotected intercourse was similar (39.8% vs 41.0%, respectively, P = .46). Only half (46.7%) of study participants who had unprotected intercourse used EC over the study period. Eight percent of participants became pregnant and 12% acquired an STI; compared with controls, women in the pharmacy access and advance provision groups did not experience a significant reduction in pregnancy rate (pharmacy access group: adjusted odds ratio [OR], 0.98; 95% confidence interval [CI], 0.58-1.64; P = .93; advance provision group: OR, 1.10; 95% CI, 0.66-1.84, P = .71) or increase in STIs (pharmacy access group: adjusted OR, 1.08, 95% CI, 0.71-1.63, P = .73; advance provision group: OR, 0.94, 95% CI, 0.62-1.44, P = .79). There were no differences in patterns of contraceptive or condom use or sexual behaviors by study group.While removing the requirement to go through pharmacists or clinics to obtain EC increases use, the public health impact may be negligible because of high rates of unprotected intercourse and relative underutilization of the method. Given that there is clear evidence that neither pharmacy access nor advance provision compromises contraceptive or sexual behavior, it seems unreasonable to restrict access to EC to clinics.","Direct access to emergency contraception through pharmacies and effect on unintended pregnancy and STIs: a randomized controlled trial."
"492","JAMA.336","0.79",15632336,2005,"It is estimated that half of unintended pregnancies could be averted if emergency contraception (EC) were easily accessible and used.To evaluate the effect of direct access to EC through pharmacies and advance provision on reproductive health outcomes.A randomized, single-blind, controlled trial (July 2001-June 2003) of 2117 women, ages 15 to 24 years, attending 4 California clinics providing family planning services, who were not desiring pregnancy, using long-term hormonal contraception or requesting EC.Participants were assigned to 1 of the following groups: (1) pharmacy access to EC; (2) advance provision of 3 packs of levonorgestrel EC; or (3) clinic access (control).Primary outcomes were use of EC, pregnancies, and sexually transmitted infections (STIs) assessed at 6 months; secondary outcomes were changes in contraceptive and condom use and sexual behavior.Women in the pharmacy access group were no more likely to use EC (24.2%) than controls (21.0%) (P = .25). Women in the advance provision group (37.4%) were almost twice as likely to use EC than controls (21.0%) (P<.001) even though the frequency of unprotected intercourse was similar (39.8% vs 41.0%, respectively, P = .46). Only half (46.7%) of study participants who had unprotected intercourse used EC over the study period. Eight percent of participants became pregnant and 12% acquired an STI; compared with controls, women in the pharmacy access and advance provision groups did not experience a significant reduction in pregnancy rate (pharmacy access group: adjusted odds ratio [OR], 0.98; 95% confidence interval [CI], 0.58-1.64; P = .93; advance provision group: OR, 1.10; 95% CI, 0.66-1.84, P = .71) or increase in STIs (pharmacy access group: adjusted OR, 1.08, 95% CI, 0.71-1.63, P = .73; advance provision group: OR, 0.94, 95% CI, 0.62-1.44, P = .79). There were no differences in patterns of contraceptive or condom use or sexual behaviors by study group.While removing the requirement to go through pharmacists or clinics to obtain EC increases use, the public health impact may be negligible because of high rates of unprotected intercourse and relative underutilization of the method. Given that there is clear evidence that neither pharmacy access nor advance provision compromises contraceptive or sexual behavior, it seems unreasonable to restrict access to EC to clinics.","Direct access to emergency contraception through pharmacies and effect on unintended pregnancy and STIs: a randomized controlled trial."
"493","JAMA.2501","0.001",15644547,2005,"Current treatment for acute myeloid leukemia (AML) in children cures about half the patients. Of the other half, most succumb to leukemia, but 5% to 15% die of treatment-related complications. Overweight children with AML seem to experience excess life-threatening and fatal toxicity. Nothing is known about how weight affects outcomes in pediatric AML.To compare survival rates in children with AML who at diagnosis are underweight (body mass index [BMI] < or =10th percentile), overweight (BMI > or =95th percentile), or middleweight (BMI = 11th-94th percentiles).Retrospective review of BMI and survival in 768 children and young adults aged 1 to 20 years enrolled in Children's Cancer Group-2961, an international cooperative group phase 3 trial for previously untreated AML conducted August 30, 1996, through December 4, 2002. Data were collected through January 9, 2004, with a median follow-up of 31 months (range, 0-78 months).Hazard ratios (HRs) for survival and treatment-related mortality.Eighty-four of 768 patients (10.9%) were underweight and 114 (14.8%) were overweight. After adjustment for potentially confounding variables of age, race, leukocyte count, cytogenetics, and bone marrow transplantation, compared with middleweight patients, underweight patients were less likely to survive (HR, 1.85; 95% confidence interval [CI], 1.19-2.87; P = .006) and more likely to experience treatment-related mortality (HR, 2.66; 95% CI, 1.38-5.11; P = .003). Similarly, overweight patients were less likely to survive (HR, 1.88; 95% CI, 1.25-2.83; P = .002) and more likely to have treatment-related mortality (HR, 3.49; 95% CI, 1.99-6.10; P<.001) than middleweight patients. Infections incurred during the first 2 courses of chemotherapy caused most treatment-related deaths.Treatment-related complications significantly reduce survival in overweight and underweight children with AML.","Mortality in overweight and underweight children with acute myeloid leukemia."
"494","JAMA.3051","0.006",15644547,2005,"Current treatment for acute myeloid leukemia (AML) in children cures about half the patients. Of the other half, most succumb to leukemia, but 5% to 15% die of treatment-related complications. Overweight children with AML seem to experience excess life-threatening and fatal toxicity. Nothing is known about how weight affects outcomes in pediatric AML.To compare survival rates in children with AML who at diagnosis are underweight (body mass index [BMI] < or =10th percentile), overweight (BMI > or =95th percentile), or middleweight (BMI = 11th-94th percentiles).Retrospective review of BMI and survival in 768 children and young adults aged 1 to 20 years enrolled in Children's Cancer Group-2961, an international cooperative group phase 3 trial for previously untreated AML conducted August 30, 1996, through December 4, 2002. Data were collected through January 9, 2004, with a median follow-up of 31 months (range, 0-78 months).Hazard ratios (HRs) for survival and treatment-related mortality.Eighty-four of 768 patients (10.9%) were underweight and 114 (14.8%) were overweight. After adjustment for potentially confounding variables of age, race, leukocyte count, cytogenetics, and bone marrow transplantation, compared with middleweight patients, underweight patients were less likely to survive (HR, 1.85; 95% confidence interval [CI], 1.19-2.87; P = .006) and more likely to experience treatment-related mortality (HR, 2.66; 95% CI, 1.38-5.11; P = .003). Similarly, overweight patients were less likely to survive (HR, 1.88; 95% CI, 1.25-2.83; P = .002) and more likely to have treatment-related mortality (HR, 3.49; 95% CI, 1.99-6.10; P<.001) than middleweight patients. Infections incurred during the first 2 courses of chemotherapy caused most treatment-related deaths.Treatment-related complications significantly reduce survival in overweight and underweight children with AML.","Mortality in overweight and underweight children with acute myeloid leukemia."
"495","JAMA.3061","0.003",15644547,2005,"Current treatment for acute myeloid leukemia (AML) in children cures about half the patients. Of the other half, most succumb to leukemia, but 5% to 15% die of treatment-related complications. Overweight children with AML seem to experience excess life-threatening and fatal toxicity. Nothing is known about how weight affects outcomes in pediatric AML.To compare survival rates in children with AML who at diagnosis are underweight (body mass index [BMI] < or =10th percentile), overweight (BMI > or =95th percentile), or middleweight (BMI = 11th-94th percentiles).Retrospective review of BMI and survival in 768 children and young adults aged 1 to 20 years enrolled in Children's Cancer Group-2961, an international cooperative group phase 3 trial for previously untreated AML conducted August 30, 1996, through December 4, 2002. Data were collected through January 9, 2004, with a median follow-up of 31 months (range, 0-78 months).Hazard ratios (HRs) for survival and treatment-related mortality.Eighty-four of 768 patients (10.9%) were underweight and 114 (14.8%) were overweight. After adjustment for potentially confounding variables of age, race, leukocyte count, cytogenetics, and bone marrow transplantation, compared with middleweight patients, underweight patients were less likely to survive (HR, 1.85; 95% confidence interval [CI], 1.19-2.87; P = .006) and more likely to experience treatment-related mortality (HR, 2.66; 95% CI, 1.38-5.11; P = .003). Similarly, overweight patients were less likely to survive (HR, 1.88; 95% CI, 1.25-2.83; P = .002) and more likely to have treatment-related mortality (HR, 3.49; 95% CI, 1.99-6.10; P<.001) than middleweight patients. Infections incurred during the first 2 courses of chemotherapy caused most treatment-related deaths.Treatment-related complications significantly reduce survival in overweight and underweight children with AML.","Mortality in overweight and underweight children with acute myeloid leukemia."
"496","JAMA.3071","0.002",15644547,2005,"Current treatment for acute myeloid leukemia (AML) in children cures about half the patients. Of the other half, most succumb to leukemia, but 5% to 15% die of treatment-related complications. Overweight children with AML seem to experience excess life-threatening and fatal toxicity. Nothing is known about how weight affects outcomes in pediatric AML.To compare survival rates in children with AML who at diagnosis are underweight (body mass index [BMI] < or =10th percentile), overweight (BMI > or =95th percentile), or middleweight (BMI = 11th-94th percentiles).Retrospective review of BMI and survival in 768 children and young adults aged 1 to 20 years enrolled in Children's Cancer Group-2961, an international cooperative group phase 3 trial for previously untreated AML conducted August 30, 1996, through December 4, 2002. Data were collected through January 9, 2004, with a median follow-up of 31 months (range, 0-78 months).Hazard ratios (HRs) for survival and treatment-related mortality.Eighty-four of 768 patients (10.9%) were underweight and 114 (14.8%) were overweight. After adjustment for potentially confounding variables of age, race, leukocyte count, cytogenetics, and bone marrow transplantation, compared with middleweight patients, underweight patients were less likely to survive (HR, 1.85; 95% confidence interval [CI], 1.19-2.87; P = .006) and more likely to experience treatment-related mortality (HR, 2.66; 95% CI, 1.38-5.11; P = .003). Similarly, overweight patients were less likely to survive (HR, 1.88; 95% CI, 1.25-2.83; P = .002) and more likely to have treatment-related mortality (HR, 3.49; 95% CI, 1.99-6.10; P<.001) than middleweight patients. Infections incurred during the first 2 courses of chemotherapy caused most treatment-related deaths.Treatment-related complications significantly reduce survival in overweight and underweight children with AML.","Mortality in overweight and underweight children with acute myeloid leukemia."
"497","JAMA.2971","0.005",15671427,2005,"Although reperfusion therapy, aspirin, beta-blockers, and angiotensin-converting enzyme inhibitors reduce mortality when used early in patients with acute myocardial infarction (MI), mortality and morbidity remain high. No antithrombotic or newer antiplatelet drug has been shown to reduce mortality in acute MI.To evaluate the effects of reviparin, a low-molecular-weight heparin, when initiated early and given for 7 days in addition to usual therapy on the primary composite outcome of death, myocardial reinfarction, or strokes at 7 and 30 days.A randomized, double-blind, placebo-controlled trial (Clinical Trial of Reviparin and Metabolic Modulation in Acute Myocardial Infarction Treatment Evaluation [CREATE]) of 15,570 patients with ST-segment elevation or new left bundle-branch block, presenting within 12 hours of symptom onset at 341 hospitals in India and China from July 2001 through July 2004.Reviparin or placebo subcutaneously twice daily for 7 days.Primary composite outcome of death, myocardial reinfarction, or stroke at 7 and 30 days.The primary composite outcome was significantly reduced from 854 (11.0%) of 7790 patients in the placebo group to 745 (9.6%) of 7780 in the reviparin group (hazard ratio [HR], 0.87; 95% CI, 0.79-0.96; P = .005). These benefits persisted at 30 days (1056 [13.6%] vs 921 [11.8%] patients; HR, 0.87; 95% CI, 0.79-0.95; P = .001) with significant reductions in 30-day mortality (877 [11.3%] vs 766 [9.8%]; HR, 0.87; 95% CI, 0.79-0.96; P = .005) and reinfarction (199 [2.6%] vs 154 [2.0%]; HR, 0.77; 95% CI, 0.62-0.95; P = .01), and no significant differences in strokes (64 [0.8%] vs 80 [1.0%]; P = .19). Reviparin treatment was significantly better when it was initiated very early after symptom onset at 7 days (<2 hours: HR, 0.70; 95% CI, 0.52-0.96; P = .03; 30/1000 events prevented; 2 to <4 hours: HR, 0.81; 95% CI, 0.67-0.98; P = .03; 21/1000 events prevented; 4 to <8 hours: HR, 0.85; 95% CI, 0.73-0.99; P = .05; 16/1000 events prevented; and > or =8 hours: HR, 1.06; 95% CI, 0.86-1.30; P = .58; P = .04 for trend). There was an increase in life-threatening bleeding at 7 days with reviparin and placebo (17 [0.2%] vs 7 [0.1%], respectively; P = .07), but the absolute excess was small (1 more per 1000) vs reductions in the primary outcome (18 fewer per 1000) or mortality (15 fewer per 1000).In patients with acute ST-segment elevation or new left bundle-branch block MI, reviparin reduces mortality and reinfarction, without a substantive increase in overall stroke rates. There is a small absolute excess of life-threatening bleeding but the benefits outweigh the risks.","Effects of reviparin, a low-molecular-weight heparin, on mortality, reinfarction, and strokes in patients with acute myocardial infarction presenting with ST-segment elevation."
"498","JAMA.2981","0.001",15671427,2005,"Although reperfusion therapy, aspirin, beta-blockers, and angiotensin-converting enzyme inhibitors reduce mortality when used early in patients with acute myocardial infarction (MI), mortality and morbidity remain high. No antithrombotic or newer antiplatelet drug has been shown to reduce mortality in acute MI.To evaluate the effects of reviparin, a low-molecular-weight heparin, when initiated early and given for 7 days in addition to usual therapy on the primary composite outcome of death, myocardial reinfarction, or strokes at 7 and 30 days.A randomized, double-blind, placebo-controlled trial (Clinical Trial of Reviparin and Metabolic Modulation in Acute Myocardial Infarction Treatment Evaluation [CREATE]) of 15,570 patients with ST-segment elevation or new left bundle-branch block, presenting within 12 hours of symptom onset at 341 hospitals in India and China from July 2001 through July 2004.Reviparin or placebo subcutaneously twice daily for 7 days.Primary composite outcome of death, myocardial reinfarction, or stroke at 7 and 30 days.The primary composite outcome was significantly reduced from 854 (11.0%) of 7790 patients in the placebo group to 745 (9.6%) of 7780 in the reviparin group (hazard ratio [HR], 0.87; 95% CI, 0.79-0.96; P = .005). These benefits persisted at 30 days (1056 [13.6%] vs 921 [11.8%] patients; HR, 0.87; 95% CI, 0.79-0.95; P = .001) with significant reductions in 30-day mortality (877 [11.3%] vs 766 [9.8%]; HR, 0.87; 95% CI, 0.79-0.96; P = .005) and reinfarction (199 [2.6%] vs 154 [2.0%]; HR, 0.77; 95% CI, 0.62-0.95; P = .01), and no significant differences in strokes (64 [0.8%] vs 80 [1.0%]; P = .19). Reviparin treatment was significantly better when it was initiated very early after symptom onset at 7 days (<2 hours: HR, 0.70; 95% CI, 0.52-0.96; P = .03; 30/1000 events prevented; 2 to <4 hours: HR, 0.81; 95% CI, 0.67-0.98; P = .03; 21/1000 events prevented; 4 to <8 hours: HR, 0.85; 95% CI, 0.73-0.99; P = .05; 16/1000 events prevented; and > or =8 hours: HR, 1.06; 95% CI, 0.86-1.30; P = .58; P = .04 for trend). There was an increase in life-threatening bleeding at 7 days with reviparin and placebo (17 [0.2%] vs 7 [0.1%], respectively; P = .07), but the absolute excess was small (1 more per 1000) vs reductions in the primary outcome (18 fewer per 1000) or mortality (15 fewer per 1000).In patients with acute ST-segment elevation or new left bundle-branch block MI, reviparin reduces mortality and reinfarction, without a substantive increase in overall stroke rates. There is a small absolute excess of life-threatening bleeding but the benefits outweigh the risks.","Effects of reviparin, a low-molecular-weight heparin, on mortality, reinfarction, and strokes in patients with acute myocardial infarction presenting with ST-segment elevation."
"499","JAMA.2991","0.005",15671427,2005,"Although reperfusion therapy, aspirin, beta-blockers, and angiotensin-converting enzyme inhibitors reduce mortality when used early in patients with acute myocardial infarction (MI), mortality and morbidity remain high. No antithrombotic or newer antiplatelet drug has been shown to reduce mortality in acute MI.To evaluate the effects of reviparin, a low-molecular-weight heparin, when initiated early and given for 7 days in addition to usual therapy on the primary composite outcome of death, myocardial reinfarction, or strokes at 7 and 30 days.A randomized, double-blind, placebo-controlled trial (Clinical Trial of Reviparin and Metabolic Modulation in Acute Myocardial Infarction Treatment Evaluation [CREATE]) of 15,570 patients with ST-segment elevation or new left bundle-branch block, presenting within 12 hours of symptom onset at 341 hospitals in India and China from July 2001 through July 2004.Reviparin or placebo subcutaneously twice daily for 7 days.Primary composite outcome of death, myocardial reinfarction, or stroke at 7 and 30 days.The primary composite outcome was significantly reduced from 854 (11.0%) of 7790 patients in the placebo group to 745 (9.6%) of 7780 in the reviparin group (hazard ratio [HR], 0.87; 95% CI, 0.79-0.96; P = .005). These benefits persisted at 30 days (1056 [13.6%] vs 921 [11.8%] patients; HR, 0.87; 95% CI, 0.79-0.95; P = .001) with significant reductions in 30-day mortality (877 [11.3%] vs 766 [9.8%]; HR, 0.87; 95% CI, 0.79-0.96; P = .005) and reinfarction (199 [2.6%] vs 154 [2.0%]; HR, 0.77; 95% CI, 0.62-0.95; P = .01), and no significant differences in strokes (64 [0.8%] vs 80 [1.0%]; P = .19). Reviparin treatment was significantly better when it was initiated very early after symptom onset at 7 days (<2 hours: HR, 0.70; 95% CI, 0.52-0.96; P = .03; 30/1000 events prevented; 2 to <4 hours: HR, 0.81; 95% CI, 0.67-0.98; P = .03; 21/1000 events prevented; 4 to <8 hours: HR, 0.85; 95% CI, 0.73-0.99; P = .05; 16/1000 events prevented; and > or =8 hours: HR, 1.06; 95% CI, 0.86-1.30; P = .58; P = .04 for trend). There was an increase in life-threatening bleeding at 7 days with reviparin and placebo (17 [0.2%] vs 7 [0.1%], respectively; P = .07), but the absolute excess was small (1 more per 1000) vs reductions in the primary outcome (18 fewer per 1000) or mortality (15 fewer per 1000).In patients with acute ST-segment elevation or new left bundle-branch block MI, reviparin reduces mortality and reinfarction, without a substantive increase in overall stroke rates. There is a small absolute excess of life-threatening bleeding but the benefits outweigh the risks.","Effects of reviparin, a low-molecular-weight heparin, on mortality, reinfarction, and strokes in patients with acute myocardial infarction presenting with ST-segment elevation."
"500","JAMA.3001","0.01",15671427,2005,"Although reperfusion therapy, aspirin, beta-blockers, and angiotensin-converting enzyme inhibitors reduce mortality when used early in patients with acute myocardial infarction (MI), mortality and morbidity remain high. No antithrombotic or newer antiplatelet drug has been shown to reduce mortality in acute MI.To evaluate the effects of reviparin, a low-molecular-weight heparin, when initiated early and given for 7 days in addition to usual therapy on the primary composite outcome of death, myocardial reinfarction, or strokes at 7 and 30 days.A randomized, double-blind, placebo-controlled trial (Clinical Trial of Reviparin and Metabolic Modulation in Acute Myocardial Infarction Treatment Evaluation [CREATE]) of 15,570 patients with ST-segment elevation or new left bundle-branch block, presenting within 12 hours of symptom onset at 341 hospitals in India and China from July 2001 through July 2004.Reviparin or placebo subcutaneously twice daily for 7 days.Primary composite outcome of death, myocardial reinfarction, or stroke at 7 and 30 days.The primary composite outcome was significantly reduced from 854 (11.0%) of 7790 patients in the placebo group to 745 (9.6%) of 7780 in the reviparin group (hazard ratio [HR], 0.87; 95% CI, 0.79-0.96; P = .005). These benefits persisted at 30 days (1056 [13.6%] vs 921 [11.8%] patients; HR, 0.87; 95% CI, 0.79-0.95; P = .001) with significant reductions in 30-day mortality (877 [11.3%] vs 766 [9.8%]; HR, 0.87; 95% CI, 0.79-0.96; P = .005) and reinfarction (199 [2.6%] vs 154 [2.0%]; HR, 0.77; 95% CI, 0.62-0.95; P = .01), and no significant differences in strokes (64 [0.8%] vs 80 [1.0%]; P = .19). Reviparin treatment was significantly better when it was initiated very early after symptom onset at 7 days (<2 hours: HR, 0.70; 95% CI, 0.52-0.96; P = .03; 30/1000 events prevented; 2 to <4 hours: HR, 0.81; 95% CI, 0.67-0.98; P = .03; 21/1000 events prevented; 4 to <8 hours: HR, 0.85; 95% CI, 0.73-0.99; P = .05; 16/1000 events prevented; and > or =8 hours: HR, 1.06; 95% CI, 0.86-1.30; P = .58; P = .04 for trend). There was an increase in life-threatening bleeding at 7 days with reviparin and placebo (17 [0.2%] vs 7 [0.1%], respectively; P = .07), but the absolute excess was small (1 more per 1000) vs reductions in the primary outcome (18 fewer per 1000) or mortality (15 fewer per 1000).In patients with acute ST-segment elevation or new left bundle-branch block MI, reviparin reduces mortality and reinfarction, without a substantive increase in overall stroke rates. There is a small absolute excess of life-threatening bleeding but the benefits outweigh the risks.","Effects of reviparin, a low-molecular-weight heparin, on mortality, reinfarction, and strokes in patients with acute myocardial infarction presenting with ST-segment elevation."
"501","JAMA.3011","0.03",15671427,2005,"Although reperfusion therapy, aspirin, beta-blockers, and angiotensin-converting enzyme inhibitors reduce mortality when used early in patients with acute myocardial infarction (MI), mortality and morbidity remain high. No antithrombotic or newer antiplatelet drug has been shown to reduce mortality in acute MI.To evaluate the effects of reviparin, a low-molecular-weight heparin, when initiated early and given for 7 days in addition to usual therapy on the primary composite outcome of death, myocardial reinfarction, or strokes at 7 and 30 days.A randomized, double-blind, placebo-controlled trial (Clinical Trial of Reviparin and Metabolic Modulation in Acute Myocardial Infarction Treatment Evaluation [CREATE]) of 15,570 patients with ST-segment elevation or new left bundle-branch block, presenting within 12 hours of symptom onset at 341 hospitals in India and China from July 2001 through July 2004.Reviparin or placebo subcutaneously twice daily for 7 days.Primary composite outcome of death, myocardial reinfarction, or stroke at 7 and 30 days.The primary composite outcome was significantly reduced from 854 (11.0%) of 7790 patients in the placebo group to 745 (9.6%) of 7780 in the reviparin group (hazard ratio [HR], 0.87; 95% CI, 0.79-0.96; P = .005). These benefits persisted at 30 days (1056 [13.6%] vs 921 [11.8%] patients; HR, 0.87; 95% CI, 0.79-0.95; P = .001) with significant reductions in 30-day mortality (877 [11.3%] vs 766 [9.8%]; HR, 0.87; 95% CI, 0.79-0.96; P = .005) and reinfarction (199 [2.6%] vs 154 [2.0%]; HR, 0.77; 95% CI, 0.62-0.95; P = .01), and no significant differences in strokes (64 [0.8%] vs 80 [1.0%]; P = .19). Reviparin treatment was significantly better when it was initiated very early after symptom onset at 7 days (<2 hours: HR, 0.70; 95% CI, 0.52-0.96; P = .03; 30/1000 events prevented; 2 to <4 hours: HR, 0.81; 95% CI, 0.67-0.98; P = .03; 21/1000 events prevented; 4 to <8 hours: HR, 0.85; 95% CI, 0.73-0.99; P = .05; 16/1000 events prevented; and > or =8 hours: HR, 1.06; 95% CI, 0.86-1.30; P = .58; P = .04 for trend). There was an increase in life-threatening bleeding at 7 days with reviparin and placebo (17 [0.2%] vs 7 [0.1%], respectively; P = .07), but the absolute excess was small (1 more per 1000) vs reductions in the primary outcome (18 fewer per 1000) or mortality (15 fewer per 1000).In patients with acute ST-segment elevation or new left bundle-branch block MI, reviparin reduces mortality and reinfarction, without a substantive increase in overall stroke rates. There is a small absolute excess of life-threatening bleeding but the benefits outweigh the risks.","Effects of reviparin, a low-molecular-weight heparin, on mortality, reinfarction, and strokes in patients with acute myocardial infarction presenting with ST-segment elevation."
"502","JAMA.3021","0.03",15671427,2005,"Although reperfusion therapy, aspirin, beta-blockers, and angiotensin-converting enzyme inhibitors reduce mortality when used early in patients with acute myocardial infarction (MI), mortality and morbidity remain high. No antithrombotic or newer antiplatelet drug has been shown to reduce mortality in acute MI.To evaluate the effects of reviparin, a low-molecular-weight heparin, when initiated early and given for 7 days in addition to usual therapy on the primary composite outcome of death, myocardial reinfarction, or strokes at 7 and 30 days.A randomized, double-blind, placebo-controlled trial (Clinical Trial of Reviparin and Metabolic Modulation in Acute Myocardial Infarction Treatment Evaluation [CREATE]) of 15,570 patients with ST-segment elevation or new left bundle-branch block, presenting within 12 hours of symptom onset at 341 hospitals in India and China from July 2001 through July 2004.Reviparin or placebo subcutaneously twice daily for 7 days.Primary composite outcome of death, myocardial reinfarction, or stroke at 7 and 30 days.The primary composite outcome was significantly reduced from 854 (11.0%) of 7790 patients in the placebo group to 745 (9.6%) of 7780 in the reviparin group (hazard ratio [HR], 0.87; 95% CI, 0.79-0.96; P = .005). These benefits persisted at 30 days (1056 [13.6%] vs 921 [11.8%] patients; HR, 0.87; 95% CI, 0.79-0.95; P = .001) with significant reductions in 30-day mortality (877 [11.3%] vs 766 [9.8%]; HR, 0.87; 95% CI, 0.79-0.96; P = .005) and reinfarction (199 [2.6%] vs 154 [2.0%]; HR, 0.77; 95% CI, 0.62-0.95; P = .01), and no significant differences in strokes (64 [0.8%] vs 80 [1.0%]; P = .19). Reviparin treatment was significantly better when it was initiated very early after symptom onset at 7 days (<2 hours: HR, 0.70; 95% CI, 0.52-0.96; P = .03; 30/1000 events prevented; 2 to <4 hours: HR, 0.81; 95% CI, 0.67-0.98; P = .03; 21/1000 events prevented; 4 to <8 hours: HR, 0.85; 95% CI, 0.73-0.99; P = .05; 16/1000 events prevented; and > or =8 hours: HR, 1.06; 95% CI, 0.86-1.30; P = .58; P = .04 for trend). There was an increase in life-threatening bleeding at 7 days with reviparin and placebo (17 [0.2%] vs 7 [0.1%], respectively; P = .07), but the absolute excess was small (1 more per 1000) vs reductions in the primary outcome (18 fewer per 1000) or mortality (15 fewer per 1000).In patients with acute ST-segment elevation or new left bundle-branch block MI, reviparin reduces mortality and reinfarction, without a substantive increase in overall stroke rates. There is a small absolute excess of life-threatening bleeding but the benefits outweigh the risks.","Effects of reviparin, a low-molecular-weight heparin, on mortality, reinfarction, and strokes in patients with acute myocardial infarction presenting with ST-segment elevation."
"503","JAMA.3031","0.05",15671427,2005,"Although reperfusion therapy, aspirin, beta-blockers, and angiotensin-converting enzyme inhibitors reduce mortality when used early in patients with acute myocardial infarction (MI), mortality and morbidity remain high. No antithrombotic or newer antiplatelet drug has been shown to reduce mortality in acute MI.To evaluate the effects of reviparin, a low-molecular-weight heparin, when initiated early and given for 7 days in addition to usual therapy on the primary composite outcome of death, myocardial reinfarction, or strokes at 7 and 30 days.A randomized, double-blind, placebo-controlled trial (Clinical Trial of Reviparin and Metabolic Modulation in Acute Myocardial Infarction Treatment Evaluation [CREATE]) of 15,570 patients with ST-segment elevation or new left bundle-branch block, presenting within 12 hours of symptom onset at 341 hospitals in India and China from July 2001 through July 2004.Reviparin or placebo subcutaneously twice daily for 7 days.Primary composite outcome of death, myocardial reinfarction, or stroke at 7 and 30 days.The primary composite outcome was significantly reduced from 854 (11.0%) of 7790 patients in the placebo group to 745 (9.6%) of 7780 in the reviparin group (hazard ratio [HR], 0.87; 95% CI, 0.79-0.96; P = .005). These benefits persisted at 30 days (1056 [13.6%] vs 921 [11.8%] patients; HR, 0.87; 95% CI, 0.79-0.95; P = .001) with significant reductions in 30-day mortality (877 [11.3%] vs 766 [9.8%]; HR, 0.87; 95% CI, 0.79-0.96; P = .005) and reinfarction (199 [2.6%] vs 154 [2.0%]; HR, 0.77; 95% CI, 0.62-0.95; P = .01), and no significant differences in strokes (64 [0.8%] vs 80 [1.0%]; P = .19). Reviparin treatment was significantly better when it was initiated very early after symptom onset at 7 days (<2 hours: HR, 0.70; 95% CI, 0.52-0.96; P = .03; 30/1000 events prevented; 2 to <4 hours: HR, 0.81; 95% CI, 0.67-0.98; P = .03; 21/1000 events prevented; 4 to <8 hours: HR, 0.85; 95% CI, 0.73-0.99; P = .05; 16/1000 events prevented; and > or =8 hours: HR, 1.06; 95% CI, 0.86-1.30; P = .58; P = .04 for trend). There was an increase in life-threatening bleeding at 7 days with reviparin and placebo (17 [0.2%] vs 7 [0.1%], respectively; P = .07), but the absolute excess was small (1 more per 1000) vs reductions in the primary outcome (18 fewer per 1000) or mortality (15 fewer per 1000).In patients with acute ST-segment elevation or new left bundle-branch block MI, reviparin reduces mortality and reinfarction, without a substantive increase in overall stroke rates. There is a small absolute excess of life-threatening bleeding but the benefits outweigh the risks.","Effects of reviparin, a low-molecular-weight heparin, on mortality, reinfarction, and strokes in patients with acute myocardial infarction presenting with ST-segment elevation."
"504","JAMA.3041","0.58",15671427,2005,"Although reperfusion therapy, aspirin, beta-blockers, and angiotensin-converting enzyme inhibitors reduce mortality when used early in patients with acute myocardial infarction (MI), mortality and morbidity remain high. No antithrombotic or newer antiplatelet drug has been shown to reduce mortality in acute MI.To evaluate the effects of reviparin, a low-molecular-weight heparin, when initiated early and given for 7 days in addition to usual therapy on the primary composite outcome of death, myocardial reinfarction, or strokes at 7 and 30 days.A randomized, double-blind, placebo-controlled trial (Clinical Trial of Reviparin and Metabolic Modulation in Acute Myocardial Infarction Treatment Evaluation [CREATE]) of 15,570 patients with ST-segment elevation or new left bundle-branch block, presenting within 12 hours of symptom onset at 341 hospitals in India and China from July 2001 through July 2004.Reviparin or placebo subcutaneously twice daily for 7 days.Primary composite outcome of death, myocardial reinfarction, or stroke at 7 and 30 days.The primary composite outcome was significantly reduced from 854 (11.0%) of 7790 patients in the placebo group to 745 (9.6%) of 7780 in the reviparin group (hazard ratio [HR], 0.87; 95% CI, 0.79-0.96; P = .005). These benefits persisted at 30 days (1056 [13.6%] vs 921 [11.8%] patients; HR, 0.87; 95% CI, 0.79-0.95; P = .001) with significant reductions in 30-day mortality (877 [11.3%] vs 766 [9.8%]; HR, 0.87; 95% CI, 0.79-0.96; P = .005) and reinfarction (199 [2.6%] vs 154 [2.0%]; HR, 0.77; 95% CI, 0.62-0.95; P = .01), and no significant differences in strokes (64 [0.8%] vs 80 [1.0%]; P = .19). Reviparin treatment was significantly better when it was initiated very early after symptom onset at 7 days (<2 hours: HR, 0.70; 95% CI, 0.52-0.96; P = .03; 30/1000 events prevented; 2 to <4 hours: HR, 0.81; 95% CI, 0.67-0.98; P = .03; 21/1000 events prevented; 4 to <8 hours: HR, 0.85; 95% CI, 0.73-0.99; P = .05; 16/1000 events prevented; and > or =8 hours: HR, 1.06; 95% CI, 0.86-1.30; P = .58; P = .04 for trend). There was an increase in life-threatening bleeding at 7 days with reviparin and placebo (17 [0.2%] vs 7 [0.1%], respectively; P = .07), but the absolute excess was small (1 more per 1000) vs reductions in the primary outcome (18 fewer per 1000) or mortality (15 fewer per 1000).In patients with acute ST-segment elevation or new left bundle-branch block MI, reviparin reduces mortality and reinfarction, without a substantive increase in overall stroke rates. There is a small absolute excess of life-threatening bleeding but the benefits outweigh the risks.","Effects of reviparin, a low-molecular-weight heparin, on mortality, reinfarction, and strokes in patients with acute myocardial infarction presenting with ST-segment elevation."
"505","JAMA.2921","0.45",15671428,2005,"Glucose-insulin-potassium (GIK) infusion is a widely applicable, low-cost therapy that has been postulated to improve mortality in patients with acute ST-segment elevation myocardial infarction (STEMI). Given the potential global importance of GIK infusion, a large, adequately powered randomized trial is required to determine the effect of GIK on mortality in patients with STEMI.To determine the effect of high-dose GIK infusion on mortality in patients with STEMI.Randomized controlled trial conducted in 470 centers worldwide among 20,201 patients with STEMI who presented within 12 hours of symptom onset. The mean age of patients was 58.6 years, and evidence-based therapies were commonly used.Patients were randomly assigned to receive GIK intravenous infusion for 24 hours plus usual care (n = 10,091) or to receive usual care alone (controls; n = 10,110).Mortality, cardiac arrest, cardiogenic shock, and reinfarction at 30 days after randomization.At 30 days, 976 control patients (9.7%) and 1004 GIK infusion patients (10.0%) died (hazard ratio [HR], 1.03; 95% confidence interval [CI], 0.95-1.13; P = .45). There were no significant differences in the rates of cardiac arrest (1.5% [151/10 107] in control and 1.4% [139/10,088] in GIK infusion; HR, 0.93; 95% CI, 0.74-1.17; P = .51), cardiogenic shock (6.3% [640/10 107] vs 6.6% [667/10 088]; HR, 1.05; 95% CI, 0.94-1.17; P = .38), or reinfarction (2.4% [246/10,107] vs 2.3% [236/10,088]; HR, 0.98; 95% CI, 0.82-1.17; P = .81). The rates of heart failure at 7 days after randomization were also similar between the groups (16.9% [1711/10,107] vs 17.1% [1721/10,088]; HR, 1.01; 95% CI, 0.95-1.08; P = .72). The lack of benefit of GIK infusion on mortality was consistent in prespecified subgroups, including in those with and without diabetes, in those presenting with and without heart failure, in those presenting early and later after symptom onset, and in those receiving and not receiving reperfusion therapy (thrombolysis or primary percutaneous coronary intervention).In this large, international randomized trial, high-dose GIK infusion had a neutral effect on mortality, cardiac arrest, and cardiogenic shock in patients with acute STEMI.","Effect of glucose-insulin-potassium infusion on mortality in patients with acute ST-segment elevation myocardial infarction: the CREATE-ECLA randomized controlled trial."
"506","JAMA.2931","0.51",15671428,2005,"Glucose-insulin-potassium (GIK) infusion is a widely applicable, low-cost therapy that has been postulated to improve mortality in patients with acute ST-segment elevation myocardial infarction (STEMI). Given the potential global importance of GIK infusion, a large, adequately powered randomized trial is required to determine the effect of GIK on mortality in patients with STEMI.To determine the effect of high-dose GIK infusion on mortality in patients with STEMI.Randomized controlled trial conducted in 470 centers worldwide among 20,201 patients with STEMI who presented within 12 hours of symptom onset. The mean age of patients was 58.6 years, and evidence-based therapies were commonly used.Patients were randomly assigned to receive GIK intravenous infusion for 24 hours plus usual care (n = 10,091) or to receive usual care alone (controls; n = 10,110).Mortality, cardiac arrest, cardiogenic shock, and reinfarction at 30 days after randomization.At 30 days, 976 control patients (9.7%) and 1004 GIK infusion patients (10.0%) died (hazard ratio [HR], 1.03; 95% confidence interval [CI], 0.95-1.13; P = .45). There were no significant differences in the rates of cardiac arrest (1.5% [151/10 107] in control and 1.4% [139/10,088] in GIK infusion; HR, 0.93; 95% CI, 0.74-1.17; P = .51), cardiogenic shock (6.3% [640/10 107] vs 6.6% [667/10 088]; HR, 1.05; 95% CI, 0.94-1.17; P = .38), or reinfarction (2.4% [246/10,107] vs 2.3% [236/10,088]; HR, 0.98; 95% CI, 0.82-1.17; P = .81). The rates of heart failure at 7 days after randomization were also similar between the groups (16.9% [1711/10,107] vs 17.1% [1721/10,088]; HR, 1.01; 95% CI, 0.95-1.08; P = .72). The lack of benefit of GIK infusion on mortality was consistent in prespecified subgroups, including in those with and without diabetes, in those presenting with and without heart failure, in those presenting early and later after symptom onset, and in those receiving and not receiving reperfusion therapy (thrombolysis or primary percutaneous coronary intervention).In this large, international randomized trial, high-dose GIK infusion had a neutral effect on mortality, cardiac arrest, and cardiogenic shock in patients with acute STEMI.","Effect of glucose-insulin-potassium infusion on mortality in patients with acute ST-segment elevation myocardial infarction: the CREATE-ECLA randomized controlled trial."
"507","JAMA.2941","0.38",15671428,2005,"Glucose-insulin-potassium (GIK) infusion is a widely applicable, low-cost therapy that has been postulated to improve mortality in patients with acute ST-segment elevation myocardial infarction (STEMI). Given the potential global importance of GIK infusion, a large, adequately powered randomized trial is required to determine the effect of GIK on mortality in patients with STEMI.To determine the effect of high-dose GIK infusion on mortality in patients with STEMI.Randomized controlled trial conducted in 470 centers worldwide among 20,201 patients with STEMI who presented within 12 hours of symptom onset. The mean age of patients was 58.6 years, and evidence-based therapies were commonly used.Patients were randomly assigned to receive GIK intravenous infusion for 24 hours plus usual care (n = 10,091) or to receive usual care alone (controls; n = 10,110).Mortality, cardiac arrest, cardiogenic shock, and reinfarction at 30 days after randomization.At 30 days, 976 control patients (9.7%) and 1004 GIK infusion patients (10.0%) died (hazard ratio [HR], 1.03; 95% confidence interval [CI], 0.95-1.13; P = .45). There were no significant differences in the rates of cardiac arrest (1.5% [151/10 107] in control and 1.4% [139/10,088] in GIK infusion; HR, 0.93; 95% CI, 0.74-1.17; P = .51), cardiogenic shock (6.3% [640/10 107] vs 6.6% [667/10 088]; HR, 1.05; 95% CI, 0.94-1.17; P = .38), or reinfarction (2.4% [246/10,107] vs 2.3% [236/10,088]; HR, 0.98; 95% CI, 0.82-1.17; P = .81). The rates of heart failure at 7 days after randomization were also similar between the groups (16.9% [1711/10,107] vs 17.1% [1721/10,088]; HR, 1.01; 95% CI, 0.95-1.08; P = .72). The lack of benefit of GIK infusion on mortality was consistent in prespecified subgroups, including in those with and without diabetes, in those presenting with and without heart failure, in those presenting early and later after symptom onset, and in those receiving and not receiving reperfusion therapy (thrombolysis or primary percutaneous coronary intervention).In this large, international randomized trial, high-dose GIK infusion had a neutral effect on mortality, cardiac arrest, and cardiogenic shock in patients with acute STEMI.","Effect of glucose-insulin-potassium infusion on mortality in patients with acute ST-segment elevation myocardial infarction: the CREATE-ECLA randomized controlled trial."
"508","JAMA.2951","0.81",15671428,2005,"Glucose-insulin-potassium (GIK) infusion is a widely applicable, low-cost therapy that has been postulated to improve mortality in patients with acute ST-segment elevation myocardial infarction (STEMI). Given the potential global importance of GIK infusion, a large, adequately powered randomized trial is required to determine the effect of GIK on mortality in patients with STEMI.To determine the effect of high-dose GIK infusion on mortality in patients with STEMI.Randomized controlled trial conducted in 470 centers worldwide among 20,201 patients with STEMI who presented within 12 hours of symptom onset. The mean age of patients was 58.6 years, and evidence-based therapies were commonly used.Patients were randomly assigned to receive GIK intravenous infusion for 24 hours plus usual care (n = 10,091) or to receive usual care alone (controls; n = 10,110).Mortality, cardiac arrest, cardiogenic shock, and reinfarction at 30 days after randomization.At 30 days, 976 control patients (9.7%) and 1004 GIK infusion patients (10.0%) died (hazard ratio [HR], 1.03; 95% confidence interval [CI], 0.95-1.13; P = .45). There were no significant differences in the rates of cardiac arrest (1.5% [151/10 107] in control and 1.4% [139/10,088] in GIK infusion; HR, 0.93; 95% CI, 0.74-1.17; P = .51), cardiogenic shock (6.3% [640/10 107] vs 6.6% [667/10 088]; HR, 1.05; 95% CI, 0.94-1.17; P = .38), or reinfarction (2.4% [246/10,107] vs 2.3% [236/10,088]; HR, 0.98; 95% CI, 0.82-1.17; P = .81). The rates of heart failure at 7 days after randomization were also similar between the groups (16.9% [1711/10,107] vs 17.1% [1721/10,088]; HR, 1.01; 95% CI, 0.95-1.08; P = .72). The lack of benefit of GIK infusion on mortality was consistent in prespecified subgroups, including in those with and without diabetes, in those presenting with and without heart failure, in those presenting early and later after symptom onset, and in those receiving and not receiving reperfusion therapy (thrombolysis or primary percutaneous coronary intervention).In this large, international randomized trial, high-dose GIK infusion had a neutral effect on mortality, cardiac arrest, and cardiogenic shock in patients with acute STEMI.","Effect of glucose-insulin-potassium infusion on mortality in patients with acute ST-segment elevation myocardial infarction: the CREATE-ECLA randomized controlled trial."
"509","JAMA.2961","0.72",15671428,2005,"Glucose-insulin-potassium (GIK) infusion is a widely applicable, low-cost therapy that has been postulated to improve mortality in patients with acute ST-segment elevation myocardial infarction (STEMI). Given the potential global importance of GIK infusion, a large, adequately powered randomized trial is required to determine the effect of GIK on mortality in patients with STEMI.To determine the effect of high-dose GIK infusion on mortality in patients with STEMI.Randomized controlled trial conducted in 470 centers worldwide among 20,201 patients with STEMI who presented within 12 hours of symptom onset. The mean age of patients was 58.6 years, and evidence-based therapies were commonly used.Patients were randomly assigned to receive GIK intravenous infusion for 24 hours plus usual care (n = 10,091) or to receive usual care alone (controls; n = 10,110).Mortality, cardiac arrest, cardiogenic shock, and reinfarction at 30 days after randomization.At 30 days, 976 control patients (9.7%) and 1004 GIK infusion patients (10.0%) died (hazard ratio [HR], 1.03; 95% confidence interval [CI], 0.95-1.13; P = .45). There were no significant differences in the rates of cardiac arrest (1.5% [151/10 107] in control and 1.4% [139/10,088] in GIK infusion; HR, 0.93; 95% CI, 0.74-1.17; P = .51), cardiogenic shock (6.3% [640/10 107] vs 6.6% [667/10 088]; HR, 1.05; 95% CI, 0.94-1.17; P = .38), or reinfarction (2.4% [246/10,107] vs 2.3% [236/10,088]; HR, 0.98; 95% CI, 0.82-1.17; P = .81). The rates of heart failure at 7 days after randomization were also similar between the groups (16.9% [1711/10,107] vs 17.1% [1721/10,088]; HR, 1.01; 95% CI, 0.95-1.08; P = .72). The lack of benefit of GIK infusion on mortality was consistent in prespecified subgroups, including in those with and without diabetes, in those presenting with and without heart failure, in those presenting early and later after symptom onset, and in those receiving and not receiving reperfusion therapy (thrombolysis or primary percutaneous coronary intervention).In this large, international randomized trial, high-dose GIK infusion had a neutral effect on mortality, cardiac arrest, and cardiogenic shock in patients with acute STEMI.","Effect of glucose-insulin-potassium infusion on mortality in patients with acute ST-segment elevation myocardial infarction: the CREATE-ECLA randomized controlled trial."
"510","Lancet.351","1.00E-04",15866308,2005,"Postmenopausal women who use hormone-replacement therapy (HRT) containing oestrogen alone are at increased risk of endometrial cancer. To minimise this risk, many HRT users who have not had a hysterectomy use combined oestrogen-progestagen preparations or tibolone. Limited information is available on the incidence of endometrial cancer in users of these therapies.716,738 postmenopausal women in the UK without previous cancer or previous hysterectomy were recruited into the Million Women Study in 1996-2001, provided information about their use of HRT and other personal details, and were followed up for an average of 3.4 years, during which time 1320 incident endometrial cancers were diagnosed.320,953 women (45%) reported at recruitment that they had used HRT, among whom 69,577 (22%) last used continuous combined therapy (progestagen added daily to oestrogen), 145,486 (45%) last used cyclic combined therapy (progestagen added to oestrogen, usually for 10-14 days per month), 28,028 (9%) last used tibolone, and 14,204 (4%) last used oestrogen-only HRT. These HRT types had sharply contrasting effects on the overall risk of endometrial cancer (p<0.0001 for heterogeneity). Compared with never users of HRT, risk was: reduced with last use of continuous combined preparations (relative risk 0.71 [95% CI 0.56-0.90]; p=0.005); increased with last use of tibolone (1.79 [1.43-2.25]; p<0.0001) and oestrogen only (1.45 [1.02-2.06]; p=0.04); and not significantly altered with last use of cyclic combined preparations (1.05 [0.91-1.22]; p=0.5). A woman's body-mass index significantly affected these associations, such that the adverse effects of tibolone and oestrogen-only HRT were greatest in non-obese women, and the beneficial effects of combined HRT were greatest in obese women.Oestrogens and tibolone increase the risk of endometrial cancer. Progestagens counteract the adverse effect of oestrogens on the endometrium, the effect being greater the more days every month that they are added to oestrogen and the more obese that women are. However, combined oestrogen-progestagen HRT causes a greater increase in breast cancer than the other therapies do. Thus, when endometrial and breast cancers are added together, there is a greater increase in total cancer incidence with use of combined HRT, both continuous and cyclic, than with use of the other therapies.","Endometrial cancer and hormone-replacement therapy in the Million Women Study."
"511","Lancet.551","0.005",15866308,2005,"Postmenopausal women who use hormone-replacement therapy (HRT) containing oestrogen alone are at increased risk of endometrial cancer. To minimise this risk, many HRT users who have not had a hysterectomy use combined oestrogen-progestagen preparations or tibolone. Limited information is available on the incidence of endometrial cancer in users of these therapies.716,738 postmenopausal women in the UK without previous cancer or previous hysterectomy were recruited into the Million Women Study in 1996-2001, provided information about their use of HRT and other personal details, and were followed up for an average of 3.4 years, during which time 1320 incident endometrial cancers were diagnosed.320,953 women (45%) reported at recruitment that they had used HRT, among whom 69,577 (22%) last used continuous combined therapy (progestagen added daily to oestrogen), 145,486 (45%) last used cyclic combined therapy (progestagen added to oestrogen, usually for 10-14 days per month), 28,028 (9%) last used tibolone, and 14,204 (4%) last used oestrogen-only HRT. These HRT types had sharply contrasting effects on the overall risk of endometrial cancer (p<0.0001 for heterogeneity). Compared with never users of HRT, risk was: reduced with last use of continuous combined preparations (relative risk 0.71 [95% CI 0.56-0.90]; p=0.005); increased with last use of tibolone (1.79 [1.43-2.25]; p<0.0001) and oestrogen only (1.45 [1.02-2.06]; p=0.04); and not significantly altered with last use of cyclic combined preparations (1.05 [0.91-1.22]; p=0.5). A woman's body-mass index significantly affected these associations, such that the adverse effects of tibolone and oestrogen-only HRT were greatest in non-obese women, and the beneficial effects of combined HRT were greatest in obese women.Oestrogens and tibolone increase the risk of endometrial cancer. Progestagens counteract the adverse effect of oestrogens on the endometrium, the effect being greater the more days every month that they are added to oestrogen and the more obese that women are. However, combined oestrogen-progestagen HRT causes a greater increase in breast cancer than the other therapies do. Thus, when endometrial and breast cancers are added together, there is a greater increase in total cancer incidence with use of combined HRT, both continuous and cyclic, than with use of the other therapies.","Endometrial cancer and hormone-replacement therapy in the Million Women Study."
"512","Lancet.561","0.04",15866308,2005,"Postmenopausal women who use hormone-replacement therapy (HRT) containing oestrogen alone are at increased risk of endometrial cancer. To minimise this risk, many HRT users who have not had a hysterectomy use combined oestrogen-progestagen preparations or tibolone. Limited information is available on the incidence of endometrial cancer in users of these therapies.716,738 postmenopausal women in the UK without previous cancer or previous hysterectomy were recruited into the Million Women Study in 1996-2001, provided information about their use of HRT and other personal details, and were followed up for an average of 3.4 years, during which time 1320 incident endometrial cancers were diagnosed.320,953 women (45%) reported at recruitment that they had used HRT, among whom 69,577 (22%) last used continuous combined therapy (progestagen added daily to oestrogen), 145,486 (45%) last used cyclic combined therapy (progestagen added to oestrogen, usually for 10-14 days per month), 28,028 (9%) last used tibolone, and 14,204 (4%) last used oestrogen-only HRT. These HRT types had sharply contrasting effects on the overall risk of endometrial cancer (p<0.0001 for heterogeneity). Compared with never users of HRT, risk was: reduced with last use of continuous combined preparations (relative risk 0.71 [95% CI 0.56-0.90]; p=0.005); increased with last use of tibolone (1.79 [1.43-2.25]; p<0.0001) and oestrogen only (1.45 [1.02-2.06]; p=0.04); and not significantly altered with last use of cyclic combined preparations (1.05 [0.91-1.22]; p=0.5). A woman's body-mass index significantly affected these associations, such that the adverse effects of tibolone and oestrogen-only HRT were greatest in non-obese women, and the beneficial effects of combined HRT were greatest in obese women.Oestrogens and tibolone increase the risk of endometrial cancer. Progestagens counteract the adverse effect of oestrogens on the endometrium, the effect being greater the more days every month that they are added to oestrogen and the more obese that women are. However, combined oestrogen-progestagen HRT causes a greater increase in breast cancer than the other therapies do. Thus, when endometrial and breast cancers are added together, there is a greater increase in total cancer incidence with use of combined HRT, both continuous and cyclic, than with use of the other therapies.","Endometrial cancer and hormone-replacement therapy in the Million Women Study."
"513","Lancet.571","0.5",15866308,2005,"Postmenopausal women who use hormone-replacement therapy (HRT) containing oestrogen alone are at increased risk of endometrial cancer. To minimise this risk, many HRT users who have not had a hysterectomy use combined oestrogen-progestagen preparations or tibolone. Limited information is available on the incidence of endometrial cancer in users of these therapies.716,738 postmenopausal women in the UK without previous cancer or previous hysterectomy were recruited into the Million Women Study in 1996-2001, provided information about their use of HRT and other personal details, and were followed up for an average of 3.4 years, during which time 1320 incident endometrial cancers were diagnosed.320,953 women (45%) reported at recruitment that they had used HRT, among whom 69,577 (22%) last used continuous combined therapy (progestagen added daily to oestrogen), 145,486 (45%) last used cyclic combined therapy (progestagen added to oestrogen, usually for 10-14 days per month), 28,028 (9%) last used tibolone, and 14,204 (4%) last used oestrogen-only HRT. These HRT types had sharply contrasting effects on the overall risk of endometrial cancer (p<0.0001 for heterogeneity). Compared with never users of HRT, risk was: reduced with last use of continuous combined preparations (relative risk 0.71 [95% CI 0.56-0.90]; p=0.005); increased with last use of tibolone (1.79 [1.43-2.25]; p<0.0001) and oestrogen only (1.45 [1.02-2.06]; p=0.04); and not significantly altered with last use of cyclic combined preparations (1.05 [0.91-1.22]; p=0.5). A woman's body-mass index significantly affected these associations, such that the adverse effects of tibolone and oestrogen-only HRT were greatest in non-obese women, and the beneficial effects of combined HRT were greatest in obese women.Oestrogens and tibolone increase the risk of endometrial cancer. Progestagens counteract the adverse effect of oestrogens on the endometrium, the effect being greater the more days every month that they are added to oestrogen and the more obese that women are. However, combined oestrogen-progestagen HRT causes a greater increase in breast cancer than the other therapies do. Thus, when endometrial and breast cancers are added together, there is a greater increase in total cancer incidence with use of combined HRT, both continuous and cyclic, than with use of the other therapies.","Endometrial cancer and hormone-replacement therapy in the Million Women Study."
"514","JAMA.2461","0.001",15870416,2005,"Traditionally, stent thrombosis has been regarded as a complication of percutaneous coronary interventions during the first 30 postprocedural days. However, delayed endothelialization associated with the implantation of drug-eluting stents may extend the risk of thrombosis beyond 30 days. Data are limited regarding the risks and the impact of this phenomenon outside clinical trials.To evaluate the incidence, predictors, and clinical outcome of stent thrombosis after implantation of sirolimus-eluting and paclitaxel-eluting stents in routine clinical practice.Prospective observational cohort study conducted at 1 academic hospital and 2 community hospitals in Germany and Italy. A total of 2229 consecutive patients underwent successful implantation of sirolimus-eluting (1062 patients, 1996 lesions, 2272 stents) or paclitaxel-eluting (1167 patients, 1801 lesions, 2223 stents) stents between April 2002 and January 2004.Implantation of a drug-eluting stent (sirolimus or paclitaxel). All patients were pretreated with ticlopidine or clopidogrel and aspirin. Aspirin was continued indefinitely and clopidogrel or ticlopidine for at least 3 months after sirolimus-eluting and for at least 6 months after paclitaxel-eluting stent implantation.Subacute thrombosis (from procedure end through 30 days), late thrombosis (>30 days), and cumulative stent thrombosis.At 9-month follow-up, 29 patients (1.3%) had stent thrombosis (9 [0.8%] with sirolimus and 20 [1.7%] with paclitaxel; P = .09). Fourteen patients had subacute thrombosis (0.6%) and 15 patients had late thrombosis (0.7%). Among these 29 patients, 13 died (case fatality rate, 45%). Independent predictors of stent thrombosis were premature antiplatelet therapy discontinuation (hazard ratio [HR], 89.78; 95% CI, 29.90-269.60; P<.001), renal failure (HR, 6.49; 95% CI, 2.60-16.15; P<.001), bifurcation lesions (HR, 6.42; 95% CI, 2.93-14.07; P<.001), diabetes (HR, 3.71; 95% CI, 1.74-7.89; P = .001), and a lower ejection fraction (HR, 1.09; 95% CI, 1.05-1.36; P<.001 for each 10% decrease).The cumulative incidence of stent thrombosis 9 months after successful drug-eluting stent implantation in consecutive ""real-world"" patients was substantially higher than the rate reported in clinical trials. Premature antiplatelet therapy discontinuation, renal failure, bifurcation lesions, diabetes, and low ejection fraction were identified as predictors of thrombotic events.","Incidence, predictors, and outcome of thrombosis after successful implantation of drug-eluting stents."
"515","JAMA.2471","0.001",15870416,2005,"Traditionally, stent thrombosis has been regarded as a complication of percutaneous coronary interventions during the first 30 postprocedural days. However, delayed endothelialization associated with the implantation of drug-eluting stents may extend the risk of thrombosis beyond 30 days. Data are limited regarding the risks and the impact of this phenomenon outside clinical trials.To evaluate the incidence, predictors, and clinical outcome of stent thrombosis after implantation of sirolimus-eluting and paclitaxel-eluting stents in routine clinical practice.Prospective observational cohort study conducted at 1 academic hospital and 2 community hospitals in Germany and Italy. A total of 2229 consecutive patients underwent successful implantation of sirolimus-eluting (1062 patients, 1996 lesions, 2272 stents) or paclitaxel-eluting (1167 patients, 1801 lesions, 2223 stents) stents between April 2002 and January 2004.Implantation of a drug-eluting stent (sirolimus or paclitaxel). All patients were pretreated with ticlopidine or clopidogrel and aspirin. Aspirin was continued indefinitely and clopidogrel or ticlopidine for at least 3 months after sirolimus-eluting and for at least 6 months after paclitaxel-eluting stent implantation.Subacute thrombosis (from procedure end through 30 days), late thrombosis (>30 days), and cumulative stent thrombosis.At 9-month follow-up, 29 patients (1.3%) had stent thrombosis (9 [0.8%] with sirolimus and 20 [1.7%] with paclitaxel; P = .09). Fourteen patients had subacute thrombosis (0.6%) and 15 patients had late thrombosis (0.7%). Among these 29 patients, 13 died (case fatality rate, 45%). Independent predictors of stent thrombosis were premature antiplatelet therapy discontinuation (hazard ratio [HR], 89.78; 95% CI, 29.90-269.60; P<.001), renal failure (HR, 6.49; 95% CI, 2.60-16.15; P<.001), bifurcation lesions (HR, 6.42; 95% CI, 2.93-14.07; P<.001), diabetes (HR, 3.71; 95% CI, 1.74-7.89; P = .001), and a lower ejection fraction (HR, 1.09; 95% CI, 1.05-1.36; P<.001 for each 10% decrease).The cumulative incidence of stent thrombosis 9 months after successful drug-eluting stent implantation in consecutive ""real-world"" patients was substantially higher than the rate reported in clinical trials. Premature antiplatelet therapy discontinuation, renal failure, bifurcation lesions, diabetes, and low ejection fraction were identified as predictors of thrombotic events.","Incidence, predictors, and outcome of thrombosis after successful implantation of drug-eluting stents."
"516","JAMA.2481","0.001",15870416,2005,"Traditionally, stent thrombosis has been regarded as a complication of percutaneous coronary interventions during the first 30 postprocedural days. However, delayed endothelialization associated with the implantation of drug-eluting stents may extend the risk of thrombosis beyond 30 days. Data are limited regarding the risks and the impact of this phenomenon outside clinical trials.To evaluate the incidence, predictors, and clinical outcome of stent thrombosis after implantation of sirolimus-eluting and paclitaxel-eluting stents in routine clinical practice.Prospective observational cohort study conducted at 1 academic hospital and 2 community hospitals in Germany and Italy. A total of 2229 consecutive patients underwent successful implantation of sirolimus-eluting (1062 patients, 1996 lesions, 2272 stents) or paclitaxel-eluting (1167 patients, 1801 lesions, 2223 stents) stents between April 2002 and January 2004.Implantation of a drug-eluting stent (sirolimus or paclitaxel). All patients were pretreated with ticlopidine or clopidogrel and aspirin. Aspirin was continued indefinitely and clopidogrel or ticlopidine for at least 3 months after sirolimus-eluting and for at least 6 months after paclitaxel-eluting stent implantation.Subacute thrombosis (from procedure end through 30 days), late thrombosis (>30 days), and cumulative stent thrombosis.At 9-month follow-up, 29 patients (1.3%) had stent thrombosis (9 [0.8%] with sirolimus and 20 [1.7%] with paclitaxel; P = .09). Fourteen patients had subacute thrombosis (0.6%) and 15 patients had late thrombosis (0.7%). Among these 29 patients, 13 died (case fatality rate, 45%). Independent predictors of stent thrombosis were premature antiplatelet therapy discontinuation (hazard ratio [HR], 89.78; 95% CI, 29.90-269.60; P<.001), renal failure (HR, 6.49; 95% CI, 2.60-16.15; P<.001), bifurcation lesions (HR, 6.42; 95% CI, 2.93-14.07; P<.001), diabetes (HR, 3.71; 95% CI, 1.74-7.89; P = .001), and a lower ejection fraction (HR, 1.09; 95% CI, 1.05-1.36; P<.001 for each 10% decrease).The cumulative incidence of stent thrombosis 9 months after successful drug-eluting stent implantation in consecutive ""real-world"" patients was substantially higher than the rate reported in clinical trials. Premature antiplatelet therapy discontinuation, renal failure, bifurcation lesions, diabetes, and low ejection fraction were identified as predictors of thrombotic events.","Incidence, predictors, and outcome of thrombosis after successful implantation of drug-eluting stents."
"517","JAMA.2491","0.001",15870416,2005,"Traditionally, stent thrombosis has been regarded as a complication of percutaneous coronary interventions during the first 30 postprocedural days. However, delayed endothelialization associated with the implantation of drug-eluting stents may extend the risk of thrombosis beyond 30 days. Data are limited regarding the risks and the impact of this phenomenon outside clinical trials.To evaluate the incidence, predictors, and clinical outcome of stent thrombosis after implantation of sirolimus-eluting and paclitaxel-eluting stents in routine clinical practice.Prospective observational cohort study conducted at 1 academic hospital and 2 community hospitals in Germany and Italy. A total of 2229 consecutive patients underwent successful implantation of sirolimus-eluting (1062 patients, 1996 lesions, 2272 stents) or paclitaxel-eluting (1167 patients, 1801 lesions, 2223 stents) stents between April 2002 and January 2004.Implantation of a drug-eluting stent (sirolimus or paclitaxel). All patients were pretreated with ticlopidine or clopidogrel and aspirin. Aspirin was continued indefinitely and clopidogrel or ticlopidine for at least 3 months after sirolimus-eluting and for at least 6 months after paclitaxel-eluting stent implantation.Subacute thrombosis (from procedure end through 30 days), late thrombosis (>30 days), and cumulative stent thrombosis.At 9-month follow-up, 29 patients (1.3%) had stent thrombosis (9 [0.8%] with sirolimus and 20 [1.7%] with paclitaxel; P = .09). Fourteen patients had subacute thrombosis (0.6%) and 15 patients had late thrombosis (0.7%). Among these 29 patients, 13 died (case fatality rate, 45%). Independent predictors of stent thrombosis were premature antiplatelet therapy discontinuation (hazard ratio [HR], 89.78; 95% CI, 29.90-269.60; P<.001), renal failure (HR, 6.49; 95% CI, 2.60-16.15; P<.001), bifurcation lesions (HR, 6.42; 95% CI, 2.93-14.07; P<.001), diabetes (HR, 3.71; 95% CI, 1.74-7.89; P = .001), and a lower ejection fraction (HR, 1.09; 95% CI, 1.05-1.36; P<.001 for each 10% decrease).The cumulative incidence of stent thrombosis 9 months after successful drug-eluting stent implantation in consecutive ""real-world"" patients was substantially higher than the rate reported in clinical trials. Premature antiplatelet therapy discontinuation, renal failure, bifurcation lesions, diabetes, and low ejection fraction were identified as predictors of thrombotic events.","Incidence, predictors, and outcome of thrombosis after successful implantation of drug-eluting stents."
"518","JAMA.2911","0.001",15870416,2005,"Traditionally, stent thrombosis has been regarded as a complication of percutaneous coronary interventions during the first 30 postprocedural days. However, delayed endothelialization associated with the implantation of drug-eluting stents may extend the risk of thrombosis beyond 30 days. Data are limited regarding the risks and the impact of this phenomenon outside clinical trials.To evaluate the incidence, predictors, and clinical outcome of stent thrombosis after implantation of sirolimus-eluting and paclitaxel-eluting stents in routine clinical practice.Prospective observational cohort study conducted at 1 academic hospital and 2 community hospitals in Germany and Italy. A total of 2229 consecutive patients underwent successful implantation of sirolimus-eluting (1062 patients, 1996 lesions, 2272 stents) or paclitaxel-eluting (1167 patients, 1801 lesions, 2223 stents) stents between April 2002 and January 2004.Implantation of a drug-eluting stent (sirolimus or paclitaxel). All patients were pretreated with ticlopidine or clopidogrel and aspirin. Aspirin was continued indefinitely and clopidogrel or ticlopidine for at least 3 months after sirolimus-eluting and for at least 6 months after paclitaxel-eluting stent implantation.Subacute thrombosis (from procedure end through 30 days), late thrombosis (>30 days), and cumulative stent thrombosis.At 9-month follow-up, 29 patients (1.3%) had stent thrombosis (9 [0.8%] with sirolimus and 20 [1.7%] with paclitaxel; P = .09). Fourteen patients had subacute thrombosis (0.6%) and 15 patients had late thrombosis (0.7%). Among these 29 patients, 13 died (case fatality rate, 45%). Independent predictors of stent thrombosis were premature antiplatelet therapy discontinuation (hazard ratio [HR], 89.78; 95% CI, 29.90-269.60; P<.001), renal failure (HR, 6.49; 95% CI, 2.60-16.15; P<.001), bifurcation lesions (HR, 6.42; 95% CI, 2.93-14.07; P<.001), diabetes (HR, 3.71; 95% CI, 1.74-7.89; P = .001), and a lower ejection fraction (HR, 1.09; 95% CI, 1.05-1.36; P<.001 for each 10% decrease).The cumulative incidence of stent thrombosis 9 months after successful drug-eluting stent implantation in consecutive ""real-world"" patients was substantially higher than the rate reported in clinical trials. Premature antiplatelet therapy discontinuation, renal failure, bifurcation lesions, diabetes, and low ejection fraction were identified as predictors of thrombotic events.","Incidence, predictors, and outcome of thrombosis after successful implantation of drug-eluting stents."
"519","JAMA.2881","0.001",15900004,2005,"While gluten ingestion is responsible for the signs and symptoms of celiac disease, it is not known what factors are associated with initial appearance of the disease.To examine whether the timing of gluten exposure in the infant diet was associated with the development of celiac disease autoimmunity (CDA).Prospective observational study conducted in Denver, Colo, from 1994-2004 of 1560 children at increased risk for celiac disease or type 1 diabetes, as defined by possession of either HLA-DR3 or DR4 alleles, or having a first-degree relative with type 1 diabetes. The mean follow-up was 4.8 years.Risk of CDA defined as being positive for tissue transglutaminase (tTG) autoantibody on 2 or more consecutive visits or being positive for tTG once and having a positive small bowel biopsy for celiac disease, by timing of introduction of gluten-containing foods into the diet.Fifty-one children developed CDA. Findings adjusted for HLA-DR3 status indicated that children exposed to foods containing wheat, barley, or rye (gluten-containing foods) in the first 3 months of life (3 [6%] CDA positive vs 40 [3%] CDA negative) had a 5-fold increased risk of CDA compared with children exposed to gluten-containing foods at 4 to 6 months (12 [23%] CDA positive vs 574 [38%] CDA negative) (hazard ratio [HR], 5.17; 95% confidence interval [CI], 1.44-18.57). Children not exposed to gluten until the seventh month or later (36 [71%] CDA positive vs 895 [59%] CDA negative) had a marginally increased risk of CDA compared with those exposed at 4 to 6 months (HR, 1.87; 95% CI, 0.97-3.60). After restricting our case group to only the 25 CDA-positive children who had biopsy-diagnosed celiac disease, initial exposure to wheat, barley, or rye in the first 3 months (3 [12%] CDA positive vs 40 [3%] CDA negative) or in the seventh month or later (19 [76%] CDA positive vs 912 [59%] CDA negative) significantly increased risk of CDA compared with exposure at 4 to 6 months (3 [12%] CDA positive vs 583 [38%] CDA negative) (HR, 22.97; 95% CI, 4.55-115.93; P = .001; and HR, 3.98; 95% CI, 1.18-13.46; P = .04, respectively).Timing of introduction of gluten into the infant diet is associated with the appearance of CDA in children at increased risk for the disease.","Risk of celiac disease autoimmunity and timing of gluten introduction in the diet of infants at increased risk of disease."
"520","JAMA.2891","0.04",15900004,2005,"While gluten ingestion is responsible for the signs and symptoms of celiac disease, it is not known what factors are associated with initial appearance of the disease.To examine whether the timing of gluten exposure in the infant diet was associated with the development of celiac disease autoimmunity (CDA).Prospective observational study conducted in Denver, Colo, from 1994-2004 of 1560 children at increased risk for celiac disease or type 1 diabetes, as defined by possession of either HLA-DR3 or DR4 alleles, or having a first-degree relative with type 1 diabetes. The mean follow-up was 4.8 years.Risk of CDA defined as being positive for tissue transglutaminase (tTG) autoantibody on 2 or more consecutive visits or being positive for tTG once and having a positive small bowel biopsy for celiac disease, by timing of introduction of gluten-containing foods into the diet.Fifty-one children developed CDA. Findings adjusted for HLA-DR3 status indicated that children exposed to foods containing wheat, barley, or rye (gluten-containing foods) in the first 3 months of life (3 [6%] CDA positive vs 40 [3%] CDA negative) had a 5-fold increased risk of CDA compared with children exposed to gluten-containing foods at 4 to 6 months (12 [23%] CDA positive vs 574 [38%] CDA negative) (hazard ratio [HR], 5.17; 95% confidence interval [CI], 1.44-18.57). Children not exposed to gluten until the seventh month or later (36 [71%] CDA positive vs 895 [59%] CDA negative) had a marginally increased risk of CDA compared with those exposed at 4 to 6 months (HR, 1.87; 95% CI, 0.97-3.60). After restricting our case group to only the 25 CDA-positive children who had biopsy-diagnosed celiac disease, initial exposure to wheat, barley, or rye in the first 3 months (3 [12%] CDA positive vs 40 [3%] CDA negative) or in the seventh month or later (19 [76%] CDA positive vs 912 [59%] CDA negative) significantly increased risk of CDA compared with exposure at 4 to 6 months (3 [12%] CDA positive vs 583 [38%] CDA negative) (HR, 22.97; 95% CI, 4.55-115.93; P = .001; and HR, 3.98; 95% CI, 1.18-13.46; P = .04, respectively).Timing of introduction of gluten into the infant diet is associated with the appearance of CDA in children at increased risk for the disease.","Risk of celiac disease autoimmunity and timing of gluten introduction in the diet of infants at increased risk of disease."
"521","JAMA.2891","NA",15900004,2005,"While gluten ingestion is responsible for the signs and symptoms of celiac disease, it is not known what factors are associated with initial appearance of the disease.To examine whether the timing of gluten exposure in the infant diet was associated with the development of celiac disease autoimmunity (CDA).Prospective observational study conducted in Denver, Colo, from 1994-2004 of 1560 children at increased risk for celiac disease or type 1 diabetes, as defined by possession of either HLA-DR3 or DR4 alleles, or having a first-degree relative with type 1 diabetes. The mean follow-up was 4.8 years.Risk of CDA defined as being positive for tissue transglutaminase (tTG) autoantibody on 2 or more consecutive visits or being positive for tTG once and having a positive small bowel biopsy for celiac disease, by timing of introduction of gluten-containing foods into the diet.Fifty-one children developed CDA. Findings adjusted for HLA-DR3 status indicated that children exposed to foods containing wheat, barley, or rye (gluten-containing foods) in the first 3 months of life (3 [6%] CDA positive vs 40 [3%] CDA negative) had a 5-fold increased risk of CDA compared with children exposed to gluten-containing foods at 4 to 6 months (12 [23%] CDA positive vs 574 [38%] CDA negative) (hazard ratio [HR], 5.17; 95% confidence interval [CI], 1.44-18.57). Children not exposed to gluten until the seventh month or later (36 [71%] CDA positive vs 895 [59%] CDA negative) had a marginally increased risk of CDA compared with those exposed at 4 to 6 months (HR, 1.87; 95% CI, 0.97-3.60). After restricting our case group to only the 25 CDA-positive children who had biopsy-diagnosed celiac disease, initial exposure to wheat, barley, or rye in the first 3 months (3 [12%] CDA positive vs 40 [3%] CDA negative) or in the seventh month or later (19 [76%] CDA positive vs 912 [59%] CDA negative) significantly increased risk of CDA compared with exposure at 4 to 6 months (3 [12%] CDA positive vs 583 [38%] CDA negative) (HR, 22.97; 95% CI, 4.55-115.93; P = .001; and HR, 3.98; 95% CI, 1.18-13.46; P = .04, respectively).Timing of introduction of gluten into the infant diet is associated with the appearance of CDA in children at increased risk for the disease.","Risk of celiac disease autoimmunity and timing of gluten introduction in the diet of infants at increased risk of disease."
"522","JAMA.2891","NA",15900004,2005,"While gluten ingestion is responsible for the signs and symptoms of celiac disease, it is not known what factors are associated with initial appearance of the disease.To examine whether the timing of gluten exposure in the infant diet was associated with the development of celiac disease autoimmunity (CDA).Prospective observational study conducted in Denver, Colo, from 1994-2004 of 1560 children at increased risk for celiac disease or type 1 diabetes, as defined by possession of either HLA-DR3 or DR4 alleles, or having a first-degree relative with type 1 diabetes. The mean follow-up was 4.8 years.Risk of CDA defined as being positive for tissue transglutaminase (tTG) autoantibody on 2 or more consecutive visits or being positive for tTG once and having a positive small bowel biopsy for celiac disease, by timing of introduction of gluten-containing foods into the diet.Fifty-one children developed CDA. Findings adjusted for HLA-DR3 status indicated that children exposed to foods containing wheat, barley, or rye (gluten-containing foods) in the first 3 months of life (3 [6%] CDA positive vs 40 [3%] CDA negative) had a 5-fold increased risk of CDA compared with children exposed to gluten-containing foods at 4 to 6 months (12 [23%] CDA positive vs 574 [38%] CDA negative) (hazard ratio [HR], 5.17; 95% confidence interval [CI], 1.44-18.57). Children not exposed to gluten until the seventh month or later (36 [71%] CDA positive vs 895 [59%] CDA negative) had a marginally increased risk of CDA compared with those exposed at 4 to 6 months (HR, 1.87; 95% CI, 0.97-3.60). After restricting our case group to only the 25 CDA-positive children who had biopsy-diagnosed celiac disease, initial exposure to wheat, barley, or rye in the first 3 months (3 [12%] CDA positive vs 40 [3%] CDA negative) or in the seventh month or later (19 [76%] CDA positive vs 912 [59%] CDA negative) significantly increased risk of CDA compared with exposure at 4 to 6 months (3 [12%] CDA positive vs 583 [38%] CDA negative) (HR, 22.97; 95% CI, 4.55-115.93; P = .001; and HR, 3.98; 95% CI, 1.18-13.46; P = .04, respectively).Timing of introduction of gluten into the infant diet is associated with the appearance of CDA in children at increased risk for the disease.","Risk of celiac disease autoimmunity and timing of gluten introduction in the diet of infants at increased risk of disease."
"523","JAMA.317","0.83",15928286,2005,"Although Chlamydia pneumoniae infection has been associated with the initiation and progression of atherosclerosis, results of clinical trials investigating antichlamydial antibiotics as adjuncts to standard therapy in patients with coronary artery disease (CAD) have been inconsistent.To conduct a meta-analysis of clinical trials of antichlamydial antibiotic therapy in patients with CAD.The MEDLINE and Cochrane Central Register of Controlled Trials databases were searched from 1966 to April 2005 for English-language trials of antibiotic therapy in patients with CAD. Bibliographies of retrieved articles were searched for further studies. Presentations at major scientific meetings (2003-2004) were also reviewed. Search terms included antibacterial agents, myocardial infarction, unstable angina, and coronary arteriosclerosis.Eligible studies were prospective, randomized, placebo-controlled trials of antichlamydial antibiotic therapy in patients with CAD that reported all-cause mortality, myocardial infarction, or unstable angina. Of the 110 potentially relevant articles identified, 11 reports enrolling 19,217 patients were included.Included studies were reviewed to determine the number of patients randomized, mean duration of follow-up, and end points. End points of interest included all-cause mortality, myocardial infarction (MI), and a combined end point of MI and unstable angina.Event rates were combined using a random-effects model. Antibiotic therapy had no impact on all-cause mortality among treated vs untreated patients (4.7% vs 4.6%; odds ratio [OR], 1.02; 95% confidence interval [CI], 0.89-1.16; P = .83), on the rates of MI (5.0% vs 5.4%; OR, 0.92; 95% CI, 0.81-1.04; P = .19), or on the combined end point of MI and unstable angina (9.2% vs 9.6%; OR, 0.91; 95% CI, 0.76-1.07; P = .25).Evidence available to date does not demonstrate an overall benefit of antibiotic therapy in reducing mortality or cardiovascular events in patients with CAD.","Effects of antibiotic therapy on outcomes of patients with coronary artery disease: a meta-analysis of randomized controlled trials."
"524","JAMA.318","0.19",15928286,2005,"Although Chlamydia pneumoniae infection has been associated with the initiation and progression of atherosclerosis, results of clinical trials investigating antichlamydial antibiotics as adjuncts to standard therapy in patients with coronary artery disease (CAD) have been inconsistent.To conduct a meta-analysis of clinical trials of antichlamydial antibiotic therapy in patients with CAD.The MEDLINE and Cochrane Central Register of Controlled Trials databases were searched from 1966 to April 2005 for English-language trials of antibiotic therapy in patients with CAD. Bibliographies of retrieved articles were searched for further studies. Presentations at major scientific meetings (2003-2004) were also reviewed. Search terms included antibacterial agents, myocardial infarction, unstable angina, and coronary arteriosclerosis.Eligible studies were prospective, randomized, placebo-controlled trials of antichlamydial antibiotic therapy in patients with CAD that reported all-cause mortality, myocardial infarction, or unstable angina. Of the 110 potentially relevant articles identified, 11 reports enrolling 19,217 patients were included.Included studies were reviewed to determine the number of patients randomized, mean duration of follow-up, and end points. End points of interest included all-cause mortality, myocardial infarction (MI), and a combined end point of MI and unstable angina.Event rates were combined using a random-effects model. Antibiotic therapy had no impact on all-cause mortality among treated vs untreated patients (4.7% vs 4.6%; odds ratio [OR], 1.02; 95% confidence interval [CI], 0.89-1.16; P = .83), on the rates of MI (5.0% vs 5.4%; OR, 0.92; 95% CI, 0.81-1.04; P = .19), or on the combined end point of MI and unstable angina (9.2% vs 9.6%; OR, 0.91; 95% CI, 0.76-1.07; P = .25).Evidence available to date does not demonstrate an overall benefit of antibiotic therapy in reducing mortality or cardiovascular events in patients with CAD.","Effects of antibiotic therapy on outcomes of patients with coronary artery disease: a meta-analysis of randomized controlled trials."
"525","JAMA.319","0.25",15928286,2005,"Although Chlamydia pneumoniae infection has been associated with the initiation and progression of atherosclerosis, results of clinical trials investigating antichlamydial antibiotics as adjuncts to standard therapy in patients with coronary artery disease (CAD) have been inconsistent.To conduct a meta-analysis of clinical trials of antichlamydial antibiotic therapy in patients with CAD.The MEDLINE and Cochrane Central Register of Controlled Trials databases were searched from 1966 to April 2005 for English-language trials of antibiotic therapy in patients with CAD. Bibliographies of retrieved articles were searched for further studies. Presentations at major scientific meetings (2003-2004) were also reviewed. Search terms included antibacterial agents, myocardial infarction, unstable angina, and coronary arteriosclerosis.Eligible studies were prospective, randomized, placebo-controlled trials of antichlamydial antibiotic therapy in patients with CAD that reported all-cause mortality, myocardial infarction, or unstable angina. Of the 110 potentially relevant articles identified, 11 reports enrolling 19,217 patients were included.Included studies were reviewed to determine the number of patients randomized, mean duration of follow-up, and end points. End points of interest included all-cause mortality, myocardial infarction (MI), and a combined end point of MI and unstable angina.Event rates were combined using a random-effects model. Antibiotic therapy had no impact on all-cause mortality among treated vs untreated patients (4.7% vs 4.6%; odds ratio [OR], 1.02; 95% confidence interval [CI], 0.89-1.16; P = .83), on the rates of MI (5.0% vs 5.4%; OR, 0.92; 95% CI, 0.81-1.04; P = .19), or on the combined end point of MI and unstable angina (9.2% vs 9.6%; OR, 0.91; 95% CI, 0.76-1.07; P = .25).Evidence available to date does not demonstrate an overall benefit of antibiotic therapy in reducing mortality or cardiovascular events in patients with CAD.","Effects of antibiotic therapy on outcomes of patients with coronary artery disease: a meta-analysis of randomized controlled trials."
"526","JAMA.275","0.001",15956636,2005,"Patients with unstable angina or non-ST-segment elevation myocardial infarction (NSTEMI) can be cared for with a routine invasive strategy involving coronary angiography and revascularization or more conservatively with a selective invasive strategy in which only those with recurrent or inducible ischemia are referred for acute intervention.To conduct a meta-analysis that compares benefits and risks of routine invasive vs selective invasive strategies.Randomized controlled trials identified through search of MEDLINE and the Cochrane databases (1970 through June 2004) and hand searching of cross-references from original articles and reviews.Trials were included that involved patients with unstable angina or NSTEMI who received a routine invasive or a selective invasive strategy.Major outcomes of death and myocardial infarction (MI) occurring from initial hospitalization to the end of follow-up were extracted from published results of eligible trials.A total of 7 trials (N = 9212 patients) were eligible. Overall, death or MI was reduced from 663 (14.4%) of 4604 patients in the selective invasive group to 561 (12.2%) of 4608 patients in the routine invasive group (odds ratio [OR], 0.82; 95% confidence interval [CI], 0.72-0.93; P = .001). There was a nonsignificant trend toward fewer deaths (6.0% vs 5.5%; OR, 0.92; 95% CI, 0.77-1.09; P = .33) and a significant reduction in MI alone (9.4% vs 7.3%; OR, 0.75; 95% CI, 0.65-0.88; P<.001). Higher-risk patients with elevated cardiac biomarker levels at baseline benefited more from routine intervention, with no significant benefit observed in lower-risk patients with negative baseline marker levels. During the initial hospitalization, a routine invasive strategy was associated with a significantly higher early mortality (1.1% vs 1.8% for selective vs routine, respectively; OR, 1.60; 95% CI, 1.14-2.25; P = .007) and the composite of death or MI (3.8% vs 5.2%; OR, 1.36; 95% CI, 1.12-1.66; P = .002). But after discharge, the routine invasive strategy was associated with fewer subsequent deaths (4.9% vs 3.8%; OR, 0.76; 95% CI, 0.62-0.94; P = .01) and the composite of death or MI (11.0% vs 7.4%; OR, 0.64; 95% CI, 0.56-0.75; P<.001). At the end of follow-up, there was a 33% reduction in severe angina (14.0% vs 11.2%; OR, 0.77; 95% CI, 0.68-0.87; P<.001) and a 34% reduction in rehospitalization (41.3% vs 32.5%; OR, 0.66; 95% CI, 0.60-0.72; P<.001) with a routine invasive strategy.A routine invasive strategy exceeded a selective invasive strategy in reducing MI, severe angina, and rehospitalization over a mean follow-up of 17 months. But routine intervention was associated with a higher early mortality hazard and a trend toward a mortality reduction at follow-up. Future strategies should explore ways to minimize the early hazard and enhance later benefits by focusing on higher-risk patients and optimizing timing of intervention and use of proven therapies.","Routine vs selective invasive strategies in patients with acute coronary syndromes: a collaborative meta-analysis of randomized trials."
"527","JAMA.276","0.001",15956636,2005,"Patients with unstable angina or non-ST-segment elevation myocardial infarction (NSTEMI) can be cared for with a routine invasive strategy involving coronary angiography and revascularization or more conservatively with a selective invasive strategy in which only those with recurrent or inducible ischemia are referred for acute intervention.To conduct a meta-analysis that compares benefits and risks of routine invasive vs selective invasive strategies.Randomized controlled trials identified through search of MEDLINE and the Cochrane databases (1970 through June 2004) and hand searching of cross-references from original articles and reviews.Trials were included that involved patients with unstable angina or NSTEMI who received a routine invasive or a selective invasive strategy.Major outcomes of death and myocardial infarction (MI) occurring from initial hospitalization to the end of follow-up were extracted from published results of eligible trials.A total of 7 trials (N = 9212 patients) were eligible. Overall, death or MI was reduced from 663 (14.4%) of 4604 patients in the selective invasive group to 561 (12.2%) of 4608 patients in the routine invasive group (odds ratio [OR], 0.82; 95% confidence interval [CI], 0.72-0.93; P = .001). There was a nonsignificant trend toward fewer deaths (6.0% vs 5.5%; OR, 0.92; 95% CI, 0.77-1.09; P = .33) and a significant reduction in MI alone (9.4% vs 7.3%; OR, 0.75; 95% CI, 0.65-0.88; P<.001). Higher-risk patients with elevated cardiac biomarker levels at baseline benefited more from routine intervention, with no significant benefit observed in lower-risk patients with negative baseline marker levels. During the initial hospitalization, a routine invasive strategy was associated with a significantly higher early mortality (1.1% vs 1.8% for selective vs routine, respectively; OR, 1.60; 95% CI, 1.14-2.25; P = .007) and the composite of death or MI (3.8% vs 5.2%; OR, 1.36; 95% CI, 1.12-1.66; P = .002). But after discharge, the routine invasive strategy was associated with fewer subsequent deaths (4.9% vs 3.8%; OR, 0.76; 95% CI, 0.62-0.94; P = .01) and the composite of death or MI (11.0% vs 7.4%; OR, 0.64; 95% CI, 0.56-0.75; P<.001). At the end of follow-up, there was a 33% reduction in severe angina (14.0% vs 11.2%; OR, 0.77; 95% CI, 0.68-0.87; P<.001) and a 34% reduction in rehospitalization (41.3% vs 32.5%; OR, 0.66; 95% CI, 0.60-0.72; P<.001) with a routine invasive strategy.A routine invasive strategy exceeded a selective invasive strategy in reducing MI, severe angina, and rehospitalization over a mean follow-up of 17 months. But routine intervention was associated with a higher early mortality hazard and a trend toward a mortality reduction at follow-up. Future strategies should explore ways to minimize the early hazard and enhance later benefits by focusing on higher-risk patients and optimizing timing of intervention and use of proven therapies.","Routine vs selective invasive strategies in patients with acute coronary syndromes: a collaborative meta-analysis of randomized trials."
"528","JAMA.277","0.001",15956636,2005,"Patients with unstable angina or non-ST-segment elevation myocardial infarction (NSTEMI) can be cared for with a routine invasive strategy involving coronary angiography and revascularization or more conservatively with a selective invasive strategy in which only those with recurrent or inducible ischemia are referred for acute intervention.To conduct a meta-analysis that compares benefits and risks of routine invasive vs selective invasive strategies.Randomized controlled trials identified through search of MEDLINE and the Cochrane databases (1970 through June 2004) and hand searching of cross-references from original articles and reviews.Trials were included that involved patients with unstable angina or NSTEMI who received a routine invasive or a selective invasive strategy.Major outcomes of death and myocardial infarction (MI) occurring from initial hospitalization to the end of follow-up were extracted from published results of eligible trials.A total of 7 trials (N = 9212 patients) were eligible. Overall, death or MI was reduced from 663 (14.4%) of 4604 patients in the selective invasive group to 561 (12.2%) of 4608 patients in the routine invasive group (odds ratio [OR], 0.82; 95% confidence interval [CI], 0.72-0.93; P = .001). There was a nonsignificant trend toward fewer deaths (6.0% vs 5.5%; OR, 0.92; 95% CI, 0.77-1.09; P = .33) and a significant reduction in MI alone (9.4% vs 7.3%; OR, 0.75; 95% CI, 0.65-0.88; P<.001). Higher-risk patients with elevated cardiac biomarker levels at baseline benefited more from routine intervention, with no significant benefit observed in lower-risk patients with negative baseline marker levels. During the initial hospitalization, a routine invasive strategy was associated with a significantly higher early mortality (1.1% vs 1.8% for selective vs routine, respectively; OR, 1.60; 95% CI, 1.14-2.25; P = .007) and the composite of death or MI (3.8% vs 5.2%; OR, 1.36; 95% CI, 1.12-1.66; P = .002). But after discharge, the routine invasive strategy was associated with fewer subsequent deaths (4.9% vs 3.8%; OR, 0.76; 95% CI, 0.62-0.94; P = .01) and the composite of death or MI (11.0% vs 7.4%; OR, 0.64; 95% CI, 0.56-0.75; P<.001). At the end of follow-up, there was a 33% reduction in severe angina (14.0% vs 11.2%; OR, 0.77; 95% CI, 0.68-0.87; P<.001) and a 34% reduction in rehospitalization (41.3% vs 32.5%; OR, 0.66; 95% CI, 0.60-0.72; P<.001) with a routine invasive strategy.A routine invasive strategy exceeded a selective invasive strategy in reducing MI, severe angina, and rehospitalization over a mean follow-up of 17 months. But routine intervention was associated with a higher early mortality hazard and a trend toward a mortality reduction at follow-up. Future strategies should explore ways to minimize the early hazard and enhance later benefits by focusing on higher-risk patients and optimizing timing of intervention and use of proven therapies.","Routine vs selective invasive strategies in patients with acute coronary syndromes: a collaborative meta-analysis of randomized trials."
"529","JAMA.278","0.001",15956636,2005,"Patients with unstable angina or non-ST-segment elevation myocardial infarction (NSTEMI) can be cared for with a routine invasive strategy involving coronary angiography and revascularization or more conservatively with a selective invasive strategy in which only those with recurrent or inducible ischemia are referred for acute intervention.To conduct a meta-analysis that compares benefits and risks of routine invasive vs selective invasive strategies.Randomized controlled trials identified through search of MEDLINE and the Cochrane databases (1970 through June 2004) and hand searching of cross-references from original articles and reviews.Trials were included that involved patients with unstable angina or NSTEMI who received a routine invasive or a selective invasive strategy.Major outcomes of death and myocardial infarction (MI) occurring from initial hospitalization to the end of follow-up were extracted from published results of eligible trials.A total of 7 trials (N = 9212 patients) were eligible. Overall, death or MI was reduced from 663 (14.4%) of 4604 patients in the selective invasive group to 561 (12.2%) of 4608 patients in the routine invasive group (odds ratio [OR], 0.82; 95% confidence interval [CI], 0.72-0.93; P = .001). There was a nonsignificant trend toward fewer deaths (6.0% vs 5.5%; OR, 0.92; 95% CI, 0.77-1.09; P = .33) and a significant reduction in MI alone (9.4% vs 7.3%; OR, 0.75; 95% CI, 0.65-0.88; P<.001). Higher-risk patients with elevated cardiac biomarker levels at baseline benefited more from routine intervention, with no significant benefit observed in lower-risk patients with negative baseline marker levels. During the initial hospitalization, a routine invasive strategy was associated with a significantly higher early mortality (1.1% vs 1.8% for selective vs routine, respectively; OR, 1.60; 95% CI, 1.14-2.25; P = .007) and the composite of death or MI (3.8% vs 5.2%; OR, 1.36; 95% CI, 1.12-1.66; P = .002). But after discharge, the routine invasive strategy was associated with fewer subsequent deaths (4.9% vs 3.8%; OR, 0.76; 95% CI, 0.62-0.94; P = .01) and the composite of death or MI (11.0% vs 7.4%; OR, 0.64; 95% CI, 0.56-0.75; P<.001). At the end of follow-up, there was a 33% reduction in severe angina (14.0% vs 11.2%; OR, 0.77; 95% CI, 0.68-0.87; P<.001) and a 34% reduction in rehospitalization (41.3% vs 32.5%; OR, 0.66; 95% CI, 0.60-0.72; P<.001) with a routine invasive strategy.A routine invasive strategy exceeded a selective invasive strategy in reducing MI, severe angina, and rehospitalization over a mean follow-up of 17 months. But routine intervention was associated with a higher early mortality hazard and a trend toward a mortality reduction at follow-up. Future strategies should explore ways to minimize the early hazard and enhance later benefits by focusing on higher-risk patients and optimizing timing of intervention and use of proven therapies.","Routine vs selective invasive strategies in patients with acute coronary syndromes: a collaborative meta-analysis of randomized trials."
"530","JAMA.312","0.001",15956636,2005,"Patients with unstable angina or non-ST-segment elevation myocardial infarction (NSTEMI) can be cared for with a routine invasive strategy involving coronary angiography and revascularization or more conservatively with a selective invasive strategy in which only those with recurrent or inducible ischemia are referred for acute intervention.To conduct a meta-analysis that compares benefits and risks of routine invasive vs selective invasive strategies.Randomized controlled trials identified through search of MEDLINE and the Cochrane databases (1970 through June 2004) and hand searching of cross-references from original articles and reviews.Trials were included that involved patients with unstable angina or NSTEMI who received a routine invasive or a selective invasive strategy.Major outcomes of death and myocardial infarction (MI) occurring from initial hospitalization to the end of follow-up were extracted from published results of eligible trials.A total of 7 trials (N = 9212 patients) were eligible. Overall, death or MI was reduced from 663 (14.4%) of 4604 patients in the selective invasive group to 561 (12.2%) of 4608 patients in the routine invasive group (odds ratio [OR], 0.82; 95% confidence interval [CI], 0.72-0.93; P = .001). There was a nonsignificant trend toward fewer deaths (6.0% vs 5.5%; OR, 0.92; 95% CI, 0.77-1.09; P = .33) and a significant reduction in MI alone (9.4% vs 7.3%; OR, 0.75; 95% CI, 0.65-0.88; P<.001). Higher-risk patients with elevated cardiac biomarker levels at baseline benefited more from routine intervention, with no significant benefit observed in lower-risk patients with negative baseline marker levels. During the initial hospitalization, a routine invasive strategy was associated with a significantly higher early mortality (1.1% vs 1.8% for selective vs routine, respectively; OR, 1.60; 95% CI, 1.14-2.25; P = .007) and the composite of death or MI (3.8% vs 5.2%; OR, 1.36; 95% CI, 1.12-1.66; P = .002). But after discharge, the routine invasive strategy was associated with fewer subsequent deaths (4.9% vs 3.8%; OR, 0.76; 95% CI, 0.62-0.94; P = .01) and the composite of death or MI (11.0% vs 7.4%; OR, 0.64; 95% CI, 0.56-0.75; P<.001). At the end of follow-up, there was a 33% reduction in severe angina (14.0% vs 11.2%; OR, 0.77; 95% CI, 0.68-0.87; P<.001) and a 34% reduction in rehospitalization (41.3% vs 32.5%; OR, 0.66; 95% CI, 0.60-0.72; P<.001) with a routine invasive strategy.A routine invasive strategy exceeded a selective invasive strategy in reducing MI, severe angina, and rehospitalization over a mean follow-up of 17 months. But routine intervention was associated with a higher early mortality hazard and a trend toward a mortality reduction at follow-up. Future strategies should explore ways to minimize the early hazard and enhance later benefits by focusing on higher-risk patients and optimizing timing of intervention and use of proven therapies.","Routine vs selective invasive strategies in patients with acute coronary syndromes: a collaborative meta-analysis of randomized trials."
"531","JAMA.313","0.33",15956636,2005,"Patients with unstable angina or non-ST-segment elevation myocardial infarction (NSTEMI) can be cared for with a routine invasive strategy involving coronary angiography and revascularization or more conservatively with a selective invasive strategy in which only those with recurrent or inducible ischemia are referred for acute intervention.To conduct a meta-analysis that compares benefits and risks of routine invasive vs selective invasive strategies.Randomized controlled trials identified through search of MEDLINE and the Cochrane databases (1970 through June 2004) and hand searching of cross-references from original articles and reviews.Trials were included that involved patients with unstable angina or NSTEMI who received a routine invasive or a selective invasive strategy.Major outcomes of death and myocardial infarction (MI) occurring from initial hospitalization to the end of follow-up were extracted from published results of eligible trials.A total of 7 trials (N = 9212 patients) were eligible. Overall, death or MI was reduced from 663 (14.4%) of 4604 patients in the selective invasive group to 561 (12.2%) of 4608 patients in the routine invasive group (odds ratio [OR], 0.82; 95% confidence interval [CI], 0.72-0.93; P = .001). There was a nonsignificant trend toward fewer deaths (6.0% vs 5.5%; OR, 0.92; 95% CI, 0.77-1.09; P = .33) and a significant reduction in MI alone (9.4% vs 7.3%; OR, 0.75; 95% CI, 0.65-0.88; P<.001). Higher-risk patients with elevated cardiac biomarker levels at baseline benefited more from routine intervention, with no significant benefit observed in lower-risk patients with negative baseline marker levels. During the initial hospitalization, a routine invasive strategy was associated with a significantly higher early mortality (1.1% vs 1.8% for selective vs routine, respectively; OR, 1.60; 95% CI, 1.14-2.25; P = .007) and the composite of death or MI (3.8% vs 5.2%; OR, 1.36; 95% CI, 1.12-1.66; P = .002). But after discharge, the routine invasive strategy was associated with fewer subsequent deaths (4.9% vs 3.8%; OR, 0.76; 95% CI, 0.62-0.94; P = .01) and the composite of death or MI (11.0% vs 7.4%; OR, 0.64; 95% CI, 0.56-0.75; P<.001). At the end of follow-up, there was a 33% reduction in severe angina (14.0% vs 11.2%; OR, 0.77; 95% CI, 0.68-0.87; P<.001) and a 34% reduction in rehospitalization (41.3% vs 32.5%; OR, 0.66; 95% CI, 0.60-0.72; P<.001) with a routine invasive strategy.A routine invasive strategy exceeded a selective invasive strategy in reducing MI, severe angina, and rehospitalization over a mean follow-up of 17 months. But routine intervention was associated with a higher early mortality hazard and a trend toward a mortality reduction at follow-up. Future strategies should explore ways to minimize the early hazard and enhance later benefits by focusing on higher-risk patients and optimizing timing of intervention and use of proven therapies.","Routine vs selective invasive strategies in patients with acute coronary syndromes: a collaborative meta-analysis of randomized trials."
"532","JAMA.314","0.007",15956636,2005,"Patients with unstable angina or non-ST-segment elevation myocardial infarction (NSTEMI) can be cared for with a routine invasive strategy involving coronary angiography and revascularization or more conservatively with a selective invasive strategy in which only those with recurrent or inducible ischemia are referred for acute intervention.To conduct a meta-analysis that compares benefits and risks of routine invasive vs selective invasive strategies.Randomized controlled trials identified through search of MEDLINE and the Cochrane databases (1970 through June 2004) and hand searching of cross-references from original articles and reviews.Trials were included that involved patients with unstable angina or NSTEMI who received a routine invasive or a selective invasive strategy.Major outcomes of death and myocardial infarction (MI) occurring from initial hospitalization to the end of follow-up were extracted from published results of eligible trials.A total of 7 trials (N = 9212 patients) were eligible. Overall, death or MI was reduced from 663 (14.4%) of 4604 patients in the selective invasive group to 561 (12.2%) of 4608 patients in the routine invasive group (odds ratio [OR], 0.82; 95% confidence interval [CI], 0.72-0.93; P = .001). There was a nonsignificant trend toward fewer deaths (6.0% vs 5.5%; OR, 0.92; 95% CI, 0.77-1.09; P = .33) and a significant reduction in MI alone (9.4% vs 7.3%; OR, 0.75; 95% CI, 0.65-0.88; P<.001). Higher-risk patients with elevated cardiac biomarker levels at baseline benefited more from routine intervention, with no significant benefit observed in lower-risk patients with negative baseline marker levels. During the initial hospitalization, a routine invasive strategy was associated with a significantly higher early mortality (1.1% vs 1.8% for selective vs routine, respectively; OR, 1.60; 95% CI, 1.14-2.25; P = .007) and the composite of death or MI (3.8% vs 5.2%; OR, 1.36; 95% CI, 1.12-1.66; P = .002). But after discharge, the routine invasive strategy was associated with fewer subsequent deaths (4.9% vs 3.8%; OR, 0.76; 95% CI, 0.62-0.94; P = .01) and the composite of death or MI (11.0% vs 7.4%; OR, 0.64; 95% CI, 0.56-0.75; P<.001). At the end of follow-up, there was a 33% reduction in severe angina (14.0% vs 11.2%; OR, 0.77; 95% CI, 0.68-0.87; P<.001) and a 34% reduction in rehospitalization (41.3% vs 32.5%; OR, 0.66; 95% CI, 0.60-0.72; P<.001) with a routine invasive strategy.A routine invasive strategy exceeded a selective invasive strategy in reducing MI, severe angina, and rehospitalization over a mean follow-up of 17 months. But routine intervention was associated with a higher early mortality hazard and a trend toward a mortality reduction at follow-up. Future strategies should explore ways to minimize the early hazard and enhance later benefits by focusing on higher-risk patients and optimizing timing of intervention and use of proven therapies.","Routine vs selective invasive strategies in patients with acute coronary syndromes: a collaborative meta-analysis of randomized trials."
"533","JAMA.315","0.002",15956636,2005,"Patients with unstable angina or non-ST-segment elevation myocardial infarction (NSTEMI) can be cared for with a routine invasive strategy involving coronary angiography and revascularization or more conservatively with a selective invasive strategy in which only those with recurrent or inducible ischemia are referred for acute intervention.To conduct a meta-analysis that compares benefits and risks of routine invasive vs selective invasive strategies.Randomized controlled trials identified through search of MEDLINE and the Cochrane databases (1970 through June 2004) and hand searching of cross-references from original articles and reviews.Trials were included that involved patients with unstable angina or NSTEMI who received a routine invasive or a selective invasive strategy.Major outcomes of death and myocardial infarction (MI) occurring from initial hospitalization to the end of follow-up were extracted from published results of eligible trials.A total of 7 trials (N = 9212 patients) were eligible. Overall, death or MI was reduced from 663 (14.4%) of 4604 patients in the selective invasive group to 561 (12.2%) of 4608 patients in the routine invasive group (odds ratio [OR], 0.82; 95% confidence interval [CI], 0.72-0.93; P = .001). There was a nonsignificant trend toward fewer deaths (6.0% vs 5.5%; OR, 0.92; 95% CI, 0.77-1.09; P = .33) and a significant reduction in MI alone (9.4% vs 7.3%; OR, 0.75; 95% CI, 0.65-0.88; P<.001). Higher-risk patients with elevated cardiac biomarker levels at baseline benefited more from routine intervention, with no significant benefit observed in lower-risk patients with negative baseline marker levels. During the initial hospitalization, a routine invasive strategy was associated with a significantly higher early mortality (1.1% vs 1.8% for selective vs routine, respectively; OR, 1.60; 95% CI, 1.14-2.25; P = .007) and the composite of death or MI (3.8% vs 5.2%; OR, 1.36; 95% CI, 1.12-1.66; P = .002). But after discharge, the routine invasive strategy was associated with fewer subsequent deaths (4.9% vs 3.8%; OR, 0.76; 95% CI, 0.62-0.94; P = .01) and the composite of death or MI (11.0% vs 7.4%; OR, 0.64; 95% CI, 0.56-0.75; P<.001). At the end of follow-up, there was a 33% reduction in severe angina (14.0% vs 11.2%; OR, 0.77; 95% CI, 0.68-0.87; P<.001) and a 34% reduction in rehospitalization (41.3% vs 32.5%; OR, 0.66; 95% CI, 0.60-0.72; P<.001) with a routine invasive strategy.A routine invasive strategy exceeded a selective invasive strategy in reducing MI, severe angina, and rehospitalization over a mean follow-up of 17 months. But routine intervention was associated with a higher early mortality hazard and a trend toward a mortality reduction at follow-up. Future strategies should explore ways to minimize the early hazard and enhance later benefits by focusing on higher-risk patients and optimizing timing of intervention and use of proven therapies.","Routine vs selective invasive strategies in patients with acute coronary syndromes: a collaborative meta-analysis of randomized trials."
"534","JAMA.316","0.01",15956636,2005,"Patients with unstable angina or non-ST-segment elevation myocardial infarction (NSTEMI) can be cared for with a routine invasive strategy involving coronary angiography and revascularization or more conservatively with a selective invasive strategy in which only those with recurrent or inducible ischemia are referred for acute intervention.To conduct a meta-analysis that compares benefits and risks of routine invasive vs selective invasive strategies.Randomized controlled trials identified through search of MEDLINE and the Cochrane databases (1970 through June 2004) and hand searching of cross-references from original articles and reviews.Trials were included that involved patients with unstable angina or NSTEMI who received a routine invasive or a selective invasive strategy.Major outcomes of death and myocardial infarction (MI) occurring from initial hospitalization to the end of follow-up were extracted from published results of eligible trials.A total of 7 trials (N = 9212 patients) were eligible. Overall, death or MI was reduced from 663 (14.4%) of 4604 patients in the selective invasive group to 561 (12.2%) of 4608 patients in the routine invasive group (odds ratio [OR], 0.82; 95% confidence interval [CI], 0.72-0.93; P = .001). There was a nonsignificant trend toward fewer deaths (6.0% vs 5.5%; OR, 0.92; 95% CI, 0.77-1.09; P = .33) and a significant reduction in MI alone (9.4% vs 7.3%; OR, 0.75; 95% CI, 0.65-0.88; P<.001). Higher-risk patients with elevated cardiac biomarker levels at baseline benefited more from routine intervention, with no significant benefit observed in lower-risk patients with negative baseline marker levels. During the initial hospitalization, a routine invasive strategy was associated with a significantly higher early mortality (1.1% vs 1.8% for selective vs routine, respectively; OR, 1.60; 95% CI, 1.14-2.25; P = .007) and the composite of death or MI (3.8% vs 5.2%; OR, 1.36; 95% CI, 1.12-1.66; P = .002). But after discharge, the routine invasive strategy was associated with fewer subsequent deaths (4.9% vs 3.8%; OR, 0.76; 95% CI, 0.62-0.94; P = .01) and the composite of death or MI (11.0% vs 7.4%; OR, 0.64; 95% CI, 0.56-0.75; P<.001). At the end of follow-up, there was a 33% reduction in severe angina (14.0% vs 11.2%; OR, 0.77; 95% CI, 0.68-0.87; P<.001) and a 34% reduction in rehospitalization (41.3% vs 32.5%; OR, 0.66; 95% CI, 0.60-0.72; P<.001) with a routine invasive strategy.A routine invasive strategy exceeded a selective invasive strategy in reducing MI, severe angina, and rehospitalization over a mean follow-up of 17 months. But routine intervention was associated with a higher early mortality hazard and a trend toward a mortality reduction at follow-up. Future strategies should explore ways to minimize the early hazard and enhance later benefits by focusing on higher-risk patients and optimizing timing of intervention and use of proven therapies.","Routine vs selective invasive strategies in patients with acute coronary syndromes: a collaborative meta-analysis of randomized trials."
"535","Lancet.341","1.00E-04",15978925,2005,"Although endovascular aneurysm repair (EVAR) has a lower 30-day operative mortality than open repair, the long-term results of EVAR are uncertain. We instigated EVAR trial 1 to compare these two treatments in terms of mortality, durability, health-related quality of life (HRQL), and costs for patients with large abdominal aortic aneurysm (AAA).We did a randomised controlled trial of 1082 patients aged 60 years or older who had aneurysms of at least 5.5 cm in diameter and who had been referred to one of 34 hospitals proficient in the EVAR technique. We assigned patients who were anatomically suitable for EVAR and fit for an open repair to EVAR (n=543) or open repair (n=539). Our primary endpoint was all-cause mortality, with secondary endpoints of aneurysm related mortality, HRQL, postoperative complications, and hospital costs. Analyses were by intention to treat.94% (1017 of 1082) of patients complied with their allocated treatment and 209 died by the end of follow-up on Dec 31, 2004 (53 of aneurysm-related causes). 4 years after randomisation, all-cause mortality was similar in the two groups (about 28%; hazard ratio 0.90, 95% CI 0.69-1.18, p=0.46), although there was a persistent reduction in aneurysm-related deaths in the EVAR group (4%vs 7%; 0.55, 0.31-0.96, p=0.04). The proportion of patients with postoperative complications within 4 years of randomisation was 41% in the EVAR group and 9% in the open repair group (4.9, 3.5-6.8, p<0.0001). After 12 months there was negligible difference in HRQL between the two groups. The mean hospital costs per patient up to 4 years were UK pound sterling 13,257 for the EVAR group versus pound sterling 9946 for the open repair group (mean difference pound sterling 3311, SE 690).Compared with open repair, EVAR offers no advantage with respect to all-cause mortality and HRQL, is more expensive, and leads to a greater number of complications and reinterventions. However, it does result in a 3% better aneurysm-related survival. The continuing need for interventions mandates ongoing surveillance and longer follow-up of EVAR for detailed cost-effectiveness assessment.","Endovascular aneurysm repair versus open repair in patients with abdominal aortic aneurysm (EVAR trial 1): randomised controlled trial."
"536","Lancet.531","0.46",15978925,2005,"Although endovascular aneurysm repair (EVAR) has a lower 30-day operative mortality than open repair, the long-term results of EVAR are uncertain. We instigated EVAR trial 1 to compare these two treatments in terms of mortality, durability, health-related quality of life (HRQL), and costs for patients with large abdominal aortic aneurysm (AAA).We did a randomised controlled trial of 1082 patients aged 60 years or older who had aneurysms of at least 5.5 cm in diameter and who had been referred to one of 34 hospitals proficient in the EVAR technique. We assigned patients who were anatomically suitable for EVAR and fit for an open repair to EVAR (n=543) or open repair (n=539). Our primary endpoint was all-cause mortality, with secondary endpoints of aneurysm related mortality, HRQL, postoperative complications, and hospital costs. Analyses were by intention to treat.94% (1017 of 1082) of patients complied with their allocated treatment and 209 died by the end of follow-up on Dec 31, 2004 (53 of aneurysm-related causes). 4 years after randomisation, all-cause mortality was similar in the two groups (about 28%; hazard ratio 0.90, 95% CI 0.69-1.18, p=0.46), although there was a persistent reduction in aneurysm-related deaths in the EVAR group (4%vs 7%; 0.55, 0.31-0.96, p=0.04). The proportion of patients with postoperative complications within 4 years of randomisation was 41% in the EVAR group and 9% in the open repair group (4.9, 3.5-6.8, p<0.0001). After 12 months there was negligible difference in HRQL between the two groups. The mean hospital costs per patient up to 4 years were UK pound sterling 13,257 for the EVAR group versus pound sterling 9946 for the open repair group (mean difference pound sterling 3311, SE 690).Compared with open repair, EVAR offers no advantage with respect to all-cause mortality and HRQL, is more expensive, and leads to a greater number of complications and reinterventions. However, it does result in a 3% better aneurysm-related survival. The continuing need for interventions mandates ongoing surveillance and longer follow-up of EVAR for detailed cost-effectiveness assessment.","Endovascular aneurysm repair versus open repair in patients with abdominal aortic aneurysm (EVAR trial 1): randomised controlled trial."
"537","Lancet.541","0.04",15978925,2005,"Although endovascular aneurysm repair (EVAR) has a lower 30-day operative mortality than open repair, the long-term results of EVAR are uncertain. We instigated EVAR trial 1 to compare these two treatments in terms of mortality, durability, health-related quality of life (HRQL), and costs for patients with large abdominal aortic aneurysm (AAA).We did a randomised controlled trial of 1082 patients aged 60 years or older who had aneurysms of at least 5.5 cm in diameter and who had been referred to one of 34 hospitals proficient in the EVAR technique. We assigned patients who were anatomically suitable for EVAR and fit for an open repair to EVAR (n=543) or open repair (n=539). Our primary endpoint was all-cause mortality, with secondary endpoints of aneurysm related mortality, HRQL, postoperative complications, and hospital costs. Analyses were by intention to treat.94% (1017 of 1082) of patients complied with their allocated treatment and 209 died by the end of follow-up on Dec 31, 2004 (53 of aneurysm-related causes). 4 years after randomisation, all-cause mortality was similar in the two groups (about 28%; hazard ratio 0.90, 95% CI 0.69-1.18, p=0.46), although there was a persistent reduction in aneurysm-related deaths in the EVAR group (4%vs 7%; 0.55, 0.31-0.96, p=0.04). The proportion of patients with postoperative complications within 4 years of randomisation was 41% in the EVAR group and 9% in the open repair group (4.9, 3.5-6.8, p<0.0001). After 12 months there was negligible difference in HRQL between the two groups. The mean hospital costs per patient up to 4 years were UK pound sterling 13,257 for the EVAR group versus pound sterling 9946 for the open repair group (mean difference pound sterling 3311, SE 690).Compared with open repair, EVAR offers no advantage with respect to all-cause mortality and HRQL, is more expensive, and leads to a greater number of complications and reinterventions. However, it does result in a 3% better aneurysm-related survival. The continuing need for interventions mandates ongoing surveillance and longer follow-up of EVAR for detailed cost-effectiveness assessment.","Endovascular aneurysm repair versus open repair in patients with abdominal aortic aneurysm (EVAR trial 1): randomised controlled trial."
"538","Lancet.521","0.25",15978926,2005,"Endovascular aneurysm repair (EVAR) to exclude abdominal aortic aneurysm (AAA) was introduced for patients of poor health status considered unfit for major surgery. We instigated EVAR trial 2 to identify whether EVAR improves survival compared with no intervention in patients unfit for open repair of aortic aneurysm.We did a randomised controlled trial of 338 patients aged 60 years or older who had aneurysms of at least 5.5 cm in diameter and who had been referred to one of 31 hospitals in the UK. We assigned patients to receive either EVAR (n=166) or no intervention (n=172). Our primary endpoint was all-cause mortality, with secondary endpoints of aneurysm-related mortality, health-related quality of life (HRQL), postoperative complications, and hospital costs. Analyses were by intention to treat.197 patients underwent aneurysm repair (47 assigned no intervention) and 80% of patients adhered to protocol. The 30-day operative mortality in the EVAR group was 9% (13 of 150, 95% CI 5-15) and the no intervention group had a rupture rate of 9.0 per 100 person years (95% CI 6.0-13.5). By end of follow up 142 patients had died, 42 of aneurysm-related factors; overall mortality after 4 years was 64%. There was no significant difference between the EVAR group and the no intervention group for all-cause mortality (hazard ratio 1.21, 95% CI 0.87-1.69, p=0.25). There was no difference in aneurysm-related mortality. The mean hospital costs per patient over 4 years were UK pound sterling 13,632 in the EVAR group and pound sterling 4983 in the no intervention group (mean difference pound sterling 8649, SE 1248), with no difference in HRQL scores.EVAR had a considerable 30-day operative mortality in patients already unfit for open repair of their aneurysm. EVAR did not improve survival over no intervention and was associated with a need for continued surveillance and reinterventions, at substantially increased cost. Ongoing follow-up and improved fitness of these patients is a priority.","Endovascular aneurysm repair and outcome in patients unfit for open repair of abdominal aortic aneurysm (EVAR trial 2): randomised controlled trial."
"539","JAMA.2871","0.002",15998893,2005,"Hyperthyroidism has been reported to cause excess all-cause and circulatory mortality. Whether this can be reversed is unknown, as is the influence of mild persisting thyroid dysfunction and treatment-induced hypothyroidism.To determine whether radioiodine treatment is associated with increased mortality and to determine the influences of mild thyroid dysfunction and the development of overt hypothyroidism treated with thyroxine (T(4)).A population-based study of 2668 individuals aged 40 years or older treated for overt hyperthyroidism with radioiodine in the West Midlands region of England from 1984-2002.Cause of death compared with age- and period-specific mortality in England and Wales and assessment of the influence of T(4) therapy for radioiodine-induced hypothyroidism and subclinical thyroid dysfunction on mortality.In 15,968 person-years of follow-up, 554 died vs 487 expected deaths (standardized mortality ratio [SMR], 1.14; 95% confidence interval [CI], 1.04-1.24, P=.002). Increased risks of all-cause and circulatory deaths vs age- and period-specific mortality were observed in follow-up in those not requiring, or prior to, T(4) therapy. These increased risks were not observed during follow-up on T(4) therapy (circulatory disease SMR prior to T(4), 1.33; 95% CI, 1.14-1.53 vs SMR, 0.91; 95% CI, 0.70-1.17 during T(4)). Patients receiving T(4) had decreased risk of mortality vs risk in the period not requiring, or prior to, T(4) therapy (all-cause mortality hazard ratio [HR], 0.65; 95% CI, 0.54-0.79; circulatory mortality HR, 0.65; 95% CI, 0.48-0.87). Increased all-cause mortality vs the background population was observed in the period prior to T(4) therapy in follow-up associated with low, normal, and high serum thyrotropin. The SMR for ischemic heart disease increased slightly when analyzed by serum thyrotropin, high serum thyrotropin being the highest SMR (low thyrotropin SMR, 1.06; 95% CI, 0.75-1.45; normal thyrotropin SMR, 1.17; 95% CI, 0.76-1.71; high thyrotropin SMR, 1.48; 95% CI, 0.86-2.37). Comparison within the cohort showed that mild hypothyroidism prior to T(4) therapy was associated with increased risk of mortality from ischemic heart disease vs biochemical euthyroidism (HR, 2.08; 95% CI, 1.04-4.19).Patients treated with radioiodine for hyperthyroidism had increased mortality vs age- and period-specific mortality in England and Wales, a finding no longer evident during T(4) therapy. This supports treating hyperthyroidism with doses of radioiodine sufficient to induce overt hypothyroidism. The association within the cohort of mortality from ischemic heart disease with subclinical hypothyroidism suggests T(4) replacement should be considered should this biochemical abnormality develop after radioiodine therapy.","Thyroid function and mortality in patients treated for hyperthyroidism."
"540","JAMA.273","0.001",15998895,2005,"It has been proposed that low sexual desire and sexual dysfunction are associated with low blood testosterone levels in women. However, evidence to support this is lacking.To determine whether women with low self-reported sexual desire and sexual satisfaction are more likely to have low serum androgen levels than women without self-reported low sexual desire and sexual satisfaction.A community-based, cross-sectional study of 1423 women aged 18 to 75 years, who were randomly recruited via the electoral roll in Victoria, Australia, from April 2002 to August 2003. Women were excluded from the analysis if they took psychiatric medication, had abnormal thyroid function, documented polycystic ovarian syndrome, or were younger than 45 years and using oral contraception.Domain scores of the Profile of Female Sexual Function (PFSF) and serum levels of total and free testosterone, androstenedione, and dehydroepiandrosterone sulfate.A total of 1021 individuals were included in the final analysis. No clinically significant relationships between having a low score for any PFSF domain and having a low serum total or free testosterone or androstenedione level was demonstrated. A low domain score for sexual responsiveness for women aged 45 years or older was associated with higher odds of having a serum dehydroepiandrosterone sulfate level below the 10th percentile for this age group (odds ratio [OR], 3.90; 95% confidence interval [CI], 1.54-9.81; P = .004). For women aged 18 to 44 years, having a low domain score for sexual desire (OR, 3.86; 95% CI, 1.27-11.67; P = .02), sexual arousal (OR, 6.39; 95% CI, 2.30-17.73; P<.001), and sexual responsiveness (OR, 6.59; 95% CI, 2.37-18.34; P<.001) was associated with having a dehydroepiandrosterone sulfate level below the 10th percentile.No single androgen level is predictive of low female sexual function, and the majority of women with low dehydroepiandrosterone sulfate levels did not have low sexual function.","Circulating androgen levels and self-reported sexual function in women."
"541","JAMA.274","0.001",15998895,2005,"It has been proposed that low sexual desire and sexual dysfunction are associated with low blood testosterone levels in women. However, evidence to support this is lacking.To determine whether women with low self-reported sexual desire and sexual satisfaction are more likely to have low serum androgen levels than women without self-reported low sexual desire and sexual satisfaction.A community-based, cross-sectional study of 1423 women aged 18 to 75 years, who were randomly recruited via the electoral roll in Victoria, Australia, from April 2002 to August 2003. Women were excluded from the analysis if they took psychiatric medication, had abnormal thyroid function, documented polycystic ovarian syndrome, or were younger than 45 years and using oral contraception.Domain scores of the Profile of Female Sexual Function (PFSF) and serum levels of total and free testosterone, androstenedione, and dehydroepiandrosterone sulfate.A total of 1021 individuals were included in the final analysis. No clinically significant relationships between having a low score for any PFSF domain and having a low serum total or free testosterone or androstenedione level was demonstrated. A low domain score for sexual responsiveness for women aged 45 years or older was associated with higher odds of having a serum dehydroepiandrosterone sulfate level below the 10th percentile for this age group (odds ratio [OR], 3.90; 95% confidence interval [CI], 1.54-9.81; P = .004). For women aged 18 to 44 years, having a low domain score for sexual desire (OR, 3.86; 95% CI, 1.27-11.67; P = .02), sexual arousal (OR, 6.39; 95% CI, 2.30-17.73; P<.001), and sexual responsiveness (OR, 6.59; 95% CI, 2.37-18.34; P<.001) was associated with having a dehydroepiandrosterone sulfate level below the 10th percentile.No single androgen level is predictive of low female sexual function, and the majority of women with low dehydroepiandrosterone sulfate levels did not have low sexual function.","Circulating androgen levels and self-reported sexual function in women."
"542","JAMA.310","0.004",15998895,2005,"It has been proposed that low sexual desire and sexual dysfunction are associated with low blood testosterone levels in women. However, evidence to support this is lacking.To determine whether women with low self-reported sexual desire and sexual satisfaction are more likely to have low serum androgen levels than women without self-reported low sexual desire and sexual satisfaction.A community-based, cross-sectional study of 1423 women aged 18 to 75 years, who were randomly recruited via the electoral roll in Victoria, Australia, from April 2002 to August 2003. Women were excluded from the analysis if they took psychiatric medication, had abnormal thyroid function, documented polycystic ovarian syndrome, or were younger than 45 years and using oral contraception.Domain scores of the Profile of Female Sexual Function (PFSF) and serum levels of total and free testosterone, androstenedione, and dehydroepiandrosterone sulfate.A total of 1021 individuals were included in the final analysis. No clinically significant relationships between having a low score for any PFSF domain and having a low serum total or free testosterone or androstenedione level was demonstrated. A low domain score for sexual responsiveness for women aged 45 years or older was associated with higher odds of having a serum dehydroepiandrosterone sulfate level below the 10th percentile for this age group (odds ratio [OR], 3.90; 95% confidence interval [CI], 1.54-9.81; P = .004). For women aged 18 to 44 years, having a low domain score for sexual desire (OR, 3.86; 95% CI, 1.27-11.67; P = .02), sexual arousal (OR, 6.39; 95% CI, 2.30-17.73; P<.001), and sexual responsiveness (OR, 6.59; 95% CI, 2.37-18.34; P<.001) was associated with having a dehydroepiandrosterone sulfate level below the 10th percentile.No single androgen level is predictive of low female sexual function, and the majority of women with low dehydroepiandrosterone sulfate levels did not have low sexual function.","Circulating androgen levels and self-reported sexual function in women."
"543","JAMA.311","0.02",15998895,2005,"It has been proposed that low sexual desire and sexual dysfunction are associated with low blood testosterone levels in women. However, evidence to support this is lacking.To determine whether women with low self-reported sexual desire and sexual satisfaction are more likely to have low serum androgen levels than women without self-reported low sexual desire and sexual satisfaction.A community-based, cross-sectional study of 1423 women aged 18 to 75 years, who were randomly recruited via the electoral roll in Victoria, Australia, from April 2002 to August 2003. Women were excluded from the analysis if they took psychiatric medication, had abnormal thyroid function, documented polycystic ovarian syndrome, or were younger than 45 years and using oral contraception.Domain scores of the Profile of Female Sexual Function (PFSF) and serum levels of total and free testosterone, androstenedione, and dehydroepiandrosterone sulfate.A total of 1021 individuals were included in the final analysis. No clinically significant relationships between having a low score for any PFSF domain and having a low serum total or free testosterone or androstenedione level was demonstrated. A low domain score for sexual responsiveness for women aged 45 years or older was associated with higher odds of having a serum dehydroepiandrosterone sulfate level below the 10th percentile for this age group (odds ratio [OR], 3.90; 95% confidence interval [CI], 1.54-9.81; P = .004). For women aged 18 to 44 years, having a low domain score for sexual desire (OR, 3.86; 95% CI, 1.27-11.67; P = .02), sexual arousal (OR, 6.39; 95% CI, 2.30-17.73; P<.001), and sexual responsiveness (OR, 6.59; 95% CI, 2.37-18.34; P<.001) was associated with having a dehydroepiandrosterone sulfate level below the 10th percentile.No single androgen level is predictive of low female sexual function, and the majority of women with low dehydroepiandrosterone sulfate levels did not have low sexual function.","Circulating androgen levels and self-reported sexual function in women."
"544","JAMA.265","0.001",16030276,2005,"Information on the school-age functioning and special health care needs of extremely low-birth-weight (ELBW, <1000 g) children is necessary to plan for medical and educational services.To examine neurosensory, developmental, and medical conditions together with the associated functional limitations and special health care needs of ELBW children compared with normal-birth-weight (NBW) term-born children (controls).A follow-up study at age 8 years of a cohort of 219 ELBW children born 1992 to 1995 (92% of survivors) and 176 NBW controls of similar sociodemographic status conducted in Cleveland, Ohio.Parent Questionnaire for Identifying Children with Chronic Conditions of 12 months or more and categorization of specific medical diagnoses and developmental disabilities based on examination of the children.In logistic regression analyses adjusting for sociodemographic status and sex, ELBW children had significantly more chronic conditions than NBW controls, including functional limitations (64% vs 20%, respectively; odds ratio [OR], 8.1; 95% confidence interval [CI], 5.0-13.1; P<.001), compensatory dependency needs (48% vs 23%, respectively; OR, 3.0; 95% CI, 1.9-4.7; P<.001), and services above those routinely required by children (65% vs 27%, respectively; OR, 5.4; 95% CI, 3.4-8.5; P<.001). These differences remained significant when the 36 ELBW children with neurosensory impairments were excluded. Specific diagnoses and disabilities for ELBW vs NBW children included cerebral palsy (14% vs 0%, respectively; P<.001), asthma (21% vs 9%; OR, 3.0; 95% CI, 1.6-5.6; P = .001), vision of less than 20/200 (10% vs 3%; OR, 3.1; 95% CI, 1.2-7.8; P = .02), low IQ of less than 85 (38% vs 14%; OR, 4.5; 95% CI, 2.7-7.7; P<.001), limited academic skills (37% vs 15%; OR, 4.2; 95% CI, 2.5-7.3; P<.001), poor motor skills (47% vs 10%; OR, 7.8; 95% CI, 4.5-13.6; P<.001), and poor adaptive functioning (69% vs 34%; OR, 6.5; 95% CI, 4.0-10.6; P<.001).The ELBW survivors in school at age 8 years who were born in the 1990s have considerable long-term health and educational needs.","Chronic conditions, functional limitations, and special health care needs of school-aged children born with extremely low-birth-weight in the 1990s."
"545","JAMA.266","0.001",16030276,2005,"Information on the school-age functioning and special health care needs of extremely low-birth-weight (ELBW, <1000 g) children is necessary to plan for medical and educational services.To examine neurosensory, developmental, and medical conditions together with the associated functional limitations and special health care needs of ELBW children compared with normal-birth-weight (NBW) term-born children (controls).A follow-up study at age 8 years of a cohort of 219 ELBW children born 1992 to 1995 (92% of survivors) and 176 NBW controls of similar sociodemographic status conducted in Cleveland, Ohio.Parent Questionnaire for Identifying Children with Chronic Conditions of 12 months or more and categorization of specific medical diagnoses and developmental disabilities based on examination of the children.In logistic regression analyses adjusting for sociodemographic status and sex, ELBW children had significantly more chronic conditions than NBW controls, including functional limitations (64% vs 20%, respectively; odds ratio [OR], 8.1; 95% confidence interval [CI], 5.0-13.1; P<.001), compensatory dependency needs (48% vs 23%, respectively; OR, 3.0; 95% CI, 1.9-4.7; P<.001), and services above those routinely required by children (65% vs 27%, respectively; OR, 5.4; 95% CI, 3.4-8.5; P<.001). These differences remained significant when the 36 ELBW children with neurosensory impairments were excluded. Specific diagnoses and disabilities for ELBW vs NBW children included cerebral palsy (14% vs 0%, respectively; P<.001), asthma (21% vs 9%; OR, 3.0; 95% CI, 1.6-5.6; P = .001), vision of less than 20/200 (10% vs 3%; OR, 3.1; 95% CI, 1.2-7.8; P = .02), low IQ of less than 85 (38% vs 14%; OR, 4.5; 95% CI, 2.7-7.7; P<.001), limited academic skills (37% vs 15%; OR, 4.2; 95% CI, 2.5-7.3; P<.001), poor motor skills (47% vs 10%; OR, 7.8; 95% CI, 4.5-13.6; P<.001), and poor adaptive functioning (69% vs 34%; OR, 6.5; 95% CI, 4.0-10.6; P<.001).The ELBW survivors in school at age 8 years who were born in the 1990s have considerable long-term health and educational needs.","Chronic conditions, functional limitations, and special health care needs of school-aged children born with extremely low-birth-weight in the 1990s."
"546","JAMA.267","0.001",16030276,2005,"Information on the school-age functioning and special health care needs of extremely low-birth-weight (ELBW, <1000 g) children is necessary to plan for medical and educational services.To examine neurosensory, developmental, and medical conditions together with the associated functional limitations and special health care needs of ELBW children compared with normal-birth-weight (NBW) term-born children (controls).A follow-up study at age 8 years of a cohort of 219 ELBW children born 1992 to 1995 (92% of survivors) and 176 NBW controls of similar sociodemographic status conducted in Cleveland, Ohio.Parent Questionnaire for Identifying Children with Chronic Conditions of 12 months or more and categorization of specific medical diagnoses and developmental disabilities based on examination of the children.In logistic regression analyses adjusting for sociodemographic status and sex, ELBW children had significantly more chronic conditions than NBW controls, including functional limitations (64% vs 20%, respectively; odds ratio [OR], 8.1; 95% confidence interval [CI], 5.0-13.1; P<.001), compensatory dependency needs (48% vs 23%, respectively; OR, 3.0; 95% CI, 1.9-4.7; P<.001), and services above those routinely required by children (65% vs 27%, respectively; OR, 5.4; 95% CI, 3.4-8.5; P<.001). These differences remained significant when the 36 ELBW children with neurosensory impairments were excluded. Specific diagnoses and disabilities for ELBW vs NBW children included cerebral palsy (14% vs 0%, respectively; P<.001), asthma (21% vs 9%; OR, 3.0; 95% CI, 1.6-5.6; P = .001), vision of less than 20/200 (10% vs 3%; OR, 3.1; 95% CI, 1.2-7.8; P = .02), low IQ of less than 85 (38% vs 14%; OR, 4.5; 95% CI, 2.7-7.7; P<.001), limited academic skills (37% vs 15%; OR, 4.2; 95% CI, 2.5-7.3; P<.001), poor motor skills (47% vs 10%; OR, 7.8; 95% CI, 4.5-13.6; P<.001), and poor adaptive functioning (69% vs 34%; OR, 6.5; 95% CI, 4.0-10.6; P<.001).The ELBW survivors in school at age 8 years who were born in the 1990s have considerable long-term health and educational needs.","Chronic conditions, functional limitations, and special health care needs of school-aged children born with extremely low-birth-weight in the 1990s."
"547","JAMA.268","0.001",16030276,2005,"Information on the school-age functioning and special health care needs of extremely low-birth-weight (ELBW, <1000 g) children is necessary to plan for medical and educational services.To examine neurosensory, developmental, and medical conditions together with the associated functional limitations and special health care needs of ELBW children compared with normal-birth-weight (NBW) term-born children (controls).A follow-up study at age 8 years of a cohort of 219 ELBW children born 1992 to 1995 (92% of survivors) and 176 NBW controls of similar sociodemographic status conducted in Cleveland, Ohio.Parent Questionnaire for Identifying Children with Chronic Conditions of 12 months or more and categorization of specific medical diagnoses and developmental disabilities based on examination of the children.In logistic regression analyses adjusting for sociodemographic status and sex, ELBW children had significantly more chronic conditions than NBW controls, including functional limitations (64% vs 20%, respectively; odds ratio [OR], 8.1; 95% confidence interval [CI], 5.0-13.1; P<.001), compensatory dependency needs (48% vs 23%, respectively; OR, 3.0; 95% CI, 1.9-4.7; P<.001), and services above those routinely required by children (65% vs 27%, respectively; OR, 5.4; 95% CI, 3.4-8.5; P<.001). These differences remained significant when the 36 ELBW children with neurosensory impairments were excluded. Specific diagnoses and disabilities for ELBW vs NBW children included cerebral palsy (14% vs 0%, respectively; P<.001), asthma (21% vs 9%; OR, 3.0; 95% CI, 1.6-5.6; P = .001), vision of less than 20/200 (10% vs 3%; OR, 3.1; 95% CI, 1.2-7.8; P = .02), low IQ of less than 85 (38% vs 14%; OR, 4.5; 95% CI, 2.7-7.7; P<.001), limited academic skills (37% vs 15%; OR, 4.2; 95% CI, 2.5-7.3; P<.001), poor motor skills (47% vs 10%; OR, 7.8; 95% CI, 4.5-13.6; P<.001), and poor adaptive functioning (69% vs 34%; OR, 6.5; 95% CI, 4.0-10.6; P<.001).The ELBW survivors in school at age 8 years who were born in the 1990s have considerable long-term health and educational needs.","Chronic conditions, functional limitations, and special health care needs of school-aged children born with extremely low-birth-weight in the 1990s."
"548","JAMA.269","0.001",16030276,2005,"Information on the school-age functioning and special health care needs of extremely low-birth-weight (ELBW, <1000 g) children is necessary to plan for medical and educational services.To examine neurosensory, developmental, and medical conditions together with the associated functional limitations and special health care needs of ELBW children compared with normal-birth-weight (NBW) term-born children (controls).A follow-up study at age 8 years of a cohort of 219 ELBW children born 1992 to 1995 (92% of survivors) and 176 NBW controls of similar sociodemographic status conducted in Cleveland, Ohio.Parent Questionnaire for Identifying Children with Chronic Conditions of 12 months or more and categorization of specific medical diagnoses and developmental disabilities based on examination of the children.In logistic regression analyses adjusting for sociodemographic status and sex, ELBW children had significantly more chronic conditions than NBW controls, including functional limitations (64% vs 20%, respectively; odds ratio [OR], 8.1; 95% confidence interval [CI], 5.0-13.1; P<.001), compensatory dependency needs (48% vs 23%, respectively; OR, 3.0; 95% CI, 1.9-4.7; P<.001), and services above those routinely required by children (65% vs 27%, respectively; OR, 5.4; 95% CI, 3.4-8.5; P<.001). These differences remained significant when the 36 ELBW children with neurosensory impairments were excluded. Specific diagnoses and disabilities for ELBW vs NBW children included cerebral palsy (14% vs 0%, respectively; P<.001), asthma (21% vs 9%; OR, 3.0; 95% CI, 1.6-5.6; P = .001), vision of less than 20/200 (10% vs 3%; OR, 3.1; 95% CI, 1.2-7.8; P = .02), low IQ of less than 85 (38% vs 14%; OR, 4.5; 95% CI, 2.7-7.7; P<.001), limited academic skills (37% vs 15%; OR, 4.2; 95% CI, 2.5-7.3; P<.001), poor motor skills (47% vs 10%; OR, 7.8; 95% CI, 4.5-13.6; P<.001), and poor adaptive functioning (69% vs 34%; OR, 6.5; 95% CI, 4.0-10.6; P<.001).The ELBW survivors in school at age 8 years who were born in the 1990s have considerable long-term health and educational needs.","Chronic conditions, functional limitations, and special health care needs of school-aged children born with extremely low-birth-weight in the 1990s."
"549","JAMA.270","0.001",16030276,2005,"Information on the school-age functioning and special health care needs of extremely low-birth-weight (ELBW, <1000 g) children is necessary to plan for medical and educational services.To examine neurosensory, developmental, and medical conditions together with the associated functional limitations and special health care needs of ELBW children compared with normal-birth-weight (NBW) term-born children (controls).A follow-up study at age 8 years of a cohort of 219 ELBW children born 1992 to 1995 (92% of survivors) and 176 NBW controls of similar sociodemographic status conducted in Cleveland, Ohio.Parent Questionnaire for Identifying Children with Chronic Conditions of 12 months or more and categorization of specific medical diagnoses and developmental disabilities based on examination of the children.In logistic regression analyses adjusting for sociodemographic status and sex, ELBW children had significantly more chronic conditions than NBW controls, including functional limitations (64% vs 20%, respectively; odds ratio [OR], 8.1; 95% confidence interval [CI], 5.0-13.1; P<.001), compensatory dependency needs (48% vs 23%, respectively; OR, 3.0; 95% CI, 1.9-4.7; P<.001), and services above those routinely required by children (65% vs 27%, respectively; OR, 5.4; 95% CI, 3.4-8.5; P<.001). These differences remained significant when the 36 ELBW children with neurosensory impairments were excluded. Specific diagnoses and disabilities for ELBW vs NBW children included cerebral palsy (14% vs 0%, respectively; P<.001), asthma (21% vs 9%; OR, 3.0; 95% CI, 1.6-5.6; P = .001), vision of less than 20/200 (10% vs 3%; OR, 3.1; 95% CI, 1.2-7.8; P = .02), low IQ of less than 85 (38% vs 14%; OR, 4.5; 95% CI, 2.7-7.7; P<.001), limited academic skills (37% vs 15%; OR, 4.2; 95% CI, 2.5-7.3; P<.001), poor motor skills (47% vs 10%; OR, 7.8; 95% CI, 4.5-13.6; P<.001), and poor adaptive functioning (69% vs 34%; OR, 6.5; 95% CI, 4.0-10.6; P<.001).The ELBW survivors in school at age 8 years who were born in the 1990s have considerable long-term health and educational needs.","Chronic conditions, functional limitations, and special health care needs of school-aged children born with extremely low-birth-weight in the 1990s."
"550","JAMA.271","0.001",16030276,2005,"Information on the school-age functioning and special health care needs of extremely low-birth-weight (ELBW, <1000 g) children is necessary to plan for medical and educational services.To examine neurosensory, developmental, and medical conditions together with the associated functional limitations and special health care needs of ELBW children compared with normal-birth-weight (NBW) term-born children (controls).A follow-up study at age 8 years of a cohort of 219 ELBW children born 1992 to 1995 (92% of survivors) and 176 NBW controls of similar sociodemographic status conducted in Cleveland, Ohio.Parent Questionnaire for Identifying Children with Chronic Conditions of 12 months or more and categorization of specific medical diagnoses and developmental disabilities based on examination of the children.In logistic regression analyses adjusting for sociodemographic status and sex, ELBW children had significantly more chronic conditions than NBW controls, including functional limitations (64% vs 20%, respectively; odds ratio [OR], 8.1; 95% confidence interval [CI], 5.0-13.1; P<.001), compensatory dependency needs (48% vs 23%, respectively; OR, 3.0; 95% CI, 1.9-4.7; P<.001), and services above those routinely required by children (65% vs 27%, respectively; OR, 5.4; 95% CI, 3.4-8.5; P<.001). These differences remained significant when the 36 ELBW children with neurosensory impairments were excluded. Specific diagnoses and disabilities for ELBW vs NBW children included cerebral palsy (14% vs 0%, respectively; P<.001), asthma (21% vs 9%; OR, 3.0; 95% CI, 1.6-5.6; P = .001), vision of less than 20/200 (10% vs 3%; OR, 3.1; 95% CI, 1.2-7.8; P = .02), low IQ of less than 85 (38% vs 14%; OR, 4.5; 95% CI, 2.7-7.7; P<.001), limited academic skills (37% vs 15%; OR, 4.2; 95% CI, 2.5-7.3; P<.001), poor motor skills (47% vs 10%; OR, 7.8; 95% CI, 4.5-13.6; P<.001), and poor adaptive functioning (69% vs 34%; OR, 6.5; 95% CI, 4.0-10.6; P<.001).The ELBW survivors in school at age 8 years who were born in the 1990s have considerable long-term health and educational needs.","Chronic conditions, functional limitations, and special health care needs of school-aged children born with extremely low-birth-weight in the 1990s."
"551","JAMA.272","0.001",16030276,2005,"Information on the school-age functioning and special health care needs of extremely low-birth-weight (ELBW, <1000 g) children is necessary to plan for medical and educational services.To examine neurosensory, developmental, and medical conditions together with the associated functional limitations and special health care needs of ELBW children compared with normal-birth-weight (NBW) term-born children (controls).A follow-up study at age 8 years of a cohort of 219 ELBW children born 1992 to 1995 (92% of survivors) and 176 NBW controls of similar sociodemographic status conducted in Cleveland, Ohio.Parent Questionnaire for Identifying Children with Chronic Conditions of 12 months or more and categorization of specific medical diagnoses and developmental disabilities based on examination of the children.In logistic regression analyses adjusting for sociodemographic status and sex, ELBW children had significantly more chronic conditions than NBW controls, including functional limitations (64% vs 20%, respectively; odds ratio [OR], 8.1; 95% confidence interval [CI], 5.0-13.1; P<.001), compensatory dependency needs (48% vs 23%, respectively; OR, 3.0; 95% CI, 1.9-4.7; P<.001), and services above those routinely required by children (65% vs 27%, respectively; OR, 5.4; 95% CI, 3.4-8.5; P<.001). These differences remained significant when the 36 ELBW children with neurosensory impairments were excluded. Specific diagnoses and disabilities for ELBW vs NBW children included cerebral palsy (14% vs 0%, respectively; P<.001), asthma (21% vs 9%; OR, 3.0; 95% CI, 1.6-5.6; P = .001), vision of less than 20/200 (10% vs 3%; OR, 3.1; 95% CI, 1.2-7.8; P = .02), low IQ of less than 85 (38% vs 14%; OR, 4.5; 95% CI, 2.7-7.7; P<.001), limited academic skills (37% vs 15%; OR, 4.2; 95% CI, 2.5-7.3; P<.001), poor motor skills (47% vs 10%; OR, 7.8; 95% CI, 4.5-13.6; P<.001), and poor adaptive functioning (69% vs 34%; OR, 6.5; 95% CI, 4.0-10.6; P<.001).The ELBW survivors in school at age 8 years who were born in the 1990s have considerable long-term health and educational needs.","Chronic conditions, functional limitations, and special health care needs of school-aged children born with extremely low-birth-weight in the 1990s."
"552","JAMA.309","0.02",16030276,2005,"Information on the school-age functioning and special health care needs of extremely low-birth-weight (ELBW, <1000 g) children is necessary to plan for medical and educational services.To examine neurosensory, developmental, and medical conditions together with the associated functional limitations and special health care needs of ELBW children compared with normal-birth-weight (NBW) term-born children (controls).A follow-up study at age 8 years of a cohort of 219 ELBW children born 1992 to 1995 (92% of survivors) and 176 NBW controls of similar sociodemographic status conducted in Cleveland, Ohio.Parent Questionnaire for Identifying Children with Chronic Conditions of 12 months or more and categorization of specific medical diagnoses and developmental disabilities based on examination of the children.In logistic regression analyses adjusting for sociodemographic status and sex, ELBW children had significantly more chronic conditions than NBW controls, including functional limitations (64% vs 20%, respectively; odds ratio [OR], 8.1; 95% confidence interval [CI], 5.0-13.1; P<.001), compensatory dependency needs (48% vs 23%, respectively; OR, 3.0; 95% CI, 1.9-4.7; P<.001), and services above those routinely required by children (65% vs 27%, respectively; OR, 5.4; 95% CI, 3.4-8.5; P<.001). These differences remained significant when the 36 ELBW children with neurosensory impairments were excluded. Specific diagnoses and disabilities for ELBW vs NBW children included cerebral palsy (14% vs 0%, respectively; P<.001), asthma (21% vs 9%; OR, 3.0; 95% CI, 1.6-5.6; P = .001), vision of less than 20/200 (10% vs 3%; OR, 3.1; 95% CI, 1.2-7.8; P = .02), low IQ of less than 85 (38% vs 14%; OR, 4.5; 95% CI, 2.7-7.7; P<.001), limited academic skills (37% vs 15%; OR, 4.2; 95% CI, 2.5-7.3; P<.001), poor motor skills (47% vs 10%; OR, 7.8; 95% CI, 4.5-13.6; P<.001), and poor adaptive functioning (69% vs 34%; OR, 6.5; 95% CI, 4.0-10.6; P<.001).The ELBW survivors in school at age 8 years who were born in the 1990s have considerable long-term health and educational needs.","Chronic conditions, functional limitations, and special health care needs of school-aged children born with extremely low-birth-weight in the 1990s."
"553","JAMA.2851","0.001",16046650,2005,"Men with localized prostate cancer and a preoperative prostate-specific antigen (PSA) velocity greater than 2.0 ng/mL per year experience a 10-fold increase in prostate cancer-specific mortality despite surgery.To assess whether a greater than 2.0-ng/mL increase in PSA level during the year prior to diagnosis was significantly associated with prostate cancer-specific mortality following radiation therapy (RT).Between January 1, 1989, and December 1, 2002, 358 men treated with RT for localized prostate cancer formed the study cohort (median age at treatment, 71.2 [range, 43.2-83.5] years). A Cox regression multivariable analysis was used to evaluate whether a PSA velocity greater than 2.0 ng/mL per year was significantly associated with prostate cancer-specific mortality and all-cause mortality after controlling for prognostic factors available at diagnosis.Time to prostate cancer-specific mortality for the 125 men with low-risk prostate cancer (clinical tumor category T1c or T2a and PSA level <10.0 ng/mL and Gleason score < or =6) and the 233 men with higher-risk disease, stratified by the PSA velocity.A PSA velocity greater than 2.0 ng/mL per year was significantly associated with a shorter time to prostate cancer-specific mortality (adjusted hazard ratio [HR], 12.0; 95% confidence interval [CI], 3.0-54.0; P = .001) and all-cause mortality (adjusted HR, 2.1; 95% CI, 1.3-3.6; P = .005) when compared with men whose PSA velocity was 2.0 ng/mL per year or less. Men presenting with low-risk disease and a PSA velocity greater than 2.0 ng/mL per year had a 7-year estimate of prostate cancer-specific mortality of 19% (95% CI, 2%-39%) compared with 0% for men whose PSA velocity was 2.0 ng/mL per year or less. The corresponding values for men with higher-risk disease were 24% (95% CI, 12%-37%) and 4% (95% CI, 0%-11%), respectively.A greater than 2.0-ng/mL increase in PSA level during the year prior to diagnosis is associated with a significantly higher risk of death due to prostate cancer following RT despite having low-risk disease. Such men who are planning to undergo RT and are in good health could be considered for RT combined with androgen suppression therapy because this approach improves survival in men with higher-risk disease.","Pretreatment PSA velocity and risk of death from prostate cancer following external beam radiation therapy."
"554","JAMA.2861","0.005",16046650,2005,"Men with localized prostate cancer and a preoperative prostate-specific antigen (PSA) velocity greater than 2.0 ng/mL per year experience a 10-fold increase in prostate cancer-specific mortality despite surgery.To assess whether a greater than 2.0-ng/mL increase in PSA level during the year prior to diagnosis was significantly associated with prostate cancer-specific mortality following radiation therapy (RT).Between January 1, 1989, and December 1, 2002, 358 men treated with RT for localized prostate cancer formed the study cohort (median age at treatment, 71.2 [range, 43.2-83.5] years). A Cox regression multivariable analysis was used to evaluate whether a PSA velocity greater than 2.0 ng/mL per year was significantly associated with prostate cancer-specific mortality and all-cause mortality after controlling for prognostic factors available at diagnosis.Time to prostate cancer-specific mortality for the 125 men with low-risk prostate cancer (clinical tumor category T1c or T2a and PSA level <10.0 ng/mL and Gleason score < or =6) and the 233 men with higher-risk disease, stratified by the PSA velocity.A PSA velocity greater than 2.0 ng/mL per year was significantly associated with a shorter time to prostate cancer-specific mortality (adjusted hazard ratio [HR], 12.0; 95% confidence interval [CI], 3.0-54.0; P = .001) and all-cause mortality (adjusted HR, 2.1; 95% CI, 1.3-3.6; P = .005) when compared with men whose PSA velocity was 2.0 ng/mL per year or less. Men presenting with low-risk disease and a PSA velocity greater than 2.0 ng/mL per year had a 7-year estimate of prostate cancer-specific mortality of 19% (95% CI, 2%-39%) compared with 0% for men whose PSA velocity was 2.0 ng/mL per year or less. The corresponding values for men with higher-risk disease were 24% (95% CI, 12%-37%) and 4% (95% CI, 0%-11%), respectively.A greater than 2.0-ng/mL increase in PSA level during the year prior to diagnosis is associated with a significantly higher risk of death due to prostate cancer following RT despite having low-risk disease. Such men who are planning to undergo RT and are in good health could be considered for RT combined with androgen suppression therapy because this approach improves survival in men with higher-risk disease.","Pretreatment PSA velocity and risk of death from prostate cancer following external beam radiation therapy."
"555","American Journal of Epidemiology.53","NA",16093295,2005,"During 1998-2000, the authors investigated relations between lung function, respiratory symptoms, and arsenic in drinking water among 287 study participants, including 132 with arsenic-caused skin lesions, in West Bengal, India. The source population involved 7,683 participants who had been surveyed for arsenic-related skin lesions in 1995-1996. Respiratory symptoms were increased among men with arsenic-caused skin lesions (versus those without lesions), particularly ""shortness of breath at night"" (odds ratio (OR) = 2.8, 95% confidence interval (CI): 1.1, 7.6) and ""morning cough"" (OR = 2.8, 95% CI: 1.2, 6.6) in smokers and ""shortness of breath ever"" (OR = 3.8, 95% CI: 0.7, 20.6) in nonsmokers. Among men with skin lesions, the average adjusted forced expiratory volume in 1 second (FEV1) was reduced by 256.2 ml (95% CI: 113.9, 398.4; p < 0.001) and the average adjusted forced vital capacity (FVC) was reduced by 287.8 ml (95% CI: 134.9, 440.8; p < 0.001). In men, a 100-microg/liter increase in arsenic level was associated with a 45.0-ml decrease (95% CI: 6.2, 83.9) in FEV1 (p = 0.02) and a 41.4-ml decrease (95% CI: -0.7, 83.5) in FVC (p = 0.054). Women had lower risks than men of developing skin lesions and showed little evidence of respiratory effects. In this study, consumption of arsenic-contaminated water was associated with respiratory symptoms and reduced lung function in men, especially among those with arsenic-related skin lesions.","Decrements in lung function related to arsenic in drinking water in West Bengal, India."
"556","American Journal of Epidemiology.54","NA",16093295,2005,"During 1998-2000, the authors investigated relations between lung function, respiratory symptoms, and arsenic in drinking water among 287 study participants, including 132 with arsenic-caused skin lesions, in West Bengal, India. The source population involved 7,683 participants who had been surveyed for arsenic-related skin lesions in 1995-1996. Respiratory symptoms were increased among men with arsenic-caused skin lesions (versus those without lesions), particularly ""shortness of breath at night"" (odds ratio (OR) = 2.8, 95% confidence interval (CI): 1.1, 7.6) and ""morning cough"" (OR = 2.8, 95% CI: 1.2, 6.6) in smokers and ""shortness of breath ever"" (OR = 3.8, 95% CI: 0.7, 20.6) in nonsmokers. Among men with skin lesions, the average adjusted forced expiratory volume in 1 second (FEV1) was reduced by 256.2 ml (95% CI: 113.9, 398.4; p < 0.001) and the average adjusted forced vital capacity (FVC) was reduced by 287.8 ml (95% CI: 134.9, 440.8; p < 0.001). In men, a 100-microg/liter increase in arsenic level was associated with a 45.0-ml decrease (95% CI: 6.2, 83.9) in FEV1 (p = 0.02) and a 41.4-ml decrease (95% CI: -0.7, 83.5) in FVC (p = 0.054). Women had lower risks than men of developing skin lesions and showed little evidence of respiratory effects. In this study, consumption of arsenic-contaminated water was associated with respiratory symptoms and reduced lung function in men, especially among those with arsenic-related skin lesions.","Decrements in lung function related to arsenic in drinking water in West Bengal, India."
"557","American Journal of Epidemiology.61","NA",16093295,2005,"During 1998-2000, the authors investigated relations between lung function, respiratory symptoms, and arsenic in drinking water among 287 study participants, including 132 with arsenic-caused skin lesions, in West Bengal, India. The source population involved 7,683 participants who had been surveyed for arsenic-related skin lesions in 1995-1996. Respiratory symptoms were increased among men with arsenic-caused skin lesions (versus those without lesions), particularly ""shortness of breath at night"" (odds ratio (OR) = 2.8, 95% confidence interval (CI): 1.1, 7.6) and ""morning cough"" (OR = 2.8, 95% CI: 1.2, 6.6) in smokers and ""shortness of breath ever"" (OR = 3.8, 95% CI: 0.7, 20.6) in nonsmokers. Among men with skin lesions, the average adjusted forced expiratory volume in 1 second (FEV1) was reduced by 256.2 ml (95% CI: 113.9, 398.4; p < 0.001) and the average adjusted forced vital capacity (FVC) was reduced by 287.8 ml (95% CI: 134.9, 440.8; p < 0.001). In men, a 100-microg/liter increase in arsenic level was associated with a 45.0-ml decrease (95% CI: 6.2, 83.9) in FEV1 (p = 0.02) and a 41.4-ml decrease (95% CI: -0.7, 83.5) in FVC (p = 0.054). Women had lower risks than men of developing skin lesions and showed little evidence of respiratory effects. In this study, consumption of arsenic-contaminated water was associated with respiratory symptoms and reduced lung function in men, especially among those with arsenic-related skin lesions.","Decrements in lung function related to arsenic in drinking water in West Bengal, India."
"558","JAMA.263","0.001",16106006,2005,"Although acute renal failure (ARF) is believed to be common in the setting of critical illness and is associated with a high risk of death, little is known about its epidemiology and outcome or how these vary in different regions of the world.To determine the period prevalence of ARF in intensive care unit (ICU) patients in multiple countries; to characterize differences in etiology, illness severity, and clinical practice; and to determine the impact of these differences on patient outcomes.Prospective observational study of ICU patients who either were treated with renal replacement therapy (RRT) or fulfilled at least 1 of the predefined criteria for ARF from September 2000 to December 2001 at 54 hospitals in 23 countries.Occurrence of ARF, factors contributing to etiology, illness severity, treatment, need for renal support after hospital discharge, and hospital mortality.Of 29 269 critically ill patients admitted during the study period, 1738 (5.7%; 95% confidence interval [CI], 5.5%-6.0%) had ARF during their ICU stay, including 1260 who were treated with RRT. The most common contributing factor to ARF was septic shock (47.5%; 95% CI, 45.2%-49.5%). Approximately 30% of patients had preadmission renal dysfunction. Overall hospital mortality was 60.3% (95% CI, 58.0%-62.6%). Dialysis dependence at hospital discharge was 13.8% (95% CI, 11.2%-16.3%) for survivors. Independent risk factors for hospital mortality included use of vasopressors (odds ratio [OR], 1.95; 95% CI, 1.50-2.55; P<.001), mechanical ventilation (OR, 2.11; 95% CI, 1.58-2.82; P<.001), septic shock (OR, 1.36; 95% CI, 1.03-1.79; P = .03), cardiogenic shock (OR, 1.41; 95% CI, 1.05-1.90; P = .02), and hepatorenal syndrome (OR, 1.87; 95% CI, 1.07-3.28; P = .03).In this multinational study, the period prevalence of ARF requiring RRT in the ICU was between 5% and 6% and was associated with a high hospital mortality rate.","Acute renal failure in critically ill patients: a multinational, multicenter study."
"559","JAMA.264","0.001",16106006,2005,"Although acute renal failure (ARF) is believed to be common in the setting of critical illness and is associated with a high risk of death, little is known about its epidemiology and outcome or how these vary in different regions of the world.To determine the period prevalence of ARF in intensive care unit (ICU) patients in multiple countries; to characterize differences in etiology, illness severity, and clinical practice; and to determine the impact of these differences on patient outcomes.Prospective observational study of ICU patients who either were treated with renal replacement therapy (RRT) or fulfilled at least 1 of the predefined criteria for ARF from September 2000 to December 2001 at 54 hospitals in 23 countries.Occurrence of ARF, factors contributing to etiology, illness severity, treatment, need for renal support after hospital discharge, and hospital mortality.Of 29 269 critically ill patients admitted during the study period, 1738 (5.7%; 95% confidence interval [CI], 5.5%-6.0%) had ARF during their ICU stay, including 1260 who were treated with RRT. The most common contributing factor to ARF was septic shock (47.5%; 95% CI, 45.2%-49.5%). Approximately 30% of patients had preadmission renal dysfunction. Overall hospital mortality was 60.3% (95% CI, 58.0%-62.6%). Dialysis dependence at hospital discharge was 13.8% (95% CI, 11.2%-16.3%) for survivors. Independent risk factors for hospital mortality included use of vasopressors (odds ratio [OR], 1.95; 95% CI, 1.50-2.55; P<.001), mechanical ventilation (OR, 2.11; 95% CI, 1.58-2.82; P<.001), septic shock (OR, 1.36; 95% CI, 1.03-1.79; P = .03), cardiogenic shock (OR, 1.41; 95% CI, 1.05-1.90; P = .02), and hepatorenal syndrome (OR, 1.87; 95% CI, 1.07-3.28; P = .03).In this multinational study, the period prevalence of ARF requiring RRT in the ICU was between 5% and 6% and was associated with a high hospital mortality rate.","Acute renal failure in critically ill patients: a multinational, multicenter study."
"560","JAMA.305","0.03",16106006,2005,"Although acute renal failure (ARF) is believed to be common in the setting of critical illness and is associated with a high risk of death, little is known about its epidemiology and outcome or how these vary in different regions of the world.To determine the period prevalence of ARF in intensive care unit (ICU) patients in multiple countries; to characterize differences in etiology, illness severity, and clinical practice; and to determine the impact of these differences on patient outcomes.Prospective observational study of ICU patients who either were treated with renal replacement therapy (RRT) or fulfilled at least 1 of the predefined criteria for ARF from September 2000 to December 2001 at 54 hospitals in 23 countries.Occurrence of ARF, factors contributing to etiology, illness severity, treatment, need for renal support after hospital discharge, and hospital mortality.Of 29 269 critically ill patients admitted during the study period, 1738 (5.7%; 95% confidence interval [CI], 5.5%-6.0%) had ARF during their ICU stay, including 1260 who were treated with RRT. The most common contributing factor to ARF was septic shock (47.5%; 95% CI, 45.2%-49.5%). Approximately 30% of patients had preadmission renal dysfunction. Overall hospital mortality was 60.3% (95% CI, 58.0%-62.6%). Dialysis dependence at hospital discharge was 13.8% (95% CI, 11.2%-16.3%) for survivors. Independent risk factors for hospital mortality included use of vasopressors (odds ratio [OR], 1.95; 95% CI, 1.50-2.55; P<.001), mechanical ventilation (OR, 2.11; 95% CI, 1.58-2.82; P<.001), septic shock (OR, 1.36; 95% CI, 1.03-1.79; P = .03), cardiogenic shock (OR, 1.41; 95% CI, 1.05-1.90; P = .02), and hepatorenal syndrome (OR, 1.87; 95% CI, 1.07-3.28; P = .03).In this multinational study, the period prevalence of ARF requiring RRT in the ICU was between 5% and 6% and was associated with a high hospital mortality rate.","Acute renal failure in critically ill patients: a multinational, multicenter study."
"561","JAMA.306","0.02",16106006,2005,"Although acute renal failure (ARF) is believed to be common in the setting of critical illness and is associated with a high risk of death, little is known about its epidemiology and outcome or how these vary in different regions of the world.To determine the period prevalence of ARF in intensive care unit (ICU) patients in multiple countries; to characterize differences in etiology, illness severity, and clinical practice; and to determine the impact of these differences on patient outcomes.Prospective observational study of ICU patients who either were treated with renal replacement therapy (RRT) or fulfilled at least 1 of the predefined criteria for ARF from September 2000 to December 2001 at 54 hospitals in 23 countries.Occurrence of ARF, factors contributing to etiology, illness severity, treatment, need for renal support after hospital discharge, and hospital mortality.Of 29 269 critically ill patients admitted during the study period, 1738 (5.7%; 95% confidence interval [CI], 5.5%-6.0%) had ARF during their ICU stay, including 1260 who were treated with RRT. The most common contributing factor to ARF was septic shock (47.5%; 95% CI, 45.2%-49.5%). Approximately 30% of patients had preadmission renal dysfunction. Overall hospital mortality was 60.3% (95% CI, 58.0%-62.6%). Dialysis dependence at hospital discharge was 13.8% (95% CI, 11.2%-16.3%) for survivors. Independent risk factors for hospital mortality included use of vasopressors (odds ratio [OR], 1.95; 95% CI, 1.50-2.55; P<.001), mechanical ventilation (OR, 2.11; 95% CI, 1.58-2.82; P<.001), septic shock (OR, 1.36; 95% CI, 1.03-1.79; P = .03), cardiogenic shock (OR, 1.41; 95% CI, 1.05-1.90; P = .02), and hepatorenal syndrome (OR, 1.87; 95% CI, 1.07-3.28; P = .03).In this multinational study, the period prevalence of ARF requiring RRT in the ICU was between 5% and 6% and was associated with a high hospital mortality rate.","Acute renal failure in critically ill patients: a multinational, multicenter study."
"562","JAMA.307","0.03",16106006,2005,"Although acute renal failure (ARF) is believed to be common in the setting of critical illness and is associated with a high risk of death, little is known about its epidemiology and outcome or how these vary in different regions of the world.To determine the period prevalence of ARF in intensive care unit (ICU) patients in multiple countries; to characterize differences in etiology, illness severity, and clinical practice; and to determine the impact of these differences on patient outcomes.Prospective observational study of ICU patients who either were treated with renal replacement therapy (RRT) or fulfilled at least 1 of the predefined criteria for ARF from September 2000 to December 2001 at 54 hospitals in 23 countries.Occurrence of ARF, factors contributing to etiology, illness severity, treatment, need for renal support after hospital discharge, and hospital mortality.Of 29 269 critically ill patients admitted during the study period, 1738 (5.7%; 95% confidence interval [CI], 5.5%-6.0%) had ARF during their ICU stay, including 1260 who were treated with RRT. The most common contributing factor to ARF was septic shock (47.5%; 95% CI, 45.2%-49.5%). Approximately 30% of patients had preadmission renal dysfunction. Overall hospital mortality was 60.3% (95% CI, 58.0%-62.6%). Dialysis dependence at hospital discharge was 13.8% (95% CI, 11.2%-16.3%) for survivors. Independent risk factors for hospital mortality included use of vasopressors (odds ratio [OR], 1.95; 95% CI, 1.50-2.55; P<.001), mechanical ventilation (OR, 2.11; 95% CI, 1.58-2.82; P<.001), septic shock (OR, 1.36; 95% CI, 1.03-1.79; P = .03), cardiogenic shock (OR, 1.41; 95% CI, 1.05-1.90; P = .02), and hepatorenal syndrome (OR, 1.87; 95% CI, 1.07-3.28; P = .03).In this multinational study, the period prevalence of ARF requiring RRT in the ICU was between 5% and 6% and was associated with a high hospital mortality rate.","Acute renal failure in critically ill patients: a multinational, multicenter study."
"563","JAMA.301","0.001",16106007,2005,"Placement of sirolimus-eluting stents or paclitaxel-eluting stents has emerged as the predominant percutaneous treatment strategy in patients with coronary artery disease (CAD). Whether there are any differences in efficacy and safety between these 2 drug-eluting stents is unclear.To compare outcomes of sirolimus-eluting and paclitaxel-eluting coronary stents on the basis of data generated by randomized head-to-head clinical trials.PubMed and the Cochrane Central Register of Controlled Trials, conference proceedings from major cardiology meetings, and Internet-based sources of information on clinical trials in cardiology from January 2003 to April 2005.Randomized trials comparing the sirolimus-eluting stent with the paclitaxel-eluting stent in patients with CAD reporting the outcomes of interest (target lesion revascularization, angiographic restenosis, stent thrombosis, myocardial infarction [MI], death, and the composite of death or MI) during a follow-up of at least 6 months.Two reviewers independently identified studies and abstracted data on sample size, baseline characteristics, and outcomes of interest.Six trials, including 3669 patients, met the selection criteria. No significant heterogeneity was found across trials. Target lesion revascularization, the primary outcome of interest, was less frequently performed in patients who were treated with the sirolimus-eluting stent (5.1%) vs the paclitaxel-eluting stent (7.8%) (odds ratio [OR], 0.64; 95% confidence interval [CI], 0.49-0.84; P = .001). Similarly, angiographic restenosis was less frequently observed among patients assigned to the sirolimus-eluting stent (9.3%) vs the paclitaxel-eluting stent (13.1%) (OR, 0.68; 95% CI, 0.55-0.86; P = .001). Event rates for sirolimus-eluting vs paclitaxel-eluting stents were 0.9% and 1.1%, respectively, for stent thrombosis (P = .62); 1.4% and 1.6%, respectively, for death (P = .56); and 4.9% and 5.8%, respectively, for the composite of death or MI (P = .23).Patients receiving sirolimus-eluting stents had a significantly lower risk of restenosis and target vessel revascularization compared with those receiving paclitaxel-eluting stents. Rates of death, death or MI, and stent thrombosis were similar.","Sirolimus-eluting stents vs paclitaxel-eluting stents in patients with coronary artery disease: meta-analysis of randomized trials."
"564","JAMA.302","0.001",16106007,2005,"Placement of sirolimus-eluting stents or paclitaxel-eluting stents has emerged as the predominant percutaneous treatment strategy in patients with coronary artery disease (CAD). Whether there are any differences in efficacy and safety between these 2 drug-eluting stents is unclear.To compare outcomes of sirolimus-eluting and paclitaxel-eluting coronary stents on the basis of data generated by randomized head-to-head clinical trials.PubMed and the Cochrane Central Register of Controlled Trials, conference proceedings from major cardiology meetings, and Internet-based sources of information on clinical trials in cardiology from January 2003 to April 2005.Randomized trials comparing the sirolimus-eluting stent with the paclitaxel-eluting stent in patients with CAD reporting the outcomes of interest (target lesion revascularization, angiographic restenosis, stent thrombosis, myocardial infarction [MI], death, and the composite of death or MI) during a follow-up of at least 6 months.Two reviewers independently identified studies and abstracted data on sample size, baseline characteristics, and outcomes of interest.Six trials, including 3669 patients, met the selection criteria. No significant heterogeneity was found across trials. Target lesion revascularization, the primary outcome of interest, was less frequently performed in patients who were treated with the sirolimus-eluting stent (5.1%) vs the paclitaxel-eluting stent (7.8%) (odds ratio [OR], 0.64; 95% confidence interval [CI], 0.49-0.84; P = .001). Similarly, angiographic restenosis was less frequently observed among patients assigned to the sirolimus-eluting stent (9.3%) vs the paclitaxel-eluting stent (13.1%) (OR, 0.68; 95% CI, 0.55-0.86; P = .001). Event rates for sirolimus-eluting vs paclitaxel-eluting stents were 0.9% and 1.1%, respectively, for stent thrombosis (P = .62); 1.4% and 1.6%, respectively, for death (P = .56); and 4.9% and 5.8%, respectively, for the composite of death or MI (P = .23).Patients receiving sirolimus-eluting stents had a significantly lower risk of restenosis and target vessel revascularization compared with those receiving paclitaxel-eluting stents. Rates of death, death or MI, and stent thrombosis were similar.","Sirolimus-eluting stents vs paclitaxel-eluting stents in patients with coronary artery disease: meta-analysis of randomized trials."
"565","JAMA.298","0.008",16143698,2005,"The benefit of clopidogrel pretreatment before percutaneous coronary intervention (PCI) remains debated and its use has not been universally adopted.To determine if clopidogrel pretreatment before PCI in patients with recent ST-segment elevation myocardial infarction (STEMI) is superior to clopidogrel treatment initiated at the time of PCI in preventing major adverse cardiovascular events.The PCI-Clopidogrel as Adjunctive Reperfusion Therapy (CLARITY) study was a prospectively planned analysis of the 1863 patients undergoing PCI after mandated angiography in CLARITY-Thrombolysis in Myocardial Infarction (TIMI) 28, a randomized, double-blind, placebo-controlled trial of clopidogrel in patients receiving fibrinolytics for STEMI. Patients were enrolled at 319 sites in 23 countries from February 2003 through October 2004.Patients received aspirin and were randomized to receive either clopidogrel (300 mg loading dose, then 75 mg once daily) or placebo initiated with fibrinolysis and given until coronary angiography, which was performed 2 to 8 days after initiation of the study drug. For patients undergoing coronary artery stenting, it was recommended that open-label clopidogrel (including a loading dose) be administered after the diagnostic angiogram.The primary outcome was the incidence of the composite of cardiovascular death, recurrent MI, or stroke from PCI to 30 days after randomization. Secondary outcomes included MI or stroke before PCI and the aforementioned composite from randomization to 30 days.Pretreatment with clopidogrel significantly reduced the incidence of cardiovascular death, MI, or stroke following PCI (34 [3.6%] vs 58 [6.2%]; adjusted odds ratio [OR], 0.54 [95% CI, 0.35-0.85]; P = .008). Pretreatment with clopidogrel also reduced the incidence of MI or stroke prior to PCI (37 [4.0%] vs 58 [6.2%]; OR, 0.62 [95% CI, 0.40-0.95]; P = .03). Overall, pretreatment with clopidogrel resulted in a highly significant reduction in cardiovascular death, MI, or stroke from randomization through 30 days (70 [7.5%] vs 112 [12.0%]; adjusted OR, 0.59 [95% CI, 0.43-0.81]; P = .001; number needed to treat = 23). There was no significant excess in the rates of TIMI major or minor bleeding (18 [2.0%] vs 17 [1.9%]; P>.99).Clopidogrel pretreatment significantly reduces the incidence of cardiovascular death or ischemic complications both before and after PCI and without a significant increase in major or minor bleeding. These data add further support to the early use of clopidogrel in STEMI and the strategy of routine clopidogrel pretreatment in patients undergoing PCI.","Effect of clopidogrel pretreatment before percutaneous coronary intervention in patients with ST-elevation myocardial infarction treated with fibrinolytics: the PCI-CLARITY study."
"566","JAMA.299","0.03",16143698,2005,"The benefit of clopidogrel pretreatment before percutaneous coronary intervention (PCI) remains debated and its use has not been universally adopted.To determine if clopidogrel pretreatment before PCI in patients with recent ST-segment elevation myocardial infarction (STEMI) is superior to clopidogrel treatment initiated at the time of PCI in preventing major adverse cardiovascular events.The PCI-Clopidogrel as Adjunctive Reperfusion Therapy (CLARITY) study was a prospectively planned analysis of the 1863 patients undergoing PCI after mandated angiography in CLARITY-Thrombolysis in Myocardial Infarction (TIMI) 28, a randomized, double-blind, placebo-controlled trial of clopidogrel in patients receiving fibrinolytics for STEMI. Patients were enrolled at 319 sites in 23 countries from February 2003 through October 2004.Patients received aspirin and were randomized to receive either clopidogrel (300 mg loading dose, then 75 mg once daily) or placebo initiated with fibrinolysis and given until coronary angiography, which was performed 2 to 8 days after initiation of the study drug. For patients undergoing coronary artery stenting, it was recommended that open-label clopidogrel (including a loading dose) be administered after the diagnostic angiogram.The primary outcome was the incidence of the composite of cardiovascular death, recurrent MI, or stroke from PCI to 30 days after randomization. Secondary outcomes included MI or stroke before PCI and the aforementioned composite from randomization to 30 days.Pretreatment with clopidogrel significantly reduced the incidence of cardiovascular death, MI, or stroke following PCI (34 [3.6%] vs 58 [6.2%]; adjusted odds ratio [OR], 0.54 [95% CI, 0.35-0.85]; P = .008). Pretreatment with clopidogrel also reduced the incidence of MI or stroke prior to PCI (37 [4.0%] vs 58 [6.2%]; OR, 0.62 [95% CI, 0.40-0.95]; P = .03). Overall, pretreatment with clopidogrel resulted in a highly significant reduction in cardiovascular death, MI, or stroke from randomization through 30 days (70 [7.5%] vs 112 [12.0%]; adjusted OR, 0.59 [95% CI, 0.43-0.81]; P = .001; number needed to treat = 23). There was no significant excess in the rates of TIMI major or minor bleeding (18 [2.0%] vs 17 [1.9%]; P>.99).Clopidogrel pretreatment significantly reduces the incidence of cardiovascular death or ischemic complications both before and after PCI and without a significant increase in major or minor bleeding. These data add further support to the early use of clopidogrel in STEMI and the strategy of routine clopidogrel pretreatment in patients undergoing PCI.","Effect of clopidogrel pretreatment before percutaneous coronary intervention in patients with ST-elevation myocardial infarction treated with fibrinolytics: the PCI-CLARITY study."
"567","JAMA.300","0.001",16143698,2005,"The benefit of clopidogrel pretreatment before percutaneous coronary intervention (PCI) remains debated and its use has not been universally adopted.To determine if clopidogrel pretreatment before PCI in patients with recent ST-segment elevation myocardial infarction (STEMI) is superior to clopidogrel treatment initiated at the time of PCI in preventing major adverse cardiovascular events.The PCI-Clopidogrel as Adjunctive Reperfusion Therapy (CLARITY) study was a prospectively planned analysis of the 1863 patients undergoing PCI after mandated angiography in CLARITY-Thrombolysis in Myocardial Infarction (TIMI) 28, a randomized, double-blind, placebo-controlled trial of clopidogrel in patients receiving fibrinolytics for STEMI. Patients were enrolled at 319 sites in 23 countries from February 2003 through October 2004.Patients received aspirin and were randomized to receive either clopidogrel (300 mg loading dose, then 75 mg once daily) or placebo initiated with fibrinolysis and given until coronary angiography, which was performed 2 to 8 days after initiation of the study drug. For patients undergoing coronary artery stenting, it was recommended that open-label clopidogrel (including a loading dose) be administered after the diagnostic angiogram.The primary outcome was the incidence of the composite of cardiovascular death, recurrent MI, or stroke from PCI to 30 days after randomization. Secondary outcomes included MI or stroke before PCI and the aforementioned composite from randomization to 30 days.Pretreatment with clopidogrel significantly reduced the incidence of cardiovascular death, MI, or stroke following PCI (34 [3.6%] vs 58 [6.2%]; adjusted odds ratio [OR], 0.54 [95% CI, 0.35-0.85]; P = .008). Pretreatment with clopidogrel also reduced the incidence of MI or stroke prior to PCI (37 [4.0%] vs 58 [6.2%]; OR, 0.62 [95% CI, 0.40-0.95]; P = .03). Overall, pretreatment with clopidogrel resulted in a highly significant reduction in cardiovascular death, MI, or stroke from randomization through 30 days (70 [7.5%] vs 112 [12.0%]; adjusted OR, 0.59 [95% CI, 0.43-0.81]; P = .001; number needed to treat = 23). There was no significant excess in the rates of TIMI major or minor bleeding (18 [2.0%] vs 17 [1.9%]; P>.99).Clopidogrel pretreatment significantly reduces the incidence of cardiovascular death or ischemic complications both before and after PCI and without a significant increase in major or minor bleeding. These data add further support to the early use of clopidogrel in STEMI and the strategy of routine clopidogrel pretreatment in patients undergoing PCI.","Effect of clopidogrel pretreatment before percutaneous coronary intervention in patients with ST-elevation myocardial infarction treated with fibrinolytics: the PCI-CLARITY study."
"568","Lancet.321","1.00E-04",16154016,2005,"The apparent shortfall in prevention of coronary heart disease (CHD) noted in early hypertension trials has been attributed to disadvantages of the diuretics and beta blockers used. For a given reduction in blood pressure, some suggested that newer agents would confer advantages over diuretics and beta blockers. Our aim, therefore, was to compare the effect on non-fatal myocardial infarction and fatal CHD of combinations of atenolol with a thiazide versus amlodipine with perindopril.We did a multicentre, prospective, randomised controlled trial in 19 257 patients with hypertension who were aged 40-79 years and had at least three other cardiovascular risk factors. Patients were assigned either amlodipine 5-10 mg adding perindopril 4-8 mg as required (amlodipine-based regimen; n=9639) or atenolol 50-100 mg adding bendroflumethiazide 1.25-2.5 mg and potassium as required (atenolol-based regimen; n=9618). Our primary endpoint was non-fatal myocardial infarction (including silent myocardial infarction) and fatal CHD. Analysis was by intention to treat.The study was stopped prematurely after 5.5 years' median follow-up and accumulated in total 106 153 patient-years of observation. Though not significant, compared with the atenolol-based regimen, fewer individuals on the amlodipine-based regimen had a primary endpoint (429 vs 474; unadjusted HR 0.90, 95% CI 0.79-1.02, p=0.1052), fatal and non-fatal stroke (327 vs 422; 0.77, 0.66-0.89, p=0.0003), total cardiovascular events and procedures (1362 vs 1602; 0.84, 0.78-0.90, p<0.0001), and all-cause mortality (738 vs 820; 0.89, 0.81-0.99, p=0.025). The incidence of developing diabetes was less on the amlodipine-based regimen (567 vs 799; 0.70, 0.63-0.78, p<0.0001).The amlodipine-based regimen prevented more major cardiovascular events and induced less diabetes than the atenolol-based regimen. On the basis of previous trial evidence, these effects might not be entirely explained by better control of blood pressure, and this issue is addressed in the accompanying article. Nevertheless, the results have implications with respect to optimum combinations of antihypertensive agents.","Prevention of cardiovascular events with an antihypertensive regimen of amlodipine adding perindopril as required versus atenolol adding bendroflumethiazide as required, in the Anglo-Scandinavian Cardiac Outcomes Trial-Blood Pressure Lowering Arm (ASCOT-BPLA): a multicentre randomised controlled trial."
"569","Lancet.331","1.00E-04",16154016,2005,"The apparent shortfall in prevention of coronary heart disease (CHD) noted in early hypertension trials has been attributed to disadvantages of the diuretics and beta blockers used. For a given reduction in blood pressure, some suggested that newer agents would confer advantages over diuretics and beta blockers. Our aim, therefore, was to compare the effect on non-fatal myocardial infarction and fatal CHD of combinations of atenolol with a thiazide versus amlodipine with perindopril.We did a multicentre, prospective, randomised controlled trial in 19 257 patients with hypertension who were aged 40-79 years and had at least three other cardiovascular risk factors. Patients were assigned either amlodipine 5-10 mg adding perindopril 4-8 mg as required (amlodipine-based regimen; n=9639) or atenolol 50-100 mg adding bendroflumethiazide 1.25-2.5 mg and potassium as required (atenolol-based regimen; n=9618). Our primary endpoint was non-fatal myocardial infarction (including silent myocardial infarction) and fatal CHD. Analysis was by intention to treat.The study was stopped prematurely after 5.5 years' median follow-up and accumulated in total 106 153 patient-years of observation. Though not significant, compared with the atenolol-based regimen, fewer individuals on the amlodipine-based regimen had a primary endpoint (429 vs 474; unadjusted HR 0.90, 95% CI 0.79-1.02, p=0.1052), fatal and non-fatal stroke (327 vs 422; 0.77, 0.66-0.89, p=0.0003), total cardiovascular events and procedures (1362 vs 1602; 0.84, 0.78-0.90, p<0.0001), and all-cause mortality (738 vs 820; 0.89, 0.81-0.99, p=0.025). The incidence of developing diabetes was less on the amlodipine-based regimen (567 vs 799; 0.70, 0.63-0.78, p<0.0001).The amlodipine-based regimen prevented more major cardiovascular events and induced less diabetes than the atenolol-based regimen. On the basis of previous trial evidence, these effects might not be entirely explained by better control of blood pressure, and this issue is addressed in the accompanying article. Nevertheless, the results have implications with respect to optimum combinations of antihypertensive agents.","Prevention of cardiovascular events with an antihypertensive regimen of amlodipine adding perindopril as required versus atenolol adding bendroflumethiazide as required, in the Anglo-Scandinavian Cardiac Outcomes Trial-Blood Pressure Lowering Arm (ASCOT-BPLA): a multicentre randomised controlled trial."
"570","Lancet.491","0.1052",16154016,2005,"The apparent shortfall in prevention of coronary heart disease (CHD) noted in early hypertension trials has been attributed to disadvantages of the diuretics and beta blockers used. For a given reduction in blood pressure, some suggested that newer agents would confer advantages over diuretics and beta blockers. Our aim, therefore, was to compare the effect on non-fatal myocardial infarction and fatal CHD of combinations of atenolol with a thiazide versus amlodipine with perindopril.We did a multicentre, prospective, randomised controlled trial in 19 257 patients with hypertension who were aged 40-79 years and had at least three other cardiovascular risk factors. Patients were assigned either amlodipine 5-10 mg adding perindopril 4-8 mg as required (amlodipine-based regimen; n=9639) or atenolol 50-100 mg adding bendroflumethiazide 1.25-2.5 mg and potassium as required (atenolol-based regimen; n=9618). Our primary endpoint was non-fatal myocardial infarction (including silent myocardial infarction) and fatal CHD. Analysis was by intention to treat.The study was stopped prematurely after 5.5 years' median follow-up and accumulated in total 106 153 patient-years of observation. Though not significant, compared with the atenolol-based regimen, fewer individuals on the amlodipine-based regimen had a primary endpoint (429 vs 474; unadjusted HR 0.90, 95% CI 0.79-1.02, p=0.1052), fatal and non-fatal stroke (327 vs 422; 0.77, 0.66-0.89, p=0.0003), total cardiovascular events and procedures (1362 vs 1602; 0.84, 0.78-0.90, p<0.0001), and all-cause mortality (738 vs 820; 0.89, 0.81-0.99, p=0.025). The incidence of developing diabetes was less on the amlodipine-based regimen (567 vs 799; 0.70, 0.63-0.78, p<0.0001).The amlodipine-based regimen prevented more major cardiovascular events and induced less diabetes than the atenolol-based regimen. On the basis of previous trial evidence, these effects might not be entirely explained by better control of blood pressure, and this issue is addressed in the accompanying article. Nevertheless, the results have implications with respect to optimum combinations of antihypertensive agents.","Prevention of cardiovascular events with an antihypertensive regimen of amlodipine adding perindopril as required versus atenolol adding bendroflumethiazide as required, in the Anglo-Scandinavian Cardiac Outcomes Trial-Blood Pressure Lowering Arm (ASCOT-BPLA): a multicentre randomised controlled trial."
"571","Lancet.501","3.00E-04",16154016,2005,"The apparent shortfall in prevention of coronary heart disease (CHD) noted in early hypertension trials has been attributed to disadvantages of the diuretics and beta blockers used. For a given reduction in blood pressure, some suggested that newer agents would confer advantages over diuretics and beta blockers. Our aim, therefore, was to compare the effect on non-fatal myocardial infarction and fatal CHD of combinations of atenolol with a thiazide versus amlodipine with perindopril.We did a multicentre, prospective, randomised controlled trial in 19 257 patients with hypertension who were aged 40-79 years and had at least three other cardiovascular risk factors. Patients were assigned either amlodipine 5-10 mg adding perindopril 4-8 mg as required (amlodipine-based regimen; n=9639) or atenolol 50-100 mg adding bendroflumethiazide 1.25-2.5 mg and potassium as required (atenolol-based regimen; n=9618). Our primary endpoint was non-fatal myocardial infarction (including silent myocardial infarction) and fatal CHD. Analysis was by intention to treat.The study was stopped prematurely after 5.5 years' median follow-up and accumulated in total 106 153 patient-years of observation. Though not significant, compared with the atenolol-based regimen, fewer individuals on the amlodipine-based regimen had a primary endpoint (429 vs 474; unadjusted HR 0.90, 95% CI 0.79-1.02, p=0.1052), fatal and non-fatal stroke (327 vs 422; 0.77, 0.66-0.89, p=0.0003), total cardiovascular events and procedures (1362 vs 1602; 0.84, 0.78-0.90, p<0.0001), and all-cause mortality (738 vs 820; 0.89, 0.81-0.99, p=0.025). The incidence of developing diabetes was less on the amlodipine-based regimen (567 vs 799; 0.70, 0.63-0.78, p<0.0001).The amlodipine-based regimen prevented more major cardiovascular events and induced less diabetes than the atenolol-based regimen. On the basis of previous trial evidence, these effects might not be entirely explained by better control of blood pressure, and this issue is addressed in the accompanying article. Nevertheless, the results have implications with respect to optimum combinations of antihypertensive agents.","Prevention of cardiovascular events with an antihypertensive regimen of amlodipine adding perindopril as required versus atenolol adding bendroflumethiazide as required, in the Anglo-Scandinavian Cardiac Outcomes Trial-Blood Pressure Lowering Arm (ASCOT-BPLA): a multicentre randomised controlled trial."
"572","Lancet.511","0.025",16154016,2005,"The apparent shortfall in prevention of coronary heart disease (CHD) noted in early hypertension trials has been attributed to disadvantages of the diuretics and beta blockers used. For a given reduction in blood pressure, some suggested that newer agents would confer advantages over diuretics and beta blockers. Our aim, therefore, was to compare the effect on non-fatal myocardial infarction and fatal CHD of combinations of atenolol with a thiazide versus amlodipine with perindopril.We did a multicentre, prospective, randomised controlled trial in 19 257 patients with hypertension who were aged 40-79 years and had at least three other cardiovascular risk factors. Patients were assigned either amlodipine 5-10 mg adding perindopril 4-8 mg as required (amlodipine-based regimen; n=9639) or atenolol 50-100 mg adding bendroflumethiazide 1.25-2.5 mg and potassium as required (atenolol-based regimen; n=9618). Our primary endpoint was non-fatal myocardial infarction (including silent myocardial infarction) and fatal CHD. Analysis was by intention to treat.The study was stopped prematurely after 5.5 years' median follow-up and accumulated in total 106 153 patient-years of observation. Though not significant, compared with the atenolol-based regimen, fewer individuals on the amlodipine-based regimen had a primary endpoint (429 vs 474; unadjusted HR 0.90, 95% CI 0.79-1.02, p=0.1052), fatal and non-fatal stroke (327 vs 422; 0.77, 0.66-0.89, p=0.0003), total cardiovascular events and procedures (1362 vs 1602; 0.84, 0.78-0.90, p<0.0001), and all-cause mortality (738 vs 820; 0.89, 0.81-0.99, p=0.025). The incidence of developing diabetes was less on the amlodipine-based regimen (567 vs 799; 0.70, 0.63-0.78, p<0.0001).The amlodipine-based regimen prevented more major cardiovascular events and induced less diabetes than the atenolol-based regimen. On the basis of previous trial evidence, these effects might not be entirely explained by better control of blood pressure, and this issue is addressed in the accompanying article. Nevertheless, the results have implications with respect to optimum combinations of antihypertensive agents.","Prevention of cardiovascular events with an antihypertensive regimen of amlodipine adding perindopril as required versus atenolol adding bendroflumethiazide as required, in the Anglo-Scandinavian Cardiac Outcomes Trial-Blood Pressure Lowering Arm (ASCOT-BPLA): a multicentre randomised controlled trial."
"573","JAMA.2391","NA",16160132,2005,"Patients with heart failure have a wide spectrum of mortality risks. To maximize the benefit of available pharmacotherapies, patients with high mortality risk should receive high rates of drug therapy.To examine patterns of drug therapy and underlying mortality risk in patients with heart failure.In the Enhanced Feedback for Effective Cardiac Treatment (EFFECT) population-based cohort (1999-2001) of 9942 patients with heart failure hospitalized in Ontario, Canada, we evaluated 1418 patients with documented left ventricular ejection fraction of 40% or less and aged 79 years or younger with low-, average-, and high-predicted risk of death within 1 year; all patients survived to hospital discharge. Administration of angiotensin-converting enzyme (ACE) inhibitors, ACE inhibitors or angiotensin II receptor blockers (ARBs), and beta-adrenoreceptor antagonists was evaluated according to predicted risk of death.Heart failure drug administration rates at time of discharge and 90 days after hospital discharge.At hospital discharge, prescription rates for patients in the low-, average-, and high-risk groups were 81%, 73%, 60%, respectively, for ACE inhibitors; 86%, 80%, 65%, respectively, for ACE inhibitors or ARBs; and 40%, 33%, 24%, respectively, for beta-adrenoreceptor antagonists (all P<.001 for trend). Within 90 days following hospital discharge, the rates were 83%, 76%, and 61% for ACE inhibitors; 89%, 83%, and 67% for ACE inhibitors or ARBs; and 43%, 36%, and 28% for beta-adrenoreceptor antagonists for the 3 risk groups, respectively (all P<.001 for trend). The pattern of lower rates of drug administration in those patients at increasing risk was maintained up to 1 year postdischarge (P<.001). After accounting for varying survival time and potential contraindications to therapy, low-risk patients were more likely to receive ACE inhibitors or ARBs (adjusted hazard ratio [HR], 1.61; 95% confidence interval [CI], 1.49-1.74) and beta-adrenoreceptor antagonists (HR, 1.80; 95% CI, 1.60-2.01) compared with high-risk patients (both P<.001).Patients with heart failure at greatest risk of death are least likely to receive ACE inhibitors, ACE inhibitors or ARBs, and beta-adrenoreceptor antagonists. Understanding the reasons underlying this mismatch may facilitate improvements in care and outcomes for patients with heart failure.","Risk-treatment mismatch in the pharmacotherapy of heart failure."
"574","JAMA.2401","NA",16160132,2005,"Patients with heart failure have a wide spectrum of mortality risks. To maximize the benefit of available pharmacotherapies, patients with high mortality risk should receive high rates of drug therapy.To examine patterns of drug therapy and underlying mortality risk in patients with heart failure.In the Enhanced Feedback for Effective Cardiac Treatment (EFFECT) population-based cohort (1999-2001) of 9942 patients with heart failure hospitalized in Ontario, Canada, we evaluated 1418 patients with documented left ventricular ejection fraction of 40% or less and aged 79 years or younger with low-, average-, and high-predicted risk of death within 1 year; all patients survived to hospital discharge. Administration of angiotensin-converting enzyme (ACE) inhibitors, ACE inhibitors or angiotensin II receptor blockers (ARBs), and beta-adrenoreceptor antagonists was evaluated according to predicted risk of death.Heart failure drug administration rates at time of discharge and 90 days after hospital discharge.At hospital discharge, prescription rates for patients in the low-, average-, and high-risk groups were 81%, 73%, 60%, respectively, for ACE inhibitors; 86%, 80%, 65%, respectively, for ACE inhibitors or ARBs; and 40%, 33%, 24%, respectively, for beta-adrenoreceptor antagonists (all P<.001 for trend). Within 90 days following hospital discharge, the rates were 83%, 76%, and 61% for ACE inhibitors; 89%, 83%, and 67% for ACE inhibitors or ARBs; and 43%, 36%, and 28% for beta-adrenoreceptor antagonists for the 3 risk groups, respectively (all P<.001 for trend). The pattern of lower rates of drug administration in those patients at increasing risk was maintained up to 1 year postdischarge (P<.001). After accounting for varying survival time and potential contraindications to therapy, low-risk patients were more likely to receive ACE inhibitors or ARBs (adjusted hazard ratio [HR], 1.61; 95% confidence interval [CI], 1.49-1.74) and beta-adrenoreceptor antagonists (HR, 1.80; 95% CI, 1.60-2.01) compared with high-risk patients (both P<.001).Patients with heart failure at greatest risk of death are least likely to receive ACE inhibitors, ACE inhibitors or ARBs, and beta-adrenoreceptor antagonists. Understanding the reasons underlying this mismatch may facilitate improvements in care and outcomes for patients with heart failure.","Risk-treatment mismatch in the pharmacotherapy of heart failure."
"575","Lancet.30","1.00E-04",16168780,2005,"Postoperative policies of ""wait-and-see"" and radiotherapy for low-grade glioma are poorly defined. A trial in the mid 1980s established the radiation dose. In 1986 the EORTC Radiotherapy and Brain Tumor Groups initiated a prospective trial to compare early radiotherapy with delayed radiotherapy. An interim analysis has been reported. We now present the long-term results.After surgery, patients from 24 centres across Europe were randomly assigned to either early radiotherapy of 54 Gy in fractions of 1.8 Gy or deferred radiotherapy until the time of progression (control group). Patients with low-grade astrocytoma, oligodendroglioma, mixed oligoastrocytoma, and incompletely resected pilocytic astrocytoma, with a WHO performance status 0-2 were eligible. Analysis was by intention to treat, and primary endpoints were overall and progression-free survival.157 patients were assigned early radiotherapy, and 157 control. Median progression-free survival was 5.3 years in the early radiotherapy group and 3.4 years in the control group (hazard ratio 0.59, 95% CI 0.45-0.77; p<0.0001). However, overall survival was similar between groups: median survival in the radiotherapy group was 7.4 years compared with 7.2 years in the control group (hazard ratio 0.97, 95% CI 0.71-1.34; p=0.872). In the control group, 65% of patients received radiotherapy at progression. At 1 year, seizures were better controlled in the early radiotherapy group.Early radiotherapy after surgery lengthens the period without progression but does not affect overall survival. Because quality of life was not studied, it is not known whether time to progression reflects clinical deterioration. Radiotherapy could be deferred for patients with low-grade glioma who are in a good condition, provided they are carefully monitored.","Long-term efficacy of early versus delayed radiotherapy for low-grade astrocytoma and oligodendroglioma in adults: the EORTC 22845 randomised trial."
"576","Lancet.40","0.872",16168780,2005,"Postoperative policies of ""wait-and-see"" and radiotherapy for low-grade glioma are poorly defined. A trial in the mid 1980s established the radiation dose. In 1986 the EORTC Radiotherapy and Brain Tumor Groups initiated a prospective trial to compare early radiotherapy with delayed radiotherapy. An interim analysis has been reported. We now present the long-term results.After surgery, patients from 24 centres across Europe were randomly assigned to either early radiotherapy of 54 Gy in fractions of 1.8 Gy or deferred radiotherapy until the time of progression (control group). Patients with low-grade astrocytoma, oligodendroglioma, mixed oligoastrocytoma, and incompletely resected pilocytic astrocytoma, with a WHO performance status 0-2 were eligible. Analysis was by intention to treat, and primary endpoints were overall and progression-free survival.157 patients were assigned early radiotherapy, and 157 control. Median progression-free survival was 5.3 years in the early radiotherapy group and 3.4 years in the control group (hazard ratio 0.59, 95% CI 0.45-0.77; p<0.0001). However, overall survival was similar between groups: median survival in the radiotherapy group was 7.4 years compared with 7.2 years in the control group (hazard ratio 0.97, 95% CI 0.71-1.34; p=0.872). In the control group, 65% of patients received radiotherapy at progression. At 1 year, seizures were better controlled in the early radiotherapy group.Early radiotherapy after surgery lengthens the period without progression but does not affect overall survival. Because quality of life was not studied, it is not known whether time to progression reflects clinical deterioration. Radiotherapy could be deferred for patients with low-grade glioma who are in a good condition, provided they are carefully monitored.","Long-term efficacy of early versus delayed radiotherapy for low-grade astrocytoma and oligodendroglioma in adults: the EORTC 22845 randomised trial."
"577","Lancet.37","2.00E-04",16168781,2005,"The proportion of women infected with human papillomavirus (HPV) varies greatly across populations, as might the distribution of HPV types. We aimed to compare HPV-type distribution in representative samples of women from different world regions.Women were randomly selected from the general population of 13 areas from 11 countries (Nigeria, India, Vietnam, Thailand, Korea, Colombia, Argentina, Chile, the Netherlands, Italy, and Spain). A standardised protocol was used for cervical specimen collection. All HPV testing was by GP5+/6+ PCR-based EIA. The proportion of HPV-positive women infected with different HPV types was compared by study area and between pooled regions with age-adjusted odds ratios (ORs) with corresponding 95% floating CIs.15 613 women aged 15-74 years without cytological abnormalities were included in a pooled analysis. Age-standardised HPV prevalence varied nearly 20 times between populations, from 1.4% (95% CI 0.5-2.2) in Spain to 25.6% (22.4-28.8) in Nigeria. Although both overall HPV prevalence and HPV16 prevalence were highest in sub-Saharan Africa, HPV-positive women in Europe were significantly more likely to be infected with HPV16 than were those in sub-Saharan Africa (OR 2.64, p=0.0002), and were significantly less likely to be infected with high-risk HPV types other than HPV16 (OR 0.57, p=0.004) and/or low-risk HPV types (OR 0.44. p=0.0002). Women from South America had HPV-type distribution in between those from sub-Saharan Africa and Europe. Heterogeneity between areas of Asia was significant.Heterogeneity in HPV type distribution among women from different populations should be taken into account when developing screening tests for the virus and predicting the effect of vaccines on the incidence of infection.","Worldwide distribution of human papillomavirus types in cytologically normal women in the International Agency for Research on Cancer HPV prevalence surveys: a pooled analysis."
"578","Lancet.38","0.004",16168781,2005,"The proportion of women infected with human papillomavirus (HPV) varies greatly across populations, as might the distribution of HPV types. We aimed to compare HPV-type distribution in representative samples of women from different world regions.Women were randomly selected from the general population of 13 areas from 11 countries (Nigeria, India, Vietnam, Thailand, Korea, Colombia, Argentina, Chile, the Netherlands, Italy, and Spain). A standardised protocol was used for cervical specimen collection. All HPV testing was by GP5+/6+ PCR-based EIA. The proportion of HPV-positive women infected with different HPV types was compared by study area and between pooled regions with age-adjusted odds ratios (ORs) with corresponding 95% floating CIs.15 613 women aged 15-74 years without cytological abnormalities were included in a pooled analysis. Age-standardised HPV prevalence varied nearly 20 times between populations, from 1.4% (95% CI 0.5-2.2) in Spain to 25.6% (22.4-28.8) in Nigeria. Although both overall HPV prevalence and HPV16 prevalence were highest in sub-Saharan Africa, HPV-positive women in Europe were significantly more likely to be infected with HPV16 than were those in sub-Saharan Africa (OR 2.64, p=0.0002), and were significantly less likely to be infected with high-risk HPV types other than HPV16 (OR 0.57, p=0.004) and/or low-risk HPV types (OR 0.44. p=0.0002). Women from South America had HPV-type distribution in between those from sub-Saharan Africa and Europe. Heterogeneity between areas of Asia was significant.Heterogeneity in HPV type distribution among women from different populations should be taken into account when developing screening tests for the virus and predicting the effect of vaccines on the incidence of infection.","Worldwide distribution of human papillomavirus types in cytologically normal women in the International Agency for Research on Cancer HPV prevalence surveys: a pooled analysis."
"579","Lancet.39","2.00E-04",16168781,2005,"The proportion of women infected with human papillomavirus (HPV) varies greatly across populations, as might the distribution of HPV types. We aimed to compare HPV-type distribution in representative samples of women from different world regions.Women were randomly selected from the general population of 13 areas from 11 countries (Nigeria, India, Vietnam, Thailand, Korea, Colombia, Argentina, Chile, the Netherlands, Italy, and Spain). A standardised protocol was used for cervical specimen collection. All HPV testing was by GP5+/6+ PCR-based EIA. The proportion of HPV-positive women infected with different HPV types was compared by study area and between pooled regions with age-adjusted odds ratios (ORs) with corresponding 95% floating CIs.15 613 women aged 15-74 years without cytological abnormalities were included in a pooled analysis. Age-standardised HPV prevalence varied nearly 20 times between populations, from 1.4% (95% CI 0.5-2.2) in Spain to 25.6% (22.4-28.8) in Nigeria. Although both overall HPV prevalence and HPV16 prevalence were highest in sub-Saharan Africa, HPV-positive women in Europe were significantly more likely to be infected with HPV16 than were those in sub-Saharan Africa (OR 2.64, p=0.0002), and were significantly less likely to be infected with high-risk HPV types other than HPV16 (OR 0.57, p=0.004) and/or low-risk HPV types (OR 0.44. p=0.0002). Women from South America had HPV-type distribution in between those from sub-Saharan Africa and Europe. Heterogeneity between areas of Asia was significant.Heterogeneity in HPV type distribution among women from different populations should be taken into account when developing screening tests for the virus and predicting the effect of vaccines on the incidence of infection.","Worldwide distribution of human papillomavirus types in cytologically normal women in the International Agency for Research on Cancer HPV prevalence surveys: a pooled analysis."
"580","JAMA.261","0.001",16189362,2005,"Despite lung-specific in vitro and in vivo studies that support a chemopreventive role for phytoestrogens, there has been little epidemiologic research focused on dietary intake of phytoestrogens and risk of lung cancer.To examine the relationship between dietary intake of phytoestrogens and risk of lung cancer.Ongoing US case-control study of 1674 patients with lung cancer (cases) and 1735 matched healthy controls. From July 1995 through October 2003, participants were personally interviewed with epidemiologic and food frequency questionnaires to collect demographic information and to quantify dietary intake of 12 individual phytoestrogens.Risk of lung cancer, estimated using unconditional multivariable logistic regression analyses stratified by sex and smoking status and adjusted for established and putative lung cancer risk factors.Reductions in risk of lung cancer tended to increase with each increasing quartile of phytoestrogen intake. The highest quartiles of total phytosterols, isoflavones, lignans, and phytoestrogens were each associated with reductions in risk of lung cancer ranging from 21% for phytosterols (odds ratio [OR], 0.79; 95% confidence interval [CI], 0.64-0.97; P = .03 for trend) to 46% for total phytoestrogens from food sources only (OR, 0.54; 95% CI, 0.42-0.70; P<.001 for trend). Sex-specific effects were also apparent. For men, statistically significant trends for decreasing risk with increasing intake were noted for each phytoestrogen group, with protective effects for the highest quartile of intake ranging from 24% for phytosterols (OR, 0.76; 95% CI, 0.56-1.02; P = .04 for trend) to 44% for isoflavones (OR, 0.56; 95% CI, 0.41-0.76; P<.001 for trend), while in women, significant trends were only present for intake of total phytoestrogens from food sources only, with a 34% (OR, 0.66; 95% CI, 0.46-0.96; P = .01 for trend) protective effect for the highest quartile of intake. The apparent benefits of high phytoestrogen intake were evident in both never and current smokers but less apparent in former smokers. In women, statistically significant joint effects were evident between hormone therapy use and phytoestrogen intake. Specifically, high intake of the lignans enterolactone and enterodiol and use of hormone therapy were associated with a 50% (OR, 0.50; 95% CI, 0.31-0.68; P = .04 for interaction) reduction in risk of lung cancer.While there are limitations and concerns regarding case-control studies of diet and cancer, these data provide further support for the limited but growing epidemiologic evidence that phytoestrogens are associated with a decrease in risk of lung cancer. Confirmation of these findings is still required in large-scale, hypothesis-driven, prospective studies.","Dietary phytoestrogens and lung cancer risk."
"581","JAMA.262","0.001",16189362,2005,"Despite lung-specific in vitro and in vivo studies that support a chemopreventive role for phytoestrogens, there has been little epidemiologic research focused on dietary intake of phytoestrogens and risk of lung cancer.To examine the relationship between dietary intake of phytoestrogens and risk of lung cancer.Ongoing US case-control study of 1674 patients with lung cancer (cases) and 1735 matched healthy controls. From July 1995 through October 2003, participants were personally interviewed with epidemiologic and food frequency questionnaires to collect demographic information and to quantify dietary intake of 12 individual phytoestrogens.Risk of lung cancer, estimated using unconditional multivariable logistic regression analyses stratified by sex and smoking status and adjusted for established and putative lung cancer risk factors.Reductions in risk of lung cancer tended to increase with each increasing quartile of phytoestrogen intake. The highest quartiles of total phytosterols, isoflavones, lignans, and phytoestrogens were each associated with reductions in risk of lung cancer ranging from 21% for phytosterols (odds ratio [OR], 0.79; 95% confidence interval [CI], 0.64-0.97; P = .03 for trend) to 46% for total phytoestrogens from food sources only (OR, 0.54; 95% CI, 0.42-0.70; P<.001 for trend). Sex-specific effects were also apparent. For men, statistically significant trends for decreasing risk with increasing intake were noted for each phytoestrogen group, with protective effects for the highest quartile of intake ranging from 24% for phytosterols (OR, 0.76; 95% CI, 0.56-1.02; P = .04 for trend) to 44% for isoflavones (OR, 0.56; 95% CI, 0.41-0.76; P<.001 for trend), while in women, significant trends were only present for intake of total phytoestrogens from food sources only, with a 34% (OR, 0.66; 95% CI, 0.46-0.96; P = .01 for trend) protective effect for the highest quartile of intake. The apparent benefits of high phytoestrogen intake were evident in both never and current smokers but less apparent in former smokers. In women, statistically significant joint effects were evident between hormone therapy use and phytoestrogen intake. Specifically, high intake of the lignans enterolactone and enterodiol and use of hormone therapy were associated with a 50% (OR, 0.50; 95% CI, 0.31-0.68; P = .04 for interaction) reduction in risk of lung cancer.While there are limitations and concerns regarding case-control studies of diet and cancer, these data provide further support for the limited but growing epidemiologic evidence that phytoestrogens are associated with a decrease in risk of lung cancer. Confirmation of these findings is still required in large-scale, hypothesis-driven, prospective studies.","Dietary phytoestrogens and lung cancer risk."
"582","JAMA.294","0.03",16189362,2005,"Despite lung-specific in vitro and in vivo studies that support a chemopreventive role for phytoestrogens, there has been little epidemiologic research focused on dietary intake of phytoestrogens and risk of lung cancer.To examine the relationship between dietary intake of phytoestrogens and risk of lung cancer.Ongoing US case-control study of 1674 patients with lung cancer (cases) and 1735 matched healthy controls. From July 1995 through October 2003, participants were personally interviewed with epidemiologic and food frequency questionnaires to collect demographic information and to quantify dietary intake of 12 individual phytoestrogens.Risk of lung cancer, estimated using unconditional multivariable logistic regression analyses stratified by sex and smoking status and adjusted for established and putative lung cancer risk factors.Reductions in risk of lung cancer tended to increase with each increasing quartile of phytoestrogen intake. The highest quartiles of total phytosterols, isoflavones, lignans, and phytoestrogens were each associated with reductions in risk of lung cancer ranging from 21% for phytosterols (odds ratio [OR], 0.79; 95% confidence interval [CI], 0.64-0.97; P = .03 for trend) to 46% for total phytoestrogens from food sources only (OR, 0.54; 95% CI, 0.42-0.70; P<.001 for trend). Sex-specific effects were also apparent. For men, statistically significant trends for decreasing risk with increasing intake were noted for each phytoestrogen group, with protective effects for the highest quartile of intake ranging from 24% for phytosterols (OR, 0.76; 95% CI, 0.56-1.02; P = .04 for trend) to 44% for isoflavones (OR, 0.56; 95% CI, 0.41-0.76; P<.001 for trend), while in women, significant trends were only present for intake of total phytoestrogens from food sources only, with a 34% (OR, 0.66; 95% CI, 0.46-0.96; P = .01 for trend) protective effect for the highest quartile of intake. The apparent benefits of high phytoestrogen intake were evident in both never and current smokers but less apparent in former smokers. In women, statistically significant joint effects were evident between hormone therapy use and phytoestrogen intake. Specifically, high intake of the lignans enterolactone and enterodiol and use of hormone therapy were associated with a 50% (OR, 0.50; 95% CI, 0.31-0.68; P = .04 for interaction) reduction in risk of lung cancer.While there are limitations and concerns regarding case-control studies of diet and cancer, these data provide further support for the limited but growing epidemiologic evidence that phytoestrogens are associated with a decrease in risk of lung cancer. Confirmation of these findings is still required in large-scale, hypothesis-driven, prospective studies.","Dietary phytoestrogens and lung cancer risk."
"583","JAMA.295","0.04",16189362,2005,"Despite lung-specific in vitro and in vivo studies that support a chemopreventive role for phytoestrogens, there has been little epidemiologic research focused on dietary intake of phytoestrogens and risk of lung cancer.To examine the relationship between dietary intake of phytoestrogens and risk of lung cancer.Ongoing US case-control study of 1674 patients with lung cancer (cases) and 1735 matched healthy controls. From July 1995 through October 2003, participants were personally interviewed with epidemiologic and food frequency questionnaires to collect demographic information and to quantify dietary intake of 12 individual phytoestrogens.Risk of lung cancer, estimated using unconditional multivariable logistic regression analyses stratified by sex and smoking status and adjusted for established and putative lung cancer risk factors.Reductions in risk of lung cancer tended to increase with each increasing quartile of phytoestrogen intake. The highest quartiles of total phytosterols, isoflavones, lignans, and phytoestrogens were each associated with reductions in risk of lung cancer ranging from 21% for phytosterols (odds ratio [OR], 0.79; 95% confidence interval [CI], 0.64-0.97; P = .03 for trend) to 46% for total phytoestrogens from food sources only (OR, 0.54; 95% CI, 0.42-0.70; P<.001 for trend). Sex-specific effects were also apparent. For men, statistically significant trends for decreasing risk with increasing intake were noted for each phytoestrogen group, with protective effects for the highest quartile of intake ranging from 24% for phytosterols (OR, 0.76; 95% CI, 0.56-1.02; P = .04 for trend) to 44% for isoflavones (OR, 0.56; 95% CI, 0.41-0.76; P<.001 for trend), while in women, significant trends were only present for intake of total phytoestrogens from food sources only, with a 34% (OR, 0.66; 95% CI, 0.46-0.96; P = .01 for trend) protective effect for the highest quartile of intake. The apparent benefits of high phytoestrogen intake were evident in both never and current smokers but less apparent in former smokers. In women, statistically significant joint effects were evident between hormone therapy use and phytoestrogen intake. Specifically, high intake of the lignans enterolactone and enterodiol and use of hormone therapy were associated with a 50% (OR, 0.50; 95% CI, 0.31-0.68; P = .04 for interaction) reduction in risk of lung cancer.While there are limitations and concerns regarding case-control studies of diet and cancer, these data provide further support for the limited but growing epidemiologic evidence that phytoestrogens are associated with a decrease in risk of lung cancer. Confirmation of these findings is still required in large-scale, hypothesis-driven, prospective studies.","Dietary phytoestrogens and lung cancer risk."
"584","JAMA.296","0.01",16189362,2005,"Despite lung-specific in vitro and in vivo studies that support a chemopreventive role for phytoestrogens, there has been little epidemiologic research focused on dietary intake of phytoestrogens and risk of lung cancer.To examine the relationship between dietary intake of phytoestrogens and risk of lung cancer.Ongoing US case-control study of 1674 patients with lung cancer (cases) and 1735 matched healthy controls. From July 1995 through October 2003, participants were personally interviewed with epidemiologic and food frequency questionnaires to collect demographic information and to quantify dietary intake of 12 individual phytoestrogens.Risk of lung cancer, estimated using unconditional multivariable logistic regression analyses stratified by sex and smoking status and adjusted for established and putative lung cancer risk factors.Reductions in risk of lung cancer tended to increase with each increasing quartile of phytoestrogen intake. The highest quartiles of total phytosterols, isoflavones, lignans, and phytoestrogens were each associated with reductions in risk of lung cancer ranging from 21% for phytosterols (odds ratio [OR], 0.79; 95% confidence interval [CI], 0.64-0.97; P = .03 for trend) to 46% for total phytoestrogens from food sources only (OR, 0.54; 95% CI, 0.42-0.70; P<.001 for trend). Sex-specific effects were also apparent. For men, statistically significant trends for decreasing risk with increasing intake were noted for each phytoestrogen group, with protective effects for the highest quartile of intake ranging from 24% for phytosterols (OR, 0.76; 95% CI, 0.56-1.02; P = .04 for trend) to 44% for isoflavones (OR, 0.56; 95% CI, 0.41-0.76; P<.001 for trend), while in women, significant trends were only present for intake of total phytoestrogens from food sources only, with a 34% (OR, 0.66; 95% CI, 0.46-0.96; P = .01 for trend) protective effect for the highest quartile of intake. The apparent benefits of high phytoestrogen intake were evident in both never and current smokers but less apparent in former smokers. In women, statistically significant joint effects were evident between hormone therapy use and phytoestrogen intake. Specifically, high intake of the lignans enterolactone and enterodiol and use of hormone therapy were associated with a 50% (OR, 0.50; 95% CI, 0.31-0.68; P = .04 for interaction) reduction in risk of lung cancer.While there are limitations and concerns regarding case-control studies of diet and cancer, these data provide further support for the limited but growing epidemiologic evidence that phytoestrogens are associated with a decrease in risk of lung cancer. Confirmation of these findings is still required in large-scale, hypothesis-driven, prospective studies.","Dietary phytoestrogens and lung cancer risk."
"585","JAMA.297","0.04",16189362,2005,"Despite lung-specific in vitro and in vivo studies that support a chemopreventive role for phytoestrogens, there has been little epidemiologic research focused on dietary intake of phytoestrogens and risk of lung cancer.To examine the relationship between dietary intake of phytoestrogens and risk of lung cancer.Ongoing US case-control study of 1674 patients with lung cancer (cases) and 1735 matched healthy controls. From July 1995 through October 2003, participants were personally interviewed with epidemiologic and food frequency questionnaires to collect demographic information and to quantify dietary intake of 12 individual phytoestrogens.Risk of lung cancer, estimated using unconditional multivariable logistic regression analyses stratified by sex and smoking status and adjusted for established and putative lung cancer risk factors.Reductions in risk of lung cancer tended to increase with each increasing quartile of phytoestrogen intake. The highest quartiles of total phytosterols, isoflavones, lignans, and phytoestrogens were each associated with reductions in risk of lung cancer ranging from 21% for phytosterols (odds ratio [OR], 0.79; 95% confidence interval [CI], 0.64-0.97; P = .03 for trend) to 46% for total phytoestrogens from food sources only (OR, 0.54; 95% CI, 0.42-0.70; P<.001 for trend). Sex-specific effects were also apparent. For men, statistically significant trends for decreasing risk with increasing intake were noted for each phytoestrogen group, with protective effects for the highest quartile of intake ranging from 24% for phytosterols (OR, 0.76; 95% CI, 0.56-1.02; P = .04 for trend) to 44% for isoflavones (OR, 0.56; 95% CI, 0.41-0.76; P<.001 for trend), while in women, significant trends were only present for intake of total phytoestrogens from food sources only, with a 34% (OR, 0.66; 95% CI, 0.46-0.96; P = .01 for trend) protective effect for the highest quartile of intake. The apparent benefits of high phytoestrogen intake were evident in both never and current smokers but less apparent in former smokers. In women, statistically significant joint effects were evident between hormone therapy use and phytoestrogen intake. Specifically, high intake of the lignans enterolactone and enterodiol and use of hormone therapy were associated with a 50% (OR, 0.50; 95% CI, 0.31-0.68; P = .04 for interaction) reduction in risk of lung cancer.While there are limitations and concerns regarding case-control studies of diet and cancer, these data provide further support for the limited but growing epidemiologic evidence that phytoestrogens are associated with a decrease in risk of lung cancer. Confirmation of these findings is still required in large-scale, hypothesis-driven, prospective studies.","Dietary phytoestrogens and lung cancer risk."
"586","JAMA.2751","0.03",16189366,2005,"Previous data support an association between polymorphisms of the beta1- and beta2-adrenergic receptors (ADRB1 and ADRB2) and surrogate end points of response to beta-adrenergic blocker therapy. However, no associations between these polymorphisms and mortality have been demonstrated.To evaluate the effect of ADRB1 Arg389Gly (1165 CG), Ser49Gly (145 AG), and ADRB2 Gly16Arg (46 GA), Gln27Glu (79 CG) genotypes on survival among patients discharged with prescribed beta-blockers after an acute coronary syndrome (ACS).Prospective cohort study of 735 ACS patients admitted to 2 Kansas City, Mo, medical centers between March 2001 and October 2002; 597 patients were discharged with beta-blocker therapy.Multivariable-adjusted time to all-cause 3-year mortality.There were 84 deaths during follow-up. There was a significant association between ADRB2 genotype and 3-year mortality among patients prescribed beta-blocker therapy. For the 79 CG polymorphism, Kaplan-Meier 3-year mortality rates were 16% (35 deaths), 11% (27 deaths), and 6% (4 deaths) for the CC, CG, and GG genotypes, respectively (P = .03; adjusted hazard ratios [AHRs], 0.51 [95% confidence interval {CI}, 0.30-0.87] for CG vs CC and 0.24 (95% CI, 0.09-0.68) for GG vs CC, P = .004). For the ADRB2 46 GA polymorphism, 3-year Kaplan-Meier mortality estimates were 10% (17 deaths), 10% (28 deaths), and 20% (20 deaths) for the GG, GA, and AA genotypes, respectively (P = .005; AHRs, 0.48 [95% CI, 0.27-0.86] for GA vs AA and 0.44 [95% CI, 0.22-0.85] for GG vs AA, P = .02). No mortality difference between genotypes was found among patients not discharged with beta-blocker therapy for either the 79 CG or 46 GA polymorphisms (P = .98 and P = .49, respectively). The ADRB2 diplotype and compound genotypes were predictive of survival in patients treated with beta-blockers (P = .04 and P = .002; AHRs, 5.36 [95% CI, 1.83-15.69] and 2.41 [95% CI, 0.86-6.74] for 46 A homozygous and composite heterozygous vs 79 G homozygous, respectively). No association of the ADRB1 variants with mortality was observed in either the beta-blocker or no beta-blocker groups.Patients prescribed beta-blocker therapy after an ACS have differential survival associated with their ADRB2 genotypes. Further assessment of the benefits of beta-blocker therapy in high-risk genotype groups may be warranted.","Beta2-adrenergic receptor genotype and survival among patients receiving beta-blocker therapy after an acute coronary syndrome."
"587","JAMA.2761","0.004",16189366,2005,"Previous data support an association between polymorphisms of the beta1- and beta2-adrenergic receptors (ADRB1 and ADRB2) and surrogate end points of response to beta-adrenergic blocker therapy. However, no associations between these polymorphisms and mortality have been demonstrated.To evaluate the effect of ADRB1 Arg389Gly (1165 CG), Ser49Gly (145 AG), and ADRB2 Gly16Arg (46 GA), Gln27Glu (79 CG) genotypes on survival among patients discharged with prescribed beta-blockers after an acute coronary syndrome (ACS).Prospective cohort study of 735 ACS patients admitted to 2 Kansas City, Mo, medical centers between March 2001 and October 2002; 597 patients were discharged with beta-blocker therapy.Multivariable-adjusted time to all-cause 3-year mortality.There were 84 deaths during follow-up. There was a significant association between ADRB2 genotype and 3-year mortality among patients prescribed beta-blocker therapy. For the 79 CG polymorphism, Kaplan-Meier 3-year mortality rates were 16% (35 deaths), 11% (27 deaths), and 6% (4 deaths) for the CC, CG, and GG genotypes, respectively (P = .03; adjusted hazard ratios [AHRs], 0.51 [95% confidence interval {CI}, 0.30-0.87] for CG vs CC and 0.24 (95% CI, 0.09-0.68) for GG vs CC, P = .004). For the ADRB2 46 GA polymorphism, 3-year Kaplan-Meier mortality estimates were 10% (17 deaths), 10% (28 deaths), and 20% (20 deaths) for the GG, GA, and AA genotypes, respectively (P = .005; AHRs, 0.48 [95% CI, 0.27-0.86] for GA vs AA and 0.44 [95% CI, 0.22-0.85] for GG vs AA, P = .02). No mortality difference between genotypes was found among patients not discharged with beta-blocker therapy for either the 79 CG or 46 GA polymorphisms (P = .98 and P = .49, respectively). The ADRB2 diplotype and compound genotypes were predictive of survival in patients treated with beta-blockers (P = .04 and P = .002; AHRs, 5.36 [95% CI, 1.83-15.69] and 2.41 [95% CI, 0.86-6.74] for 46 A homozygous and composite heterozygous vs 79 G homozygous, respectively). No association of the ADRB1 variants with mortality was observed in either the beta-blocker or no beta-blocker groups.Patients prescribed beta-blocker therapy after an ACS have differential survival associated with their ADRB2 genotypes. Further assessment of the benefits of beta-blocker therapy in high-risk genotype groups may be warranted.","Beta2-adrenergic receptor genotype and survival among patients receiving beta-blocker therapy after an acute coronary syndrome."
"588","JAMA.2771","0.005",16189366,2005,"Previous data support an association between polymorphisms of the beta1- and beta2-adrenergic receptors (ADRB1 and ADRB2) and surrogate end points of response to beta-adrenergic blocker therapy. However, no associations between these polymorphisms and mortality have been demonstrated.To evaluate the effect of ADRB1 Arg389Gly (1165 CG), Ser49Gly (145 AG), and ADRB2 Gly16Arg (46 GA), Gln27Glu (79 CG) genotypes on survival among patients discharged with prescribed beta-blockers after an acute coronary syndrome (ACS).Prospective cohort study of 735 ACS patients admitted to 2 Kansas City, Mo, medical centers between March 2001 and October 2002; 597 patients were discharged with beta-blocker therapy.Multivariable-adjusted time to all-cause 3-year mortality.There were 84 deaths during follow-up. There was a significant association between ADRB2 genotype and 3-year mortality among patients prescribed beta-blocker therapy. For the 79 CG polymorphism, Kaplan-Meier 3-year mortality rates were 16% (35 deaths), 11% (27 deaths), and 6% (4 deaths) for the CC, CG, and GG genotypes, respectively (P = .03; adjusted hazard ratios [AHRs], 0.51 [95% confidence interval {CI}, 0.30-0.87] for CG vs CC and 0.24 (95% CI, 0.09-0.68) for GG vs CC, P = .004). For the ADRB2 46 GA polymorphism, 3-year Kaplan-Meier mortality estimates were 10% (17 deaths), 10% (28 deaths), and 20% (20 deaths) for the GG, GA, and AA genotypes, respectively (P = .005; AHRs, 0.48 [95% CI, 0.27-0.86] for GA vs AA and 0.44 [95% CI, 0.22-0.85] for GG vs AA, P = .02). No mortality difference between genotypes was found among patients not discharged with beta-blocker therapy for either the 79 CG or 46 GA polymorphisms (P = .98 and P = .49, respectively). The ADRB2 diplotype and compound genotypes were predictive of survival in patients treated with beta-blockers (P = .04 and P = .002; AHRs, 5.36 [95% CI, 1.83-15.69] and 2.41 [95% CI, 0.86-6.74] for 46 A homozygous and composite heterozygous vs 79 G homozygous, respectively). No association of the ADRB1 variants with mortality was observed in either the beta-blocker or no beta-blocker groups.Patients prescribed beta-blocker therapy after an ACS have differential survival associated with their ADRB2 genotypes. Further assessment of the benefits of beta-blocker therapy in high-risk genotype groups may be warranted.","Beta2-adrenergic receptor genotype and survival among patients receiving beta-blocker therapy after an acute coronary syndrome."
"589","JAMA.2781","0.02",16189366,2005,"Previous data support an association between polymorphisms of the beta1- and beta2-adrenergic receptors (ADRB1 and ADRB2) and surrogate end points of response to beta-adrenergic blocker therapy. However, no associations between these polymorphisms and mortality have been demonstrated.To evaluate the effect of ADRB1 Arg389Gly (1165 CG), Ser49Gly (145 AG), and ADRB2 Gly16Arg (46 GA), Gln27Glu (79 CG) genotypes on survival among patients discharged with prescribed beta-blockers after an acute coronary syndrome (ACS).Prospective cohort study of 735 ACS patients admitted to 2 Kansas City, Mo, medical centers between March 2001 and October 2002; 597 patients were discharged with beta-blocker therapy.Multivariable-adjusted time to all-cause 3-year mortality.There were 84 deaths during follow-up. There was a significant association between ADRB2 genotype and 3-year mortality among patients prescribed beta-blocker therapy. For the 79 CG polymorphism, Kaplan-Meier 3-year mortality rates were 16% (35 deaths), 11% (27 deaths), and 6% (4 deaths) for the CC, CG, and GG genotypes, respectively (P = .03; adjusted hazard ratios [AHRs], 0.51 [95% confidence interval {CI}, 0.30-0.87] for CG vs CC and 0.24 (95% CI, 0.09-0.68) for GG vs CC, P = .004). For the ADRB2 46 GA polymorphism, 3-year Kaplan-Meier mortality estimates were 10% (17 deaths), 10% (28 deaths), and 20% (20 deaths) for the GG, GA, and AA genotypes, respectively (P = .005; AHRs, 0.48 [95% CI, 0.27-0.86] for GA vs AA and 0.44 [95% CI, 0.22-0.85] for GG vs AA, P = .02). No mortality difference between genotypes was found among patients not discharged with beta-blocker therapy for either the 79 CG or 46 GA polymorphisms (P = .98 and P = .49, respectively). The ADRB2 diplotype and compound genotypes were predictive of survival in patients treated with beta-blockers (P = .04 and P = .002; AHRs, 5.36 [95% CI, 1.83-15.69] and 2.41 [95% CI, 0.86-6.74] for 46 A homozygous and composite heterozygous vs 79 G homozygous, respectively). No association of the ADRB1 variants with mortality was observed in either the beta-blocker or no beta-blocker groups.Patients prescribed beta-blocker therapy after an ACS have differential survival associated with their ADRB2 genotypes. Further assessment of the benefits of beta-blocker therapy in high-risk genotype groups may be warranted.","Beta2-adrenergic receptor genotype and survival among patients receiving beta-blocker therapy after an acute coronary syndrome."
"590","JAMA.2811","0.04",16189366,2005,"Previous data support an association between polymorphisms of the beta1- and beta2-adrenergic receptors (ADRB1 and ADRB2) and surrogate end points of response to beta-adrenergic blocker therapy. However, no associations between these polymorphisms and mortality have been demonstrated.To evaluate the effect of ADRB1 Arg389Gly (1165 CG), Ser49Gly (145 AG), and ADRB2 Gly16Arg (46 GA), Gln27Glu (79 CG) genotypes on survival among patients discharged with prescribed beta-blockers after an acute coronary syndrome (ACS).Prospective cohort study of 735 ACS patients admitted to 2 Kansas City, Mo, medical centers between March 2001 and October 2002; 597 patients were discharged with beta-blocker therapy.Multivariable-adjusted time to all-cause 3-year mortality.There were 84 deaths during follow-up. There was a significant association between ADRB2 genotype and 3-year mortality among patients prescribed beta-blocker therapy. For the 79 CG polymorphism, Kaplan-Meier 3-year mortality rates were 16% (35 deaths), 11% (27 deaths), and 6% (4 deaths) for the CC, CG, and GG genotypes, respectively (P = .03; adjusted hazard ratios [AHRs], 0.51 [95% confidence interval {CI}, 0.30-0.87] for CG vs CC and 0.24 (95% CI, 0.09-0.68) for GG vs CC, P = .004). For the ADRB2 46 GA polymorphism, 3-year Kaplan-Meier mortality estimates were 10% (17 deaths), 10% (28 deaths), and 20% (20 deaths) for the GG, GA, and AA genotypes, respectively (P = .005; AHRs, 0.48 [95% CI, 0.27-0.86] for GA vs AA and 0.44 [95% CI, 0.22-0.85] for GG vs AA, P = .02). No mortality difference between genotypes was found among patients not discharged with beta-blocker therapy for either the 79 CG or 46 GA polymorphisms (P = .98 and P = .49, respectively). The ADRB2 diplotype and compound genotypes were predictive of survival in patients treated with beta-blockers (P = .04 and P = .002; AHRs, 5.36 [95% CI, 1.83-15.69] and 2.41 [95% CI, 0.86-6.74] for 46 A homozygous and composite heterozygous vs 79 G homozygous, respectively). No association of the ADRB1 variants with mortality was observed in either the beta-blocker or no beta-blocker groups.Patients prescribed beta-blocker therapy after an ACS have differential survival associated with their ADRB2 genotypes. Further assessment of the benefits of beta-blocker therapy in high-risk genotype groups may be warranted.","Beta2-adrenergic receptor genotype and survival among patients receiving beta-blocker therapy after an acute coronary syndrome."
"591","JAMA.2821","0.002",16189366,2005,"Previous data support an association between polymorphisms of the beta1- and beta2-adrenergic receptors (ADRB1 and ADRB2) and surrogate end points of response to beta-adrenergic blocker therapy. However, no associations between these polymorphisms and mortality have been demonstrated.To evaluate the effect of ADRB1 Arg389Gly (1165 CG), Ser49Gly (145 AG), and ADRB2 Gly16Arg (46 GA), Gln27Glu (79 CG) genotypes on survival among patients discharged with prescribed beta-blockers after an acute coronary syndrome (ACS).Prospective cohort study of 735 ACS patients admitted to 2 Kansas City, Mo, medical centers between March 2001 and October 2002; 597 patients were discharged with beta-blocker therapy.Multivariable-adjusted time to all-cause 3-year mortality.There were 84 deaths during follow-up. There was a significant association between ADRB2 genotype and 3-year mortality among patients prescribed beta-blocker therapy. For the 79 CG polymorphism, Kaplan-Meier 3-year mortality rates were 16% (35 deaths), 11% (27 deaths), and 6% (4 deaths) for the CC, CG, and GG genotypes, respectively (P = .03; adjusted hazard ratios [AHRs], 0.51 [95% confidence interval {CI}, 0.30-0.87] for CG vs CC and 0.24 (95% CI, 0.09-0.68) for GG vs CC, P = .004). For the ADRB2 46 GA polymorphism, 3-year Kaplan-Meier mortality estimates were 10% (17 deaths), 10% (28 deaths), and 20% (20 deaths) for the GG, GA, and AA genotypes, respectively (P = .005; AHRs, 0.48 [95% CI, 0.27-0.86] for GA vs AA and 0.44 [95% CI, 0.22-0.85] for GG vs AA, P = .02). No mortality difference between genotypes was found among patients not discharged with beta-blocker therapy for either the 79 CG or 46 GA polymorphisms (P = .98 and P = .49, respectively). The ADRB2 diplotype and compound genotypes were predictive of survival in patients treated with beta-blockers (P = .04 and P = .002; AHRs, 5.36 [95% CI, 1.83-15.69] and 2.41 [95% CI, 0.86-6.74] for 46 A homozygous and composite heterozygous vs 79 G homozygous, respectively). No association of the ADRB1 variants with mortality was observed in either the beta-blocker or no beta-blocker groups.Patients prescribed beta-blocker therapy after an ACS have differential survival associated with their ADRB2 genotypes. Further assessment of the benefits of beta-blocker therapy in high-risk genotype groups may be warranted.","Beta2-adrenergic receptor genotype and survival among patients receiving beta-blocker therapy after an acute coronary syndrome."
"592","JAMA.289","0.99",16204662,2005,"Pulmonary artery catheters (PACs) have been used to guide therapy in multiple settings, but recent studies have raised concerns that PACs may lead to increased mortality in hospitalized patients.To determine whether PAC use is safe and improves clinical outcomes in patients hospitalized with severe symptomatic and recurrent heart failure.The Evaluation Study of Congestive Heart Failure and Pulmonary Artery Catheterization Effectiveness (ESCAPE) was a randomized controlled trial of 433 patients at 26 sites conducted from January 18, 2000, to November 17, 2003. Patients were assigned to receive therapy guided by clinical assessment and a PAC or clinical assessment alone. The target in both groups was resolution of clinical congestion, with additional PAC targets of a pulmonary capillary wedge pressure of 15 mm Hg and a right atrial pressure of 8 mm Hg. Medications were not specified, but inotrope use was explicitly discouraged.The primary end point was days alive out of the hospital during the first 6 months, with secondary end points of exercise, quality of life, biochemical, and echocardiographic changes.Severity of illness was reflected by the following values: average left ventricular ejection fraction, 19%; systolic blood pressure, 106 mm Hg; sodium level, 137 mEq/L; urea nitrogen, 35 mg/dL (12.40 mmol/L); and creatinine, 1.5 mg/dL (132.6 micromol/L). Therapy in both groups led to substantial reduction in symptoms, jugular venous pressure, and edema. Use of the PAC did not significantly affect the primary end point of days alive and out of the hospital during the first 6 months (133 days vs 135 days; hazard ratio [HR], 1.00 [95% confidence interval {CI}, 0.82-1.21]; P = .99), mortality (43 patients [10%] vs 38 patients [9%]; odds ratio [OR], 1.26 [95% CI, 0.78-2.03]; P = .35), or the number of days hospitalized (8.7 vs 8.3; HR, 1.04 [95% CI, 0.86-1.27]; P = .67). In-hospital adverse events were more common among patients in the PAC group (47 [21.9%] vs 25 [11.5%]; P = .04). There were no deaths related to PAC use, and no difference for in-hospital plus 30-day mortality (10 [4.7%] vs 11 [5.0%]; OR, 0.97 [95% CI, 0.38-2.22]; P = .97). Exercise and quality of life end points improved in both groups with a trend toward greater improvement with the PAC, which reached significance for the time trade-off at all time points after randomization.Therapy to reduce volume overload during hospitalization for heart failure led to marked improvement in signs and symptoms of elevated filling pressures with or without the PAC. Addition of the PAC to careful clinical assessment increased anticipated adverse events, but did not affect overall mortality and hospitalization. Future trials should test noninvasive assessments with specific treatment strategies that could be used to better tailor therapy for both survival time and survival quality as valued by patients.","Evaluation study of congestive heart failure and pulmonary artery catheterization effectiveness: the ESCAPE trial."
"593","JAMA.290","0.35",16204662,2005,"Pulmonary artery catheters (PACs) have been used to guide therapy in multiple settings, but recent studies have raised concerns that PACs may lead to increased mortality in hospitalized patients.To determine whether PAC use is safe and improves clinical outcomes in patients hospitalized with severe symptomatic and recurrent heart failure.The Evaluation Study of Congestive Heart Failure and Pulmonary Artery Catheterization Effectiveness (ESCAPE) was a randomized controlled trial of 433 patients at 26 sites conducted from January 18, 2000, to November 17, 2003. Patients were assigned to receive therapy guided by clinical assessment and a PAC or clinical assessment alone. The target in both groups was resolution of clinical congestion, with additional PAC targets of a pulmonary capillary wedge pressure of 15 mm Hg and a right atrial pressure of 8 mm Hg. Medications were not specified, but inotrope use was explicitly discouraged.The primary end point was days alive out of the hospital during the first 6 months, with secondary end points of exercise, quality of life, biochemical, and echocardiographic changes.Severity of illness was reflected by the following values: average left ventricular ejection fraction, 19%; systolic blood pressure, 106 mm Hg; sodium level, 137 mEq/L; urea nitrogen, 35 mg/dL (12.40 mmol/L); and creatinine, 1.5 mg/dL (132.6 micromol/L). Therapy in both groups led to substantial reduction in symptoms, jugular venous pressure, and edema. Use of the PAC did not significantly affect the primary end point of days alive and out of the hospital during the first 6 months (133 days vs 135 days; hazard ratio [HR], 1.00 [95% confidence interval {CI}, 0.82-1.21]; P = .99), mortality (43 patients [10%] vs 38 patients [9%]; odds ratio [OR], 1.26 [95% CI, 0.78-2.03]; P = .35), or the number of days hospitalized (8.7 vs 8.3; HR, 1.04 [95% CI, 0.86-1.27]; P = .67). In-hospital adverse events were more common among patients in the PAC group (47 [21.9%] vs 25 [11.5%]; P = .04). There were no deaths related to PAC use, and no difference for in-hospital plus 30-day mortality (10 [4.7%] vs 11 [5.0%]; OR, 0.97 [95% CI, 0.38-2.22]; P = .97). Exercise and quality of life end points improved in both groups with a trend toward greater improvement with the PAC, which reached significance for the time trade-off at all time points after randomization.Therapy to reduce volume overload during hospitalization for heart failure led to marked improvement in signs and symptoms of elevated filling pressures with or without the PAC. Addition of the PAC to careful clinical assessment increased anticipated adverse events, but did not affect overall mortality and hospitalization. Future trials should test noninvasive assessments with specific treatment strategies that could be used to better tailor therapy for both survival time and survival quality as valued by patients.","Evaluation study of congestive heart failure and pulmonary artery catheterization effectiveness: the ESCAPE trial."
"594","JAMA.291","0.67",16204662,2005,"Pulmonary artery catheters (PACs) have been used to guide therapy in multiple settings, but recent studies have raised concerns that PACs may lead to increased mortality in hospitalized patients.To determine whether PAC use is safe and improves clinical outcomes in patients hospitalized with severe symptomatic and recurrent heart failure.The Evaluation Study of Congestive Heart Failure and Pulmonary Artery Catheterization Effectiveness (ESCAPE) was a randomized controlled trial of 433 patients at 26 sites conducted from January 18, 2000, to November 17, 2003. Patients were assigned to receive therapy guided by clinical assessment and a PAC or clinical assessment alone. The target in both groups was resolution of clinical congestion, with additional PAC targets of a pulmonary capillary wedge pressure of 15 mm Hg and a right atrial pressure of 8 mm Hg. Medications were not specified, but inotrope use was explicitly discouraged.The primary end point was days alive out of the hospital during the first 6 months, with secondary end points of exercise, quality of life, biochemical, and echocardiographic changes.Severity of illness was reflected by the following values: average left ventricular ejection fraction, 19%; systolic blood pressure, 106 mm Hg; sodium level, 137 mEq/L; urea nitrogen, 35 mg/dL (12.40 mmol/L); and creatinine, 1.5 mg/dL (132.6 micromol/L). Therapy in both groups led to substantial reduction in symptoms, jugular venous pressure, and edema. Use of the PAC did not significantly affect the primary end point of days alive and out of the hospital during the first 6 months (133 days vs 135 days; hazard ratio [HR], 1.00 [95% confidence interval {CI}, 0.82-1.21]; P = .99), mortality (43 patients [10%] vs 38 patients [9%]; odds ratio [OR], 1.26 [95% CI, 0.78-2.03]; P = .35), or the number of days hospitalized (8.7 vs 8.3; HR, 1.04 [95% CI, 0.86-1.27]; P = .67). In-hospital adverse events were more common among patients in the PAC group (47 [21.9%] vs 25 [11.5%]; P = .04). There were no deaths related to PAC use, and no difference for in-hospital plus 30-day mortality (10 [4.7%] vs 11 [5.0%]; OR, 0.97 [95% CI, 0.38-2.22]; P = .97). Exercise and quality of life end points improved in both groups with a trend toward greater improvement with the PAC, which reached significance for the time trade-off at all time points after randomization.Therapy to reduce volume overload during hospitalization for heart failure led to marked improvement in signs and symptoms of elevated filling pressures with or without the PAC. Addition of the PAC to careful clinical assessment increased anticipated adverse events, but did not affect overall mortality and hospitalization. Future trials should test noninvasive assessments with specific treatment strategies that could be used to better tailor therapy for both survival time and survival quality as valued by patients.","Evaluation study of congestive heart failure and pulmonary artery catheterization effectiveness: the ESCAPE trial."
"595","JAMA.293","0.97",16204662,2005,"Pulmonary artery catheters (PACs) have been used to guide therapy in multiple settings, but recent studies have raised concerns that PACs may lead to increased mortality in hospitalized patients.To determine whether PAC use is safe and improves clinical outcomes in patients hospitalized with severe symptomatic and recurrent heart failure.The Evaluation Study of Congestive Heart Failure and Pulmonary Artery Catheterization Effectiveness (ESCAPE) was a randomized controlled trial of 433 patients at 26 sites conducted from January 18, 2000, to November 17, 2003. Patients were assigned to receive therapy guided by clinical assessment and a PAC or clinical assessment alone. The target in both groups was resolution of clinical congestion, with additional PAC targets of a pulmonary capillary wedge pressure of 15 mm Hg and a right atrial pressure of 8 mm Hg. Medications were not specified, but inotrope use was explicitly discouraged.The primary end point was days alive out of the hospital during the first 6 months, with secondary end points of exercise, quality of life, biochemical, and echocardiographic changes.Severity of illness was reflected by the following values: average left ventricular ejection fraction, 19%; systolic blood pressure, 106 mm Hg; sodium level, 137 mEq/L; urea nitrogen, 35 mg/dL (12.40 mmol/L); and creatinine, 1.5 mg/dL (132.6 micromol/L). Therapy in both groups led to substantial reduction in symptoms, jugular venous pressure, and edema. Use of the PAC did not significantly affect the primary end point of days alive and out of the hospital during the first 6 months (133 days vs 135 days; hazard ratio [HR], 1.00 [95% confidence interval {CI}, 0.82-1.21]; P = .99), mortality (43 patients [10%] vs 38 patients [9%]; odds ratio [OR], 1.26 [95% CI, 0.78-2.03]; P = .35), or the number of days hospitalized (8.7 vs 8.3; HR, 1.04 [95% CI, 0.86-1.27]; P = .67). In-hospital adverse events were more common among patients in the PAC group (47 [21.9%] vs 25 [11.5%]; P = .04). There were no deaths related to PAC use, and no difference for in-hospital plus 30-day mortality (10 [4.7%] vs 11 [5.0%]; OR, 0.97 [95% CI, 0.38-2.22]; P = .97). Exercise and quality of life end points improved in both groups with a trend toward greater improvement with the PAC, which reached significance for the time trade-off at all time points after randomization.Therapy to reduce volume overload during hospitalization for heart failure led to marked improvement in signs and symptoms of elevated filling pressures with or without the PAC. Addition of the PAC to careful clinical assessment increased anticipated adverse events, but did not affect overall mortality and hospitalization. Future trials should test noninvasive assessments with specific treatment strategies that could be used to better tailor therapy for both survival time and survival quality as valued by patients.","Evaluation study of congestive heart failure and pulmonary artery catheterization effectiveness: the ESCAPE trial."
"596","JAMA.260","0.001",16204666,2005,"Randomized clinical trials (RCTs) evaluating the pulmonary artery catheter (PAC) have been limited by small sample size. Some nonrandomized studies suggest that PAC use is associated with increased morbidity and mortality.To estimate the impact of the PAC device in critically ill patients.MEDLINE (1985-2005), the Cochrane Controlled Trials Registry (1988-2005), the National Institutes of Health ClinicalTrials.gov database, and the US Food and Drug Administration Web site for RCTs in which patients were randomly assigned to PAC or no PAC were searched. Results from the ESCAPE trial of patients with severe heart failure were also included. Search terms included pulmonary artery catheter, right heart catheter, catheter, and Swan-Ganz.Eligible studies included patients who were undergoing surgery, in the intensive care unit (ICU), admitted with advanced heart failure, or diagnosed with acute respiratory distress syndrome and/or sepsis; and studies that reported death and the number of days hospitalized or the number of days in the ICU as outcome measures.Information on eligibility criteria, baseline characteristics, interventions, outcomes, and methodological quality was extracted by 2 reviewers. Disagreements were resolved by consensus.In 13 RCTs, 5051 patients were randomized. Hemodynamic goals and treatment strategies varied among trials. A random-effects model was used to estimate the odds ratios (ORs) for death, number of days hospitalized, and use of inotropes and intravenous vasodilators. The combined OR for mortality was 1.04 (95% confidence interval [CI], 0.90-1.20; P = .59). The difference in the mean number of days hospitalized for PAC minus the mean for no PAC was 0.11 (95% CI, -0.51 to 0.74; P = .73). Use of the PAC was associated with a higher use of inotropes (OR, 1.58; 95% CI, 1.19-2.12; P = .002) and intravenous vasodilators (OR, 2.35; 95% CI, 1.75-3.15; P<.001).In critically ill patients, use of the PAC neither increased overall mortality or days in hospital nor conferred benefit. Despite almost 20 years of RCTs, a clear strategy leading to improved survival with the PAC has not been devised. The neutrality of the PAC for clinical outcomes may result from the absence of effective evidence-based treatments to use in combination with PAC information across the spectrum of critically ill patients.","Impact of the pulmonary artery catheter in critically ill patients: meta-analysis of randomized clinical trials."
"597","JAMA.286","0.59",16204666,2005,"Randomized clinical trials (RCTs) evaluating the pulmonary artery catheter (PAC) have been limited by small sample size. Some nonrandomized studies suggest that PAC use is associated with increased morbidity and mortality.To estimate the impact of the PAC device in critically ill patients.MEDLINE (1985-2005), the Cochrane Controlled Trials Registry (1988-2005), the National Institutes of Health ClinicalTrials.gov database, and the US Food and Drug Administration Web site for RCTs in which patients were randomly assigned to PAC or no PAC were searched. Results from the ESCAPE trial of patients with severe heart failure were also included. Search terms included pulmonary artery catheter, right heart catheter, catheter, and Swan-Ganz.Eligible studies included patients who were undergoing surgery, in the intensive care unit (ICU), admitted with advanced heart failure, or diagnosed with acute respiratory distress syndrome and/or sepsis; and studies that reported death and the number of days hospitalized or the number of days in the ICU as outcome measures.Information on eligibility criteria, baseline characteristics, interventions, outcomes, and methodological quality was extracted by 2 reviewers. Disagreements were resolved by consensus.In 13 RCTs, 5051 patients were randomized. Hemodynamic goals and treatment strategies varied among trials. A random-effects model was used to estimate the odds ratios (ORs) for death, number of days hospitalized, and use of inotropes and intravenous vasodilators. The combined OR for mortality was 1.04 (95% confidence interval [CI], 0.90-1.20; P = .59). The difference in the mean number of days hospitalized for PAC minus the mean for no PAC was 0.11 (95% CI, -0.51 to 0.74; P = .73). Use of the PAC was associated with a higher use of inotropes (OR, 1.58; 95% CI, 1.19-2.12; P = .002) and intravenous vasodilators (OR, 2.35; 95% CI, 1.75-3.15; P<.001).In critically ill patients, use of the PAC neither increased overall mortality or days in hospital nor conferred benefit. Despite almost 20 years of RCTs, a clear strategy leading to improved survival with the PAC has not been devised. The neutrality of the PAC for clinical outcomes may result from the absence of effective evidence-based treatments to use in combination with PAC information across the spectrum of critically ill patients.","Impact of the pulmonary artery catheter in critically ill patients: meta-analysis of randomized clinical trials."
"598","JAMA.288","0.002",16204666,2005,"Randomized clinical trials (RCTs) evaluating the pulmonary artery catheter (PAC) have been limited by small sample size. Some nonrandomized studies suggest that PAC use is associated with increased morbidity and mortality.To estimate the impact of the PAC device in critically ill patients.MEDLINE (1985-2005), the Cochrane Controlled Trials Registry (1988-2005), the National Institutes of Health ClinicalTrials.gov database, and the US Food and Drug Administration Web site for RCTs in which patients were randomly assigned to PAC or no PAC were searched. Results from the ESCAPE trial of patients with severe heart failure were also included. Search terms included pulmonary artery catheter, right heart catheter, catheter, and Swan-Ganz.Eligible studies included patients who were undergoing surgery, in the intensive care unit (ICU), admitted with advanced heart failure, or diagnosed with acute respiratory distress syndrome and/or sepsis; and studies that reported death and the number of days hospitalized or the number of days in the ICU as outcome measures.Information on eligibility criteria, baseline characteristics, interventions, outcomes, and methodological quality was extracted by 2 reviewers. Disagreements were resolved by consensus.In 13 RCTs, 5051 patients were randomized. Hemodynamic goals and treatment strategies varied among trials. A random-effects model was used to estimate the odds ratios (ORs) for death, number of days hospitalized, and use of inotropes and intravenous vasodilators. The combined OR for mortality was 1.04 (95% confidence interval [CI], 0.90-1.20; P = .59). The difference in the mean number of days hospitalized for PAC minus the mean for no PAC was 0.11 (95% CI, -0.51 to 0.74; P = .73). Use of the PAC was associated with a higher use of inotropes (OR, 1.58; 95% CI, 1.19-2.12; P = .002) and intravenous vasodilators (OR, 2.35; 95% CI, 1.75-3.15; P<.001).In critically ill patients, use of the PAC neither increased overall mortality or days in hospital nor conferred benefit. Despite almost 20 years of RCTs, a clear strategy leading to improved survival with the PAC has not been devised. The neutrality of the PAC for clinical outcomes may result from the absence of effective evidence-based treatments to use in combination with PAC information across the spectrum of critically ill patients.","Impact of the pulmonary artery catheter in critically ill patients: meta-analysis of randomized clinical trials."
"599","American Journal of Epidemiology.51","0.001",16207807,2005,"Community-acquired alveolar pneumonia (CAAP) is typically associated with bacterial infections and is especially prevalent in vulnerable populations worldwide. The authors studied nutritional status and diarrheal history as risk factors for CAAP in Bedouin children <5 years of age living in Israel. In this prospective case-control study (2001-2002), 334 children with radiographically confirmed CAAP were compared with 529 controls without pneumonia with regard to nutritional status and diarrhea history. Controls were frequency matched to cases on age and enrollment month. Logistic regression models were used to evaluate associations of CAAP with nutritional status and recent diarrhea experience. Anemia (adjusted odds ratio (AOR) = 3.32, 95% confidence interval (CI): 2.24, 4.94; p < 0.001), low birth weight (AOR = 2.16, 95% CI: 1.32, 3.54; p = 0.002), stunting (AOR = 2.22, 95% CI: 1.31, 3.78; p = 0.004), serum retinol concentration (AOR = 1.03 per microg/dl, 95% CI: 1.02, 1.05; p < 0.001), and having > or =1 diarrhea episodes within 31 days prior to enrollment (AOR = 2.30, 95% CI: 1.26, 4.19; p = 0.007) were identified as risk factors for CAAP. Results suggest that improving antenatal care and the nutritional status of infants may reduce the risk of CAAP in Bedouin children. Furthermore, they suggest that vaccines developed to prevent diarrhea may also lower the risk of CAAP.","Nutritional status and diarrheal illness as independent risk factors for alveolar pneumonia."
"600","American Journal of Epidemiology.52","0.001",16207807,2005,"Community-acquired alveolar pneumonia (CAAP) is typically associated with bacterial infections and is especially prevalent in vulnerable populations worldwide. The authors studied nutritional status and diarrheal history as risk factors for CAAP in Bedouin children <5 years of age living in Israel. In this prospective case-control study (2001-2002), 334 children with radiographically confirmed CAAP were compared with 529 controls without pneumonia with regard to nutritional status and diarrhea history. Controls were frequency matched to cases on age and enrollment month. Logistic regression models were used to evaluate associations of CAAP with nutritional status and recent diarrhea experience. Anemia (adjusted odds ratio (AOR) = 3.32, 95% confidence interval (CI): 2.24, 4.94; p < 0.001), low birth weight (AOR = 2.16, 95% CI: 1.32, 3.54; p = 0.002), stunting (AOR = 2.22, 95% CI: 1.31, 3.78; p = 0.004), serum retinol concentration (AOR = 1.03 per microg/dl, 95% CI: 1.02, 1.05; p < 0.001), and having > or =1 diarrhea episodes within 31 days prior to enrollment (AOR = 2.30, 95% CI: 1.26, 4.19; p = 0.007) were identified as risk factors for CAAP. Results suggest that improving antenatal care and the nutritional status of infants may reduce the risk of CAAP in Bedouin children. Furthermore, they suggest that vaccines developed to prevent diarrhea may also lower the risk of CAAP.","Nutritional status and diarrheal illness as independent risk factors for alveolar pneumonia."
"601","American Journal of Epidemiology.58","0.002",16207807,2005,"Community-acquired alveolar pneumonia (CAAP) is typically associated with bacterial infections and is especially prevalent in vulnerable populations worldwide. The authors studied nutritional status and diarrheal history as risk factors for CAAP in Bedouin children <5 years of age living in Israel. In this prospective case-control study (2001-2002), 334 children with radiographically confirmed CAAP were compared with 529 controls without pneumonia with regard to nutritional status and diarrhea history. Controls were frequency matched to cases on age and enrollment month. Logistic regression models were used to evaluate associations of CAAP with nutritional status and recent diarrhea experience. Anemia (adjusted odds ratio (AOR) = 3.32, 95% confidence interval (CI): 2.24, 4.94; p < 0.001), low birth weight (AOR = 2.16, 95% CI: 1.32, 3.54; p = 0.002), stunting (AOR = 2.22, 95% CI: 1.31, 3.78; p = 0.004), serum retinol concentration (AOR = 1.03 per microg/dl, 95% CI: 1.02, 1.05; p < 0.001), and having > or =1 diarrhea episodes within 31 days prior to enrollment (AOR = 2.30, 95% CI: 1.26, 4.19; p = 0.007) were identified as risk factors for CAAP. Results suggest that improving antenatal care and the nutritional status of infants may reduce the risk of CAAP in Bedouin children. Furthermore, they suggest that vaccines developed to prevent diarrhea may also lower the risk of CAAP.","Nutritional status and diarrheal illness as independent risk factors for alveolar pneumonia."
"602","American Journal of Epidemiology.59","0.004",16207807,2005,"Community-acquired alveolar pneumonia (CAAP) is typically associated with bacterial infections and is especially prevalent in vulnerable populations worldwide. The authors studied nutritional status and diarrheal history as risk factors for CAAP in Bedouin children <5 years of age living in Israel. In this prospective case-control study (2001-2002), 334 children with radiographically confirmed CAAP were compared with 529 controls without pneumonia with regard to nutritional status and diarrhea history. Controls were frequency matched to cases on age and enrollment month. Logistic regression models were used to evaluate associations of CAAP with nutritional status and recent diarrhea experience. Anemia (adjusted odds ratio (AOR) = 3.32, 95% confidence interval (CI): 2.24, 4.94; p < 0.001), low birth weight (AOR = 2.16, 95% CI: 1.32, 3.54; p = 0.002), stunting (AOR = 2.22, 95% CI: 1.31, 3.78; p = 0.004), serum retinol concentration (AOR = 1.03 per microg/dl, 95% CI: 1.02, 1.05; p < 0.001), and having > or =1 diarrhea episodes within 31 days prior to enrollment (AOR = 2.30, 95% CI: 1.26, 4.19; p = 0.007) were identified as risk factors for CAAP. Results suggest that improving antenatal care and the nutritional status of infants may reduce the risk of CAAP in Bedouin children. Furthermore, they suggest that vaccines developed to prevent diarrhea may also lower the risk of CAAP.","Nutritional status and diarrheal illness as independent risk factors for alveolar pneumonia."
"603","American Journal of Epidemiology.60","0.007",16207807,2005,"Community-acquired alveolar pneumonia (CAAP) is typically associated with bacterial infections and is especially prevalent in vulnerable populations worldwide. The authors studied nutritional status and diarrheal history as risk factors for CAAP in Bedouin children <5 years of age living in Israel. In this prospective case-control study (2001-2002), 334 children with radiographically confirmed CAAP were compared with 529 controls without pneumonia with regard to nutritional status and diarrhea history. Controls were frequency matched to cases on age and enrollment month. Logistic regression models were used to evaluate associations of CAAP with nutritional status and recent diarrhea experience. Anemia (adjusted odds ratio (AOR) = 3.32, 95% confidence interval (CI): 2.24, 4.94; p < 0.001), low birth weight (AOR = 2.16, 95% CI: 1.32, 3.54; p = 0.002), stunting (AOR = 2.22, 95% CI: 1.31, 3.78; p = 0.004), serum retinol concentration (AOR = 1.03 per microg/dl, 95% CI: 1.02, 1.05; p < 0.001), and having > or =1 diarrhea episodes within 31 days prior to enrollment (AOR = 2.30, 95% CI: 1.26, 4.19; p = 0.007) were identified as risk factors for CAAP. Results suggest that improving antenatal care and the nutritional status of infants may reduce the risk of CAAP in Bedouin children. Furthermore, they suggest that vaccines developed to prevent diarrhea may also lower the risk of CAAP.","Nutritional status and diarrheal illness as independent risk factors for alveolar pneumonia."
"604","Lancet.471","0.095",16214598,2005,"Patients with type 2 diabetes are at high risk of fatal and non-fatal myocardial infarction and stroke. There is indirect evidence that agonists of peroxisome proliferator-activated receptor gamma (PPAR gamma) could reduce macrovascular complications. Our aim, therefore, was to ascertain whether pioglitazone reduces macrovascular morbidity and mortality in high-risk patients with type 2 diabetes.We did a prospective, randomised controlled trial in 5238 patients with type 2 diabetes who had evidence of macrovascular disease. We recruited patients from primary-care practices and hospitals. We assigned patients to oral pioglitazone titrated from 15 mg to 45 mg (n=2605) or matching placebo (n=2633), to be taken in addition to their glucose-lowering drugs and other medications. Our primary endpoint was the composite of all-cause mortality, non fatal myocardial infarction (including silent myocardial infarction), stroke, acute coronary syndrome, endovascular or surgical intervention in the coronary or leg arteries, and amputation above the ankle. Analysis was by intention to treat. This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN NCT00174993.Two patients were lost to follow-up, but were included in analyses. The average time of observation was 34.5 months. 514 of 2605 patients in the pioglitazone group and 572 of 2633 patients in the placebo group had at least one event in the primary composite endpoint (HR 0.90, 95% CI 0.80-1.02, p=0.095). The main secondary endpoint was the composite of all-cause mortality, non-fatal myocardial infarction, and stroke. 301 patients in the pioglitazone group and 358 in the placebo group reached this endpoint (0.84, 0.72-0.98, p=0.027). Overall safety and tolerability was good with no change in the safety profile of pioglitazone identified. 6% (149 of 2065) and 4% (108 of 2633) of those in the pioglitazone and placebo groups, respectively, were admitted to hospital with heart failure; mortality rates from heart failure did not differ between groups.Pioglitazone reduces the composite of all-cause mortality, non-fatal myocardial infarction, and stroke in patients with type 2 diabetes who have a high risk of macrovascular events.","Secondary prevention of macrovascular events in patients with type 2 diabetes in the PROactive Study (PROspective pioglitAzone Clinical Trial In macroVascular Events): a randomised controlled trial."
"605","Lancet.481","0.027",16214598,2005,"Patients with type 2 diabetes are at high risk of fatal and non-fatal myocardial infarction and stroke. There is indirect evidence that agonists of peroxisome proliferator-activated receptor gamma (PPAR gamma) could reduce macrovascular complications. Our aim, therefore, was to ascertain whether pioglitazone reduces macrovascular morbidity and mortality in high-risk patients with type 2 diabetes.We did a prospective, randomised controlled trial in 5238 patients with type 2 diabetes who had evidence of macrovascular disease. We recruited patients from primary-care practices and hospitals. We assigned patients to oral pioglitazone titrated from 15 mg to 45 mg (n=2605) or matching placebo (n=2633), to be taken in addition to their glucose-lowering drugs and other medications. Our primary endpoint was the composite of all-cause mortality, non fatal myocardial infarction (including silent myocardial infarction), stroke, acute coronary syndrome, endovascular or surgical intervention in the coronary or leg arteries, and amputation above the ankle. Analysis was by intention to treat. This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN NCT00174993.Two patients were lost to follow-up, but were included in analyses. The average time of observation was 34.5 months. 514 of 2605 patients in the pioglitazone group and 572 of 2633 patients in the placebo group had at least one event in the primary composite endpoint (HR 0.90, 95% CI 0.80-1.02, p=0.095). The main secondary endpoint was the composite of all-cause mortality, non-fatal myocardial infarction, and stroke. 301 patients in the pioglitazone group and 358 in the placebo group reached this endpoint (0.84, 0.72-0.98, p=0.027). Overall safety and tolerability was good with no change in the safety profile of pioglitazone identified. 6% (149 of 2065) and 4% (108 of 2633) of those in the pioglitazone and placebo groups, respectively, were admitted to hospital with heart failure; mortality rates from heart failure did not differ between groups.Pioglitazone reduces the composite of all-cause mortality, non-fatal myocardial infarction, and stroke in patients with type 2 diabetes who have a high risk of macrovascular events.","Secondary prevention of macrovascular events in patients with type 2 diabetes in the PROactive Study (PROspective pioglitAzone Clinical Trial In macroVascular Events): a randomised controlled trial."
"606","JAMA.2671","0.004",16219883,2005,"Angiotensin-converting enzyme (ACE) inhibitors reduce the risk of myocardial infarction (MI), but it is not known whether angiotensin receptor blockers have the same effect.To assess the impact of the angiotensin receptor blocker candesartan on MI and other coronary events in patients with heart failure.The Candesartan in Heart Failure: Assessment of Reduction in Mortality and Morbidity (CHARM) program, a randomized, placebo-controlled study enrolling patients (mean age, 66 [SD, 11] years) with New York Heart Association class II to IV symptoms who were randomly allocated to receive candesartan (target dose, 32 mg once daily) or matching placebo given in addition to optimal therapy for heart failure. Patients were enrolled from March 1999 through March 2001. Of 7599 patients allocated, 4004 (53%) had experienced a previous MI, and 1808 (24%) currently had angina. At baseline, 3125 (41%) were receiving an ACE inhibitor; 4203 (55%), a beta-blocker; 3153 (42%), a lipid-lowering drug; 4246 (56%), aspirin; and 6286 (83%), a diuretic.The primary outcome of the present analysis was the composite of cardiovascular death or nonfatal MI in patients with heart failure receiving candesartan or placebo.During the median follow-up of 37.7 months, the primary outcome of cardiovascular death or nonfatal MI was significantly reduced in the candesartan group (775 patients [20.4%]) vs the placebo group (868 [22.9%]) (hazard ratio [HR], 0.87; 95% confidence interval [CI], 0.79-0.96; P = .004; number needed to treat [NNT], 40). Nonfatal MI alone was also significantly reduced in the candesartan group (116 [3.1%]) vs the placebo group (148 [3.9%]) (HR, 0.77; 95% CI, 0.60-0.98; P = .03; NNT, 118). The secondary outcome of fatal MI, sudden death, or nonfatal MI was significantly reduced with candesartan (459 [12.1%]) vs placebo (522 [13.8%]) (HR, 0.86; 95% CI, 0.75-0.97; P = .02; NNT, 59). Risk reductions in cardiovascular death or nonfatal MI were similar across predetermined subgroups and the component CHARM trials. There was no impact on hospitalizations for unstable angina or coronary revascularization procedures with candesartan.In patients with heart failure, candesartan significantly reduces the risk of the composite outcome of cardiovascular death or nonfatal MI.","Impact of candesartan on nonfatal myocardial infarction and cardiovascular death in patients with heart failure."
"607","JAMA.2681","0.03",16219883,2005,"Angiotensin-converting enzyme (ACE) inhibitors reduce the risk of myocardial infarction (MI), but it is not known whether angiotensin receptor blockers have the same effect.To assess the impact of the angiotensin receptor blocker candesartan on MI and other coronary events in patients with heart failure.The Candesartan in Heart Failure: Assessment of Reduction in Mortality and Morbidity (CHARM) program, a randomized, placebo-controlled study enrolling patients (mean age, 66 [SD, 11] years) with New York Heart Association class II to IV symptoms who were randomly allocated to receive candesartan (target dose, 32 mg once daily) or matching placebo given in addition to optimal therapy for heart failure. Patients were enrolled from March 1999 through March 2001. Of 7599 patients allocated, 4004 (53%) had experienced a previous MI, and 1808 (24%) currently had angina. At baseline, 3125 (41%) were receiving an ACE inhibitor; 4203 (55%), a beta-blocker; 3153 (42%), a lipid-lowering drug; 4246 (56%), aspirin; and 6286 (83%), a diuretic.The primary outcome of the present analysis was the composite of cardiovascular death or nonfatal MI in patients with heart failure receiving candesartan or placebo.During the median follow-up of 37.7 months, the primary outcome of cardiovascular death or nonfatal MI was significantly reduced in the candesartan group (775 patients [20.4%]) vs the placebo group (868 [22.9%]) (hazard ratio [HR], 0.87; 95% confidence interval [CI], 0.79-0.96; P = .004; number needed to treat [NNT], 40). Nonfatal MI alone was also significantly reduced in the candesartan group (116 [3.1%]) vs the placebo group (148 [3.9%]) (HR, 0.77; 95% CI, 0.60-0.98; P = .03; NNT, 118). The secondary outcome of fatal MI, sudden death, or nonfatal MI was significantly reduced with candesartan (459 [12.1%]) vs placebo (522 [13.8%]) (HR, 0.86; 95% CI, 0.75-0.97; P = .02; NNT, 59). Risk reductions in cardiovascular death or nonfatal MI were similar across predetermined subgroups and the component CHARM trials. There was no impact on hospitalizations for unstable angina or coronary revascularization procedures with candesartan.In patients with heart failure, candesartan significantly reduces the risk of the composite outcome of cardiovascular death or nonfatal MI.","Impact of candesartan on nonfatal myocardial infarction and cardiovascular death in patients with heart failure."
"608","JAMA.2691","0.02",16219883,2005,"Angiotensin-converting enzyme (ACE) inhibitors reduce the risk of myocardial infarction (MI), but it is not known whether angiotensin receptor blockers have the same effect.To assess the impact of the angiotensin receptor blocker candesartan on MI and other coronary events in patients with heart failure.The Candesartan in Heart Failure: Assessment of Reduction in Mortality and Morbidity (CHARM) program, a randomized, placebo-controlled study enrolling patients (mean age, 66 [SD, 11] years) with New York Heart Association class II to IV symptoms who were randomly allocated to receive candesartan (target dose, 32 mg once daily) or matching placebo given in addition to optimal therapy for heart failure. Patients were enrolled from March 1999 through March 2001. Of 7599 patients allocated, 4004 (53%) had experienced a previous MI, and 1808 (24%) currently had angina. At baseline, 3125 (41%) were receiving an ACE inhibitor; 4203 (55%), a beta-blocker; 3153 (42%), a lipid-lowering drug; 4246 (56%), aspirin; and 6286 (83%), a diuretic.The primary outcome of the present analysis was the composite of cardiovascular death or nonfatal MI in patients with heart failure receiving candesartan or placebo.During the median follow-up of 37.7 months, the primary outcome of cardiovascular death or nonfatal MI was significantly reduced in the candesartan group (775 patients [20.4%]) vs the placebo group (868 [22.9%]) (hazard ratio [HR], 0.87; 95% confidence interval [CI], 0.79-0.96; P = .004; number needed to treat [NNT], 40). Nonfatal MI alone was also significantly reduced in the candesartan group (116 [3.1%]) vs the placebo group (148 [3.9%]) (HR, 0.77; 95% CI, 0.60-0.98; P = .03; NNT, 118). The secondary outcome of fatal MI, sudden death, or nonfatal MI was significantly reduced with candesartan (459 [12.1%]) vs placebo (522 [13.8%]) (HR, 0.86; 95% CI, 0.75-0.97; P = .02; NNT, 59). Risk reductions in cardiovascular death or nonfatal MI were similar across predetermined subgroups and the component CHARM trials. There was no impact on hospitalizations for unstable angina or coronary revascularization procedures with candesartan.In patients with heart failure, candesartan significantly reduces the risk of the composite outcome of cardiovascular death or nonfatal MI.","Impact of candesartan on nonfatal myocardial infarction and cardiovascular death in patients with heart failure."
"609","Lancet.28","1.00E-04",16226613,2005,"Non-steroidal anti-inflammatory drugs (NSAIDs) seem to prevent several types of cancer, but could increase the risk of cardiovascular complications. We investigated whether use of NSAIDs was associated with a change in the incidence of oral cancer or overall or cardiovascular mortality.We undertook a nested case-control study to analyse data from a population-based database (Cohort of Norway; CONOR), which consisted of prospectively obtained health data from all regions of Norway. People with oral cancer were identified from the 9241 individuals in CONOR who were at increased risk of oral cancer because of heavy smoking (15 pack-years), and matched controls were selected from the remaining heavy smokers (who did not have cancer).We identified and analysed 454 (5%) people with oral cancer (279 men, 175 women, mean [SD] age at diagnosis 63.3 [13.2] years) and 454 matched controls (n=908); 263 (29%) had used NSAIDs, 83 (9%) had used paracetamol (for a minimum of 6 months), and 562 (62%) had used neither drug. NSAID use (but not paracetamol use) was associated with a reduced risk of oral cancer (including in active smokers; hazard ratio 0.47, 95% CI 0.37-0.60, p<0.0001). Smoking cessation also lowered the risk of oral cancer (0.41, 0.32-0.52, p<0.0001). Additionally, long-term use of NSAIDs (but not paracetamol) was associated with an increased risk of cardiovascular-disease-related death (2.06, 1.34-3.18, p=0.001). NSAID use did not significantly reduce overall mortality (p=0.17).Long-term use of NSAIDs is associated with a reduced incidence of oral cancer (including in active smokers), but also with an increased risk of death due to cardiovascular disease. These findings highlight the need for a careful risk-benefit analysis when the long-term use of NSAIDs is considered.","Non-steroidal anti-inflammatory drugs and the risk of oral cancer: a nested case-control study."
"610","Lancet.29","1.00E-04",16226613,2005,"Non-steroidal anti-inflammatory drugs (NSAIDs) seem to prevent several types of cancer, but could increase the risk of cardiovascular complications. We investigated whether use of NSAIDs was associated with a change in the incidence of oral cancer or overall or cardiovascular mortality.We undertook a nested case-control study to analyse data from a population-based database (Cohort of Norway; CONOR), which consisted of prospectively obtained health data from all regions of Norway. People with oral cancer were identified from the 9241 individuals in CONOR who were at increased risk of oral cancer because of heavy smoking (15 pack-years), and matched controls were selected from the remaining heavy smokers (who did not have cancer).We identified and analysed 454 (5%) people with oral cancer (279 men, 175 women, mean [SD] age at diagnosis 63.3 [13.2] years) and 454 matched controls (n=908); 263 (29%) had used NSAIDs, 83 (9%) had used paracetamol (for a minimum of 6 months), and 562 (62%) had used neither drug. NSAID use (but not paracetamol use) was associated with a reduced risk of oral cancer (including in active smokers; hazard ratio 0.47, 95% CI 0.37-0.60, p<0.0001). Smoking cessation also lowered the risk of oral cancer (0.41, 0.32-0.52, p<0.0001). Additionally, long-term use of NSAIDs (but not paracetamol) was associated with an increased risk of cardiovascular-disease-related death (2.06, 1.34-3.18, p=0.001). NSAID use did not significantly reduce overall mortality (p=0.17).Long-term use of NSAIDs is associated with a reduced incidence of oral cancer (including in active smokers), but also with an increased risk of death due to cardiovascular disease. These findings highlight the need for a careful risk-benefit analysis when the long-term use of NSAIDs is considered.","Non-steroidal anti-inflammatory drugs and the risk of oral cancer: a nested case-control study."
"611","Lancet.35","0.001",16226613,2005,"Non-steroidal anti-inflammatory drugs (NSAIDs) seem to prevent several types of cancer, but could increase the risk of cardiovascular complications. We investigated whether use of NSAIDs was associated with a change in the incidence of oral cancer or overall or cardiovascular mortality.We undertook a nested case-control study to analyse data from a population-based database (Cohort of Norway; CONOR), which consisted of prospectively obtained health data from all regions of Norway. People with oral cancer were identified from the 9241 individuals in CONOR who were at increased risk of oral cancer because of heavy smoking (15 pack-years), and matched controls were selected from the remaining heavy smokers (who did not have cancer).We identified and analysed 454 (5%) people with oral cancer (279 men, 175 women, mean [SD] age at diagnosis 63.3 [13.2] years) and 454 matched controls (n=908); 263 (29%) had used NSAIDs, 83 (9%) had used paracetamol (for a minimum of 6 months), and 562 (62%) had used neither drug. NSAID use (but not paracetamol use) was associated with a reduced risk of oral cancer (including in active smokers; hazard ratio 0.47, 95% CI 0.37-0.60, p<0.0001). Smoking cessation also lowered the risk of oral cancer (0.41, 0.32-0.52, p<0.0001). Additionally, long-term use of NSAIDs (but not paracetamol) was associated with an increased risk of cardiovascular-disease-related death (2.06, 1.34-3.18, p=0.001). NSAID use did not significantly reduce overall mortality (p=0.17).Long-term use of NSAIDs is associated with a reduced incidence of oral cancer (including in active smokers), but also with an increased risk of death due to cardiovascular disease. These findings highlight the need for a careful risk-benefit analysis when the long-term use of NSAIDs is considered.","Non-steroidal anti-inflammatory drugs and the risk of oral cancer: a nested case-control study."
"612","JAMA.284","0.02",16234500,2005,"Atypical antipsychotic medications are widely used to treat delusions, aggression, and agitation in people with Alzheimer disease and other dementia; however, concerns have arisen about the increased risk for cerebrovascular adverse events, rapid cognitive decline, and mortality with their use.To assess the evidence for increased mortality from atypical antipsychotic drug treatment for people with dementia.MEDLINE (1966 to April 2005), the Cochrane Controlled Trials Register (2005, Issue 1), meetings presentations (1997-2004), and information from the sponsors were searched using the terms for atypical antipsychotic drugs (aripiprazole, clozapine, olanzapine, quetiapine, risperidone, and ziprasidone), dementia, Alzheimer disease, and clinical trial.Published and unpublished randomized placebo-controlled, parallel-group clinical trials of atypical antipsychotic drugs marketed in the United States to treat patients with Alzheimer disease or dementia were selected by consensus of the authors.Trials, baseline characteristics, outcomes, all-cause dropouts, and deaths were extracted by one reviewer; treatment exposure was obtained or estimated. Data were checked by a second reviewer.Fifteen trials (9 unpublished), generally 10 to 12 weeks in duration, including 16 contrasts of atypical antipsychotic drugs with placebo met criteria (aripiprazole [n = 3], olanzapine [n = 5], quetiapine [n = 3], risperidone [n = 5]). A total of 3353 patients were randomized to study drug and 1757 were randomized to placebo. Outcomes were assessed using standard methods (with random- or fixed-effects models) to calculate odds ratios (ORs) and risk differences based on patients randomized and relative risks based on total exposure to treatment. There were no differences in dropouts. Death occurred more often among patients randomized to drugs (118 [3.5%] vs 40 [2.3%]. The OR by meta-analysis was 1.54; 95% confidence interval [CI], 1.06-2.23; P = .02; and risk difference was 0.01; 95% CI, 0.004-0.02; P = .01). Sensitivity analyses did not show evidence for differential risks for individual drugs, severity, sample selection, or diagnosis.Atypical antipsychotic drugs may be associated with a small increased risk for death compared with placebo. This risk should be considered within the context of medical need for the drugs, efficacy evidence, medical comorbidity, and the efficacy and safety of alternatives. Individual patient analyses modeling survival and causes of death are needed.","Risk of death with atypical antipsychotic drug treatment for dementia: meta-analysis of randomized placebo-controlled trials."
"613","Lancet.27","1.00E-05",16271643,2005,"Despite previous randomised trials of early beta-blocker therapy in the emergency treatment of myocardial infarction (MI), uncertainty has persisted about the value of adding it to current standard interventions (eg, aspirin and fibrinolytic therapy), and the balance of potential benefits and hazards is still unclear in high-risk patients.45,852 patients admitted to 1250 hospitals within 24 h of suspected acute MI onset were randomly allocated metoprolol (up to 15 mg intravenous then 200 mg oral daily; n=22,929) or matching placebo (n=22,923). 93% had ST-segment elevation or bundle branch block, and 7% had ST-segment depression. Treatment was to continue until discharge or up to 4 weeks in hospital (mean 15 days in survivors) and 89% completed it. The two prespecified co-primary outcomes were: (1) composite of death, reinfarction, or cardiac arrest; and (2) death from any cause during the scheduled treatment period. Comparisons were by intention to treat, and used the log-rank method. This study is registered with ClinicalTrials.gov, number NCT 00222573.Neither of the co-primary outcomes was significantly reduced by allocation to metoprolol. For death, reinfarction, or cardiac arrest, 2166 (9.4%) patients allocated metoprolol had at least one such event compared with 2261 (9.9%) allocated placebo (odds ratio [OR] 0.96, 95% CI 0.90-1.01; p=0.1). For death alone, there were 1774 (7.7%) deaths in the metoprolol group versus 1797 (7.8%) in the placebo group (OR 0.99, 0.92-1.05; p=0.69). Allocation to metoprolol was associated with five fewer people having reinfarction (464 [2.0%] metoprolol vs 568 [2.5%] placebo; OR 0.82, 0.72-0.92; p=0.001) and five fewer having ventricular fibrillation (581 [2.5%] vs 698 [3.0%]; OR 0.83, 0.75-0.93; p=0.001) per 1000 treated. Overall, these reductions were counterbalanced by 11 more per 1000 developing cardiogenic shock (1141 [5.0%] vs 885 [3.9%]; OR 1.30, 1.19-1.41; p<0.00001). This excess of cardiogenic shock was mainly during days 0-1 after admission, whereas the reductions in reinfarction and ventricular fibrillation emerged more gradually. Consequently, the overall effect on death, reinfarction, arrest, or shock was significantly adverse during days 0-1 and significantly beneficial thereafter. There was substantial net hazard in haemodynamically unstable patients, and moderate net benefit in those who were relatively stable (particularly after days 0-1).The use of early beta-blocker therapy in acute MI reduces the risks of reinfarction and ventricular fibrillation, but increases the risk of cardiogenic shock, especially during the first day or so after admission. Consequently, it might generally be prudent to consider starting beta-blocker therapy in hospital only when the haemodynamic condition after MI has stabilised.","Early intravenous then oral metoprolol in 45,852 patients with acute myocardial infarction: randomised placebo-controlled trial."
"614","Lancet.31","0.1",16271643,2005,"Despite previous randomised trials of early beta-blocker therapy in the emergency treatment of myocardial infarction (MI), uncertainty has persisted about the value of adding it to current standard interventions (eg, aspirin and fibrinolytic therapy), and the balance of potential benefits and hazards is still unclear in high-risk patients.45,852 patients admitted to 1250 hospitals within 24 h of suspected acute MI onset were randomly allocated metoprolol (up to 15 mg intravenous then 200 mg oral daily; n=22,929) or matching placebo (n=22,923). 93% had ST-segment elevation or bundle branch block, and 7% had ST-segment depression. Treatment was to continue until discharge or up to 4 weeks in hospital (mean 15 days in survivors) and 89% completed it. The two prespecified co-primary outcomes were: (1) composite of death, reinfarction, or cardiac arrest; and (2) death from any cause during the scheduled treatment period. Comparisons were by intention to treat, and used the log-rank method. This study is registered with ClinicalTrials.gov, number NCT 00222573.Neither of the co-primary outcomes was significantly reduced by allocation to metoprolol. For death, reinfarction, or cardiac arrest, 2166 (9.4%) patients allocated metoprolol had at least one such event compared with 2261 (9.9%) allocated placebo (odds ratio [OR] 0.96, 95% CI 0.90-1.01; p=0.1). For death alone, there were 1774 (7.7%) deaths in the metoprolol group versus 1797 (7.8%) in the placebo group (OR 0.99, 0.92-1.05; p=0.69). Allocation to metoprolol was associated with five fewer people having reinfarction (464 [2.0%] metoprolol vs 568 [2.5%] placebo; OR 0.82, 0.72-0.92; p=0.001) and five fewer having ventricular fibrillation (581 [2.5%] vs 698 [3.0%]; OR 0.83, 0.75-0.93; p=0.001) per 1000 treated. Overall, these reductions were counterbalanced by 11 more per 1000 developing cardiogenic shock (1141 [5.0%] vs 885 [3.9%]; OR 1.30, 1.19-1.41; p<0.00001). This excess of cardiogenic shock was mainly during days 0-1 after admission, whereas the reductions in reinfarction and ventricular fibrillation emerged more gradually. Consequently, the overall effect on death, reinfarction, arrest, or shock was significantly adverse during days 0-1 and significantly beneficial thereafter. There was substantial net hazard in haemodynamically unstable patients, and moderate net benefit in those who were relatively stable (particularly after days 0-1).The use of early beta-blocker therapy in acute MI reduces the risks of reinfarction and ventricular fibrillation, but increases the risk of cardiogenic shock, especially during the first day or so after admission. Consequently, it might generally be prudent to consider starting beta-blocker therapy in hospital only when the haemodynamic condition after MI has stabilised.","Early intravenous then oral metoprolol in 45,852 patients with acute myocardial infarction: randomised placebo-controlled trial."
"615","Lancet.32","0.69",16271643,2005,"Despite previous randomised trials of early beta-blocker therapy in the emergency treatment of myocardial infarction (MI), uncertainty has persisted about the value of adding it to current standard interventions (eg, aspirin and fibrinolytic therapy), and the balance of potential benefits and hazards is still unclear in high-risk patients.45,852 patients admitted to 1250 hospitals within 24 h of suspected acute MI onset were randomly allocated metoprolol (up to 15 mg intravenous then 200 mg oral daily; n=22,929) or matching placebo (n=22,923). 93% had ST-segment elevation or bundle branch block, and 7% had ST-segment depression. Treatment was to continue until discharge or up to 4 weeks in hospital (mean 15 days in survivors) and 89% completed it. The two prespecified co-primary outcomes were: (1) composite of death, reinfarction, or cardiac arrest; and (2) death from any cause during the scheduled treatment period. Comparisons were by intention to treat, and used the log-rank method. This study is registered with ClinicalTrials.gov, number NCT 00222573.Neither of the co-primary outcomes was significantly reduced by allocation to metoprolol. For death, reinfarction, or cardiac arrest, 2166 (9.4%) patients allocated metoprolol had at least one such event compared with 2261 (9.9%) allocated placebo (odds ratio [OR] 0.96, 95% CI 0.90-1.01; p=0.1). For death alone, there were 1774 (7.7%) deaths in the metoprolol group versus 1797 (7.8%) in the placebo group (OR 0.99, 0.92-1.05; p=0.69). Allocation to metoprolol was associated with five fewer people having reinfarction (464 [2.0%] metoprolol vs 568 [2.5%] placebo; OR 0.82, 0.72-0.92; p=0.001) and five fewer having ventricular fibrillation (581 [2.5%] vs 698 [3.0%]; OR 0.83, 0.75-0.93; p=0.001) per 1000 treated. Overall, these reductions were counterbalanced by 11 more per 1000 developing cardiogenic shock (1141 [5.0%] vs 885 [3.9%]; OR 1.30, 1.19-1.41; p<0.00001). This excess of cardiogenic shock was mainly during days 0-1 after admission, whereas the reductions in reinfarction and ventricular fibrillation emerged more gradually. Consequently, the overall effect on death, reinfarction, arrest, or shock was significantly adverse during days 0-1 and significantly beneficial thereafter. There was substantial net hazard in haemodynamically unstable patients, and moderate net benefit in those who were relatively stable (particularly after days 0-1).The use of early beta-blocker therapy in acute MI reduces the risks of reinfarction and ventricular fibrillation, but increases the risk of cardiogenic shock, especially during the first day or so after admission. Consequently, it might generally be prudent to consider starting beta-blocker therapy in hospital only when the haemodynamic condition after MI has stabilised.","Early intravenous then oral metoprolol in 45,852 patients with acute myocardial infarction: randomised placebo-controlled trial."
"616","Lancet.33","0.001",16271643,2005,"Despite previous randomised trials of early beta-blocker therapy in the emergency treatment of myocardial infarction (MI), uncertainty has persisted about the value of adding it to current standard interventions (eg, aspirin and fibrinolytic therapy), and the balance of potential benefits and hazards is still unclear in high-risk patients.45,852 patients admitted to 1250 hospitals within 24 h of suspected acute MI onset were randomly allocated metoprolol (up to 15 mg intravenous then 200 mg oral daily; n=22,929) or matching placebo (n=22,923). 93% had ST-segment elevation or bundle branch block, and 7% had ST-segment depression. Treatment was to continue until discharge or up to 4 weeks in hospital (mean 15 days in survivors) and 89% completed it. The two prespecified co-primary outcomes were: (1) composite of death, reinfarction, or cardiac arrest; and (2) death from any cause during the scheduled treatment period. Comparisons were by intention to treat, and used the log-rank method. This study is registered with ClinicalTrials.gov, number NCT 00222573.Neither of the co-primary outcomes was significantly reduced by allocation to metoprolol. For death, reinfarction, or cardiac arrest, 2166 (9.4%) patients allocated metoprolol had at least one such event compared with 2261 (9.9%) allocated placebo (odds ratio [OR] 0.96, 95% CI 0.90-1.01; p=0.1). For death alone, there were 1774 (7.7%) deaths in the metoprolol group versus 1797 (7.8%) in the placebo group (OR 0.99, 0.92-1.05; p=0.69). Allocation to metoprolol was associated with five fewer people having reinfarction (464 [2.0%] metoprolol vs 568 [2.5%] placebo; OR 0.82, 0.72-0.92; p=0.001) and five fewer having ventricular fibrillation (581 [2.5%] vs 698 [3.0%]; OR 0.83, 0.75-0.93; p=0.001) per 1000 treated. Overall, these reductions were counterbalanced by 11 more per 1000 developing cardiogenic shock (1141 [5.0%] vs 885 [3.9%]; OR 1.30, 1.19-1.41; p<0.00001). This excess of cardiogenic shock was mainly during days 0-1 after admission, whereas the reductions in reinfarction and ventricular fibrillation emerged more gradually. Consequently, the overall effect on death, reinfarction, arrest, or shock was significantly adverse during days 0-1 and significantly beneficial thereafter. There was substantial net hazard in haemodynamically unstable patients, and moderate net benefit in those who were relatively stable (particularly after days 0-1).The use of early beta-blocker therapy in acute MI reduces the risks of reinfarction and ventricular fibrillation, but increases the risk of cardiogenic shock, especially during the first day or so after admission. Consequently, it might generally be prudent to consider starting beta-blocker therapy in hospital only when the haemodynamic condition after MI has stabilised.","Early intravenous then oral metoprolol in 45,852 patients with acute myocardial infarction: randomised placebo-controlled trial."
"617","Lancet.34","0.001",16271643,2005,"Despite previous randomised trials of early beta-blocker therapy in the emergency treatment of myocardial infarction (MI), uncertainty has persisted about the value of adding it to current standard interventions (eg, aspirin and fibrinolytic therapy), and the balance of potential benefits and hazards is still unclear in high-risk patients.45,852 patients admitted to 1250 hospitals within 24 h of suspected acute MI onset were randomly allocated metoprolol (up to 15 mg intravenous then 200 mg oral daily; n=22,929) or matching placebo (n=22,923). 93% had ST-segment elevation or bundle branch block, and 7% had ST-segment depression. Treatment was to continue until discharge or up to 4 weeks in hospital (mean 15 days in survivors) and 89% completed it. The two prespecified co-primary outcomes were: (1) composite of death, reinfarction, or cardiac arrest; and (2) death from any cause during the scheduled treatment period. Comparisons were by intention to treat, and used the log-rank method. This study is registered with ClinicalTrials.gov, number NCT 00222573.Neither of the co-primary outcomes was significantly reduced by allocation to metoprolol. For death, reinfarction, or cardiac arrest, 2166 (9.4%) patients allocated metoprolol had at least one such event compared with 2261 (9.9%) allocated placebo (odds ratio [OR] 0.96, 95% CI 0.90-1.01; p=0.1). For death alone, there were 1774 (7.7%) deaths in the metoprolol group versus 1797 (7.8%) in the placebo group (OR 0.99, 0.92-1.05; p=0.69). Allocation to metoprolol was associated with five fewer people having reinfarction (464 [2.0%] metoprolol vs 568 [2.5%] placebo; OR 0.82, 0.72-0.92; p=0.001) and five fewer having ventricular fibrillation (581 [2.5%] vs 698 [3.0%]; OR 0.83, 0.75-0.93; p=0.001) per 1000 treated. Overall, these reductions were counterbalanced by 11 more per 1000 developing cardiogenic shock (1141 [5.0%] vs 885 [3.9%]; OR 1.30, 1.19-1.41; p<0.00001). This excess of cardiogenic shock was mainly during days 0-1 after admission, whereas the reductions in reinfarction and ventricular fibrillation emerged more gradually. Consequently, the overall effect on death, reinfarction, arrest, or shock was significantly adverse during days 0-1 and significantly beneficial thereafter. There was substantial net hazard in haemodynamically unstable patients, and moderate net benefit in those who were relatively stable (particularly after days 0-1).The use of early beta-blocker therapy in acute MI reduces the risks of reinfarction and ventricular fibrillation, but increases the risk of cardiogenic shock, especially during the first day or so after admission. Consequently, it might generally be prudent to consider starting beta-blocker therapy in hospital only when the haemodynamic condition after MI has stabilised.","Early intravenous then oral metoprolol in 45,852 patients with acute myocardial infarction: randomised placebo-controlled trial."
"618","JAMA.2341","0.001",16287954,2005,"Evidence suggests that more intensive lowering of low-density lipoprotein cholesterol (LDL-C) than is commonly applied clinically will provide further benefit in stable coronary artery disease.To compare the effects of 2 strategies of lipid lowering on the risk of cardiovascular disease among patients with a previous myocardial infarction (MI).The IDEAL study, a prospective, randomized, open-label, blinded end-point evaluation trial conducted at 190 ambulatory cardiology care and specialist practices in northern Europe between March 1999 and March 2005 with a median follow-up of 4.8 years, which enrolled 8888 patients aged 80 years or younger with a history of acute MI.Patients were randomly assigned to receive a high dose of atorvastatin (80 mg/d; n = 4439), or usual-dose simvastatin (20 mg/d; n = 4449).Occurrence of a major coronary event, defined as coronary death, confirmed nonfatal acute MI, or cardiac arrest with resuscitation.During treatment, mean LDL-C levels were 104 (SE, 0.3) mg/dL in the simvastatin group and 81 (SE, 0.3) mg/dL in the atorvastatin group. A major coronary event occurred in 463 simvastatin patients (10.4%) and in 411 atorvastatin patients (9.3%) (hazard ratio [HR], 0.89; 95% CI, 0.78-1.01; P = .07). Nonfatal acute MI occurred in 321 (7.2%) and 267 (6.0%) in the 2 groups (HR, 0.83; 95% CI, 0.71-0.98; P = .02), but no differences were seen in the 2 other components of the primary end point. Major cardiovascular events occurred in 608 and 533 in the 2 groups, respectively (HR, 0.87; 95% CI, 0.77-0.98; P = .02). Occurrence of any coronary event was reported in 1059 simvastatin and 898 atorvastatin patients (HR, 0.84; 95% CI, 0.76-0.91; P<.001). Noncardiovascular death occurred in 156 (3.5%) and 143 (3.2%) in the 2 groups (HR, 0.92; 95% CI, 0.73-1.15; P = .47). Death from any cause occurred in 374 (8.4%) in the simvastatin group and 366 (8.2%) in the atorvastatin group (HR, 0.98; 95% CI, 0.85-1.13; P = .81). Patients in the atorvastatin group had higher rates of drug discontinuation due to nonserious adverse events; transaminase elevation resulted in 43 (1.0%) vs 5 (0.1%) withdrawals (P<.001). Serious myopathy and rhabdomyolysis were rare in both groups.In this study of patients with previous MI, intensive lowering of LDL-C did not result in a significant reduction in the primary outcome of major coronary events, but did reduce the risk of other composite secondary end points and nonfatal acute MI. There were no differences in cardiovascular or all-cause mortality. Patients with MI may benefit from intensive lowering of LDL-C without an increase in noncardiovascular mortality or other serious adverse reactions.Trial Registration ClinicalTrials.gov Identifier: NCT00159835.","High-dose atorvastatin vs usual-dose simvastatin for secondary prevention after myocardial infarction: the IDEAL study: a randomized controlled trial."
"619","JAMA.2621","0.07",16287954,2005,"Evidence suggests that more intensive lowering of low-density lipoprotein cholesterol (LDL-C) than is commonly applied clinically will provide further benefit in stable coronary artery disease.To compare the effects of 2 strategies of lipid lowering on the risk of cardiovascular disease among patients with a previous myocardial infarction (MI).The IDEAL study, a prospective, randomized, open-label, blinded end-point evaluation trial conducted at 190 ambulatory cardiology care and specialist practices in northern Europe between March 1999 and March 2005 with a median follow-up of 4.8 years, which enrolled 8888 patients aged 80 years or younger with a history of acute MI.Patients were randomly assigned to receive a high dose of atorvastatin (80 mg/d; n = 4439), or usual-dose simvastatin (20 mg/d; n = 4449).Occurrence of a major coronary event, defined as coronary death, confirmed nonfatal acute MI, or cardiac arrest with resuscitation.During treatment, mean LDL-C levels were 104 (SE, 0.3) mg/dL in the simvastatin group and 81 (SE, 0.3) mg/dL in the atorvastatin group. A major coronary event occurred in 463 simvastatin patients (10.4%) and in 411 atorvastatin patients (9.3%) (hazard ratio [HR], 0.89; 95% CI, 0.78-1.01; P = .07). Nonfatal acute MI occurred in 321 (7.2%) and 267 (6.0%) in the 2 groups (HR, 0.83; 95% CI, 0.71-0.98; P = .02), but no differences were seen in the 2 other components of the primary end point. Major cardiovascular events occurred in 608 and 533 in the 2 groups, respectively (HR, 0.87; 95% CI, 0.77-0.98; P = .02). Occurrence of any coronary event was reported in 1059 simvastatin and 898 atorvastatin patients (HR, 0.84; 95% CI, 0.76-0.91; P<.001). Noncardiovascular death occurred in 156 (3.5%) and 143 (3.2%) in the 2 groups (HR, 0.92; 95% CI, 0.73-1.15; P = .47). Death from any cause occurred in 374 (8.4%) in the simvastatin group and 366 (8.2%) in the atorvastatin group (HR, 0.98; 95% CI, 0.85-1.13; P = .81). Patients in the atorvastatin group had higher rates of drug discontinuation due to nonserious adverse events; transaminase elevation resulted in 43 (1.0%) vs 5 (0.1%) withdrawals (P<.001). Serious myopathy and rhabdomyolysis were rare in both groups.In this study of patients with previous MI, intensive lowering of LDL-C did not result in a significant reduction in the primary outcome of major coronary events, but did reduce the risk of other composite secondary end points and nonfatal acute MI. There were no differences in cardiovascular or all-cause mortality. Patients with MI may benefit from intensive lowering of LDL-C without an increase in noncardiovascular mortality or other serious adverse reactions.Trial Registration ClinicalTrials.gov Identifier: NCT00159835.","High-dose atorvastatin vs usual-dose simvastatin for secondary prevention after myocardial infarction: the IDEAL study: a randomized controlled trial."
"620","JAMA.2631","0.02",16287954,2005,"Evidence suggests that more intensive lowering of low-density lipoprotein cholesterol (LDL-C) than is commonly applied clinically will provide further benefit in stable coronary artery disease.To compare the effects of 2 strategies of lipid lowering on the risk of cardiovascular disease among patients with a previous myocardial infarction (MI).The IDEAL study, a prospective, randomized, open-label, blinded end-point evaluation trial conducted at 190 ambulatory cardiology care and specialist practices in northern Europe between March 1999 and March 2005 with a median follow-up of 4.8 years, which enrolled 8888 patients aged 80 years or younger with a history of acute MI.Patients were randomly assigned to receive a high dose of atorvastatin (80 mg/d; n = 4439), or usual-dose simvastatin (20 mg/d; n = 4449).Occurrence of a major coronary event, defined as coronary death, confirmed nonfatal acute MI, or cardiac arrest with resuscitation.During treatment, mean LDL-C levels were 104 (SE, 0.3) mg/dL in the simvastatin group and 81 (SE, 0.3) mg/dL in the atorvastatin group. A major coronary event occurred in 463 simvastatin patients (10.4%) and in 411 atorvastatin patients (9.3%) (hazard ratio [HR], 0.89; 95% CI, 0.78-1.01; P = .07). Nonfatal acute MI occurred in 321 (7.2%) and 267 (6.0%) in the 2 groups (HR, 0.83; 95% CI, 0.71-0.98; P = .02), but no differences were seen in the 2 other components of the primary end point. Major cardiovascular events occurred in 608 and 533 in the 2 groups, respectively (HR, 0.87; 95% CI, 0.77-0.98; P = .02). Occurrence of any coronary event was reported in 1059 simvastatin and 898 atorvastatin patients (HR, 0.84; 95% CI, 0.76-0.91; P<.001). Noncardiovascular death occurred in 156 (3.5%) and 143 (3.2%) in the 2 groups (HR, 0.92; 95% CI, 0.73-1.15; P = .47). Death from any cause occurred in 374 (8.4%) in the simvastatin group and 366 (8.2%) in the atorvastatin group (HR, 0.98; 95% CI, 0.85-1.13; P = .81). Patients in the atorvastatin group had higher rates of drug discontinuation due to nonserious adverse events; transaminase elevation resulted in 43 (1.0%) vs 5 (0.1%) withdrawals (P<.001). Serious myopathy and rhabdomyolysis were rare in both groups.In this study of patients with previous MI, intensive lowering of LDL-C did not result in a significant reduction in the primary outcome of major coronary events, but did reduce the risk of other composite secondary end points and nonfatal acute MI. There were no differences in cardiovascular or all-cause mortality. Patients with MI may benefit from intensive lowering of LDL-C without an increase in noncardiovascular mortality or other serious adverse reactions.Trial Registration ClinicalTrials.gov Identifier: NCT00159835.","High-dose atorvastatin vs usual-dose simvastatin for secondary prevention after myocardial infarction: the IDEAL study: a randomized controlled trial."
"621","JAMA.2641","0.02",16287954,2005,"Evidence suggests that more intensive lowering of low-density lipoprotein cholesterol (LDL-C) than is commonly applied clinically will provide further benefit in stable coronary artery disease.To compare the effects of 2 strategies of lipid lowering on the risk of cardiovascular disease among patients with a previous myocardial infarction (MI).The IDEAL study, a prospective, randomized, open-label, blinded end-point evaluation trial conducted at 190 ambulatory cardiology care and specialist practices in northern Europe between March 1999 and March 2005 with a median follow-up of 4.8 years, which enrolled 8888 patients aged 80 years or younger with a history of acute MI.Patients were randomly assigned to receive a high dose of atorvastatin (80 mg/d; n = 4439), or usual-dose simvastatin (20 mg/d; n = 4449).Occurrence of a major coronary event, defined as coronary death, confirmed nonfatal acute MI, or cardiac arrest with resuscitation.During treatment, mean LDL-C levels were 104 (SE, 0.3) mg/dL in the simvastatin group and 81 (SE, 0.3) mg/dL in the atorvastatin group. A major coronary event occurred in 463 simvastatin patients (10.4%) and in 411 atorvastatin patients (9.3%) (hazard ratio [HR], 0.89; 95% CI, 0.78-1.01; P = .07). Nonfatal acute MI occurred in 321 (7.2%) and 267 (6.0%) in the 2 groups (HR, 0.83; 95% CI, 0.71-0.98; P = .02), but no differences were seen in the 2 other components of the primary end point. Major cardiovascular events occurred in 608 and 533 in the 2 groups, respectively (HR, 0.87; 95% CI, 0.77-0.98; P = .02). Occurrence of any coronary event was reported in 1059 simvastatin and 898 atorvastatin patients (HR, 0.84; 95% CI, 0.76-0.91; P<.001). Noncardiovascular death occurred in 156 (3.5%) and 143 (3.2%) in the 2 groups (HR, 0.92; 95% CI, 0.73-1.15; P = .47). Death from any cause occurred in 374 (8.4%) in the simvastatin group and 366 (8.2%) in the atorvastatin group (HR, 0.98; 95% CI, 0.85-1.13; P = .81). Patients in the atorvastatin group had higher rates of drug discontinuation due to nonserious adverse events; transaminase elevation resulted in 43 (1.0%) vs 5 (0.1%) withdrawals (P<.001). Serious myopathy and rhabdomyolysis were rare in both groups.In this study of patients with previous MI, intensive lowering of LDL-C did not result in a significant reduction in the primary outcome of major coronary events, but did reduce the risk of other composite secondary end points and nonfatal acute MI. There were no differences in cardiovascular or all-cause mortality. Patients with MI may benefit from intensive lowering of LDL-C without an increase in noncardiovascular mortality or other serious adverse reactions.Trial Registration ClinicalTrials.gov Identifier: NCT00159835.","High-dose atorvastatin vs usual-dose simvastatin for secondary prevention after myocardial infarction: the IDEAL study: a randomized controlled trial."
"622","JAMA.2651","0.47",16287954,2005,"Evidence suggests that more intensive lowering of low-density lipoprotein cholesterol (LDL-C) than is commonly applied clinically will provide further benefit in stable coronary artery disease.To compare the effects of 2 strategies of lipid lowering on the risk of cardiovascular disease among patients with a previous myocardial infarction (MI).The IDEAL study, a prospective, randomized, open-label, blinded end-point evaluation trial conducted at 190 ambulatory cardiology care and specialist practices in northern Europe between March 1999 and March 2005 with a median follow-up of 4.8 years, which enrolled 8888 patients aged 80 years or younger with a history of acute MI.Patients were randomly assigned to receive a high dose of atorvastatin (80 mg/d; n = 4439), or usual-dose simvastatin (20 mg/d; n = 4449).Occurrence of a major coronary event, defined as coronary death, confirmed nonfatal acute MI, or cardiac arrest with resuscitation.During treatment, mean LDL-C levels were 104 (SE, 0.3) mg/dL in the simvastatin group and 81 (SE, 0.3) mg/dL in the atorvastatin group. A major coronary event occurred in 463 simvastatin patients (10.4%) and in 411 atorvastatin patients (9.3%) (hazard ratio [HR], 0.89; 95% CI, 0.78-1.01; P = .07). Nonfatal acute MI occurred in 321 (7.2%) and 267 (6.0%) in the 2 groups (HR, 0.83; 95% CI, 0.71-0.98; P = .02), but no differences were seen in the 2 other components of the primary end point. Major cardiovascular events occurred in 608 and 533 in the 2 groups, respectively (HR, 0.87; 95% CI, 0.77-0.98; P = .02). Occurrence of any coronary event was reported in 1059 simvastatin and 898 atorvastatin patients (HR, 0.84; 95% CI, 0.76-0.91; P<.001). Noncardiovascular death occurred in 156 (3.5%) and 143 (3.2%) in the 2 groups (HR, 0.92; 95% CI, 0.73-1.15; P = .47). Death from any cause occurred in 374 (8.4%) in the simvastatin group and 366 (8.2%) in the atorvastatin group (HR, 0.98; 95% CI, 0.85-1.13; P = .81). Patients in the atorvastatin group had higher rates of drug discontinuation due to nonserious adverse events; transaminase elevation resulted in 43 (1.0%) vs 5 (0.1%) withdrawals (P<.001). Serious myopathy and rhabdomyolysis were rare in both groups.In this study of patients with previous MI, intensive lowering of LDL-C did not result in a significant reduction in the primary outcome of major coronary events, but did reduce the risk of other composite secondary end points and nonfatal acute MI. There were no differences in cardiovascular or all-cause mortality. Patients with MI may benefit from intensive lowering of LDL-C without an increase in noncardiovascular mortality or other serious adverse reactions.Trial Registration ClinicalTrials.gov Identifier: NCT00159835.","High-dose atorvastatin vs usual-dose simvastatin for secondary prevention after myocardial infarction: the IDEAL study: a randomized controlled trial."
"623","JAMA.2661","0.81",16287954,2005,"Evidence suggests that more intensive lowering of low-density lipoprotein cholesterol (LDL-C) than is commonly applied clinically will provide further benefit in stable coronary artery disease.To compare the effects of 2 strategies of lipid lowering on the risk of cardiovascular disease among patients with a previous myocardial infarction (MI).The IDEAL study, a prospective, randomized, open-label, blinded end-point evaluation trial conducted at 190 ambulatory cardiology care and specialist practices in northern Europe between March 1999 and March 2005 with a median follow-up of 4.8 years, which enrolled 8888 patients aged 80 years or younger with a history of acute MI.Patients were randomly assigned to receive a high dose of atorvastatin (80 mg/d; n = 4439), or usual-dose simvastatin (20 mg/d; n = 4449).Occurrence of a major coronary event, defined as coronary death, confirmed nonfatal acute MI, or cardiac arrest with resuscitation.During treatment, mean LDL-C levels were 104 (SE, 0.3) mg/dL in the simvastatin group and 81 (SE, 0.3) mg/dL in the atorvastatin group. A major coronary event occurred in 463 simvastatin patients (10.4%) and in 411 atorvastatin patients (9.3%) (hazard ratio [HR], 0.89; 95% CI, 0.78-1.01; P = .07). Nonfatal acute MI occurred in 321 (7.2%) and 267 (6.0%) in the 2 groups (HR, 0.83; 95% CI, 0.71-0.98; P = .02), but no differences were seen in the 2 other components of the primary end point. Major cardiovascular events occurred in 608 and 533 in the 2 groups, respectively (HR, 0.87; 95% CI, 0.77-0.98; P = .02). Occurrence of any coronary event was reported in 1059 simvastatin and 898 atorvastatin patients (HR, 0.84; 95% CI, 0.76-0.91; P<.001). Noncardiovascular death occurred in 156 (3.5%) and 143 (3.2%) in the 2 groups (HR, 0.92; 95% CI, 0.73-1.15; P = .47). Death from any cause occurred in 374 (8.4%) in the simvastatin group and 366 (8.2%) in the atorvastatin group (HR, 0.98; 95% CI, 0.85-1.13; P = .81). Patients in the atorvastatin group had higher rates of drug discontinuation due to nonserious adverse events; transaminase elevation resulted in 43 (1.0%) vs 5 (0.1%) withdrawals (P<.001). Serious myopathy and rhabdomyolysis were rare in both groups.In this study of patients with previous MI, intensive lowering of LDL-C did not result in a significant reduction in the primary outcome of major coronary events, but did reduce the risk of other composite secondary end points and nonfatal acute MI. There were no differences in cardiovascular or all-cause mortality. Patients with MI may benefit from intensive lowering of LDL-C without an increase in noncardiovascular mortality or other serious adverse reactions.Trial Registration ClinicalTrials.gov Identifier: NCT00159835.","High-dose atorvastatin vs usual-dose simvastatin for secondary prevention after myocardial infarction: the IDEAL study: a randomized controlled trial."
"624","JAMA.2571","0.65",16304073,2005,"The SYNERGY trial comparing enoxaparin and unfractionated heparin in high-risk patients with acute coronary syndromes (ACS) showed that enoxaparin was not inferior to unfractionated heparin in reducing death or nonfatal myocardial infarction (MI) at 30 days.To evaluate continued risk in this patient cohort through 6-month and 1-year follow-up.Overall, 9978 patients were randomized from August 2001 through December 2003 in 487 hospitals in 12 countries. Patients were followed up for 6 months and for 1 year.Six-month outcomes were death, nonfatal MI, revascularization procedures, stroke, and site-investigator-reported need for rehospitalization; 1-year outcome was all-cause death.Six-month and 1-year follow-up data were available for 9957 (99.8%) and 9608 (96.3%) of 9978 patients, respectively; 541 patients (5.4%) had died at 6 months and 739 (7.4%) at 1 year. Death or nonfatal MI at 6 months occurred in 872 patients receiving enoxaparin (17.6%) vs 884 receiving unfractionated heparin (17.8%) (hazard ratio [HR], 0.98; 95% confidence interval [CI], 0.89-1.07; P = .65). In the subgroup of patients receiving consistent therapy, ie, only enoxaparin or unfractionated heparin during the index hospitalization (n = 6138), a reduction in death or nonfatal MI with enoxaparin was maintained at 180 days (HR, 0.85; 95% CI, 0.75-0.95; P = .006). Rehospitalization within 180 days occurred in 858 patients receiving enoxaparin (17.9%) and 911 receiving unfractionated heparin (19.0%) (HR, 0.94; 95% CI, 0.85-1.03; P = .17). One-year all-cause death rates were similar in the 2 treatment groups (380/4974 [7.6%] for enoxaparin vs 359/4948 [7.3%] for unfractionated heparin; HR, 1.06; 95% CI, 0.92-1.22; P = .44). One-year death rates in patients receiving consistent therapy were also similar (251/3386 [7.4%] for enoxaparin vs 213/2720 [7.8%] for unfractionated heparin; HR, 0.95; 95% CI, 0.79-1.14; P = .55).In the SYNERGY trial, patients continued to experience adverse cardiac events through long-term follow-up. The effect of enoxaparin on death or MI compared with that of unfractionated heparin at 6 months was similar to that observed at 30 days in the overall trial and in the consistent-therapy group. One-year death rates were also similar in both groups. High-risk patients with ACS remain susceptible to continued cardiac events despite aggressive therapies.ClinicalTrials.gov Identifier: NCT00043784.","High-risk patients with acute coronary syndromes treated with low-molecular-weight or unfractionated heparin: outcomes at 6 months and 1 year in the SYNERGY trial."
"625","JAMA.2581","0.006",16304073,2005,"The SYNERGY trial comparing enoxaparin and unfractionated heparin in high-risk patients with acute coronary syndromes (ACS) showed that enoxaparin was not inferior to unfractionated heparin in reducing death or nonfatal myocardial infarction (MI) at 30 days.To evaluate continued risk in this patient cohort through 6-month and 1-year follow-up.Overall, 9978 patients were randomized from August 2001 through December 2003 in 487 hospitals in 12 countries. Patients were followed up for 6 months and for 1 year.Six-month outcomes were death, nonfatal MI, revascularization procedures, stroke, and site-investigator-reported need for rehospitalization; 1-year outcome was all-cause death.Six-month and 1-year follow-up data were available for 9957 (99.8%) and 9608 (96.3%) of 9978 patients, respectively; 541 patients (5.4%) had died at 6 months and 739 (7.4%) at 1 year. Death or nonfatal MI at 6 months occurred in 872 patients receiving enoxaparin (17.6%) vs 884 receiving unfractionated heparin (17.8%) (hazard ratio [HR], 0.98; 95% confidence interval [CI], 0.89-1.07; P = .65). In the subgroup of patients receiving consistent therapy, ie, only enoxaparin or unfractionated heparin during the index hospitalization (n = 6138), a reduction in death or nonfatal MI with enoxaparin was maintained at 180 days (HR, 0.85; 95% CI, 0.75-0.95; P = .006). Rehospitalization within 180 days occurred in 858 patients receiving enoxaparin (17.9%) and 911 receiving unfractionated heparin (19.0%) (HR, 0.94; 95% CI, 0.85-1.03; P = .17). One-year all-cause death rates were similar in the 2 treatment groups (380/4974 [7.6%] for enoxaparin vs 359/4948 [7.3%] for unfractionated heparin; HR, 1.06; 95% CI, 0.92-1.22; P = .44). One-year death rates in patients receiving consistent therapy were also similar (251/3386 [7.4%] for enoxaparin vs 213/2720 [7.8%] for unfractionated heparin; HR, 0.95; 95% CI, 0.79-1.14; P = .55).In the SYNERGY trial, patients continued to experience adverse cardiac events through long-term follow-up. The effect of enoxaparin on death or MI compared with that of unfractionated heparin at 6 months was similar to that observed at 30 days in the overall trial and in the consistent-therapy group. One-year death rates were also similar in both groups. High-risk patients with ACS remain susceptible to continued cardiac events despite aggressive therapies.ClinicalTrials.gov Identifier: NCT00043784.","High-risk patients with acute coronary syndromes treated with low-molecular-weight or unfractionated heparin: outcomes at 6 months and 1 year in the SYNERGY trial."
"626","JAMA.2591","0.17",16304073,2005,"The SYNERGY trial comparing enoxaparin and unfractionated heparin in high-risk patients with acute coronary syndromes (ACS) showed that enoxaparin was not inferior to unfractionated heparin in reducing death or nonfatal myocardial infarction (MI) at 30 days.To evaluate continued risk in this patient cohort through 6-month and 1-year follow-up.Overall, 9978 patients were randomized from August 2001 through December 2003 in 487 hospitals in 12 countries. Patients were followed up for 6 months and for 1 year.Six-month outcomes were death, nonfatal MI, revascularization procedures, stroke, and site-investigator-reported need for rehospitalization; 1-year outcome was all-cause death.Six-month and 1-year follow-up data were available for 9957 (99.8%) and 9608 (96.3%) of 9978 patients, respectively; 541 patients (5.4%) had died at 6 months and 739 (7.4%) at 1 year. Death or nonfatal MI at 6 months occurred in 872 patients receiving enoxaparin (17.6%) vs 884 receiving unfractionated heparin (17.8%) (hazard ratio [HR], 0.98; 95% confidence interval [CI], 0.89-1.07; P = .65). In the subgroup of patients receiving consistent therapy, ie, only enoxaparin or unfractionated heparin during the index hospitalization (n = 6138), a reduction in death or nonfatal MI with enoxaparin was maintained at 180 days (HR, 0.85; 95% CI, 0.75-0.95; P = .006). Rehospitalization within 180 days occurred in 858 patients receiving enoxaparin (17.9%) and 911 receiving unfractionated heparin (19.0%) (HR, 0.94; 95% CI, 0.85-1.03; P = .17). One-year all-cause death rates were similar in the 2 treatment groups (380/4974 [7.6%] for enoxaparin vs 359/4948 [7.3%] for unfractionated heparin; HR, 1.06; 95% CI, 0.92-1.22; P = .44). One-year death rates in patients receiving consistent therapy were also similar (251/3386 [7.4%] for enoxaparin vs 213/2720 [7.8%] for unfractionated heparin; HR, 0.95; 95% CI, 0.79-1.14; P = .55).In the SYNERGY trial, patients continued to experience adverse cardiac events through long-term follow-up. The effect of enoxaparin on death or MI compared with that of unfractionated heparin at 6 months was similar to that observed at 30 days in the overall trial and in the consistent-therapy group. One-year death rates were also similar in both groups. High-risk patients with ACS remain susceptible to continued cardiac events despite aggressive therapies.ClinicalTrials.gov Identifier: NCT00043784.","High-risk patients with acute coronary syndromes treated with low-molecular-weight or unfractionated heparin: outcomes at 6 months and 1 year in the SYNERGY trial."
"627","JAMA.2601","0.44",16304073,2005,"The SYNERGY trial comparing enoxaparin and unfractionated heparin in high-risk patients with acute coronary syndromes (ACS) showed that enoxaparin was not inferior to unfractionated heparin in reducing death or nonfatal myocardial infarction (MI) at 30 days.To evaluate continued risk in this patient cohort through 6-month and 1-year follow-up.Overall, 9978 patients were randomized from August 2001 through December 2003 in 487 hospitals in 12 countries. Patients were followed up for 6 months and for 1 year.Six-month outcomes were death, nonfatal MI, revascularization procedures, stroke, and site-investigator-reported need for rehospitalization; 1-year outcome was all-cause death.Six-month and 1-year follow-up data were available for 9957 (99.8%) and 9608 (96.3%) of 9978 patients, respectively; 541 patients (5.4%) had died at 6 months and 739 (7.4%) at 1 year. Death or nonfatal MI at 6 months occurred in 872 patients receiving enoxaparin (17.6%) vs 884 receiving unfractionated heparin (17.8%) (hazard ratio [HR], 0.98; 95% confidence interval [CI], 0.89-1.07; P = .65). In the subgroup of patients receiving consistent therapy, ie, only enoxaparin or unfractionated heparin during the index hospitalization (n = 6138), a reduction in death or nonfatal MI with enoxaparin was maintained at 180 days (HR, 0.85; 95% CI, 0.75-0.95; P = .006). Rehospitalization within 180 days occurred in 858 patients receiving enoxaparin (17.9%) and 911 receiving unfractionated heparin (19.0%) (HR, 0.94; 95% CI, 0.85-1.03; P = .17). One-year all-cause death rates were similar in the 2 treatment groups (380/4974 [7.6%] for enoxaparin vs 359/4948 [7.3%] for unfractionated heparin; HR, 1.06; 95% CI, 0.92-1.22; P = .44). One-year death rates in patients receiving consistent therapy were also similar (251/3386 [7.4%] for enoxaparin vs 213/2720 [7.8%] for unfractionated heparin; HR, 0.95; 95% CI, 0.79-1.14; P = .55).In the SYNERGY trial, patients continued to experience adverse cardiac events through long-term follow-up. The effect of enoxaparin on death or MI compared with that of unfractionated heparin at 6 months was similar to that observed at 30 days in the overall trial and in the consistent-therapy group. One-year death rates were also similar in both groups. High-risk patients with ACS remain susceptible to continued cardiac events despite aggressive therapies.ClinicalTrials.gov Identifier: NCT00043784.","High-risk patients with acute coronary syndromes treated with low-molecular-weight or unfractionated heparin: outcomes at 6 months and 1 year in the SYNERGY trial."
"628","JAMA.2611","0.55",16304073,2005,"The SYNERGY trial comparing enoxaparin and unfractionated heparin in high-risk patients with acute coronary syndromes (ACS) showed that enoxaparin was not inferior to unfractionated heparin in reducing death or nonfatal myocardial infarction (MI) at 30 days.To evaluate continued risk in this patient cohort through 6-month and 1-year follow-up.Overall, 9978 patients were randomized from August 2001 through December 2003 in 487 hospitals in 12 countries. Patients were followed up for 6 months and for 1 year.Six-month outcomes were death, nonfatal MI, revascularization procedures, stroke, and site-investigator-reported need for rehospitalization; 1-year outcome was all-cause death.Six-month and 1-year follow-up data were available for 9957 (99.8%) and 9608 (96.3%) of 9978 patients, respectively; 541 patients (5.4%) had died at 6 months and 739 (7.4%) at 1 year. Death or nonfatal MI at 6 months occurred in 872 patients receiving enoxaparin (17.6%) vs 884 receiving unfractionated heparin (17.8%) (hazard ratio [HR], 0.98; 95% confidence interval [CI], 0.89-1.07; P = .65). In the subgroup of patients receiving consistent therapy, ie, only enoxaparin or unfractionated heparin during the index hospitalization (n = 6138), a reduction in death or nonfatal MI with enoxaparin was maintained at 180 days (HR, 0.85; 95% CI, 0.75-0.95; P = .006). Rehospitalization within 180 days occurred in 858 patients receiving enoxaparin (17.9%) and 911 receiving unfractionated heparin (19.0%) (HR, 0.94; 95% CI, 0.85-1.03; P = .17). One-year all-cause death rates were similar in the 2 treatment groups (380/4974 [7.6%] for enoxaparin vs 359/4948 [7.3%] for unfractionated heparin; HR, 1.06; 95% CI, 0.92-1.22; P = .44). One-year death rates in patients receiving consistent therapy were also similar (251/3386 [7.4%] for enoxaparin vs 213/2720 [7.8%] for unfractionated heparin; HR, 0.95; 95% CI, 0.79-1.14; P = .55).In the SYNERGY trial, patients continued to experience adverse cardiac events through long-term follow-up. The effect of enoxaparin on death or MI compared with that of unfractionated heparin at 6 months was similar to that observed at 30 days in the overall trial and in the consistent-therapy group. One-year death rates were also similar in both groups. High-risk patients with ACS remain susceptible to continued cardiac events despite aggressive therapies.ClinicalTrials.gov Identifier: NCT00043784.","High-risk patients with acute coronary syndromes treated with low-molecular-weight or unfractionated heparin: outcomes at 6 months and 1 year in the SYNERGY trial."
"629","Lancet.371","0.16",16310551,2005,"Patients with type 2 diabetes mellitus are at increased risk of cardiovascular disease, partly owing to dyslipidaemia, which can be amenable to fibrate therapy. We designed the Fenofibrate Intervention and Event Lowering in Diabetes (FIELD) study to assess the effect of fenofibrate on cardiovascular disease events in these patients.We did a multinational, randomised controlled trial with 9795 participants aged 50-75 years, with type 2 diabetes mellitus, and not taking statin therapy at study entry. After a placebo and a fenofibrate run-in phase, we randomly assigned patients (2131 with previous cardiovascular disease and 7664 without) with a total-cholesterol concentration of 3.0-6.5 mmol/L and a total-cholesterol/HDL-cholesterol ratio of 4.0 or more or plasma triglyceride of 1.0-5.0 mmol/L to micronised fenofibrate 200 mg daily (n=4895) or matching placebo (n=4900). Our primary outcome was coronary events (coronary heart disease death or non-fatal myocardial infarction); the outcome for prespecified subgroup analyses was total cardiovascular events (the composite of cardiovascular death, myocardial infarction, stroke, and coronary and carotid revascularisation). Analysis was by intention to treat. The study was prospectively registered (number ISRCTN 64783481).Vital status was confirmed on all but 22 patients. Averaged over the 5 years' study duration, similar proportions in each group discontinued study medication (10% placebo vs 11% fenofibrate) and more patients allocated placebo (17%) than fenofibrate (8%; p<0.0001) commenced other lipid treatments, predominantly statins. 5.9% (n=288) of patients on placebo and 5.2% (n=256) of those on fenofibrate had a coronary event (relative reduction of 11%; hazard ratio [HR] 0.89, 95% CI 0.75-1.05; p=0.16). This finding corresponds to a significant 24% reduction in non-fatal myocardial infarction (0.76, 0.62-0.94; p=0.010) and a non-significant increase in coronary heart disease mortality (1.19, 0.90-1.57; p=0.22). Total cardiovascular disease events were significantly reduced from 13.9% to 12.5% (0.89, 0.80-0.99; p=0.035). This finding included a 21% reduction in coronary revascularisation (0.79, 0.68-0.93; p=0.003). Total mortality was 6.6% in the placebo group and 7.3% in the fenofibrate group (p=0.18). Fenofibrate was associated with less albuminuria progression (p=0.002), and less retinopathy needing laser treatment (5.2%vs 3.6%, p=0.0003). There was a slight increase in pancreatitis (0.5%vs 0.8%, p=0.031) and pulmonary embolism (0.7%vs 1.1%, p=0.022), but no other significant adverse effects.Fenofibrate did not significantly reduce the risk of the primary outcome of coronary events. It did reduce total cardiovascular events, mainly due to fewer non-fatal myocardial infarctions and revascularisations. The higher rate of starting statin therapy in patients allocated placebo might have masked a moderately larger treatment benefit.","Effects of long-term fenofibrate therapy on cardiovascular events in 9795 people with type 2 diabetes mellitus (the FIELD study): randomised controlled trial."
"630","Lancet.381","0.01",16310551,2005,"Patients with type 2 diabetes mellitus are at increased risk of cardiovascular disease, partly owing to dyslipidaemia, which can be amenable to fibrate therapy. We designed the Fenofibrate Intervention and Event Lowering in Diabetes (FIELD) study to assess the effect of fenofibrate on cardiovascular disease events in these patients.We did a multinational, randomised controlled trial with 9795 participants aged 50-75 years, with type 2 diabetes mellitus, and not taking statin therapy at study entry. After a placebo and a fenofibrate run-in phase, we randomly assigned patients (2131 with previous cardiovascular disease and 7664 without) with a total-cholesterol concentration of 3.0-6.5 mmol/L and a total-cholesterol/HDL-cholesterol ratio of 4.0 or more or plasma triglyceride of 1.0-5.0 mmol/L to micronised fenofibrate 200 mg daily (n=4895) or matching placebo (n=4900). Our primary outcome was coronary events (coronary heart disease death or non-fatal myocardial infarction); the outcome for prespecified subgroup analyses was total cardiovascular events (the composite of cardiovascular death, myocardial infarction, stroke, and coronary and carotid revascularisation). Analysis was by intention to treat. The study was prospectively registered (number ISRCTN 64783481).Vital status was confirmed on all but 22 patients. Averaged over the 5 years' study duration, similar proportions in each group discontinued study medication (10% placebo vs 11% fenofibrate) and more patients allocated placebo (17%) than fenofibrate (8%; p<0.0001) commenced other lipid treatments, predominantly statins. 5.9% (n=288) of patients on placebo and 5.2% (n=256) of those on fenofibrate had a coronary event (relative reduction of 11%; hazard ratio [HR] 0.89, 95% CI 0.75-1.05; p=0.16). This finding corresponds to a significant 24% reduction in non-fatal myocardial infarction (0.76, 0.62-0.94; p=0.010) and a non-significant increase in coronary heart disease mortality (1.19, 0.90-1.57; p=0.22). Total cardiovascular disease events were significantly reduced from 13.9% to 12.5% (0.89, 0.80-0.99; p=0.035). This finding included a 21% reduction in coronary revascularisation (0.79, 0.68-0.93; p=0.003). Total mortality was 6.6% in the placebo group and 7.3% in the fenofibrate group (p=0.18). Fenofibrate was associated with less albuminuria progression (p=0.002), and less retinopathy needing laser treatment (5.2%vs 3.6%, p=0.0003). There was a slight increase in pancreatitis (0.5%vs 0.8%, p=0.031) and pulmonary embolism (0.7%vs 1.1%, p=0.022), but no other significant adverse effects.Fenofibrate did not significantly reduce the risk of the primary outcome of coronary events. It did reduce total cardiovascular events, mainly due to fewer non-fatal myocardial infarctions and revascularisations. The higher rate of starting statin therapy in patients allocated placebo might have masked a moderately larger treatment benefit.","Effects of long-term fenofibrate therapy on cardiovascular events in 9795 people with type 2 diabetes mellitus (the FIELD study): randomised controlled trial."
"631","Lancet.391","0.22",16310551,2005,"Patients with type 2 diabetes mellitus are at increased risk of cardiovascular disease, partly owing to dyslipidaemia, which can be amenable to fibrate therapy. We designed the Fenofibrate Intervention and Event Lowering in Diabetes (FIELD) study to assess the effect of fenofibrate on cardiovascular disease events in these patients.We did a multinational, randomised controlled trial with 9795 participants aged 50-75 years, with type 2 diabetes mellitus, and not taking statin therapy at study entry. After a placebo and a fenofibrate run-in phase, we randomly assigned patients (2131 with previous cardiovascular disease and 7664 without) with a total-cholesterol concentration of 3.0-6.5 mmol/L and a total-cholesterol/HDL-cholesterol ratio of 4.0 or more or plasma triglyceride of 1.0-5.0 mmol/L to micronised fenofibrate 200 mg daily (n=4895) or matching placebo (n=4900). Our primary outcome was coronary events (coronary heart disease death or non-fatal myocardial infarction); the outcome for prespecified subgroup analyses was total cardiovascular events (the composite of cardiovascular death, myocardial infarction, stroke, and coronary and carotid revascularisation). Analysis was by intention to treat. The study was prospectively registered (number ISRCTN 64783481).Vital status was confirmed on all but 22 patients. Averaged over the 5 years' study duration, similar proportions in each group discontinued study medication (10% placebo vs 11% fenofibrate) and more patients allocated placebo (17%) than fenofibrate (8%; p<0.0001) commenced other lipid treatments, predominantly statins. 5.9% (n=288) of patients on placebo and 5.2% (n=256) of those on fenofibrate had a coronary event (relative reduction of 11%; hazard ratio [HR] 0.89, 95% CI 0.75-1.05; p=0.16). This finding corresponds to a significant 24% reduction in non-fatal myocardial infarction (0.76, 0.62-0.94; p=0.010) and a non-significant increase in coronary heart disease mortality (1.19, 0.90-1.57; p=0.22). Total cardiovascular disease events were significantly reduced from 13.9% to 12.5% (0.89, 0.80-0.99; p=0.035). This finding included a 21% reduction in coronary revascularisation (0.79, 0.68-0.93; p=0.003). Total mortality was 6.6% in the placebo group and 7.3% in the fenofibrate group (p=0.18). Fenofibrate was associated with less albuminuria progression (p=0.002), and less retinopathy needing laser treatment (5.2%vs 3.6%, p=0.0003). There was a slight increase in pancreatitis (0.5%vs 0.8%, p=0.031) and pulmonary embolism (0.7%vs 1.1%, p=0.022), but no other significant adverse effects.Fenofibrate did not significantly reduce the risk of the primary outcome of coronary events. It did reduce total cardiovascular events, mainly due to fewer non-fatal myocardial infarctions and revascularisations. The higher rate of starting statin therapy in patients allocated placebo might have masked a moderately larger treatment benefit.","Effects of long-term fenofibrate therapy on cardiovascular events in 9795 people with type 2 diabetes mellitus (the FIELD study): randomised controlled trial."
"632","Lancet.401","0.035",16310551,2005,"Patients with type 2 diabetes mellitus are at increased risk of cardiovascular disease, partly owing to dyslipidaemia, which can be amenable to fibrate therapy. We designed the Fenofibrate Intervention and Event Lowering in Diabetes (FIELD) study to assess the effect of fenofibrate on cardiovascular disease events in these patients.We did a multinational, randomised controlled trial with 9795 participants aged 50-75 years, with type 2 diabetes mellitus, and not taking statin therapy at study entry. After a placebo and a fenofibrate run-in phase, we randomly assigned patients (2131 with previous cardiovascular disease and 7664 without) with a total-cholesterol concentration of 3.0-6.5 mmol/L and a total-cholesterol/HDL-cholesterol ratio of 4.0 or more or plasma triglyceride of 1.0-5.0 mmol/L to micronised fenofibrate 200 mg daily (n=4895) or matching placebo (n=4900). Our primary outcome was coronary events (coronary heart disease death or non-fatal myocardial infarction); the outcome for prespecified subgroup analyses was total cardiovascular events (the composite of cardiovascular death, myocardial infarction, stroke, and coronary and carotid revascularisation). Analysis was by intention to treat. The study was prospectively registered (number ISRCTN 64783481).Vital status was confirmed on all but 22 patients. Averaged over the 5 years' study duration, similar proportions in each group discontinued study medication (10% placebo vs 11% fenofibrate) and more patients allocated placebo (17%) than fenofibrate (8%; p<0.0001) commenced other lipid treatments, predominantly statins. 5.9% (n=288) of patients on placebo and 5.2% (n=256) of those on fenofibrate had a coronary event (relative reduction of 11%; hazard ratio [HR] 0.89, 95% CI 0.75-1.05; p=0.16). This finding corresponds to a significant 24% reduction in non-fatal myocardial infarction (0.76, 0.62-0.94; p=0.010) and a non-significant increase in coronary heart disease mortality (1.19, 0.90-1.57; p=0.22). Total cardiovascular disease events were significantly reduced from 13.9% to 12.5% (0.89, 0.80-0.99; p=0.035). This finding included a 21% reduction in coronary revascularisation (0.79, 0.68-0.93; p=0.003). Total mortality was 6.6% in the placebo group and 7.3% in the fenofibrate group (p=0.18). Fenofibrate was associated with less albuminuria progression (p=0.002), and less retinopathy needing laser treatment (5.2%vs 3.6%, p=0.0003). There was a slight increase in pancreatitis (0.5%vs 0.8%, p=0.031) and pulmonary embolism (0.7%vs 1.1%, p=0.022), but no other significant adverse effects.Fenofibrate did not significantly reduce the risk of the primary outcome of coronary events. It did reduce total cardiovascular events, mainly due to fewer non-fatal myocardial infarctions and revascularisations. The higher rate of starting statin therapy in patients allocated placebo might have masked a moderately larger treatment benefit.","Effects of long-term fenofibrate therapy on cardiovascular events in 9795 people with type 2 diabetes mellitus (the FIELD study): randomised controlled trial."
"633","Lancet.411","0.003",16310551,2005,"Patients with type 2 diabetes mellitus are at increased risk of cardiovascular disease, partly owing to dyslipidaemia, which can be amenable to fibrate therapy. We designed the Fenofibrate Intervention and Event Lowering in Diabetes (FIELD) study to assess the effect of fenofibrate on cardiovascular disease events in these patients.We did a multinational, randomised controlled trial with 9795 participants aged 50-75 years, with type 2 diabetes mellitus, and not taking statin therapy at study entry. After a placebo and a fenofibrate run-in phase, we randomly assigned patients (2131 with previous cardiovascular disease and 7664 without) with a total-cholesterol concentration of 3.0-6.5 mmol/L and a total-cholesterol/HDL-cholesterol ratio of 4.0 or more or plasma triglyceride of 1.0-5.0 mmol/L to micronised fenofibrate 200 mg daily (n=4895) or matching placebo (n=4900). Our primary outcome was coronary events (coronary heart disease death or non-fatal myocardial infarction); the outcome for prespecified subgroup analyses was total cardiovascular events (the composite of cardiovascular death, myocardial infarction, stroke, and coronary and carotid revascularisation). Analysis was by intention to treat. The study was prospectively registered (number ISRCTN 64783481).Vital status was confirmed on all but 22 patients. Averaged over the 5 years' study duration, similar proportions in each group discontinued study medication (10% placebo vs 11% fenofibrate) and more patients allocated placebo (17%) than fenofibrate (8%; p<0.0001) commenced other lipid treatments, predominantly statins. 5.9% (n=288) of patients on placebo and 5.2% (n=256) of those on fenofibrate had a coronary event (relative reduction of 11%; hazard ratio [HR] 0.89, 95% CI 0.75-1.05; p=0.16). This finding corresponds to a significant 24% reduction in non-fatal myocardial infarction (0.76, 0.62-0.94; p=0.010) and a non-significant increase in coronary heart disease mortality (1.19, 0.90-1.57; p=0.22). Total cardiovascular disease events were significantly reduced from 13.9% to 12.5% (0.89, 0.80-0.99; p=0.035). This finding included a 21% reduction in coronary revascularisation (0.79, 0.68-0.93; p=0.003). Total mortality was 6.6% in the placebo group and 7.3% in the fenofibrate group (p=0.18). Fenofibrate was associated with less albuminuria progression (p=0.002), and less retinopathy needing laser treatment (5.2%vs 3.6%, p=0.0003). There was a slight increase in pancreatitis (0.5%vs 0.8%, p=0.031) and pulmonary embolism (0.7%vs 1.1%, p=0.022), but no other significant adverse effects.Fenofibrate did not significantly reduce the risk of the primary outcome of coronary events. It did reduce total cardiovascular events, mainly due to fewer non-fatal myocardial infarctions and revascularisations. The higher rate of starting statin therapy in patients allocated placebo might have masked a moderately larger treatment benefit.","Effects of long-term fenofibrate therapy on cardiovascular events in 9795 people with type 2 diabetes mellitus (the FIELD study): randomised controlled trial."
"634","Lancet.284","1.00E-04",16338449,2005,"Chronic heart failure (CHF) is an important cause of hospital admission and death. Poor adherence to medication is common in some chronic illnesses and might reduce the population effectiveness of proven treatments. Because little is known about adherence in patients with CHF and about the consequences of non-adherence, we assessed the association between adherence and clinical outcome in the CHARM (Candesartan in Heart failure: Assessment of Reduction in Mortality and morbidity) programme.CHARM was a double-blind, randomised, controlled clinical trial, comparing the effects of the angiotensin receptor blocker candesartan with placebo in 7599 patients with CHF. Median follow-up was 38 months. The proportion of time patients took more than 80% of their study medication was defined as good adherence and 80% or less as poor adherence. We used a Cox proportional hazards regression model, with adherence as a time-dependent covariate in the model, to examine the association between adherence and mortality in the candesartan and placebo groups.We excluded 187 patients because of missing information on adherence. In the time-dependent Cox regression model, after adjustment for predictive factors (demographics, physiological and severity-of-illness variables, smoking history, and number of concomitant medications), good adherence was associated with lower all-cause mortality in all patients (hazard ratio [HR] 0.65, 95% CI 0.57-0.75, p<0.0001). The adjusted HR for good adherence was similar in the candesartan (0.66, 0.55-0.81, p<0.0001) and placebo (0.64, 0.53-0.78, p<0.0001) groups.Good adherence to medication is associated with a lower risk of death than poor adherence in patients with CHF, irrespective of assigned treatment. This finding suggests that adherence is a marker for adherence to effective treatments other than study medications, or to other adherence behaviours that affect outcome. Understanding these factors could provide an opportunity for new interventions, including those aimed at improving adherence.","Adherence to candesartan and placebo and outcomes in chronic heart failure in the CHARM programme: double-blind, randomised, controlled clinical trial."
"635","Lancet.291","1.00E-04",16338449,2005,"Chronic heart failure (CHF) is an important cause of hospital admission and death. Poor adherence to medication is common in some chronic illnesses and might reduce the population effectiveness of proven treatments. Because little is known about adherence in patients with CHF and about the consequences of non-adherence, we assessed the association between adherence and clinical outcome in the CHARM (Candesartan in Heart failure: Assessment of Reduction in Mortality and morbidity) programme.CHARM was a double-blind, randomised, controlled clinical trial, comparing the effects of the angiotensin receptor blocker candesartan with placebo in 7599 patients with CHF. Median follow-up was 38 months. The proportion of time patients took more than 80% of their study medication was defined as good adherence and 80% or less as poor adherence. We used a Cox proportional hazards regression model, with adherence as a time-dependent covariate in the model, to examine the association between adherence and mortality in the candesartan and placebo groups.We excluded 187 patients because of missing information on adherence. In the time-dependent Cox regression model, after adjustment for predictive factors (demographics, physiological and severity-of-illness variables, smoking history, and number of concomitant medications), good adherence was associated with lower all-cause mortality in all patients (hazard ratio [HR] 0.65, 95% CI 0.57-0.75, p<0.0001). The adjusted HR for good adherence was similar in the candesartan (0.66, 0.55-0.81, p<0.0001) and placebo (0.64, 0.53-0.78, p<0.0001) groups.Good adherence to medication is associated with a lower risk of death than poor adherence in patients with CHF, irrespective of assigned treatment. This finding suggests that adherence is a marker for adherence to effective treatments other than study medications, or to other adherence behaviours that affect outcome. Understanding these factors could provide an opportunity for new interventions, including those aimed at improving adherence.","Adherence to candesartan and placebo and outcomes in chronic heart failure in the CHARM programme: double-blind, randomised, controlled clinical trial."
"636","Lancet.301","1.00E-04",16338449,2005,"Chronic heart failure (CHF) is an important cause of hospital admission and death. Poor adherence to medication is common in some chronic illnesses and might reduce the population effectiveness of proven treatments. Because little is known about adherence in patients with CHF and about the consequences of non-adherence, we assessed the association between adherence and clinical outcome in the CHARM (Candesartan in Heart failure: Assessment of Reduction in Mortality and morbidity) programme.CHARM was a double-blind, randomised, controlled clinical trial, comparing the effects of the angiotensin receptor blocker candesartan with placebo in 7599 patients with CHF. Median follow-up was 38 months. The proportion of time patients took more than 80% of their study medication was defined as good adherence and 80% or less as poor adherence. We used a Cox proportional hazards regression model, with adherence as a time-dependent covariate in the model, to examine the association between adherence and mortality in the candesartan and placebo groups.We excluded 187 patients because of missing information on adherence. In the time-dependent Cox regression model, after adjustment for predictive factors (demographics, physiological and severity-of-illness variables, smoking history, and number of concomitant medications), good adherence was associated with lower all-cause mortality in all patients (hazard ratio [HR] 0.65, 95% CI 0.57-0.75, p<0.0001). The adjusted HR for good adherence was similar in the candesartan (0.66, 0.55-0.81, p<0.0001) and placebo (0.64, 0.53-0.78, p<0.0001) groups.Good adherence to medication is associated with a lower risk of death than poor adherence in patients with CHF, irrespective of assigned treatment. This finding suggests that adherence is a marker for adherence to effective treatments other than study medications, or to other adherence behaviours that affect outcome. Understanding these factors could provide an opportunity for new interventions, including those aimed at improving adherence.","Adherence to candesartan and placebo and outcomes in chronic heart failure in the CHARM programme: double-blind, randomised, controlled clinical trial."
"637","JAMA.2311","0.001",16380589,2005,"Atrial tachyarrhythmias after cardiac surgery are associated with adverse outcomes and increased costs. Previous trials of amiodarone prophylaxis, while promising, were relatively small and yielded conflicting results.To determine whether a brief perioperative course of oral amiodarone is an effective and safe prophylaxis for atrial tachyarrhythmias after cardiac surgery overall and in important subgroups.Double-blind randomized controlled trial of 601 patients listed for nonemergent coronary artery bypass graft (CABG) surgery and/or valve replacement/repair surgery between February 1, 1999, and September 26, 2003, at a tertiary care hospital. The patients were followed up for 1 year.Oral amiodarone (10 mg/kg daily) or placebo administered 6 days prior to surgery through 6 days after surgery (13 days). Randomization was stratified for subgroups defined by age, type of surgery, and use of preoperative beta-blockers.Incidence of atrial tachyarrhythmias lasting 5 minutes or longer that prompted therapy by the sixth postoperative day.Atrial tachyarrhythmias occurred in fewer amiodarone patients (48/299; 16.1%) than in placebo patients (89/302; 29.5%) overall (hazard ratio [HR], 0.52; 95% confidence interval [CI], 0.34-0.69; P<.001); in patients younger than 65 years (19 [11.2%] vs 36 [21.1%]; HR, 0.51 [95% CI, 0.28-0.94]; P = .02); in patients aged 65 years or older (28 [21.7%] vs 54 [41.2%]; HR, 0.45 [95% CI, 0.27-0.75]; P<.001); in patients who had CABG surgery only (22 [11.3%] vs 46 [23.6%]; HR, 0.45 [95% CI, 0.26-0.79]; P = .002); in patients who had valve replacement/repair surgery with or without CABG surgery (25 [23.8%] vs 44 [44.1%]; HR, 0.51 [95% CI, 0.31-0.84; P = .008); in patients who received preoperative beta-blocker therapy (27 [15.3%] vs 42 [25.0%]; HR, 0.58 [95% CI, 0.34-0.99]; P = .03); and in patients who did not receive preoperative beta-blocker therapy (20 [16.3%] vs 48 [35.8%]; HR, 0.40 [95% CI, 0.22-0.71]; P<.001), respectively. Postoperative sustained ventricular tachyarrhythmias occurred less frequently in amiodarone patients (1/299; 0.3%) than in placebo patients (8/302; 2.6%) (P = .04). Dosage reductions of blinded therapy were more common in amiodarone patients (34/299; 11.4%) than in placebo patients (16/302; 5.3%) (P = .008). There were no differences in serious postoperative complications, in-hospital mortality, or readmission to the hospital within 6 months of discharge or in 1-year mortality.Oral amiodarone prophylaxis of atrial tachyarrhythmias after cardiac surgery is effective and may be safe overall and in important patient subgroups. Clinical Trials Registration ClinicalTrials.gov Identifier: NCT00251706.","Prophylactic Oral Amiodarone for the Prevention of Arrhythmias that Begin Early After Revascularization, Valve Replacement, or Repair: PAPABEAR: a randomized controlled trial."
"638","JAMA.2321","0.001",16380589,2005,"Atrial tachyarrhythmias after cardiac surgery are associated with adverse outcomes and increased costs. Previous trials of amiodarone prophylaxis, while promising, were relatively small and yielded conflicting results.To determine whether a brief perioperative course of oral amiodarone is an effective and safe prophylaxis for atrial tachyarrhythmias after cardiac surgery overall and in important subgroups.Double-blind randomized controlled trial of 601 patients listed for nonemergent coronary artery bypass graft (CABG) surgery and/or valve replacement/repair surgery between February 1, 1999, and September 26, 2003, at a tertiary care hospital. The patients were followed up for 1 year.Oral amiodarone (10 mg/kg daily) or placebo administered 6 days prior to surgery through 6 days after surgery (13 days). Randomization was stratified for subgroups defined by age, type of surgery, and use of preoperative beta-blockers.Incidence of atrial tachyarrhythmias lasting 5 minutes or longer that prompted therapy by the sixth postoperative day.Atrial tachyarrhythmias occurred in fewer amiodarone patients (48/299; 16.1%) than in placebo patients (89/302; 29.5%) overall (hazard ratio [HR], 0.52; 95% confidence interval [CI], 0.34-0.69; P<.001); in patients younger than 65 years (19 [11.2%] vs 36 [21.1%]; HR, 0.51 [95% CI, 0.28-0.94]; P = .02); in patients aged 65 years or older (28 [21.7%] vs 54 [41.2%]; HR, 0.45 [95% CI, 0.27-0.75]; P<.001); in patients who had CABG surgery only (22 [11.3%] vs 46 [23.6%]; HR, 0.45 [95% CI, 0.26-0.79]; P = .002); in patients who had valve replacement/repair surgery with or without CABG surgery (25 [23.8%] vs 44 [44.1%]; HR, 0.51 [95% CI, 0.31-0.84; P = .008); in patients who received preoperative beta-blocker therapy (27 [15.3%] vs 42 [25.0%]; HR, 0.58 [95% CI, 0.34-0.99]; P = .03); and in patients who did not receive preoperative beta-blocker therapy (20 [16.3%] vs 48 [35.8%]; HR, 0.40 [95% CI, 0.22-0.71]; P<.001), respectively. Postoperative sustained ventricular tachyarrhythmias occurred less frequently in amiodarone patients (1/299; 0.3%) than in placebo patients (8/302; 2.6%) (P = .04). Dosage reductions of blinded therapy were more common in amiodarone patients (34/299; 11.4%) than in placebo patients (16/302; 5.3%) (P = .008). There were no differences in serious postoperative complications, in-hospital mortality, or readmission to the hospital within 6 months of discharge or in 1-year mortality.Oral amiodarone prophylaxis of atrial tachyarrhythmias after cardiac surgery is effective and may be safe overall and in important patient subgroups. Clinical Trials Registration ClinicalTrials.gov Identifier: NCT00251706.","Prophylactic Oral Amiodarone for the Prevention of Arrhythmias that Begin Early After Revascularization, Valve Replacement, or Repair: PAPABEAR: a randomized controlled trial."
"639","JAMA.2331","0.001",16380589,2005,"Atrial tachyarrhythmias after cardiac surgery are associated with adverse outcomes and increased costs. Previous trials of amiodarone prophylaxis, while promising, were relatively small and yielded conflicting results.To determine whether a brief perioperative course of oral amiodarone is an effective and safe prophylaxis for atrial tachyarrhythmias after cardiac surgery overall and in important subgroups.Double-blind randomized controlled trial of 601 patients listed for nonemergent coronary artery bypass graft (CABG) surgery and/or valve replacement/repair surgery between February 1, 1999, and September 26, 2003, at a tertiary care hospital. The patients were followed up for 1 year.Oral amiodarone (10 mg/kg daily) or placebo administered 6 days prior to surgery through 6 days after surgery (13 days). Randomization was stratified for subgroups defined by age, type of surgery, and use of preoperative beta-blockers.Incidence of atrial tachyarrhythmias lasting 5 minutes or longer that prompted therapy by the sixth postoperative day.Atrial tachyarrhythmias occurred in fewer amiodarone patients (48/299; 16.1%) than in placebo patients (89/302; 29.5%) overall (hazard ratio [HR], 0.52; 95% confidence interval [CI], 0.34-0.69; P<.001); in patients younger than 65 years (19 [11.2%] vs 36 [21.1%]; HR, 0.51 [95% CI, 0.28-0.94]; P = .02); in patients aged 65 years or older (28 [21.7%] vs 54 [41.2%]; HR, 0.45 [95% CI, 0.27-0.75]; P<.001); in patients who had CABG surgery only (22 [11.3%] vs 46 [23.6%]; HR, 0.45 [95% CI, 0.26-0.79]; P = .002); in patients who had valve replacement/repair surgery with or without CABG surgery (25 [23.8%] vs 44 [44.1%]; HR, 0.51 [95% CI, 0.31-0.84; P = .008); in patients who received preoperative beta-blocker therapy (27 [15.3%] vs 42 [25.0%]; HR, 0.58 [95% CI, 0.34-0.99]; P = .03); and in patients who did not receive preoperative beta-blocker therapy (20 [16.3%] vs 48 [35.8%]; HR, 0.40 [95% CI, 0.22-0.71]; P<.001), respectively. Postoperative sustained ventricular tachyarrhythmias occurred less frequently in amiodarone patients (1/299; 0.3%) than in placebo patients (8/302; 2.6%) (P = .04). Dosage reductions of blinded therapy were more common in amiodarone patients (34/299; 11.4%) than in placebo patients (16/302; 5.3%) (P = .008). There were no differences in serious postoperative complications, in-hospital mortality, or readmission to the hospital within 6 months of discharge or in 1-year mortality.Oral amiodarone prophylaxis of atrial tachyarrhythmias after cardiac surgery is effective and may be safe overall and in important patient subgroups. Clinical Trials Registration ClinicalTrials.gov Identifier: NCT00251706.","Prophylactic Oral Amiodarone for the Prevention of Arrhythmias that Begin Early After Revascularization, Valve Replacement, or Repair: PAPABEAR: a randomized controlled trial."
"640","JAMA.2511","0.02",16380589,2005,"Atrial tachyarrhythmias after cardiac surgery are associated with adverse outcomes and increased costs. Previous trials of amiodarone prophylaxis, while promising, were relatively small and yielded conflicting results.To determine whether a brief perioperative course of oral amiodarone is an effective and safe prophylaxis for atrial tachyarrhythmias after cardiac surgery overall and in important subgroups.Double-blind randomized controlled trial of 601 patients listed for nonemergent coronary artery bypass graft (CABG) surgery and/or valve replacement/repair surgery between February 1, 1999, and September 26, 2003, at a tertiary care hospital. The patients were followed up for 1 year.Oral amiodarone (10 mg/kg daily) or placebo administered 6 days prior to surgery through 6 days after surgery (13 days). Randomization was stratified for subgroups defined by age, type of surgery, and use of preoperative beta-blockers.Incidence of atrial tachyarrhythmias lasting 5 minutes or longer that prompted therapy by the sixth postoperative day.Atrial tachyarrhythmias occurred in fewer amiodarone patients (48/299; 16.1%) than in placebo patients (89/302; 29.5%) overall (hazard ratio [HR], 0.52; 95% confidence interval [CI], 0.34-0.69; P<.001); in patients younger than 65 years (19 [11.2%] vs 36 [21.1%]; HR, 0.51 [95% CI, 0.28-0.94]; P = .02); in patients aged 65 years or older (28 [21.7%] vs 54 [41.2%]; HR, 0.45 [95% CI, 0.27-0.75]; P<.001); in patients who had CABG surgery only (22 [11.3%] vs 46 [23.6%]; HR, 0.45 [95% CI, 0.26-0.79]; P = .002); in patients who had valve replacement/repair surgery with or without CABG surgery (25 [23.8%] vs 44 [44.1%]; HR, 0.51 [95% CI, 0.31-0.84; P = .008); in patients who received preoperative beta-blocker therapy (27 [15.3%] vs 42 [25.0%]; HR, 0.58 [95% CI, 0.34-0.99]; P = .03); and in patients who did not receive preoperative beta-blocker therapy (20 [16.3%] vs 48 [35.8%]; HR, 0.40 [95% CI, 0.22-0.71]; P<.001), respectively. Postoperative sustained ventricular tachyarrhythmias occurred less frequently in amiodarone patients (1/299; 0.3%) than in placebo patients (8/302; 2.6%) (P = .04). Dosage reductions of blinded therapy were more common in amiodarone patients (34/299; 11.4%) than in placebo patients (16/302; 5.3%) (P = .008). There were no differences in serious postoperative complications, in-hospital mortality, or readmission to the hospital within 6 months of discharge or in 1-year mortality.Oral amiodarone prophylaxis of atrial tachyarrhythmias after cardiac surgery is effective and may be safe overall and in important patient subgroups. Clinical Trials Registration ClinicalTrials.gov Identifier: NCT00251706.","Prophylactic Oral Amiodarone for the Prevention of Arrhythmias that Begin Early After Revascularization, Valve Replacement, or Repair: PAPABEAR: a randomized controlled trial."
"641","JAMA.2521","0.002",16380589,2005,"Atrial tachyarrhythmias after cardiac surgery are associated with adverse outcomes and increased costs. Previous trials of amiodarone prophylaxis, while promising, were relatively small and yielded conflicting results.To determine whether a brief perioperative course of oral amiodarone is an effective and safe prophylaxis for atrial tachyarrhythmias after cardiac surgery overall and in important subgroups.Double-blind randomized controlled trial of 601 patients listed for nonemergent coronary artery bypass graft (CABG) surgery and/or valve replacement/repair surgery between February 1, 1999, and September 26, 2003, at a tertiary care hospital. The patients were followed up for 1 year.Oral amiodarone (10 mg/kg daily) or placebo administered 6 days prior to surgery through 6 days after surgery (13 days). Randomization was stratified for subgroups defined by age, type of surgery, and use of preoperative beta-blockers.Incidence of atrial tachyarrhythmias lasting 5 minutes or longer that prompted therapy by the sixth postoperative day.Atrial tachyarrhythmias occurred in fewer amiodarone patients (48/299; 16.1%) than in placebo patients (89/302; 29.5%) overall (hazard ratio [HR], 0.52; 95% confidence interval [CI], 0.34-0.69; P<.001); in patients younger than 65 years (19 [11.2%] vs 36 [21.1%]; HR, 0.51 [95% CI, 0.28-0.94]; P = .02); in patients aged 65 years or older (28 [21.7%] vs 54 [41.2%]; HR, 0.45 [95% CI, 0.27-0.75]; P<.001); in patients who had CABG surgery only (22 [11.3%] vs 46 [23.6%]; HR, 0.45 [95% CI, 0.26-0.79]; P = .002); in patients who had valve replacement/repair surgery with or without CABG surgery (25 [23.8%] vs 44 [44.1%]; HR, 0.51 [95% CI, 0.31-0.84; P = .008); in patients who received preoperative beta-blocker therapy (27 [15.3%] vs 42 [25.0%]; HR, 0.58 [95% CI, 0.34-0.99]; P = .03); and in patients who did not receive preoperative beta-blocker therapy (20 [16.3%] vs 48 [35.8%]; HR, 0.40 [95% CI, 0.22-0.71]; P<.001), respectively. Postoperative sustained ventricular tachyarrhythmias occurred less frequently in amiodarone patients (1/299; 0.3%) than in placebo patients (8/302; 2.6%) (P = .04). Dosage reductions of blinded therapy were more common in amiodarone patients (34/299; 11.4%) than in placebo patients (16/302; 5.3%) (P = .008). There were no differences in serious postoperative complications, in-hospital mortality, or readmission to the hospital within 6 months of discharge or in 1-year mortality.Oral amiodarone prophylaxis of atrial tachyarrhythmias after cardiac surgery is effective and may be safe overall and in important patient subgroups. Clinical Trials Registration ClinicalTrials.gov Identifier: NCT00251706.","Prophylactic Oral Amiodarone for the Prevention of Arrhythmias that Begin Early After Revascularization, Valve Replacement, or Repair: PAPABEAR: a randomized controlled trial."
"642","JAMA.2531","0.008",16380589,2005,"Atrial tachyarrhythmias after cardiac surgery are associated with adverse outcomes and increased costs. Previous trials of amiodarone prophylaxis, while promising, were relatively small and yielded conflicting results.To determine whether a brief perioperative course of oral amiodarone is an effective and safe prophylaxis for atrial tachyarrhythmias after cardiac surgery overall and in important subgroups.Double-blind randomized controlled trial of 601 patients listed for nonemergent coronary artery bypass graft (CABG) surgery and/or valve replacement/repair surgery between February 1, 1999, and September 26, 2003, at a tertiary care hospital. The patients were followed up for 1 year.Oral amiodarone (10 mg/kg daily) or placebo administered 6 days prior to surgery through 6 days after surgery (13 days). Randomization was stratified for subgroups defined by age, type of surgery, and use of preoperative beta-blockers.Incidence of atrial tachyarrhythmias lasting 5 minutes or longer that prompted therapy by the sixth postoperative day.Atrial tachyarrhythmias occurred in fewer amiodarone patients (48/299; 16.1%) than in placebo patients (89/302; 29.5%) overall (hazard ratio [HR], 0.52; 95% confidence interval [CI], 0.34-0.69; P<.001); in patients younger than 65 years (19 [11.2%] vs 36 [21.1%]; HR, 0.51 [95% CI, 0.28-0.94]; P = .02); in patients aged 65 years or older (28 [21.7%] vs 54 [41.2%]; HR, 0.45 [95% CI, 0.27-0.75]; P<.001); in patients who had CABG surgery only (22 [11.3%] vs 46 [23.6%]; HR, 0.45 [95% CI, 0.26-0.79]; P = .002); in patients who had valve replacement/repair surgery with or without CABG surgery (25 [23.8%] vs 44 [44.1%]; HR, 0.51 [95% CI, 0.31-0.84; P = .008); in patients who received preoperative beta-blocker therapy (27 [15.3%] vs 42 [25.0%]; HR, 0.58 [95% CI, 0.34-0.99]; P = .03); and in patients who did not receive preoperative beta-blocker therapy (20 [16.3%] vs 48 [35.8%]; HR, 0.40 [95% CI, 0.22-0.71]; P<.001), respectively. Postoperative sustained ventricular tachyarrhythmias occurred less frequently in amiodarone patients (1/299; 0.3%) than in placebo patients (8/302; 2.6%) (P = .04). Dosage reductions of blinded therapy were more common in amiodarone patients (34/299; 11.4%) than in placebo patients (16/302; 5.3%) (P = .008). There were no differences in serious postoperative complications, in-hospital mortality, or readmission to the hospital within 6 months of discharge or in 1-year mortality.Oral amiodarone prophylaxis of atrial tachyarrhythmias after cardiac surgery is effective and may be safe overall and in important patient subgroups. Clinical Trials Registration ClinicalTrials.gov Identifier: NCT00251706.","Prophylactic Oral Amiodarone for the Prevention of Arrhythmias that Begin Early After Revascularization, Valve Replacement, or Repair: PAPABEAR: a randomized controlled trial."
"643","JAMA.2541","0.03",16380589,2005,"Atrial tachyarrhythmias after cardiac surgery are associated with adverse outcomes and increased costs. Previous trials of amiodarone prophylaxis, while promising, were relatively small and yielded conflicting results.To determine whether a brief perioperative course of oral amiodarone is an effective and safe prophylaxis for atrial tachyarrhythmias after cardiac surgery overall and in important subgroups.Double-blind randomized controlled trial of 601 patients listed for nonemergent coronary artery bypass graft (CABG) surgery and/or valve replacement/repair surgery between February 1, 1999, and September 26, 2003, at a tertiary care hospital. The patients were followed up for 1 year.Oral amiodarone (10 mg/kg daily) or placebo administered 6 days prior to surgery through 6 days after surgery (13 days). Randomization was stratified for subgroups defined by age, type of surgery, and use of preoperative beta-blockers.Incidence of atrial tachyarrhythmias lasting 5 minutes or longer that prompted therapy by the sixth postoperative day.Atrial tachyarrhythmias occurred in fewer amiodarone patients (48/299; 16.1%) than in placebo patients (89/302; 29.5%) overall (hazard ratio [HR], 0.52; 95% confidence interval [CI], 0.34-0.69; P<.001); in patients younger than 65 years (19 [11.2%] vs 36 [21.1%]; HR, 0.51 [95% CI, 0.28-0.94]; P = .02); in patients aged 65 years or older (28 [21.7%] vs 54 [41.2%]; HR, 0.45 [95% CI, 0.27-0.75]; P<.001); in patients who had CABG surgery only (22 [11.3%] vs 46 [23.6%]; HR, 0.45 [95% CI, 0.26-0.79]; P = .002); in patients who had valve replacement/repair surgery with or without CABG surgery (25 [23.8%] vs 44 [44.1%]; HR, 0.51 [95% CI, 0.31-0.84; P = .008); in patients who received preoperative beta-blocker therapy (27 [15.3%] vs 42 [25.0%]; HR, 0.58 [95% CI, 0.34-0.99]; P = .03); and in patients who did not receive preoperative beta-blocker therapy (20 [16.3%] vs 48 [35.8%]; HR, 0.40 [95% CI, 0.22-0.71]; P<.001), respectively. Postoperative sustained ventricular tachyarrhythmias occurred less frequently in amiodarone patients (1/299; 0.3%) than in placebo patients (8/302; 2.6%) (P = .04). Dosage reductions of blinded therapy were more common in amiodarone patients (34/299; 11.4%) than in placebo patients (16/302; 5.3%) (P = .008). There were no differences in serious postoperative complications, in-hospital mortality, or readmission to the hospital within 6 months of discharge or in 1-year mortality.Oral amiodarone prophylaxis of atrial tachyarrhythmias after cardiac surgery is effective and may be safe overall and in important patient subgroups. Clinical Trials Registration ClinicalTrials.gov Identifier: NCT00251706.","Prophylactic Oral Amiodarone for the Prevention of Arrhythmias that Begin Early After Revascularization, Valve Replacement, or Repair: PAPABEAR: a randomized controlled trial."
"644","JAMA.357","0.001",16391216,2006,"Cardiac arrests in adults are often due to ventricular fibrillation (VF) or pulseless ventricular tachycardia (VT), which are associated with better outcomes than asystole or pulseless electrical activity (PEA). Cardiac arrests in children are typically asystole or PEA.To test the hypothesis that children have relatively fewer in-hospital cardiac arrests associated with VF or pulseless VT compared with adults and, therefore, worse survival outcomes.A prospective observational study from a multicenter registry (National Registry of Cardiopulmonary Resuscitation) of cardiac arrests in 253 US and Canadian hospitals between January 1, 2000, and March 30, 2004. A total of 36,902 adults (> or =18 years) and 880 children (<18 years) with pulseless cardiac arrests requiring chest compressions, defibrillation, or both were assessed. Cardiac arrests occurring in the delivery department, neonatal intensive care unit, and in the out-of-hospital setting were excluded.Survival to hospital discharge.The rate of survival to hospital discharge following pulseless cardiac arrest was higher in children than adults (27% [236/880] vs 18% [6485/36,902]; adjusted odds ratio [OR], 2.29; 95% confidence interval [CI], 1.95-2.68). Of these survivors, 65% (154/236) of children and 73% (4737/6485) of adults had good neurological outcome. The prevalence of VF or pulseless VT as the first documented pulseless rhythm was 14% (120/880) in children and 23% (8361/36,902) in adults (OR, 0.54; 95% CI, 0.44-0.65; P<.001). The prevalence of asystole was 40% (350) in children and 35% (13 024) in adults (OR, 1.20; 95% CI, 1.10-1.40; P = .006), whereas the prevalence of PEA was 24% (213) in children and 32% (11,963) in adults (OR, 0.67; 95% CI, 0.57-0.78; P<.001). After adjustment for differences in preexisting conditions, interventions in place at time of arrest, witnessed and/or monitored status, time to defibrillation of VF or pulseless VT, intensive care unit location of arrest, and duration of cardiopulmonary resuscitation, only first documented pulseless arrest rhythm remained significantly associated with differential survival to discharge (24% [135/563] in children vs 11% [2719/24,987] in adults with asystole and PEA; adjusted OR, 2.73; 95% CI, 2.23-3.32).In this multicenter registry of in-hospital cardiac arrest, the first documented pulseless arrest rhythm was typically asystole or PEA in both children and adults. Because of better survival after asystole and PEA, children had better outcomes than adults despite fewer cardiac arrests due to VF or pulseless VT.","First documented rhythm and clinical outcome from in-hospital cardiac arrest among children and adults."
"645","JAMA.358","0.001",16391216,2006,"Cardiac arrests in adults are often due to ventricular fibrillation (VF) or pulseless ventricular tachycardia (VT), which are associated with better outcomes than asystole or pulseless electrical activity (PEA). Cardiac arrests in children are typically asystole or PEA.To test the hypothesis that children have relatively fewer in-hospital cardiac arrests associated with VF or pulseless VT compared with adults and, therefore, worse survival outcomes.A prospective observational study from a multicenter registry (National Registry of Cardiopulmonary Resuscitation) of cardiac arrests in 253 US and Canadian hospitals between January 1, 2000, and March 30, 2004. A total of 36,902 adults (> or =18 years) and 880 children (<18 years) with pulseless cardiac arrests requiring chest compressions, defibrillation, or both were assessed. Cardiac arrests occurring in the delivery department, neonatal intensive care unit, and in the out-of-hospital setting were excluded.Survival to hospital discharge.The rate of survival to hospital discharge following pulseless cardiac arrest was higher in children than adults (27% [236/880] vs 18% [6485/36,902]; adjusted odds ratio [OR], 2.29; 95% confidence interval [CI], 1.95-2.68). Of these survivors, 65% (154/236) of children and 73% (4737/6485) of adults had good neurological outcome. The prevalence of VF or pulseless VT as the first documented pulseless rhythm was 14% (120/880) in children and 23% (8361/36,902) in adults (OR, 0.54; 95% CI, 0.44-0.65; P<.001). The prevalence of asystole was 40% (350) in children and 35% (13 024) in adults (OR, 1.20; 95% CI, 1.10-1.40; P = .006), whereas the prevalence of PEA was 24% (213) in children and 32% (11,963) in adults (OR, 0.67; 95% CI, 0.57-0.78; P<.001). After adjustment for differences in preexisting conditions, interventions in place at time of arrest, witnessed and/or monitored status, time to defibrillation of VF or pulseless VT, intensive care unit location of arrest, and duration of cardiopulmonary resuscitation, only first documented pulseless arrest rhythm remained significantly associated with differential survival to discharge (24% [135/563] in children vs 11% [2719/24,987] in adults with asystole and PEA; adjusted OR, 2.73; 95% CI, 2.23-3.32).In this multicenter registry of in-hospital cardiac arrest, the first documented pulseless arrest rhythm was typically asystole or PEA in both children and adults. Because of better survival after asystole and PEA, children had better outcomes than adults despite fewer cardiac arrests due to VF or pulseless VT.","First documented rhythm and clinical outcome from in-hospital cardiac arrest among children and adults."
"646","JAMA.387","0.006",16391216,2006,"Cardiac arrests in adults are often due to ventricular fibrillation (VF) or pulseless ventricular tachycardia (VT), which are associated with better outcomes than asystole or pulseless electrical activity (PEA). Cardiac arrests in children are typically asystole or PEA.To test the hypothesis that children have relatively fewer in-hospital cardiac arrests associated with VF or pulseless VT compared with adults and, therefore, worse survival outcomes.A prospective observational study from a multicenter registry (National Registry of Cardiopulmonary Resuscitation) of cardiac arrests in 253 US and Canadian hospitals between January 1, 2000, and March 30, 2004. A total of 36,902 adults (> or =18 years) and 880 children (<18 years) with pulseless cardiac arrests requiring chest compressions, defibrillation, or both were assessed. Cardiac arrests occurring in the delivery department, neonatal intensive care unit, and in the out-of-hospital setting were excluded.Survival to hospital discharge.The rate of survival to hospital discharge following pulseless cardiac arrest was higher in children than adults (27% [236/880] vs 18% [6485/36,902]; adjusted odds ratio [OR], 2.29; 95% confidence interval [CI], 1.95-2.68). Of these survivors, 65% (154/236) of children and 73% (4737/6485) of adults had good neurological outcome. The prevalence of VF or pulseless VT as the first documented pulseless rhythm was 14% (120/880) in children and 23% (8361/36,902) in adults (OR, 0.54; 95% CI, 0.44-0.65; P<.001). The prevalence of asystole was 40% (350) in children and 35% (13 024) in adults (OR, 1.20; 95% CI, 1.10-1.40; P = .006), whereas the prevalence of PEA was 24% (213) in children and 32% (11,963) in adults (OR, 0.67; 95% CI, 0.57-0.78; P<.001). After adjustment for differences in preexisting conditions, interventions in place at time of arrest, witnessed and/or monitored status, time to defibrillation of VF or pulseless VT, intensive care unit location of arrest, and duration of cardiopulmonary resuscitation, only first documented pulseless arrest rhythm remained significantly associated with differential survival to discharge (24% [135/563] in children vs 11% [2719/24,987] in adults with asystole and PEA; adjusted OR, 2.73; 95% CI, 2.23-3.32).In this multicenter registry of in-hospital cardiac arrest, the first documented pulseless arrest rhythm was typically asystole or PEA in both children and adults. Because of better survival after asystole and PEA, children had better outcomes than adults despite fewer cardiac arrests due to VF or pulseless VT.","First documented rhythm and clinical outcome from in-hospital cardiac arrest among children and adults."
"647","JAMA.3271","0.001",16403928,2006,"Implantable cardioverter defibrillator (ICD) therapy is effective but is associated with high-voltage shocks that are painful.To determine whether amiodarone plus beta-blocker or sotalol are better than beta-blocker alone for prevention of ICD shocks.A randomized controlled trial with blinded adjudication of events of 412 patients from 39 outpatient ICD clinical centers located in Canada, Germany, United States, England, Sweden, and Austria, conducted from January 13, 2001, to September 28, 2004. Patients were eligible if they had received an ICD within 21 days for inducible or spontaneously occurring ventricular tachycardia or fibrillation.Patients were randomized to treatment for 1 year with amiodarone plus beta-blocker, sotalol alone, or beta-blocker alone.Primary outcome was ICD shock for any reason.Shocks occurred in 41 patients (38.5%) assigned to beta-blocker alone, 26 (24.3%) assigned to sotalol, and 12 (10.3%) assigned to amiodarone plus beta-blocker. A reduction in the risk of shock was observed with use of either amiodarone plus beta-blocker or sotalol vs beta-blocker alone (hazard ratio [HR], 0.44; 95% confidence interval [CI], 0.28-0.68; P<.001). Amiodarone plus beta-blocker significantly reduced the risk of shock compared with beta-blocker alone (HR, 0.27; 95% CI, 0.14-0.52; P<.001) and sotalol (HR, 0.43; 95% CI, 0.22-0.85; P = .02). There was a trend for sotalol to reduce shocks compared with beta-blocker alone (HR, 0.61; 95% CI, 0.37-1.01; P = .055). The rates of study drug discontinuation at 1 year were 18.2% for amiodarone, 23.5% for sotalol, and 5.3% for beta-blocker alone. Adverse pulmonary and thyroid events and symptomatic bradycardia were more common among patients randomized to amiodarone.Despite use of advanced ICD technology and treatment with a beta-blocker, shocks occur commonly in the first year after ICD implant. Amiodarone plus beta-blocker is effective for preventing these shocks and is more effective than sotalol but has an increased risk of drug-related adverse effects.Clinical Trials Registration ClinicalTrials.gov Identifier: NCT00257959.","Comparison of beta-blockers, amiodarone plus beta-blockers, or sotalol for prevention of shocks from implantable cardioverter defibrillators: the OPTIC Study: a randomized trial."
"648","JAMA.3281","0.001",16403928,2006,"Implantable cardioverter defibrillator (ICD) therapy is effective but is associated with high-voltage shocks that are painful.To determine whether amiodarone plus beta-blocker or sotalol are better than beta-blocker alone for prevention of ICD shocks.A randomized controlled trial with blinded adjudication of events of 412 patients from 39 outpatient ICD clinical centers located in Canada, Germany, United States, England, Sweden, and Austria, conducted from January 13, 2001, to September 28, 2004. Patients were eligible if they had received an ICD within 21 days for inducible or spontaneously occurring ventricular tachycardia or fibrillation.Patients were randomized to treatment for 1 year with amiodarone plus beta-blocker, sotalol alone, or beta-blocker alone.Primary outcome was ICD shock for any reason.Shocks occurred in 41 patients (38.5%) assigned to beta-blocker alone, 26 (24.3%) assigned to sotalol, and 12 (10.3%) assigned to amiodarone plus beta-blocker. A reduction in the risk of shock was observed with use of either amiodarone plus beta-blocker or sotalol vs beta-blocker alone (hazard ratio [HR], 0.44; 95% confidence interval [CI], 0.28-0.68; P<.001). Amiodarone plus beta-blocker significantly reduced the risk of shock compared with beta-blocker alone (HR, 0.27; 95% CI, 0.14-0.52; P<.001) and sotalol (HR, 0.43; 95% CI, 0.22-0.85; P = .02). There was a trend for sotalol to reduce shocks compared with beta-blocker alone (HR, 0.61; 95% CI, 0.37-1.01; P = .055). The rates of study drug discontinuation at 1 year were 18.2% for amiodarone, 23.5% for sotalol, and 5.3% for beta-blocker alone. Adverse pulmonary and thyroid events and symptomatic bradycardia were more common among patients randomized to amiodarone.Despite use of advanced ICD technology and treatment with a beta-blocker, shocks occur commonly in the first year after ICD implant. Amiodarone plus beta-blocker is effective for preventing these shocks and is more effective than sotalol but has an increased risk of drug-related adverse effects.Clinical Trials Registration ClinicalTrials.gov Identifier: NCT00257959.","Comparison of beta-blockers, amiodarone plus beta-blockers, or sotalol for prevention of shocks from implantable cardioverter defibrillators: the OPTIC Study: a randomized trial."
"649","JAMA.3521","0.02",16403928,2006,"Implantable cardioverter defibrillator (ICD) therapy is effective but is associated with high-voltage shocks that are painful.To determine whether amiodarone plus beta-blocker or sotalol are better than beta-blocker alone for prevention of ICD shocks.A randomized controlled trial with blinded adjudication of events of 412 patients from 39 outpatient ICD clinical centers located in Canada, Germany, United States, England, Sweden, and Austria, conducted from January 13, 2001, to September 28, 2004. Patients were eligible if they had received an ICD within 21 days for inducible or spontaneously occurring ventricular tachycardia or fibrillation.Patients were randomized to treatment for 1 year with amiodarone plus beta-blocker, sotalol alone, or beta-blocker alone.Primary outcome was ICD shock for any reason.Shocks occurred in 41 patients (38.5%) assigned to beta-blocker alone, 26 (24.3%) assigned to sotalol, and 12 (10.3%) assigned to amiodarone plus beta-blocker. A reduction in the risk of shock was observed with use of either amiodarone plus beta-blocker or sotalol vs beta-blocker alone (hazard ratio [HR], 0.44; 95% confidence interval [CI], 0.28-0.68; P<.001). Amiodarone plus beta-blocker significantly reduced the risk of shock compared with beta-blocker alone (HR, 0.27; 95% CI, 0.14-0.52; P<.001) and sotalol (HR, 0.43; 95% CI, 0.22-0.85; P = .02). There was a trend for sotalol to reduce shocks compared with beta-blocker alone (HR, 0.61; 95% CI, 0.37-1.01; P = .055). The rates of study drug discontinuation at 1 year were 18.2% for amiodarone, 23.5% for sotalol, and 5.3% for beta-blocker alone. Adverse pulmonary and thyroid events and symptomatic bradycardia were more common among patients randomized to amiodarone.Despite use of advanced ICD technology and treatment with a beta-blocker, shocks occur commonly in the first year after ICD implant. Amiodarone plus beta-blocker is effective for preventing these shocks and is more effective than sotalol but has an increased risk of drug-related adverse effects.Clinical Trials Registration ClinicalTrials.gov Identifier: NCT00257959.","Comparison of beta-blockers, amiodarone plus beta-blockers, or sotalol for prevention of shocks from implantable cardioverter defibrillators: the OPTIC Study: a randomized trial."
"650","JAMA.3531","0.055",16403928,2006,"Implantable cardioverter defibrillator (ICD) therapy is effective but is associated with high-voltage shocks that are painful.To determine whether amiodarone plus beta-blocker or sotalol are better than beta-blocker alone for prevention of ICD shocks.A randomized controlled trial with blinded adjudication of events of 412 patients from 39 outpatient ICD clinical centers located in Canada, Germany, United States, England, Sweden, and Austria, conducted from January 13, 2001, to September 28, 2004. Patients were eligible if they had received an ICD within 21 days for inducible or spontaneously occurring ventricular tachycardia or fibrillation.Patients were randomized to treatment for 1 year with amiodarone plus beta-blocker, sotalol alone, or beta-blocker alone.Primary outcome was ICD shock for any reason.Shocks occurred in 41 patients (38.5%) assigned to beta-blocker alone, 26 (24.3%) assigned to sotalol, and 12 (10.3%) assigned to amiodarone plus beta-blocker. A reduction in the risk of shock was observed with use of either amiodarone plus beta-blocker or sotalol vs beta-blocker alone (hazard ratio [HR], 0.44; 95% confidence interval [CI], 0.28-0.68; P<.001). Amiodarone plus beta-blocker significantly reduced the risk of shock compared with beta-blocker alone (HR, 0.27; 95% CI, 0.14-0.52; P<.001) and sotalol (HR, 0.43; 95% CI, 0.22-0.85; P = .02). There was a trend for sotalol to reduce shocks compared with beta-blocker alone (HR, 0.61; 95% CI, 0.37-1.01; P = .055). The rates of study drug discontinuation at 1 year were 18.2% for amiodarone, 23.5% for sotalol, and 5.3% for beta-blocker alone. Adverse pulmonary and thyroid events and symptomatic bradycardia were more common among patients randomized to amiodarone.Despite use of advanced ICD technology and treatment with a beta-blocker, shocks occur commonly in the first year after ICD implant. Amiodarone plus beta-blocker is effective for preventing these shocks and is more effective than sotalol but has an increased risk of drug-related adverse effects.Clinical Trials Registration ClinicalTrials.gov Identifier: NCT00257959.","Comparison of beta-blockers, amiodarone plus beta-blockers, or sotalol for prevention of shocks from implantable cardioverter defibrillators: the OPTIC Study: a randomized trial."
"651","Lancet.46","0.36",16413875,2006,"The benefit of reperfusion therapies for ST-elevation acute myocardial infarction (STEMI) is limited by post-infarction left-ventricular (LV) dysfunction. Our aim was to investigate the effect of autologous bone marrow-derived stem cell (BMSC) transfer in the infarct-related artery on LV function and structure.We did a randomised, double-blind, placebo-controlled study in 67 patients from whom we harvested bone marrow 1 day after successful percutaneous coronary intervention for STEMI. We assigned patients optimum medical treatment and infusion of placebo (n=34) or BMSC (n=33). Our primary endpoint was the increase in LV ejection fraction and our secondary endpoints were change in infarct size and regional LV function at 4 months' follow-up, all assessed by MRI. We assessed changes in myocardial perfusion and oxidative metabolism with serial 1-[11C]acetate PET. Analyses were per protocol. This study is registered with , number NCT00264316.Mean global LV ejection fraction 4 days after percutaneous coronary intervention was 46.9% (SD 8.2) in controls and 48.5% (7.2) in BMSC patients, and increased after 4 months to 49.1% (10.7) and 51.8% (8.8; OR for treatment effect 1.036, 95% CI 0.961-1.118, p=0.36). Compared with placebo infusion, BMSC transfer was associated with a significant reduction in myocardial infarct size (BMSC treatment effect 28%, p=0.036) and a better recovery of regional systolic function. Myocardial perfusion and metabolism increased similarly in both groups. We noted no complications associated with BMSC transfer and all but one patient in the BMSC group completed the 4 months' follow-up.Intracoronary transfer of autologous bone marrow cells within 24 h of optimum reperfusion therapy does not augment recovery of global LV function after myocardial infarction, but could favourably affect infarct remodelling.","Autologous bone marrow-derived stem-cell transfer in patients with ST-segment elevation myocardial infarction: double-blind, randomised controlled trial."
"652","JAMA.356","0.001",16418466,2006,"Aspirin therapy reduces the risk of cardiovascular disease in adults who are at increased risk. However, it is unclear if women derive the same benefit as men.To determine if the benefits and risks of aspirin treatment in the primary prevention of cardiovascular disease vary by sex.MEDLINE and the Cochrane Central Register of Controlled Trials databases (1966 to March 2005), bibliographies of retrieved trials, and reports presented at major scientific meetings. Eligible studies were prospective, randomized controlled trials of aspirin therapy in participants without cardiovascular disease that reported data on myocardial infarction (MI), stroke, and cardiovascular mortality. Six trials with a total of 95 456 individuals were identified; 3 trials included only men, 1 included only women, and 2 included both sexes.Studies were reviewed to determine the number of patients randomized, mean duration of follow-up, and end points (a composite of cardiovascular events [nonfatal MI, nonfatal stroke, and cardiovascular mortality], each of these individual components separately, and major bleeding).Among 51,342 women, there were 1285 major cardiovascular events: 625 strokes, 469 MIs, and 364 cardiovascular deaths. Aspirin therapy was associated with a significant 12% reduction in cardiovascular events (odds ratio [OR], 0.88; 95% confidence interval [CI], 0.79-0.99; P = .03) and a 17% reduction in stroke (OR, 0.83; 95% CI, 0.70-0.97; P = .02), which was a reflection of reduced rates of ischemic stroke (OR, 0.76; 95% CI, 0.63-0.93; P = .008). There was no significant effect on MI or cardiovascular mortality. Among 44,114 men, there were 2047 major cardiovascular events: 597 strokes, 1023 MIs, and 776 cardiovascular deaths. Aspirin therapy was associated with a significant 14% reduction in cardiovascular events (OR, 0.86; 95% CI, 0.78-0.94; P = .01) and a 32% reduction in MI (OR, 0.68; 95% CI, 0.54-0.86; P = .001). There was no significant effect on stroke or cardiovascular mortality. Aspirin treatment increased the risk of bleeding in women (OR, 1.68; 95% CI, 1.13-2.52; P = .01) and in men (OR, 1.72; 95% CI, 1.35-2.20; P<.001).For women and men, aspirin therapy reduced the risk of a composite of cardiovascular events due to its effect on reducing the risk of ischemic stroke in women and MI in men. Aspirin significantly increased the risk of bleeding to a similar degree among women and men.","Aspirin for the primary prevention of cardiovascular events in women and men: a sex-specific meta-analysis of randomized controlled trials."
"653","JAMA.381","0.03",16418466,2006,"Aspirin therapy reduces the risk of cardiovascular disease in adults who are at increased risk. However, it is unclear if women derive the same benefit as men.To determine if the benefits and risks of aspirin treatment in the primary prevention of cardiovascular disease vary by sex.MEDLINE and the Cochrane Central Register of Controlled Trials databases (1966 to March 2005), bibliographies of retrieved trials, and reports presented at major scientific meetings. Eligible studies were prospective, randomized controlled trials of aspirin therapy in participants without cardiovascular disease that reported data on myocardial infarction (MI), stroke, and cardiovascular mortality. Six trials with a total of 95 456 individuals were identified; 3 trials included only men, 1 included only women, and 2 included both sexes.Studies were reviewed to determine the number of patients randomized, mean duration of follow-up, and end points (a composite of cardiovascular events [nonfatal MI, nonfatal stroke, and cardiovascular mortality], each of these individual components separately, and major bleeding).Among 51,342 women, there were 1285 major cardiovascular events: 625 strokes, 469 MIs, and 364 cardiovascular deaths. Aspirin therapy was associated with a significant 12% reduction in cardiovascular events (odds ratio [OR], 0.88; 95% confidence interval [CI], 0.79-0.99; P = .03) and a 17% reduction in stroke (OR, 0.83; 95% CI, 0.70-0.97; P = .02), which was a reflection of reduced rates of ischemic stroke (OR, 0.76; 95% CI, 0.63-0.93; P = .008). There was no significant effect on MI or cardiovascular mortality. Among 44,114 men, there were 2047 major cardiovascular events: 597 strokes, 1023 MIs, and 776 cardiovascular deaths. Aspirin therapy was associated with a significant 14% reduction in cardiovascular events (OR, 0.86; 95% CI, 0.78-0.94; P = .01) and a 32% reduction in MI (OR, 0.68; 95% CI, 0.54-0.86; P = .001). There was no significant effect on stroke or cardiovascular mortality. Aspirin treatment increased the risk of bleeding in women (OR, 1.68; 95% CI, 1.13-2.52; P = .01) and in men (OR, 1.72; 95% CI, 1.35-2.20; P<.001).For women and men, aspirin therapy reduced the risk of a composite of cardiovascular events due to its effect on reducing the risk of ischemic stroke in women and MI in men. Aspirin significantly increased the risk of bleeding to a similar degree among women and men.","Aspirin for the primary prevention of cardiovascular events in women and men: a sex-specific meta-analysis of randomized controlled trials."
"654","JAMA.382","0.02",16418466,2006,"Aspirin therapy reduces the risk of cardiovascular disease in adults who are at increased risk. However, it is unclear if women derive the same benefit as men.To determine if the benefits and risks of aspirin treatment in the primary prevention of cardiovascular disease vary by sex.MEDLINE and the Cochrane Central Register of Controlled Trials databases (1966 to March 2005), bibliographies of retrieved trials, and reports presented at major scientific meetings. Eligible studies were prospective, randomized controlled trials of aspirin therapy in participants without cardiovascular disease that reported data on myocardial infarction (MI), stroke, and cardiovascular mortality. Six trials with a total of 95 456 individuals were identified; 3 trials included only men, 1 included only women, and 2 included both sexes.Studies were reviewed to determine the number of patients randomized, mean duration of follow-up, and end points (a composite of cardiovascular events [nonfatal MI, nonfatal stroke, and cardiovascular mortality], each of these individual components separately, and major bleeding).Among 51,342 women, there were 1285 major cardiovascular events: 625 strokes, 469 MIs, and 364 cardiovascular deaths. Aspirin therapy was associated with a significant 12% reduction in cardiovascular events (odds ratio [OR], 0.88; 95% confidence interval [CI], 0.79-0.99; P = .03) and a 17% reduction in stroke (OR, 0.83; 95% CI, 0.70-0.97; P = .02), which was a reflection of reduced rates of ischemic stroke (OR, 0.76; 95% CI, 0.63-0.93; P = .008). There was no significant effect on MI or cardiovascular mortality. Among 44,114 men, there were 2047 major cardiovascular events: 597 strokes, 1023 MIs, and 776 cardiovascular deaths. Aspirin therapy was associated with a significant 14% reduction in cardiovascular events (OR, 0.86; 95% CI, 0.78-0.94; P = .01) and a 32% reduction in MI (OR, 0.68; 95% CI, 0.54-0.86; P = .001). There was no significant effect on stroke or cardiovascular mortality. Aspirin treatment increased the risk of bleeding in women (OR, 1.68; 95% CI, 1.13-2.52; P = .01) and in men (OR, 1.72; 95% CI, 1.35-2.20; P<.001).For women and men, aspirin therapy reduced the risk of a composite of cardiovascular events due to its effect on reducing the risk of ischemic stroke in women and MI in men. Aspirin significantly increased the risk of bleeding to a similar degree among women and men.","Aspirin for the primary prevention of cardiovascular events in women and men: a sex-specific meta-analysis of randomized controlled trials."
"655","JAMA.383","0.008",16418466,2006,"Aspirin therapy reduces the risk of cardiovascular disease in adults who are at increased risk. However, it is unclear if women derive the same benefit as men.To determine if the benefits and risks of aspirin treatment in the primary prevention of cardiovascular disease vary by sex.MEDLINE and the Cochrane Central Register of Controlled Trials databases (1966 to March 2005), bibliographies of retrieved trials, and reports presented at major scientific meetings. Eligible studies were prospective, randomized controlled trials of aspirin therapy in participants without cardiovascular disease that reported data on myocardial infarction (MI), stroke, and cardiovascular mortality. Six trials with a total of 95 456 individuals were identified; 3 trials included only men, 1 included only women, and 2 included both sexes.Studies were reviewed to determine the number of patients randomized, mean duration of follow-up, and end points (a composite of cardiovascular events [nonfatal MI, nonfatal stroke, and cardiovascular mortality], each of these individual components separately, and major bleeding).Among 51,342 women, there were 1285 major cardiovascular events: 625 strokes, 469 MIs, and 364 cardiovascular deaths. Aspirin therapy was associated with a significant 12% reduction in cardiovascular events (odds ratio [OR], 0.88; 95% confidence interval [CI], 0.79-0.99; P = .03) and a 17% reduction in stroke (OR, 0.83; 95% CI, 0.70-0.97; P = .02), which was a reflection of reduced rates of ischemic stroke (OR, 0.76; 95% CI, 0.63-0.93; P = .008). There was no significant effect on MI or cardiovascular mortality. Among 44,114 men, there were 2047 major cardiovascular events: 597 strokes, 1023 MIs, and 776 cardiovascular deaths. Aspirin therapy was associated with a significant 14% reduction in cardiovascular events (OR, 0.86; 95% CI, 0.78-0.94; P = .01) and a 32% reduction in MI (OR, 0.68; 95% CI, 0.54-0.86; P = .001). There was no significant effect on stroke or cardiovascular mortality. Aspirin treatment increased the risk of bleeding in women (OR, 1.68; 95% CI, 1.13-2.52; P = .01) and in men (OR, 1.72; 95% CI, 1.35-2.20; P<.001).For women and men, aspirin therapy reduced the risk of a composite of cardiovascular events due to its effect on reducing the risk of ischemic stroke in women and MI in men. Aspirin significantly increased the risk of bleeding to a similar degree among women and men.","Aspirin for the primary prevention of cardiovascular events in women and men: a sex-specific meta-analysis of randomized controlled trials."
"656","JAMA.384","0.01",16418466,2006,"Aspirin therapy reduces the risk of cardiovascular disease in adults who are at increased risk. However, it is unclear if women derive the same benefit as men.To determine if the benefits and risks of aspirin treatment in the primary prevention of cardiovascular disease vary by sex.MEDLINE and the Cochrane Central Register of Controlled Trials databases (1966 to March 2005), bibliographies of retrieved trials, and reports presented at major scientific meetings. Eligible studies were prospective, randomized controlled trials of aspirin therapy in participants without cardiovascular disease that reported data on myocardial infarction (MI), stroke, and cardiovascular mortality. Six trials with a total of 95 456 individuals were identified; 3 trials included only men, 1 included only women, and 2 included both sexes.Studies were reviewed to determine the number of patients randomized, mean duration of follow-up, and end points (a composite of cardiovascular events [nonfatal MI, nonfatal stroke, and cardiovascular mortality], each of these individual components separately, and major bleeding).Among 51,342 women, there were 1285 major cardiovascular events: 625 strokes, 469 MIs, and 364 cardiovascular deaths. Aspirin therapy was associated with a significant 12% reduction in cardiovascular events (odds ratio [OR], 0.88; 95% confidence interval [CI], 0.79-0.99; P = .03) and a 17% reduction in stroke (OR, 0.83; 95% CI, 0.70-0.97; P = .02), which was a reflection of reduced rates of ischemic stroke (OR, 0.76; 95% CI, 0.63-0.93; P = .008). There was no significant effect on MI or cardiovascular mortality. Among 44,114 men, there were 2047 major cardiovascular events: 597 strokes, 1023 MIs, and 776 cardiovascular deaths. Aspirin therapy was associated with a significant 14% reduction in cardiovascular events (OR, 0.86; 95% CI, 0.78-0.94; P = .01) and a 32% reduction in MI (OR, 0.68; 95% CI, 0.54-0.86; P = .001). There was no significant effect on stroke or cardiovascular mortality. Aspirin treatment increased the risk of bleeding in women (OR, 1.68; 95% CI, 1.13-2.52; P = .01) and in men (OR, 1.72; 95% CI, 1.35-2.20; P<.001).For women and men, aspirin therapy reduced the risk of a composite of cardiovascular events due to its effect on reducing the risk of ischemic stroke in women and MI in men. Aspirin significantly increased the risk of bleeding to a similar degree among women and men.","Aspirin for the primary prevention of cardiovascular events in women and men: a sex-specific meta-analysis of randomized controlled trials."
"657","JAMA.385","0.001",16418466,2006,"Aspirin therapy reduces the risk of cardiovascular disease in adults who are at increased risk. However, it is unclear if women derive the same benefit as men.To determine if the benefits and risks of aspirin treatment in the primary prevention of cardiovascular disease vary by sex.MEDLINE and the Cochrane Central Register of Controlled Trials databases (1966 to March 2005), bibliographies of retrieved trials, and reports presented at major scientific meetings. Eligible studies were prospective, randomized controlled trials of aspirin therapy in participants without cardiovascular disease that reported data on myocardial infarction (MI), stroke, and cardiovascular mortality. Six trials with a total of 95 456 individuals were identified; 3 trials included only men, 1 included only women, and 2 included both sexes.Studies were reviewed to determine the number of patients randomized, mean duration of follow-up, and end points (a composite of cardiovascular events [nonfatal MI, nonfatal stroke, and cardiovascular mortality], each of these individual components separately, and major bleeding).Among 51,342 women, there were 1285 major cardiovascular events: 625 strokes, 469 MIs, and 364 cardiovascular deaths. Aspirin therapy was associated with a significant 12% reduction in cardiovascular events (odds ratio [OR], 0.88; 95% confidence interval [CI], 0.79-0.99; P = .03) and a 17% reduction in stroke (OR, 0.83; 95% CI, 0.70-0.97; P = .02), which was a reflection of reduced rates of ischemic stroke (OR, 0.76; 95% CI, 0.63-0.93; P = .008). There was no significant effect on MI or cardiovascular mortality. Among 44,114 men, there were 2047 major cardiovascular events: 597 strokes, 1023 MIs, and 776 cardiovascular deaths. Aspirin therapy was associated with a significant 14% reduction in cardiovascular events (OR, 0.86; 95% CI, 0.78-0.94; P = .01) and a 32% reduction in MI (OR, 0.68; 95% CI, 0.54-0.86; P = .001). There was no significant effect on stroke or cardiovascular mortality. Aspirin treatment increased the risk of bleeding in women (OR, 1.68; 95% CI, 1.13-2.52; P = .01) and in men (OR, 1.72; 95% CI, 1.35-2.20; P<.001).For women and men, aspirin therapy reduced the risk of a composite of cardiovascular events due to its effect on reducing the risk of ischemic stroke in women and MI in men. Aspirin significantly increased the risk of bleeding to a similar degree among women and men.","Aspirin for the primary prevention of cardiovascular events in women and men: a sex-specific meta-analysis of randomized controlled trials."
"658","JAMA.386","0.01",16418466,2006,"Aspirin therapy reduces the risk of cardiovascular disease in adults who are at increased risk. However, it is unclear if women derive the same benefit as men.To determine if the benefits and risks of aspirin treatment in the primary prevention of cardiovascular disease vary by sex.MEDLINE and the Cochrane Central Register of Controlled Trials databases (1966 to March 2005), bibliographies of retrieved trials, and reports presented at major scientific meetings. Eligible studies were prospective, randomized controlled trials of aspirin therapy in participants without cardiovascular disease that reported data on myocardial infarction (MI), stroke, and cardiovascular mortality. Six trials with a total of 95 456 individuals were identified; 3 trials included only men, 1 included only women, and 2 included both sexes.Studies were reviewed to determine the number of patients randomized, mean duration of follow-up, and end points (a composite of cardiovascular events [nonfatal MI, nonfatal stroke, and cardiovascular mortality], each of these individual components separately, and major bleeding).Among 51,342 women, there were 1285 major cardiovascular events: 625 strokes, 469 MIs, and 364 cardiovascular deaths. Aspirin therapy was associated with a significant 12% reduction in cardiovascular events (odds ratio [OR], 0.88; 95% confidence interval [CI], 0.79-0.99; P = .03) and a 17% reduction in stroke (OR, 0.83; 95% CI, 0.70-0.97; P = .02), which was a reflection of reduced rates of ischemic stroke (OR, 0.76; 95% CI, 0.63-0.93; P = .008). There was no significant effect on MI or cardiovascular mortality. Among 44,114 men, there were 2047 major cardiovascular events: 597 strokes, 1023 MIs, and 776 cardiovascular deaths. Aspirin therapy was associated with a significant 14% reduction in cardiovascular events (OR, 0.86; 95% CI, 0.78-0.94; P = .01) and a 32% reduction in MI (OR, 0.68; 95% CI, 0.54-0.86; P = .001). There was no significant effect on stroke or cardiovascular mortality. Aspirin treatment increased the risk of bleeding in women (OR, 1.68; 95% CI, 1.13-2.52; P = .01) and in men (OR, 1.72; 95% CI, 1.35-2.20; P<.001).For women and men, aspirin therapy reduced the risk of a composite of cardiovascular events due to its effect on reducing the risk of ischemic stroke in women and MI in men. Aspirin significantly increased the risk of bleeding to a similar degree among women and men.","Aspirin for the primary prevention of cardiovascular events in women and men: a sex-specific meta-analysis of randomized controlled trials."
"659","JAMA.3241","0.001",16434629,2006,"The benefit of adjuvant radiation therapy (RT) in stage I endometrial adenocarcinoma remains controversial despite several phase 3 trials.To evaluate the frequency and effect of adjuvant RT on overall and relative survival within a large US population database.A retrospective analysis that used data from the Surveillance, Epidemiology, and End Results program of the US National Cancer Institute from January 1, 1988, to December 31, 2001. A total of 21,249 patients with American Joint Committee on Cancer stage IA-C node-negative endometrial adenocarcinoma comprised the study population.Overall survival curves were constructed using Kaplan-Meier method and compared via stratified log-rank test within T stage/grade combinations, adjusted for age. Relative survival was performed to assess the effects of age, race, stage, grade, whether nodes were examined, and whether adjuvant RT was administered.Of 21,249 women, 4080 received adjuvant RT (19.2%) and 17,169 did not receive adjuvant RT (80.8%). The mean age at diagnosis was 63.2 years (range, 14-99 years). Adjuvant RT significantly improved overall survival for patients with stage IC/grade 1 (P<.001) and stage IC/grades 3 and 4 (P<.001). Cox proportional hazards regression analysis revealed a statistically detectable association of adjuvant RT with improved relative survival in patients with stage IC/grade 1 and stage IC/grades 3 and 4 (hazard ratio [HR], 0.44; 95% confidence interval [CI], 0.31-0.63; P<.001; and HR, 0.72; 95% CI, 0.57-0.92; P = .009; respectively). A separate analysis of those patients with a surgical lymph node examination at the time of total abdominal hysterectomy and bilateral salpingo-oophorectomy revealed similar estimates (HR, 0.59; 95% CI, 0.39-0.90; P = .01; and HR, 0.73; 95% CI, 0.55-0.96; P = .02; respectively).As the largest reported population analysis to date of adjuvant RT in early stage endometrial adenocarcinoma, our study reveals a statistically significant association between improved overall and relative survival and adjuvant RT in stage IC disease (grades 1 and 3-4). Future work is needed to continue to delineate clinical and biological factors, which can guide treatment decisions and account for disparities in outcome between varied subsets of patients.","Frequency and effect of adjuvant radiation therapy among women with stage I endometrial adenocarcinoma."
"660","JAMA.3491","0.009",16434629,2006,"The benefit of adjuvant radiation therapy (RT) in stage I endometrial adenocarcinoma remains controversial despite several phase 3 trials.To evaluate the frequency and effect of adjuvant RT on overall and relative survival within a large US population database.A retrospective analysis that used data from the Surveillance, Epidemiology, and End Results program of the US National Cancer Institute from January 1, 1988, to December 31, 2001. A total of 21,249 patients with American Joint Committee on Cancer stage IA-C node-negative endometrial adenocarcinoma comprised the study population.Overall survival curves were constructed using Kaplan-Meier method and compared via stratified log-rank test within T stage/grade combinations, adjusted for age. Relative survival was performed to assess the effects of age, race, stage, grade, whether nodes were examined, and whether adjuvant RT was administered.Of 21,249 women, 4080 received adjuvant RT (19.2%) and 17,169 did not receive adjuvant RT (80.8%). The mean age at diagnosis was 63.2 years (range, 14-99 years). Adjuvant RT significantly improved overall survival for patients with stage IC/grade 1 (P<.001) and stage IC/grades 3 and 4 (P<.001). Cox proportional hazards regression analysis revealed a statistically detectable association of adjuvant RT with improved relative survival in patients with stage IC/grade 1 and stage IC/grades 3 and 4 (hazard ratio [HR], 0.44; 95% confidence interval [CI], 0.31-0.63; P<.001; and HR, 0.72; 95% CI, 0.57-0.92; P = .009; respectively). A separate analysis of those patients with a surgical lymph node examination at the time of total abdominal hysterectomy and bilateral salpingo-oophorectomy revealed similar estimates (HR, 0.59; 95% CI, 0.39-0.90; P = .01; and HR, 0.73; 95% CI, 0.55-0.96; P = .02; respectively).As the largest reported population analysis to date of adjuvant RT in early stage endometrial adenocarcinoma, our study reveals a statistically significant association between improved overall and relative survival and adjuvant RT in stage IC disease (grades 1 and 3-4). Future work is needed to continue to delineate clinical and biological factors, which can guide treatment decisions and account for disparities in outcome between varied subsets of patients.","Frequency and effect of adjuvant radiation therapy among women with stage I endometrial adenocarcinoma."
"661","JAMA.3501","0.01",16434629,2006,"The benefit of adjuvant radiation therapy (RT) in stage I endometrial adenocarcinoma remains controversial despite several phase 3 trials.To evaluate the frequency and effect of adjuvant RT on overall and relative survival within a large US population database.A retrospective analysis that used data from the Surveillance, Epidemiology, and End Results program of the US National Cancer Institute from January 1, 1988, to December 31, 2001. A total of 21,249 patients with American Joint Committee on Cancer stage IA-C node-negative endometrial adenocarcinoma comprised the study population.Overall survival curves were constructed using Kaplan-Meier method and compared via stratified log-rank test within T stage/grade combinations, adjusted for age. Relative survival was performed to assess the effects of age, race, stage, grade, whether nodes were examined, and whether adjuvant RT was administered.Of 21,249 women, 4080 received adjuvant RT (19.2%) and 17,169 did not receive adjuvant RT (80.8%). The mean age at diagnosis was 63.2 years (range, 14-99 years). Adjuvant RT significantly improved overall survival for patients with stage IC/grade 1 (P<.001) and stage IC/grades 3 and 4 (P<.001). Cox proportional hazards regression analysis revealed a statistically detectable association of adjuvant RT with improved relative survival in patients with stage IC/grade 1 and stage IC/grades 3 and 4 (hazard ratio [HR], 0.44; 95% confidence interval [CI], 0.31-0.63; P<.001; and HR, 0.72; 95% CI, 0.57-0.92; P = .009; respectively). A separate analysis of those patients with a surgical lymph node examination at the time of total abdominal hysterectomy and bilateral salpingo-oophorectomy revealed similar estimates (HR, 0.59; 95% CI, 0.39-0.90; P = .01; and HR, 0.73; 95% CI, 0.55-0.96; P = .02; respectively).As the largest reported population analysis to date of adjuvant RT in early stage endometrial adenocarcinoma, our study reveals a statistically significant association between improved overall and relative survival and adjuvant RT in stage IC disease (grades 1 and 3-4). Future work is needed to continue to delineate clinical and biological factors, which can guide treatment decisions and account for disparities in outcome between varied subsets of patients.","Frequency and effect of adjuvant radiation therapy among women with stage I endometrial adenocarcinoma."
"662","JAMA.3511","0.02",16434629,2006,"The benefit of adjuvant radiation therapy (RT) in stage I endometrial adenocarcinoma remains controversial despite several phase 3 trials.To evaluate the frequency and effect of adjuvant RT on overall and relative survival within a large US population database.A retrospective analysis that used data from the Surveillance, Epidemiology, and End Results program of the US National Cancer Institute from January 1, 1988, to December 31, 2001. A total of 21,249 patients with American Joint Committee on Cancer stage IA-C node-negative endometrial adenocarcinoma comprised the study population.Overall survival curves were constructed using Kaplan-Meier method and compared via stratified log-rank test within T stage/grade combinations, adjusted for age. Relative survival was performed to assess the effects of age, race, stage, grade, whether nodes were examined, and whether adjuvant RT was administered.Of 21,249 women, 4080 received adjuvant RT (19.2%) and 17,169 did not receive adjuvant RT (80.8%). The mean age at diagnosis was 63.2 years (range, 14-99 years). Adjuvant RT significantly improved overall survival for patients with stage IC/grade 1 (P<.001) and stage IC/grades 3 and 4 (P<.001). Cox proportional hazards regression analysis revealed a statistically detectable association of adjuvant RT with improved relative survival in patients with stage IC/grade 1 and stage IC/grades 3 and 4 (hazard ratio [HR], 0.44; 95% confidence interval [CI], 0.31-0.63; P<.001; and HR, 0.72; 95% CI, 0.57-0.92; P = .009; respectively). A separate analysis of those patients with a surgical lymph node examination at the time of total abdominal hysterectomy and bilateral salpingo-oophorectomy revealed similar estimates (HR, 0.59; 95% CI, 0.39-0.90; P = .01; and HR, 0.73; 95% CI, 0.55-0.96; P = .02; respectively).As the largest reported population analysis to date of adjuvant RT in early stage endometrial adenocarcinoma, our study reveals a statistically significant association between improved overall and relative survival and adjuvant RT in stage IC disease (grades 1 and 3-4). Future work is needed to continue to delineate clinical and biological factors, which can guide treatment decisions and account for disparities in outcome between varied subsets of patients.","Frequency and effect of adjuvant radiation therapy among women with stage I endometrial adenocarcinoma."
"663","American Journal of Epidemiology.66","0.01",16524957,2006,"Between 2001 and 2003, the authors studied pregnancy outcomes and infant mortality among 202 married women in West Bengal, India. Reproductive histories were ascertained using structured interviews. Arsenic exposure during each pregnancy, including all water sources used, was assessed; this involved measurements from 409 wells. Odds ratios for spontaneous abortion, stillbirth, neonatal mortality, and infant mortality were estimated with logistic regression based on the method of generalized estimating equations. Exposure to high concentrations of arsenic (> or =200 microg/liter) during pregnancy was associated with a sixfold increased risk of stillbirth after adjustment for potential confounders (odds ratio (OR) = 6.07, 95% confidence interval (CI): 1.54, 24.0; p = 0.01). Arsenic-related skin lesions were found in 12 women who had a substantially increased risk of stillbirth (OR = 13.1, 95% CI: 3.17, 54.0; p = 0.002). The odds ratio for neonatal death was 2.81 (95% CI: 0.73, 10.8). No association was found between arsenic exposure and spontaneous abortion (OR = 1.01, 95% CI: 0.38, 2.70) or overall infant mortality (OR = 1.33, 95% CI: 0.43, 4.04). This study adds to the limited evidence that exposure to high concentrations of arsenic during pregnancy increases the risk of stillbirth. However, there was no indication of the increased rates of spontaneous abortion and overall infant mortality that have been reported in some studies.","Pregnancy outcomes, infant mortality, and arsenic in drinking water in West Bengal, India."
"664","American Journal of Epidemiology.67","0.002",16524957,2006,"Between 2001 and 2003, the authors studied pregnancy outcomes and infant mortality among 202 married women in West Bengal, India. Reproductive histories were ascertained using structured interviews. Arsenic exposure during each pregnancy, including all water sources used, was assessed; this involved measurements from 409 wells. Odds ratios for spontaneous abortion, stillbirth, neonatal mortality, and infant mortality were estimated with logistic regression based on the method of generalized estimating equations. Exposure to high concentrations of arsenic (> or =200 microg/liter) during pregnancy was associated with a sixfold increased risk of stillbirth after adjustment for potential confounders (odds ratio (OR) = 6.07, 95% confidence interval (CI): 1.54, 24.0; p = 0.01). Arsenic-related skin lesions were found in 12 women who had a substantially increased risk of stillbirth (OR = 13.1, 95% CI: 3.17, 54.0; p = 0.002). The odds ratio for neonatal death was 2.81 (95% CI: 0.73, 10.8). No association was found between arsenic exposure and spontaneous abortion (OR = 1.01, 95% CI: 0.38, 2.70) or overall infant mortality (OR = 1.33, 95% CI: 0.43, 4.04). This study adds to the limited evidence that exposure to high concentrations of arsenic during pregnancy increases the risk of stillbirth. However, there was no indication of the increased rates of spontaneous abortion and overall infant mortality that have been reported in some studies.","Pregnancy outcomes, infant mortality, and arsenic in drinking water in West Bengal, India."
"665","Lancet.631","0.19",16530576,2006,"Since 1960, oral melphalan and prednisone (MP) has been regarded as the standard of care in elderly multiple myeloma patients. This multicentre randomised trial compared oral MP plus thalidomide (MPT) with MP alone in patients aged 60-85 years.Patients with newly diagnosed multiple myeloma were randomly assigned to receive oral MP for six 4-week cycles plus thalidomide (n=129; 100 mg per day continuously until any sign of relapse or progressive disease) or MP alone (n=126). Analysis was intention-to-treat. This study is registered at , number NCT00232934.Patients treated with thalidomide had higher response rates and longer event-free survival (primary endpoints) than patients who were not. Combined complete or partial response rates were 76.0% for MPT and 47.6% for MP alone (absolute difference 28.3%, 95% CI 16.5-39.1), and the near-complete or complete response rates were 27.9% and 7.2%, respectively. 2-year event-free survival rates were 54% for MPT and 27% for MP (hazard ratio [HR] for MPT 0.51, 95% CI 0.35-0.75, p=0.0006). 3-year survival rates were 80% for MPT and 64% for MP (HR for MPT 0.68, 95% CI 0.38-1.22, p=0.19). Rates of grade 3 or 4 adverse events were 48% in MPT patients and 25% in MP patients (p=0.0002). Introduction of enoxaparin prophylaxis reduced rate of thromboembolism from 20% to 3% (p=0.005).Oral MPT is an effective first-line treatment for elderly patients with multiple myeloma. Anticoagulant prophylaxis reduces frequency of thrombosis. Longer follow-up is needed to assess effect on overall survival.","Oral melphalan and prednisone chemotherapy plus thalidomide compared with melphalan and prednisone alone in elderly patients with multiple myeloma: randomised controlled trial."
"666","Lancet.641","6.00E-04",16530576,2006,"Since 1960, oral melphalan and prednisone (MP) has been regarded as the standard of care in elderly multiple myeloma patients. This multicentre randomised trial compared oral MP plus thalidomide (MPT) with MP alone in patients aged 60-85 years.Patients with newly diagnosed multiple myeloma were randomly assigned to receive oral MP for six 4-week cycles plus thalidomide (n=129; 100 mg per day continuously until any sign of relapse or progressive disease) or MP alone (n=126). Analysis was intention-to-treat. This study is registered at , number NCT00232934.Patients treated with thalidomide had higher response rates and longer event-free survival (primary endpoints) than patients who were not. Combined complete or partial response rates were 76.0% for MPT and 47.6% for MP alone (absolute difference 28.3%, 95% CI 16.5-39.1), and the near-complete or complete response rates were 27.9% and 7.2%, respectively. 2-year event-free survival rates were 54% for MPT and 27% for MP (hazard ratio [HR] for MPT 0.51, 95% CI 0.35-0.75, p=0.0006). 3-year survival rates were 80% for MPT and 64% for MP (HR for MPT 0.68, 95% CI 0.38-1.22, p=0.19). Rates of grade 3 or 4 adverse events were 48% in MPT patients and 25% in MP patients (p=0.0002). Introduction of enoxaparin prophylaxis reduced rate of thromboembolism from 20% to 3% (p=0.005).Oral MPT is an effective first-line treatment for elderly patients with multiple myeloma. Anticoagulant prophylaxis reduces frequency of thrombosis. Longer follow-up is needed to assess effect on overall survival.","Oral melphalan and prednisone chemotherapy plus thalidomide compared with melphalan and prednisone alone in elderly patients with multiple myeloma: randomised controlled trial."
"667","JAMA.3401","0.008",16537725,2006,"Despite many therapeutic advances, mortality in patients with acute ST-segment elevation myocardial infarction (STEMI) remains high. The role of additional antithrombotic agents is unclear, especially among patients not receiving reperfusion therapy.To evaluate the effect of fondaparinux, a factor Xa inhibitor, when initiated early and given for up to 8 days vs usual care (placebo in those in whom unfractionated heparin [UFH] is not indicated [stratum 1] or unfractionated heparin for up to 48 hours followed by placebo for up to 8 days [stratum 2]) in patients with STEMI.Randomized double-blind comparison of fondaparinux 2.5 mg once daily or control for up to 8 days in 12,092 patients with STEMI from 447 hospitals in 41 countries (September 2003-January 2006). From day 3 through day 9, all patients received either fondaparinux or placebo according to the original randomized assignment.Composite of death or reinfarction at 30 days (primary) with secondary assessments at 9 days and at final follow-up (3 or 6 months).Death or reinfarction at 30 days was significantly reduced from 677 (11.2%) of 6056 patients in the control group to 585 (9.7%) of 6036 patients in the fondaparinux group (hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.77-0.96; P = .008); absolute risk reduction, 1.5%; 95% CI, 0.4%-2.6%). These benefits were observed at 9 days (537 [8.9%] placebo vs 444 [7.4%] fondaparinux; HR, 0.83; 95% CI, 0.73-0.94; P = .003, and at study end (857 [14.8%] placebo vs 756 [13.4%] fondaparinux; HR, 0.88; 95% CI, 0.79-0.97; P = .008). Mortality was significantly reduced throughout the study. There was no heterogeneity of the effects of fondaparinux in the 2 strata by planned heparin use. However, there was no benefit in those undergoing primary percutaneous coronary intervention. In other patients in stratum 2, fondaparinux was superior to unfractionated heparin in preventing death or reinfarction at 30 days (HR, 0.82; 95% CI, 0.66-1.02; P = .08) and at study end (HR, 0.77; 95% CI, 0.64-0.93; P = .008). Significant benefits were observed in those receiving thrombolytic therapy (HR, 0.79; P = .003) and those not receiving any reperfusion therapy (HR, 0.80; P = .03). There was a tendency to fewer severe bleeds (79 for placebo vs 61 for fondaparinux; P = .13), with significantly fewer cardiac tamponade (48 vs 28; P = .02) with fondaparinux at 9 days.In patients with STEMI, particularly those not undergoing primary percutaneous coronary intervention, fondaparinux significantly reduces mortality and reinfarction without increasing bleeding and strokes.ClinicalTrials.gov Identifier NCT00064428.","Effects of fondaparinux on mortality and reinfarction in patients with acute ST-segment elevation myocardial infarction: the OASIS-6 randomized trial."
"668","JAMA.3411","0.003",16537725,2006,"Despite many therapeutic advances, mortality in patients with acute ST-segment elevation myocardial infarction (STEMI) remains high. The role of additional antithrombotic agents is unclear, especially among patients not receiving reperfusion therapy.To evaluate the effect of fondaparinux, a factor Xa inhibitor, when initiated early and given for up to 8 days vs usual care (placebo in those in whom unfractionated heparin [UFH] is not indicated [stratum 1] or unfractionated heparin for up to 48 hours followed by placebo for up to 8 days [stratum 2]) in patients with STEMI.Randomized double-blind comparison of fondaparinux 2.5 mg once daily or control for up to 8 days in 12,092 patients with STEMI from 447 hospitals in 41 countries (September 2003-January 2006). From day 3 through day 9, all patients received either fondaparinux or placebo according to the original randomized assignment.Composite of death or reinfarction at 30 days (primary) with secondary assessments at 9 days and at final follow-up (3 or 6 months).Death or reinfarction at 30 days was significantly reduced from 677 (11.2%) of 6056 patients in the control group to 585 (9.7%) of 6036 patients in the fondaparinux group (hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.77-0.96; P = .008); absolute risk reduction, 1.5%; 95% CI, 0.4%-2.6%). These benefits were observed at 9 days (537 [8.9%] placebo vs 444 [7.4%] fondaparinux; HR, 0.83; 95% CI, 0.73-0.94; P = .003, and at study end (857 [14.8%] placebo vs 756 [13.4%] fondaparinux; HR, 0.88; 95% CI, 0.79-0.97; P = .008). Mortality was significantly reduced throughout the study. There was no heterogeneity of the effects of fondaparinux in the 2 strata by planned heparin use. However, there was no benefit in those undergoing primary percutaneous coronary intervention. In other patients in stratum 2, fondaparinux was superior to unfractionated heparin in preventing death or reinfarction at 30 days (HR, 0.82; 95% CI, 0.66-1.02; P = .08) and at study end (HR, 0.77; 95% CI, 0.64-0.93; P = .008). Significant benefits were observed in those receiving thrombolytic therapy (HR, 0.79; P = .003) and those not receiving any reperfusion therapy (HR, 0.80; P = .03). There was a tendency to fewer severe bleeds (79 for placebo vs 61 for fondaparinux; P = .13), with significantly fewer cardiac tamponade (48 vs 28; P = .02) with fondaparinux at 9 days.In patients with STEMI, particularly those not undergoing primary percutaneous coronary intervention, fondaparinux significantly reduces mortality and reinfarction without increasing bleeding and strokes.ClinicalTrials.gov Identifier NCT00064428.","Effects of fondaparinux on mortality and reinfarction in patients with acute ST-segment elevation myocardial infarction: the OASIS-6 randomized trial."
"669","JAMA.3421","0.008",16537725,2006,"Despite many therapeutic advances, mortality in patients with acute ST-segment elevation myocardial infarction (STEMI) remains high. The role of additional antithrombotic agents is unclear, especially among patients not receiving reperfusion therapy.To evaluate the effect of fondaparinux, a factor Xa inhibitor, when initiated early and given for up to 8 days vs usual care (placebo in those in whom unfractionated heparin [UFH] is not indicated [stratum 1] or unfractionated heparin for up to 48 hours followed by placebo for up to 8 days [stratum 2]) in patients with STEMI.Randomized double-blind comparison of fondaparinux 2.5 mg once daily or control for up to 8 days in 12,092 patients with STEMI from 447 hospitals in 41 countries (September 2003-January 2006). From day 3 through day 9, all patients received either fondaparinux or placebo according to the original randomized assignment.Composite of death or reinfarction at 30 days (primary) with secondary assessments at 9 days and at final follow-up (3 or 6 months).Death or reinfarction at 30 days was significantly reduced from 677 (11.2%) of 6056 patients in the control group to 585 (9.7%) of 6036 patients in the fondaparinux group (hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.77-0.96; P = .008); absolute risk reduction, 1.5%; 95% CI, 0.4%-2.6%). These benefits were observed at 9 days (537 [8.9%] placebo vs 444 [7.4%] fondaparinux; HR, 0.83; 95% CI, 0.73-0.94; P = .003, and at study end (857 [14.8%] placebo vs 756 [13.4%] fondaparinux; HR, 0.88; 95% CI, 0.79-0.97; P = .008). Mortality was significantly reduced throughout the study. There was no heterogeneity of the effects of fondaparinux in the 2 strata by planned heparin use. However, there was no benefit in those undergoing primary percutaneous coronary intervention. In other patients in stratum 2, fondaparinux was superior to unfractionated heparin in preventing death or reinfarction at 30 days (HR, 0.82; 95% CI, 0.66-1.02; P = .08) and at study end (HR, 0.77; 95% CI, 0.64-0.93; P = .008). Significant benefits were observed in those receiving thrombolytic therapy (HR, 0.79; P = .003) and those not receiving any reperfusion therapy (HR, 0.80; P = .03). There was a tendency to fewer severe bleeds (79 for placebo vs 61 for fondaparinux; P = .13), with significantly fewer cardiac tamponade (48 vs 28; P = .02) with fondaparinux at 9 days.In patients with STEMI, particularly those not undergoing primary percutaneous coronary intervention, fondaparinux significantly reduces mortality and reinfarction without increasing bleeding and strokes.ClinicalTrials.gov Identifier NCT00064428.","Effects of fondaparinux on mortality and reinfarction in patients with acute ST-segment elevation myocardial infarction: the OASIS-6 randomized trial."
"670","JAMA.3431","0.08",16537725,2006,"Despite many therapeutic advances, mortality in patients with acute ST-segment elevation myocardial infarction (STEMI) remains high. The role of additional antithrombotic agents is unclear, especially among patients not receiving reperfusion therapy.To evaluate the effect of fondaparinux, a factor Xa inhibitor, when initiated early and given for up to 8 days vs usual care (placebo in those in whom unfractionated heparin [UFH] is not indicated [stratum 1] or unfractionated heparin for up to 48 hours followed by placebo for up to 8 days [stratum 2]) in patients with STEMI.Randomized double-blind comparison of fondaparinux 2.5 mg once daily or control for up to 8 days in 12,092 patients with STEMI from 447 hospitals in 41 countries (September 2003-January 2006). From day 3 through day 9, all patients received either fondaparinux or placebo according to the original randomized assignment.Composite of death or reinfarction at 30 days (primary) with secondary assessments at 9 days and at final follow-up (3 or 6 months).Death or reinfarction at 30 days was significantly reduced from 677 (11.2%) of 6056 patients in the control group to 585 (9.7%) of 6036 patients in the fondaparinux group (hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.77-0.96; P = .008); absolute risk reduction, 1.5%; 95% CI, 0.4%-2.6%). These benefits were observed at 9 days (537 [8.9%] placebo vs 444 [7.4%] fondaparinux; HR, 0.83; 95% CI, 0.73-0.94; P = .003, and at study end (857 [14.8%] placebo vs 756 [13.4%] fondaparinux; HR, 0.88; 95% CI, 0.79-0.97; P = .008). Mortality was significantly reduced throughout the study. There was no heterogeneity of the effects of fondaparinux in the 2 strata by planned heparin use. However, there was no benefit in those undergoing primary percutaneous coronary intervention. In other patients in stratum 2, fondaparinux was superior to unfractionated heparin in preventing death or reinfarction at 30 days (HR, 0.82; 95% CI, 0.66-1.02; P = .08) and at study end (HR, 0.77; 95% CI, 0.64-0.93; P = .008). Significant benefits were observed in those receiving thrombolytic therapy (HR, 0.79; P = .003) and those not receiving any reperfusion therapy (HR, 0.80; P = .03). There was a tendency to fewer severe bleeds (79 for placebo vs 61 for fondaparinux; P = .13), with significantly fewer cardiac tamponade (48 vs 28; P = .02) with fondaparinux at 9 days.In patients with STEMI, particularly those not undergoing primary percutaneous coronary intervention, fondaparinux significantly reduces mortality and reinfarction without increasing bleeding and strokes.ClinicalTrials.gov Identifier NCT00064428.","Effects of fondaparinux on mortality and reinfarction in patients with acute ST-segment elevation myocardial infarction: the OASIS-6 randomized trial."
"671","JAMA.3441","0.008",16537725,2006,"Despite many therapeutic advances, mortality in patients with acute ST-segment elevation myocardial infarction (STEMI) remains high. The role of additional antithrombotic agents is unclear, especially among patients not receiving reperfusion therapy.To evaluate the effect of fondaparinux, a factor Xa inhibitor, when initiated early and given for up to 8 days vs usual care (placebo in those in whom unfractionated heparin [UFH] is not indicated [stratum 1] or unfractionated heparin for up to 48 hours followed by placebo for up to 8 days [stratum 2]) in patients with STEMI.Randomized double-blind comparison of fondaparinux 2.5 mg once daily or control for up to 8 days in 12,092 patients with STEMI from 447 hospitals in 41 countries (September 2003-January 2006). From day 3 through day 9, all patients received either fondaparinux or placebo according to the original randomized assignment.Composite of death or reinfarction at 30 days (primary) with secondary assessments at 9 days and at final follow-up (3 or 6 months).Death or reinfarction at 30 days was significantly reduced from 677 (11.2%) of 6056 patients in the control group to 585 (9.7%) of 6036 patients in the fondaparinux group (hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.77-0.96; P = .008); absolute risk reduction, 1.5%; 95% CI, 0.4%-2.6%). These benefits were observed at 9 days (537 [8.9%] placebo vs 444 [7.4%] fondaparinux; HR, 0.83; 95% CI, 0.73-0.94; P = .003, and at study end (857 [14.8%] placebo vs 756 [13.4%] fondaparinux; HR, 0.88; 95% CI, 0.79-0.97; P = .008). Mortality was significantly reduced throughout the study. There was no heterogeneity of the effects of fondaparinux in the 2 strata by planned heparin use. However, there was no benefit in those undergoing primary percutaneous coronary intervention. In other patients in stratum 2, fondaparinux was superior to unfractionated heparin in preventing death or reinfarction at 30 days (HR, 0.82; 95% CI, 0.66-1.02; P = .08) and at study end (HR, 0.77; 95% CI, 0.64-0.93; P = .008). Significant benefits were observed in those receiving thrombolytic therapy (HR, 0.79; P = .003) and those not receiving any reperfusion therapy (HR, 0.80; P = .03). There was a tendency to fewer severe bleeds (79 for placebo vs 61 for fondaparinux; P = .13), with significantly fewer cardiac tamponade (48 vs 28; P = .02) with fondaparinux at 9 days.In patients with STEMI, particularly those not undergoing primary percutaneous coronary intervention, fondaparinux significantly reduces mortality and reinfarction without increasing bleeding and strokes.ClinicalTrials.gov Identifier NCT00064428.","Effects of fondaparinux on mortality and reinfarction in patients with acute ST-segment elevation myocardial infarction: the OASIS-6 randomized trial."
"672","JAMA.3451","0.003",16537725,2006,"Despite many therapeutic advances, mortality in patients with acute ST-segment elevation myocardial infarction (STEMI) remains high. The role of additional antithrombotic agents is unclear, especially among patients not receiving reperfusion therapy.To evaluate the effect of fondaparinux, a factor Xa inhibitor, when initiated early and given for up to 8 days vs usual care (placebo in those in whom unfractionated heparin [UFH] is not indicated [stratum 1] or unfractionated heparin for up to 48 hours followed by placebo for up to 8 days [stratum 2]) in patients with STEMI.Randomized double-blind comparison of fondaparinux 2.5 mg once daily or control for up to 8 days in 12,092 patients with STEMI from 447 hospitals in 41 countries (September 2003-January 2006). From day 3 through day 9, all patients received either fondaparinux or placebo according to the original randomized assignment.Composite of death or reinfarction at 30 days (primary) with secondary assessments at 9 days and at final follow-up (3 or 6 months).Death or reinfarction at 30 days was significantly reduced from 677 (11.2%) of 6056 patients in the control group to 585 (9.7%) of 6036 patients in the fondaparinux group (hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.77-0.96; P = .008); absolute risk reduction, 1.5%; 95% CI, 0.4%-2.6%). These benefits were observed at 9 days (537 [8.9%] placebo vs 444 [7.4%] fondaparinux; HR, 0.83; 95% CI, 0.73-0.94; P = .003, and at study end (857 [14.8%] placebo vs 756 [13.4%] fondaparinux; HR, 0.88; 95% CI, 0.79-0.97; P = .008). Mortality was significantly reduced throughout the study. There was no heterogeneity of the effects of fondaparinux in the 2 strata by planned heparin use. However, there was no benefit in those undergoing primary percutaneous coronary intervention. In other patients in stratum 2, fondaparinux was superior to unfractionated heparin in preventing death or reinfarction at 30 days (HR, 0.82; 95% CI, 0.66-1.02; P = .08) and at study end (HR, 0.77; 95% CI, 0.64-0.93; P = .008). Significant benefits were observed in those receiving thrombolytic therapy (HR, 0.79; P = .003) and those not receiving any reperfusion therapy (HR, 0.80; P = .03). There was a tendency to fewer severe bleeds (79 for placebo vs 61 for fondaparinux; P = .13), with significantly fewer cardiac tamponade (48 vs 28; P = .02) with fondaparinux at 9 days.In patients with STEMI, particularly those not undergoing primary percutaneous coronary intervention, fondaparinux significantly reduces mortality and reinfarction without increasing bleeding and strokes.ClinicalTrials.gov Identifier NCT00064428.","Effects of fondaparinux on mortality and reinfarction in patients with acute ST-segment elevation myocardial infarction: the OASIS-6 randomized trial."
"673","JAMA.3461","0.03",16537725,2006,"Despite many therapeutic advances, mortality in patients with acute ST-segment elevation myocardial infarction (STEMI) remains high. The role of additional antithrombotic agents is unclear, especially among patients not receiving reperfusion therapy.To evaluate the effect of fondaparinux, a factor Xa inhibitor, when initiated early and given for up to 8 days vs usual care (placebo in those in whom unfractionated heparin [UFH] is not indicated [stratum 1] or unfractionated heparin for up to 48 hours followed by placebo for up to 8 days [stratum 2]) in patients with STEMI.Randomized double-blind comparison of fondaparinux 2.5 mg once daily or control for up to 8 days in 12,092 patients with STEMI from 447 hospitals in 41 countries (September 2003-January 2006). From day 3 through day 9, all patients received either fondaparinux or placebo according to the original randomized assignment.Composite of death or reinfarction at 30 days (primary) with secondary assessments at 9 days and at final follow-up (3 or 6 months).Death or reinfarction at 30 days was significantly reduced from 677 (11.2%) of 6056 patients in the control group to 585 (9.7%) of 6036 patients in the fondaparinux group (hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.77-0.96; P = .008); absolute risk reduction, 1.5%; 95% CI, 0.4%-2.6%). These benefits were observed at 9 days (537 [8.9%] placebo vs 444 [7.4%] fondaparinux; HR, 0.83; 95% CI, 0.73-0.94; P = .003, and at study end (857 [14.8%] placebo vs 756 [13.4%] fondaparinux; HR, 0.88; 95% CI, 0.79-0.97; P = .008). Mortality was significantly reduced throughout the study. There was no heterogeneity of the effects of fondaparinux in the 2 strata by planned heparin use. However, there was no benefit in those undergoing primary percutaneous coronary intervention. In other patients in stratum 2, fondaparinux was superior to unfractionated heparin in preventing death or reinfarction at 30 days (HR, 0.82; 95% CI, 0.66-1.02; P = .08) and at study end (HR, 0.77; 95% CI, 0.64-0.93; P = .008). Significant benefits were observed in those receiving thrombolytic therapy (HR, 0.79; P = .003) and those not receiving any reperfusion therapy (HR, 0.80; P = .03). There was a tendency to fewer severe bleeds (79 for placebo vs 61 for fondaparinux; P = .13), with significantly fewer cardiac tamponade (48 vs 28; P = .02) with fondaparinux at 9 days.In patients with STEMI, particularly those not undergoing primary percutaneous coronary intervention, fondaparinux significantly reduces mortality and reinfarction without increasing bleeding and strokes.ClinicalTrials.gov Identifier NCT00064428.","Effects of fondaparinux on mortality and reinfarction in patients with acute ST-segment elevation myocardial infarction: the OASIS-6 randomized trial."
"674","JAMA.3381","0.09",16609086,2006,"The Women's Health Initiative Estrogen-Aone trial comparing conjugated equine estrogens (CEE) with placebo was stopped early because of an increased stroke incidence and no reduction in risk of coronary heart disease. Preliminary results suggesting possible reduction in breast cancers warranted more detailed analysis.To determine the effects of CEE on breast cancers and mammographic findings.Following breast cancer risk assessment, 10,739 postmenopausal women aged 50 to 79 years with prior hysterectomy were randomized to CEE or placebo at 40 US clinical centers from 1993 through 1998. Mammography screenings and clinical breast examinations were performed at baseline and annually. All breast cancers diagnosed through February 29, 2004, are included.A dose of 0.625 mg/d of CEE or an identical-appearing placebo.Breast cancer incidence, tumor characteristics, and mammogram findings.After a mean (SD) follow-up of 7.1 (1.6) years, the invasive breast cancer hazard ratio (HR) for women assigned to CEE vs placebo was 0.80 (95% confidence interval [CI], 0.62-1.04; P = .09) with annualized rates of 0.28% (104 cases in the CEE group) and 0.34% (133 cases in the placebo group). In exploratory analyses, ductal carcinomas (HR, 0.71; 95% CI, 0.52-0.99) were reduced in the CEE group vs placebo group; however, the test for interaction by tumor type was not significant (P = .054). At 1 year, 9.2% of women in the CEE group had mammograms with abnormalities requiring follow-up vs 5.5% in the placebo group (P<.001), a pattern that continued through the trial to reach a cumulative percentage of 36.2% vs 28.1%, respectively (P<.001); however, this difference was primarily in assessments requiring short interval follow-up.Treatment with CEE alone for 7.1 years does not increase breast cancer incidence in postmenopausal women with prior hysterectomy. However, treatment with CEE increases the frequency of mammography screening requiring short interval follow-up. Initiation of CEE should be based on consideration of the individual woman's potential risks and benefits.clinicaltrials.gov Identifier: NCT00000611.","Effects of conjugated equine estrogens on breast cancer and mammography screening in postmenopausal women with hysterectomy."
"675","JAMA.3191","0.001",16670410,2006,"Aerobic fitness, an important predictor of cardiovascular disease and mortality, is difficult to assess by maximal exercise testing in older adults. Extended walking tests have been examined as outcome predictors in medically ill populations but not in community-dwelling older adults.To determine whether an extended walking test predicts poor outcomes in older adults.Observational cohort study enrolling 3075 community-dwelling adults aged 70 to 79 years living in Pittsburgh, Pa, or Memphis, Tenn. Of those participating in the Health, Aging, and Body Composition Study, 1584 (52%) were women and 1281 (42%) were black. Participants enrolled from March 1997 to April 1998. Ability to complete the long-distance corridor walk and total performance time was assessed at the baseline examination.Total mortality, incident cardiovascular disease, incident mobility limitation, and mobility disability were ascertained after a mean (SD) of 4.9 (0.9) years.Among patients eligible to exercise, 351 died, 308 had episodes of incident cardiovascular disease, 1116 had occurrences of mobility limitation, and 509 had occurrences of mobility disability. Inability to complete walking 400 m tended to be associated with a higher risk of mortality and incident cardiovascular disease and, after accounting for potential confounders, was associated with incident mobility limitation (212.6 vs 79.1 events/1000 person-years; adjusted hazard ratio [HR], 1.86; 95% confidence interval [CI], 1.58-2.18; P<.001) and mobility disability (85.2 vs 28.8 events/1000 person-years; adjusted HR, 1.95; 95% CI, 1.56-2.44; P<.001). Of those who completed 400 m, each additional minute of performance time was associated with an adjusted HR of 1.29 (95% CI, 1.12-1.48) for mortality, 1.20 (95% CI, 1.01-1.42) for incident cardiovascular disease, 1.52 (95% CI, 1.41-1.63) for mobility limitation, and 1.52 (95% CI, 1.37-1.70) for disability after adjustment for demographics, health behaviors, clinical and subclinical disease, and cardiovascular disease risk factors. Findings were consistent in both men and women and blacks and whites. Among participants who completed the test and after adjusting for potential confounders, those in the poorest quartile of functional capacity (walk time >362 seconds) had a higher risk of death than those in the best quartile (walk time <290 seconds; adjusted HR, 3.23; 95% CI, 2.11-4.94; P<.001).Older adults in the community who reported no difficulty walking had a wide range of performance on this extended walking test. Ability to do the test and performance were important prognostic factors for total mortality, cardiovascular disease, mobility limitation, and mobility disability in persons in their eighth decade.","Association of long-distance corridor walk performance with mortality, cardiovascular disease, mobility limitation, and disability."
"676","JAMA.3201","0.001",16670410,2006,"Aerobic fitness, an important predictor of cardiovascular disease and mortality, is difficult to assess by maximal exercise testing in older adults. Extended walking tests have been examined as outcome predictors in medically ill populations but not in community-dwelling older adults.To determine whether an extended walking test predicts poor outcomes in older adults.Observational cohort study enrolling 3075 community-dwelling adults aged 70 to 79 years living in Pittsburgh, Pa, or Memphis, Tenn. Of those participating in the Health, Aging, and Body Composition Study, 1584 (52%) were women and 1281 (42%) were black. Participants enrolled from March 1997 to April 1998. Ability to complete the long-distance corridor walk and total performance time was assessed at the baseline examination.Total mortality, incident cardiovascular disease, incident mobility limitation, and mobility disability were ascertained after a mean (SD) of 4.9 (0.9) years.Among patients eligible to exercise, 351 died, 308 had episodes of incident cardiovascular disease, 1116 had occurrences of mobility limitation, and 509 had occurrences of mobility disability. Inability to complete walking 400 m tended to be associated with a higher risk of mortality and incident cardiovascular disease and, after accounting for potential confounders, was associated with incident mobility limitation (212.6 vs 79.1 events/1000 person-years; adjusted hazard ratio [HR], 1.86; 95% confidence interval [CI], 1.58-2.18; P<.001) and mobility disability (85.2 vs 28.8 events/1000 person-years; adjusted HR, 1.95; 95% CI, 1.56-2.44; P<.001). Of those who completed 400 m, each additional minute of performance time was associated with an adjusted HR of 1.29 (95% CI, 1.12-1.48) for mortality, 1.20 (95% CI, 1.01-1.42) for incident cardiovascular disease, 1.52 (95% CI, 1.41-1.63) for mobility limitation, and 1.52 (95% CI, 1.37-1.70) for disability after adjustment for demographics, health behaviors, clinical and subclinical disease, and cardiovascular disease risk factors. Findings were consistent in both men and women and blacks and whites. Among participants who completed the test and after adjusting for potential confounders, those in the poorest quartile of functional capacity (walk time >362 seconds) had a higher risk of death than those in the best quartile (walk time <290 seconds; adjusted HR, 3.23; 95% CI, 2.11-4.94; P<.001).Older adults in the community who reported no difficulty walking had a wide range of performance on this extended walking test. Ability to do the test and performance were important prognostic factors for total mortality, cardiovascular disease, mobility limitation, and mobility disability in persons in their eighth decade.","Association of long-distance corridor walk performance with mortality, cardiovascular disease, mobility limitation, and disability."
"677","JAMA.3208","0.001",16670410,2006,"Aerobic fitness, an important predictor of cardiovascular disease and mortality, is difficult to assess by maximal exercise testing in older adults. Extended walking tests have been examined as outcome predictors in medically ill populations but not in community-dwelling older adults.To determine whether an extended walking test predicts poor outcomes in older adults.Observational cohort study enrolling 3075 community-dwelling adults aged 70 to 79 years living in Pittsburgh, Pa, or Memphis, Tenn. Of those participating in the Health, Aging, and Body Composition Study, 1584 (52%) were women and 1281 (42%) were black. Participants enrolled from March 1997 to April 1998. Ability to complete the long-distance corridor walk and total performance time was assessed at the baseline examination.Total mortality, incident cardiovascular disease, incident mobility limitation, and mobility disability were ascertained after a mean (SD) of 4.9 (0.9) years.Among patients eligible to exercise, 351 died, 308 had episodes of incident cardiovascular disease, 1116 had occurrences of mobility limitation, and 509 had occurrences of mobility disability. Inability to complete walking 400 m tended to be associated with a higher risk of mortality and incident cardiovascular disease and, after accounting for potential confounders, was associated with incident mobility limitation (212.6 vs 79.1 events/1000 person-years; adjusted hazard ratio [HR], 1.86; 95% confidence interval [CI], 1.58-2.18; P<.001) and mobility disability (85.2 vs 28.8 events/1000 person-years; adjusted HR, 1.95; 95% CI, 1.56-2.44; P<.001). Of those who completed 400 m, each additional minute of performance time was associated with an adjusted HR of 1.29 (95% CI, 1.12-1.48) for mortality, 1.20 (95% CI, 1.01-1.42) for incident cardiovascular disease, 1.52 (95% CI, 1.41-1.63) for mobility limitation, and 1.52 (95% CI, 1.37-1.70) for disability after adjustment for demographics, health behaviors, clinical and subclinical disease, and cardiovascular disease risk factors. Findings were consistent in both men and women and blacks and whites. Among participants who completed the test and after adjusting for potential confounders, those in the poorest quartile of functional capacity (walk time >362 seconds) had a higher risk of death than those in the best quartile (walk time <290 seconds; adjusted HR, 3.23; 95% CI, 2.11-4.94; P<.001).Older adults in the community who reported no difficulty walking had a wide range of performance on this extended walking test. Ability to do the test and performance were important prognostic factors for total mortality, cardiovascular disease, mobility limitation, and mobility disability in persons in their eighth decade.","Association of long-distance corridor walk performance with mortality, cardiovascular disease, mobility limitation, and disability."
"678","JAMA.3209","NA",16670410,2006,"Aerobic fitness, an important predictor of cardiovascular disease and mortality, is difficult to assess by maximal exercise testing in older adults. Extended walking tests have been examined as outcome predictors in medically ill populations but not in community-dwelling older adults.To determine whether an extended walking test predicts poor outcomes in older adults.Observational cohort study enrolling 3075 community-dwelling adults aged 70 to 79 years living in Pittsburgh, Pa, or Memphis, Tenn. Of those participating in the Health, Aging, and Body Composition Study, 1584 (52%) were women and 1281 (42%) were black. Participants enrolled from March 1997 to April 1998. Ability to complete the long-distance corridor walk and total performance time was assessed at the baseline examination.Total mortality, incident cardiovascular disease, incident mobility limitation, and mobility disability were ascertained after a mean (SD) of 4.9 (0.9) years.Among patients eligible to exercise, 351 died, 308 had episodes of incident cardiovascular disease, 1116 had occurrences of mobility limitation, and 509 had occurrences of mobility disability. Inability to complete walking 400 m tended to be associated with a higher risk of mortality and incident cardiovascular disease and, after accounting for potential confounders, was associated with incident mobility limitation (212.6 vs 79.1 events/1000 person-years; adjusted hazard ratio [HR], 1.86; 95% confidence interval [CI], 1.58-2.18; P<.001) and mobility disability (85.2 vs 28.8 events/1000 person-years; adjusted HR, 1.95; 95% CI, 1.56-2.44; P<.001). Of those who completed 400 m, each additional minute of performance time was associated with an adjusted HR of 1.29 (95% CI, 1.12-1.48) for mortality, 1.20 (95% CI, 1.01-1.42) for incident cardiovascular disease, 1.52 (95% CI, 1.41-1.63) for mobility limitation, and 1.52 (95% CI, 1.37-1.70) for disability after adjustment for demographics, health behaviors, clinical and subclinical disease, and cardiovascular disease risk factors. Findings were consistent in both men and women and blacks and whites. Among participants who completed the test and after adjusting for potential confounders, those in the poorest quartile of functional capacity (walk time >362 seconds) had a higher risk of death than those in the best quartile (walk time <290 seconds; adjusted HR, 3.23; 95% CI, 2.11-4.94; P<.001).Older adults in the community who reported no difficulty walking had a wide range of performance on this extended walking test. Ability to do the test and performance were important prognostic factors for total mortality, cardiovascular disease, mobility limitation, and mobility disability in persons in their eighth decade.","Association of long-distance corridor walk performance with mortality, cardiovascular disease, mobility limitation, and disability."
"679","JAMA.3210","NA",16670410,2006,"Aerobic fitness, an important predictor of cardiovascular disease and mortality, is difficult to assess by maximal exercise testing in older adults. Extended walking tests have been examined as outcome predictors in medically ill populations but not in community-dwelling older adults.To determine whether an extended walking test predicts poor outcomes in older adults.Observational cohort study enrolling 3075 community-dwelling adults aged 70 to 79 years living in Pittsburgh, Pa, or Memphis, Tenn. Of those participating in the Health, Aging, and Body Composition Study, 1584 (52%) were women and 1281 (42%) were black. Participants enrolled from March 1997 to April 1998. Ability to complete the long-distance corridor walk and total performance time was assessed at the baseline examination.Total mortality, incident cardiovascular disease, incident mobility limitation, and mobility disability were ascertained after a mean (SD) of 4.9 (0.9) years.Among patients eligible to exercise, 351 died, 308 had episodes of incident cardiovascular disease, 1116 had occurrences of mobility limitation, and 509 had occurrences of mobility disability. Inability to complete walking 400 m tended to be associated with a higher risk of mortality and incident cardiovascular disease and, after accounting for potential confounders, was associated with incident mobility limitation (212.6 vs 79.1 events/1000 person-years; adjusted hazard ratio [HR], 1.86; 95% confidence interval [CI], 1.58-2.18; P<.001) and mobility disability (85.2 vs 28.8 events/1000 person-years; adjusted HR, 1.95; 95% CI, 1.56-2.44; P<.001). Of those who completed 400 m, each additional minute of performance time was associated with an adjusted HR of 1.29 (95% CI, 1.12-1.48) for mortality, 1.20 (95% CI, 1.01-1.42) for incident cardiovascular disease, 1.52 (95% CI, 1.41-1.63) for mobility limitation, and 1.52 (95% CI, 1.37-1.70) for disability after adjustment for demographics, health behaviors, clinical and subclinical disease, and cardiovascular disease risk factors. Findings were consistent in both men and women and blacks and whites. Among participants who completed the test and after adjusting for potential confounders, those in the poorest quartile of functional capacity (walk time >362 seconds) had a higher risk of death than those in the best quartile (walk time <290 seconds; adjusted HR, 3.23; 95% CI, 2.11-4.94; P<.001).Older adults in the community who reported no difficulty walking had a wide range of performance on this extended walking test. Ability to do the test and performance were important prognostic factors for total mortality, cardiovascular disease, mobility limitation, and mobility disability in persons in their eighth decade.","Association of long-distance corridor walk performance with mortality, cardiovascular disease, mobility limitation, and disability."
"680","JAMA.3211","NA",16670410,2006,"Aerobic fitness, an important predictor of cardiovascular disease and mortality, is difficult to assess by maximal exercise testing in older adults. Extended walking tests have been examined as outcome predictors in medically ill populations but not in community-dwelling older adults.To determine whether an extended walking test predicts poor outcomes in older adults.Observational cohort study enrolling 3075 community-dwelling adults aged 70 to 79 years living in Pittsburgh, Pa, or Memphis, Tenn. Of those participating in the Health, Aging, and Body Composition Study, 1584 (52%) were women and 1281 (42%) were black. Participants enrolled from March 1997 to April 1998. Ability to complete the long-distance corridor walk and total performance time was assessed at the baseline examination.Total mortality, incident cardiovascular disease, incident mobility limitation, and mobility disability were ascertained after a mean (SD) of 4.9 (0.9) years.Among patients eligible to exercise, 351 died, 308 had episodes of incident cardiovascular disease, 1116 had occurrences of mobility limitation, and 509 had occurrences of mobility disability. Inability to complete walking 400 m tended to be associated with a higher risk of mortality and incident cardiovascular disease and, after accounting for potential confounders, was associated with incident mobility limitation (212.6 vs 79.1 events/1000 person-years; adjusted hazard ratio [HR], 1.86; 95% confidence interval [CI], 1.58-2.18; P<.001) and mobility disability (85.2 vs 28.8 events/1000 person-years; adjusted HR, 1.95; 95% CI, 1.56-2.44; P<.001). Of those who completed 400 m, each additional minute of performance time was associated with an adjusted HR of 1.29 (95% CI, 1.12-1.48) for mortality, 1.20 (95% CI, 1.01-1.42) for incident cardiovascular disease, 1.52 (95% CI, 1.41-1.63) for mobility limitation, and 1.52 (95% CI, 1.37-1.70) for disability after adjustment for demographics, health behaviors, clinical and subclinical disease, and cardiovascular disease risk factors. Findings were consistent in both men and women and blacks and whites. Among participants who completed the test and after adjusting for potential confounders, those in the poorest quartile of functional capacity (walk time >362 seconds) had a higher risk of death than those in the best quartile (walk time <290 seconds; adjusted HR, 3.23; 95% CI, 2.11-4.94; P<.001).Older adults in the community who reported no difficulty walking had a wide range of performance on this extended walking test. Ability to do the test and performance were important prognostic factors for total mortality, cardiovascular disease, mobility limitation, and mobility disability in persons in their eighth decade.","Association of long-distance corridor walk performance with mortality, cardiovascular disease, mobility limitation, and disability."
"681","JAMA.3211","NA",16670410,2006,"Aerobic fitness, an important predictor of cardiovascular disease and mortality, is difficult to assess by maximal exercise testing in older adults. Extended walking tests have been examined as outcome predictors in medically ill populations but not in community-dwelling older adults.To determine whether an extended walking test predicts poor outcomes in older adults.Observational cohort study enrolling 3075 community-dwelling adults aged 70 to 79 years living in Pittsburgh, Pa, or Memphis, Tenn. Of those participating in the Health, Aging, and Body Composition Study, 1584 (52%) were women and 1281 (42%) were black. Participants enrolled from March 1997 to April 1998. Ability to complete the long-distance corridor walk and total performance time was assessed at the baseline examination.Total mortality, incident cardiovascular disease, incident mobility limitation, and mobility disability were ascertained after a mean (SD) of 4.9 (0.9) years.Among patients eligible to exercise, 351 died, 308 had episodes of incident cardiovascular disease, 1116 had occurrences of mobility limitation, and 509 had occurrences of mobility disability. Inability to complete walking 400 m tended to be associated with a higher risk of mortality and incident cardiovascular disease and, after accounting for potential confounders, was associated with incident mobility limitation (212.6 vs 79.1 events/1000 person-years; adjusted hazard ratio [HR], 1.86; 95% confidence interval [CI], 1.58-2.18; P<.001) and mobility disability (85.2 vs 28.8 events/1000 person-years; adjusted HR, 1.95; 95% CI, 1.56-2.44; P<.001). Of those who completed 400 m, each additional minute of performance time was associated with an adjusted HR of 1.29 (95% CI, 1.12-1.48) for mortality, 1.20 (95% CI, 1.01-1.42) for incident cardiovascular disease, 1.52 (95% CI, 1.41-1.63) for mobility limitation, and 1.52 (95% CI, 1.37-1.70) for disability after adjustment for demographics, health behaviors, clinical and subclinical disease, and cardiovascular disease risk factors. Findings were consistent in both men and women and blacks and whites. Among participants who completed the test and after adjusting for potential confounders, those in the poorest quartile of functional capacity (walk time >362 seconds) had a higher risk of death than those in the best quartile (walk time <290 seconds; adjusted HR, 3.23; 95% CI, 2.11-4.94; P<.001).Older adults in the community who reported no difficulty walking had a wide range of performance on this extended walking test. Ability to do the test and performance were important prognostic factors for total mortality, cardiovascular disease, mobility limitation, and mobility disability in persons in their eighth decade.","Association of long-distance corridor walk performance with mortality, cardiovascular disease, mobility limitation, and disability."
"682","JAMA.3361","0.03",16757723,2006,"Cardiogenic shock remains the major cause of death for patients hospitalized with acute myocardial infarction (MI). Although survival in patients with cardiogenic shock complicating acute MI has been shown to be significantly higher at 1 year in those receiving early revascularization vs initial medical stabilization, data demonstrating long-term survival are lacking.To determine if early revascularization affects long-term survival of patients with cardiogenic shock complicating acute MI.The Should We Emergently Revascularize Occluded Coronaries for Cardiogenic Shock (SHOCK) trial, an international randomized clinical trial enrolling 302 patients from April 1993 through November 1998 with acute myocardial infarction complicated by cardiogenic shock (mean [SD] age at randomization, 66 [11] years); long-term follow-up of vital status, conducted annually until 2005, ranged from 1 to 11 years (median for survivors, 6 years).All-cause mortality during long-term follow-up.The group difference in survival of 13 absolute percentage points at 1 year favoring those assigned to early revascularization remained stable at 3 and 6 years (13.1% and 13.2%, respectively; hazard ratio [HR], 0.74; 95% confidence interval [CI], 0.57-0.97; log-rank P = .03). At 6 years, overall survival rates were 32.8% and 19.6% in the early revascularization and initial medical stabilization groups, respectively. Among the 143 hospital survivors, a group difference in survival also was observed (HR, 0.59; 95% CI, 0.36-0.95; P = .03). The 6-year survival rates for the hospital survivors were 62.4% vs 44.4% for the early revascularization and initial medical stabilization groups, respectively, with annualized death rates of 8.3% vs 14.3% and, for the 1-year survivors, 8.0% vs 10.7%. There was no significant interaction between any subgroup and treatment effect.In this randomized trial, almost two thirds of hospital survivors with cardiogenic shock who were treated with early revascularization were alive 6 years later. A strategy of early revascularization resulted in a 13.2% absolute and a 67% relative improvement in 6-year survival compared with initial medical stabilization. Early revascularization should be used for patients with acute MI complicated by cardiogenic shock due to left ventricular failure.clinicaltrials.gov Identifier: NCT00000552.","Early revascularization and long-term survival in cardiogenic shock complicating acute myocardial infarction."
"683","JAMA.3371","0.03",16757723,2006,"Cardiogenic shock remains the major cause of death for patients hospitalized with acute myocardial infarction (MI). Although survival in patients with cardiogenic shock complicating acute MI has been shown to be significantly higher at 1 year in those receiving early revascularization vs initial medical stabilization, data demonstrating long-term survival are lacking.To determine if early revascularization affects long-term survival of patients with cardiogenic shock complicating acute MI.The Should We Emergently Revascularize Occluded Coronaries for Cardiogenic Shock (SHOCK) trial, an international randomized clinical trial enrolling 302 patients from April 1993 through November 1998 with acute myocardial infarction complicated by cardiogenic shock (mean [SD] age at randomization, 66 [11] years); long-term follow-up of vital status, conducted annually until 2005, ranged from 1 to 11 years (median for survivors, 6 years).All-cause mortality during long-term follow-up.The group difference in survival of 13 absolute percentage points at 1 year favoring those assigned to early revascularization remained stable at 3 and 6 years (13.1% and 13.2%, respectively; hazard ratio [HR], 0.74; 95% confidence interval [CI], 0.57-0.97; log-rank P = .03). At 6 years, overall survival rates were 32.8% and 19.6% in the early revascularization and initial medical stabilization groups, respectively. Among the 143 hospital survivors, a group difference in survival also was observed (HR, 0.59; 95% CI, 0.36-0.95; P = .03). The 6-year survival rates for the hospital survivors were 62.4% vs 44.4% for the early revascularization and initial medical stabilization groups, respectively, with annualized death rates of 8.3% vs 14.3% and, for the 1-year survivors, 8.0% vs 10.7%. There was no significant interaction between any subgroup and treatment effect.In this randomized trial, almost two thirds of hospital survivors with cardiogenic shock who were treated with early revascularization were alive 6 years later. A strategy of early revascularization resulted in a 13.2% absolute and a 67% relative improvement in 6-year survival compared with initial medical stabilization. Early revascularization should be used for patients with acute MI complicated by cardiogenic shock due to left ventricular failure.clinicaltrials.gov Identifier: NCT00000552.","Early revascularization and long-term survival in cardiogenic shock complicating acute myocardial infarction."
"684","JAMA.3350","0.33",16772624,2006,"Very-long-chain n-3 polyunsaturated fatty acids (omega-3 PUFAs) from fish are thought to reduce risk of sudden death, possibly by reducing susceptibility to cardiac arrhythmia.To study the effect of supplemental fish oil vs placebo on ventricular tachyarrhythmia or death.The Study on Omega-3 Fatty acids and ventricular Arrhythmia (SOFA) was a randomized, parallel, placebo-controlled, double-blind trial conducted at 26 cardiology clinics across Europe. A total of 546 patients with implantable cardioverter-defibrillators (ICDs) and prior documented malignant ventricular tachycardia (VT) or ventricular fibrillation (VF) were enrolled between October 2001 and August 2004. Patients were randomly assigned to receive 2 g/d of fish oil (n = 273) or placebo (n = 273) for a median period of 356 days (range, 14-379 days).Appropriate ICD intervention for VT or VF, or all-cause death.The primary end point occurred in 81 (30%) patients taking fish oil vs 90 (33%) patients taking placebo (hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.64-1.16; P = .33). In prespecified subgroup analyses, the HR was 0.91 (95% CI, 0.66-1.26) for fish oil vs placebo in the 411 patients who had experienced VT in the year before the study, and 0.76 (95% CI, 0.52-1.11) for 332 patients with prior myocardial infarctions.Our findings do not indicate evidence of a strong protective effect of intake of omega-3 PUFAs from fish oil against ventricular arrhythmia in patients with ICDs.clinicaltrials.gov Identifier: NCT00110838.","Effect of fish oil on ventricular tachyarrhythmia and death in patients with implantable cardioverter defibrillators: the Study on Omega-3 Fatty Acids and Ventricular Arrhythmia (SOFA) randomized trial."
"685","JAMA.3351","NA",16772624,2006,"Very-long-chain n-3 polyunsaturated fatty acids (omega-3 PUFAs) from fish are thought to reduce risk of sudden death, possibly by reducing susceptibility to cardiac arrhythmia.To study the effect of supplemental fish oil vs placebo on ventricular tachyarrhythmia or death.The Study on Omega-3 Fatty acids and ventricular Arrhythmia (SOFA) was a randomized, parallel, placebo-controlled, double-blind trial conducted at 26 cardiology clinics across Europe. A total of 546 patients with implantable cardioverter-defibrillators (ICDs) and prior documented malignant ventricular tachycardia (VT) or ventricular fibrillation (VF) were enrolled between October 2001 and August 2004. Patients were randomly assigned to receive 2 g/d of fish oil (n = 273) or placebo (n = 273) for a median period of 356 days (range, 14-379 days).Appropriate ICD intervention for VT or VF, or all-cause death.The primary end point occurred in 81 (30%) patients taking fish oil vs 90 (33%) patients taking placebo (hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.64-1.16; P = .33). In prespecified subgroup analyses, the HR was 0.91 (95% CI, 0.66-1.26) for fish oil vs placebo in the 411 patients who had experienced VT in the year before the study, and 0.76 (95% CI, 0.52-1.11) for 332 patients with prior myocardial infarctions.Our findings do not indicate evidence of a strong protective effect of intake of omega-3 PUFAs from fish oil against ventricular arrhythmia in patients with ICDs.clinicaltrials.gov Identifier: NCT00110838.","Effect of fish oil on ventricular tachyarrhythmia and death in patients with implantable cardioverter defibrillators: the Study on Omega-3 Fatty Acids and Ventricular Arrhythmia (SOFA) randomized trial."
"686","JAMA.3351","NA",16772624,2006,"Very-long-chain n-3 polyunsaturated fatty acids (omega-3 PUFAs) from fish are thought to reduce risk of sudden death, possibly by reducing susceptibility to cardiac arrhythmia.To study the effect of supplemental fish oil vs placebo on ventricular tachyarrhythmia or death.The Study on Omega-3 Fatty acids and ventricular Arrhythmia (SOFA) was a randomized, parallel, placebo-controlled, double-blind trial conducted at 26 cardiology clinics across Europe. A total of 546 patients with implantable cardioverter-defibrillators (ICDs) and prior documented malignant ventricular tachycardia (VT) or ventricular fibrillation (VF) were enrolled between October 2001 and August 2004. Patients were randomly assigned to receive 2 g/d of fish oil (n = 273) or placebo (n = 273) for a median period of 356 days (range, 14-379 days).Appropriate ICD intervention for VT or VF, or all-cause death.The primary end point occurred in 81 (30%) patients taking fish oil vs 90 (33%) patients taking placebo (hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.64-1.16; P = .33). In prespecified subgroup analyses, the HR was 0.91 (95% CI, 0.66-1.26) for fish oil vs placebo in the 411 patients who had experienced VT in the year before the study, and 0.76 (95% CI, 0.52-1.11) for 332 patients with prior myocardial infarctions.Our findings do not indicate evidence of a strong protective effect of intake of omega-3 PUFAs from fish oil against ventricular arrhythmia in patients with ICDs.clinicaltrials.gov Identifier: NCT00110838.","Effect of fish oil on ventricular tachyarrhythmia and death in patients with implantable cardioverter defibrillators: the Study on Omega-3 Fatty Acids and Ventricular Arrhythmia (SOFA) randomized trial."
"687","Lancet.42","NA",16798389,2006,"The presence of pathological Q waves in the infarct leads on the surface electrocardiogram in an ST-elevation acute myocardial infarction indicates myocardial necrosis. Clinically it might be difficult to ascertain the onset of acute myocardial infarction. Our aim was to assess whether the presence or absence of Q waves at presentation could be used as an indicator of the duration of acute myocardial infarction and predict mortality.15,222 patients with ST-elevation acute myocardial infarction and normal intraventricular conduction were randomly assigned streptokinase and aspirin plus bivalirudin or unfractionated heparin in the HERO-2 trial; randomisation did not alter 30-day mortality. 10,244 patients (67%) had Q waves in the infarct territory at the time of randomisation, and 4978 (33%) did not. The primary endpoint was 30-day mortality.There were more deaths at 30 days in patients with initial Q waves than in those without (1044 [10%] vs 344 [7%], p<0.0001). These findings were similar in patients with a first acute myocardial infarction and when stratified by time to randomisation (0-2, >2-4, >4 h) and by acute myocardial infarction location (anterior or inferior). Both the presence of initial Q waves and time to randomisation were positive univariate predictors, but only the presence of initial Q waves independently predicted 30-day mortality on multivariate analysis (adjusted OR 1.44, 95% CI 1.25-1.65 with clinical indices, and 1.31, 1.12-1.54 with clinical plus ST indices included as predictors).The presence of Q waves in the infarct leads at presentation of ST-elevation acute myocardial infarction independently predicts higher 30-day mortality in patients treated with fibrinolytic therapy. Therefore, a more aggressive approach to reperfusion might be warranted in these patients.","Initial Q waves accompanying ST-segment elevation at presentation of acute myocardial infarction and 30-day mortality in patients given streptokinase therapy: an analysis from HERO-2."
"688","JAMA.348","0.001",16820546,2006,"The alpha4beta2 nicotinic acetylcholine receptors (nAChRs) are linked to the reinforcing effects of nicotine and maintaining smoking behavior. Varenicline, a novel alpha4beta2 nAChR partial agonist, may be beneficial for smoking cessation.To assess efficacy and safety of varenicline for smoking cessation compared with sustained-release bupropion (bupropion SR) and placebo.Randomized, double-blind, parallel-group, placebo- and active-treatment-controlled, phase 3 clinical trial conducted at 19 US centers from June 19, 2003, to April 22, 2005. Participants were 1025 generally healthy smokers (> or =10 cigarettes/d) with fewer than 3 months of smoking abstinence in the past year, 18 to 75 years old, recruited via advertising.Participants were randomly assigned in a 1:1:1 ratio to receive brief counseling and varenicline titrated to 1 mg twice per day (n = 352), bupropion SR titrated to 150 mg twice per day (n = 329), or placebo (n = 344) orally for 12 weeks, with 40 weeks of nondrug follow-up.Primary outcome was the exhaled carbon monoxide-confirmed 4-week rate of continuous abstinence from smoking for weeks 9 through 12. A secondary outcome was the continuous abstinence rate for weeks 9 through 24 and weeks 9 through 52.For weeks 9 through 12, the 4-week continuous abstinence rates were 44.0% for varenicline vs 17.7% for placebo (odds ratio [OR], 3.85; 95% confidence interval [CI], 2.70-5.50; P<.001) and vs 29.5% for bupropion SR (OR, 1.93; 95% CI, 1.40-2.68; P<.001). Bupropion SR was also significantly more efficacious than placebo (OR, 2.00; 95% CI, 1.38-2.89; P<.001). For weeks 9 through 52, the continuous abstinence rates were 21.9% for varenicline vs 8.4% for placebo (OR, 3.09; 95% CI, 1.95-4.91; P<.001) and vs 16.1% for bupropion SR (OR, 1.46; 95% CI, 0.99-2.17; P = .057). Varenicline reduced craving and withdrawal and, for those who smoked while receiving study drug, smoking satisfaction. No sex differences in efficacy for varenicline were observed. Varenicline was safe and generally well tolerated, with study drug discontinuation rates similar to those for placebo. The most common adverse events for participants receiving active-drug treatment were nausea (98 participants receiving varenicline [28.1%]) and insomnia (72 receiving bupropion SR [21.9%]).Varenicline was significantly more efficacious than placebo for smoking cessation at all time points and significantly more efficacious than bupropion SR at the end of 12 weeks of drug treatment and at 24 weeks.clinicaltrials.gov Identifier: NCT00141206.","Varenicline, an alpha4beta2 nicotinic acetylcholine receptor partial agonist, vs sustained-release bupropion and placebo for smoking cessation: a randomized controlled trial."
"689","JAMA.349","0.001",16820546,2006,"The alpha4beta2 nicotinic acetylcholine receptors (nAChRs) are linked to the reinforcing effects of nicotine and maintaining smoking behavior. Varenicline, a novel alpha4beta2 nAChR partial agonist, may be beneficial for smoking cessation.To assess efficacy and safety of varenicline for smoking cessation compared with sustained-release bupropion (bupropion SR) and placebo.Randomized, double-blind, parallel-group, placebo- and active-treatment-controlled, phase 3 clinical trial conducted at 19 US centers from June 19, 2003, to April 22, 2005. Participants were 1025 generally healthy smokers (> or =10 cigarettes/d) with fewer than 3 months of smoking abstinence in the past year, 18 to 75 years old, recruited via advertising.Participants were randomly assigned in a 1:1:1 ratio to receive brief counseling and varenicline titrated to 1 mg twice per day (n = 352), bupropion SR titrated to 150 mg twice per day (n = 329), or placebo (n = 344) orally for 12 weeks, with 40 weeks of nondrug follow-up.Primary outcome was the exhaled carbon monoxide-confirmed 4-week rate of continuous abstinence from smoking for weeks 9 through 12. A secondary outcome was the continuous abstinence rate for weeks 9 through 24 and weeks 9 through 52.For weeks 9 through 12, the 4-week continuous abstinence rates were 44.0% for varenicline vs 17.7% for placebo (odds ratio [OR], 3.85; 95% confidence interval [CI], 2.70-5.50; P<.001) and vs 29.5% for bupropion SR (OR, 1.93; 95% CI, 1.40-2.68; P<.001). Bupropion SR was also significantly more efficacious than placebo (OR, 2.00; 95% CI, 1.38-2.89; P<.001). For weeks 9 through 52, the continuous abstinence rates were 21.9% for varenicline vs 8.4% for placebo (OR, 3.09; 95% CI, 1.95-4.91; P<.001) and vs 16.1% for bupropion SR (OR, 1.46; 95% CI, 0.99-2.17; P = .057). Varenicline reduced craving and withdrawal and, for those who smoked while receiving study drug, smoking satisfaction. No sex differences in efficacy for varenicline were observed. Varenicline was safe and generally well tolerated, with study drug discontinuation rates similar to those for placebo. The most common adverse events for participants receiving active-drug treatment were nausea (98 participants receiving varenicline [28.1%]) and insomnia (72 receiving bupropion SR [21.9%]).Varenicline was significantly more efficacious than placebo for smoking cessation at all time points and significantly more efficacious than bupropion SR at the end of 12 weeks of drug treatment and at 24 weeks.clinicaltrials.gov Identifier: NCT00141206.","Varenicline, an alpha4beta2 nicotinic acetylcholine receptor partial agonist, vs sustained-release bupropion and placebo for smoking cessation: a randomized controlled trial."
"690","JAMA.350","0.001",16820546,2006,"The alpha4beta2 nicotinic acetylcholine receptors (nAChRs) are linked to the reinforcing effects of nicotine and maintaining smoking behavior. Varenicline, a novel alpha4beta2 nAChR partial agonist, may be beneficial for smoking cessation.To assess efficacy and safety of varenicline for smoking cessation compared with sustained-release bupropion (bupropion SR) and placebo.Randomized, double-blind, parallel-group, placebo- and active-treatment-controlled, phase 3 clinical trial conducted at 19 US centers from June 19, 2003, to April 22, 2005. Participants were 1025 generally healthy smokers (> or =10 cigarettes/d) with fewer than 3 months of smoking abstinence in the past year, 18 to 75 years old, recruited via advertising.Participants were randomly assigned in a 1:1:1 ratio to receive brief counseling and varenicline titrated to 1 mg twice per day (n = 352), bupropion SR titrated to 150 mg twice per day (n = 329), or placebo (n = 344) orally for 12 weeks, with 40 weeks of nondrug follow-up.Primary outcome was the exhaled carbon monoxide-confirmed 4-week rate of continuous abstinence from smoking for weeks 9 through 12. A secondary outcome was the continuous abstinence rate for weeks 9 through 24 and weeks 9 through 52.For weeks 9 through 12, the 4-week continuous abstinence rates were 44.0% for varenicline vs 17.7% for placebo (odds ratio [OR], 3.85; 95% confidence interval [CI], 2.70-5.50; P<.001) and vs 29.5% for bupropion SR (OR, 1.93; 95% CI, 1.40-2.68; P<.001). Bupropion SR was also significantly more efficacious than placebo (OR, 2.00; 95% CI, 1.38-2.89; P<.001). For weeks 9 through 52, the continuous abstinence rates were 21.9% for varenicline vs 8.4% for placebo (OR, 3.09; 95% CI, 1.95-4.91; P<.001) and vs 16.1% for bupropion SR (OR, 1.46; 95% CI, 0.99-2.17; P = .057). Varenicline reduced craving and withdrawal and, for those who smoked while receiving study drug, smoking satisfaction. No sex differences in efficacy for varenicline were observed. Varenicline was safe and generally well tolerated, with study drug discontinuation rates similar to those for placebo. The most common adverse events for participants receiving active-drug treatment were nausea (98 participants receiving varenicline [28.1%]) and insomnia (72 receiving bupropion SR [21.9%]).Varenicline was significantly more efficacious than placebo for smoking cessation at all time points and significantly more efficacious than bupropion SR at the end of 12 weeks of drug treatment and at 24 weeks.clinicaltrials.gov Identifier: NCT00141206.","Varenicline, an alpha4beta2 nicotinic acetylcholine receptor partial agonist, vs sustained-release bupropion and placebo for smoking cessation: a randomized controlled trial."
"691","JAMA.351","0.001",16820546,2006,"The alpha4beta2 nicotinic acetylcholine receptors (nAChRs) are linked to the reinforcing effects of nicotine and maintaining smoking behavior. Varenicline, a novel alpha4beta2 nAChR partial agonist, may be beneficial for smoking cessation.To assess efficacy and safety of varenicline for smoking cessation compared with sustained-release bupropion (bupropion SR) and placebo.Randomized, double-blind, parallel-group, placebo- and active-treatment-controlled, phase 3 clinical trial conducted at 19 US centers from June 19, 2003, to April 22, 2005. Participants were 1025 generally healthy smokers (> or =10 cigarettes/d) with fewer than 3 months of smoking abstinence in the past year, 18 to 75 years old, recruited via advertising.Participants were randomly assigned in a 1:1:1 ratio to receive brief counseling and varenicline titrated to 1 mg twice per day (n = 352), bupropion SR titrated to 150 mg twice per day (n = 329), or placebo (n = 344) orally for 12 weeks, with 40 weeks of nondrug follow-up.Primary outcome was the exhaled carbon monoxide-confirmed 4-week rate of continuous abstinence from smoking for weeks 9 through 12. A secondary outcome was the continuous abstinence rate for weeks 9 through 24 and weeks 9 through 52.For weeks 9 through 12, the 4-week continuous abstinence rates were 44.0% for varenicline vs 17.7% for placebo (odds ratio [OR], 3.85; 95% confidence interval [CI], 2.70-5.50; P<.001) and vs 29.5% for bupropion SR (OR, 1.93; 95% CI, 1.40-2.68; P<.001). Bupropion SR was also significantly more efficacious than placebo (OR, 2.00; 95% CI, 1.38-2.89; P<.001). For weeks 9 through 52, the continuous abstinence rates were 21.9% for varenicline vs 8.4% for placebo (OR, 3.09; 95% CI, 1.95-4.91; P<.001) and vs 16.1% for bupropion SR (OR, 1.46; 95% CI, 0.99-2.17; P = .057). Varenicline reduced craving and withdrawal and, for those who smoked while receiving study drug, smoking satisfaction. No sex differences in efficacy for varenicline were observed. Varenicline was safe and generally well tolerated, with study drug discontinuation rates similar to those for placebo. The most common adverse events for participants receiving active-drug treatment were nausea (98 participants receiving varenicline [28.1%]) and insomnia (72 receiving bupropion SR [21.9%]).Varenicline was significantly more efficacious than placebo for smoking cessation at all time points and significantly more efficacious than bupropion SR at the end of 12 weeks of drug treatment and at 24 weeks.clinicaltrials.gov Identifier: NCT00141206.","Varenicline, an alpha4beta2 nicotinic acetylcholine receptor partial agonist, vs sustained-release bupropion and placebo for smoking cessation: a randomized controlled trial."
"692","JAMA.377","0.057",16820546,2006,"The alpha4beta2 nicotinic acetylcholine receptors (nAChRs) are linked to the reinforcing effects of nicotine and maintaining smoking behavior. Varenicline, a novel alpha4beta2 nAChR partial agonist, may be beneficial for smoking cessation.To assess efficacy and safety of varenicline for smoking cessation compared with sustained-release bupropion (bupropion SR) and placebo.Randomized, double-blind, parallel-group, placebo- and active-treatment-controlled, phase 3 clinical trial conducted at 19 US centers from June 19, 2003, to April 22, 2005. Participants were 1025 generally healthy smokers (> or =10 cigarettes/d) with fewer than 3 months of smoking abstinence in the past year, 18 to 75 years old, recruited via advertising.Participants were randomly assigned in a 1:1:1 ratio to receive brief counseling and varenicline titrated to 1 mg twice per day (n = 352), bupropion SR titrated to 150 mg twice per day (n = 329), or placebo (n = 344) orally for 12 weeks, with 40 weeks of nondrug follow-up.Primary outcome was the exhaled carbon monoxide-confirmed 4-week rate of continuous abstinence from smoking for weeks 9 through 12. A secondary outcome was the continuous abstinence rate for weeks 9 through 24 and weeks 9 through 52.For weeks 9 through 12, the 4-week continuous abstinence rates were 44.0% for varenicline vs 17.7% for placebo (odds ratio [OR], 3.85; 95% confidence interval [CI], 2.70-5.50; P<.001) and vs 29.5% for bupropion SR (OR, 1.93; 95% CI, 1.40-2.68; P<.001). Bupropion SR was also significantly more efficacious than placebo (OR, 2.00; 95% CI, 1.38-2.89; P<.001). For weeks 9 through 52, the continuous abstinence rates were 21.9% for varenicline vs 8.4% for placebo (OR, 3.09; 95% CI, 1.95-4.91; P<.001) and vs 16.1% for bupropion SR (OR, 1.46; 95% CI, 0.99-2.17; P = .057). Varenicline reduced craving and withdrawal and, for those who smoked while receiving study drug, smoking satisfaction. No sex differences in efficacy for varenicline were observed. Varenicline was safe and generally well tolerated, with study drug discontinuation rates similar to those for placebo. The most common adverse events for participants receiving active-drug treatment were nausea (98 participants receiving varenicline [28.1%]) and insomnia (72 receiving bupropion SR [21.9%]).Varenicline was significantly more efficacious than placebo for smoking cessation at all time points and significantly more efficacious than bupropion SR at the end of 12 weeks of drug treatment and at 24 weeks.clinicaltrials.gov Identifier: NCT00141206.","Varenicline, an alpha4beta2 nicotinic acetylcholine receptor partial agonist, vs sustained-release bupropion and placebo for smoking cessation: a randomized controlled trial."
"693","JAMA.344","0.001",16820547,2006,"Varenicline, a partial agonist at the alpha4beta2 nicotinic acetylcholine receptor, has the potential to aid smoking cessation by relieving nicotine withdrawal symptoms and reducing the rewarding properties of nicotine.To determine the efficacy and safety of varenicline for smoking cessation compared with placebo or sustained-release bupropion (bupropion SR).A randomized, double-blind, placebo-controlled trial conducted between June 2003 and March 2005 at 14 research centers with a 12-week treatment period and follow-up of smoking status to week 52. Of 1413 adult smokers who volunteered for the study, 1027 were enrolled; 65% of randomized participants completed the study.Varenicline titrated to 1 mg twice daily (n = 344) or bupropion SR titrated to 150 mg twice daily (n = 342) or placebo (n = 341) for 12 weeks, plus weekly brief smoking cessation counseling.Continuous abstinence from smoking during the last 4 weeks of treatment (weeks 9-12; primary end point) and through the follow-up period (weeks 9-24 and 9-52).During the last 4 weeks of treatment (weeks 9-12), 43.9% of participants in the varenicline group were continuously abstinent from smoking compared with 17.6% in the placebo group (odds ratio [OR], 3.85; 95% confidence interval [CI], 2.69-5.50; P<.001) and 29.8% in the bupropion SR group (OR, 1.90; 95% CI, 1.38-2.62; P<.001). For weeks 9 through 24, 29.7% of participants in the varenicline group were continuously abstinent compared with 13.2% in the placebo group (OR, 2.83; 95% CI, 1.91-4.19; P<.001) and 20.2% in the bupropion group (OR, 1.69; 95% CI, 1.19-2.42; P = .003). For weeks 9 through 52, 23% of participants in the varenicline group were continuously abstinent compared with 10.3% in the placebo group (OR, 2.66; 95% CI, 1.72-4.11; P<.001) and 14.6% in the bupropion SR group (OR, 1.77; 95% CI, 1.19-2.63; P = .004). Treatment was discontinued due to adverse events by 10.5% of participants in the varenicline group, 12.6% in the bupropion SR group, and 7.3% in the placebo group. The most common adverse event with varenicline was nausea, which occurred in 101 participants (29.4%).Varenicline is an efficacious, safe, and well-tolerated smoking cessation pharmacotherapy. Varenicline's short-term and long-term efficacy exceeded that of both placebo and bupropion SR.clinicaltrials.gov Identifier: NCT00143364.","Efficacy of varenicline, an alpha4beta2 nicotinic acetylcholine receptor partial agonist, vs placebo or sustained-release bupropion for smoking cessation: a randomized controlled trial."
"694","JAMA.345","0.001",16820547,2006,"Varenicline, a partial agonist at the alpha4beta2 nicotinic acetylcholine receptor, has the potential to aid smoking cessation by relieving nicotine withdrawal symptoms and reducing the rewarding properties of nicotine.To determine the efficacy and safety of varenicline for smoking cessation compared with placebo or sustained-release bupropion (bupropion SR).A randomized, double-blind, placebo-controlled trial conducted between June 2003 and March 2005 at 14 research centers with a 12-week treatment period and follow-up of smoking status to week 52. Of 1413 adult smokers who volunteered for the study, 1027 were enrolled; 65% of randomized participants completed the study.Varenicline titrated to 1 mg twice daily (n = 344) or bupropion SR titrated to 150 mg twice daily (n = 342) or placebo (n = 341) for 12 weeks, plus weekly brief smoking cessation counseling.Continuous abstinence from smoking during the last 4 weeks of treatment (weeks 9-12; primary end point) and through the follow-up period (weeks 9-24 and 9-52).During the last 4 weeks of treatment (weeks 9-12), 43.9% of participants in the varenicline group were continuously abstinent from smoking compared with 17.6% in the placebo group (odds ratio [OR], 3.85; 95% confidence interval [CI], 2.69-5.50; P<.001) and 29.8% in the bupropion SR group (OR, 1.90; 95% CI, 1.38-2.62; P<.001). For weeks 9 through 24, 29.7% of participants in the varenicline group were continuously abstinent compared with 13.2% in the placebo group (OR, 2.83; 95% CI, 1.91-4.19; P<.001) and 20.2% in the bupropion group (OR, 1.69; 95% CI, 1.19-2.42; P = .003). For weeks 9 through 52, 23% of participants in the varenicline group were continuously abstinent compared with 10.3% in the placebo group (OR, 2.66; 95% CI, 1.72-4.11; P<.001) and 14.6% in the bupropion SR group (OR, 1.77; 95% CI, 1.19-2.63; P = .004). Treatment was discontinued due to adverse events by 10.5% of participants in the varenicline group, 12.6% in the bupropion SR group, and 7.3% in the placebo group. The most common adverse event with varenicline was nausea, which occurred in 101 participants (29.4%).Varenicline is an efficacious, safe, and well-tolerated smoking cessation pharmacotherapy. Varenicline's short-term and long-term efficacy exceeded that of both placebo and bupropion SR.clinicaltrials.gov Identifier: NCT00143364.","Efficacy of varenicline, an alpha4beta2 nicotinic acetylcholine receptor partial agonist, vs placebo or sustained-release bupropion for smoking cessation: a randomized controlled trial."
"695","JAMA.346","0.001",16820547,2006,"Varenicline, a partial agonist at the alpha4beta2 nicotinic acetylcholine receptor, has the potential to aid smoking cessation by relieving nicotine withdrawal symptoms and reducing the rewarding properties of nicotine.To determine the efficacy and safety of varenicline for smoking cessation compared with placebo or sustained-release bupropion (bupropion SR).A randomized, double-blind, placebo-controlled trial conducted between June 2003 and March 2005 at 14 research centers with a 12-week treatment period and follow-up of smoking status to week 52. Of 1413 adult smokers who volunteered for the study, 1027 were enrolled; 65% of randomized participants completed the study.Varenicline titrated to 1 mg twice daily (n = 344) or bupropion SR titrated to 150 mg twice daily (n = 342) or placebo (n = 341) for 12 weeks, plus weekly brief smoking cessation counseling.Continuous abstinence from smoking during the last 4 weeks of treatment (weeks 9-12; primary end point) and through the follow-up period (weeks 9-24 and 9-52).During the last 4 weeks of treatment (weeks 9-12), 43.9% of participants in the varenicline group were continuously abstinent from smoking compared with 17.6% in the placebo group (odds ratio [OR], 3.85; 95% confidence interval [CI], 2.69-5.50; P<.001) and 29.8% in the bupropion SR group (OR, 1.90; 95% CI, 1.38-2.62; P<.001). For weeks 9 through 24, 29.7% of participants in the varenicline group were continuously abstinent compared with 13.2% in the placebo group (OR, 2.83; 95% CI, 1.91-4.19; P<.001) and 20.2% in the bupropion group (OR, 1.69; 95% CI, 1.19-2.42; P = .003). For weeks 9 through 52, 23% of participants in the varenicline group were continuously abstinent compared with 10.3% in the placebo group (OR, 2.66; 95% CI, 1.72-4.11; P<.001) and 14.6% in the bupropion SR group (OR, 1.77; 95% CI, 1.19-2.63; P = .004). Treatment was discontinued due to adverse events by 10.5% of participants in the varenicline group, 12.6% in the bupropion SR group, and 7.3% in the placebo group. The most common adverse event with varenicline was nausea, which occurred in 101 participants (29.4%).Varenicline is an efficacious, safe, and well-tolerated smoking cessation pharmacotherapy. Varenicline's short-term and long-term efficacy exceeded that of both placebo and bupropion SR.clinicaltrials.gov Identifier: NCT00143364.","Efficacy of varenicline, an alpha4beta2 nicotinic acetylcholine receptor partial agonist, vs placebo or sustained-release bupropion for smoking cessation: a randomized controlled trial."
"696","JAMA.347","0.001",16820547,2006,"Varenicline, a partial agonist at the alpha4beta2 nicotinic acetylcholine receptor, has the potential to aid smoking cessation by relieving nicotine withdrawal symptoms and reducing the rewarding properties of nicotine.To determine the efficacy and safety of varenicline for smoking cessation compared with placebo or sustained-release bupropion (bupropion SR).A randomized, double-blind, placebo-controlled trial conducted between June 2003 and March 2005 at 14 research centers with a 12-week treatment period and follow-up of smoking status to week 52. Of 1413 adult smokers who volunteered for the study, 1027 were enrolled; 65% of randomized participants completed the study.Varenicline titrated to 1 mg twice daily (n = 344) or bupropion SR titrated to 150 mg twice daily (n = 342) or placebo (n = 341) for 12 weeks, plus weekly brief smoking cessation counseling.Continuous abstinence from smoking during the last 4 weeks of treatment (weeks 9-12; primary end point) and through the follow-up period (weeks 9-24 and 9-52).During the last 4 weeks of treatment (weeks 9-12), 43.9% of participants in the varenicline group were continuously abstinent from smoking compared with 17.6% in the placebo group (odds ratio [OR], 3.85; 95% confidence interval [CI], 2.69-5.50; P<.001) and 29.8% in the bupropion SR group (OR, 1.90; 95% CI, 1.38-2.62; P<.001). For weeks 9 through 24, 29.7% of participants in the varenicline group were continuously abstinent compared with 13.2% in the placebo group (OR, 2.83; 95% CI, 1.91-4.19; P<.001) and 20.2% in the bupropion group (OR, 1.69; 95% CI, 1.19-2.42; P = .003). For weeks 9 through 52, 23% of participants in the varenicline group were continuously abstinent compared with 10.3% in the placebo group (OR, 2.66; 95% CI, 1.72-4.11; P<.001) and 14.6% in the bupropion SR group (OR, 1.77; 95% CI, 1.19-2.63; P = .004). Treatment was discontinued due to adverse events by 10.5% of participants in the varenicline group, 12.6% in the bupropion SR group, and 7.3% in the placebo group. The most common adverse event with varenicline was nausea, which occurred in 101 participants (29.4%).Varenicline is an efficacious, safe, and well-tolerated smoking cessation pharmacotherapy. Varenicline's short-term and long-term efficacy exceeded that of both placebo and bupropion SR.clinicaltrials.gov Identifier: NCT00143364.","Efficacy of varenicline, an alpha4beta2 nicotinic acetylcholine receptor partial agonist, vs placebo or sustained-release bupropion for smoking cessation: a randomized controlled trial."
"697","JAMA.375","0.003",16820547,2006,"Varenicline, a partial agonist at the alpha4beta2 nicotinic acetylcholine receptor, has the potential to aid smoking cessation by relieving nicotine withdrawal symptoms and reducing the rewarding properties of nicotine.To determine the efficacy and safety of varenicline for smoking cessation compared with placebo or sustained-release bupropion (bupropion SR).A randomized, double-blind, placebo-controlled trial conducted between June 2003 and March 2005 at 14 research centers with a 12-week treatment period and follow-up of smoking status to week 52. Of 1413 adult smokers who volunteered for the study, 1027 were enrolled; 65% of randomized participants completed the study.Varenicline titrated to 1 mg twice daily (n = 344) or bupropion SR titrated to 150 mg twice daily (n = 342) or placebo (n = 341) for 12 weeks, plus weekly brief smoking cessation counseling.Continuous abstinence from smoking during the last 4 weeks of treatment (weeks 9-12; primary end point) and through the follow-up period (weeks 9-24 and 9-52).During the last 4 weeks of treatment (weeks 9-12), 43.9% of participants in the varenicline group were continuously abstinent from smoking compared with 17.6% in the placebo group (odds ratio [OR], 3.85; 95% confidence interval [CI], 2.69-5.50; P<.001) and 29.8% in the bupropion SR group (OR, 1.90; 95% CI, 1.38-2.62; P<.001). For weeks 9 through 24, 29.7% of participants in the varenicline group were continuously abstinent compared with 13.2% in the placebo group (OR, 2.83; 95% CI, 1.91-4.19; P<.001) and 20.2% in the bupropion group (OR, 1.69; 95% CI, 1.19-2.42; P = .003). For weeks 9 through 52, 23% of participants in the varenicline group were continuously abstinent compared with 10.3% in the placebo group (OR, 2.66; 95% CI, 1.72-4.11; P<.001) and 14.6% in the bupropion SR group (OR, 1.77; 95% CI, 1.19-2.63; P = .004). Treatment was discontinued due to adverse events by 10.5% of participants in the varenicline group, 12.6% in the bupropion SR group, and 7.3% in the placebo group. The most common adverse event with varenicline was nausea, which occurred in 101 participants (29.4%).Varenicline is an efficacious, safe, and well-tolerated smoking cessation pharmacotherapy. Varenicline's short-term and long-term efficacy exceeded that of both placebo and bupropion SR.clinicaltrials.gov Identifier: NCT00143364.","Efficacy of varenicline, an alpha4beta2 nicotinic acetylcholine receptor partial agonist, vs placebo or sustained-release bupropion for smoking cessation: a randomized controlled trial."
"698","JAMA.376","0.004",16820547,2006,"Varenicline, a partial agonist at the alpha4beta2 nicotinic acetylcholine receptor, has the potential to aid smoking cessation by relieving nicotine withdrawal symptoms and reducing the rewarding properties of nicotine.To determine the efficacy and safety of varenicline for smoking cessation compared with placebo or sustained-release bupropion (bupropion SR).A randomized, double-blind, placebo-controlled trial conducted between June 2003 and March 2005 at 14 research centers with a 12-week treatment period and follow-up of smoking status to week 52. Of 1413 adult smokers who volunteered for the study, 1027 were enrolled; 65% of randomized participants completed the study.Varenicline titrated to 1 mg twice daily (n = 344) or bupropion SR titrated to 150 mg twice daily (n = 342) or placebo (n = 341) for 12 weeks, plus weekly brief smoking cessation counseling.Continuous abstinence from smoking during the last 4 weeks of treatment (weeks 9-12; primary end point) and through the follow-up period (weeks 9-24 and 9-52).During the last 4 weeks of treatment (weeks 9-12), 43.9% of participants in the varenicline group were continuously abstinent from smoking compared with 17.6% in the placebo group (odds ratio [OR], 3.85; 95% confidence interval [CI], 2.69-5.50; P<.001) and 29.8% in the bupropion SR group (OR, 1.90; 95% CI, 1.38-2.62; P<.001). For weeks 9 through 24, 29.7% of participants in the varenicline group were continuously abstinent compared with 13.2% in the placebo group (OR, 2.83; 95% CI, 1.91-4.19; P<.001) and 20.2% in the bupropion group (OR, 1.69; 95% CI, 1.19-2.42; P = .003). For weeks 9 through 52, 23% of participants in the varenicline group were continuously abstinent compared with 10.3% in the placebo group (OR, 2.66; 95% CI, 1.72-4.11; P<.001) and 14.6% in the bupropion SR group (OR, 1.77; 95% CI, 1.19-2.63; P = .004). Treatment was discontinued due to adverse events by 10.5% of participants in the varenicline group, 12.6% in the bupropion SR group, and 7.3% in the placebo group. The most common adverse event with varenicline was nausea, which occurred in 101 participants (29.4%).Varenicline is an efficacious, safe, and well-tolerated smoking cessation pharmacotherapy. Varenicline's short-term and long-term efficacy exceeded that of both placebo and bupropion SR.clinicaltrials.gov Identifier: NCT00143364.","Efficacy of varenicline, an alpha4beta2 nicotinic acetylcholine receptor partial agonist, vs placebo or sustained-release bupropion for smoking cessation: a randomized controlled trial."
"699","JAMA.343","0.001",16820548,2006,"The majority of cigarette smokers who achieve abstinence relapse within the first year and require many attempts before achieving permanent abstinence. Evidence to support pharmacological treatment for relapse prevention is insufficient.To determine whether smokers who quit after 12 weeks of treatment with varenicline, a selective alpha4beta2 nicotinic acetylcholine receptor partial agonist, maintain greater continuous abstinence rates (defined as not a single ""puff"" of a cigarette) than placebo controls during an additional 12 weeks of treatment and until 52 weeks after treatment initiation.Randomized controlled trial conducted at multiple medical clinics in 7 countries with follow-up to 52 weeks after study baseline. Of 1927 cigarette smokers recruited between April 2003 and February 2004 and treated for 12 weeks with open-label varenicline titrated to 1 mg twice per day, 1236 (64.1%) did not smoke, use tobacco, or use nicotine replacement therapy during the last week of treatment and 62.8% (n = 1210) were randomized to additional treatment or placebo.Participants were randomly assigned to receive either double-blind varenicline, 1 mg twice per day (n = 603), or placebo (n = 607) for an additional 12 weeks.Carbon monoxide-confirmed continued abstinence during weeks 13 to 24 and weeks 13 to 52 of the study.The carbon monoxide-confirmed continuous abstinence rate was significantly higher for the varenicline group than for the placebo group for weeks 13 to 24 (70.5% vs 49.6%; odds ratio [OR], 2.48; 95% confidence interval [CI], 1.95-3.16; P<.001) as well as for weeks 13 to 52 (43.6% vs 36.9%; OR, 1.34; 95% CI, 1.06-1.69; P = .02). Adverse events reported in the open-label period were mostly mild; no difference in adverse events between varenicline and placebo was observed during the double-blind period.Smokers who achieved abstinence for at least 7 days at the end of 12 weeks of open-label varenicline treatment and were randomized to receive an additional 12 weeks of varenicline treatment showed significantly greater continuous abstinence in weeks 13 to 24 compared with placebo. This advantage was maintained through the nontreatment follow-up to week 52. Varenicline may be an efficacious, safe, and well-tolerated agent for maintaining abstinence from smoking.clinicaltrials.gov Identifier: NCT00143286.","Effect of maintenance therapy with varenicline on smoking cessation: a randomized controlled trial."
"700","JAMA.374","0.02",16820548,2006,"The majority of cigarette smokers who achieve abstinence relapse within the first year and require many attempts before achieving permanent abstinence. Evidence to support pharmacological treatment for relapse prevention is insufficient.To determine whether smokers who quit after 12 weeks of treatment with varenicline, a selective alpha4beta2 nicotinic acetylcholine receptor partial agonist, maintain greater continuous abstinence rates (defined as not a single ""puff"" of a cigarette) than placebo controls during an additional 12 weeks of treatment and until 52 weeks after treatment initiation.Randomized controlled trial conducted at multiple medical clinics in 7 countries with follow-up to 52 weeks after study baseline. Of 1927 cigarette smokers recruited between April 2003 and February 2004 and treated for 12 weeks with open-label varenicline titrated to 1 mg twice per day, 1236 (64.1%) did not smoke, use tobacco, or use nicotine replacement therapy during the last week of treatment and 62.8% (n = 1210) were randomized to additional treatment or placebo.Participants were randomly assigned to receive either double-blind varenicline, 1 mg twice per day (n = 603), or placebo (n = 607) for an additional 12 weeks.Carbon monoxide-confirmed continued abstinence during weeks 13 to 24 and weeks 13 to 52 of the study.The carbon monoxide-confirmed continuous abstinence rate was significantly higher for the varenicline group than for the placebo group for weeks 13 to 24 (70.5% vs 49.6%; odds ratio [OR], 2.48; 95% confidence interval [CI], 1.95-3.16; P<.001) as well as for weeks 13 to 52 (43.6% vs 36.9%; OR, 1.34; 95% CI, 1.06-1.69; P = .02). Adverse events reported in the open-label period were mostly mild; no difference in adverse events between varenicline and placebo was observed during the double-blind period.Smokers who achieved abstinence for at least 7 days at the end of 12 weeks of open-label varenicline treatment and were randomized to receive an additional 12 weeks of varenicline treatment showed significantly greater continuous abstinence in weeks 13 to 24 compared with placebo. This advantage was maintained through the nontreatment follow-up to week 52. Varenicline may be an efficacious, safe, and well-tolerated agent for maintaining abstinence from smoking.clinicaltrials.gov Identifier: NCT00143286.","Effect of maintenance therapy with varenicline on smoking cessation: a randomized controlled trial."
"701","JAMA.373","0.009",16882963,2006,"In May 2002, the World Health Organization and the United Nations Children's Fund recommended that the formulation of oral rehydration solution (ORS) for treatment of patients with diarrhea be changed to one with a reduced osmolarity and that safety of the new formulation, particularly development of symptomatic hyponatremia, be monitored.To measure the rates of symptomatic hyponatremia during treatment of patients with diarrhea with reduced osmolarity ORS.A phase 4 trial conducted at the Dhaka hospital (December 1, 2002-November 30, 2003) and Matlab hospital (February 2, 2003-January 31, 2004) of the International Centre for Diarrhoeal Disease Research Bangladesh: Centre for Health and Population Research, Dhaka, Bangladesh. All patients admitted with uncomplicated watery diarrhea were treated with the newly recommended ORS and monitored. Patients developing neurological symptoms (seizure or altered consciousness) were transferred to the special care ward for treatment and investigated to identify the cause of the symptoms. Patient records of the Dhaka hospital were reviewed during the previous year when the old ORS formulation was used.Reduced osmolarity ORS.Incidence rate of symptomatic hyponatremia in a 1-year period.A total of 53,280 patients, including 22,536 children younger than 60 months, were monitored at the Dhaka and Matlab hospitals. Twenty-four patients, none older than 36 months, developed seizures or altered consciousness associated with hyponatremia, with an overall incidence rate of 0.05% (95% confidence interval [CI], 0.03%-0.07%) at the Dhaka hospital and 0.03% (95% CI, 0.01%-0.09%) at the Matlab hospital. During the previous year, 47 patients at the Dhaka hospital had symptoms associated with hyponatremia, for an estimated incidence rate of 0.10% (95% CI, 0.07%-0.13%). The reduction in the rates was statistically significant (odds ratio, 0.50; 95% CI, 0.29-0.85; P = .009).The risk of symptoms associated with hyponatremia in patients treated with the reduced osmolarity ORS is minimal and did not increase with the change in formulation.","Symptomatic hyponatremia during treatment of dehydrating diarrheal disease with reduced osmolarity oral rehydration solution."
"702","Lancet.41","1.00E-04",16920470,2006,"Tobacco use is one of the major avoidable causes of cardiovascular diseases. We aimed to assess the risks associated with tobacco use (both smoking and non-smoking) and second hand tobacco smoke (SHS) worldwide.We did a standardised case-control study of acute myocardial infarction (AMI) with 27,089 participants in 52 countries (12,461 cases, 14,637 controls). We assessed relation between risk of AMI and current or former smoking, type of tobacco, amount smoked, effect of smokeless tobacco, and exposure to SHS. We controlled for confounders such as differences in lifestyles between smokers and non-smokers.Current smoking was associated with a greater risk of non-fatal AMI (odds ratio [OR] 2.95, 95% CI 2.77-3.14, p<0.0001) compared with never smoking; risk increased by 5.6% for every additional cigarette smoked. The OR associated with former smoking fell to 1.87 (95% CI 1.55-2.24) within 3 years of quitting. A residual excess risk remained 20 or more years after quitting (1.22, 1.09-1.37). Exclusion of individuals exposed to SHS in the never smoker reference group raised the risk in former smokers by about 10%. Smoking beedies alone (indigenous to South Asia) was associated with increased risk (2.89, 2.11-3.96) similar to that associated with cigarette smoking. Chewing tobacco alone was associated with OR 2.23 (1.41-3.52), and smokers who also chewed tobacco had the highest increase in risk (4.09, 2.98-5.61). SHS was associated with a graded increase in risk related to exposure; OR was 1.24 (1.17-1.32) in individuals who were least exposed (1-7 h per week) and 1.62 (1.45-1.81) in people who were most exposed (>21 h per week). Young male current smokers had the highest population attributable risk (58.3%; 95% CI 55.0-61.6) and older women the lowest (6.2%, 4.1-9.2). Population attributable risk for exposure to SHS for more than 1 h per week in never smokers was 15.4% (12.1-19.3).Tobacco use is one of the most important causes of AMI globally, especially in men. All forms of tobacco use, including different types of smoking and chewing tobacco and inhalation of SHS, should be discouraged to prevent cardiovascular diseases.","Tobacco use and risk of myocardial infarction in 52 countries in the INTERHEART study: a case-control study."
"703","JAMA.3331","0.007",16968848,2006,"Atrial fibrillation (AF) is associated with increased risk of mortality and cardiovascular events, particularly stroke, making prevention of new-onset AF a clinical priority. Although the presence and severity of electrocardiographic left ventricular hypertrophy (LVH) appear to predict development of AF, whether regression of electrocardiographic LVH is associated with a decreased incidence of AF is unclear.To test the hypothesis that in-treatment regression or continued absence of electrocardiographic LVH during antihypertensive therapy is associated with a decreased incidence of AF, independent of blood pressure and treatment modality.Double-blind, randomized, parallel-group study conducted in 1995-2001 among 8831 men and women with hypertension, aged 55-80 years (median, 67 years), with electrocardiographic LVH by Cornell voltage-duration product or Sokolow-Lyon voltage, with no history of AF, without AF on the baseline electrocardiogram, and enrolled in the Losartan Intervention for Endpoint Reduction in Hypertension Study.Losartan- or atenolol-based treatment regimens, with follow-up assessments at 6 months and then yearly until death or study end.New-onset AF in relation to electrocardiographic LVH determined at baseline and subsequently. Electrocardiographic LVH was measured using sex-adjusted Cornell product criteria ({R(aVL) + S(V3) [+ 6 mm in women]} x QRS duration).After a mean (SD) follow-up of 4.7 (1.1) years, new-onset AF occurred in 290 patients with in-treatment regression or continued absence of Cornell product LVH for a rate of 14.9 per 1000 patient-years and in 411 patients with in-treatment persistence or development of LVH by Cornell product criteria for a rate of 19.0 per 1000 patient-years. In time-dependent Cox analyses adjusted for treatment effects, baseline differences in risk factors for AF, baseline and in-treatment blood pressure, and baseline severity of electrocardiographic LVH, lower in-treatment Cornell product LVH treated as a time-varying covariate was associated with a 12.4% lower rate of new-onset AF (adjusted hazard ratio [HR], 0.88; 95% CI, 0.80-0.97; P = .007) for every 1050 mm x msec (per 1-SD) lower Cornell product, with persistence of the benefit of losartan vs atenolol therapy on developing AF (HR, 0.83; 95% CI, 0.71-0.97; P = .01).Lower Cornell product electrocardiographic LVH during antihypertensive therapy is associated with a lower likelihood of new-onset AF, independent of blood pressure lowering and treatment modality in essential hypertension. These findings suggest that antihypertensive therapy targeted at regression or prevention of electrocardiographic LVH may reduce the incidence of new-onset AF.","Regression of electrocardiographic left ventricular hypertrophy and decreased incidence of new-onset atrial fibrillation in patients with hypertension."
"704","JAMA.3341","0.01",16968848,2006,"Atrial fibrillation (AF) is associated with increased risk of mortality and cardiovascular events, particularly stroke, making prevention of new-onset AF a clinical priority. Although the presence and severity of electrocardiographic left ventricular hypertrophy (LVH) appear to predict development of AF, whether regression of electrocardiographic LVH is associated with a decreased incidence of AF is unclear.To test the hypothesis that in-treatment regression or continued absence of electrocardiographic LVH during antihypertensive therapy is associated with a decreased incidence of AF, independent of blood pressure and treatment modality.Double-blind, randomized, parallel-group study conducted in 1995-2001 among 8831 men and women with hypertension, aged 55-80 years (median, 67 years), with electrocardiographic LVH by Cornell voltage-duration product or Sokolow-Lyon voltage, with no history of AF, without AF on the baseline electrocardiogram, and enrolled in the Losartan Intervention for Endpoint Reduction in Hypertension Study.Losartan- or atenolol-based treatment regimens, with follow-up assessments at 6 months and then yearly until death or study end.New-onset AF in relation to electrocardiographic LVH determined at baseline and subsequently. Electrocardiographic LVH was measured using sex-adjusted Cornell product criteria ({R(aVL) + S(V3) [+ 6 mm in women]} x QRS duration).After a mean (SD) follow-up of 4.7 (1.1) years, new-onset AF occurred in 290 patients with in-treatment regression or continued absence of Cornell product LVH for a rate of 14.9 per 1000 patient-years and in 411 patients with in-treatment persistence or development of LVH by Cornell product criteria for a rate of 19.0 per 1000 patient-years. In time-dependent Cox analyses adjusted for treatment effects, baseline differences in risk factors for AF, baseline and in-treatment blood pressure, and baseline severity of electrocardiographic LVH, lower in-treatment Cornell product LVH treated as a time-varying covariate was associated with a 12.4% lower rate of new-onset AF (adjusted hazard ratio [HR], 0.88; 95% CI, 0.80-0.97; P = .007) for every 1050 mm x msec (per 1-SD) lower Cornell product, with persistence of the benefit of losartan vs atenolol therapy on developing AF (HR, 0.83; 95% CI, 0.71-0.97; P = .01).Lower Cornell product electrocardiographic LVH during antihypertensive therapy is associated with a lower likelihood of new-onset AF, independent of blood pressure lowering and treatment modality in essential hypertension. These findings suggest that antihypertensive therapy targeted at regression or prevention of electrocardiographic LVH may reduce the incidence of new-onset AF.","Regression of electrocardiographic left ventricular hypertrophy and decreased incidence of new-onset atrial fibrillation in patients with hypertension."
"705","JAMA.3131","0.01",16968849,2006,"Analysis of predictors of cardiac events in hereditary long-QT syndrome (LQTS) has primarily considered syncope as the predominant end point. Risk factors specific for aborted cardiac arrest and sudden cardiac death have not been investigated.To identify risk factors associated with aborted cardiac arrest and sudden cardiac death during adolescence in patients with clinically suspected LQTS.The study involved 2772 participants from the International Long QT Syndrome Registry who were alive at age 10 years and were followed up during adolescence until age 20 years. The registry enrollment began in 1979 at 5 cardiology centers in the United States and Europe.Aborted cardiac arrest or LQTS-related sudden cardiac death; follow-up ended on February 15, 2005.There were 81 patients who experienced aborted cardiac arrest and 45 who had sudden cardiac death; 9 of the 81 patients who had an aborted cardiac arrest event experienced subsequent sudden cardiac death. Significant independent predictors of aborted cardiac arrest or sudden cardiac death during adolescence included recent syncope, QTc interval, and sex. Compared with those with no syncopal events in the last 10 years, patients with 1 or 2 or more episodes of syncope 2 to 10 years ago (but none in the last 2 years) had an adjusted hazard ratio (HR) of 2.7; (95% confidence interval [CI], 1.3-5.7; P<.01) and an adjusted HR of 5.8 (95% CI, 3.6-9.4; P<.001), respectively, for life-threatening events; those with 1 syncopal episodes in the last 2 years had an adjusted HR of 11.7 (95% CI, 7.0-19.5; P<.001) and those with 2 or more syncopal episodes in the last 2 years had an adjusted HR of 18.1 (95% CI, 10.4-31.2; P<.001). Irrespective of events occurring more than 2 years ago, QTc of 530 ms or longer was associated with increased risk (adjusted HR, 2.3; 95% CI, 1.6-3.3; P<.001) compared with those having a shorter QTc. Males between the ages of 10 and 12 years had higher risk than females (HR, 4.0; 95% CI, 1.8-9.2; P = .001), but there was no significant risk difference between males and females between the ages of 13 and 20 years. Among individuals with syncope in the past 2 years, beta-blocker therapy was associated with a 64% reduced risk (HR, 0.36; 95% CI, 0.18-0.72; P<.01).In LQTS, the timing and frequency of syncope, QTc prolongation, and sex were predictive of risk for aborted cardiac arrest and sudden cardiac death during adolescence. Among patients with recent syncope, beta-blocker treatment was associated with reduced risk.","Risk of aborted cardiac arrest or sudden cardiac death during adolescence in the long-QT syndrome."
"706","JAMA.3141","0.001",16968849,2006,"Analysis of predictors of cardiac events in hereditary long-QT syndrome (LQTS) has primarily considered syncope as the predominant end point. Risk factors specific for aborted cardiac arrest and sudden cardiac death have not been investigated.To identify risk factors associated with aborted cardiac arrest and sudden cardiac death during adolescence in patients with clinically suspected LQTS.The study involved 2772 participants from the International Long QT Syndrome Registry who were alive at age 10 years and were followed up during adolescence until age 20 years. The registry enrollment began in 1979 at 5 cardiology centers in the United States and Europe.Aborted cardiac arrest or LQTS-related sudden cardiac death; follow-up ended on February 15, 2005.There were 81 patients who experienced aborted cardiac arrest and 45 who had sudden cardiac death; 9 of the 81 patients who had an aborted cardiac arrest event experienced subsequent sudden cardiac death. Significant independent predictors of aborted cardiac arrest or sudden cardiac death during adolescence included recent syncope, QTc interval, and sex. Compared with those with no syncopal events in the last 10 years, patients with 1 or 2 or more episodes of syncope 2 to 10 years ago (but none in the last 2 years) had an adjusted hazard ratio (HR) of 2.7; (95% confidence interval [CI], 1.3-5.7; P<.01) and an adjusted HR of 5.8 (95% CI, 3.6-9.4; P<.001), respectively, for life-threatening events; those with 1 syncopal episodes in the last 2 years had an adjusted HR of 11.7 (95% CI, 7.0-19.5; P<.001) and those with 2 or more syncopal episodes in the last 2 years had an adjusted HR of 18.1 (95% CI, 10.4-31.2; P<.001). Irrespective of events occurring more than 2 years ago, QTc of 530 ms or longer was associated with increased risk (adjusted HR, 2.3; 95% CI, 1.6-3.3; P<.001) compared with those having a shorter QTc. Males between the ages of 10 and 12 years had higher risk than females (HR, 4.0; 95% CI, 1.8-9.2; P = .001), but there was no significant risk difference between males and females between the ages of 13 and 20 years. Among individuals with syncope in the past 2 years, beta-blocker therapy was associated with a 64% reduced risk (HR, 0.36; 95% CI, 0.18-0.72; P<.01).In LQTS, the timing and frequency of syncope, QTc prolongation, and sex were predictive of risk for aborted cardiac arrest and sudden cardiac death during adolescence. Among patients with recent syncope, beta-blocker treatment was associated with reduced risk.","Risk of aborted cardiac arrest or sudden cardiac death during adolescence in the long-QT syndrome."
"707","JAMA.3151","0.001",16968849,2006,"Analysis of predictors of cardiac events in hereditary long-QT syndrome (LQTS) has primarily considered syncope as the predominant end point. Risk factors specific for aborted cardiac arrest and sudden cardiac death have not been investigated.To identify risk factors associated with aborted cardiac arrest and sudden cardiac death during adolescence in patients with clinically suspected LQTS.The study involved 2772 participants from the International Long QT Syndrome Registry who were alive at age 10 years and were followed up during adolescence until age 20 years. The registry enrollment began in 1979 at 5 cardiology centers in the United States and Europe.Aborted cardiac arrest or LQTS-related sudden cardiac death; follow-up ended on February 15, 2005.There were 81 patients who experienced aborted cardiac arrest and 45 who had sudden cardiac death; 9 of the 81 patients who had an aborted cardiac arrest event experienced subsequent sudden cardiac death. Significant independent predictors of aborted cardiac arrest or sudden cardiac death during adolescence included recent syncope, QTc interval, and sex. Compared with those with no syncopal events in the last 10 years, patients with 1 or 2 or more episodes of syncope 2 to 10 years ago (but none in the last 2 years) had an adjusted hazard ratio (HR) of 2.7; (95% confidence interval [CI], 1.3-5.7; P<.01) and an adjusted HR of 5.8 (95% CI, 3.6-9.4; P<.001), respectively, for life-threatening events; those with 1 syncopal episodes in the last 2 years had an adjusted HR of 11.7 (95% CI, 7.0-19.5; P<.001) and those with 2 or more syncopal episodes in the last 2 years had an adjusted HR of 18.1 (95% CI, 10.4-31.2; P<.001). Irrespective of events occurring more than 2 years ago, QTc of 530 ms or longer was associated with increased risk (adjusted HR, 2.3; 95% CI, 1.6-3.3; P<.001) compared with those having a shorter QTc. Males between the ages of 10 and 12 years had higher risk than females (HR, 4.0; 95% CI, 1.8-9.2; P = .001), but there was no significant risk difference between males and females between the ages of 13 and 20 years. Among individuals with syncope in the past 2 years, beta-blocker therapy was associated with a 64% reduced risk (HR, 0.36; 95% CI, 0.18-0.72; P<.01).In LQTS, the timing and frequency of syncope, QTc prolongation, and sex were predictive of risk for aborted cardiac arrest and sudden cardiac death during adolescence. Among patients with recent syncope, beta-blocker treatment was associated with reduced risk.","Risk of aborted cardiac arrest or sudden cardiac death during adolescence in the long-QT syndrome."
"708","JAMA.3161","0.001",16968849,2006,"Analysis of predictors of cardiac events in hereditary long-QT syndrome (LQTS) has primarily considered syncope as the predominant end point. Risk factors specific for aborted cardiac arrest and sudden cardiac death have not been investigated.To identify risk factors associated with aborted cardiac arrest and sudden cardiac death during adolescence in patients with clinically suspected LQTS.The study involved 2772 participants from the International Long QT Syndrome Registry who were alive at age 10 years and were followed up during adolescence until age 20 years. The registry enrollment began in 1979 at 5 cardiology centers in the United States and Europe.Aborted cardiac arrest or LQTS-related sudden cardiac death; follow-up ended on February 15, 2005.There were 81 patients who experienced aborted cardiac arrest and 45 who had sudden cardiac death; 9 of the 81 patients who had an aborted cardiac arrest event experienced subsequent sudden cardiac death. Significant independent predictors of aborted cardiac arrest or sudden cardiac death during adolescence included recent syncope, QTc interval, and sex. Compared with those with no syncopal events in the last 10 years, patients with 1 or 2 or more episodes of syncope 2 to 10 years ago (but none in the last 2 years) had an adjusted hazard ratio (HR) of 2.7; (95% confidence interval [CI], 1.3-5.7; P<.01) and an adjusted HR of 5.8 (95% CI, 3.6-9.4; P<.001), respectively, for life-threatening events; those with 1 syncopal episodes in the last 2 years had an adjusted HR of 11.7 (95% CI, 7.0-19.5; P<.001) and those with 2 or more syncopal episodes in the last 2 years had an adjusted HR of 18.1 (95% CI, 10.4-31.2; P<.001). Irrespective of events occurring more than 2 years ago, QTc of 530 ms or longer was associated with increased risk (adjusted HR, 2.3; 95% CI, 1.6-3.3; P<.001) compared with those having a shorter QTc. Males between the ages of 10 and 12 years had higher risk than females (HR, 4.0; 95% CI, 1.8-9.2; P = .001), but there was no significant risk difference between males and females between the ages of 13 and 20 years. Among individuals with syncope in the past 2 years, beta-blocker therapy was associated with a 64% reduced risk (HR, 0.36; 95% CI, 0.18-0.72; P<.01).In LQTS, the timing and frequency of syncope, QTc prolongation, and sex were predictive of risk for aborted cardiac arrest and sudden cardiac death during adolescence. Among patients with recent syncope, beta-blocker treatment was associated with reduced risk.","Risk of aborted cardiac arrest or sudden cardiac death during adolescence in the long-QT syndrome."
"709","JAMA.3171","0.001",16968849,2006,"Analysis of predictors of cardiac events in hereditary long-QT syndrome (LQTS) has primarily considered syncope as the predominant end point. Risk factors specific for aborted cardiac arrest and sudden cardiac death have not been investigated.To identify risk factors associated with aborted cardiac arrest and sudden cardiac death during adolescence in patients with clinically suspected LQTS.The study involved 2772 participants from the International Long QT Syndrome Registry who were alive at age 10 years and were followed up during adolescence until age 20 years. The registry enrollment began in 1979 at 5 cardiology centers in the United States and Europe.Aborted cardiac arrest or LQTS-related sudden cardiac death; follow-up ended on February 15, 2005.There were 81 patients who experienced aborted cardiac arrest and 45 who had sudden cardiac death; 9 of the 81 patients who had an aborted cardiac arrest event experienced subsequent sudden cardiac death. Significant independent predictors of aborted cardiac arrest or sudden cardiac death during adolescence included recent syncope, QTc interval, and sex. Compared with those with no syncopal events in the last 10 years, patients with 1 or 2 or more episodes of syncope 2 to 10 years ago (but none in the last 2 years) had an adjusted hazard ratio (HR) of 2.7; (95% confidence interval [CI], 1.3-5.7; P<.01) and an adjusted HR of 5.8 (95% CI, 3.6-9.4; P<.001), respectively, for life-threatening events; those with 1 syncopal episodes in the last 2 years had an adjusted HR of 11.7 (95% CI, 7.0-19.5; P<.001) and those with 2 or more syncopal episodes in the last 2 years had an adjusted HR of 18.1 (95% CI, 10.4-31.2; P<.001). Irrespective of events occurring more than 2 years ago, QTc of 530 ms or longer was associated with increased risk (adjusted HR, 2.3; 95% CI, 1.6-3.3; P<.001) compared with those having a shorter QTc. Males between the ages of 10 and 12 years had higher risk than females (HR, 4.0; 95% CI, 1.8-9.2; P = .001), but there was no significant risk difference between males and females between the ages of 13 and 20 years. Among individuals with syncope in the past 2 years, beta-blocker therapy was associated with a 64% reduced risk (HR, 0.36; 95% CI, 0.18-0.72; P<.01).In LQTS, the timing and frequency of syncope, QTc prolongation, and sex were predictive of risk for aborted cardiac arrest and sudden cardiac death during adolescence. Among patients with recent syncope, beta-blocker treatment was associated with reduced risk.","Risk of aborted cardiac arrest or sudden cardiac death during adolescence in the long-QT syndrome."
"710","JAMA.3181","0.01",16968849,2006,"Analysis of predictors of cardiac events in hereditary long-QT syndrome (LQTS) has primarily considered syncope as the predominant end point. Risk factors specific for aborted cardiac arrest and sudden cardiac death have not been investigated.To identify risk factors associated with aborted cardiac arrest and sudden cardiac death during adolescence in patients with clinically suspected LQTS.The study involved 2772 participants from the International Long QT Syndrome Registry who were alive at age 10 years and were followed up during adolescence until age 20 years. The registry enrollment began in 1979 at 5 cardiology centers in the United States and Europe.Aborted cardiac arrest or LQTS-related sudden cardiac death; follow-up ended on February 15, 2005.There were 81 patients who experienced aborted cardiac arrest and 45 who had sudden cardiac death; 9 of the 81 patients who had an aborted cardiac arrest event experienced subsequent sudden cardiac death. Significant independent predictors of aborted cardiac arrest or sudden cardiac death during adolescence included recent syncope, QTc interval, and sex. Compared with those with no syncopal events in the last 10 years, patients with 1 or 2 or more episodes of syncope 2 to 10 years ago (but none in the last 2 years) had an adjusted hazard ratio (HR) of 2.7; (95% confidence interval [CI], 1.3-5.7; P<.01) and an adjusted HR of 5.8 (95% CI, 3.6-9.4; P<.001), respectively, for life-threatening events; those with 1 syncopal episodes in the last 2 years had an adjusted HR of 11.7 (95% CI, 7.0-19.5; P<.001) and those with 2 or more syncopal episodes in the last 2 years had an adjusted HR of 18.1 (95% CI, 10.4-31.2; P<.001). Irrespective of events occurring more than 2 years ago, QTc of 530 ms or longer was associated with increased risk (adjusted HR, 2.3; 95% CI, 1.6-3.3; P<.001) compared with those having a shorter QTc. Males between the ages of 10 and 12 years had higher risk than females (HR, 4.0; 95% CI, 1.8-9.2; P = .001), but there was no significant risk difference between males and females between the ages of 13 and 20 years. Among individuals with syncope in the past 2 years, beta-blocker therapy was associated with a 64% reduced risk (HR, 0.36; 95% CI, 0.18-0.72; P<.01).In LQTS, the timing and frequency of syncope, QTc prolongation, and sex were predictive of risk for aborted cardiac arrest and sudden cardiac death during adolescence. Among patients with recent syncope, beta-blocker treatment was associated with reduced risk.","Risk of aborted cardiac arrest or sudden cardiac death during adolescence in the long-QT syndrome."
"711","JAMA.3321","0.001",16968849,2006,"Analysis of predictors of cardiac events in hereditary long-QT syndrome (LQTS) has primarily considered syncope as the predominant end point. Risk factors specific for aborted cardiac arrest and sudden cardiac death have not been investigated.To identify risk factors associated with aborted cardiac arrest and sudden cardiac death during adolescence in patients with clinically suspected LQTS.The study involved 2772 participants from the International Long QT Syndrome Registry who were alive at age 10 years and were followed up during adolescence until age 20 years. The registry enrollment began in 1979 at 5 cardiology centers in the United States and Europe.Aborted cardiac arrest or LQTS-related sudden cardiac death; follow-up ended on February 15, 2005.There were 81 patients who experienced aborted cardiac arrest and 45 who had sudden cardiac death; 9 of the 81 patients who had an aborted cardiac arrest event experienced subsequent sudden cardiac death. Significant independent predictors of aborted cardiac arrest or sudden cardiac death during adolescence included recent syncope, QTc interval, and sex. Compared with those with no syncopal events in the last 10 years, patients with 1 or 2 or more episodes of syncope 2 to 10 years ago (but none in the last 2 years) had an adjusted hazard ratio (HR) of 2.7; (95% confidence interval [CI], 1.3-5.7; P<.01) and an adjusted HR of 5.8 (95% CI, 3.6-9.4; P<.001), respectively, for life-threatening events; those with 1 syncopal episodes in the last 2 years had an adjusted HR of 11.7 (95% CI, 7.0-19.5; P<.001) and those with 2 or more syncopal episodes in the last 2 years had an adjusted HR of 18.1 (95% CI, 10.4-31.2; P<.001). Irrespective of events occurring more than 2 years ago, QTc of 530 ms or longer was associated with increased risk (adjusted HR, 2.3; 95% CI, 1.6-3.3; P<.001) compared with those having a shorter QTc. Males between the ages of 10 and 12 years had higher risk than females (HR, 4.0; 95% CI, 1.8-9.2; P = .001), but there was no significant risk difference between males and females between the ages of 13 and 20 years. Among individuals with syncope in the past 2 years, beta-blocker therapy was associated with a 64% reduced risk (HR, 0.36; 95% CI, 0.18-0.72; P<.01).In LQTS, the timing and frequency of syncope, QTc prolongation, and sex were predictive of risk for aborted cardiac arrest and sudden cardiac death during adolescence. Among patients with recent syncope, beta-blocker treatment was associated with reduced risk.","Risk of aborted cardiac arrest or sudden cardiac death during adolescence in the long-QT syndrome."
"712","JAMA.371","0.005",17003397,2006,"The World Health Organization developed the SAFE strategy (Surgery for trichiasis; Antibiotics for Chlamydia trachomatis infection; Facial cleanliness; and Environmental improvement) to eliminate blinding trachoma globally by the year 2020. Despite a number of studies using various intervals of treatment for different prevalence rates, there has been a lack of sufficient follow-up beyond the final treatment point to determine rates of recurrence of disease and infection and the risk factors that may contribute to each.To evaluate the impact of 2 annual targeted azithromycin treatments on active trachoma and C trachomatis infection rates over 3 years in Vietnam.Three communes were randomly selected for a longitudinal study in Vietnam from November 2000 through November 2003. Individuals (n = 3186) were graded for trachoma followed by conjunctival sampling to detect chlamydiae by commercial polymerase chain reaction. Grading and chlamydial detection were repeated every 6 months for 3 years.Azithromycin was given to children aged 5 through 15 years with active trachoma and their household members in SAFE and SA communes at baseline and 12 months; these communes were compared with the S-only control commune that did not receive azithromycin targeted treatment.Prevalence and incidence of active trachoma and C trachomatis infection in all communes at baseline, 6, 12, 18, 24, and 36 months. Subgroup analysis evaluated new infection, continuing infection, and reinfection at 6, 12, 18, 24, and 36 months and risk factors for each.Reinfection rates increased significantly between 12 and 36 months for SAFE (from 1.6 to 29.3 per 1000; P<.001) and SA (5.1 to 25.3 per 1000; P = .002) communes but not for the S-only commune (13.4 to 6.7 per 1000; P = .55) after 24 months. Compared with the S-only commune, mixed-effects and generalized estimating equations (GEE) logistic models showed that reinfection risk was significantly higher for SAFE (odds ratio [OR], 4.1; 95% confidence interval [CI], 1.5-9.8; P = .005) and SA (OR, 4.2; 95% CI, 1.1-17.3; P = .04) communes at 36 months.Increasing reinfection rates suggest that treatment may interrupt the duration of infection required for developing immunity, increasing the number of individuals susceptible to reinfection and adversely affecting disease prevalence over time. Additional research is needed to determine optimal trachoma control strategies, including evaluation of the ""F"" and ""E"" components.www.actr.org.au Identifier: 12606000360516.","Impact of annual targeted treatment on infectious trachoma and susceptibility to reinfection."
"713","JAMA.372","0.04",17003397,2006,"The World Health Organization developed the SAFE strategy (Surgery for trichiasis; Antibiotics for Chlamydia trachomatis infection; Facial cleanliness; and Environmental improvement) to eliminate blinding trachoma globally by the year 2020. Despite a number of studies using various intervals of treatment for different prevalence rates, there has been a lack of sufficient follow-up beyond the final treatment point to determine rates of recurrence of disease and infection and the risk factors that may contribute to each.To evaluate the impact of 2 annual targeted azithromycin treatments on active trachoma and C trachomatis infection rates over 3 years in Vietnam.Three communes were randomly selected for a longitudinal study in Vietnam from November 2000 through November 2003. Individuals (n = 3186) were graded for trachoma followed by conjunctival sampling to detect chlamydiae by commercial polymerase chain reaction. Grading and chlamydial detection were repeated every 6 months for 3 years.Azithromycin was given to children aged 5 through 15 years with active trachoma and their household members in SAFE and SA communes at baseline and 12 months; these communes were compared with the S-only control commune that did not receive azithromycin targeted treatment.Prevalence and incidence of active trachoma and C trachomatis infection in all communes at baseline, 6, 12, 18, 24, and 36 months. Subgroup analysis evaluated new infection, continuing infection, and reinfection at 6, 12, 18, 24, and 36 months and risk factors for each.Reinfection rates increased significantly between 12 and 36 months for SAFE (from 1.6 to 29.3 per 1000; P<.001) and SA (5.1 to 25.3 per 1000; P = .002) communes but not for the S-only commune (13.4 to 6.7 per 1000; P = .55) after 24 months. Compared with the S-only commune, mixed-effects and generalized estimating equations (GEE) logistic models showed that reinfection risk was significantly higher for SAFE (odds ratio [OR], 4.1; 95% confidence interval [CI], 1.5-9.8; P = .005) and SA (OR, 4.2; 95% CI, 1.1-17.3; P = .04) communes at 36 months.Increasing reinfection rates suggest that treatment may interrupt the duration of infection required for developing immunity, increasing the number of individuals susceptible to reinfection and adversely affecting disease prevalence over time. Additional research is needed to determine optimal trachoma control strategies, including evaluation of the ""F"" and ""E"" components.www.actr.org.au Identifier: 12606000360516.","Impact of annual targeted treatment on infectious trachoma and susceptibility to reinfection."
"714","Lancet.621","0.01",17011942,2006,"Evidence-based treatment for hypercholesterolaemia in Japan has been hindered by the lack of direct evidence in this population. Our aim was to assess whether evidence for treatment with statins derived from western populations can be extrapolated to the Japanese population.In this prospective, randomised, open-labelled, blinded study, patients with hypercholesterolaemia (total cholesterol 5.69-6.98 mmol/L) and no history of coronary heart disease or stroke were randomly assigned diet or diet plus 10-20 mg pravastatin daily. The primary endpoint was the first occurrence of coronary heart disease. Statistical analyses were done by intention to treat. This trial is registered at ClinicalTrials.gov, number NCT00211705.3966 patients were randomly assigned to the diet group and 3866 to the diet plus pravastatin group. Mean follow-up was 5.3 years. At the end of study, 471 and 522 patients had withdrawn, died, or been lost to follow-up in the diet and diet plus pravastatin groups, respectively. Mean total cholesterol was reduced by 2.1% (from 6.27 mmol/L to 6.13 mmol/L) and 11.5% (from 6.27 mmol/L to 5.55 mmol/L) and mean LDL cholesterol by 3.2% (from 4.05 mmol/L to 3.90 mmol/L) and 18.0% (from 4.05 mmol/L to 3.31 mmol/L) in the diet and the diet plus pravastatin groups, respectively. Coronary heart disease was significantly lower in the diet plus pravastatin group than in the diet alone group (66 events vs 101 events; HR 0.67, 95% CI 0.49-0.91; p=0.01). There was no difference in the incidence of malignant neoplasms or other serious adverse events between the two groups.Treatment with a low dose of pravastatin reduces the risk of coronary heart disease in Japan by much the same amount as higher doses have shown in Europe and the USA.","Primary prevention of cardiovascular disease with pravastatin in Japan (MEGA Study): a prospective randomised controlled trial."
"715","JAMA.339","0.001",17018806,2006,"Polymorphisms in the serotonin transporter gene (5-HTT) may influence antidepressant response to selective serotonin reuptake inhibitors (SSRIs). The norepinephrine transporter (NET) is the analogous target for norepinephrine reuptake inhibitors (NRIs).To determine whether antidepressant responses to SSRIs or NRIs are associated with genetic polymorphisms of the corresponding monoamine transporters.A 6-week naturalistic treatment study with blinded outcome evaluation of 241 Korean inpatients and outpatients with major depression at an academic psychiatry service. Patients were recruited to the study from March 1998 through February 2003.Treatment with an SSRI (fluoxetine or sertraline; n = 136) or an NRI (nortriptyline; n = 105) antidepressant. Adherence was assessed by measuring plasma concentration at 4 weeks. Patients were genotyped for s/l polymorphisms in 5-HTT promoter region (5-HTTLPR), 5-HTT intron 2 s/l variation, and NET G1287A variation of exon 9.An SSRI and NRI response (defined as > or =50% decrease in Hamilton Rating Scale for Depression score at 6 weeks).NRI response was associated with the NET G1287A polymorphism (odds ratio [OR], 7.54; 95% confidence interval [CI], 2.53-22.49; P<.001). An SSRI response was associated with the 5-HTT intron 2 s/l variation (OR, 20.11; 95% CI, 4.27-94.74; P<.001). The 5-HTTLPR was also associated with an SSRI response (OR, 3.34; 95% CI, 1.41-7.91; P = .006). In contrast to studies in white patients, the favorable allele for SSRI response was S 5-HTTLPR. The S 5-HTTLPR was associated also with NRI response (OR, 3.73; 95% CI, 1.32-10.53; P = .01). The NET polymorphism was not associated with an SSRI response. The NET G1287A GG genotype (56% of the population) was associated with better response to the NRI (83.3% [35/42]) than to SSRI (58.7% [44/75]) (OR, 3.52; 95% CI, 1.39-8.95; P = .006). Some genotype combinations were associated with high rates of antidepressant response and others with low rates of response.Monoamine transporter gene polymorphisms were associated with response to antidepressants with homologous monoamine transporter targets. Combinations of polymorphisms were informative for response and nonresponse. Confirmation of these preliminary findings would permit refined pharmacogenetic selection of antidepressant treatment.","Monoamine transporter gene polymorphisms and antidepressant response in koreans with late-life depression."
"716","JAMA.340","0.001",17018806,2006,"Polymorphisms in the serotonin transporter gene (5-HTT) may influence antidepressant response to selective serotonin reuptake inhibitors (SSRIs). The norepinephrine transporter (NET) is the analogous target for norepinephrine reuptake inhibitors (NRIs).To determine whether antidepressant responses to SSRIs or NRIs are associated with genetic polymorphisms of the corresponding monoamine transporters.A 6-week naturalistic treatment study with blinded outcome evaluation of 241 Korean inpatients and outpatients with major depression at an academic psychiatry service. Patients were recruited to the study from March 1998 through February 2003.Treatment with an SSRI (fluoxetine or sertraline; n = 136) or an NRI (nortriptyline; n = 105) antidepressant. Adherence was assessed by measuring plasma concentration at 4 weeks. Patients were genotyped for s/l polymorphisms in 5-HTT promoter region (5-HTTLPR), 5-HTT intron 2 s/l variation, and NET G1287A variation of exon 9.An SSRI and NRI response (defined as > or =50% decrease in Hamilton Rating Scale for Depression score at 6 weeks).NRI response was associated with the NET G1287A polymorphism (odds ratio [OR], 7.54; 95% confidence interval [CI], 2.53-22.49; P<.001). An SSRI response was associated with the 5-HTT intron 2 s/l variation (OR, 20.11; 95% CI, 4.27-94.74; P<.001). The 5-HTTLPR was also associated with an SSRI response (OR, 3.34; 95% CI, 1.41-7.91; P = .006). In contrast to studies in white patients, the favorable allele for SSRI response was S 5-HTTLPR. The S 5-HTTLPR was associated also with NRI response (OR, 3.73; 95% CI, 1.32-10.53; P = .01). The NET polymorphism was not associated with an SSRI response. The NET G1287A GG genotype (56% of the population) was associated with better response to the NRI (83.3% [35/42]) than to SSRI (58.7% [44/75]) (OR, 3.52; 95% CI, 1.39-8.95; P = .006). Some genotype combinations were associated with high rates of antidepressant response and others with low rates of response.Monoamine transporter gene polymorphisms were associated with response to antidepressants with homologous monoamine transporter targets. Combinations of polymorphisms were informative for response and nonresponse. Confirmation of these preliminary findings would permit refined pharmacogenetic selection of antidepressant treatment.","Monoamine transporter gene polymorphisms and antidepressant response in koreans with late-life depression."
"717","JAMA.366","0.006",17018806,2006,"Polymorphisms in the serotonin transporter gene (5-HTT) may influence antidepressant response to selective serotonin reuptake inhibitors (SSRIs). The norepinephrine transporter (NET) is the analogous target for norepinephrine reuptake inhibitors (NRIs).To determine whether antidepressant responses to SSRIs or NRIs are associated with genetic polymorphisms of the corresponding monoamine transporters.A 6-week naturalistic treatment study with blinded outcome evaluation of 241 Korean inpatients and outpatients with major depression at an academic psychiatry service. Patients were recruited to the study from March 1998 through February 2003.Treatment with an SSRI (fluoxetine or sertraline; n = 136) or an NRI (nortriptyline; n = 105) antidepressant. Adherence was assessed by measuring plasma concentration at 4 weeks. Patients were genotyped for s/l polymorphisms in 5-HTT promoter region (5-HTTLPR), 5-HTT intron 2 s/l variation, and NET G1287A variation of exon 9.An SSRI and NRI response (defined as > or =50% decrease in Hamilton Rating Scale for Depression score at 6 weeks).NRI response was associated with the NET G1287A polymorphism (odds ratio [OR], 7.54; 95% confidence interval [CI], 2.53-22.49; P<.001). An SSRI response was associated with the 5-HTT intron 2 s/l variation (OR, 20.11; 95% CI, 4.27-94.74; P<.001). The 5-HTTLPR was also associated with an SSRI response (OR, 3.34; 95% CI, 1.41-7.91; P = .006). In contrast to studies in white patients, the favorable allele for SSRI response was S 5-HTTLPR. The S 5-HTTLPR was associated also with NRI response (OR, 3.73; 95% CI, 1.32-10.53; P = .01). The NET polymorphism was not associated with an SSRI response. The NET G1287A GG genotype (56% of the population) was associated with better response to the NRI (83.3% [35/42]) than to SSRI (58.7% [44/75]) (OR, 3.52; 95% CI, 1.39-8.95; P = .006). Some genotype combinations were associated with high rates of antidepressant response and others with low rates of response.Monoamine transporter gene polymorphisms were associated with response to antidepressants with homologous monoamine transporter targets. Combinations of polymorphisms were informative for response and nonresponse. Confirmation of these preliminary findings would permit refined pharmacogenetic selection of antidepressant treatment.","Monoamine transporter gene polymorphisms and antidepressant response in koreans with late-life depression."
"718","JAMA.367","0.01",17018806,2006,"Polymorphisms in the serotonin transporter gene (5-HTT) may influence antidepressant response to selective serotonin reuptake inhibitors (SSRIs). The norepinephrine transporter (NET) is the analogous target for norepinephrine reuptake inhibitors (NRIs).To determine whether antidepressant responses to SSRIs or NRIs are associated with genetic polymorphisms of the corresponding monoamine transporters.A 6-week naturalistic treatment study with blinded outcome evaluation of 241 Korean inpatients and outpatients with major depression at an academic psychiatry service. Patients were recruited to the study from March 1998 through February 2003.Treatment with an SSRI (fluoxetine or sertraline; n = 136) or an NRI (nortriptyline; n = 105) antidepressant. Adherence was assessed by measuring plasma concentration at 4 weeks. Patients were genotyped for s/l polymorphisms in 5-HTT promoter region (5-HTTLPR), 5-HTT intron 2 s/l variation, and NET G1287A variation of exon 9.An SSRI and NRI response (defined as > or =50% decrease in Hamilton Rating Scale for Depression score at 6 weeks).NRI response was associated with the NET G1287A polymorphism (odds ratio [OR], 7.54; 95% confidence interval [CI], 2.53-22.49; P<.001). An SSRI response was associated with the 5-HTT intron 2 s/l variation (OR, 20.11; 95% CI, 4.27-94.74; P<.001). The 5-HTTLPR was also associated with an SSRI response (OR, 3.34; 95% CI, 1.41-7.91; P = .006). In contrast to studies in white patients, the favorable allele for SSRI response was S 5-HTTLPR. The S 5-HTTLPR was associated also with NRI response (OR, 3.73; 95% CI, 1.32-10.53; P = .01). The NET polymorphism was not associated with an SSRI response. The NET G1287A GG genotype (56% of the population) was associated with better response to the NRI (83.3% [35/42]) than to SSRI (58.7% [44/75]) (OR, 3.52; 95% CI, 1.39-8.95; P = .006). Some genotype combinations were associated with high rates of antidepressant response and others with low rates of response.Monoamine transporter gene polymorphisms were associated with response to antidepressants with homologous monoamine transporter targets. Combinations of polymorphisms were informative for response and nonresponse. Confirmation of these preliminary findings would permit refined pharmacogenetic selection of antidepressant treatment.","Monoamine transporter gene polymorphisms and antidepressant response in koreans with late-life depression."
"719","JAMA.368","0.006",17018806,2006,"Polymorphisms in the serotonin transporter gene (5-HTT) may influence antidepressant response to selective serotonin reuptake inhibitors (SSRIs). The norepinephrine transporter (NET) is the analogous target for norepinephrine reuptake inhibitors (NRIs).To determine whether antidepressant responses to SSRIs or NRIs are associated with genetic polymorphisms of the corresponding monoamine transporters.A 6-week naturalistic treatment study with blinded outcome evaluation of 241 Korean inpatients and outpatients with major depression at an academic psychiatry service. Patients were recruited to the study from March 1998 through February 2003.Treatment with an SSRI (fluoxetine or sertraline; n = 136) or an NRI (nortriptyline; n = 105) antidepressant. Adherence was assessed by measuring plasma concentration at 4 weeks. Patients were genotyped for s/l polymorphisms in 5-HTT promoter region (5-HTTLPR), 5-HTT intron 2 s/l variation, and NET G1287A variation of exon 9.An SSRI and NRI response (defined as > or =50% decrease in Hamilton Rating Scale for Depression score at 6 weeks).NRI response was associated with the NET G1287A polymorphism (odds ratio [OR], 7.54; 95% confidence interval [CI], 2.53-22.49; P<.001). An SSRI response was associated with the 5-HTT intron 2 s/l variation (OR, 20.11; 95% CI, 4.27-94.74; P<.001). The 5-HTTLPR was also associated with an SSRI response (OR, 3.34; 95% CI, 1.41-7.91; P = .006). In contrast to studies in white patients, the favorable allele for SSRI response was S 5-HTTLPR. The S 5-HTTLPR was associated also with NRI response (OR, 3.73; 95% CI, 1.32-10.53; P = .01). The NET polymorphism was not associated with an SSRI response. The NET G1287A GG genotype (56% of the population) was associated with better response to the NRI (83.3% [35/42]) than to SSRI (58.7% [44/75]) (OR, 3.52; 95% CI, 1.39-8.95; P = .006). Some genotype combinations were associated with high rates of antidepressant response and others with low rates of response.Monoamine transporter gene polymorphisms were associated with response to antidepressants with homologous monoamine transporter targets. Combinations of polymorphisms were informative for response and nonresponse. Confirmation of these preliminary findings would permit refined pharmacogenetic selection of antidepressant treatment.","Monoamine transporter gene polymorphisms and antidepressant response in koreans with late-life depression."
"720","Lancet.44","0.02",17046466,2006,"6-mercaptopurine has been a standard component of long-term continuing treatment for childhood lymphoblastic leukaemia, whereas 6-thioguanine has been mainly used for intensification courses. Since preliminary data have shown that 6-thioguanine is more effective than 6-mercaptopurine, we compared the efficacy and toxicity of the two drugs for childhood lymphoblastic leukaemia.Consecutive children with lymphoblastic leukaemia diagnosed in the UK and Ireland between April, 1997, and June, 2002, were randomly assigned either 6-thioguanine (750 patients) or 6-mercaptopurine (748 patients) during interim maintenance and continuing therapy. All patients received 6-thioguanine during intensification courses. We analysed event-free and overall survival on an intention-to-treat basis. We obtained toxicity data using an adverse-event reporting system, with follow-up questionnaires to seek detailed information for specific toxicities. This trial is registered with the International Standard Randomised Controlled Number 26727615 with the name ALL97.After a median follow up of 6 years, there was no difference in event-free or overall survival between the two treatment groups. Although 6-thioguanine conferred a significantly lower risk of isolated CNS relapse than did 6-mercaptopurine (odds ratio [OR] 0.53, 95% CI 0.30-0.92, p=0.02), the benefit was offset by an increased risk of death in remission (2.22, 1.20-4.14, p=0.01), mainly due to infections during continuing therapy. Additionally, 95 patients developed veno-occlusive disease of the liver. Of these, 82 were randomly assigned 6-thioguanine, representing 11% of all 6-thioguanine recipients. On long-term follow-up, about 5% of 6-thioguanine recipients have evidence of non-cirrhotic portal hypertension due to periportal liver fibrosis or nodular regenerative hyperplasia.Compared with 6-mercaptopurine, 6-thioguanine causes excess toxicity without an overall benefit. 6-mercaptopurine should remain the thiopurine of choice for continuing therapy of childhood lymphoblastic leukaemia.","Toxicity and efficacy of 6-thioguanine versus 6-mercaptopurine in childhood lymphoblastic leukaemia: a randomised trial."
"721","Lancet.45","0.01",17046466,2006,"6-mercaptopurine has been a standard component of long-term continuing treatment for childhood lymphoblastic leukaemia, whereas 6-thioguanine has been mainly used for intensification courses. Since preliminary data have shown that 6-thioguanine is more effective than 6-mercaptopurine, we compared the efficacy and toxicity of the two drugs for childhood lymphoblastic leukaemia.Consecutive children with lymphoblastic leukaemia diagnosed in the UK and Ireland between April, 1997, and June, 2002, were randomly assigned either 6-thioguanine (750 patients) or 6-mercaptopurine (748 patients) during interim maintenance and continuing therapy. All patients received 6-thioguanine during intensification courses. We analysed event-free and overall survival on an intention-to-treat basis. We obtained toxicity data using an adverse-event reporting system, with follow-up questionnaires to seek detailed information for specific toxicities. This trial is registered with the International Standard Randomised Controlled Number 26727615 with the name ALL97.After a median follow up of 6 years, there was no difference in event-free or overall survival between the two treatment groups. Although 6-thioguanine conferred a significantly lower risk of isolated CNS relapse than did 6-mercaptopurine (odds ratio [OR] 0.53, 95% CI 0.30-0.92, p=0.02), the benefit was offset by an increased risk of death in remission (2.22, 1.20-4.14, p=0.01), mainly due to infections during continuing therapy. Additionally, 95 patients developed veno-occlusive disease of the liver. Of these, 82 were randomly assigned 6-thioguanine, representing 11% of all 6-thioguanine recipients. On long-term follow-up, about 5% of 6-thioguanine recipients have evidence of non-cirrhotic portal hypertension due to periportal liver fibrosis or nodular regenerative hyperplasia.Compared with 6-mercaptopurine, 6-thioguanine causes excess toxicity without an overall benefit. 6-mercaptopurine should remain the thiopurine of choice for continuing therapy of childhood lymphoblastic leukaemia.","Toxicity and efficacy of 6-thioguanine versus 6-mercaptopurine in childhood lymphoblastic leukaemia: a randomised trial."
"722","JAMA.3091","0.001",17090769,2006,"Pneumatic dilatation and surgical (Heller) myotomy are the 2 principal methods for treatment of achalasia. There are no population-based studies comparing outcomes of these 2 treatments in typical practice settings.To compare the outcomes of pneumatic dilatation and surgical myotomy for achalasia.Retrospective longitudinal study using linked administrative health data in Ontario. A total of 1461 persons aged 18 years or older received treatment for achalasia between July 1991 and December 2002, 1181 (80.8%) of whom had pneumatic dilatation and 280 (19.2%) of whom had surgical myotomy as the first procedure.Use of subsequent interventions for achalasia (pneumatic dilatation, surgical myotomy, or esophagectomy) following the first treatment during the study period, subsequent physician visits, and use of gastrointestinal medications among persons aged 65 years or older. We adjusted for confounding variables using regression models.The cumulative risk of any subsequent intervention for achalasia after 1, 5, and 10 years, respectively, was 36.8%, 56.2%, and 63.5% for persons treated initially with pneumatic dilatation and was 16.4%, 30.3%, and 37.5% for persons treated initially with surgical myotomy (adjusted hazard ratio [HR], 2.37; 95% confidence interval [CI], 1.86-3.02; P<.001). Differences in risk were observed only when subsequent pneumatic dilatation was included as an adverse outcome; there was no statistical difference between the 2 groups with respect to the risk of subsequent surgical myotomy or esophagectomy. Compared with persons treated initially with surgical myotomy, those treated with pneumatic dilatation were not statistically different with respect to subsequent physician visits (adjusted rate ratio, 1.01; 95% CI, 1.00-1.03), or time to use of histamine-2 receptor blockers (adjusted HR, 1.19; 95% CI, 0.79-1.80), proton pump inhibitors (HR, 1.02; 95% CI, 0.70-1.49), and prokinetic medications (HR, 0.92; 95% CI, 0.60-1.41).Subsequent intervention after the initial treatment of achalasia is common. Although the risk of subsequent interventions among persons treated with surgical myotomy in typical practice settings is higher than previously thought, the risk of subsequent intervention is greater among persons treated with pneumatic dilatation than with surgical myotomy. This difference is attributable to the use of subsequent pneumatic dilatation rather than surgical procedures.","Pneumatic dilatation and surgical myotomy for achalasia."
"723","JAMA.3081","0.001",17105795,2006,"Despite a stage-shift to earlier cancer stages and lower tumor volumes for prostate cancer, pathologically advanced disease is detected at radical prostatectomy in 38% to 52% of patients. However, the optimal management of these patients after radical prostatectomy is unknown.To determine whether adjuvant radiotherapy improves metastasis-free survival in patients with stage pT3 N0 M0 prostate cancer.Randomized, prospective, multi-institutional, US clinical trial with enrollment between August 15, 1988, and January 1, 1997 (with database frozen for statistical analysis on September 21, 2005). Patients were 425 men with pathologically advanced prostate cancer who had undergone radical prostatectomy.Men were randomly assigned to receive 60 to 64 Gy of external beam radiotherapy delivered to the prostatic fossa (n = 214) or usual care plus observation (n = 211).Primary outcome was metastasis-free survival, defined as time to first occurrence of metastatic disease or death due to any cause. Secondary outcomes included prostate-specific antigen (PSA) relapse, recurrence-free survival, overall survival, freedom from hormonal therapy, and postoperative complications.Among the 425 men, median follow-up was 10.6 years (interquartile range, 9.2-12.7 years). For metastasis-free survival, 76 (35.5%) of 214 men in the adjuvant radiotherapy group were diagnosed with metastatic disease or died (median metastasis-free estimate, 14.7 years), compared with 91 (43.1%) of 211 (median metastasis-free estimate, 13.2 years) of those in the observation group (hazard ratio [HR], 0.75; 95% CI, 0.55-1.02; P = .06). There were no significant between-group differences for overall survival (71 deaths, median survival of 14.7 years for radiotherapy vs 83 deaths, median survival of 13.8 years for observation; HR, 0.80; 95% CI, 0.58-1.09; P = .16). PSA relapse (median PSA relapse-free survival, 10.3 years for radiotherapy vs 3.1 years for observation; HR, 0.43; 95% CI, 0.31-0.58; P<.001) and disease recurrence (median recurrence-free survival, 13.8 years for radiotherapy vs 9.9 years for observation; HR, 0.62; 95% CI, 0.46-0.82; P = .001) were both significantly reduced with radiotherapy. Adverse effects were more common with radiotherapy vs observation (23.8% vs 11.9%), including rectal complications (3.3% vs 0%), urethral strictures (17.8% vs 9.5%), and total urinary incontinence (6.5% vs 2.8%).In men who had undergone radical prostatectomy for pathologically advanced prostate cancer, adjuvant radiotherapy resulted in significantly reduced risk of PSA relapse and disease recurrence, although the improvements in metastasis-free survival and overall survival were not statistically significant. Trial Registration clinicaltrials.gov Identifier: NCT00394511.","Adjuvant radiotherapy for pathologically advanced prostate cancer: a randomized clinical trial."
"724","JAMA.3291","0.06",17105795,2006,"Despite a stage-shift to earlier cancer stages and lower tumor volumes for prostate cancer, pathologically advanced disease is detected at radical prostatectomy in 38% to 52% of patients. However, the optimal management of these patients after radical prostatectomy is unknown.To determine whether adjuvant radiotherapy improves metastasis-free survival in patients with stage pT3 N0 M0 prostate cancer.Randomized, prospective, multi-institutional, US clinical trial with enrollment between August 15, 1988, and January 1, 1997 (with database frozen for statistical analysis on September 21, 2005). Patients were 425 men with pathologically advanced prostate cancer who had undergone radical prostatectomy.Men were randomly assigned to receive 60 to 64 Gy of external beam radiotherapy delivered to the prostatic fossa (n = 214) or usual care plus observation (n = 211).Primary outcome was metastasis-free survival, defined as time to first occurrence of metastatic disease or death due to any cause. Secondary outcomes included prostate-specific antigen (PSA) relapse, recurrence-free survival, overall survival, freedom from hormonal therapy, and postoperative complications.Among the 425 men, median follow-up was 10.6 years (interquartile range, 9.2-12.7 years). For metastasis-free survival, 76 (35.5%) of 214 men in the adjuvant radiotherapy group were diagnosed with metastatic disease or died (median metastasis-free estimate, 14.7 years), compared with 91 (43.1%) of 211 (median metastasis-free estimate, 13.2 years) of those in the observation group (hazard ratio [HR], 0.75; 95% CI, 0.55-1.02; P = .06). There were no significant between-group differences for overall survival (71 deaths, median survival of 14.7 years for radiotherapy vs 83 deaths, median survival of 13.8 years for observation; HR, 0.80; 95% CI, 0.58-1.09; P = .16). PSA relapse (median PSA relapse-free survival, 10.3 years for radiotherapy vs 3.1 years for observation; HR, 0.43; 95% CI, 0.31-0.58; P<.001) and disease recurrence (median recurrence-free survival, 13.8 years for radiotherapy vs 9.9 years for observation; HR, 0.62; 95% CI, 0.46-0.82; P = .001) were both significantly reduced with radiotherapy. Adverse effects were more common with radiotherapy vs observation (23.8% vs 11.9%), including rectal complications (3.3% vs 0%), urethral strictures (17.8% vs 9.5%), and total urinary incontinence (6.5% vs 2.8%).In men who had undergone radical prostatectomy for pathologically advanced prostate cancer, adjuvant radiotherapy resulted in significantly reduced risk of PSA relapse and disease recurrence, although the improvements in metastasis-free survival and overall survival were not statistically significant. Trial Registration clinicaltrials.gov Identifier: NCT00394511.","Adjuvant radiotherapy for pathologically advanced prostate cancer: a randomized clinical trial."
"725","JAMA.3301","0.16",17105795,2006,"Despite a stage-shift to earlier cancer stages and lower tumor volumes for prostate cancer, pathologically advanced disease is detected at radical prostatectomy in 38% to 52% of patients. However, the optimal management of these patients after radical prostatectomy is unknown.To determine whether adjuvant radiotherapy improves metastasis-free survival in patients with stage pT3 N0 M0 prostate cancer.Randomized, prospective, multi-institutional, US clinical trial with enrollment between August 15, 1988, and January 1, 1997 (with database frozen for statistical analysis on September 21, 2005). Patients were 425 men with pathologically advanced prostate cancer who had undergone radical prostatectomy.Men were randomly assigned to receive 60 to 64 Gy of external beam radiotherapy delivered to the prostatic fossa (n = 214) or usual care plus observation (n = 211).Primary outcome was metastasis-free survival, defined as time to first occurrence of metastatic disease or death due to any cause. Secondary outcomes included prostate-specific antigen (PSA) relapse, recurrence-free survival, overall survival, freedom from hormonal therapy, and postoperative complications.Among the 425 men, median follow-up was 10.6 years (interquartile range, 9.2-12.7 years). For metastasis-free survival, 76 (35.5%) of 214 men in the adjuvant radiotherapy group were diagnosed with metastatic disease or died (median metastasis-free estimate, 14.7 years), compared with 91 (43.1%) of 211 (median metastasis-free estimate, 13.2 years) of those in the observation group (hazard ratio [HR], 0.75; 95% CI, 0.55-1.02; P = .06). There were no significant between-group differences for overall survival (71 deaths, median survival of 14.7 years for radiotherapy vs 83 deaths, median survival of 13.8 years for observation; HR, 0.80; 95% CI, 0.58-1.09; P = .16). PSA relapse (median PSA relapse-free survival, 10.3 years for radiotherapy vs 3.1 years for observation; HR, 0.43; 95% CI, 0.31-0.58; P<.001) and disease recurrence (median recurrence-free survival, 13.8 years for radiotherapy vs 9.9 years for observation; HR, 0.62; 95% CI, 0.46-0.82; P = .001) were both significantly reduced with radiotherapy. Adverse effects were more common with radiotherapy vs observation (23.8% vs 11.9%), including rectal complications (3.3% vs 0%), urethral strictures (17.8% vs 9.5%), and total urinary incontinence (6.5% vs 2.8%).In men who had undergone radical prostatectomy for pathologically advanced prostate cancer, adjuvant radiotherapy resulted in significantly reduced risk of PSA relapse and disease recurrence, although the improvements in metastasis-free survival and overall survival were not statistically significant. Trial Registration clinicaltrials.gov Identifier: NCT00394511.","Adjuvant radiotherapy for pathologically advanced prostate cancer: a randomized clinical trial."
"726","JAMA.3311","0.001",17105795,2006,"Despite a stage-shift to earlier cancer stages and lower tumor volumes for prostate cancer, pathologically advanced disease is detected at radical prostatectomy in 38% to 52% of patients. However, the optimal management of these patients after radical prostatectomy is unknown.To determine whether adjuvant radiotherapy improves metastasis-free survival in patients with stage pT3 N0 M0 prostate cancer.Randomized, prospective, multi-institutional, US clinical trial with enrollment between August 15, 1988, and January 1, 1997 (with database frozen for statistical analysis on September 21, 2005). Patients were 425 men with pathologically advanced prostate cancer who had undergone radical prostatectomy.Men were randomly assigned to receive 60 to 64 Gy of external beam radiotherapy delivered to the prostatic fossa (n = 214) or usual care plus observation (n = 211).Primary outcome was metastasis-free survival, defined as time to first occurrence of metastatic disease or death due to any cause. Secondary outcomes included prostate-specific antigen (PSA) relapse, recurrence-free survival, overall survival, freedom from hormonal therapy, and postoperative complications.Among the 425 men, median follow-up was 10.6 years (interquartile range, 9.2-12.7 years). For metastasis-free survival, 76 (35.5%) of 214 men in the adjuvant radiotherapy group were diagnosed with metastatic disease or died (median metastasis-free estimate, 14.7 years), compared with 91 (43.1%) of 211 (median metastasis-free estimate, 13.2 years) of those in the observation group (hazard ratio [HR], 0.75; 95% CI, 0.55-1.02; P = .06). There were no significant between-group differences for overall survival (71 deaths, median survival of 14.7 years for radiotherapy vs 83 deaths, median survival of 13.8 years for observation; HR, 0.80; 95% CI, 0.58-1.09; P = .16). PSA relapse (median PSA relapse-free survival, 10.3 years for radiotherapy vs 3.1 years for observation; HR, 0.43; 95% CI, 0.31-0.58; P<.001) and disease recurrence (median recurrence-free survival, 13.8 years for radiotherapy vs 9.9 years for observation; HR, 0.62; 95% CI, 0.46-0.82; P = .001) were both significantly reduced with radiotherapy. Adverse effects were more common with radiotherapy vs observation (23.8% vs 11.9%), including rectal complications (3.3% vs 0%), urethral strictures (17.8% vs 9.5%), and total urinary incontinence (6.5% vs 2.8%).In men who had undergone radical prostatectomy for pathologically advanced prostate cancer, adjuvant radiotherapy resulted in significantly reduced risk of PSA relapse and disease recurrence, although the improvements in metastasis-free survival and overall survival were not statistically significant. Trial Registration clinicaltrials.gov Identifier: NCT00394511.","Adjuvant radiotherapy for pathologically advanced prostate cancer: a randomized clinical trial."
"727","Lancet.43","0.94",17126719,2006,"Intravenous tissue plasminogen activator is the only approved specific treatment for acute ischaemic stroke. Ancrod, a natural defibrinogenating agent from snake venom, has proved to have a favourable effect when given within 3 h after an acute ischaemic stroke. The European Stroke Treatment with Ancrod Trial was undertaken to assess the effects of ancrod when given within 6 h.1222 patients with an acute ischaemic stroke were included in this randomised double-blind placebo-controlled trial. Brain CT scans were done to exclude intracranial haemorrhages and large evolving ischaemic infarctions. Patients were randomly assigned ancrod (n=604) or placebo (n=618). The primary outcome was functional success at 3 months (survival, Barthel Index of 95 or 100, or return to prestroke level). The analysis was by intention-to-treat. This trial is registered with ClinicalTrials.gov, trial number NCT00343174.Functional success at 3 months did not differ between patients given ancrod (42%) and those given placebo (42%) (p=0.94, OR=0.99, 95% CI, 0.76-1.29).On the basis of our findings, ancrod should not be recommended for use in acute ischaemic stroke beyond 3 h.","Intravenous ancrod for acute ischaemic stroke in the European Stroke Treatment with Ancrod Trial: a randomised controlled trial."
"728","Lancet.581","1.00E-04",17174704,2006,"Long-term data from randomised trials on the consequences of treatment with a protease inhibitor (PI), non-nucleoside reverse transcriptase inhibitor (NNRTI), or both are lacking. Here, we report results from the FIRST trial, which compared initial treatment strategies for clinical, immunological, and virological outcomes.Between 1999 and 2002, 1397 antiretroviral-treatment-naive patients, presenting at 18 clinical trial units with 80 research sites in the USA, were randomly assigned in a ratio of 1:1:1 to a protease inhibitor (PI) strategy (PI plus nucleoside reverse transcriptase inhibitor [NRTI]; n=470), a non-nucleoside reverse transcriptase inhibitor (NNRTI) strategy (NNRTI plus NRTI; n=463), or a three-class strategy (PI plus NNRTI plus NRTI; n=464). Primary endpoints were a composite of an AIDS-defining event, death, or CD4 cell count decline to less than 200 cells per mm3 for the PI versus NNRTI comparison, and average change in CD4 cell count at or after 32 months for the three-class versus combined two-class comparison. Analyses were by intention-to-treat. This study is registered ClinicalTrials.gov, number NCT00000922.1397 patients were assessed for the composite endpoint. A total of 388 participants developed the composite endpoint, 302 developed AIDS or died, and 188 died. NNRTI versus PI hazard ratios ","A comparison of three highly active antiretroviral treatment strategies consisting of non-nucleoside reverse transcriptase inhibitors, protease inhibitors, or both in the presence of nucleoside reverse transcriptase inhibitors as initial therapy (CPCRA 058 FIRST Study): a long-term randomised trial."
"729","JAMA.364","0.006",17179460,2006,"Epidemiological and experimental evidence suggests that high levels of vitamin D, a potent immunomodulator, may decrease the risk of multiple sclerosis. There are no prospective studies addressing this hypothesis.To examine whether levels of 25-hydroxyvitamin D are associated with risk of multiple sclerosis.Prospective, nested case-control study among more than 7 million US military personnel who have serum samples stored in the Department of Defense Serum Repository. Multiple sclerosis cases were identified through Army and Navy physical disability databases for 1992 through 2004, and diagnoses were confirmed by medical record review. Each case (n = 257) was matched to 2 controls by age, sex, race/ethnicity, and dates of blood collection. Vitamin D status was estimated by averaging 25-hydroxyvitamin D levels of 2 or more serum samples collected before the date of initial multiple sclerosis symptoms.Odds ratios of multiple sclerosis associated with continuous or categorical levels (quantiles or a priori-defined categories) of serum 25-hydroxyvitamin D within each racial/ethnic group.Among whites (148 cases, 296 controls), the risk of multiple sclerosis significantly decreased with increasing levels of 25-hydroxyvitamin D (odds ratio [OR] for a 50-nmol/L increase in 25-hydroxyvitamin D, 0.59; 95% confidence interval, 0.36-0.97). In categorical analyses using the lowest quintile (<63.3 nmol/L) as the reference, the ORs for each subsequent quintile were 0.57, 0.57, 0.74, and 0.38 (P = .02 for trend across quintiles). Only the OR for the highest quintile, corresponding to 25-hydroxyvitamin D levels higher than 99.1 nmol/L, was significantly different from 1.00 (OR, 0.38; 95% confidence interval, 0.19-0.75; P = .006). The inverse relation with multiple sclerosis risk was particularly strong for 25-hydroxyvitamin D levels measured before age 20 years. Among blacks and Hispanics (109 cases, 218 controls), who had lower 25-hydroxyvitamin D levels than whites, no significant associations between vitamin D and multiple sclerosis risk were found.The results of our study suggest that high circulating levels of vitamin D are associated with a lower risk of multiple sclerosis.","Serum 25-hydroxyvitamin D levels and risk of multiple sclerosis."
"730","JAMA.337","0.001",17190895,2006,"Proton pump inhibitors (PPIs) may interfere with calcium absorption through induction of hypochlorhydria but they also may reduce bone resorption through inhibition of osteoclastic vacuolar proton pumps.To determine the association between PPI therapy and risk of hip fracture.A nested case-control study was conducted using the General Practice Research Database (1987-2003), which contains information on patients in the United Kingdom. The study cohort consisted of users of PPI therapy and nonusers of acid suppression drugs who were older than 50 years. Cases included all patients with an incident hip fracture. Controls were selected using incidence density sampling, matched for sex, index date, year of birth, and both calendar period and duration of up-to-standard follow-up before the index date. For comparison purposes, a similar nested case-control analysis for histamine 2 receptor antagonists was performed.The risk of hip fractures associated with PPI use.There were 13,556 hip fracture cases and 135,386 controls. The adjusted odds ratio (AOR) for hip fracture associated with more than 1 year of PPI therapy was 1.44 (95% confidence interval [CI], 1.30-1.59). The risk of hip fracture was significantly increased among patients prescribed long-term high-dose PPIs (AOR, 2.65; 95% CI, 1.80-3.90; P<.001). The strength of the association increased with increasing duration of PPI therapy (AOR for 1 year, 1.22 [95% CI, 1.15-1.30]; 2 years, 1.41 [95% CI, 1.28-1.56]; 3 years, 1.54 [95% CI, 1.37-1.73]; and 4 years, 1.59 [95% CI, 1.39-1.80]; P<.001 for all comparisons).Long-term PPI therapy, particularly at high doses, is associated with an increased risk of hip fracture.","Long-term proton pump inhibitor therapy and risk of hip fracture."
"731","JAMA.359","0.004",17190896,2006,"Individuals susceptible to high-altitude pulmonary edema (HAPE) are characterized by exaggerated pulmonary hypertension and arterial hypoxemia at high altitude, but the underlying mechanism is incompletely understood. Anecdotal evidence suggests that shunting across a patent foramen ovale (PFO) may exacerbate hypoxemia in HAPE.We hypothesized that PFO is more frequent in HAPE-susceptible individuals and may contribute to more severe arterial hypoxemia at high altitude.Case-control study of 16 HAPE-susceptible participants and 19 mountaineers resistant to this condition (repeated climbing to peaks above 4000 m and no symptoms of HAPE).Presence of PFO determined by transesophageal echocardiography, estimated pulmonary artery pressure by Doppler echocardiography, and arterial oxygen saturation measured by pulse oximetry in HAPE-susceptible and HAPE-resistant participants at low (550 m) and high altitude (4559 m).The frequency of PFO was more than 4 times higher in HAPE-susceptible than in HAPE-resistant participants, both at low altitude (56% vs 11%, P = .004; odds ratio [OR], 10.9 [95% confidence interval {CI}, 1.9-64.0]) and high altitude (69% vs 16%, P = .001; OR, 11.7 [95% CI, 2.3-59.5]). At high altitude, mean (SD) arterial oxygen saturation prior to the onset of pulmonary edema was significantly lower in HAPE-susceptible participants than in the control group (73% [10%] vs 83% [7%], P = .001). Moreover, in the HAPE-susceptible group, participants with a large PFO had more severe arterial hypoxemia (65% [6%] vs 77% [8%], P = .02) than those with smaller or no PFO.Patent foramen ovale was roughly 4 times more frequent in HAPE-susceptible mountaineers than in participants resistant to this condition. At high altitude, HAPE-susceptible participants with a large PFO had more severe hypoxemia. We speculate that at high altitude, a large PFO may contribute to exaggerated arterial hypoxemia and facilitate HAPE.","Patent foramen ovale and high-altitude pulmonary edema."
"732","JAMA.360","0.001",17190896,2006,"Individuals susceptible to high-altitude pulmonary edema (HAPE) are characterized by exaggerated pulmonary hypertension and arterial hypoxemia at high altitude, but the underlying mechanism is incompletely understood. Anecdotal evidence suggests that shunting across a patent foramen ovale (PFO) may exacerbate hypoxemia in HAPE.We hypothesized that PFO is more frequent in HAPE-susceptible individuals and may contribute to more severe arterial hypoxemia at high altitude.Case-control study of 16 HAPE-susceptible participants and 19 mountaineers resistant to this condition (repeated climbing to peaks above 4000 m and no symptoms of HAPE).Presence of PFO determined by transesophageal echocardiography, estimated pulmonary artery pressure by Doppler echocardiography, and arterial oxygen saturation measured by pulse oximetry in HAPE-susceptible and HAPE-resistant participants at low (550 m) and high altitude (4559 m).The frequency of PFO was more than 4 times higher in HAPE-susceptible than in HAPE-resistant participants, both at low altitude (56% vs 11%, P = .004; odds ratio [OR], 10.9 [95% confidence interval {CI}, 1.9-64.0]) and high altitude (69% vs 16%, P = .001; OR, 11.7 [95% CI, 2.3-59.5]). At high altitude, mean (SD) arterial oxygen saturation prior to the onset of pulmonary edema was significantly lower in HAPE-susceptible participants than in the control group (73% [10%] vs 83% [7%], P = .001). Moreover, in the HAPE-susceptible group, participants with a large PFO had more severe arterial hypoxemia (65% [6%] vs 77% [8%], P = .02) than those with smaller or no PFO.Patent foramen ovale was roughly 4 times more frequent in HAPE-susceptible mountaineers than in participants resistant to this condition. At high altitude, HAPE-susceptible participants with a large PFO had more severe hypoxemia. We speculate that at high altitude, a large PFO may contribute to exaggerated arterial hypoxemia and facilitate HAPE.","Patent foramen ovale and high-altitude pulmonary edema."
"733","JAMA.4231","0.78",17200474,2007,"Reperfusion with percutaneous transluminal coronary intervention (PCI) is effective at improving outcomes in patients with acute ST-elevation myocardial infarction (STEMI). However, in patients without prompt reestablishment of brisk coronary flow and tissue perfusion, mortality remains high, providing an opportunity for novel treatments, including anti-inflammatory agents.To evaluate the effectiveness of pexelizumab, a humanized monoclonal antibody that binds the C5 component of complement, as an adjunct to PCI in improving 30-day mortality from STEMI.This trial was a prospective, multicenter, double-blind, placebo-controlled, phase 3 study of the intravenous administration of pexelizumab in conjunction with primary PCI in STEMI with prespecified high-risk electrocardiographic findings. The trial was intended to enroll 8500 patients, but in conjunction with the US Food and Drug Administration enrollment was modified to 5745 patients presenting from 296 hospitals in 17 countries from July 13, 2004, to May 11, 2006.Two thousand eight hundred eighty-five patients were randomly assigned to receive placebo and 2860 to receive pexelizumab given as a 2-mg/kg intravenous bolus prior to PCI followed by 0.05-mg/kg per hour infusion over the subsequent 24 hours. Patients were randomized within 6 hours of symptom onset.The primary end point was all-cause mortality through day 30. Secondary end points were death through day 90 and the composite of death, cardiogenic shock, or congestive heart failure through days 30 and 90.No difference in mortality through day 30 was observed between the pexelizumab and placebo treatment groups, with 116 patients (4.06%) and 113 patients (3.92%) who died in the respective groups (hazard ratio [HR], 1.04; 95% confidence interval [CI], 0.80-1.35; log-rank P = .78). The composite end points of death, shock, or heart failure were also similar with 257 patients (8.99%) receiving pexelizumab and 265 patients (9.19%) receiving placebo at 30 days (HR, 0.98; 95% CI, 0.83-1.16; P = .81) and 293 patients (10.24%) receiving pexelizumab and 293 patients (10.16%) receiving placebo at 90 days (HR, 1.01; 95% CI, 0.86-1.19; P = .91).In this large clinical trial of patients treated with primary PCI for STEMI, mortality was low and unaffected by administration of pexelizumab.clinicaltrials.gov Identifier: NCT00091637.","Pexelizumab for acute ST-elevation myocardial infarction in patients undergoing primary percutaneous coronary intervention: a randomized controlled trial."
"734","JAMA.4241","0.81",17200474,2007,"Reperfusion with percutaneous transluminal coronary intervention (PCI) is effective at improving outcomes in patients with acute ST-elevation myocardial infarction (STEMI). However, in patients without prompt reestablishment of brisk coronary flow and tissue perfusion, mortality remains high, providing an opportunity for novel treatments, including anti-inflammatory agents.To evaluate the effectiveness of pexelizumab, a humanized monoclonal antibody that binds the C5 component of complement, as an adjunct to PCI in improving 30-day mortality from STEMI.This trial was a prospective, multicenter, double-blind, placebo-controlled, phase 3 study of the intravenous administration of pexelizumab in conjunction with primary PCI in STEMI with prespecified high-risk electrocardiographic findings. The trial was intended to enroll 8500 patients, but in conjunction with the US Food and Drug Administration enrollment was modified to 5745 patients presenting from 296 hospitals in 17 countries from July 13, 2004, to May 11, 2006.Two thousand eight hundred eighty-five patients were randomly assigned to receive placebo and 2860 to receive pexelizumab given as a 2-mg/kg intravenous bolus prior to PCI followed by 0.05-mg/kg per hour infusion over the subsequent 24 hours. Patients were randomized within 6 hours of symptom onset.The primary end point was all-cause mortality through day 30. Secondary end points were death through day 90 and the composite of death, cardiogenic shock, or congestive heart failure through days 30 and 90.No difference in mortality through day 30 was observed between the pexelizumab and placebo treatment groups, with 116 patients (4.06%) and 113 patients (3.92%) who died in the respective groups (hazard ratio [HR], 1.04; 95% confidence interval [CI], 0.80-1.35; log-rank P = .78). The composite end points of death, shock, or heart failure were also similar with 257 patients (8.99%) receiving pexelizumab and 265 patients (9.19%) receiving placebo at 30 days (HR, 0.98; 95% CI, 0.83-1.16; P = .81) and 293 patients (10.24%) receiving pexelizumab and 293 patients (10.16%) receiving placebo at 90 days (HR, 1.01; 95% CI, 0.86-1.19; P = .91).In this large clinical trial of patients treated with primary PCI for STEMI, mortality was low and unaffected by administration of pexelizumab.clinicaltrials.gov Identifier: NCT00091637.","Pexelizumab for acute ST-elevation myocardial infarction in patients undergoing primary percutaneous coronary intervention: a randomized controlled trial."
"735","JAMA.4251","0.91",17200474,2007,"Reperfusion with percutaneous transluminal coronary intervention (PCI) is effective at improving outcomes in patients with acute ST-elevation myocardial infarction (STEMI). However, in patients without prompt reestablishment of brisk coronary flow and tissue perfusion, mortality remains high, providing an opportunity for novel treatments, including anti-inflammatory agents.To evaluate the effectiveness of pexelizumab, a humanized monoclonal antibody that binds the C5 component of complement, as an adjunct to PCI in improving 30-day mortality from STEMI.This trial was a prospective, multicenter, double-blind, placebo-controlled, phase 3 study of the intravenous administration of pexelizumab in conjunction with primary PCI in STEMI with prespecified high-risk electrocardiographic findings. The trial was intended to enroll 8500 patients, but in conjunction with the US Food and Drug Administration enrollment was modified to 5745 patients presenting from 296 hospitals in 17 countries from July 13, 2004, to May 11, 2006.Two thousand eight hundred eighty-five patients were randomly assigned to receive placebo and 2860 to receive pexelizumab given as a 2-mg/kg intravenous bolus prior to PCI followed by 0.05-mg/kg per hour infusion over the subsequent 24 hours. Patients were randomized within 6 hours of symptom onset.The primary end point was all-cause mortality through day 30. Secondary end points were death through day 90 and the composite of death, cardiogenic shock, or congestive heart failure through days 30 and 90.No difference in mortality through day 30 was observed between the pexelizumab and placebo treatment groups, with 116 patients (4.06%) and 113 patients (3.92%) who died in the respective groups (hazard ratio [HR], 1.04; 95% confidence interval [CI], 0.80-1.35; log-rank P = .78). The composite end points of death, shock, or heart failure were also similar with 257 patients (8.99%) receiving pexelizumab and 265 patients (9.19%) receiving placebo at 30 days (HR, 0.98; 95% CI, 0.83-1.16; P = .81) and 293 patients (10.24%) receiving pexelizumab and 293 patients (10.16%) receiving placebo at 90 days (HR, 1.01; 95% CI, 0.86-1.19; P = .91).In this large clinical trial of patients treated with primary PCI for STEMI, mortality was low and unaffected by administration of pexelizumab.clinicaltrials.gov Identifier: NCT00091637.","Pexelizumab for acute ST-elevation myocardial infarction in patients undergoing primary percutaneous coronary intervention: a randomized controlled trial."
"736","Lancet.681","1.00E-04",17208639,2007,"Trastuzumab--a humanised monoclonal antibody against HER2--has been shown to improve disease-free survival after chemotherapy in women with HER2-positive early breast cancer. We investigated the drug's effect on overall survival after a median follow-up of 2 years in the Herceptin Adjuvant (HERA) study.HERA is an international multicentre randomised trial that compared 1 or 2 years of trastuzumab treatment with observation alone after standard neoadjuvant or adjuvant chemotherapy in women with HER2-positive node positive or high-risk node negative breast cancer. 5102 women participated in the trial; we analysed data from 1703 women who had been randomised for treatment with trastuzumab for 1 year and 1698 women from the control group, with median follow-up of 23.5 months (range 0-48 months). The primary endpoint of the trial was disease-free survival. Here, we assess overall survival, a secondary endpoint. Analyses were done on an intent-to-treat basis. This trial is registered with the European Clinical Trials Database, number 2005-002385-11.97 (5.7%) patients randomised to observation alone and 58 (3.4%) patients randomised to 1 year of treatment with trastuzumab were lost to follow-up. 172 women stopped trastuzumab prematurely. 59 deaths were reported for trastuzumab and 90 in the control group. The unadjusted hazard ratio (HR) for the risk of death with trastuzumab compared with observation alone was 0.66 (95% CI 0.47-0.91; p=0.0115). 218 disease-free survival events were reported with trastuzumab compared with 321 in the control group. The unadjusted HR for the risk of an event with trastuzumab compared with observation alone was 0.64 (0.54-0.76; p<0.0001).Our results show that 1 year of treatment with trastuzumab after adjuvant chemotherapy has a significant overall survival benefit after a median follow-up of 2 years. The emergence of this benefit after only 2 years reinforces the importance of trastuzumab in the treatment of women with HER2-positive early breast cancer.","2-year follow-up of trastuzumab after adjuvant chemotherapy in HER2-positive breast cancer: a randomised controlled trial."
"737","JAMA.3761","0.001",17213400,2007,"Identification of individuals at high risk for cardiovascular events is important for the optimal use of primary and secondary prevention measures.To determine whether plasma levels of amino terminal fragment of the prohormone brain-type natriuretic peptide (NT-proBNP) predict cardiovascular events or death independent of other available prognostic tests.Prospective cohort study (2000-2002) of 987 individuals in California with stable coronary heart disease in the Heart and Soul Study, who were followed up for a mean of 3.7 (range, 0.1-5.3) years.The association of baseline NT-proBNP levels with death or cardiovascular events (myocardial infarction, stroke, or heart failure). Traditional clinical risk factors, echocardiographic measures, ischemia, other biomarkers, and New York Heart Association classification were adjusted for to determine whether NT-proBNP levels were independent of other prognostic factors. Receiver operating characteristic (ROC) curves were used to assess the incremental prognostic value of adding NT-proBNP level to these other measures.A total of 256 participants (26.2%) had a cardiovascular event or died. Each increasing quartile of NT-proBNP level (range of quartile 1, 8.06-73.95 pg/mL; quartile 2, 74-174.5 pg/mL; quartile 3, 175.1-459 pg/mL; quartile 4, > or =460 pg/mL) was associated with a greater risk of cardiovascular events or death, ranging from 23 of 247 (annual event rate, 2.6%) in the lowest quartile to 134 of 246 (annual event rate, 19.6%) in the highest quartile (unadjusted hazard ratio [HR] for quartile 4 vs quartile 1, 7.8; 95% confidence interval [CI], 5.0-12.1; P<.001). Each SD increase in log NT-proBNP level (1.3 pg/mL) was associated with a 2.3-fold increased rate of adverse cardiovascular outcomes (unadjusted HR, 2.3; 95% CI, 2.0-2.6; P<.001), and this association persisted after adjustment for all of the other prognostic measures (adjusted HR, 1.7; 95% CI, 1.3-2.2; P<.001). The addition of NT-proBNP level to standard clinical assessment and complete echocardiographic parameters significantly improved the area under the ROC curves for predicting subsequent adverse cardiovascular outcomes (0.80 for clinical risk factors and echocardiographic parameters plus log NT-proBNP vs 0.76 for clinical risk factors and echocardiographic parameters only; P = .006).Elevated levels of NT-proBNP predict cardiovascular morbidity and mortality, independent of other prognostic markers, and identify at-risk individuals even in the absence of systolic or diastolic dysfunction by echocardiography. Level of NT-proBNP may help guide risk stratification of high-risk individuals, such as those with coronary heart disease.","N-terminal fragment of the prohormone brain-type natriuretic peptide (NT-proBNP), cardiovascular events, and mortality in patients with stable coronary heart disease."
"738","JAMA.3771","0.001",17213400,2007,"Identification of individuals at high risk for cardiovascular events is important for the optimal use of primary and secondary prevention measures.To determine whether plasma levels of amino terminal fragment of the prohormone brain-type natriuretic peptide (NT-proBNP) predict cardiovascular events or death independent of other available prognostic tests.Prospective cohort study (2000-2002) of 987 individuals in California with stable coronary heart disease in the Heart and Soul Study, who were followed up for a mean of 3.7 (range, 0.1-5.3) years.The association of baseline NT-proBNP levels with death or cardiovascular events (myocardial infarction, stroke, or heart failure). Traditional clinical risk factors, echocardiographic measures, ischemia, other biomarkers, and New York Heart Association classification were adjusted for to determine whether NT-proBNP levels were independent of other prognostic factors. Receiver operating characteristic (ROC) curves were used to assess the incremental prognostic value of adding NT-proBNP level to these other measures.A total of 256 participants (26.2%) had a cardiovascular event or died. Each increasing quartile of NT-proBNP level (range of quartile 1, 8.06-73.95 pg/mL; quartile 2, 74-174.5 pg/mL; quartile 3, 175.1-459 pg/mL; quartile 4, > or =460 pg/mL) was associated with a greater risk of cardiovascular events or death, ranging from 23 of 247 (annual event rate, 2.6%) in the lowest quartile to 134 of 246 (annual event rate, 19.6%) in the highest quartile (unadjusted hazard ratio [HR] for quartile 4 vs quartile 1, 7.8; 95% confidence interval [CI], 5.0-12.1; P<.001). Each SD increase in log NT-proBNP level (1.3 pg/mL) was associated with a 2.3-fold increased rate of adverse cardiovascular outcomes (unadjusted HR, 2.3; 95% CI, 2.0-2.6; P<.001), and this association persisted after adjustment for all of the other prognostic measures (adjusted HR, 1.7; 95% CI, 1.3-2.2; P<.001). The addition of NT-proBNP level to standard clinical assessment and complete echocardiographic parameters significantly improved the area under the ROC curves for predicting subsequent adverse cardiovascular outcomes (0.80 for clinical risk factors and echocardiographic parameters plus log NT-proBNP vs 0.76 for clinical risk factors and echocardiographic parameters only; P = .006).Elevated levels of NT-proBNP predict cardiovascular morbidity and mortality, independent of other prognostic markers, and identify at-risk individuals even in the absence of systolic or diastolic dysfunction by echocardiography. Level of NT-proBNP may help guide risk stratification of high-risk individuals, such as those with coronary heart disease.","N-terminal fragment of the prohormone brain-type natriuretic peptide (NT-proBNP), cardiovascular events, and mortality in patients with stable coronary heart disease."
"739","JAMA.3781","0.001",17213400,2007,"Identification of individuals at high risk for cardiovascular events is important for the optimal use of primary and secondary prevention measures.To determine whether plasma levels of amino terminal fragment of the prohormone brain-type natriuretic peptide (NT-proBNP) predict cardiovascular events or death independent of other available prognostic tests.Prospective cohort study (2000-2002) of 987 individuals in California with stable coronary heart disease in the Heart and Soul Study, who were followed up for a mean of 3.7 (range, 0.1-5.3) years.The association of baseline NT-proBNP levels with death or cardiovascular events (myocardial infarction, stroke, or heart failure). Traditional clinical risk factors, echocardiographic measures, ischemia, other biomarkers, and New York Heart Association classification were adjusted for to determine whether NT-proBNP levels were independent of other prognostic factors. Receiver operating characteristic (ROC) curves were used to assess the incremental prognostic value of adding NT-proBNP level to these other measures.A total of 256 participants (26.2%) had a cardiovascular event or died. Each increasing quartile of NT-proBNP level (range of quartile 1, 8.06-73.95 pg/mL; quartile 2, 74-174.5 pg/mL; quartile 3, 175.1-459 pg/mL; quartile 4, > or =460 pg/mL) was associated with a greater risk of cardiovascular events or death, ranging from 23 of 247 (annual event rate, 2.6%) in the lowest quartile to 134 of 246 (annual event rate, 19.6%) in the highest quartile (unadjusted hazard ratio [HR] for quartile 4 vs quartile 1, 7.8; 95% confidence interval [CI], 5.0-12.1; P<.001). Each SD increase in log NT-proBNP level (1.3 pg/mL) was associated with a 2.3-fold increased rate of adverse cardiovascular outcomes (unadjusted HR, 2.3; 95% CI, 2.0-2.6; P<.001), and this association persisted after adjustment for all of the other prognostic measures (adjusted HR, 1.7; 95% CI, 1.3-2.2; P<.001). The addition of NT-proBNP level to standard clinical assessment and complete echocardiographic parameters significantly improved the area under the ROC curves for predicting subsequent adverse cardiovascular outcomes (0.80 for clinical risk factors and echocardiographic parameters plus log NT-proBNP vs 0.76 for clinical risk factors and echocardiographic parameters only; P = .006).Elevated levels of NT-proBNP predict cardiovascular morbidity and mortality, independent of other prognostic markers, and identify at-risk individuals even in the absence of systolic or diastolic dysfunction by echocardiography. Level of NT-proBNP may help guide risk stratification of high-risk individuals, such as those with coronary heart disease.","N-terminal fragment of the prohormone brain-type natriuretic peptide (NT-proBNP), cardiovascular events, and mortality in patients with stable coronary heart disease."
"740","Lancet.63","0.0029",17223473,2007,"Inter-individual differences in biological ageing could affect susceptibility to coronary heart disease. Our aim was to determine whether mean leucocyte telomere length is a predictor of the development of coronary heart disease.We compared telomere lengths at recruitment in 484 individuals in the West of Scotland Primary Prevention Study (WOSCOPS) who went on to develop coronary heart disease events with those from 1058 matched controls who remained event free. We also investigated whether there was any association between telomere length and observed clinical benefit of statin treatment in WOSCOPS.Mean telomere length decreased with age by 9% per decade (95% CI 3.6-14.1; p=0.001) in controls; much the same trend was seen in cases (-5.9% per decade, -3.1 to 14.1; p=0.1902). Individuals in the middle and the lowest tertiles of telomere length were more at risk of developing a coronary heart disease event than were individuals in the highest tertile (odds ratio [OR] for coronary heart disease: 1.51, 95% CI 1.15-1.98; p=0.0029 in the middle tertile; 1.44, 1.10-1.90, p=0.0090 in the lowest). In placebo-treated patients, the risk of coronary heart disease was almost double in those in the lower two tertiles of telomere length compared with those in the highest tertile (1.93, 1.33-2.80, p=0.0005 in the middle tertile; 1.94, 1.33-2.84, p=0.0006 in the lowest). By contrast, in patients treated with pravastatin, the increased risk with shorter telomeres was substantially attenuated (1.12, 0.75-1.69, p=0.5755 in the middle tertile; 1.02, 0.68-1.52, p=0.9380 in the lowest).Mean leucocyte telomere length is a predictor of future coronary heart disease events in middle-aged, high-risk men and could identify individuals who would benefit most from statin treatment. Our findings lend support to the hypothesis that differences in biological ageing might contribute to the risk--and variability in age of onset--of coronary heart disease.","Telomere length, risk of coronary heart disease, and statin treatment in the West of Scotland Primary Prevention Study: a nested case-control study."
"741","Lancet.64","0.009",17223473,2007,"Inter-individual differences in biological ageing could affect susceptibility to coronary heart disease. Our aim was to determine whether mean leucocyte telomere length is a predictor of the development of coronary heart disease.We compared telomere lengths at recruitment in 484 individuals in the West of Scotland Primary Prevention Study (WOSCOPS) who went on to develop coronary heart disease events with those from 1058 matched controls who remained event free. We also investigated whether there was any association between telomere length and observed clinical benefit of statin treatment in WOSCOPS.Mean telomere length decreased with age by 9% per decade (95% CI 3.6-14.1; p=0.001) in controls; much the same trend was seen in cases (-5.9% per decade, -3.1 to 14.1; p=0.1902). Individuals in the middle and the lowest tertiles of telomere length were more at risk of developing a coronary heart disease event than were individuals in the highest tertile (odds ratio [OR] for coronary heart disease: 1.51, 95% CI 1.15-1.98; p=0.0029 in the middle tertile; 1.44, 1.10-1.90, p=0.0090 in the lowest). In placebo-treated patients, the risk of coronary heart disease was almost double in those in the lower two tertiles of telomere length compared with those in the highest tertile (1.93, 1.33-2.80, p=0.0005 in the middle tertile; 1.94, 1.33-2.84, p=0.0006 in the lowest). By contrast, in patients treated with pravastatin, the increased risk with shorter telomeres was substantially attenuated (1.12, 0.75-1.69, p=0.5755 in the middle tertile; 1.02, 0.68-1.52, p=0.9380 in the lowest).Mean leucocyte telomere length is a predictor of future coronary heart disease events in middle-aged, high-risk men and could identify individuals who would benefit most from statin treatment. Our findings lend support to the hypothesis that differences in biological ageing might contribute to the risk--and variability in age of onset--of coronary heart disease.","Telomere length, risk of coronary heart disease, and statin treatment in the West of Scotland Primary Prevention Study: a nested case-control study."
"742","Lancet.65","5.00E-04",17223473,2007,"Inter-individual differences in biological ageing could affect susceptibility to coronary heart disease. Our aim was to determine whether mean leucocyte telomere length is a predictor of the development of coronary heart disease.We compared telomere lengths at recruitment in 484 individuals in the West of Scotland Primary Prevention Study (WOSCOPS) who went on to develop coronary heart disease events with those from 1058 matched controls who remained event free. We also investigated whether there was any association between telomere length and observed clinical benefit of statin treatment in WOSCOPS.Mean telomere length decreased with age by 9% per decade (95% CI 3.6-14.1; p=0.001) in controls; much the same trend was seen in cases (-5.9% per decade, -3.1 to 14.1; p=0.1902). Individuals in the middle and the lowest tertiles of telomere length were more at risk of developing a coronary heart disease event than were individuals in the highest tertile (odds ratio [OR] for coronary heart disease: 1.51, 95% CI 1.15-1.98; p=0.0029 in the middle tertile; 1.44, 1.10-1.90, p=0.0090 in the lowest). In placebo-treated patients, the risk of coronary heart disease was almost double in those in the lower two tertiles of telomere length compared with those in the highest tertile (1.93, 1.33-2.80, p=0.0005 in the middle tertile; 1.94, 1.33-2.84, p=0.0006 in the lowest). By contrast, in patients treated with pravastatin, the increased risk with shorter telomeres was substantially attenuated (1.12, 0.75-1.69, p=0.5755 in the middle tertile; 1.02, 0.68-1.52, p=0.9380 in the lowest).Mean leucocyte telomere length is a predictor of future coronary heart disease events in middle-aged, high-risk men and could identify individuals who would benefit most from statin treatment. Our findings lend support to the hypothesis that differences in biological ageing might contribute to the risk--and variability in age of onset--of coronary heart disease.","Telomere length, risk of coronary heart disease, and statin treatment in the West of Scotland Primary Prevention Study: a nested case-control study."
"743","Lancet.66","6.00E-04",17223473,2007,"Inter-individual differences in biological ageing could affect susceptibility to coronary heart disease. Our aim was to determine whether mean leucocyte telomere length is a predictor of the development of coronary heart disease.We compared telomere lengths at recruitment in 484 individuals in the West of Scotland Primary Prevention Study (WOSCOPS) who went on to develop coronary heart disease events with those from 1058 matched controls who remained event free. We also investigated whether there was any association between telomere length and observed clinical benefit of statin treatment in WOSCOPS.Mean telomere length decreased with age by 9% per decade (95% CI 3.6-14.1; p=0.001) in controls; much the same trend was seen in cases (-5.9% per decade, -3.1 to 14.1; p=0.1902). Individuals in the middle and the lowest tertiles of telomere length were more at risk of developing a coronary heart disease event than were individuals in the highest tertile (odds ratio [OR] for coronary heart disease: 1.51, 95% CI 1.15-1.98; p=0.0029 in the middle tertile; 1.44, 1.10-1.90, p=0.0090 in the lowest). In placebo-treated patients, the risk of coronary heart disease was almost double in those in the lower two tertiles of telomere length compared with those in the highest tertile (1.93, 1.33-2.80, p=0.0005 in the middle tertile; 1.94, 1.33-2.84, p=0.0006 in the lowest). By contrast, in patients treated with pravastatin, the increased risk with shorter telomeres was substantially attenuated (1.12, 0.75-1.69, p=0.5755 in the middle tertile; 1.02, 0.68-1.52, p=0.9380 in the lowest).Mean leucocyte telomere length is a predictor of future coronary heart disease events in middle-aged, high-risk men and could identify individuals who would benefit most from statin treatment. Our findings lend support to the hypothesis that differences in biological ageing might contribute to the risk--and variability in age of onset--of coronary heart disease.","Telomere length, risk of coronary heart disease, and statin treatment in the West of Scotland Primary Prevention Study: a nested case-control study."
"744","Lancet.67","0.5755",17223473,2007,"Inter-individual differences in biological ageing could affect susceptibility to coronary heart disease. Our aim was to determine whether mean leucocyte telomere length is a predictor of the development of coronary heart disease.We compared telomere lengths at recruitment in 484 individuals in the West of Scotland Primary Prevention Study (WOSCOPS) who went on to develop coronary heart disease events with those from 1058 matched controls who remained event free. We also investigated whether there was any association between telomere length and observed clinical benefit of statin treatment in WOSCOPS.Mean telomere length decreased with age by 9% per decade (95% CI 3.6-14.1; p=0.001) in controls; much the same trend was seen in cases (-5.9% per decade, -3.1 to 14.1; p=0.1902). Individuals in the middle and the lowest tertiles of telomere length were more at risk of developing a coronary heart disease event than were individuals in the highest tertile (odds ratio [OR] for coronary heart disease: 1.51, 95% CI 1.15-1.98; p=0.0029 in the middle tertile; 1.44, 1.10-1.90, p=0.0090 in the lowest). In placebo-treated patients, the risk of coronary heart disease was almost double in those in the lower two tertiles of telomere length compared with those in the highest tertile (1.93, 1.33-2.80, p=0.0005 in the middle tertile; 1.94, 1.33-2.84, p=0.0006 in the lowest). By contrast, in patients treated with pravastatin, the increased risk with shorter telomeres was substantially attenuated (1.12, 0.75-1.69, p=0.5755 in the middle tertile; 1.02, 0.68-1.52, p=0.9380 in the lowest).Mean leucocyte telomere length is a predictor of future coronary heart disease events in middle-aged, high-risk men and could identify individuals who would benefit most from statin treatment. Our findings lend support to the hypothesis that differences in biological ageing might contribute to the risk--and variability in age of onset--of coronary heart disease.","Telomere length, risk of coronary heart disease, and statin treatment in the West of Scotland Primary Prevention Study: a nested case-control study."
"745","Lancet.68","0.938",17223473,2007,"Inter-individual differences in biological ageing could affect susceptibility to coronary heart disease. Our aim was to determine whether mean leucocyte telomere length is a predictor of the development of coronary heart disease.We compared telomere lengths at recruitment in 484 individuals in the West of Scotland Primary Prevention Study (WOSCOPS) who went on to develop coronary heart disease events with those from 1058 matched controls who remained event free. We also investigated whether there was any association between telomere length and observed clinical benefit of statin treatment in WOSCOPS.Mean telomere length decreased with age by 9% per decade (95% CI 3.6-14.1; p=0.001) in controls; much the same trend was seen in cases (-5.9% per decade, -3.1 to 14.1; p=0.1902). Individuals in the middle and the lowest tertiles of telomere length were more at risk of developing a coronary heart disease event than were individuals in the highest tertile (odds ratio [OR] for coronary heart disease: 1.51, 95% CI 1.15-1.98; p=0.0029 in the middle tertile; 1.44, 1.10-1.90, p=0.0090 in the lowest). In placebo-treated patients, the risk of coronary heart disease was almost double in those in the lower two tertiles of telomere length compared with those in the highest tertile (1.93, 1.33-2.80, p=0.0005 in the middle tertile; 1.94, 1.33-2.84, p=0.0006 in the lowest). By contrast, in patients treated with pravastatin, the increased risk with shorter telomeres was substantially attenuated (1.12, 0.75-1.69, p=0.5755 in the middle tertile; 1.02, 0.68-1.52, p=0.9380 in the lowest).Mean leucocyte telomere length is a predictor of future coronary heart disease events in middle-aged, high-risk men and could identify individuals who would benefit most from statin treatment. Our findings lend support to the hypothesis that differences in biological ageing might contribute to the risk--and variability in age of onset--of coronary heart disease.","Telomere length, risk of coronary heart disease, and statin treatment in the West of Scotland Primary Prevention Study: a nested case-control study."
"746","Lancet.60","0.05",17223474,2007,"Despite three decades of prenatal screening for congenital toxoplasmosis in some European countries, uncertainty remains about the effectiveness of prenatal treatment.We did a systematic review of cohort studies based on universal screening for congenital toxoplasmosis. We did a meta-analysis using individual patients' data to assess the effect of timing and type of prenatal treatment on mother-to-child transmission of infection and clinical manifestations before age 1 year. Analyses were adjusted for gestational age at maternal seroconversion and other covariates.We included 26 cohorts in the review. In 1438 treated mothers identified by prenatal screening, we found weak evidence that treatment started within 3 weeks of seroconversion reduced mother-to-child transmission compared with treatment started after 8 or more weeks (adjusted odds ratio [OR] 0.48, 95% CI 0.28-0.80; p=0.05). In 550 infected liveborn infants identified by prenatal or neonatal screening, we found no evidence that prenatal treatment significantly reduced the risk of clinical manifestations (adjusted OR for treated vs not treated 1.11, 95% CI 0.61-2.02). Increasing gestational age at seroconversion was strongly associated with increased risk of mother-to-child transmission (OR 1.15, 95% CI 1.12-1.17) and decreased risk of intracranial lesions (0.91, 0.87-0.95), but not with eye lesions (0.97, 0.93-1.00).We found weak evidence for an association between early treatment and reduced risk of congenital toxoplasmosis. Further evidence from observational studies is unlikely to change these results and would not distinguish whether the association is due to treatment or to biases caused by confounding. Only a large randomised controlled clinical trial would provide clinicians and patients with valid evidence of the potential benefit of prenatal treatment.","Effectiveness of prenatal treatment for congenital toxoplasmosis: a meta-analysis of individual patients' data."
"747","Lancet.671","1.00E-04",17292766,2007,"Upper gastrointestinal safety of cyclo-oxygenase (COX)-2 selective inhibitors versus traditional non-steroidal anti-inflammatory drugs (NSAIDs) has not been assessed in trials that simulate standard clinical practice. Our aim was to assess the effects of these drugs on gastrointestinal outcomes in a population that includes patients taking gastrointestinal protective therapy.A prespecified pooled intent-to-treat analysis of three double-blind randomised comparisons of etoricoxib (60 or 90 mg daily) and diclofenac (150 mg daily) in 34 701 patients with osteoarthritis or rheumatoid arthritis was done for upper gastrointestinal clinical events (bleeding, perforation, obstruction, or ulcer) and the subset of complicated events (perforation, obstruction, witnessed ulcer bleeding, or significant bleeding). We also assessed such outcomes in patients who were taking concomitant proton pump inhibitors (PPIs) or low-dose aspirin. These trials are registered with , with the numbers , , and .Overall upper gastrointestinal clinical events were significantly less common with etoricoxib than with diclofenac (hazard ratio [HR] 0.69, 95% CI 0.57-0.83; p=0.0001). There were significantly fewer uncomplicated gastrointestinal events with etoricoxib than there were with diclofenac (0.57, 0.45-0.74; p<0.0001); there was no difference in complicated events (0.91, 0.67-1.24; p=0.561). PPIs were used concomitantly for at least 75% of the study period by 13 862 (40%) and low-dose aspirin by 11 418 (33%) patients; treatment effects did not differ significantly in these individuals.There were significantly fewer upper gastrointestinal clinical events with the COX-2 selective inhibitor etoricoxib than with the traditional NSAID diclofenac due to a decrease in uncomplicated events, but not in the more serious complicated events. The reduction in uncomplicated events with etoricoxib is maintained in patients treated with PPIs and is also observed with regular low-dose aspirin use.","Assessment of upper gastrointestinal safety of etoricoxib and diclofenac in patients with osteoarthritis and rheumatoid arthritis in the Multinational Etoricoxib and Diclofenac Arthritis Long-term (MEDAL) programme: a randomised comparison."
"748","Lancet.1031","1.00E-04",17292766,2007,"Upper gastrointestinal safety of cyclo-oxygenase (COX)-2 selective inhibitors versus traditional non-steroidal anti-inflammatory drugs (NSAIDs) has not been assessed in trials that simulate standard clinical practice. Our aim was to assess the effects of these drugs on gastrointestinal outcomes in a population that includes patients taking gastrointestinal protective therapy.A prespecified pooled intent-to-treat analysis of three double-blind randomised comparisons of etoricoxib (60 or 90 mg daily) and diclofenac (150 mg daily) in 34 701 patients with osteoarthritis or rheumatoid arthritis was done for upper gastrointestinal clinical events (bleeding, perforation, obstruction, or ulcer) and the subset of complicated events (perforation, obstruction, witnessed ulcer bleeding, or significant bleeding). We also assessed such outcomes in patients who were taking concomitant proton pump inhibitors (PPIs) or low-dose aspirin. These trials are registered with , with the numbers , , and .Overall upper gastrointestinal clinical events were significantly less common with etoricoxib than with diclofenac (hazard ratio [HR] 0.69, 95% CI 0.57-0.83; p=0.0001). There were significantly fewer uncomplicated gastrointestinal events with etoricoxib than there were with diclofenac (0.57, 0.45-0.74; p<0.0001); there was no difference in complicated events (0.91, 0.67-1.24; p=0.561). PPIs were used concomitantly for at least 75% of the study period by 13 862 (40%) and low-dose aspirin by 11 418 (33%) patients; treatment effects did not differ significantly in these individuals.There were significantly fewer upper gastrointestinal clinical events with the COX-2 selective inhibitor etoricoxib than with the traditional NSAID diclofenac due to a decrease in uncomplicated events, but not in the more serious complicated events. The reduction in uncomplicated events with etoricoxib is maintained in patients treated with PPIs and is also observed with regular low-dose aspirin use.","Assessment of upper gastrointestinal safety of etoricoxib and diclofenac in patients with osteoarthritis and rheumatoid arthritis in the Multinational Etoricoxib and Diclofenac Arthritis Long-term (MEDAL) programme: a randomised comparison."
"749","Lancet.1041","0.561",17292766,2007,"Upper gastrointestinal safety of cyclo-oxygenase (COX)-2 selective inhibitors versus traditional non-steroidal anti-inflammatory drugs (NSAIDs) has not been assessed in trials that simulate standard clinical practice. Our aim was to assess the effects of these drugs on gastrointestinal outcomes in a population that includes patients taking gastrointestinal protective therapy.A prespecified pooled intent-to-treat analysis of three double-blind randomised comparisons of etoricoxib (60 or 90 mg daily) and diclofenac (150 mg daily) in 34 701 patients with osteoarthritis or rheumatoid arthritis was done for upper gastrointestinal clinical events (bleeding, perforation, obstruction, or ulcer) and the subset of complicated events (perforation, obstruction, witnessed ulcer bleeding, or significant bleeding). We also assessed such outcomes in patients who were taking concomitant proton pump inhibitors (PPIs) or low-dose aspirin. These trials are registered with , with the numbers , , and .Overall upper gastrointestinal clinical events were significantly less common with etoricoxib than with diclofenac (hazard ratio [HR] 0.69, 95% CI 0.57-0.83; p=0.0001). There were significantly fewer uncomplicated gastrointestinal events with etoricoxib than there were with diclofenac (0.57, 0.45-0.74; p<0.0001); there was no difference in complicated events (0.91, 0.67-1.24; p=0.561). PPIs were used concomitantly for at least 75% of the study period by 13 862 (40%) and low-dose aspirin by 11 418 (33%) patients; treatment effects did not differ significantly in these individuals.There were significantly fewer upper gastrointestinal clinical events with the COX-2 selective inhibitor etoricoxib than with the traditional NSAID diclofenac due to a decrease in uncomplicated events, but not in the more serious complicated events. The reduction in uncomplicated events with etoricoxib is maintained in patients treated with PPIs and is also observed with regular low-dose aspirin use.","Assessment of upper gastrointestinal safety of etoricoxib and diclofenac in patients with osteoarthritis and rheumatoid arthritis in the Multinational Etoricoxib and Diclofenac Arthritis Long-term (MEDAL) programme: a randomised comparison."
"750","JAMA.4201","0.17",17299195,2007,"Accumulation of iron in excess of physiologic requirements has been implicated in risk of cardiovascular disease because of increased iron-catalyzed free radical-mediated oxidative stress.To test the hypothesis that reducing body iron stores through phlebotomy will influence clinical outcomes in a cohort of patients with symptomatic peripheral arterial disease (PAD). Design, Setting, andMulticenter, randomized, controlled, single-blinded clinical trial based on the Iron (Fe) and Atherosclerosis Study (FeAST) (VA Cooperative Study #410) and conducted between May 1, 1999, and April 30, 2005, within the Department of Veterans Affairs Cooperative Studies Program and enrolling 1277 patients with symptomatic but stable PAD. Those with conditions likely to cause acute-phase increase of the ferritin level or with a diagnosis of visceral malignancy within the preceding 5 years were excluded. Analysis was by intent-to-treat.Patients were assigned to a control group (n = 641) or to a group undergoing reduction of iron stores by phlebotomy with removal of defined volumes of blood at 6-month intervals (avoiding iron deficiency) (n = 636), stratified by hospital, age, and baseline smoking status, diagnosis of diabetes mellitus, ratio of high-density to low-density lipoprotein cholesterol level, and ferritin level.The primary end point was all-cause mortality; the secondary end point was death plus nonfatal myocardial infarction and stroke.There were no significant differences between treatment groups for the primary or secondary study end points. All-cause deaths occurred in 148 patients (23%) in the control group and in 125 (20%) in the iron-reduction group (hazard ratio (HR), 0.85; 95% confidence interval (CI), 0.67-1.08; P = .17). Death plus nonfatal myocardial infarction and stroke occurred in 205 patients (32%) in the control group and in 180 (28%) in the iron-reduction group (HR, 0.88; 95% CI, 0.72-1.07; P = .20).Reduction of body iron stores in patients with symptomatic PAD did not significantly decrease all-cause mortality or death plus nonfatal myocardial infarction and stroke.Clinicaltrials.gov Identifier: NCT00032357.","Reduction of iron stores and cardiovascular outcomes in patients with peripheral arterial disease: a randomized controlled trial."
"751","JAMA.4211","0.2",17299195,2007,"Accumulation of iron in excess of physiologic requirements has been implicated in risk of cardiovascular disease because of increased iron-catalyzed free radical-mediated oxidative stress.To test the hypothesis that reducing body iron stores through phlebotomy will influence clinical outcomes in a cohort of patients with symptomatic peripheral arterial disease (PAD). Design, Setting, andMulticenter, randomized, controlled, single-blinded clinical trial based on the Iron (Fe) and Atherosclerosis Study (FeAST) (VA Cooperative Study #410) and conducted between May 1, 1999, and April 30, 2005, within the Department of Veterans Affairs Cooperative Studies Program and enrolling 1277 patients with symptomatic but stable PAD. Those with conditions likely to cause acute-phase increase of the ferritin level or with a diagnosis of visceral malignancy within the preceding 5 years were excluded. Analysis was by intent-to-treat.Patients were assigned to a control group (n = 641) or to a group undergoing reduction of iron stores by phlebotomy with removal of defined volumes of blood at 6-month intervals (avoiding iron deficiency) (n = 636), stratified by hospital, age, and baseline smoking status, diagnosis of diabetes mellitus, ratio of high-density to low-density lipoprotein cholesterol level, and ferritin level.The primary end point was all-cause mortality; the secondary end point was death plus nonfatal myocardial infarction and stroke.There were no significant differences between treatment groups for the primary or secondary study end points. All-cause deaths occurred in 148 patients (23%) in the control group and in 125 (20%) in the iron-reduction group (hazard ratio (HR), 0.85; 95% confidence interval (CI), 0.67-1.08; P = .17). Death plus nonfatal myocardial infarction and stroke occurred in 205 patients (32%) in the control group and in 180 (28%) in the iron-reduction group (HR, 0.88; 95% CI, 0.72-1.07; P = .20).Reduction of body iron stores in patients with symptomatic PAD did not significantly decrease all-cause mortality or death plus nonfatal myocardial infarction and stroke.Clinicaltrials.gov Identifier: NCT00032357.","Reduction of iron stores and cardiovascular outcomes in patients with peripheral arterial disease: a randomized controlled trial."
"752","American Journal of Epidemiology.69","0.05",17308332,2007,"Asthma prevalence in the Catao Air Basin of Puerto Rico is 27% for children aged 13-14 years and 45% for children aged 5-6 years. There is concern that these rates are related to air pollution. The authors conducted a nested case-control study to evaluate whether proximity to air pollution point sources was associated with increased risk of asthma attacks. For 1997-2001, 1,382 asthma-related medical visits (International Classification of Diseases, Ninth Revision, codes 493 and 493.9) in children under 17 were identified through health insurance claims. Controls were children with no asthma attacks who were randomly selected from enrollees in two health insurance companies by incidence density sampling (1:5) and matched to cases on gender, age, insurance company, and event date. The distance from a point source to the subject's residence area represented a surrogate exposure measurement. Odds ratios for a 1-km decrease in distance were obtained by conditional logistic regression. Risk of asthma attack was associated with residing near a grain mill (odds ratio (OR) = 1.35), petroleum refinery (OR = 1.44), asphalt plant (OR = 1.23), or power plant (OR = 1.28) (all p's < 0.05). Residence near major air emissions sources (>100 tons/year) increased asthma attack risk by 108% (p < 0.05). These results showed that proximity to some air pollution sources is associated with increased risks of asthma attacks.","Air pollution sources and childhood asthma attacks in Catano, Puerto Rico."
"753","American Journal of Epidemiology.70","0.05",17308332,2007,"Asthma prevalence in the Catao Air Basin of Puerto Rico is 27% for children aged 13-14 years and 45% for children aged 5-6 years. There is concern that these rates are related to air pollution. The authors conducted a nested case-control study to evaluate whether proximity to air pollution point sources was associated with increased risk of asthma attacks. For 1997-2001, 1,382 asthma-related medical visits (International Classification of Diseases, Ninth Revision, codes 493 and 493.9) in children under 17 were identified through health insurance claims. Controls were children with no asthma attacks who were randomly selected from enrollees in two health insurance companies by incidence density sampling (1:5) and matched to cases on gender, age, insurance company, and event date. The distance from a point source to the subject's residence area represented a surrogate exposure measurement. Odds ratios for a 1-km decrease in distance were obtained by conditional logistic regression. Risk of asthma attack was associated with residing near a grain mill (odds ratio (OR) = 1.35), petroleum refinery (OR = 1.44), asphalt plant (OR = 1.23), or power plant (OR = 1.28) (all p's < 0.05). Residence near major air emissions sources (>100 tons/year) increased asthma attack risk by 108% (p < 0.05). These results showed that proximity to some air pollution sources is associated with increased risks of asthma attacks.","Air pollution sources and childhood asthma attacks in Catano, Puerto Rico."
"754","American Journal of Epidemiology.71","0.05",17308332,2007,"Asthma prevalence in the Catao Air Basin of Puerto Rico is 27% for children aged 13-14 years and 45% for children aged 5-6 years. There is concern that these rates are related to air pollution. The authors conducted a nested case-control study to evaluate whether proximity to air pollution point sources was associated with increased risk of asthma attacks. For 1997-2001, 1,382 asthma-related medical visits (International Classification of Diseases, Ninth Revision, codes 493 and 493.9) in children under 17 were identified through health insurance claims. Controls were children with no asthma attacks who were randomly selected from enrollees in two health insurance companies by incidence density sampling (1:5) and matched to cases on gender, age, insurance company, and event date. The distance from a point source to the subject's residence area represented a surrogate exposure measurement. Odds ratios for a 1-km decrease in distance were obtained by conditional logistic regression. Risk of asthma attack was associated with residing near a grain mill (odds ratio (OR) = 1.35), petroleum refinery (OR = 1.44), asphalt plant (OR = 1.23), or power plant (OR = 1.28) (all p's < 0.05). Residence near major air emissions sources (>100 tons/year) increased asthma attack risk by 108% (p < 0.05). These results showed that proximity to some air pollution sources is associated with increased risks of asthma attacks.","Air pollution sources and childhood asthma attacks in Catano, Puerto Rico."
"755","American Journal of Epidemiology.71","0.05",17308332,2007,"Asthma prevalence in the Catao Air Basin of Puerto Rico is 27% for children aged 13-14 years and 45% for children aged 5-6 years. There is concern that these rates are related to air pollution. The authors conducted a nested case-control study to evaluate whether proximity to air pollution point sources was associated with increased risk of asthma attacks. For 1997-2001, 1,382 asthma-related medical visits (International Classification of Diseases, Ninth Revision, codes 493 and 493.9) in children under 17 were identified through health insurance claims. Controls were children with no asthma attacks who were randomly selected from enrollees in two health insurance companies by incidence density sampling (1:5) and matched to cases on gender, age, insurance company, and event date. The distance from a point source to the subject's residence area represented a surrogate exposure measurement. Odds ratios for a 1-km decrease in distance were obtained by conditional logistic regression. Risk of asthma attack was associated with residing near a grain mill (odds ratio (OR) = 1.35), petroleum refinery (OR = 1.44), asphalt plant (OR = 1.23), or power plant (OR = 1.28) (all p's < 0.05). Residence near major air emissions sources (>100 tons/year) increased asthma attack risk by 108% (p < 0.05). These results showed that proximity to some air pollution sources is associated with increased risks of asthma attacks.","Air pollution sources and childhood asthma attacks in Catano, Puerto Rico."
"756","JAMA.3751","0.001",17312290,2007,"Atrial fibrillation (AF) is responsible for considerable morbidity and mortality, making identification of modifiable risk factors a priority. Increased pulse pressure, a reflection of aortic stiffness, increases cardiac load and may increase AF risk.To examine relations between pulse pressure and incident AF.Prospective, community-based observational cohort in Framingham, Mass, including 5331 Framingham Heart Study participants aged 35 years and older and initially free from AF (median age, 57 years; 55% women).Incident AF.AF developed in 698 participants (13.1%) a median of 12 years after pulse pressure assessment. Cumulative 20-year AF incidence rates were 5.6% for pulse pressure of 40 mm Hg or less (25th percentile) and 23.3% for pulse pressure greater than 61 mm Hg (75th percentile). In models adjusted for age, sex, baseline and time-dependent change in mean arterial pressure, and clinical risk factors for AF (body mass index, smoking, valvular disease, diabetes, electrocardiographic left ventricular hypertrophy, hypertension treatment, and prevalent myocardial infarction or heart failure), pulse pressure was associated with increased risk for AF (adjusted hazard ratio [HR], 1.26 per 20-mm Hg increment; 95% confidence interval [CI], 1.12-1.43; P<.001). In contrast, mean arterial pressure was unrelated to incident AF (adjusted HR, 0.96 per 10-mm Hg increment; 95% CI, 0.88-1.05; P = .39). Systolic pressure was related to AF (HR, 1.14 per 20-mm Hg increment; 95% CI, 1.04-1.25; P = .006); however, if diastolic pressure was added, model fit improved and the diastolic relation was inverse (adjusted HR, 0.87 per 10-mm Hg increment; 95% CI, 0.78-0.96; P = .01), consistent with a pulse pressure effect. Among patients with interpretable echocardiographic images, the association between pulse pressure and AF persisted in models that adjusted for baseline left atrial dimension, left ventricular mass, and left ventricular fractional shortening (adjusted HR, 1.23; 95% CI, 1.09-1.39; P = .001).Pulse pressure is an important risk factor for incident AF in a community-based sample. Further research is needed to determine whether interventions that reduce pulse pressure will limit the growing incidence of AF.","Pulse pressure and risk of new-onset atrial fibrillation."
"757","JAMA.4161","0.39",17312290,2007,"Atrial fibrillation (AF) is responsible for considerable morbidity and mortality, making identification of modifiable risk factors a priority. Increased pulse pressure, a reflection of aortic stiffness, increases cardiac load and may increase AF risk.To examine relations between pulse pressure and incident AF.Prospective, community-based observational cohort in Framingham, Mass, including 5331 Framingham Heart Study participants aged 35 years and older and initially free from AF (median age, 57 years; 55% women).Incident AF.AF developed in 698 participants (13.1%) a median of 12 years after pulse pressure assessment. Cumulative 20-year AF incidence rates were 5.6% for pulse pressure of 40 mm Hg or less (25th percentile) and 23.3% for pulse pressure greater than 61 mm Hg (75th percentile). In models adjusted for age, sex, baseline and time-dependent change in mean arterial pressure, and clinical risk factors for AF (body mass index, smoking, valvular disease, diabetes, electrocardiographic left ventricular hypertrophy, hypertension treatment, and prevalent myocardial infarction or heart failure), pulse pressure was associated with increased risk for AF (adjusted hazard ratio [HR], 1.26 per 20-mm Hg increment; 95% confidence interval [CI], 1.12-1.43; P<.001). In contrast, mean arterial pressure was unrelated to incident AF (adjusted HR, 0.96 per 10-mm Hg increment; 95% CI, 0.88-1.05; P = .39). Systolic pressure was related to AF (HR, 1.14 per 20-mm Hg increment; 95% CI, 1.04-1.25; P = .006); however, if diastolic pressure was added, model fit improved and the diastolic relation was inverse (adjusted HR, 0.87 per 10-mm Hg increment; 95% CI, 0.78-0.96; P = .01), consistent with a pulse pressure effect. Among patients with interpretable echocardiographic images, the association between pulse pressure and AF persisted in models that adjusted for baseline left atrial dimension, left ventricular mass, and left ventricular fractional shortening (adjusted HR, 1.23; 95% CI, 1.09-1.39; P = .001).Pulse pressure is an important risk factor for incident AF in a community-based sample. Further research is needed to determine whether interventions that reduce pulse pressure will limit the growing incidence of AF.","Pulse pressure and risk of new-onset atrial fibrillation."
"758","JAMA.4171","0.006",17312290,2007,"Atrial fibrillation (AF) is responsible for considerable morbidity and mortality, making identification of modifiable risk factors a priority. Increased pulse pressure, a reflection of aortic stiffness, increases cardiac load and may increase AF risk.To examine relations between pulse pressure and incident AF.Prospective, community-based observational cohort in Framingham, Mass, including 5331 Framingham Heart Study participants aged 35 years and older and initially free from AF (median age, 57 years; 55% women).Incident AF.AF developed in 698 participants (13.1%) a median of 12 years after pulse pressure assessment. Cumulative 20-year AF incidence rates were 5.6% for pulse pressure of 40 mm Hg or less (25th percentile) and 23.3% for pulse pressure greater than 61 mm Hg (75th percentile). In models adjusted for age, sex, baseline and time-dependent change in mean arterial pressure, and clinical risk factors for AF (body mass index, smoking, valvular disease, diabetes, electrocardiographic left ventricular hypertrophy, hypertension treatment, and prevalent myocardial infarction or heart failure), pulse pressure was associated with increased risk for AF (adjusted hazard ratio [HR], 1.26 per 20-mm Hg increment; 95% confidence interval [CI], 1.12-1.43; P<.001). In contrast, mean arterial pressure was unrelated to incident AF (adjusted HR, 0.96 per 10-mm Hg increment; 95% CI, 0.88-1.05; P = .39). Systolic pressure was related to AF (HR, 1.14 per 20-mm Hg increment; 95% CI, 1.04-1.25; P = .006); however, if diastolic pressure was added, model fit improved and the diastolic relation was inverse (adjusted HR, 0.87 per 10-mm Hg increment; 95% CI, 0.78-0.96; P = .01), consistent with a pulse pressure effect. Among patients with interpretable echocardiographic images, the association between pulse pressure and AF persisted in models that adjusted for baseline left atrial dimension, left ventricular mass, and left ventricular fractional shortening (adjusted HR, 1.23; 95% CI, 1.09-1.39; P = .001).Pulse pressure is an important risk factor for incident AF in a community-based sample. Further research is needed to determine whether interventions that reduce pulse pressure will limit the growing incidence of AF.","Pulse pressure and risk of new-onset atrial fibrillation."
"759","JAMA.4181","0.01",17312290,2007,"Atrial fibrillation (AF) is responsible for considerable morbidity and mortality, making identification of modifiable risk factors a priority. Increased pulse pressure, a reflection of aortic stiffness, increases cardiac load and may increase AF risk.To examine relations between pulse pressure and incident AF.Prospective, community-based observational cohort in Framingham, Mass, including 5331 Framingham Heart Study participants aged 35 years and older and initially free from AF (median age, 57 years; 55% women).Incident AF.AF developed in 698 participants (13.1%) a median of 12 years after pulse pressure assessment. Cumulative 20-year AF incidence rates were 5.6% for pulse pressure of 40 mm Hg or less (25th percentile) and 23.3% for pulse pressure greater than 61 mm Hg (75th percentile). In models adjusted for age, sex, baseline and time-dependent change in mean arterial pressure, and clinical risk factors for AF (body mass index, smoking, valvular disease, diabetes, electrocardiographic left ventricular hypertrophy, hypertension treatment, and prevalent myocardial infarction or heart failure), pulse pressure was associated with increased risk for AF (adjusted hazard ratio [HR], 1.26 per 20-mm Hg increment; 95% confidence interval [CI], 1.12-1.43; P<.001). In contrast, mean arterial pressure was unrelated to incident AF (adjusted HR, 0.96 per 10-mm Hg increment; 95% CI, 0.88-1.05; P = .39). Systolic pressure was related to AF (HR, 1.14 per 20-mm Hg increment; 95% CI, 1.04-1.25; P = .006); however, if diastolic pressure was added, model fit improved and the diastolic relation was inverse (adjusted HR, 0.87 per 10-mm Hg increment; 95% CI, 0.78-0.96; P = .01), consistent with a pulse pressure effect. Among patients with interpretable echocardiographic images, the association between pulse pressure and AF persisted in models that adjusted for baseline left atrial dimension, left ventricular mass, and left ventricular fractional shortening (adjusted HR, 1.23; 95% CI, 1.09-1.39; P = .001).Pulse pressure is an important risk factor for incident AF in a community-based sample. Further research is needed to determine whether interventions that reduce pulse pressure will limit the growing incidence of AF.","Pulse pressure and risk of new-onset atrial fibrillation."
"760","JAMA.4191","0.001",17312290,2007,"Atrial fibrillation (AF) is responsible for considerable morbidity and mortality, making identification of modifiable risk factors a priority. Increased pulse pressure, a reflection of aortic stiffness, increases cardiac load and may increase AF risk.To examine relations between pulse pressure and incident AF.Prospective, community-based observational cohort in Framingham, Mass, including 5331 Framingham Heart Study participants aged 35 years and older and initially free from AF (median age, 57 years; 55% women).Incident AF.AF developed in 698 participants (13.1%) a median of 12 years after pulse pressure assessment. Cumulative 20-year AF incidence rates were 5.6% for pulse pressure of 40 mm Hg or less (25th percentile) and 23.3% for pulse pressure greater than 61 mm Hg (75th percentile). In models adjusted for age, sex, baseline and time-dependent change in mean arterial pressure, and clinical risk factors for AF (body mass index, smoking, valvular disease, diabetes, electrocardiographic left ventricular hypertrophy, hypertension treatment, and prevalent myocardial infarction or heart failure), pulse pressure was associated with increased risk for AF (adjusted hazard ratio [HR], 1.26 per 20-mm Hg increment; 95% confidence interval [CI], 1.12-1.43; P<.001). In contrast, mean arterial pressure was unrelated to incident AF (adjusted HR, 0.96 per 10-mm Hg increment; 95% CI, 0.88-1.05; P = .39). Systolic pressure was related to AF (HR, 1.14 per 20-mm Hg increment; 95% CI, 1.04-1.25; P = .006); however, if diastolic pressure was added, model fit improved and the diastolic relation was inverse (adjusted HR, 0.87 per 10-mm Hg increment; 95% CI, 0.78-0.96; P = .01), consistent with a pulse pressure effect. Among patients with interpretable echocardiographic images, the association between pulse pressure and AF persisted in models that adjusted for baseline left atrial dimension, left ventricular mass, and left ventricular fractional shortening (adjusted HR, 1.23; 95% CI, 1.09-1.39; P = .001).Pulse pressure is an important risk factor for incident AF in a community-based sample. Further research is needed to determine whether interventions that reduce pulse pressure will limit the growing incidence of AF.","Pulse pressure and risk of new-onset atrial fibrillation."
"761","Lancet.981","0.09",17350451,2007,"The ICTUS trial was a study that compared an early invasive with a selective invasive treatment strategy in patients with non-ST-elevation acute coronary syndrome (nSTE-ACS). The study reported no difference between the strategies for frequency of death, myocardial infarction, or rehospitalisation after 1 year. We did a follow-up study to assess the effects of these treatment strategies after 4 years.1200 patients with nSTE-ACS and an elevated cardiac troponin were enrolled from 42 hospitals in the Netherlands. Patients were randomly assigned either to an early invasive strategy, including early routine catheterisation and revascularisation where appropriate, or to a more selective invasive strategy, where catheterisation was done if the patient had refractory angina or recurrent ischaemia. The main endpoints for the current follow-up study were death, recurrent myocardial infarction, or rehospitalisation for anginal symptoms within 3 years after randomisation, and cardiovascular mortality and all-cause mortality within 4 years. Analysis was by intention-to-treat. This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN82153174.The in-hospital revascularisation rate was 76% in the early invasive group and 40% in the selective invasive group. After 3 years, the cumulative rate for the combined endpoint was 30.0% in the early invasive group compared with 26.0% in the selective invasive group (hazard ratio 1.21; 95% CI 0.97-1.50; p=0.09). Myocardial infarction was more frequent in the early invasive strategy group (106 [18.3%] vs 69 [12.3%]; HR 1.61; 1.19-2.18; p=0.002). Rates of death or spontaneous myocardial infarction were not different (76 [14.3%] patients in the early invasive and 63 [11.2%] patients in the selective invasive strategy [HR 1.19; 0.86-1.67; p=0.30]). No difference in all-cause mortality (7.9%vs 7.7%; p=0.62) or cardiovascular mortality (4.5%vs 5.0%; p=0.97) was seen within 4 years.Long-term follow-up of the ICTUS trial suggests that an early invasive strategy might not be better than a more selective invasive strategy in patients with nSTE-ACS and an elevated cardiac troponin, and implementation of either strategy might be acceptable in these patients.","Long-term outcome after an early invasive versus selective invasive treatment strategy in patients with non-ST-elevation acute coronary syndrome and elevated cardiac troponin T (the ICTUS trial): a follow-up study."
"762","Lancet.991","0.002",17350451,2007,"The ICTUS trial was a study that compared an early invasive with a selective invasive treatment strategy in patients with non-ST-elevation acute coronary syndrome (nSTE-ACS). The study reported no difference between the strategies for frequency of death, myocardial infarction, or rehospitalisation after 1 year. We did a follow-up study to assess the effects of these treatment strategies after 4 years.1200 patients with nSTE-ACS and an elevated cardiac troponin were enrolled from 42 hospitals in the Netherlands. Patients were randomly assigned either to an early invasive strategy, including early routine catheterisation and revascularisation where appropriate, or to a more selective invasive strategy, where catheterisation was done if the patient had refractory angina or recurrent ischaemia. The main endpoints for the current follow-up study were death, recurrent myocardial infarction, or rehospitalisation for anginal symptoms within 3 years after randomisation, and cardiovascular mortality and all-cause mortality within 4 years. Analysis was by intention-to-treat. This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN82153174.The in-hospital revascularisation rate was 76% in the early invasive group and 40% in the selective invasive group. After 3 years, the cumulative rate for the combined endpoint was 30.0% in the early invasive group compared with 26.0% in the selective invasive group (hazard ratio 1.21; 95% CI 0.97-1.50; p=0.09). Myocardial infarction was more frequent in the early invasive strategy group (106 [18.3%] vs 69 [12.3%]; HR 1.61; 1.19-2.18; p=0.002). Rates of death or spontaneous myocardial infarction were not different (76 [14.3%] patients in the early invasive and 63 [11.2%] patients in the selective invasive strategy [HR 1.19; 0.86-1.67; p=0.30]). No difference in all-cause mortality (7.9%vs 7.7%; p=0.62) or cardiovascular mortality (4.5%vs 5.0%; p=0.97) was seen within 4 years.Long-term follow-up of the ICTUS trial suggests that an early invasive strategy might not be better than a more selective invasive strategy in patients with nSTE-ACS and an elevated cardiac troponin, and implementation of either strategy might be acceptable in these patients.","Long-term outcome after an early invasive versus selective invasive treatment strategy in patients with non-ST-elevation acute coronary syndrome and elevated cardiac troponin T (the ICTUS trial): a follow-up study."
"763","Lancet.1001","0.3",17350451,2007,"The ICTUS trial was a study that compared an early invasive with a selective invasive treatment strategy in patients with non-ST-elevation acute coronary syndrome (nSTE-ACS). The study reported no difference between the strategies for frequency of death, myocardial infarction, or rehospitalisation after 1 year. We did a follow-up study to assess the effects of these treatment strategies after 4 years.1200 patients with nSTE-ACS and an elevated cardiac troponin were enrolled from 42 hospitals in the Netherlands. Patients were randomly assigned either to an early invasive strategy, including early routine catheterisation and revascularisation where appropriate, or to a more selective invasive strategy, where catheterisation was done if the patient had refractory angina or recurrent ischaemia. The main endpoints for the current follow-up study were death, recurrent myocardial infarction, or rehospitalisation for anginal symptoms within 3 years after randomisation, and cardiovascular mortality and all-cause mortality within 4 years. Analysis was by intention-to-treat. This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN82153174.The in-hospital revascularisation rate was 76% in the early invasive group and 40% in the selective invasive group. After 3 years, the cumulative rate for the combined endpoint was 30.0% in the early invasive group compared with 26.0% in the selective invasive group (hazard ratio 1.21; 95% CI 0.97-1.50; p=0.09). Myocardial infarction was more frequent in the early invasive strategy group (106 [18.3%] vs 69 [12.3%]; HR 1.61; 1.19-2.18; p=0.002). Rates of death or spontaneous myocardial infarction were not different (76 [14.3%] patients in the early invasive and 63 [11.2%] patients in the selective invasive strategy [HR 1.19; 0.86-1.67; p=0.30]). No difference in all-cause mortality (7.9%vs 7.7%; p=0.62) or cardiovascular mortality (4.5%vs 5.0%; p=0.97) was seen within 4 years.Long-term follow-up of the ICTUS trial suggests that an early invasive strategy might not be better than a more selective invasive strategy in patients with nSTE-ACS and an elevated cardiac troponin, and implementation of either strategy might be acceptable in these patients.","Long-term outcome after an early invasive versus selective invasive treatment strategy in patients with non-ST-elevation acute coronary syndrome and elevated cardiac troponin T (the ICTUS trial): a follow-up study."
"764","JAMA.398","0.001",17392239,2007,"Prosthetic valve endocarditis (PVE) is associated with significant mortality and morbidity. The contemporary clinical profile and outcome of PVE are not well defined.To describe the prevalence, clinical characteristics, and outcome of PVE, with attention to health care-associated infection, and to determine prognostic factors associated with in-hospital mortality.Prospective, observational cohort study conducted at 61 medical centers in 28 countries, including 556 patients with definite PVE as defined by Duke University diagnostic criteria who were enrolled in the International Collaboration on Endocarditis-Prospective Cohort Study from June 2000 to August 2005.In-hospital mortality.Definite PVE was present in 556 (20.1%) of 2670 patients with infective endocarditis. Staphylococcus aureus was the most common causative organism (128 patients [23.0%]), followed by coagulase-negative staphylococci (94 patients [16.9%]). Health care-associated PVE was present in 203 (36.5%) of the overall cohort. Seventy-one percent of health care-associated PVE occurred within the first year of valve implantation, and the majority of cases were diagnosed after the early (60-day) period. Surgery was performed in 272 (48.9%) patients during the index hospitalization. In-hospital death occurred in 127 (22.8%) patients and was predicted by older age, health care-associated infection (62/203 [30.5%]; adjusted odds ratio [OR], 1.62; 95% confidence interval [CI], 1.08-2.44; P = .02), S aureus infection (44/128 [34.4%]; adjusted OR, 1.73; 95% CI, 1.01-2.95; P = .05), and complications of PVE, including heart failure (60/183 [32.8%]; adjusted OR, 2.33; 95% CI, 1.62-3.34; P<.001), stroke (34/101 [33.7%]; adjusted OR, 2.25; 95% CI, 1.25-4.03; P = .007), intracardiac abscess (47/144 [32.6%]; adjusted OR, 1.86; 95% CI, 1.10-3.15; P = .02), and persistent bacteremia (27/49 [55.1%]; adjusted OR, 4.29; 95% CI, 1.99-9.22; P<.001).Prosthetic valve endocarditis accounts for a high percentage of all cases of infective endocarditis in many regions of the world. Staphylococcus aureus is now the leading cause of PVE. Health care-associated infection significantly influences the clinical characteristics and outcome of PVE. Complications of PVE strongly predict in-hospital mortality, which remains high despite prompt diagnosis and the frequent use of surgical intervention.","Contemporary clinical profile and outcome of prosthetic valve endocarditis."
"765","JAMA.399","0.001",17392239,2007,"Prosthetic valve endocarditis (PVE) is associated with significant mortality and morbidity. The contemporary clinical profile and outcome of PVE are not well defined.To describe the prevalence, clinical characteristics, and outcome of PVE, with attention to health care-associated infection, and to determine prognostic factors associated with in-hospital mortality.Prospective, observational cohort study conducted at 61 medical centers in 28 countries, including 556 patients with definite PVE as defined by Duke University diagnostic criteria who were enrolled in the International Collaboration on Endocarditis-Prospective Cohort Study from June 2000 to August 2005.In-hospital mortality.Definite PVE was present in 556 (20.1%) of 2670 patients with infective endocarditis. Staphylococcus aureus was the most common causative organism (128 patients [23.0%]), followed by coagulase-negative staphylococci (94 patients [16.9%]). Health care-associated PVE was present in 203 (36.5%) of the overall cohort. Seventy-one percent of health care-associated PVE occurred within the first year of valve implantation, and the majority of cases were diagnosed after the early (60-day) period. Surgery was performed in 272 (48.9%) patients during the index hospitalization. In-hospital death occurred in 127 (22.8%) patients and was predicted by older age, health care-associated infection (62/203 [30.5%]; adjusted odds ratio [OR], 1.62; 95% confidence interval [CI], 1.08-2.44; P = .02), S aureus infection (44/128 [34.4%]; adjusted OR, 1.73; 95% CI, 1.01-2.95; P = .05), and complications of PVE, including heart failure (60/183 [32.8%]; adjusted OR, 2.33; 95% CI, 1.62-3.34; P<.001), stroke (34/101 [33.7%]; adjusted OR, 2.25; 95% CI, 1.25-4.03; P = .007), intracardiac abscess (47/144 [32.6%]; adjusted OR, 1.86; 95% CI, 1.10-3.15; P = .02), and persistent bacteremia (27/49 [55.1%]; adjusted OR, 4.29; 95% CI, 1.99-9.22; P<.001).Prosthetic valve endocarditis accounts for a high percentage of all cases of infective endocarditis in many regions of the world. Staphylococcus aureus is now the leading cause of PVE. Health care-associated infection significantly influences the clinical characteristics and outcome of PVE. Complications of PVE strongly predict in-hospital mortality, which remains high despite prompt diagnosis and the frequent use of surgical intervention.","Contemporary clinical profile and outcome of prosthetic valve endocarditis."
"766","JAMA.417","0.02",17392239,2007,"Prosthetic valve endocarditis (PVE) is associated with significant mortality and morbidity. The contemporary clinical profile and outcome of PVE are not well defined.To describe the prevalence, clinical characteristics, and outcome of PVE, with attention to health care-associated infection, and to determine prognostic factors associated with in-hospital mortality.Prospective, observational cohort study conducted at 61 medical centers in 28 countries, including 556 patients with definite PVE as defined by Duke University diagnostic criteria who were enrolled in the International Collaboration on Endocarditis-Prospective Cohort Study from June 2000 to August 2005.In-hospital mortality.Definite PVE was present in 556 (20.1%) of 2670 patients with infective endocarditis. Staphylococcus aureus was the most common causative organism (128 patients [23.0%]), followed by coagulase-negative staphylococci (94 patients [16.9%]). Health care-associated PVE was present in 203 (36.5%) of the overall cohort. Seventy-one percent of health care-associated PVE occurred within the first year of valve implantation, and the majority of cases were diagnosed after the early (60-day) period. Surgery was performed in 272 (48.9%) patients during the index hospitalization. In-hospital death occurred in 127 (22.8%) patients and was predicted by older age, health care-associated infection (62/203 [30.5%]; adjusted odds ratio [OR], 1.62; 95% confidence interval [CI], 1.08-2.44; P = .02), S aureus infection (44/128 [34.4%]; adjusted OR, 1.73; 95% CI, 1.01-2.95; P = .05), and complications of PVE, including heart failure (60/183 [32.8%]; adjusted OR, 2.33; 95% CI, 1.62-3.34; P<.001), stroke (34/101 [33.7%]; adjusted OR, 2.25; 95% CI, 1.25-4.03; P = .007), intracardiac abscess (47/144 [32.6%]; adjusted OR, 1.86; 95% CI, 1.10-3.15; P = .02), and persistent bacteremia (27/49 [55.1%]; adjusted OR, 4.29; 95% CI, 1.99-9.22; P<.001).Prosthetic valve endocarditis accounts for a high percentage of all cases of infective endocarditis in many regions of the world. Staphylococcus aureus is now the leading cause of PVE. Health care-associated infection significantly influences the clinical characteristics and outcome of PVE. Complications of PVE strongly predict in-hospital mortality, which remains high despite prompt diagnosis and the frequent use of surgical intervention.","Contemporary clinical profile and outcome of prosthetic valve endocarditis."
"767","JAMA.418","0.05",17392239,2007,"Prosthetic valve endocarditis (PVE) is associated with significant mortality and morbidity. The contemporary clinical profile and outcome of PVE are not well defined.To describe the prevalence, clinical characteristics, and outcome of PVE, with attention to health care-associated infection, and to determine prognostic factors associated with in-hospital mortality.Prospective, observational cohort study conducted at 61 medical centers in 28 countries, including 556 patients with definite PVE as defined by Duke University diagnostic criteria who were enrolled in the International Collaboration on Endocarditis-Prospective Cohort Study from June 2000 to August 2005.In-hospital mortality.Definite PVE was present in 556 (20.1%) of 2670 patients with infective endocarditis. Staphylococcus aureus was the most common causative organism (128 patients [23.0%]), followed by coagulase-negative staphylococci (94 patients [16.9%]). Health care-associated PVE was present in 203 (36.5%) of the overall cohort. Seventy-one percent of health care-associated PVE occurred within the first year of valve implantation, and the majority of cases were diagnosed after the early (60-day) period. Surgery was performed in 272 (48.9%) patients during the index hospitalization. In-hospital death occurred in 127 (22.8%) patients and was predicted by older age, health care-associated infection (62/203 [30.5%]; adjusted odds ratio [OR], 1.62; 95% confidence interval [CI], 1.08-2.44; P = .02), S aureus infection (44/128 [34.4%]; adjusted OR, 1.73; 95% CI, 1.01-2.95; P = .05), and complications of PVE, including heart failure (60/183 [32.8%]; adjusted OR, 2.33; 95% CI, 1.62-3.34; P<.001), stroke (34/101 [33.7%]; adjusted OR, 2.25; 95% CI, 1.25-4.03; P = .007), intracardiac abscess (47/144 [32.6%]; adjusted OR, 1.86; 95% CI, 1.10-3.15; P = .02), and persistent bacteremia (27/49 [55.1%]; adjusted OR, 4.29; 95% CI, 1.99-9.22; P<.001).Prosthetic valve endocarditis accounts for a high percentage of all cases of infective endocarditis in many regions of the world. Staphylococcus aureus is now the leading cause of PVE. Health care-associated infection significantly influences the clinical characteristics and outcome of PVE. Complications of PVE strongly predict in-hospital mortality, which remains high despite prompt diagnosis and the frequent use of surgical intervention.","Contemporary clinical profile and outcome of prosthetic valve endocarditis."
"768","JAMA.419","0.007",17392239,2007,"Prosthetic valve endocarditis (PVE) is associated with significant mortality and morbidity. The contemporary clinical profile and outcome of PVE are not well defined.To describe the prevalence, clinical characteristics, and outcome of PVE, with attention to health care-associated infection, and to determine prognostic factors associated with in-hospital mortality.Prospective, observational cohort study conducted at 61 medical centers in 28 countries, including 556 patients with definite PVE as defined by Duke University diagnostic criteria who were enrolled in the International Collaboration on Endocarditis-Prospective Cohort Study from June 2000 to August 2005.In-hospital mortality.Definite PVE was present in 556 (20.1%) of 2670 patients with infective endocarditis. Staphylococcus aureus was the most common causative organism (128 patients [23.0%]), followed by coagulase-negative staphylococci (94 patients [16.9%]). Health care-associated PVE was present in 203 (36.5%) of the overall cohort. Seventy-one percent of health care-associated PVE occurred within the first year of valve implantation, and the majority of cases were diagnosed after the early (60-day) period. Surgery was performed in 272 (48.9%) patients during the index hospitalization. In-hospital death occurred in 127 (22.8%) patients and was predicted by older age, health care-associated infection (62/203 [30.5%]; adjusted odds ratio [OR], 1.62; 95% confidence interval [CI], 1.08-2.44; P = .02), S aureus infection (44/128 [34.4%]; adjusted OR, 1.73; 95% CI, 1.01-2.95; P = .05), and complications of PVE, including heart failure (60/183 [32.8%]; adjusted OR, 2.33; 95% CI, 1.62-3.34; P<.001), stroke (34/101 [33.7%]; adjusted OR, 2.25; 95% CI, 1.25-4.03; P = .007), intracardiac abscess (47/144 [32.6%]; adjusted OR, 1.86; 95% CI, 1.10-3.15; P = .02), and persistent bacteremia (27/49 [55.1%]; adjusted OR, 4.29; 95% CI, 1.99-9.22; P<.001).Prosthetic valve endocarditis accounts for a high percentage of all cases of infective endocarditis in many regions of the world. Staphylococcus aureus is now the leading cause of PVE. Health care-associated infection significantly influences the clinical characteristics and outcome of PVE. Complications of PVE strongly predict in-hospital mortality, which remains high despite prompt diagnosis and the frequent use of surgical intervention.","Contemporary clinical profile and outcome of prosthetic valve endocarditis."
"769","JAMA.420","0.02",17392239,2007,"Prosthetic valve endocarditis (PVE) is associated with significant mortality and morbidity. The contemporary clinical profile and outcome of PVE are not well defined.To describe the prevalence, clinical characteristics, and outcome of PVE, with attention to health care-associated infection, and to determine prognostic factors associated with in-hospital mortality.Prospective, observational cohort study conducted at 61 medical centers in 28 countries, including 556 patients with definite PVE as defined by Duke University diagnostic criteria who were enrolled in the International Collaboration on Endocarditis-Prospective Cohort Study from June 2000 to August 2005.In-hospital mortality.Definite PVE was present in 556 (20.1%) of 2670 patients with infective endocarditis. Staphylococcus aureus was the most common causative organism (128 patients [23.0%]), followed by coagulase-negative staphylococci (94 patients [16.9%]). Health care-associated PVE was present in 203 (36.5%) of the overall cohort. Seventy-one percent of health care-associated PVE occurred within the first year of valve implantation, and the majority of cases were diagnosed after the early (60-day) period. Surgery was performed in 272 (48.9%) patients during the index hospitalization. In-hospital death occurred in 127 (22.8%) patients and was predicted by older age, health care-associated infection (62/203 [30.5%]; adjusted odds ratio [OR], 1.62; 95% confidence interval [CI], 1.08-2.44; P = .02), S aureus infection (44/128 [34.4%]; adjusted OR, 1.73; 95% CI, 1.01-2.95; P = .05), and complications of PVE, including heart failure (60/183 [32.8%]; adjusted OR, 2.33; 95% CI, 1.62-3.34; P<.001), stroke (34/101 [33.7%]; adjusted OR, 2.25; 95% CI, 1.25-4.03; P = .007), intracardiac abscess (47/144 [32.6%]; adjusted OR, 1.86; 95% CI, 1.10-3.15; P = .02), and persistent bacteremia (27/49 [55.1%]; adjusted OR, 4.29; 95% CI, 1.99-9.22; P<.001).Prosthetic valve endocarditis accounts for a high percentage of all cases of infective endocarditis in many regions of the world. Staphylococcus aureus is now the leading cause of PVE. Health care-associated infection significantly influences the clinical characteristics and outcome of PVE. Complications of PVE strongly predict in-hospital mortality, which remains high despite prompt diagnosis and the frequent use of surgical intervention.","Contemporary clinical profile and outcome of prosthetic valve endocarditis."
"770","Lancet.951","0.018",17398310,2007,"Exclusive breastfeeding, though better than other forms of infant feeding and associated with improved child survival, is uncommon. We assessed the HIV-1 transmission risks and survival associated with exclusive breastfeeding and other types of infant feeding.2722 HIV-infected and uninfected pregnant women attending antenatal clinics in KwaZulu Natal, South Africa (seven rural, one semiurban, and one urban), were enrolled into a non-randomised intervention cohort study. Infant feeding data were obtained every week from mothers, and blood samples from infants were taken monthly at clinics to establish HIV infection status. Kaplan-Meier analyses conditional on exclusive breastfeeding were used to estimate transmission risks at 6 weeks and 22 weeks of age, and Cox's proportional hazard was used to quantify associations with maternal and infant factors.1132 of 1372 (83%) infants born to HIV-infected mothers initiated exclusive breastfeeding from birth. Of 1276 infants with complete feeding data, median duration of cumulative exclusive breastfeeding was 159 days (first quartile [Q1] to third quartile [Q3], 122-174 days). 14.1% (95% CI 12.0-16.4) of exclusively breastfed infants were infected with HIV-1 by age 6 weeks and 19.5% (17.0-22.4) by 6 months; risk was significantly associated with maternal CD4-cell counts below 200 cells per muL (adjusted hazard ratio [HR] 3.79; 2.35-6.12) and birthweight less than 2500 g (1.81, 1.07-3.06). Kaplan-Meier estimated risk of acquisition of infection at 6 months of age was 4.04% (2.29-5.76). Breastfed infants who also received solids were significantly more likely to acquire infection than were exclusively breastfed children (HR 10.87, 1.51-78.00, p=0.018), as were infants who at 12 weeks received both breastmilk and formula milk (1.82, 0.98-3.36, p=0.057). Cumulative 3-month mortality in exclusively breastfed infants was 6.1% (4.74-7.92) versus 15.1% (7.63-28.73) in infants given replacement feeds (HR 2.06, 1.00-4.27, p=0.051).The association between mixed breastfeeding and increased HIV transmission risk, together with evidence that exclusive breastfeeding can be successfully supported in HIV-infected women, warrant revision of the present UNICEF, WHO, and UNAIDS infant feeding guidelines.","Mother-to-child transmission of HIV-1 infection during exclusive breastfeeding in the first 6 months of life: an intervention cohort study."
"771","Lancet.961","0.057",17398310,2007,"Exclusive breastfeeding, though better than other forms of infant feeding and associated with improved child survival, is uncommon. We assessed the HIV-1 transmission risks and survival associated with exclusive breastfeeding and other types of infant feeding.2722 HIV-infected and uninfected pregnant women attending antenatal clinics in KwaZulu Natal, South Africa (seven rural, one semiurban, and one urban), were enrolled into a non-randomised intervention cohort study. Infant feeding data were obtained every week from mothers, and blood samples from infants were taken monthly at clinics to establish HIV infection status. Kaplan-Meier analyses conditional on exclusive breastfeeding were used to estimate transmission risks at 6 weeks and 22 weeks of age, and Cox's proportional hazard was used to quantify associations with maternal and infant factors.1132 of 1372 (83%) infants born to HIV-infected mothers initiated exclusive breastfeeding from birth. Of 1276 infants with complete feeding data, median duration of cumulative exclusive breastfeeding was 159 days (first quartile [Q1] to third quartile [Q3], 122-174 days). 14.1% (95% CI 12.0-16.4) of exclusively breastfed infants were infected with HIV-1 by age 6 weeks and 19.5% (17.0-22.4) by 6 months; risk was significantly associated with maternal CD4-cell counts below 200 cells per muL (adjusted hazard ratio [HR] 3.79; 2.35-6.12) and birthweight less than 2500 g (1.81, 1.07-3.06). Kaplan-Meier estimated risk of acquisition of infection at 6 months of age was 4.04% (2.29-5.76). Breastfed infants who also received solids were significantly more likely to acquire infection than were exclusively breastfed children (HR 10.87, 1.51-78.00, p=0.018), as were infants who at 12 weeks received both breastmilk and formula milk (1.82, 0.98-3.36, p=0.057). Cumulative 3-month mortality in exclusively breastfed infants was 6.1% (4.74-7.92) versus 15.1% (7.63-28.73) in infants given replacement feeds (HR 2.06, 1.00-4.27, p=0.051).The association between mixed breastfeeding and increased HIV transmission risk, together with evidence that exclusive breastfeeding can be successfully supported in HIV-infected women, warrant revision of the present UNICEF, WHO, and UNAIDS infant feeding guidelines.","Mother-to-child transmission of HIV-1 infection during exclusive breastfeeding in the first 6 months of life: an intervention cohort study."
"772","Lancet.971","0.051",17398310,2007,"Exclusive breastfeeding, though better than other forms of infant feeding and associated with improved child survival, is uncommon. We assessed the HIV-1 transmission risks and survival associated with exclusive breastfeeding and other types of infant feeding.2722 HIV-infected and uninfected pregnant women attending antenatal clinics in KwaZulu Natal, South Africa (seven rural, one semiurban, and one urban), were enrolled into a non-randomised intervention cohort study. Infant feeding data were obtained every week from mothers, and blood samples from infants were taken monthly at clinics to establish HIV infection status. Kaplan-Meier analyses conditional on exclusive breastfeeding were used to estimate transmission risks at 6 weeks and 22 weeks of age, and Cox's proportional hazard was used to quantify associations with maternal and infant factors.1132 of 1372 (83%) infants born to HIV-infected mothers initiated exclusive breastfeeding from birth. Of 1276 infants with complete feeding data, median duration of cumulative exclusive breastfeeding was 159 days (first quartile [Q1] to third quartile [Q3], 122-174 days). 14.1% (95% CI 12.0-16.4) of exclusively breastfed infants were infected with HIV-1 by age 6 weeks and 19.5% (17.0-22.4) by 6 months; risk was significantly associated with maternal CD4-cell counts below 200 cells per muL (adjusted hazard ratio [HR] 3.79; 2.35-6.12) and birthweight less than 2500 g (1.81, 1.07-3.06). Kaplan-Meier estimated risk of acquisition of infection at 6 months of age was 4.04% (2.29-5.76). Breastfed infants who also received solids were significantly more likely to acquire infection than were exclusively breastfed children (HR 10.87, 1.51-78.00, p=0.018), as were infants who at 12 weeks received both breastmilk and formula milk (1.82, 0.98-3.36, p=0.057). Cumulative 3-month mortality in exclusively breastfed infants was 6.1% (4.74-7.92) versus 15.1% (7.63-28.73) in infants given replacement feeds (HR 2.06, 1.00-4.27, p=0.051).The association between mixed breastfeeding and increased HIV transmission risk, together with evidence that exclusive breastfeeding can be successfully supported in HIV-infected women, warrant revision of the present UNICEF, WHO, and UNAIDS infant feeding guidelines.","Mother-to-child transmission of HIV-1 infection during exclusive breastfeeding in the first 6 months of life: an intervention cohort study."
"773","JAMA.4101","0.11",17456819,2007,"Ranolazine is a novel antianginal agent that reduces ischemia in patients with chronic angina but has not been studied in patients with acute coronary syndromes (ACS).To determine the efficacy and safety of ranolazine during long-term treatment of patients with non-ST-elevation ACS.A randomized, double-blind, placebo-controlled, multinational clinical trial of 6560 patients within 48 hours of ischemic symptoms who were treated with ranolazine (initiated intravenously and followed by oral ranolazine extended-release 1000 mg twice daily, n = 3279) or matching placebo (n = 3281), and followed up for a median of 348 days in the Metabolic Efficiency With Ranolazine for Less Ischemia in Non-ST-Elevation Acute Coronary Syndromes (MERLIN)-TIMI 36 trial between October 8, 2004, and February 14, 2007.The primary efficacy end point was a composite of cardiovascular death, myocardial infarction (MI), or recurrent ischemia through the end of study. The major safety end points were death from any cause and symptomatic documented arrhythmia.The primary end point occurred in 696 patients (21.8%) in the ranolazine group and 753 patients (23.5%) in the placebo group (hazard ratio [HR], 0.92; 95% confidence interval [CI], 0.83-1.02; P = .11). The major secondary end point (cardiovascular death, MI, or severe recurrent ischemia) occurred in 602 patients (18.7%) in the ranolazine group and 625 (19.2%) in the placebo group (HR, 0.96; 95% CI, 0.86-1.08; P = .50). Cardiovascular death or MI occurred in 338 patients (10.4%) allocated to ranolazine and 343 patients (10.5%) allocated to placebo (HR, 0.99; 95% CI, 0.85-1.15; P = .87). Recurrent ischemia was reduced in the ranolazine group (430 [13.9%]) compared with the placebo group (494 [16.1%]; HR, 0.87; 95% CI, 0.76-0.99; P = .03). QTc prolongation requiring a reduction in the dose of intravenous drug occurred in 31 patients (0.9%) receiving ranolazine compared with 10 patients (0.3%) receiving placebo. Symptomatic documented arrhythmias did not differ between the ranolazine (99 [3.0%]) and placebo (102 [3.1%]) groups (P = .84). No difference in total mortality was observed with ranolazine compared with placebo (172 vs 175; HR, 0.99; 95% CI, 0.80-1.22; P = .91).The addition of ranolazine to standard treatment for ACS was not effective in reducing major cardiovascular events. Ranolazine did not adversely affect the risk of all-cause death or symptomatic documented arrhythmia. Our findings provide support for the safety and efficacy of ranolazine as antianginal therapy.clinicaltrials.gov Identifier: NCT00099788.","Effects of ranolazine on recurrent cardiovascular events in patients with non-ST-elevation acute coronary syndromes: the MERLIN-TIMI 36 randomized trial."
"774","JAMA.4111","0.5",17456819,2007,"Ranolazine is a novel antianginal agent that reduces ischemia in patients with chronic angina but has not been studied in patients with acute coronary syndromes (ACS).To determine the efficacy and safety of ranolazine during long-term treatment of patients with non-ST-elevation ACS.A randomized, double-blind, placebo-controlled, multinational clinical trial of 6560 patients within 48 hours of ischemic symptoms who were treated with ranolazine (initiated intravenously and followed by oral ranolazine extended-release 1000 mg twice daily, n = 3279) or matching placebo (n = 3281), and followed up for a median of 348 days in the Metabolic Efficiency With Ranolazine for Less Ischemia in Non-ST-Elevation Acute Coronary Syndromes (MERLIN)-TIMI 36 trial between October 8, 2004, and February 14, 2007.The primary efficacy end point was a composite of cardiovascular death, myocardial infarction (MI), or recurrent ischemia through the end of study. The major safety end points were death from any cause and symptomatic documented arrhythmia.The primary end point occurred in 696 patients (21.8%) in the ranolazine group and 753 patients (23.5%) in the placebo group (hazard ratio [HR], 0.92; 95% confidence interval [CI], 0.83-1.02; P = .11). The major secondary end point (cardiovascular death, MI, or severe recurrent ischemia) occurred in 602 patients (18.7%) in the ranolazine group and 625 (19.2%) in the placebo group (HR, 0.96; 95% CI, 0.86-1.08; P = .50). Cardiovascular death or MI occurred in 338 patients (10.4%) allocated to ranolazine and 343 patients (10.5%) allocated to placebo (HR, 0.99; 95% CI, 0.85-1.15; P = .87). Recurrent ischemia was reduced in the ranolazine group (430 [13.9%]) compared with the placebo group (494 [16.1%]; HR, 0.87; 95% CI, 0.76-0.99; P = .03). QTc prolongation requiring a reduction in the dose of intravenous drug occurred in 31 patients (0.9%) receiving ranolazine compared with 10 patients (0.3%) receiving placebo. Symptomatic documented arrhythmias did not differ between the ranolazine (99 [3.0%]) and placebo (102 [3.1%]) groups (P = .84). No difference in total mortality was observed with ranolazine compared with placebo (172 vs 175; HR, 0.99; 95% CI, 0.80-1.22; P = .91).The addition of ranolazine to standard treatment for ACS was not effective in reducing major cardiovascular events. Ranolazine did not adversely affect the risk of all-cause death or symptomatic documented arrhythmia. Our findings provide support for the safety and efficacy of ranolazine as antianginal therapy.clinicaltrials.gov Identifier: NCT00099788.","Effects of ranolazine on recurrent cardiovascular events in patients with non-ST-elevation acute coronary syndromes: the MERLIN-TIMI 36 randomized trial."
"775","JAMA.4121","0.87",17456819,2007,"Ranolazine is a novel antianginal agent that reduces ischemia in patients with chronic angina but has not been studied in patients with acute coronary syndromes (ACS).To determine the efficacy and safety of ranolazine during long-term treatment of patients with non-ST-elevation ACS.A randomized, double-blind, placebo-controlled, multinational clinical trial of 6560 patients within 48 hours of ischemic symptoms who were treated with ranolazine (initiated intravenously and followed by oral ranolazine extended-release 1000 mg twice daily, n = 3279) or matching placebo (n = 3281), and followed up for a median of 348 days in the Metabolic Efficiency With Ranolazine for Less Ischemia in Non-ST-Elevation Acute Coronary Syndromes (MERLIN)-TIMI 36 trial between October 8, 2004, and February 14, 2007.The primary efficacy end point was a composite of cardiovascular death, myocardial infarction (MI), or recurrent ischemia through the end of study. The major safety end points were death from any cause and symptomatic documented arrhythmia.The primary end point occurred in 696 patients (21.8%) in the ranolazine group and 753 patients (23.5%) in the placebo group (hazard ratio [HR], 0.92; 95% confidence interval [CI], 0.83-1.02; P = .11). The major secondary end point (cardiovascular death, MI, or severe recurrent ischemia) occurred in 602 patients (18.7%) in the ranolazine group and 625 (19.2%) in the placebo group (HR, 0.96; 95% CI, 0.86-1.08; P = .50). Cardiovascular death or MI occurred in 338 patients (10.4%) allocated to ranolazine and 343 patients (10.5%) allocated to placebo (HR, 0.99; 95% CI, 0.85-1.15; P = .87). Recurrent ischemia was reduced in the ranolazine group (430 [13.9%]) compared with the placebo group (494 [16.1%]; HR, 0.87; 95% CI, 0.76-0.99; P = .03). QTc prolongation requiring a reduction in the dose of intravenous drug occurred in 31 patients (0.9%) receiving ranolazine compared with 10 patients (0.3%) receiving placebo. Symptomatic documented arrhythmias did not differ between the ranolazine (99 [3.0%]) and placebo (102 [3.1%]) groups (P = .84). No difference in total mortality was observed with ranolazine compared with placebo (172 vs 175; HR, 0.99; 95% CI, 0.80-1.22; P = .91).The addition of ranolazine to standard treatment for ACS was not effective in reducing major cardiovascular events. Ranolazine did not adversely affect the risk of all-cause death or symptomatic documented arrhythmia. Our findings provide support for the safety and efficacy of ranolazine as antianginal therapy.clinicaltrials.gov Identifier: NCT00099788.","Effects of ranolazine on recurrent cardiovascular events in patients with non-ST-elevation acute coronary syndromes: the MERLIN-TIMI 36 randomized trial."
"776","JAMA.4131","0.03",17456819,2007,"Ranolazine is a novel antianginal agent that reduces ischemia in patients with chronic angina but has not been studied in patients with acute coronary syndromes (ACS).To determine the efficacy and safety of ranolazine during long-term treatment of patients with non-ST-elevation ACS.A randomized, double-blind, placebo-controlled, multinational clinical trial of 6560 patients within 48 hours of ischemic symptoms who were treated with ranolazine (initiated intravenously and followed by oral ranolazine extended-release 1000 mg twice daily, n = 3279) or matching placebo (n = 3281), and followed up for a median of 348 days in the Metabolic Efficiency With Ranolazine for Less Ischemia in Non-ST-Elevation Acute Coronary Syndromes (MERLIN)-TIMI 36 trial between October 8, 2004, and February 14, 2007.The primary efficacy end point was a composite of cardiovascular death, myocardial infarction (MI), or recurrent ischemia through the end of study. The major safety end points were death from any cause and symptomatic documented arrhythmia.The primary end point occurred in 696 patients (21.8%) in the ranolazine group and 753 patients (23.5%) in the placebo group (hazard ratio [HR], 0.92; 95% confidence interval [CI], 0.83-1.02; P = .11). The major secondary end point (cardiovascular death, MI, or severe recurrent ischemia) occurred in 602 patients (18.7%) in the ranolazine group and 625 (19.2%) in the placebo group (HR, 0.96; 95% CI, 0.86-1.08; P = .50). Cardiovascular death or MI occurred in 338 patients (10.4%) allocated to ranolazine and 343 patients (10.5%) allocated to placebo (HR, 0.99; 95% CI, 0.85-1.15; P = .87). Recurrent ischemia was reduced in the ranolazine group (430 [13.9%]) compared with the placebo group (494 [16.1%]; HR, 0.87; 95% CI, 0.76-0.99; P = .03). QTc prolongation requiring a reduction in the dose of intravenous drug occurred in 31 patients (0.9%) receiving ranolazine compared with 10 patients (0.3%) receiving placebo. Symptomatic documented arrhythmias did not differ between the ranolazine (99 [3.0%]) and placebo (102 [3.1%]) groups (P = .84). No difference in total mortality was observed with ranolazine compared with placebo (172 vs 175; HR, 0.99; 95% CI, 0.80-1.22; P = .91).The addition of ranolazine to standard treatment for ACS was not effective in reducing major cardiovascular events. Ranolazine did not adversely affect the risk of all-cause death or symptomatic documented arrhythmia. Our findings provide support for the safety and efficacy of ranolazine as antianginal therapy.clinicaltrials.gov Identifier: NCT00099788.","Effects of ranolazine on recurrent cardiovascular events in patients with non-ST-elevation acute coronary syndromes: the MERLIN-TIMI 36 randomized trial."
"777","JAMA.4151","0.91",17456819,2007,"Ranolazine is a novel antianginal agent that reduces ischemia in patients with chronic angina but has not been studied in patients with acute coronary syndromes (ACS).To determine the efficacy and safety of ranolazine during long-term treatment of patients with non-ST-elevation ACS.A randomized, double-blind, placebo-controlled, multinational clinical trial of 6560 patients within 48 hours of ischemic symptoms who were treated with ranolazine (initiated intravenously and followed by oral ranolazine extended-release 1000 mg twice daily, n = 3279) or matching placebo (n = 3281), and followed up for a median of 348 days in the Metabolic Efficiency With Ranolazine for Less Ischemia in Non-ST-Elevation Acute Coronary Syndromes (MERLIN)-TIMI 36 trial between October 8, 2004, and February 14, 2007.The primary efficacy end point was a composite of cardiovascular death, myocardial infarction (MI), or recurrent ischemia through the end of study. The major safety end points were death from any cause and symptomatic documented arrhythmia.The primary end point occurred in 696 patients (21.8%) in the ranolazine group and 753 patients (23.5%) in the placebo group (hazard ratio [HR], 0.92; 95% confidence interval [CI], 0.83-1.02; P = .11). The major secondary end point (cardiovascular death, MI, or severe recurrent ischemia) occurred in 602 patients (18.7%) in the ranolazine group and 625 (19.2%) in the placebo group (HR, 0.96; 95% CI, 0.86-1.08; P = .50). Cardiovascular death or MI occurred in 338 patients (10.4%) allocated to ranolazine and 343 patients (10.5%) allocated to placebo (HR, 0.99; 95% CI, 0.85-1.15; P = .87). Recurrent ischemia was reduced in the ranolazine group (430 [13.9%]) compared with the placebo group (494 [16.1%]; HR, 0.87; 95% CI, 0.76-0.99; P = .03). QTc prolongation requiring a reduction in the dose of intravenous drug occurred in 31 patients (0.9%) receiving ranolazine compared with 10 patients (0.3%) receiving placebo. Symptomatic documented arrhythmias did not differ between the ranolazine (99 [3.0%]) and placebo (102 [3.1%]) groups (P = .84). No difference in total mortality was observed with ranolazine compared with placebo (172 vs 175; HR, 0.99; 95% CI, 0.80-1.22; P = .91).The addition of ranolazine to standard treatment for ACS was not effective in reducing major cardiovascular events. Ranolazine did not adversely affect the risk of all-cause death or symptomatic documented arrhythmia. Our findings provide support for the safety and efficacy of ranolazine as antianginal therapy.clinicaltrials.gov Identifier: NCT00099788.","Effects of ranolazine on recurrent cardiovascular events in patients with non-ST-elevation acute coronary syndromes: the MERLIN-TIMI 36 randomized trial."
"778","Lancet.57","0.03",17482983,2007,"Tuberculosis is re-emerging as an important health problem in industrialised countries. Uncertainty surrounds the effect of public-health control options. We therefore aimed to assess a programme to promote screening for tuberculosis in a UK primary health care district.In a cluster randomised controlled trial, we randomised 50 of 52 (96%) eligible general practices in Hackney, London, UK, to receive an outreach programme that promoted screening for tuberculosis in people registering in primary care, or to continue with usual care. Screening was verbal, and proceeded to tuberculin skin testing, if appropriate. The primary outcome was the proportion of new cases of active tuberculosis identified in primary care. Analyses were done on an intention-to-treat basis. This study was registered at clinicaltrials.gov, number NCT00214708.Between June 1, 2002, and Oct 1, 2004, 44,986 and 48,984 patients registered with intervention and control practices, respectively. In intervention practices 57% (13,478 of 23,573) of people attending a registration health check were screened for tuberculosis compared with 0.4% (84 of 23 051) in control practices. Intervention practices showed increases in the diagnosis of active tuberculosis cases in primary care compared with control practices (66/141 [47%] vs 54/157 [34%], odds ratio (OR) 1.68, 95% CI 1.05-2.68, p=0.03). Intervention practices also had increases in diagnosis of latent tuberculosis (11/59 [19%] vs 5/68 [9%], OR 3.00, 0.98-9.20, p=0.055) and BCG coverage (mean BCG rate 26.8/1000 vs 3.8/1000, intervention rate ratio 9.52, 4.0-22.7, p<0.001).Our educational intervention for promotion of screening for tuberculosis in primary care improved identification of active and latent tuberculosis, and increased BCG coverage. Yield from screening was low, but was augmented by improved case-finding. Screening programmes in primary care should be considered as part of tuberculosis control initiatives in industrialised countries.","Educational outreach to promote screening for tuberculosis in primary care: a cluster randomised controlled trial."
"779","Lancet.58","0.055",17482983,2007,"Tuberculosis is re-emerging as an important health problem in industrialised countries. Uncertainty surrounds the effect of public-health control options. We therefore aimed to assess a programme to promote screening for tuberculosis in a UK primary health care district.In a cluster randomised controlled trial, we randomised 50 of 52 (96%) eligible general practices in Hackney, London, UK, to receive an outreach programme that promoted screening for tuberculosis in people registering in primary care, or to continue with usual care. Screening was verbal, and proceeded to tuberculin skin testing, if appropriate. The primary outcome was the proportion of new cases of active tuberculosis identified in primary care. Analyses were done on an intention-to-treat basis. This study was registered at clinicaltrials.gov, number NCT00214708.Between June 1, 2002, and Oct 1, 2004, 44,986 and 48,984 patients registered with intervention and control practices, respectively. In intervention practices 57% (13,478 of 23,573) of people attending a registration health check were screened for tuberculosis compared with 0.4% (84 of 23 051) in control practices. Intervention practices showed increases in the diagnosis of active tuberculosis cases in primary care compared with control practices (66/141 [47%] vs 54/157 [34%], odds ratio (OR) 1.68, 95% CI 1.05-2.68, p=0.03). Intervention practices also had increases in diagnosis of latent tuberculosis (11/59 [19%] vs 5/68 [9%], OR 3.00, 0.98-9.20, p=0.055) and BCG coverage (mean BCG rate 26.8/1000 vs 3.8/1000, intervention rate ratio 9.52, 4.0-22.7, p<0.001).Our educational intervention for promotion of screening for tuberculosis in primary care improved identification of active and latent tuberculosis, and increased BCG coverage. Yield from screening was low, but was augmented by improved case-finding. Screening programmes in primary care should be considered as part of tuberculosis control initiatives in industrialised countries.","Educational outreach to promote screening for tuberculosis in primary care: a cluster randomised controlled trial."
"780","JAMA.4041","0.005",17488964,2007,"Limited data exist regarding use of drug-eluting stents outside of approved indications in real-world settings.To determine the frequency, safety, and effectiveness of drug-eluting stents for off-label (restenosis, bypass graft lesion, long lesions, vessel size outside of information for use recommendation) and untested (left main, ostial, bifurcation, or total occlusion lesions) indications in percutaneous coronary intervention (PCI).Observational, prospective, multicenter registry to evaluate in-hospital, 30-day, and 1-year outcomes among patients undergoing PCI between January and June 2005 in 140 US academic and community medical centers. Of 7752 PCI-treated patients, 6993 (90%) received drug-eluting stents; of these, 5851 (84%) received no other devices. Standard, off-label, and untested use was determined in 5541 (95%) of these 5851 patients, constituting the study cohort.Frequency of off-label and untested use, 1-year repeat target vessel revascularization, and composite of death, myocardial infarction (MI), or stent thrombosis at in-hospital follow-up and during 1 year of follow-up.Of 5541 patients receiving drug-eluting stents, 2588 (47%) received stents for off-label or untested indications. Adjusted in-hospital risk of death, MI, or stent thrombosis was not statistically different with off-label or untested vs standard use. At 30 days, the risk of this composite end point was significantly higher with off-label use (adjusted hazard ratio [HR], 2.08; 95% confidence interval [CI], 1.24-3.48; P = .005) but not untested use (adjusted HR, 1.45; 95% CI, 0.79-2.67; P = .23). Excluding early events, this end point was not different at 1 year with off-label use (adjusted HR, 1.10; 95% CI, 0.79-1.54; P = .57) or untested use (adjusted HR, 0.91; 95% CI, 0.60-1.38; P = .66). At 1 year, compared with standard use, significantly higher rates of target vessel revascularization were associated with off-label use (adjusted HR, 1.49; 95% CI, 1.13-1.98; P = .005) and untested use (adjusted HR, 1.49; 95% CI, 1.10-2.02; P = .01), although absolute rates were low (standard, 4.4% [n = 113]; off-label, 7.6% [n = 95]; untested, 6.7% [n = 72]).In contemporary US practice, off-label and untested use of drug-eluting stents is common. Compared with standard use, relative early safety is lower with off-label use, and the long-term effectiveness is lower with both off-label and untested use. However, the absolute event rates remain low.","Outcomes and complications associated with off-label and untested use of drug-eluting stents."
"781","JAMA.4051","0.23",17488964,2007,"Limited data exist regarding use of drug-eluting stents outside of approved indications in real-world settings.To determine the frequency, safety, and effectiveness of drug-eluting stents for off-label (restenosis, bypass graft lesion, long lesions, vessel size outside of information for use recommendation) and untested (left main, ostial, bifurcation, or total occlusion lesions) indications in percutaneous coronary intervention (PCI).Observational, prospective, multicenter registry to evaluate in-hospital, 30-day, and 1-year outcomes among patients undergoing PCI between January and June 2005 in 140 US academic and community medical centers. Of 7752 PCI-treated patients, 6993 (90%) received drug-eluting stents; of these, 5851 (84%) received no other devices. Standard, off-label, and untested use was determined in 5541 (95%) of these 5851 patients, constituting the study cohort.Frequency of off-label and untested use, 1-year repeat target vessel revascularization, and composite of death, myocardial infarction (MI), or stent thrombosis at in-hospital follow-up and during 1 year of follow-up.Of 5541 patients receiving drug-eluting stents, 2588 (47%) received stents for off-label or untested indications. Adjusted in-hospital risk of death, MI, or stent thrombosis was not statistically different with off-label or untested vs standard use. At 30 days, the risk of this composite end point was significantly higher with off-label use (adjusted hazard ratio [HR], 2.08; 95% confidence interval [CI], 1.24-3.48; P = .005) but not untested use (adjusted HR, 1.45; 95% CI, 0.79-2.67; P = .23). Excluding early events, this end point was not different at 1 year with off-label use (adjusted HR, 1.10; 95% CI, 0.79-1.54; P = .57) or untested use (adjusted HR, 0.91; 95% CI, 0.60-1.38; P = .66). At 1 year, compared with standard use, significantly higher rates of target vessel revascularization were associated with off-label use (adjusted HR, 1.49; 95% CI, 1.13-1.98; P = .005) and untested use (adjusted HR, 1.49; 95% CI, 1.10-2.02; P = .01), although absolute rates were low (standard, 4.4% [n = 113]; off-label, 7.6% [n = 95]; untested, 6.7% [n = 72]).In contemporary US practice, off-label and untested use of drug-eluting stents is common. Compared with standard use, relative early safety is lower with off-label use, and the long-term effectiveness is lower with both off-label and untested use. However, the absolute event rates remain low.","Outcomes and complications associated with off-label and untested use of drug-eluting stents."
"782","JAMA.4061","0.57",17488964,2007,"Limited data exist regarding use of drug-eluting stents outside of approved indications in real-world settings.To determine the frequency, safety, and effectiveness of drug-eluting stents for off-label (restenosis, bypass graft lesion, long lesions, vessel size outside of information for use recommendation) and untested (left main, ostial, bifurcation, or total occlusion lesions) indications in percutaneous coronary intervention (PCI).Observational, prospective, multicenter registry to evaluate in-hospital, 30-day, and 1-year outcomes among patients undergoing PCI between January and June 2005 in 140 US academic and community medical centers. Of 7752 PCI-treated patients, 6993 (90%) received drug-eluting stents; of these, 5851 (84%) received no other devices. Standard, off-label, and untested use was determined in 5541 (95%) of these 5851 patients, constituting the study cohort.Frequency of off-label and untested use, 1-year repeat target vessel revascularization, and composite of death, myocardial infarction (MI), or stent thrombosis at in-hospital follow-up and during 1 year of follow-up.Of 5541 patients receiving drug-eluting stents, 2588 (47%) received stents for off-label or untested indications. Adjusted in-hospital risk of death, MI, or stent thrombosis was not statistically different with off-label or untested vs standard use. At 30 days, the risk of this composite end point was significantly higher with off-label use (adjusted hazard ratio [HR], 2.08; 95% confidence interval [CI], 1.24-3.48; P = .005) but not untested use (adjusted HR, 1.45; 95% CI, 0.79-2.67; P = .23). Excluding early events, this end point was not different at 1 year with off-label use (adjusted HR, 1.10; 95% CI, 0.79-1.54; P = .57) or untested use (adjusted HR, 0.91; 95% CI, 0.60-1.38; P = .66). At 1 year, compared with standard use, significantly higher rates of target vessel revascularization were associated with off-label use (adjusted HR, 1.49; 95% CI, 1.13-1.98; P = .005) and untested use (adjusted HR, 1.49; 95% CI, 1.10-2.02; P = .01), although absolute rates were low (standard, 4.4% [n = 113]; off-label, 7.6% [n = 95]; untested, 6.7% [n = 72]).In contemporary US practice, off-label and untested use of drug-eluting stents is common. Compared with standard use, relative early safety is lower with off-label use, and the long-term effectiveness is lower with both off-label and untested use. However, the absolute event rates remain low.","Outcomes and complications associated with off-label and untested use of drug-eluting stents."
"783","JAMA.4071","0.66",17488964,2007,"Limited data exist regarding use of drug-eluting stents outside of approved indications in real-world settings.To determine the frequency, safety, and effectiveness of drug-eluting stents for off-label (restenosis, bypass graft lesion, long lesions, vessel size outside of information for use recommendation) and untested (left main, ostial, bifurcation, or total occlusion lesions) indications in percutaneous coronary intervention (PCI).Observational, prospective, multicenter registry to evaluate in-hospital, 30-day, and 1-year outcomes among patients undergoing PCI between January and June 2005 in 140 US academic and community medical centers. Of 7752 PCI-treated patients, 6993 (90%) received drug-eluting stents; of these, 5851 (84%) received no other devices. Standard, off-label, and untested use was determined in 5541 (95%) of these 5851 patients, constituting the study cohort.Frequency of off-label and untested use, 1-year repeat target vessel revascularization, and composite of death, myocardial infarction (MI), or stent thrombosis at in-hospital follow-up and during 1 year of follow-up.Of 5541 patients receiving drug-eluting stents, 2588 (47%) received stents for off-label or untested indications. Adjusted in-hospital risk of death, MI, or stent thrombosis was not statistically different with off-label or untested vs standard use. At 30 days, the risk of this composite end point was significantly higher with off-label use (adjusted hazard ratio [HR], 2.08; 95% confidence interval [CI], 1.24-3.48; P = .005) but not untested use (adjusted HR, 1.45; 95% CI, 0.79-2.67; P = .23). Excluding early events, this end point was not different at 1 year with off-label use (adjusted HR, 1.10; 95% CI, 0.79-1.54; P = .57) or untested use (adjusted HR, 0.91; 95% CI, 0.60-1.38; P = .66). At 1 year, compared with standard use, significantly higher rates of target vessel revascularization were associated with off-label use (adjusted HR, 1.49; 95% CI, 1.13-1.98; P = .005) and untested use (adjusted HR, 1.49; 95% CI, 1.10-2.02; P = .01), although absolute rates were low (standard, 4.4% [n = 113]; off-label, 7.6% [n = 95]; untested, 6.7% [n = 72]).In contemporary US practice, off-label and untested use of drug-eluting stents is common. Compared with standard use, relative early safety is lower with off-label use, and the long-term effectiveness is lower with both off-label and untested use. However, the absolute event rates remain low.","Outcomes and complications associated with off-label and untested use of drug-eluting stents."
"784","JAMA.4081","0.005",17488964,2007,"Limited data exist regarding use of drug-eluting stents outside of approved indications in real-world settings.To determine the frequency, safety, and effectiveness of drug-eluting stents for off-label (restenosis, bypass graft lesion, long lesions, vessel size outside of information for use recommendation) and untested (left main, ostial, bifurcation, or total occlusion lesions) indications in percutaneous coronary intervention (PCI).Observational, prospective, multicenter registry to evaluate in-hospital, 30-day, and 1-year outcomes among patients undergoing PCI between January and June 2005 in 140 US academic and community medical centers. Of 7752 PCI-treated patients, 6993 (90%) received drug-eluting stents; of these, 5851 (84%) received no other devices. Standard, off-label, and untested use was determined in 5541 (95%) of these 5851 patients, constituting the study cohort.Frequency of off-label and untested use, 1-year repeat target vessel revascularization, and composite of death, myocardial infarction (MI), or stent thrombosis at in-hospital follow-up and during 1 year of follow-up.Of 5541 patients receiving drug-eluting stents, 2588 (47%) received stents for off-label or untested indications. Adjusted in-hospital risk of death, MI, or stent thrombosis was not statistically different with off-label or untested vs standard use. At 30 days, the risk of this composite end point was significantly higher with off-label use (adjusted hazard ratio [HR], 2.08; 95% confidence interval [CI], 1.24-3.48; P = .005) but not untested use (adjusted HR, 1.45; 95% CI, 0.79-2.67; P = .23). Excluding early events, this end point was not different at 1 year with off-label use (adjusted HR, 1.10; 95% CI, 0.79-1.54; P = .57) or untested use (adjusted HR, 0.91; 95% CI, 0.60-1.38; P = .66). At 1 year, compared with standard use, significantly higher rates of target vessel revascularization were associated with off-label use (adjusted HR, 1.49; 95% CI, 1.13-1.98; P = .005) and untested use (adjusted HR, 1.49; 95% CI, 1.10-2.02; P = .01), although absolute rates were low (standard, 4.4% [n = 113]; off-label, 7.6% [n = 95]; untested, 6.7% [n = 72]).In contemporary US practice, off-label and untested use of drug-eluting stents is common. Compared with standard use, relative early safety is lower with off-label use, and the long-term effectiveness is lower with both off-label and untested use. However, the absolute event rates remain low.","Outcomes and complications associated with off-label and untested use of drug-eluting stents."
"785","JAMA.4091","0.01",17488964,2007,"Limited data exist regarding use of drug-eluting stents outside of approved indications in real-world settings.To determine the frequency, safety, and effectiveness of drug-eluting stents for off-label (restenosis, bypass graft lesion, long lesions, vessel size outside of information for use recommendation) and untested (left main, ostial, bifurcation, or total occlusion lesions) indications in percutaneous coronary intervention (PCI).Observational, prospective, multicenter registry to evaluate in-hospital, 30-day, and 1-year outcomes among patients undergoing PCI between January and June 2005 in 140 US academic and community medical centers. Of 7752 PCI-treated patients, 6993 (90%) received drug-eluting stents; of these, 5851 (84%) received no other devices. Standard, off-label, and untested use was determined in 5541 (95%) of these 5851 patients, constituting the study cohort.Frequency of off-label and untested use, 1-year repeat target vessel revascularization, and composite of death, myocardial infarction (MI), or stent thrombosis at in-hospital follow-up and during 1 year of follow-up.Of 5541 patients receiving drug-eluting stents, 2588 (47%) received stents for off-label or untested indications. Adjusted in-hospital risk of death, MI, or stent thrombosis was not statistically different with off-label or untested vs standard use. At 30 days, the risk of this composite end point was significantly higher with off-label use (adjusted hazard ratio [HR], 2.08; 95% confidence interval [CI], 1.24-3.48; P = .005) but not untested use (adjusted HR, 1.45; 95% CI, 0.79-2.67; P = .23). Excluding early events, this end point was not different at 1 year with off-label use (adjusted HR, 1.10; 95% CI, 0.79-1.54; P = .57) or untested use (adjusted HR, 0.91; 95% CI, 0.60-1.38; P = .66). At 1 year, compared with standard use, significantly higher rates of target vessel revascularization were associated with off-label use (adjusted HR, 1.49; 95% CI, 1.13-1.98; P = .005) and untested use (adjusted HR, 1.49; 95% CI, 1.10-2.02; P = .01), although absolute rates were low (standard, 4.4% [n = 113]; off-label, 7.6% [n = 95]; untested, 6.7% [n = 72]).In contemporary US practice, off-label and untested use of drug-eluting stents is common. Compared with standard use, relative early safety is lower with off-label use, and the long-term effectiveness is lower with both off-label and untested use. However, the absolute event rates remain low.","Outcomes and complications associated with off-label and untested use of drug-eluting stents."
"786","JAMA.3681","0.001",17488965,2007,"Clinical trials that have excluded patients at high risk for cardiac events have led to commercial labeling approval of drug-eluting stents; nevertheless, such high-risk patients commonly undergo stent placement in clinical practice. The degree to which they experience cardiac events at a higher rate than non-high-risk patients is unclear.To assess the rates of major adverse cardiac events during the index admission and 1 year after the implantation of drug-eluting stents in patients with high-risk angiographic and clinical features.From July 2004 to September 2005, consecutive patients who underwent attempted stent placement at 42 different hospitals throughout the United States were enrolled in a prospective multicenter registry. We analyzed outcomes of 3323 patients who received at least 1 drug-eluting stent for a reason other than acute ST-segment elevation myocardial infarction. The study population was divided into 2 groups based on presence of at least 1 of 9 off-label characteristics based on the current US Food and Drug Administration-approved indications for sirolimus- and paclitaxel-eluting stents.The composite clinical outcomes of death, myocardial infarction, or target vessel revascularization during the index admission and death, myocardial infarction, or target lesion revascularization at 1 year were evaluated.Of the 3323 patients, 1817 (54.7%) had at least 1 off-label characteristic. During the index hospitalization, the composite clinical outcome occurred in 198 (10.9%) of patients in the off-label group and 76 (5.0%) of patients in the on-label group (adjusted odds ratio, 2.32; 95% confidence interval [CI], 1.75-3.07; P<.001). At 1 year, the composite clinical outcome occurred more often in the off-label group compared with the on-label group; 309 (17.5%) vs 131 (8.9%) (adjusted hazard ratio [HR], 2.16; 95% CI, 1.74-2.67; P<.001). Stent thrombosis also occurred more frequently among patients in the off-label group during the initial hospitalization (8 [0.4%] vs 0) and at 1 year: 29 (1.6%) vs 13 (0.9%), adjusted HR, 2.29 (95% CI, 1.02-5.16; P = .05).Compared with on-label use, off-label use of drug-eluting stents is associated with a higher rate of adverse outcomes during the index admission and at 1 year. Stent thrombosis occurred predominantly in patients who underwent off-label drug-eluting stent implantation. Clinicians should be cautious about extrapolating the benefits of drug-eluting stents over bare-metal stents observed in randomized clinical trials to higher-risk clinical settings that have not been assessed.","Clinical outcomes and stent thrombosis following off-label use of drug-eluting stents."
"787","JAMA.3691","0.001",17488965,2007,"Clinical trials that have excluded patients at high risk for cardiac events have led to commercial labeling approval of drug-eluting stents; nevertheless, such high-risk patients commonly undergo stent placement in clinical practice. The degree to which they experience cardiac events at a higher rate than non-high-risk patients is unclear.To assess the rates of major adverse cardiac events during the index admission and 1 year after the implantation of drug-eluting stents in patients with high-risk angiographic and clinical features.From July 2004 to September 2005, consecutive patients who underwent attempted stent placement at 42 different hospitals throughout the United States were enrolled in a prospective multicenter registry. We analyzed outcomes of 3323 patients who received at least 1 drug-eluting stent for a reason other than acute ST-segment elevation myocardial infarction. The study population was divided into 2 groups based on presence of at least 1 of 9 off-label characteristics based on the current US Food and Drug Administration-approved indications for sirolimus- and paclitaxel-eluting stents.The composite clinical outcomes of death, myocardial infarction, or target vessel revascularization during the index admission and death, myocardial infarction, or target lesion revascularization at 1 year were evaluated.Of the 3323 patients, 1817 (54.7%) had at least 1 off-label characteristic. During the index hospitalization, the composite clinical outcome occurred in 198 (10.9%) of patients in the off-label group and 76 (5.0%) of patients in the on-label group (adjusted odds ratio, 2.32; 95% confidence interval [CI], 1.75-3.07; P<.001). At 1 year, the composite clinical outcome occurred more often in the off-label group compared with the on-label group; 309 (17.5%) vs 131 (8.9%) (adjusted hazard ratio [HR], 2.16; 95% CI, 1.74-2.67; P<.001). Stent thrombosis also occurred more frequently among patients in the off-label group during the initial hospitalization (8 [0.4%] vs 0) and at 1 year: 29 (1.6%) vs 13 (0.9%), adjusted HR, 2.29 (95% CI, 1.02-5.16; P = .05).Compared with on-label use, off-label use of drug-eluting stents is associated with a higher rate of adverse outcomes during the index admission and at 1 year. Stent thrombosis occurred predominantly in patients who underwent off-label drug-eluting stent implantation. Clinicians should be cautious about extrapolating the benefits of drug-eluting stents over bare-metal stents observed in randomized clinical trials to higher-risk clinical settings that have not been assessed.","Clinical outcomes and stent thrombosis following off-label use of drug-eluting stents."
"788","JAMA.4031","0.05",17488965,2007,"Clinical trials that have excluded patients at high risk for cardiac events have led to commercial labeling approval of drug-eluting stents; nevertheless, such high-risk patients commonly undergo stent placement in clinical practice. The degree to which they experience cardiac events at a higher rate than non-high-risk patients is unclear.To assess the rates of major adverse cardiac events during the index admission and 1 year after the implantation of drug-eluting stents in patients with high-risk angiographic and clinical features.From July 2004 to September 2005, consecutive patients who underwent attempted stent placement at 42 different hospitals throughout the United States were enrolled in a prospective multicenter registry. We analyzed outcomes of 3323 patients who received at least 1 drug-eluting stent for a reason other than acute ST-segment elevation myocardial infarction. The study population was divided into 2 groups based on presence of at least 1 of 9 off-label characteristics based on the current US Food and Drug Administration-approved indications for sirolimus- and paclitaxel-eluting stents.The composite clinical outcomes of death, myocardial infarction, or target vessel revascularization during the index admission and death, myocardial infarction, or target lesion revascularization at 1 year were evaluated.Of the 3323 patients, 1817 (54.7%) had at least 1 off-label characteristic. During the index hospitalization, the composite clinical outcome occurred in 198 (10.9%) of patients in the off-label group and 76 (5.0%) of patients in the on-label group (adjusted odds ratio, 2.32; 95% confidence interval [CI], 1.75-3.07; P<.001). At 1 year, the composite clinical outcome occurred more often in the off-label group compared with the on-label group; 309 (17.5%) vs 131 (8.9%) (adjusted hazard ratio [HR], 2.16; 95% CI, 1.74-2.67; P<.001). Stent thrombosis also occurred more frequently among patients in the off-label group during the initial hospitalization (8 [0.4%] vs 0) and at 1 year: 29 (1.6%) vs 13 (0.9%), adjusted HR, 2.29 (95% CI, 1.02-5.16; P = .05).Compared with on-label use, off-label use of drug-eluting stents is associated with a higher rate of adverse outcomes during the index admission and at 1 year. Stent thrombosis occurred predominantly in patients who underwent off-label drug-eluting stent implantation. Clinicians should be cautious about extrapolating the benefits of drug-eluting stents over bare-metal stents observed in randomized clinical trials to higher-risk clinical settings that have not been assessed.","Clinical outcomes and stent thrombosis following off-label use of drug-eluting stents."
"789","Lancet.891","0.02",17499602,2007,"Randomised trials have shown that aspirin reduces the short-term risk of recurrent colorectal adenomas in patients with a history of adenomas or cancer, but large trials have shown no effect in primary prevention of colorectal cancer during 10 years' follow-up. However, the delay from the early development of adenoma to presentation with cancer is at least 10 years. We aimed to assess the longer-term effect of aspirin on the incidence of cancers.We studied the effect of aspirin in two large randomised trials with reliable post-trial follow-up for more than 20 years: the British Doctors Aspirin Trial (N=5139, two-thirds allocated 500 mg aspirin for 5 years, a third to open control) and UK-TIA Aspirin Trial (N=2449, two-thirds allocated 300 mg or 1200 mg aspirin for 1-7 years, a third placebo control). We also did a systematic review of all relevant observational studies to establish whether associations were consistent with the results of the randomised trials and, if so, what could be concluded about the likely effects of dose and regularity of aspirin use, other non-steroidal anti-inflammatory drugs (NSAID), and the effect of patient characteristics.In the randomised trials, allocation to aspirin reduced the incidence of colorectal cancer (pooled HR 0.74, 95% CI 0.56-0.97, p=0.02 overall; 0.63, 0.47-0.85, p=0.002 if allocated aspirin for 5 years or more). However, this effect was only seen after a latency of 10 years (years 0-9: 0.92, 0.56-1.49, p=0.73; years 10-19: 0.60, 0.42-0.87, p=0.007), was dependent on duration of scheduled trial treatment and compliance, and was greatest 10-14 years after randomisation in patients who had had scheduled trial treatment of 5 years or more (0.37, 0.20-0.70, p=0.002; 0.26, 0.12-0.56, p=0.0002, if compliant). No significant effect on incidence of non-colorectal cancers was recorded (1.01, 0.88-1.16, p=0.87). In 19 case-control studies (20 815 cases) and 11 cohort studies (1 136 110 individuals), regular use of aspirin or NSAID was consistently associated with a reduced risk of colorectal cancer, especially after use for 10 years or more, with no difference between aspirin and other NSAIDs, or in relation to age, sex, race, or family history, site or aggressiveness of cancer, or any reduction in apparent effect with use for 20 years or more. However, a consistent association was only seen with use of 300 mg or more of aspirin a day, with diminished and inconsistent results for lower or less frequent doses.Use of 300 mg or more of aspirin a day for about 5 years is effective in primary prevention of colorectal cancer in randomised controlled trials, with a latency of about 10 years, which is consistent with findings from observational studies. Long-term follow-up is required from other randomised trials to establish the effects of lower or less frequent doses of aspirin.","Effect of aspirin on long-term risk of colorectal cancer: consistent evidence from randomised and observational studies."
"790","Lancet.901","0.002",17499602,2007,"Randomised trials have shown that aspirin reduces the short-term risk of recurrent colorectal adenomas in patients with a history of adenomas or cancer, but large trials have shown no effect in primary prevention of colorectal cancer during 10 years' follow-up. However, the delay from the early development of adenoma to presentation with cancer is at least 10 years. We aimed to assess the longer-term effect of aspirin on the incidence of cancers.We studied the effect of aspirin in two large randomised trials with reliable post-trial follow-up for more than 20 years: the British Doctors Aspirin Trial (N=5139, two-thirds allocated 500 mg aspirin for 5 years, a third to open control) and UK-TIA Aspirin Trial (N=2449, two-thirds allocated 300 mg or 1200 mg aspirin for 1-7 years, a third placebo control). We also did a systematic review of all relevant observational studies to establish whether associations were consistent with the results of the randomised trials and, if so, what could be concluded about the likely effects of dose and regularity of aspirin use, other non-steroidal anti-inflammatory drugs (NSAID), and the effect of patient characteristics.In the randomised trials, allocation to aspirin reduced the incidence of colorectal cancer (pooled HR 0.74, 95% CI 0.56-0.97, p=0.02 overall; 0.63, 0.47-0.85, p=0.002 if allocated aspirin for 5 years or more). However, this effect was only seen after a latency of 10 years (years 0-9: 0.92, 0.56-1.49, p=0.73; years 10-19: 0.60, 0.42-0.87, p=0.007), was dependent on duration of scheduled trial treatment and compliance, and was greatest 10-14 years after randomisation in patients who had had scheduled trial treatment of 5 years or more (0.37, 0.20-0.70, p=0.002; 0.26, 0.12-0.56, p=0.0002, if compliant). No significant effect on incidence of non-colorectal cancers was recorded (1.01, 0.88-1.16, p=0.87). In 19 case-control studies (20 815 cases) and 11 cohort studies (1 136 110 individuals), regular use of aspirin or NSAID was consistently associated with a reduced risk of colorectal cancer, especially after use for 10 years or more, with no difference between aspirin and other NSAIDs, or in relation to age, sex, race, or family history, site or aggressiveness of cancer, or any reduction in apparent effect with use for 20 years or more. However, a consistent association was only seen with use of 300 mg or more of aspirin a day, with diminished and inconsistent results for lower or less frequent doses.Use of 300 mg or more of aspirin a day for about 5 years is effective in primary prevention of colorectal cancer in randomised controlled trials, with a latency of about 10 years, which is consistent with findings from observational studies. Long-term follow-up is required from other randomised trials to establish the effects of lower or less frequent doses of aspirin.","Effect of aspirin on long-term risk of colorectal cancer: consistent evidence from randomised and observational studies."
"791","Lancet.911","0.73",17499602,2007,"Randomised trials have shown that aspirin reduces the short-term risk of recurrent colorectal adenomas in patients with a history of adenomas or cancer, but large trials have shown no effect in primary prevention of colorectal cancer during 10 years' follow-up. However, the delay from the early development of adenoma to presentation with cancer is at least 10 years. We aimed to assess the longer-term effect of aspirin on the incidence of cancers.We studied the effect of aspirin in two large randomised trials with reliable post-trial follow-up for more than 20 years: the British Doctors Aspirin Trial (N=5139, two-thirds allocated 500 mg aspirin for 5 years, a third to open control) and UK-TIA Aspirin Trial (N=2449, two-thirds allocated 300 mg or 1200 mg aspirin for 1-7 years, a third placebo control). We also did a systematic review of all relevant observational studies to establish whether associations were consistent with the results of the randomised trials and, if so, what could be concluded about the likely effects of dose and regularity of aspirin use, other non-steroidal anti-inflammatory drugs (NSAID), and the effect of patient characteristics.In the randomised trials, allocation to aspirin reduced the incidence of colorectal cancer (pooled HR 0.74, 95% CI 0.56-0.97, p=0.02 overall; 0.63, 0.47-0.85, p=0.002 if allocated aspirin for 5 years or more). However, this effect was only seen after a latency of 10 years (years 0-9: 0.92, 0.56-1.49, p=0.73; years 10-19: 0.60, 0.42-0.87, p=0.007), was dependent on duration of scheduled trial treatment and compliance, and was greatest 10-14 years after randomisation in patients who had had scheduled trial treatment of 5 years or more (0.37, 0.20-0.70, p=0.002; 0.26, 0.12-0.56, p=0.0002, if compliant). No significant effect on incidence of non-colorectal cancers was recorded (1.01, 0.88-1.16, p=0.87). In 19 case-control studies (20 815 cases) and 11 cohort studies (1 136 110 individuals), regular use of aspirin or NSAID was consistently associated with a reduced risk of colorectal cancer, especially after use for 10 years or more, with no difference between aspirin and other NSAIDs, or in relation to age, sex, race, or family history, site or aggressiveness of cancer, or any reduction in apparent effect with use for 20 years or more. However, a consistent association was only seen with use of 300 mg or more of aspirin a day, with diminished and inconsistent results for lower or less frequent doses.Use of 300 mg or more of aspirin a day for about 5 years is effective in primary prevention of colorectal cancer in randomised controlled trials, with a latency of about 10 years, which is consistent with findings from observational studies. Long-term follow-up is required from other randomised trials to establish the effects of lower or less frequent doses of aspirin.","Effect of aspirin on long-term risk of colorectal cancer: consistent evidence from randomised and observational studies."
"792","Lancet.921","0.007",17499602,2007,"Randomised trials have shown that aspirin reduces the short-term risk of recurrent colorectal adenomas in patients with a history of adenomas or cancer, but large trials have shown no effect in primary prevention of colorectal cancer during 10 years' follow-up. However, the delay from the early development of adenoma to presentation with cancer is at least 10 years. We aimed to assess the longer-term effect of aspirin on the incidence of cancers.We studied the effect of aspirin in two large randomised trials with reliable post-trial follow-up for more than 20 years: the British Doctors Aspirin Trial (N=5139, two-thirds allocated 500 mg aspirin for 5 years, a third to open control) and UK-TIA Aspirin Trial (N=2449, two-thirds allocated 300 mg or 1200 mg aspirin for 1-7 years, a third placebo control). We also did a systematic review of all relevant observational studies to establish whether associations were consistent with the results of the randomised trials and, if so, what could be concluded about the likely effects of dose and regularity of aspirin use, other non-steroidal anti-inflammatory drugs (NSAID), and the effect of patient characteristics.In the randomised trials, allocation to aspirin reduced the incidence of colorectal cancer (pooled HR 0.74, 95% CI 0.56-0.97, p=0.02 overall; 0.63, 0.47-0.85, p=0.002 if allocated aspirin for 5 years or more). However, this effect was only seen after a latency of 10 years (years 0-9: 0.92, 0.56-1.49, p=0.73; years 10-19: 0.60, 0.42-0.87, p=0.007), was dependent on duration of scheduled trial treatment and compliance, and was greatest 10-14 years after randomisation in patients who had had scheduled trial treatment of 5 years or more (0.37, 0.20-0.70, p=0.002; 0.26, 0.12-0.56, p=0.0002, if compliant). No significant effect on incidence of non-colorectal cancers was recorded (1.01, 0.88-1.16, p=0.87). In 19 case-control studies (20 815 cases) and 11 cohort studies (1 136 110 individuals), regular use of aspirin or NSAID was consistently associated with a reduced risk of colorectal cancer, especially after use for 10 years or more, with no difference between aspirin and other NSAIDs, or in relation to age, sex, race, or family history, site or aggressiveness of cancer, or any reduction in apparent effect with use for 20 years or more. However, a consistent association was only seen with use of 300 mg or more of aspirin a day, with diminished and inconsistent results for lower or less frequent doses.Use of 300 mg or more of aspirin a day for about 5 years is effective in primary prevention of colorectal cancer in randomised controlled trials, with a latency of about 10 years, which is consistent with findings from observational studies. Long-term follow-up is required from other randomised trials to establish the effects of lower or less frequent doses of aspirin.","Effect of aspirin on long-term risk of colorectal cancer: consistent evidence from randomised and observational studies."
"793","Lancet.931","2.00E-03",17499602,2007,"Randomised trials have shown that aspirin reduces the short-term risk of recurrent colorectal adenomas in patients with a history of adenomas or cancer, but large trials have shown no effect in primary prevention of colorectal cancer during 10 years' follow-up. However, the delay from the early development of adenoma to presentation with cancer is at least 10 years. We aimed to assess the longer-term effect of aspirin on the incidence of cancers.We studied the effect of aspirin in two large randomised trials with reliable post-trial follow-up for more than 20 years: the British Doctors Aspirin Trial (N=5139, two-thirds allocated 500 mg aspirin for 5 years, a third to open control) and UK-TIA Aspirin Trial (N=2449, two-thirds allocated 300 mg or 1200 mg aspirin for 1-7 years, a third placebo control). We also did a systematic review of all relevant observational studies to establish whether associations were consistent with the results of the randomised trials and, if so, what could be concluded about the likely effects of dose and regularity of aspirin use, other non-steroidal anti-inflammatory drugs (NSAID), and the effect of patient characteristics.In the randomised trials, allocation to aspirin reduced the incidence of colorectal cancer (pooled HR 0.74, 95% CI 0.56-0.97, p=0.02 overall; 0.63, 0.47-0.85, p=0.002 if allocated aspirin for 5 years or more). However, this effect was only seen after a latency of 10 years (years 0-9: 0.92, 0.56-1.49, p=0.73; years 10-19: 0.60, 0.42-0.87, p=0.007), was dependent on duration of scheduled trial treatment and compliance, and was greatest 10-14 years after randomisation in patients who had had scheduled trial treatment of 5 years or more (0.37, 0.20-0.70, p=0.002; 0.26, 0.12-0.56, p=0.0002, if compliant). No significant effect on incidence of non-colorectal cancers was recorded (1.01, 0.88-1.16, p=0.87). In 19 case-control studies (20 815 cases) and 11 cohort studies (1 136 110 individuals), regular use of aspirin or NSAID was consistently associated with a reduced risk of colorectal cancer, especially after use for 10 years or more, with no difference between aspirin and other NSAIDs, or in relation to age, sex, race, or family history, site or aggressiveness of cancer, or any reduction in apparent effect with use for 20 years or more. However, a consistent association was only seen with use of 300 mg or more of aspirin a day, with diminished and inconsistent results for lower or less frequent doses.Use of 300 mg or more of aspirin a day for about 5 years is effective in primary prevention of colorectal cancer in randomised controlled trials, with a latency of about 10 years, which is consistent with findings from observational studies. Long-term follow-up is required from other randomised trials to establish the effects of lower or less frequent doses of aspirin.","Effect of aspirin on long-term risk of colorectal cancer: consistent evidence from randomised and observational studies."
"794","Lancet.931","2.00E-04",17499602,2007,"Randomised trials have shown that aspirin reduces the short-term risk of recurrent colorectal adenomas in patients with a history of adenomas or cancer, but large trials have shown no effect in primary prevention of colorectal cancer during 10 years' follow-up. However, the delay from the early development of adenoma to presentation with cancer is at least 10 years. We aimed to assess the longer-term effect of aspirin on the incidence of cancers.We studied the effect of aspirin in two large randomised trials with reliable post-trial follow-up for more than 20 years: the British Doctors Aspirin Trial (N=5139, two-thirds allocated 500 mg aspirin for 5 years, a third to open control) and UK-TIA Aspirin Trial (N=2449, two-thirds allocated 300 mg or 1200 mg aspirin for 1-7 years, a third placebo control). We also did a systematic review of all relevant observational studies to establish whether associations were consistent with the results of the randomised trials and, if so, what could be concluded about the likely effects of dose and regularity of aspirin use, other non-steroidal anti-inflammatory drugs (NSAID), and the effect of patient characteristics.In the randomised trials, allocation to aspirin reduced the incidence of colorectal cancer (pooled HR 0.74, 95% CI 0.56-0.97, p=0.02 overall; 0.63, 0.47-0.85, p=0.002 if allocated aspirin for 5 years or more). However, this effect was only seen after a latency of 10 years (years 0-9: 0.92, 0.56-1.49, p=0.73; years 10-19: 0.60, 0.42-0.87, p=0.007), was dependent on duration of scheduled trial treatment and compliance, and was greatest 10-14 years after randomisation in patients who had had scheduled trial treatment of 5 years or more (0.37, 0.20-0.70, p=0.002; 0.26, 0.12-0.56, p=0.0002, if compliant). No significant effect on incidence of non-colorectal cancers was recorded (1.01, 0.88-1.16, p=0.87). In 19 case-control studies (20 815 cases) and 11 cohort studies (1 136 110 individuals), regular use of aspirin or NSAID was consistently associated with a reduced risk of colorectal cancer, especially after use for 10 years or more, with no difference between aspirin and other NSAIDs, or in relation to age, sex, race, or family history, site or aggressiveness of cancer, or any reduction in apparent effect with use for 20 years or more. However, a consistent association was only seen with use of 300 mg or more of aspirin a day, with diminished and inconsistent results for lower or less frequent doses.Use of 300 mg or more of aspirin a day for about 5 years is effective in primary prevention of colorectal cancer in randomised controlled trials, with a latency of about 10 years, which is consistent with findings from observational studies. Long-term follow-up is required from other randomised trials to establish the effects of lower or less frequent doses of aspirin.","Effect of aspirin on long-term risk of colorectal cancer: consistent evidence from randomised and observational studies."
"795","Lancet.941","0.87",17499602,2007,"Randomised trials have shown that aspirin reduces the short-term risk of recurrent colorectal adenomas in patients with a history of adenomas or cancer, but large trials have shown no effect in primary prevention of colorectal cancer during 10 years' follow-up. However, the delay from the early development of adenoma to presentation with cancer is at least 10 years. We aimed to assess the longer-term effect of aspirin on the incidence of cancers.We studied the effect of aspirin in two large randomised trials with reliable post-trial follow-up for more than 20 years: the British Doctors Aspirin Trial (N=5139, two-thirds allocated 500 mg aspirin for 5 years, a third to open control) and UK-TIA Aspirin Trial (N=2449, two-thirds allocated 300 mg or 1200 mg aspirin for 1-7 years, a third placebo control). We also did a systematic review of all relevant observational studies to establish whether associations were consistent with the results of the randomised trials and, if so, what could be concluded about the likely effects of dose and regularity of aspirin use, other non-steroidal anti-inflammatory drugs (NSAID), and the effect of patient characteristics.In the randomised trials, allocation to aspirin reduced the incidence of colorectal cancer (pooled HR 0.74, 95% CI 0.56-0.97, p=0.02 overall; 0.63, 0.47-0.85, p=0.002 if allocated aspirin for 5 years or more). However, this effect was only seen after a latency of 10 years (years 0-9: 0.92, 0.56-1.49, p=0.73; years 10-19: 0.60, 0.42-0.87, p=0.007), was dependent on duration of scheduled trial treatment and compliance, and was greatest 10-14 years after randomisation in patients who had had scheduled trial treatment of 5 years or more (0.37, 0.20-0.70, p=0.002; 0.26, 0.12-0.56, p=0.0002, if compliant). No significant effect on incidence of non-colorectal cancers was recorded (1.01, 0.88-1.16, p=0.87). In 19 case-control studies (20 815 cases) and 11 cohort studies (1 136 110 individuals), regular use of aspirin or NSAID was consistently associated with a reduced risk of colorectal cancer, especially after use for 10 years or more, with no difference between aspirin and other NSAIDs, or in relation to age, sex, race, or family history, site or aggressiveness of cancer, or any reduction in apparent effect with use for 20 years or more. However, a consistent association was only seen with use of 300 mg or more of aspirin a day, with diminished and inconsistent results for lower or less frequent doses.Use of 300 mg or more of aspirin a day for about 5 years is effective in primary prevention of colorectal cancer in randomised controlled trials, with a latency of about 10 years, which is consistent with findings from observational studies. Long-term follow-up is required from other randomised trials to establish the effects of lower or less frequent doses of aspirin.","Effect of aspirin on long-term risk of colorectal cancer: consistent evidence from randomised and observational studies."
"796","Lancet.871","2.00E-04",17512855,2007,"Ovarian cancer is the fourth most common cancer in women in the UK, with about 6700 developing the malignancy and 4600 dying from it every year. However, there is limited information about the risk of ovarian cancer associated with the use of hormone replacement therapy (HRT).948,576 postmenopausal women from the UK Million Women Study who did not have previous cancer or bilateral oophorectomy were followed-up for an average of 5.3 years for incident ovarian cancer and 6.9 years for death. Information on HRT use was obtained at recruitment and updated where possible. Relative risks for ovarian cancer were calculated, stratified by age and hysterectomy status, and adjusted by area of residence, socioeconomic group, time since menopause, parity, body-mass index, alcohol consumption, and use of oral contraceptives.When they last reported HRT use, 287,143 women (30%) were current users and 186 751 (20%) were past users. During follow-up, 2273 incident ovarian cancers and 1591 deaths from the malignancy were recorded. Current users were significantly more likely to develop and die from ovarian cancer than never users (relative risk 1.20 [95% CI 1.09-1.32; p=0.0002] for incident disease and 1.23 [1.09-1.38; p=0.0006] for death). For current users of HRT, incidence of ovarian cancer increased with increasing duration of use, but did not differ significantly by type of preparation used, its constituents, or mode of administration. Risks associated with HRT varied significantly according to tumour histology (p<0.0001), and in women with epithelial tumours the relative risk for current versus never use of HRT was greater for serous than for mucinous, endometroid, or clear cell tumours (1.53 [1.31-1.79], 0.72 [0.52-1.00], 1.05 [0.77-1.43], or 0.77 [0.48-1.23], respectively). Past users of HRT were not at an increased risk of ovarian cancer (0.98 [0.88-1.11] and 0.97 [0.84-1.11], respectively, for incident and fatal disease). Over 5 years, the standardised incidence rates for ovarian cancer in current and never users of HRT were 2.6 (2.4-2.9) and 2.2 (2.1-2.3) per 1000, respectively-ie, one extra ovarian cancer in roughly 2500 users; death rates were 1.6 (1.4-1.8) and 1.3 (1.2-1.4) per 1000, respectively-ie, one extra ovarian cancer death in roughly 3300 users.Women who use HRT are at an increased risk of both incident and fatal ovarian cancer. Since 1991, use of HRT has resulted in some 1300 additional ovarian cancers and 1000 additional deaths from the malignancy in the UK.","Ovarian cancer and hormone replacement therapy in the Million Women Study."
"797","Lancet.881","6.00E-04",17512855,2007,"Ovarian cancer is the fourth most common cancer in women in the UK, with about 6700 developing the malignancy and 4600 dying from it every year. However, there is limited information about the risk of ovarian cancer associated with the use of hormone replacement therapy (HRT).948,576 postmenopausal women from the UK Million Women Study who did not have previous cancer or bilateral oophorectomy were followed-up for an average of 5.3 years for incident ovarian cancer and 6.9 years for death. Information on HRT use was obtained at recruitment and updated where possible. Relative risks for ovarian cancer were calculated, stratified by age and hysterectomy status, and adjusted by area of residence, socioeconomic group, time since menopause, parity, body-mass index, alcohol consumption, and use of oral contraceptives.When they last reported HRT use, 287,143 women (30%) were current users and 186 751 (20%) were past users. During follow-up, 2273 incident ovarian cancers and 1591 deaths from the malignancy were recorded. Current users were significantly more likely to develop and die from ovarian cancer than never users (relative risk 1.20 [95% CI 1.09-1.32; p=0.0002] for incident disease and 1.23 [1.09-1.38; p=0.0006] for death). For current users of HRT, incidence of ovarian cancer increased with increasing duration of use, but did not differ significantly by type of preparation used, its constituents, or mode of administration. Risks associated with HRT varied significantly according to tumour histology (p<0.0001), and in women with epithelial tumours the relative risk for current versus never use of HRT was greater for serous than for mucinous, endometroid, or clear cell tumours (1.53 [1.31-1.79], 0.72 [0.52-1.00], 1.05 [0.77-1.43], or 0.77 [0.48-1.23], respectively). Past users of HRT were not at an increased risk of ovarian cancer (0.98 [0.88-1.11] and 0.97 [0.84-1.11], respectively, for incident and fatal disease). Over 5 years, the standardised incidence rates for ovarian cancer in current and never users of HRT were 2.6 (2.4-2.9) and 2.2 (2.1-2.3) per 1000, respectively-ie, one extra ovarian cancer in roughly 2500 users; death rates were 1.6 (1.4-1.8) and 1.3 (1.2-1.4) per 1000, respectively-ie, one extra ovarian cancer death in roughly 3300 users.Women who use HRT are at an increased risk of both incident and fatal ovarian cancer. Since 1991, use of HRT has resulted in some 1300 additional ovarian cancers and 1000 additional deaths from the malignancy in the UK.","Ovarian cancer and hormone replacement therapy in the Million Women Study."
"798","JAMA.396","0.001",17519409,2007,"In areas where Plasmodium falciparum and Plasmodium vivax coexist and treatments for the 2 species differ, misdiagnosis can lead to poor outcomes in either disease. A unified therapy effective against both species would reduce reliance on species-specific diagnosis, which in many areas is difficult to maintain. The antifolates are an important and affordable antimalarial class to which it is often assumed P vivax malaria is intrinsically resistant.To test the relative efficacy and safety of 2 antifolate drugs against P vivax malaria and compare each with chloroquine.An open-label randomized controlled trial comparing chloroquine, sulfadoxine-pyrimethamine, and chlorproguanil-dapsone for the treatment of P vivax malaria was conducted in eastern Afghanistan and northwestern Pakistan, areas in which P vivax malaria predominates. A total of 20,410 patients older than 3 years were screened; 767 patients (315 in Pakistan and 452 in Afghanistan) with confirmed P vivax malaria were enrolled and followed up daily for 4 days, then weekly for 28 days, between March 2004 and June 2006.Complete clearance of parasites with no recrudescence by day 14. Secondary outcomes included being parasite-free by day 28, clinical failure, and anemia.By day 14, only 1 patient in the sulfadoxine-pyrimethamine group had parasites. By day 28, failure rates were found in 2 of 153 patients (1.3%) in the chloroquine group, 5 of 290 patients (1.7%) in the sulfadoxine-pyrimethamine group, and 27 of 272 patients (9.9%) in the chlorproguanil-dapsone group. Chlorproguanil-dapsone was less effective than sulfadoxine-pyrimethamine (adjusted odds ratio [OR], 6.4; 95% confidence interval [CI], 2.4-17.0; P<.001) and chloroquine (adjusted OR, 8.4; 95% CI, 2.0-36.5; P = .004). Chloroquine and sulfadoxine-pyrimethamine were equivalent in efficacy at day 28 (adjusted OR, 1.3; 95% CI, 0.3-7.0; P = .73). Chloroquine cleared gametocytes and asexual parasites more rapidly than sulfadoxine-pyrimethamine or chlorproguanil-dapsone did. All drugs were well tolerated.Although chloroquine remains the drug of choice, antifolates are effective against P vivax malaria in South Asia. These drugs may be appropriate for unified treatment where species-specific diagnosis is unavailable, most likely in combination with other drugs.clinicaltrials.gov Identifier: NCT00158561.","Sulfadoxine-pyrimethamine, chlorproguanil-dapsone, or chloroquine for the treatment of Plasmodium vivax malaria in Afghanistan and Pakistan: a randomized controlled trial."
"799","JAMA.415","0.004",17519409,2007,"In areas where Plasmodium falciparum and Plasmodium vivax coexist and treatments for the 2 species differ, misdiagnosis can lead to poor outcomes in either disease. A unified therapy effective against both species would reduce reliance on species-specific diagnosis, which in many areas is difficult to maintain. The antifolates are an important and affordable antimalarial class to which it is often assumed P vivax malaria is intrinsically resistant.To test the relative efficacy and safety of 2 antifolate drugs against P vivax malaria and compare each with chloroquine.An open-label randomized controlled trial comparing chloroquine, sulfadoxine-pyrimethamine, and chlorproguanil-dapsone for the treatment of P vivax malaria was conducted in eastern Afghanistan and northwestern Pakistan, areas in which P vivax malaria predominates. A total of 20,410 patients older than 3 years were screened; 767 patients (315 in Pakistan and 452 in Afghanistan) with confirmed P vivax malaria were enrolled and followed up daily for 4 days, then weekly for 28 days, between March 2004 and June 2006.Complete clearance of parasites with no recrudescence by day 14. Secondary outcomes included being parasite-free by day 28, clinical failure, and anemia.By day 14, only 1 patient in the sulfadoxine-pyrimethamine group had parasites. By day 28, failure rates were found in 2 of 153 patients (1.3%) in the chloroquine group, 5 of 290 patients (1.7%) in the sulfadoxine-pyrimethamine group, and 27 of 272 patients (9.9%) in the chlorproguanil-dapsone group. Chlorproguanil-dapsone was less effective than sulfadoxine-pyrimethamine (adjusted odds ratio [OR], 6.4; 95% confidence interval [CI], 2.4-17.0; P<.001) and chloroquine (adjusted OR, 8.4; 95% CI, 2.0-36.5; P = .004). Chloroquine and sulfadoxine-pyrimethamine were equivalent in efficacy at day 28 (adjusted OR, 1.3; 95% CI, 0.3-7.0; P = .73). Chloroquine cleared gametocytes and asexual parasites more rapidly than sulfadoxine-pyrimethamine or chlorproguanil-dapsone did. All drugs were well tolerated.Although chloroquine remains the drug of choice, antifolates are effective against P vivax malaria in South Asia. These drugs may be appropriate for unified treatment where species-specific diagnosis is unavailable, most likely in combination with other drugs.clinicaltrials.gov Identifier: NCT00158561.","Sulfadoxine-pyrimethamine, chlorproguanil-dapsone, or chloroquine for the treatment of Plasmodium vivax malaria in Afghanistan and Pakistan: a randomized controlled trial."
"800","JAMA.416","0.73",17519409,2007,"In areas where Plasmodium falciparum and Plasmodium vivax coexist and treatments for the 2 species differ, misdiagnosis can lead to poor outcomes in either disease. A unified therapy effective against both species would reduce reliance on species-specific diagnosis, which in many areas is difficult to maintain. The antifolates are an important and affordable antimalarial class to which it is often assumed P vivax malaria is intrinsically resistant.To test the relative efficacy and safety of 2 antifolate drugs against P vivax malaria and compare each with chloroquine.An open-label randomized controlled trial comparing chloroquine, sulfadoxine-pyrimethamine, and chlorproguanil-dapsone for the treatment of P vivax malaria was conducted in eastern Afghanistan and northwestern Pakistan, areas in which P vivax malaria predominates. A total of 20,410 patients older than 3 years were screened; 767 patients (315 in Pakistan and 452 in Afghanistan) with confirmed P vivax malaria were enrolled and followed up daily for 4 days, then weekly for 28 days, between March 2004 and June 2006.Complete clearance of parasites with no recrudescence by day 14. Secondary outcomes included being parasite-free by day 28, clinical failure, and anemia.By day 14, only 1 patient in the sulfadoxine-pyrimethamine group had parasites. By day 28, failure rates were found in 2 of 153 patients (1.3%) in the chloroquine group, 5 of 290 patients (1.7%) in the sulfadoxine-pyrimethamine group, and 27 of 272 patients (9.9%) in the chlorproguanil-dapsone group. Chlorproguanil-dapsone was less effective than sulfadoxine-pyrimethamine (adjusted odds ratio [OR], 6.4; 95% confidence interval [CI], 2.4-17.0; P<.001) and chloroquine (adjusted OR, 8.4; 95% CI, 2.0-36.5; P = .004). Chloroquine and sulfadoxine-pyrimethamine were equivalent in efficacy at day 28 (adjusted OR, 1.3; 95% CI, 0.3-7.0; P = .73). Chloroquine cleared gametocytes and asexual parasites more rapidly than sulfadoxine-pyrimethamine or chlorproguanil-dapsone did. All drugs were well tolerated.Although chloroquine remains the drug of choice, antifolates are effective against P vivax malaria in South Asia. These drugs may be appropriate for unified treatment where species-specific diagnosis is unavailable, most likely in combination with other drugs.clinicaltrials.gov Identifier: NCT00158561.","Sulfadoxine-pyrimethamine, chlorproguanil-dapsone, or chloroquine for the treatment of Plasmodium vivax malaria in Afghanistan and Pakistan: a randomized controlled trial."
"801","Lancet.811","0.86",17544497,2007,"Although surgery offers the best chance of cure for patients with non-small cell lung cancer (NSCLC), the overall 5-year survival rate is modest, and improvements are urgently needed. In the 1990s, much interest was generated from two small trials that reported striking results with neo-adjuvant chemotherapy, and therefore our intergroup randomised trial was designed to investigate whether, in patients with operable non-small cell lung cancer of any stage, outcomes could be improved by giving platinum-based chemotherapy before surgery.Patients were randomised to receive either surgery alone (S), or three cycles of platinum-based chemotherapy followed by surgery (CT-S). Before randomisation, clinicians chose the chemotherapy that would be given from a list of six standard regimens. The primary outcome measure was overall survival, which was analysed on an intention-to-treat basis. This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN25582437.519 patients were randomised (S: 261, CT-S: 258) from 70 centres in the UK, Netherlands, Germany, and Belgium. Most (61%) were clinical stage I, with 31% stage II, and 7% stage III. Neo-adjuvant chemotherapy was feasible (75% of patients received all three cycles of chemotherapy), resulted in a good response rate (49% [95% CI 43%-55%]) and down-staging in 31% (25%-37%) of patients, and did not alter the type or completeness of the surgery (lobectomy: S: 56%, CT-S: 60%, complete resection: S: 80%, CT-S: 82%). Post-operative complications were not increased in the CT-S group, and no impairment of quality of life was observed. However, there was no evidence of a benefit in terms of overall survival (hazard ratio [HR] 1.02, 95% CI 0.80-1.31, p=0.86). Updating the systematic review by addition of the present result suggests a 12% relative survival benefit with the addition of neoadjuvant chemotherapy (1507 patients, HR 0.88, 95% CI 0.76-1.01, p=0.07), equivalent to an absolute improvement in survival of 5% at 5 yearsAlthough there was no evidence of a difference in overall survival with neo-adjuvant chemotherapy, the result is statistically consistent with previous trials, and therefore adds considerable weight to the current evidence.","Preoperative chemotherapy in patients with resectable non-small cell lung cancer: results of the MRC LU22/NVALT 2/EORTC 08012 multicentre randomised trial and update of systematic review."
"802","Lancet.821","0.07",17544497,2007,"Although surgery offers the best chance of cure for patients with non-small cell lung cancer (NSCLC), the overall 5-year survival rate is modest, and improvements are urgently needed. In the 1990s, much interest was generated from two small trials that reported striking results with neo-adjuvant chemotherapy, and therefore our intergroup randomised trial was designed to investigate whether, in patients with operable non-small cell lung cancer of any stage, outcomes could be improved by giving platinum-based chemotherapy before surgery.Patients were randomised to receive either surgery alone (S), or three cycles of platinum-based chemotherapy followed by surgery (CT-S). Before randomisation, clinicians chose the chemotherapy that would be given from a list of six standard regimens. The primary outcome measure was overall survival, which was analysed on an intention-to-treat basis. This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN25582437.519 patients were randomised (S: 261, CT-S: 258) from 70 centres in the UK, Netherlands, Germany, and Belgium. Most (61%) were clinical stage I, with 31% stage II, and 7% stage III. Neo-adjuvant chemotherapy was feasible (75% of patients received all three cycles of chemotherapy), resulted in a good response rate (49% [95% CI 43%-55%]) and down-staging in 31% (25%-37%) of patients, and did not alter the type or completeness of the surgery (lobectomy: S: 56%, CT-S: 60%, complete resection: S: 80%, CT-S: 82%). Post-operative complications were not increased in the CT-S group, and no impairment of quality of life was observed. However, there was no evidence of a benefit in terms of overall survival (hazard ratio [HR] 1.02, 95% CI 0.80-1.31, p=0.86). Updating the systematic review by addition of the present result suggests a 12% relative survival benefit with the addition of neoadjuvant chemotherapy (1507 patients, HR 0.88, 95% CI 0.76-1.01, p=0.07), equivalent to an absolute improvement in survival of 5% at 5 yearsAlthough there was no evidence of a difference in overall survival with neo-adjuvant chemotherapy, the result is statistically consistent with previous trials, and therefore adds considerable weight to the current evidence.","Preoperative chemotherapy in patients with resectable non-small cell lung cancer: results of the MRC LU22/NVALT 2/EORTC 08012 multicentre randomised trial and update of systematic review."
"803","JAMA.410","0.04",17551130,2007,"Pay for performance has been promoted as a tool for improving quality of care. In 2003, the Centers for Medicare & Medicaid Services (CMS) launched the largest pay-for-performance pilot project to date in the United States, including indicators for acute myocardial infarction.To determine if pay for performance was associated with either improved processes of care and outcomes or unintended consequences for acute myocardial infarction at hospitals participating in the CMS pilot project.An observational, patient-level analysis of 105,383 patients with acute non-ST-segment elevation myocardial infarction enrolled in the Can Rapid Risk Stratification of Unstable Angina Patients Suppress Adverse Outcomes With Early Implementation of the American College of Cardiology/American Heart Association (ACC/AHA) Guidelines (CRUSADE) national quality-improvement initiative. Patients were treated between July 1, 2003, and June 30, 2006, at 54 hospitals in the CMS program and 446 control hospitals.The differences in the use of ACC/AHA class I guideline recommended therapies and in-hospital mortality between pay for performance and control hospitals.Among treatments subject to financial incentives, there was a slightly higher rate of improvement for 2 of 6 targeted therapies at pay-for-performance vs control hospitals (odds ratio [OR] comparing adherence scores from 2003 through 2006 at half-year intervals for aspirin at discharge, 1.31; 95% confidence interval [CI], 1.18-1.46 vs OR, 1.17; 95% CI, 1.12-1.21; P = .04) and for smoking cessation counseling (OR, 1.50; 95% CI, 1.29-1.73 vs OR, 1.28; 95% CI, 1.22-1.35; P = .05). There was no significant difference in a composite measure of the 6 CMS rewarded therapies between the 2 hospital groups (change in odds per half-year period of receiving CMS therapies: OR, 1.23; 95% CI, 1.15-1.30 vs OR, 1.17; 95% CI, 1.14-1.20; P = .16). For composite measures of acute myocardial infarction treatments not subject to incentives, rates of improvement were not significantly different (OR, 1.09; 95% CI, 1.05-1.14 vs OR, 1.08; 95% CI, 1.06-1.09; P = .49). Overall, there was no evidence that improvements in in-hospital mortality were incrementally greater at pay-for-performance sites (change in odds of in-hospital death per half-year period, 0.91; 95% CI, 0.84-0.99 vs 0.97; 95% CI, 0.94-0.99; P = .21).Among hospitals participating in a voluntary quality-improvement initiative, the pay-for-performance program was not associated with a significant incremental improvement in quality of care or outcomes for acute myocardial infarction. Conversely, we did not find evidence that pay for performance had an adverse association with improvement in processes of care that were not subject to financial incentives. Additional studies of pay for performance are needed to determine its optimal role in quality-improvement initiatives.","Pay for performance, quality of care, and outcomes in acute myocardial infarction."
"804","JAMA.411","0.05",17551130,2007,"Pay for performance has been promoted as a tool for improving quality of care. In 2003, the Centers for Medicare & Medicaid Services (CMS) launched the largest pay-for-performance pilot project to date in the United States, including indicators for acute myocardial infarction.To determine if pay for performance was associated with either improved processes of care and outcomes or unintended consequences for acute myocardial infarction at hospitals participating in the CMS pilot project.An observational, patient-level analysis of 105,383 patients with acute non-ST-segment elevation myocardial infarction enrolled in the Can Rapid Risk Stratification of Unstable Angina Patients Suppress Adverse Outcomes With Early Implementation of the American College of Cardiology/American Heart Association (ACC/AHA) Guidelines (CRUSADE) national quality-improvement initiative. Patients were treated between July 1, 2003, and June 30, 2006, at 54 hospitals in the CMS program and 446 control hospitals.The differences in the use of ACC/AHA class I guideline recommended therapies and in-hospital mortality between pay for performance and control hospitals.Among treatments subject to financial incentives, there was a slightly higher rate of improvement for 2 of 6 targeted therapies at pay-for-performance vs control hospitals (odds ratio [OR] comparing adherence scores from 2003 through 2006 at half-year intervals for aspirin at discharge, 1.31; 95% confidence interval [CI], 1.18-1.46 vs OR, 1.17; 95% CI, 1.12-1.21; P = .04) and for smoking cessation counseling (OR, 1.50; 95% CI, 1.29-1.73 vs OR, 1.28; 95% CI, 1.22-1.35; P = .05). There was no significant difference in a composite measure of the 6 CMS rewarded therapies between the 2 hospital groups (change in odds per half-year period of receiving CMS therapies: OR, 1.23; 95% CI, 1.15-1.30 vs OR, 1.17; 95% CI, 1.14-1.20; P = .16). For composite measures of acute myocardial infarction treatments not subject to incentives, rates of improvement were not significantly different (OR, 1.09; 95% CI, 1.05-1.14 vs OR, 1.08; 95% CI, 1.06-1.09; P = .49). Overall, there was no evidence that improvements in in-hospital mortality were incrementally greater at pay-for-performance sites (change in odds of in-hospital death per half-year period, 0.91; 95% CI, 0.84-0.99 vs 0.97; 95% CI, 0.94-0.99; P = .21).Among hospitals participating in a voluntary quality-improvement initiative, the pay-for-performance program was not associated with a significant incremental improvement in quality of care or outcomes for acute myocardial infarction. Conversely, we did not find evidence that pay for performance had an adverse association with improvement in processes of care that were not subject to financial incentives. Additional studies of pay for performance are needed to determine its optimal role in quality-improvement initiatives.","Pay for performance, quality of care, and outcomes in acute myocardial infarction."
"805","JAMA.412","0.16",17551130,2007,"Pay for performance has been promoted as a tool for improving quality of care. In 2003, the Centers for Medicare & Medicaid Services (CMS) launched the largest pay-for-performance pilot project to date in the United States, including indicators for acute myocardial infarction.To determine if pay for performance was associated with either improved processes of care and outcomes or unintended consequences for acute myocardial infarction at hospitals participating in the CMS pilot project.An observational, patient-level analysis of 105,383 patients with acute non-ST-segment elevation myocardial infarction enrolled in the Can Rapid Risk Stratification of Unstable Angina Patients Suppress Adverse Outcomes With Early Implementation of the American College of Cardiology/American Heart Association (ACC/AHA) Guidelines (CRUSADE) national quality-improvement initiative. Patients were treated between July 1, 2003, and June 30, 2006, at 54 hospitals in the CMS program and 446 control hospitals.The differences in the use of ACC/AHA class I guideline recommended therapies and in-hospital mortality between pay for performance and control hospitals.Among treatments subject to financial incentives, there was a slightly higher rate of improvement for 2 of 6 targeted therapies at pay-for-performance vs control hospitals (odds ratio [OR] comparing adherence scores from 2003 through 2006 at half-year intervals for aspirin at discharge, 1.31; 95% confidence interval [CI], 1.18-1.46 vs OR, 1.17; 95% CI, 1.12-1.21; P = .04) and for smoking cessation counseling (OR, 1.50; 95% CI, 1.29-1.73 vs OR, 1.28; 95% CI, 1.22-1.35; P = .05). There was no significant difference in a composite measure of the 6 CMS rewarded therapies between the 2 hospital groups (change in odds per half-year period of receiving CMS therapies: OR, 1.23; 95% CI, 1.15-1.30 vs OR, 1.17; 95% CI, 1.14-1.20; P = .16). For composite measures of acute myocardial infarction treatments not subject to incentives, rates of improvement were not significantly different (OR, 1.09; 95% CI, 1.05-1.14 vs OR, 1.08; 95% CI, 1.06-1.09; P = .49). Overall, there was no evidence that improvements in in-hospital mortality were incrementally greater at pay-for-performance sites (change in odds of in-hospital death per half-year period, 0.91; 95% CI, 0.84-0.99 vs 0.97; 95% CI, 0.94-0.99; P = .21).Among hospitals participating in a voluntary quality-improvement initiative, the pay-for-performance program was not associated with a significant incremental improvement in quality of care or outcomes for acute myocardial infarction. Conversely, we did not find evidence that pay for performance had an adverse association with improvement in processes of care that were not subject to financial incentives. Additional studies of pay for performance are needed to determine its optimal role in quality-improvement initiatives.","Pay for performance, quality of care, and outcomes in acute myocardial infarction."
"806","JAMA.413","0.49",17551130,2007,"Pay for performance has been promoted as a tool for improving quality of care. In 2003, the Centers for Medicare & Medicaid Services (CMS) launched the largest pay-for-performance pilot project to date in the United States, including indicators for acute myocardial infarction.To determine if pay for performance was associated with either improved processes of care and outcomes or unintended consequences for acute myocardial infarction at hospitals participating in the CMS pilot project.An observational, patient-level analysis of 105,383 patients with acute non-ST-segment elevation myocardial infarction enrolled in the Can Rapid Risk Stratification of Unstable Angina Patients Suppress Adverse Outcomes With Early Implementation of the American College of Cardiology/American Heart Association (ACC/AHA) Guidelines (CRUSADE) national quality-improvement initiative. Patients were treated between July 1, 2003, and June 30, 2006, at 54 hospitals in the CMS program and 446 control hospitals.The differences in the use of ACC/AHA class I guideline recommended therapies and in-hospital mortality between pay for performance and control hospitals.Among treatments subject to financial incentives, there was a slightly higher rate of improvement for 2 of 6 targeted therapies at pay-for-performance vs control hospitals (odds ratio [OR] comparing adherence scores from 2003 through 2006 at half-year intervals for aspirin at discharge, 1.31; 95% confidence interval [CI], 1.18-1.46 vs OR, 1.17; 95% CI, 1.12-1.21; P = .04) and for smoking cessation counseling (OR, 1.50; 95% CI, 1.29-1.73 vs OR, 1.28; 95% CI, 1.22-1.35; P = .05). There was no significant difference in a composite measure of the 6 CMS rewarded therapies between the 2 hospital groups (change in odds per half-year period of receiving CMS therapies: OR, 1.23; 95% CI, 1.15-1.30 vs OR, 1.17; 95% CI, 1.14-1.20; P = .16). For composite measures of acute myocardial infarction treatments not subject to incentives, rates of improvement were not significantly different (OR, 1.09; 95% CI, 1.05-1.14 vs OR, 1.08; 95% CI, 1.06-1.09; P = .49). Overall, there was no evidence that improvements in in-hospital mortality were incrementally greater at pay-for-performance sites (change in odds of in-hospital death per half-year period, 0.91; 95% CI, 0.84-0.99 vs 0.97; 95% CI, 0.94-0.99; P = .21).Among hospitals participating in a voluntary quality-improvement initiative, the pay-for-performance program was not associated with a significant incremental improvement in quality of care or outcomes for acute myocardial infarction. Conversely, we did not find evidence that pay for performance had an adverse association with improvement in processes of care that were not subject to financial incentives. Additional studies of pay for performance are needed to determine its optimal role in quality-improvement initiatives.","Pay for performance, quality of care, and outcomes in acute myocardial infarction."
"807","JAMA.414","0.21",17551130,2007,"Pay for performance has been promoted as a tool for improving quality of care. In 2003, the Centers for Medicare & Medicaid Services (CMS) launched the largest pay-for-performance pilot project to date in the United States, including indicators for acute myocardial infarction.To determine if pay for performance was associated with either improved processes of care and outcomes or unintended consequences for acute myocardial infarction at hospitals participating in the CMS pilot project.An observational, patient-level analysis of 105,383 patients with acute non-ST-segment elevation myocardial infarction enrolled in the Can Rapid Risk Stratification of Unstable Angina Patients Suppress Adverse Outcomes With Early Implementation of the American College of Cardiology/American Heart Association (ACC/AHA) Guidelines (CRUSADE) national quality-improvement initiative. Patients were treated between July 1, 2003, and June 30, 2006, at 54 hospitals in the CMS program and 446 control hospitals.The differences in the use of ACC/AHA class I guideline recommended therapies and in-hospital mortality between pay for performance and control hospitals.Among treatments subject to financial incentives, there was a slightly higher rate of improvement for 2 of 6 targeted therapies at pay-for-performance vs control hospitals (odds ratio [OR] comparing adherence scores from 2003 through 2006 at half-year intervals for aspirin at discharge, 1.31; 95% confidence interval [CI], 1.18-1.46 vs OR, 1.17; 95% CI, 1.12-1.21; P = .04) and for smoking cessation counseling (OR, 1.50; 95% CI, 1.29-1.73 vs OR, 1.28; 95% CI, 1.22-1.35; P = .05). There was no significant difference in a composite measure of the 6 CMS rewarded therapies between the 2 hospital groups (change in odds per half-year period of receiving CMS therapies: OR, 1.23; 95% CI, 1.15-1.30 vs OR, 1.17; 95% CI, 1.14-1.20; P = .16). For composite measures of acute myocardial infarction treatments not subject to incentives, rates of improvement were not significantly different (OR, 1.09; 95% CI, 1.05-1.14 vs OR, 1.08; 95% CI, 1.06-1.09; P = .49). Overall, there was no evidence that improvements in in-hospital mortality were incrementally greater at pay-for-performance sites (change in odds of in-hospital death per half-year period, 0.91; 95% CI, 0.84-0.99 vs 0.97; 95% CI, 0.94-0.99; P = .21).Among hospitals participating in a voluntary quality-improvement initiative, the pay-for-performance program was not associated with a significant incremental improvement in quality of care or outcomes for acute myocardial infarction. Conversely, we did not find evidence that pay for performance had an adverse association with improvement in processes of care that were not subject to financial incentives. Additional studies of pay for performance are needed to determine its optimal role in quality-improvement initiatives.","Pay for performance, quality of care, and outcomes in acute myocardial infarction."
"808","JAMA.3591","0.001",17565083,2007,"Racial differences in the use of coronary revascularization after acute myocardial infarction (AMI) have been widely reported. However, few studies have examined patterns of care for AMI patients admitted to hospitals with and without revascularization services.To compare rates of hospital transfer, coronary revascularization, and mortality after AMI for black and white patients admitted to hospitals with and without revascularization services.Retrospective cohort study of 1,215,924 black and white Medicare beneficiaries aged 68 years and older, admitted with AMI between January 1, 2000, and June 30, 2005, to 4627 US hospitals with and without revascularization services.For patients admitted to nonrevascularization hospitals, transfer to another hospital with revascularization services; for all patients, risk-adjusted rates of 30-day coronary revascularization and 1-year mortality.Black patients admitted to hospitals without revascularization were less likely (25.2% vs 31.0%; P<.001) to be transferred. Black patients admitted to hospitals with or without revascularization services were less likely to undergo revascularization than white patients (34.3% vs 50.2% and 18.3% vs 25.9%; P<.001) and had higher 1-year mortality (35.3% vs 30.2% and 39.7% vs 37.6%; P<.001). After adjustment for sociodemographics, comorbidity, and illness severity, blacks remained less likely to be transferred (hazard ratio [HR], 0.78; 95% confidence interval [CI], 0.75-0.81; P<.001) and undergo revascularization (HR, 0.71; 95% CI, 0.69-0.74; P<.001; and HR, 0.68; 95% CI, 0.65-0.70; P<.001 in hospitals with and without revascularization, respectively). Risk-adjusted mortality was lower for blacks during the first 30 days after admission (HR, 0.91; 95% CI, 0.88-0.93; P<.001; and HR, 0.90; 95% CI, 0.87-0.92; P<.001 in hospitals with and without revascularization, respectively) but was higher (P<.001) thereafter.Black patients admitted to hospitals with and without coronary revascularization services are less likely to receive coronary revascularization. The higher long-term mortality of black patients may reflect the lower use of revascularization or other aspects of AMI care.","Differences in mortality and use of revascularization in black and white patients with acute MI admitted to hospitals with and without revascularization services."
"809","JAMA.3601","0.001",17565083,2007,"Racial differences in the use of coronary revascularization after acute myocardial infarction (AMI) have been widely reported. However, few studies have examined patterns of care for AMI patients admitted to hospitals with and without revascularization services.To compare rates of hospital transfer, coronary revascularization, and mortality after AMI for black and white patients admitted to hospitals with and without revascularization services.Retrospective cohort study of 1,215,924 black and white Medicare beneficiaries aged 68 years and older, admitted with AMI between January 1, 2000, and June 30, 2005, to 4627 US hospitals with and without revascularization services.For patients admitted to nonrevascularization hospitals, transfer to another hospital with revascularization services; for all patients, risk-adjusted rates of 30-day coronary revascularization and 1-year mortality.Black patients admitted to hospitals without revascularization were less likely (25.2% vs 31.0%; P<.001) to be transferred. Black patients admitted to hospitals with or without revascularization services were less likely to undergo revascularization than white patients (34.3% vs 50.2% and 18.3% vs 25.9%; P<.001) and had higher 1-year mortality (35.3% vs 30.2% and 39.7% vs 37.6%; P<.001). After adjustment for sociodemographics, comorbidity, and illness severity, blacks remained less likely to be transferred (hazard ratio [HR], 0.78; 95% confidence interval [CI], 0.75-0.81; P<.001) and undergo revascularization (HR, 0.71; 95% CI, 0.69-0.74; P<.001; and HR, 0.68; 95% CI, 0.65-0.70; P<.001 in hospitals with and without revascularization, respectively). Risk-adjusted mortality was lower for blacks during the first 30 days after admission (HR, 0.91; 95% CI, 0.88-0.93; P<.001; and HR, 0.90; 95% CI, 0.87-0.92; P<.001 in hospitals with and without revascularization, respectively) but was higher (P<.001) thereafter.Black patients admitted to hospitals with and without coronary revascularization services are less likely to receive coronary revascularization. The higher long-term mortality of black patients may reflect the lower use of revascularization or other aspects of AMI care.","Differences in mortality and use of revascularization in black and white patients with acute MI admitted to hospitals with and without revascularization services."
"810","JAMA.3611","0.001",17565083,2007,"Racial differences in the use of coronary revascularization after acute myocardial infarction (AMI) have been widely reported. However, few studies have examined patterns of care for AMI patients admitted to hospitals with and without revascularization services.To compare rates of hospital transfer, coronary revascularization, and mortality after AMI for black and white patients admitted to hospitals with and without revascularization services.Retrospective cohort study of 1,215,924 black and white Medicare beneficiaries aged 68 years and older, admitted with AMI between January 1, 2000, and June 30, 2005, to 4627 US hospitals with and without revascularization services.For patients admitted to nonrevascularization hospitals, transfer to another hospital with revascularization services; for all patients, risk-adjusted rates of 30-day coronary revascularization and 1-year mortality.Black patients admitted to hospitals without revascularization were less likely (25.2% vs 31.0%; P<.001) to be transferred. Black patients admitted to hospitals with or without revascularization services were less likely to undergo revascularization than white patients (34.3% vs 50.2% and 18.3% vs 25.9%; P<.001) and had higher 1-year mortality (35.3% vs 30.2% and 39.7% vs 37.6%; P<.001). After adjustment for sociodemographics, comorbidity, and illness severity, blacks remained less likely to be transferred (hazard ratio [HR], 0.78; 95% confidence interval [CI], 0.75-0.81; P<.001) and undergo revascularization (HR, 0.71; 95% CI, 0.69-0.74; P<.001; and HR, 0.68; 95% CI, 0.65-0.70; P<.001 in hospitals with and without revascularization, respectively). Risk-adjusted mortality was lower for blacks during the first 30 days after admission (HR, 0.91; 95% CI, 0.88-0.93; P<.001; and HR, 0.90; 95% CI, 0.87-0.92; P<.001 in hospitals with and without revascularization, respectively) but was higher (P<.001) thereafter.Black patients admitted to hospitals with and without coronary revascularization services are less likely to receive coronary revascularization. The higher long-term mortality of black patients may reflect the lower use of revascularization or other aspects of AMI care.","Differences in mortality and use of revascularization in black and white patients with acute MI admitted to hospitals with and without revascularization services."
"811","JAMA.3621","0.001",17565083,2007,"Racial differences in the use of coronary revascularization after acute myocardial infarction (AMI) have been widely reported. However, few studies have examined patterns of care for AMI patients admitted to hospitals with and without revascularization services.To compare rates of hospital transfer, coronary revascularization, and mortality after AMI for black and white patients admitted to hospitals with and without revascularization services.Retrospective cohort study of 1,215,924 black and white Medicare beneficiaries aged 68 years and older, admitted with AMI between January 1, 2000, and June 30, 2005, to 4627 US hospitals with and without revascularization services.For patients admitted to nonrevascularization hospitals, transfer to another hospital with revascularization services; for all patients, risk-adjusted rates of 30-day coronary revascularization and 1-year mortality.Black patients admitted to hospitals without revascularization were less likely (25.2% vs 31.0%; P<.001) to be transferred. Black patients admitted to hospitals with or without revascularization services were less likely to undergo revascularization than white patients (34.3% vs 50.2% and 18.3% vs 25.9%; P<.001) and had higher 1-year mortality (35.3% vs 30.2% and 39.7% vs 37.6%; P<.001). After adjustment for sociodemographics, comorbidity, and illness severity, blacks remained less likely to be transferred (hazard ratio [HR], 0.78; 95% confidence interval [CI], 0.75-0.81; P<.001) and undergo revascularization (HR, 0.71; 95% CI, 0.69-0.74; P<.001; and HR, 0.68; 95% CI, 0.65-0.70; P<.001 in hospitals with and without revascularization, respectively). Risk-adjusted mortality was lower for blacks during the first 30 days after admission (HR, 0.91; 95% CI, 0.88-0.93; P<.001; and HR, 0.90; 95% CI, 0.87-0.92; P<.001 in hospitals with and without revascularization, respectively) but was higher (P<.001) thereafter.Black patients admitted to hospitals with and without coronary revascularization services are less likely to receive coronary revascularization. The higher long-term mortality of black patients may reflect the lower use of revascularization or other aspects of AMI care.","Differences in mortality and use of revascularization in black and white patients with acute MI admitted to hospitals with and without revascularization services."
"812","JAMA.3631","0.001",17565083,2007,"Racial differences in the use of coronary revascularization after acute myocardial infarction (AMI) have been widely reported. However, few studies have examined patterns of care for AMI patients admitted to hospitals with and without revascularization services.To compare rates of hospital transfer, coronary revascularization, and mortality after AMI for black and white patients admitted to hospitals with and without revascularization services.Retrospective cohort study of 1,215,924 black and white Medicare beneficiaries aged 68 years and older, admitted with AMI between January 1, 2000, and June 30, 2005, to 4627 US hospitals with and without revascularization services.For patients admitted to nonrevascularization hospitals, transfer to another hospital with revascularization services; for all patients, risk-adjusted rates of 30-day coronary revascularization and 1-year mortality.Black patients admitted to hospitals without revascularization were less likely (25.2% vs 31.0%; P<.001) to be transferred. Black patients admitted to hospitals with or without revascularization services were less likely to undergo revascularization than white patients (34.3% vs 50.2% and 18.3% vs 25.9%; P<.001) and had higher 1-year mortality (35.3% vs 30.2% and 39.7% vs 37.6%; P<.001). After adjustment for sociodemographics, comorbidity, and illness severity, blacks remained less likely to be transferred (hazard ratio [HR], 0.78; 95% confidence interval [CI], 0.75-0.81; P<.001) and undergo revascularization (HR, 0.71; 95% CI, 0.69-0.74; P<.001; and HR, 0.68; 95% CI, 0.65-0.70; P<.001 in hospitals with and without revascularization, respectively). Risk-adjusted mortality was lower for blacks during the first 30 days after admission (HR, 0.91; 95% CI, 0.88-0.93; P<.001; and HR, 0.90; 95% CI, 0.87-0.92; P<.001 in hospitals with and without revascularization, respectively) but was higher (P<.001) thereafter.Black patients admitted to hospitals with and without coronary revascularization services are less likely to receive coronary revascularization. The higher long-term mortality of black patients may reflect the lower use of revascularization or other aspects of AMI care.","Differences in mortality and use of revascularization in black and white patients with acute MI admitted to hospitals with and without revascularization services."
"813","Lancet.55","0.012",17765523,2007,"Chronic obstructive pulmonary disease (COPD) is a growing cause of morbidity and mortality worldwide, and accurate estimates of the prevalence of this disease are needed to anticipate the future burden of COPD, target key risk factors, and plan for providing COPD-related health services. We aimed to measure the prevalence of COPD and its risk factors and investigate variation across countries by age, sex, and smoking status.Participants from 12 sites (n=9425) completed postbronchodilator spirometry testing plus questionnaires about respiratory symptoms, health status, and exposure to COPD risk factors. COPD prevalence estimates based on the Global Initiative for Chronic Obstructive Lung Disease staging criteria were adjusted for the target population. Logistic regression was used to estimate adjusted odds ratios (ORs) for COPD associated with 10-year age increments and 10-pack-year (defined as the number of cigarettes smoked per day divided by 20 and multiplied by the number of years that the participant smoked) increments. Meta-analyses provided pooled estimates for these risk factors.The prevalence of stage II or higher COPD was 10.1% (SE 4.8) overall, 11.8% (7.9) for men, and 8.5% (5.8) for women. The ORs for 10-year age increments were much the same across sites and for women and men. The overall pooled estimate was 1.94 (95% CI 1.80-2.10) per 10-year increment. Site-specific pack-year ORs varied significantly in women (pooled OR=1.28, 95% CI 1.15-1.42, p=0.012), but not in men (1.16, 1.12-1.21, p=0.743).This worldwide study showed higher levels and more advanced staging of spirometrically confirmed COPD than have typically been reported. However, although age and smoking are strong contributors to COPD, they do not fully explain variations in disease prevalence-other factors also seem to be important. Although smoking cessation is becoming an increasingly urgent objective for an ageing worldwide population, a better understanding of other factors that contribute to COPD is crucial to assist local public-health officials in developing the best possible primary and secondary prevention policies for their regions.","International variation in the prevalence of COPD (the BOLD Study): a population-based prevalence study."
"814","Lancet.56","0.743",17765523,2007,"Chronic obstructive pulmonary disease (COPD) is a growing cause of morbidity and mortality worldwide, and accurate estimates of the prevalence of this disease are needed to anticipate the future burden of COPD, target key risk factors, and plan for providing COPD-related health services. We aimed to measure the prevalence of COPD and its risk factors and investigate variation across countries by age, sex, and smoking status.Participants from 12 sites (n=9425) completed postbronchodilator spirometry testing plus questionnaires about respiratory symptoms, health status, and exposure to COPD risk factors. COPD prevalence estimates based on the Global Initiative for Chronic Obstructive Lung Disease staging criteria were adjusted for the target population. Logistic regression was used to estimate adjusted odds ratios (ORs) for COPD associated with 10-year age increments and 10-pack-year (defined as the number of cigarettes smoked per day divided by 20 and multiplied by the number of years that the participant smoked) increments. Meta-analyses provided pooled estimates for these risk factors.The prevalence of stage II or higher COPD was 10.1% (SE 4.8) overall, 11.8% (7.9) for men, and 8.5% (5.8) for women. The ORs for 10-year age increments were much the same across sites and for women and men. The overall pooled estimate was 1.94 (95% CI 1.80-2.10) per 10-year increment. Site-specific pack-year ORs varied significantly in women (pooled OR=1.28, 95% CI 1.15-1.42, p=0.012), but not in men (1.16, 1.12-1.21, p=0.743).This worldwide study showed higher levels and more advanced staging of spirometrically confirmed COPD than have typically been reported. However, although age and smoking are strong contributors to COPD, they do not fully explain variations in disease prevalence-other factors also seem to be important. Although smoking cessation is becoming an increasingly urgent objective for an ageing worldwide population, a better understanding of other factors that contribute to COPD is crucial to assist local public-health officials in developing the best possible primary and secondary prevention policies for their regions.","International variation in the prevalence of COPD (the BOLD Study): a population-based prevalence study."
"815","American Journal of Epidemiology.171","0.035",17827444,2007,"Combined hormone replacement therapy (CHRT) containing estrogens and progestins is associated with breast cancer risk. The authors evaluated interactions between CHRT use and progestin metabolism genotypes at CYP3A4 and the progesterone receptor (PGR) and their effects on breast cancer risk using the population-based Women's Insights and Shared Experiences (WISE) Study (1999-2002) of postmenopausal Caucasian women (522 breast cancer cases, 708 controls). The authors observed an elevated risk of ductal tumors in women with 3 or more years of CHRT use and PGR 331A alleles compared with those who had neither factor (odds ratio = 3.35, 95% confidence interval (CI): 1.13, 9.99; two-sided p(interaction) = 0.035). They also observed an elevated risk of progesterone receptor-positive tumors in women who had had 3 or more years of CHRT use and PGR 331A alleles compared with those who had neither factor (odds ratio = 3.82, 95% CI: 1.26, 11.55; p = 0.028). Finally, they observed an increased risk of estrogen receptor-negative tumors in women without CHRT exposure and CYP3A4*1B alleles compared with those who had neither factor (odds ratio = 6.46, 95% CI: 2.02, 20.66; p = 0.024), although the biologic interpretation of this result requires further study. When stratified by recency of use, PGR effects were observed only in current CHRT users, while CYP3A4 effects were observed only in former CHRT users. Breast cancer risk in women who have used CHRT may be influenced by genetic factors involved in progestin metabolism.","Pharmacogenetic modulation of combined hormone replacement therapy by progesterone-metabolism genotypes in postmenopausal breast cancer risk."
"816","American Journal of Epidemiology.171","0.028",17827444,2007,"Combined hormone replacement therapy (CHRT) containing estrogens and progestins is associated with breast cancer risk. The authors evaluated interactions between CHRT use and progestin metabolism genotypes at CYP3A4 and the progesterone receptor (PGR) and their effects on breast cancer risk using the population-based Women's Insights and Shared Experiences (WISE) Study (1999-2002) of postmenopausal Caucasian women (522 breast cancer cases, 708 controls). The authors observed an elevated risk of ductal tumors in women with 3 or more years of CHRT use and PGR 331A alleles compared with those who had neither factor (odds ratio = 3.35, 95% confidence interval (CI): 1.13, 9.99; two-sided p(interaction) = 0.035). They also observed an elevated risk of progesterone receptor-positive tumors in women who had had 3 or more years of CHRT use and PGR 331A alleles compared with those who had neither factor (odds ratio = 3.82, 95% CI: 1.26, 11.55; p = 0.028). Finally, they observed an increased risk of estrogen receptor-negative tumors in women without CHRT exposure and CYP3A4*1B alleles compared with those who had neither factor (odds ratio = 6.46, 95% CI: 2.02, 20.66; p = 0.024), although the biologic interpretation of this result requires further study. When stratified by recency of use, PGR effects were observed only in current CHRT users, while CYP3A4 effects were observed only in former CHRT users. Breast cancer risk in women who have used CHRT may be influenced by genetic factors involved in progestin metabolism.","Pharmacogenetic modulation of combined hormone replacement therapy by progesterone-metabolism genotypes in postmenopausal breast cancer risk."
"817","American Journal of Epidemiology.181","0.024",17827444,2007,"Combined hormone replacement therapy (CHRT) containing estrogens and progestins is associated with breast cancer risk. The authors evaluated interactions between CHRT use and progestin metabolism genotypes at CYP3A4 and the progesterone receptor (PGR) and their effects on breast cancer risk using the population-based Women's Insights and Shared Experiences (WISE) Study (1999-2002) of postmenopausal Caucasian women (522 breast cancer cases, 708 controls). The authors observed an elevated risk of ductal tumors in women with 3 or more years of CHRT use and PGR 331A alleles compared with those who had neither factor (odds ratio = 3.35, 95% confidence interval (CI): 1.13, 9.99; two-sided p(interaction) = 0.035). They also observed an elevated risk of progesterone receptor-positive tumors in women who had had 3 or more years of CHRT use and PGR 331A alleles compared with those who had neither factor (odds ratio = 3.82, 95% CI: 1.26, 11.55; p = 0.028). Finally, they observed an increased risk of estrogen receptor-negative tumors in women without CHRT exposure and CYP3A4*1B alleles compared with those who had neither factor (odds ratio = 6.46, 95% CI: 2.02, 20.66; p = 0.024), although the biologic interpretation of this result requires further study. When stratified by recency of use, PGR effects were observed only in current CHRT users, while CYP3A4 effects were observed only in former CHRT users. Breast cancer risk in women who have used CHRT may be influenced by genetic factors involved in progestin metabolism.","Pharmacogenetic modulation of combined hormone replacement therapy by progesterone-metabolism genotypes in postmenopausal breast cancer risk."
"818","JAMA.3931","0.005",17848652,2007,"Pioglitazone is widely used for glycemic control in patients with type 2 diabetes mellitus, but evidence is mixed regarding the influence of medications of this class on cardiovascular outcomes.To systematically evaluate the effect of pioglitazone on ischemic cardiovascular events.A database containing individual patient-level time-to-event data collected during pioglitazone clinical trials was transferred from the drug's manufacturer for independent analysis. Trials were included if they were randomized, double-blinded, and controlled with placebo or active comparator.The primary outcome was a composite of death, myocardial infarction, or stroke. Secondary outcome measures included the incidence of serious heart failure. A fixed-effects approach was used to combine the estimates across the duration strata and statistical heterogeneity across all the trials was tested with the I2 statistic.A total of 19 trials enrolling 16 390 patients were analyzed. Study drug treatment duration ranged from 4 months to 3.5 years. Death, myocardial infarction, or stroke occurred in 375 of 8554 patients (4.4%) receiving pioglitazone and 450 of 7836 patients (5.7%) receiving control therapy (hazard ratio [HR], 0.82; 95% confidence interval [CI], 0.72-0.94; P = .005). Progressive separation of time-to-event curves became apparent after approximately 1 year of therapy. Individual components of the primary end point were all reduced by a similar magnitude with pioglitazone treatment, with HRs ranging from 0.80 to 0.92. Serious heart failure was reported in 200 (2.3%) of the pioglitazone-treated patients and 139 (1.8%) of the control patients (HR, 1.41; 95% CI, 1.14-1.76; P = .002). The magnitude and direction of the favorable effect of pioglitazone on ischemic events and unfavorable effect on heart failure was homogeneous across trials of different durations, for different comparators, and for patients with or without established vascular disease. There was no evidence of heterogeneity across the trials for either end point (I2 = 0%; P = .87 for the composite end point and I2 = 0%; P = .97 for heart failure).Pioglitazone is associated with a significantly lower risk of death, myocardial infarction, or stroke among a diverse population of patients with diabetes. Serious heart failure is increased by pioglitazone, although without an associated increase in mortality.","Pioglitazone and risk of cardiovascular events in patients with type 2 diabetes mellitus: a meta-analysis of randomized trials."
"819","JAMA.3941","0.002",17848652,2007,"Pioglitazone is widely used for glycemic control in patients with type 2 diabetes mellitus, but evidence is mixed regarding the influence of medications of this class on cardiovascular outcomes.To systematically evaluate the effect of pioglitazone on ischemic cardiovascular events.A database containing individual patient-level time-to-event data collected during pioglitazone clinical trials was transferred from the drug's manufacturer for independent analysis. Trials were included if they were randomized, double-blinded, and controlled with placebo or active comparator.The primary outcome was a composite of death, myocardial infarction, or stroke. Secondary outcome measures included the incidence of serious heart failure. A fixed-effects approach was used to combine the estimates across the duration strata and statistical heterogeneity across all the trials was tested with the I2 statistic.A total of 19 trials enrolling 16 390 patients were analyzed. Study drug treatment duration ranged from 4 months to 3.5 years. Death, myocardial infarction, or stroke occurred in 375 of 8554 patients (4.4%) receiving pioglitazone and 450 of 7836 patients (5.7%) receiving control therapy (hazard ratio [HR], 0.82; 95% confidence interval [CI], 0.72-0.94; P = .005). Progressive separation of time-to-event curves became apparent after approximately 1 year of therapy. Individual components of the primary end point were all reduced by a similar magnitude with pioglitazone treatment, with HRs ranging from 0.80 to 0.92. Serious heart failure was reported in 200 (2.3%) of the pioglitazone-treated patients and 139 (1.8%) of the control patients (HR, 1.41; 95% CI, 1.14-1.76; P = .002). The magnitude and direction of the favorable effect of pioglitazone on ischemic events and unfavorable effect on heart failure was homogeneous across trials of different durations, for different comparators, and for patients with or without established vascular disease. There was no evidence of heterogeneity across the trials for either end point (I2 = 0%; P = .87 for the composite end point and I2 = 0%; P = .97 for heart failure).Pioglitazone is associated with a significantly lower risk of death, myocardial infarction, or stroke among a diverse population of patients with diabetes. Serious heart failure is increased by pioglitazone, although without an associated increase in mortality.","Pioglitazone and risk of cardiovascular events in patients with type 2 diabetes mellitus: a meta-analysis of randomized trials."
"820","Lancet.751","0.03",17869634,2007,"Whether the two drug-eluting stents approved by the US Food and Drug Administration-a sirolimus-eluting stent and a paclitaxel-eluting stent-are associated with increased risks of death, myocardial infarction, or stent thrombosis compared with bare-metal stents is uncertain. Our aim was to compare the safety and effectiveness of these stents.We searched relevant sources from inception to March, 2007, and contacted investigators and manufacturers to identify randomised controlled trials in patients with coronary artery disease that compared drug-eluting with bare-metal stents, or that compared sirolimus-eluting stents head-to-head with paclitaxel-eluting stents. Safety outcomes included mortality, myocardial infarction, and definite stent thrombosis; the effectiveness outcome was target lesion revascularisation. We included 38 trials (18,023 patients) with a follow-up of up to 4 years. Trialists and manufacturers provided additional data on clinical outcomes for 29 trials. We did a network meta-analysis with a mixed-treatment comparison method to combine direct within-trial comparisons between stents with indirect evidence from other trials while maintaining randomisation.Mortality was similar in the three groups: hazard ratios (HR) were 1.00 (95% credibility interval 0.82-1.25) for sirolimus-eluting versus bare-metal stents, 1.03 (0.84-1.22) for paclitaxel-eluting versus bare-metal stents, and 0.96 (0.83-1.24) for sirolimus-eluting versus paclitaxel-eluting stents. Sirolimus-eluting stents were associated with the lowest risk of myocardial infarction (HR 0.81, 95% credibility interval 0.66-0.97, p=0.030 vs bare-metal stents; 0.83, 0.71-1.00, p=0.045 vs paclitaxel-eluting stents). There were no significant differences in the risk of definite stent thrombosis (0 days to 4 years). However, the risk of late definite stent thrombosis (>30 days) was increased with paclitaxel-eluting stents (HR 2.11, 95% credibility interval 1.19-4.23, p=0.017 vs bare-metal stents; 1.85, 1.02-3.85, p=0.041 vs sirolimus-eluting stents). The reduction in target lesion revascularisation seen with drug-eluting stents compared with bare-metal stents was more pronounced with sirolimus-eluting stents than with paclitaxel-eluting stents (0.70, 0.56-0.84; p=0.0021).The risks of mortality associated with drug-eluting and bare-metal stents are similar. Sirolimus-eluting stents seem to be clinically better than bare-metal and paclitaxel-eluting stents.","Outcomes associated with drug-eluting and bare-metal stents: a collaborative network meta-analysis."
"821","Lancet.761","0.045",17869634,2007,"Whether the two drug-eluting stents approved by the US Food and Drug Administration-a sirolimus-eluting stent and a paclitaxel-eluting stent-are associated with increased risks of death, myocardial infarction, or stent thrombosis compared with bare-metal stents is uncertain. Our aim was to compare the safety and effectiveness of these stents.We searched relevant sources from inception to March, 2007, and contacted investigators and manufacturers to identify randomised controlled trials in patients with coronary artery disease that compared drug-eluting with bare-metal stents, or that compared sirolimus-eluting stents head-to-head with paclitaxel-eluting stents. Safety outcomes included mortality, myocardial infarction, and definite stent thrombosis; the effectiveness outcome was target lesion revascularisation. We included 38 trials (18,023 patients) with a follow-up of up to 4 years. Trialists and manufacturers provided additional data on clinical outcomes for 29 trials. We did a network meta-analysis with a mixed-treatment comparison method to combine direct within-trial comparisons between stents with indirect evidence from other trials while maintaining randomisation.Mortality was similar in the three groups: hazard ratios (HR) were 1.00 (95% credibility interval 0.82-1.25) for sirolimus-eluting versus bare-metal stents, 1.03 (0.84-1.22) for paclitaxel-eluting versus bare-metal stents, and 0.96 (0.83-1.24) for sirolimus-eluting versus paclitaxel-eluting stents. Sirolimus-eluting stents were associated with the lowest risk of myocardial infarction (HR 0.81, 95% credibility interval 0.66-0.97, p=0.030 vs bare-metal stents; 0.83, 0.71-1.00, p=0.045 vs paclitaxel-eluting stents). There were no significant differences in the risk of definite stent thrombosis (0 days to 4 years). However, the risk of late definite stent thrombosis (>30 days) was increased with paclitaxel-eluting stents (HR 2.11, 95% credibility interval 1.19-4.23, p=0.017 vs bare-metal stents; 1.85, 1.02-3.85, p=0.041 vs sirolimus-eluting stents). The reduction in target lesion revascularisation seen with drug-eluting stents compared with bare-metal stents was more pronounced with sirolimus-eluting stents than with paclitaxel-eluting stents (0.70, 0.56-0.84; p=0.0021).The risks of mortality associated with drug-eluting and bare-metal stents are similar. Sirolimus-eluting stents seem to be clinically better than bare-metal and paclitaxel-eluting stents.","Outcomes associated with drug-eluting and bare-metal stents: a collaborative network meta-analysis."
"822","Lancet.771","0.017",17869634,2007,"Whether the two drug-eluting stents approved by the US Food and Drug Administration-a sirolimus-eluting stent and a paclitaxel-eluting stent-are associated with increased risks of death, myocardial infarction, or stent thrombosis compared with bare-metal stents is uncertain. Our aim was to compare the safety and effectiveness of these stents.We searched relevant sources from inception to March, 2007, and contacted investigators and manufacturers to identify randomised controlled trials in patients with coronary artery disease that compared drug-eluting with bare-metal stents, or that compared sirolimus-eluting stents head-to-head with paclitaxel-eluting stents. Safety outcomes included mortality, myocardial infarction, and definite stent thrombosis; the effectiveness outcome was target lesion revascularisation. We included 38 trials (18,023 patients) with a follow-up of up to 4 years. Trialists and manufacturers provided additional data on clinical outcomes for 29 trials. We did a network meta-analysis with a mixed-treatment comparison method to combine direct within-trial comparisons between stents with indirect evidence from other trials while maintaining randomisation.Mortality was similar in the three groups: hazard ratios (HR) were 1.00 (95% credibility interval 0.82-1.25) for sirolimus-eluting versus bare-metal stents, 1.03 (0.84-1.22) for paclitaxel-eluting versus bare-metal stents, and 0.96 (0.83-1.24) for sirolimus-eluting versus paclitaxel-eluting stents. Sirolimus-eluting stents were associated with the lowest risk of myocardial infarction (HR 0.81, 95% credibility interval 0.66-0.97, p=0.030 vs bare-metal stents; 0.83, 0.71-1.00, p=0.045 vs paclitaxel-eluting stents). There were no significant differences in the risk of definite stent thrombosis (0 days to 4 years). However, the risk of late definite stent thrombosis (>30 days) was increased with paclitaxel-eluting stents (HR 2.11, 95% credibility interval 1.19-4.23, p=0.017 vs bare-metal stents; 1.85, 1.02-3.85, p=0.041 vs sirolimus-eluting stents). The reduction in target lesion revascularisation seen with drug-eluting stents compared with bare-metal stents was more pronounced with sirolimus-eluting stents than with paclitaxel-eluting stents (0.70, 0.56-0.84; p=0.0021).The risks of mortality associated with drug-eluting and bare-metal stents are similar. Sirolimus-eluting stents seem to be clinically better than bare-metal and paclitaxel-eluting stents.","Outcomes associated with drug-eluting and bare-metal stents: a collaborative network meta-analysis."
"823","Lancet.781","0.041",17869634,2007,"Whether the two drug-eluting stents approved by the US Food and Drug Administration-a sirolimus-eluting stent and a paclitaxel-eluting stent-are associated with increased risks of death, myocardial infarction, or stent thrombosis compared with bare-metal stents is uncertain. Our aim was to compare the safety and effectiveness of these stents.We searched relevant sources from inception to March, 2007, and contacted investigators and manufacturers to identify randomised controlled trials in patients with coronary artery disease that compared drug-eluting with bare-metal stents, or that compared sirolimus-eluting stents head-to-head with paclitaxel-eluting stents. Safety outcomes included mortality, myocardial infarction, and definite stent thrombosis; the effectiveness outcome was target lesion revascularisation. We included 38 trials (18,023 patients) with a follow-up of up to 4 years. Trialists and manufacturers provided additional data on clinical outcomes for 29 trials. We did a network meta-analysis with a mixed-treatment comparison method to combine direct within-trial comparisons between stents with indirect evidence from other trials while maintaining randomisation.Mortality was similar in the three groups: hazard ratios (HR) were 1.00 (95% credibility interval 0.82-1.25) for sirolimus-eluting versus bare-metal stents, 1.03 (0.84-1.22) for paclitaxel-eluting versus bare-metal stents, and 0.96 (0.83-1.24) for sirolimus-eluting versus paclitaxel-eluting stents. Sirolimus-eluting stents were associated with the lowest risk of myocardial infarction (HR 0.81, 95% credibility interval 0.66-0.97, p=0.030 vs bare-metal stents; 0.83, 0.71-1.00, p=0.045 vs paclitaxel-eluting stents). There were no significant differences in the risk of definite stent thrombosis (0 days to 4 years). However, the risk of late definite stent thrombosis (>30 days) was increased with paclitaxel-eluting stents (HR 2.11, 95% credibility interval 1.19-4.23, p=0.017 vs bare-metal stents; 1.85, 1.02-3.85, p=0.041 vs sirolimus-eluting stents). The reduction in target lesion revascularisation seen with drug-eluting stents compared with bare-metal stents was more pronounced with sirolimus-eluting stents than with paclitaxel-eluting stents (0.70, 0.56-0.84; p=0.0021).The risks of mortality associated with drug-eluting and bare-metal stents are similar. Sirolimus-eluting stents seem to be clinically better than bare-metal and paclitaxel-eluting stents.","Outcomes associated with drug-eluting and bare-metal stents: a collaborative network meta-analysis."
"824","Lancet.791","0.0021",17869634,2007,"Whether the two drug-eluting stents approved by the US Food and Drug Administration-a sirolimus-eluting stent and a paclitaxel-eluting stent-are associated with increased risks of death, myocardial infarction, or stent thrombosis compared with bare-metal stents is uncertain. Our aim was to compare the safety and effectiveness of these stents.We searched relevant sources from inception to March, 2007, and contacted investigators and manufacturers to identify randomised controlled trials in patients with coronary artery disease that compared drug-eluting with bare-metal stents, or that compared sirolimus-eluting stents head-to-head with paclitaxel-eluting stents. Safety outcomes included mortality, myocardial infarction, and definite stent thrombosis; the effectiveness outcome was target lesion revascularisation. We included 38 trials (18,023 patients) with a follow-up of up to 4 years. Trialists and manufacturers provided additional data on clinical outcomes for 29 trials. We did a network meta-analysis with a mixed-treatment comparison method to combine direct within-trial comparisons between stents with indirect evidence from other trials while maintaining randomisation.Mortality was similar in the three groups: hazard ratios (HR) were 1.00 (95% credibility interval 0.82-1.25) for sirolimus-eluting versus bare-metal stents, 1.03 (0.84-1.22) for paclitaxel-eluting versus bare-metal stents, and 0.96 (0.83-1.24) for sirolimus-eluting versus paclitaxel-eluting stents. Sirolimus-eluting stents were associated with the lowest risk of myocardial infarction (HR 0.81, 95% credibility interval 0.66-0.97, p=0.030 vs bare-metal stents; 0.83, 0.71-1.00, p=0.045 vs paclitaxel-eluting stents). There were no significant differences in the risk of definite stent thrombosis (0 days to 4 years). However, the risk of late definite stent thrombosis (>30 days) was increased with paclitaxel-eluting stents (HR 2.11, 95% credibility interval 1.19-4.23, p=0.017 vs bare-metal stents; 1.85, 1.02-3.85, p=0.041 vs sirolimus-eluting stents). The reduction in target lesion revascularisation seen with drug-eluting stents compared with bare-metal stents was more pronounced with sirolimus-eluting stents than with paclitaxel-eluting stents (0.70, 0.56-0.84; p=0.0021).The risks of mortality associated with drug-eluting and bare-metal stents are similar. Sirolimus-eluting stents seem to be clinically better than bare-metal and paclitaxel-eluting stents.","Outcomes associated with drug-eluting and bare-metal stents: a collaborative network meta-analysis."
"825","JAMA.388","0.001",17895457,2007,"Colorectal neoplasm and coronary artery disease (CAD) share similar risk factors, and their co-occurrence may be associated.To investigate the prevalence of colorectal neoplasm in patients with CAD in a cross-sectional study and to identify the predisposing factors for the association of the 2 diseases.Patients in Hong Kong, China, were recruited for screening colonoscopy after undergoing coronary angiography for suspected CAD during November 2004 to June 2006. Presence of CAD (n = 206) was defined as at least 50% diameter stenosis in any 1 of the major coronary arteries; otherwise, patients were considered CAD-negative (n = 208). An age- and sex-matched control group was recruited from the general population (n = 207). Patients were excluded for use of aspirin or statins, personal history of colonic disease, or colonoscopy in the past 10 years.The prevalence of colorectal neoplasm in CAD-positive, CAD-negative, and general population participants was determined. Bivariate logistic regression was performed to study the association between colorectal neoplasm and CAD and to identify risk factors for the association of the 2 diseases after adjusting for age and sex.The prevalence of colorectal neoplasm in the CAD-positive, CAD-negative, and general population groups was 34.0%, 18.8%, and 20.8% (P < .001 by chi2 test), prevalence of advanced lesions was 18.4%, 8.7%, and 5.8% (P < .001), and prevalence of cancer was 4.4%, 0.5%, and 1.4% (P = .02), respectively. Fifty percent of the cancers in CAD-positive participants were early stage. After adjusting for age and sex, an association still existed between colorectal neoplasm and presence of CAD (odds ratio [OR], 1.88; 95% confidence interval [CI], 1.25-2.70; P = .002) and between advanced lesions and presence of CAD (OR, 2.51; 95% CI, 1.43-4.35; P = .001). The metabolic syndrome (OR, 5.99; 95% CI, 1.43-27.94; P = .02) and history of smoking (OR, 4.74; 95% CI, 1.38-18.92; P = .02) were independent factors for the association of advanced colonic lesions and CAD.In this study population undergoing coronary angiography, the prevalence of colorectal neoplasm was greater in patients with CAD. The association between the presence of advanced colonic lesions and CAD was stronger in persons with the metabolic syndrome and a history of smoking.","Prevalence of colorectal neoplasm among patients with newly diagnosed coronary artery disease."
"826","JAMA.405","0.02",17895457,2007,"Colorectal neoplasm and coronary artery disease (CAD) share similar risk factors, and their co-occurrence may be associated.To investigate the prevalence of colorectal neoplasm in patients with CAD in a cross-sectional study and to identify the predisposing factors for the association of the 2 diseases.Patients in Hong Kong, China, were recruited for screening colonoscopy after undergoing coronary angiography for suspected CAD during November 2004 to June 2006. Presence of CAD (n = 206) was defined as at least 50% diameter stenosis in any 1 of the major coronary arteries; otherwise, patients were considered CAD-negative (n = 208). An age- and sex-matched control group was recruited from the general population (n = 207). Patients were excluded for use of aspirin or statins, personal history of colonic disease, or colonoscopy in the past 10 years.The prevalence of colorectal neoplasm in CAD-positive, CAD-negative, and general population participants was determined. Bivariate logistic regression was performed to study the association between colorectal neoplasm and CAD and to identify risk factors for the association of the 2 diseases after adjusting for age and sex.The prevalence of colorectal neoplasm in the CAD-positive, CAD-negative, and general population groups was 34.0%, 18.8%, and 20.8% (P < .001 by chi2 test), prevalence of advanced lesions was 18.4%, 8.7%, and 5.8% (P < .001), and prevalence of cancer was 4.4%, 0.5%, and 1.4% (P = .02), respectively. Fifty percent of the cancers in CAD-positive participants were early stage. After adjusting for age and sex, an association still existed between colorectal neoplasm and presence of CAD (odds ratio [OR], 1.88; 95% confidence interval [CI], 1.25-2.70; P = .002) and between advanced lesions and presence of CAD (OR, 2.51; 95% CI, 1.43-4.35; P = .001). The metabolic syndrome (OR, 5.99; 95% CI, 1.43-27.94; P = .02) and history of smoking (OR, 4.74; 95% CI, 1.38-18.92; P = .02) were independent factors for the association of advanced colonic lesions and CAD.In this study population undergoing coronary angiography, the prevalence of colorectal neoplasm was greater in patients with CAD. The association between the presence of advanced colonic lesions and CAD was stronger in persons with the metabolic syndrome and a history of smoking.","Prevalence of colorectal neoplasm among patients with newly diagnosed coronary artery disease."
"827","JAMA.406","0.002",17895457,2007,"Colorectal neoplasm and coronary artery disease (CAD) share similar risk factors, and their co-occurrence may be associated.To investigate the prevalence of colorectal neoplasm in patients with CAD in a cross-sectional study and to identify the predisposing factors for the association of the 2 diseases.Patients in Hong Kong, China, were recruited for screening colonoscopy after undergoing coronary angiography for suspected CAD during November 2004 to June 2006. Presence of CAD (n = 206) was defined as at least 50% diameter stenosis in any 1 of the major coronary arteries; otherwise, patients were considered CAD-negative (n = 208). An age- and sex-matched control group was recruited from the general population (n = 207). Patients were excluded for use of aspirin or statins, personal history of colonic disease, or colonoscopy in the past 10 years.The prevalence of colorectal neoplasm in CAD-positive, CAD-negative, and general population participants was determined. Bivariate logistic regression was performed to study the association between colorectal neoplasm and CAD and to identify risk factors for the association of the 2 diseases after adjusting for age and sex.The prevalence of colorectal neoplasm in the CAD-positive, CAD-negative, and general population groups was 34.0%, 18.8%, and 20.8% (P < .001 by chi2 test), prevalence of advanced lesions was 18.4%, 8.7%, and 5.8% (P < .001), and prevalence of cancer was 4.4%, 0.5%, and 1.4% (P = .02), respectively. Fifty percent of the cancers in CAD-positive participants were early stage. After adjusting for age and sex, an association still existed between colorectal neoplasm and presence of CAD (odds ratio [OR], 1.88; 95% confidence interval [CI], 1.25-2.70; P = .002) and between advanced lesions and presence of CAD (OR, 2.51; 95% CI, 1.43-4.35; P = .001). The metabolic syndrome (OR, 5.99; 95% CI, 1.43-27.94; P = .02) and history of smoking (OR, 4.74; 95% CI, 1.38-18.92; P = .02) were independent factors for the association of advanced colonic lesions and CAD.In this study population undergoing coronary angiography, the prevalence of colorectal neoplasm was greater in patients with CAD. The association between the presence of advanced colonic lesions and CAD was stronger in persons with the metabolic syndrome and a history of smoking.","Prevalence of colorectal neoplasm among patients with newly diagnosed coronary artery disease."
"828","JAMA.408","0.02",17895457,2007,"Colorectal neoplasm and coronary artery disease (CAD) share similar risk factors, and their co-occurrence may be associated.To investigate the prevalence of colorectal neoplasm in patients with CAD in a cross-sectional study and to identify the predisposing factors for the association of the 2 diseases.Patients in Hong Kong, China, were recruited for screening colonoscopy after undergoing coronary angiography for suspected CAD during November 2004 to June 2006. Presence of CAD (n = 206) was defined as at least 50% diameter stenosis in any 1 of the major coronary arteries; otherwise, patients were considered CAD-negative (n = 208). An age- and sex-matched control group was recruited from the general population (n = 207). Patients were excluded for use of aspirin or statins, personal history of colonic disease, or colonoscopy in the past 10 years.The prevalence of colorectal neoplasm in CAD-positive, CAD-negative, and general population participants was determined. Bivariate logistic regression was performed to study the association between colorectal neoplasm and CAD and to identify risk factors for the association of the 2 diseases after adjusting for age and sex.The prevalence of colorectal neoplasm in the CAD-positive, CAD-negative, and general population groups was 34.0%, 18.8%, and 20.8% (P < .001 by chi2 test), prevalence of advanced lesions was 18.4%, 8.7%, and 5.8% (P < .001), and prevalence of cancer was 4.4%, 0.5%, and 1.4% (P = .02), respectively. Fifty percent of the cancers in CAD-positive participants were early stage. After adjusting for age and sex, an association still existed between colorectal neoplasm and presence of CAD (odds ratio [OR], 1.88; 95% confidence interval [CI], 1.25-2.70; P = .002) and between advanced lesions and presence of CAD (OR, 2.51; 95% CI, 1.43-4.35; P = .001). The metabolic syndrome (OR, 5.99; 95% CI, 1.43-27.94; P = .02) and history of smoking (OR, 4.74; 95% CI, 1.38-18.92; P = .02) were independent factors for the association of advanced colonic lesions and CAD.In this study population undergoing coronary angiography, the prevalence of colorectal neoplasm was greater in patients with CAD. The association between the presence of advanced colonic lesions and CAD was stronger in persons with the metabolic syndrome and a history of smoking.","Prevalence of colorectal neoplasm among patients with newly diagnosed coronary artery disease."
"829","JAMA.3901","0.04",17895458,2007,"Cod liver oil supplements in infancy have been associated with a decreased risk of type 1 diabetes mellitus in a retrospective study.To examine whether intakes of omega-3 and omega-6 fatty acids are associated with the development of islet autoimmunity (IA) in children.A longitudinal, observational study, the Diabetes Autoimmunity Study in the Young (DAISY), conducted in Denver, Colorado, between January 1994 and November 2006, of 1770 children at increased risk for type 1 diabetes, defined as either possession of a high diabetes risk HLA genotype or having a sibling or parent with type 1 diabetes. The mean age at follow-up was 6.2 years. Islet autoimmunity was assessed in association with reported dietary intake of polyunsaturated fatty acids starting at age 1 year. A case-cohort study (N = 244) was also conducted in which risk of IA by polyunsaturated fatty acid content of erythrocyte membranes (as a percentage of total lipids) was examined.Risk of IA, defined as being positive for insulin, glutamic acid decarboxylase, or insulinoma-associated antigen-2 autoantibodies on 2 consecutive visits and still autoantibody positive or having diabetes at last follow-up visit.Fifty-eight children developed IA. Adjusting for HLA genotype, family history of type 1 diabetes, caloric intake, and omega-6 fatty acid intake, omega-3 fatty acid intake was inversely associated with risk of IA (hazard ratio [HR], 0.45; 95% confidence interval [CI], 0.21-0.96; P = .04). The association was strengthened when the definition of the outcome was limited to those positive for 2 or more autoantibodies (HR, 0.23; 95% CI, 0.09-0.58; P = .002). In the case-cohort study, omega-3 fatty acid content of erythrocyte membranes was also inversely associated with IA risk (HR, 0.63; 95% CI, 0.41-0.96; P = .03).Dietary intake of omega-3 fatty acids is associated with reduced risk of IA in children at increased genetic risk for type 1 diabetes.","Omega-3 polyunsaturated fatty acid intake and islet autoimmunity in children at increased risk for type 1 diabetes."
"830","JAMA.3911","0.002",17895458,2007,"Cod liver oil supplements in infancy have been associated with a decreased risk of type 1 diabetes mellitus in a retrospective study.To examine whether intakes of omega-3 and omega-6 fatty acids are associated with the development of islet autoimmunity (IA) in children.A longitudinal, observational study, the Diabetes Autoimmunity Study in the Young (DAISY), conducted in Denver, Colorado, between January 1994 and November 2006, of 1770 children at increased risk for type 1 diabetes, defined as either possession of a high diabetes risk HLA genotype or having a sibling or parent with type 1 diabetes. The mean age at follow-up was 6.2 years. Islet autoimmunity was assessed in association with reported dietary intake of polyunsaturated fatty acids starting at age 1 year. A case-cohort study (N = 244) was also conducted in which risk of IA by polyunsaturated fatty acid content of erythrocyte membranes (as a percentage of total lipids) was examined.Risk of IA, defined as being positive for insulin, glutamic acid decarboxylase, or insulinoma-associated antigen-2 autoantibodies on 2 consecutive visits and still autoantibody positive or having diabetes at last follow-up visit.Fifty-eight children developed IA. Adjusting for HLA genotype, family history of type 1 diabetes, caloric intake, and omega-6 fatty acid intake, omega-3 fatty acid intake was inversely associated with risk of IA (hazard ratio [HR], 0.45; 95% confidence interval [CI], 0.21-0.96; P = .04). The association was strengthened when the definition of the outcome was limited to those positive for 2 or more autoantibodies (HR, 0.23; 95% CI, 0.09-0.58; P = .002). In the case-cohort study, omega-3 fatty acid content of erythrocyte membranes was also inversely associated with IA risk (HR, 0.63; 95% CI, 0.41-0.96; P = .03).Dietary intake of omega-3 fatty acids is associated with reduced risk of IA in children at increased genetic risk for type 1 diabetes.","Omega-3 polyunsaturated fatty acid intake and islet autoimmunity in children at increased risk for type 1 diabetes."
"831","JAMA.3921","0.03",17895458,2007,"Cod liver oil supplements in infancy have been associated with a decreased risk of type 1 diabetes mellitus in a retrospective study.To examine whether intakes of omega-3 and omega-6 fatty acids are associated with the development of islet autoimmunity (IA) in children.A longitudinal, observational study, the Diabetes Autoimmunity Study in the Young (DAISY), conducted in Denver, Colorado, between January 1994 and November 2006, of 1770 children at increased risk for type 1 diabetes, defined as either possession of a high diabetes risk HLA genotype or having a sibling or parent with type 1 diabetes. The mean age at follow-up was 6.2 years. Islet autoimmunity was assessed in association with reported dietary intake of polyunsaturated fatty acids starting at age 1 year. A case-cohort study (N = 244) was also conducted in which risk of IA by polyunsaturated fatty acid content of erythrocyte membranes (as a percentage of total lipids) was examined.Risk of IA, defined as being positive for insulin, glutamic acid decarboxylase, or insulinoma-associated antigen-2 autoantibodies on 2 consecutive visits and still autoantibody positive or having diabetes at last follow-up visit.Fifty-eight children developed IA. Adjusting for HLA genotype, family history of type 1 diabetes, caloric intake, and omega-6 fatty acid intake, omega-3 fatty acid intake was inversely associated with risk of IA (hazard ratio [HR], 0.45; 95% confidence interval [CI], 0.21-0.96; P = .04). The association was strengthened when the definition of the outcome was limited to those positive for 2 or more autoantibodies (HR, 0.23; 95% CI, 0.09-0.58; P = .002). In the case-cohort study, omega-3 fatty acid content of erythrocyte membranes was also inversely associated with IA risk (HR, 0.63; 95% CI, 0.41-0.96; P = .03).Dietary intake of omega-3 fatty acids is associated with reduced risk of IA in children at increased genetic risk for type 1 diabetes.","Omega-3 polyunsaturated fatty acid intake and islet autoimmunity in children at increased risk for type 1 diabetes."
"832","JAMA.3551","0.001",17911498,2007,"In 2005, the International Society of Urologic Pathology consensus conference recommended that men with biopsy Gleason score 3 + 4 or 4 + 3 prostate cancer and tertiary pattern 5 should have their cancer classified as Gleason score 8 or 9, respectively. Yet, the management of men with Gleason score 7 vs 8 or 9 prostate cancer differs.To compare the prognostic significance of Gleason score 7 with tertiary grade 5 vs other Gleason scores with respect to time to prostate-specific antigen (PSA) failure in men with prostate cancer.From 1989 to 2005, 2370 men with clinical tumor category 1c to 3b, node-negative, and nonmetastatic prostate cancer underwent definitive therapy with surgery or radiation therapy with or without hormonal therapy. A pathologist with expertise in genitourinary cancers assigned Gleason scores to the prostate needle biopsy specimens. Cox regression was used to assess whether a significant association existed between the presence of tertiary grade 5 in men with Gleason score 7 disease and time to recurrence compared with men with Gleason score 7 without tertiary grade 5, Gleason score 5 to 6, or 8 to 10 disease, adjusting for known prognostic factors and treatment.Time to PSA failure.Men with Gleason score 7 and tertiary grade 5 disease had a significantly shorter time to PSA failure than men with 7 without tertiary grade 5 (median time, 5.0 vs 6.7 years, respectively; adjusted hazard ratio (HR), 0.56; 95% confidence interval [CI], 0.32-0.97; P = .04) or score of 6 or less (median time, 15.4 years; adjusted HR, 0.24; 95% CI, 0.13-0.43; P < .001). However, a significant difference was not observed when these men were compared with men with Gleason score 8 to 10 disease (median time, 5.1 years; adjusted HR, 0.96; 95% CI, 0.54-1.71; P = .90).In this study population, men with prostate cancer having biopsy Gleason score 7 and tertiary grade 5 had a higher risk of PSA-failure when compared with men with Gleason score 7 without tertiary grade 5 and had a comparable risk with men with Gleason score 8 to 10.","PSA failure following definitive treatment of prostate cancer having biopsy Gleason score 7 with tertiary grade 5."
"833","JAMA.3881","0.04",17911498,2007,"In 2005, the International Society of Urologic Pathology consensus conference recommended that men with biopsy Gleason score 3 + 4 or 4 + 3 prostate cancer and tertiary pattern 5 should have their cancer classified as Gleason score 8 or 9, respectively. Yet, the management of men with Gleason score 7 vs 8 or 9 prostate cancer differs.To compare the prognostic significance of Gleason score 7 with tertiary grade 5 vs other Gleason scores with respect to time to prostate-specific antigen (PSA) failure in men with prostate cancer.From 1989 to 2005, 2370 men with clinical tumor category 1c to 3b, node-negative, and nonmetastatic prostate cancer underwent definitive therapy with surgery or radiation therapy with or without hormonal therapy. A pathologist with expertise in genitourinary cancers assigned Gleason scores to the prostate needle biopsy specimens. Cox regression was used to assess whether a significant association existed between the presence of tertiary grade 5 in men with Gleason score 7 disease and time to recurrence compared with men with Gleason score 7 without tertiary grade 5, Gleason score 5 to 6, or 8 to 10 disease, adjusting for known prognostic factors and treatment.Time to PSA failure.Men with Gleason score 7 and tertiary grade 5 disease had a significantly shorter time to PSA failure than men with 7 without tertiary grade 5 (median time, 5.0 vs 6.7 years, respectively; adjusted hazard ratio (HR), 0.56; 95% confidence interval [CI], 0.32-0.97; P = .04) or score of 6 or less (median time, 15.4 years; adjusted HR, 0.24; 95% CI, 0.13-0.43; P < .001). However, a significant difference was not observed when these men were compared with men with Gleason score 8 to 10 disease (median time, 5.1 years; adjusted HR, 0.96; 95% CI, 0.54-1.71; P = .90).In this study population, men with prostate cancer having biopsy Gleason score 7 and tertiary grade 5 had a higher risk of PSA-failure when compared with men with Gleason score 7 without tertiary grade 5 and had a comparable risk with men with Gleason score 8 to 10.","PSA failure following definitive treatment of prostate cancer having biopsy Gleason score 7 with tertiary grade 5."
"834","JAMA.3891","0.9",17911498,2007,"In 2005, the International Society of Urologic Pathology consensus conference recommended that men with biopsy Gleason score 3 + 4 or 4 + 3 prostate cancer and tertiary pattern 5 should have their cancer classified as Gleason score 8 or 9, respectively. Yet, the management of men with Gleason score 7 vs 8 or 9 prostate cancer differs.To compare the prognostic significance of Gleason score 7 with tertiary grade 5 vs other Gleason scores with respect to time to prostate-specific antigen (PSA) failure in men with prostate cancer.From 1989 to 2005, 2370 men with clinical tumor category 1c to 3b, node-negative, and nonmetastatic prostate cancer underwent definitive therapy with surgery or radiation therapy with or without hormonal therapy. A pathologist with expertise in genitourinary cancers assigned Gleason scores to the prostate needle biopsy specimens. Cox regression was used to assess whether a significant association existed between the presence of tertiary grade 5 in men with Gleason score 7 disease and time to recurrence compared with men with Gleason score 7 without tertiary grade 5, Gleason score 5 to 6, or 8 to 10 disease, adjusting for known prognostic factors and treatment.Time to PSA failure.Men with Gleason score 7 and tertiary grade 5 disease had a significantly shorter time to PSA failure than men with 7 without tertiary grade 5 (median time, 5.0 vs 6.7 years, respectively; adjusted hazard ratio (HR), 0.56; 95% confidence interval [CI], 0.32-0.97; P = .04) or score of 6 or less (median time, 15.4 years; adjusted HR, 0.24; 95% CI, 0.13-0.43; P < .001). However, a significant difference was not observed when these men were compared with men with Gleason score 8 to 10 disease (median time, 5.1 years; adjusted HR, 0.96; 95% CI, 0.54-1.71; P = .90).In this study population, men with prostate cancer having biopsy Gleason score 7 and tertiary grade 5 had a higher risk of PSA-failure when compared with men with Gleason score 7 without tertiary grade 5 and had a comparable risk with men with Gleason score 8 to 10.","PSA failure following definitive treatment of prostate cancer having biopsy Gleason score 7 with tertiary grade 5."
"835","Lancet.701","2.00E-04",17988728,2007,"Laser treatment for diabetic retinopathy is often associated with visual field reduction and other ocular side-effects. Our aim was to assess whether long-term lipid-lowering therapy with fenofibrate could reduce the progression of retinopathy and the need for laser treatment in patients with type 2 diabetes mellitus.The Fenofibrate Intervention and Event Lowering in Diabetes (FIELD) study was a multinational randomised trial of 9795 patients aged 50-75 years with type 2 diabetes mellitus. Eligible patients were randomly assigned to receive fenofibrate 200 mg/day (n=4895) or matching placebo (n=4900). At each clinic visit, information concerning laser treatment for diabetic retinopathy-a prespecified tertiary endpoint of the main study-was gathered. Adjudication by ophthalmologists masked to treatment allocation defined instances of laser treatment for macular oedema, proliferative retinopathy, or other eye conditions. In a substudy of 1012 patients, standardised retinal photography was done and photographs graded with Early Treatment Diabetic Retinopathy Study (ETDRS) criteria to determine the cumulative incidence of diabetic retinopathy and its component lesions. Analyses were by intention to treat. This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN64783481.Laser treatment was needed more frequently in participants with poorer glycaemic or blood pressure control than in those with good control of these factors, and in those with a greater burden of clinical microvascular disease, but the need for such treatment was not affected by plasma lipid concentrations. The requirement for first laser treatment for all retinopathy was significantly lower in the fenofibrate group than in the placebo group (164 [3.4%] patients on fenofibrate vs 238 [4.9%] on placebo; hazard ratio [HR] 0.69, 95% CI 0.56-0.84; p=0.0002; absolute risk reduction 1.5% [0.7-2.3]). In the ophthalmology substudy, the primary endpoint of 2-step progression of retinopathy grade did not differ significantly between the two groups overall (46 [9.6%] patients on fenofibrate vs 57 [12.3%] on placebo; p=0.19) or in the subset of patients without pre-existing retinopathy (43 [11.4%] vs 43 [11.7%]; p=0.87). By contrast, in patients with pre-existing retinopathy, significantly fewer patients on fenofibrate had a 2-step progression than did those on placebo (three [3.1%] patients vs 14 [14.6%]; p=0.004). An exploratory composite endpoint of 2-step progression of retinopathy grade, macular oedema, or laser treatments was significantly lower in the fenofibrate group than in the placebo group (HR 0.66, 95% CI 0.47-0.94; p=0.022).Treatment with fenofibrate in individuals with type 2 diabetes mellitus reduces the need for laser treatment for diabetic retinopathy, although the mechanism of this effect does not seem to be related to plasma concentrations of lipids.","Effect of fenofibrate on the need for laser treatment for diabetic retinopathy (FIELD study): a randomised controlled trial."
"836","Lancet.741","0.022",17988728,2007,"Laser treatment for diabetic retinopathy is often associated with visual field reduction and other ocular side-effects. Our aim was to assess whether long-term lipid-lowering therapy with fenofibrate could reduce the progression of retinopathy and the need for laser treatment in patients with type 2 diabetes mellitus.The Fenofibrate Intervention and Event Lowering in Diabetes (FIELD) study was a multinational randomised trial of 9795 patients aged 50-75 years with type 2 diabetes mellitus. Eligible patients were randomly assigned to receive fenofibrate 200 mg/day (n=4895) or matching placebo (n=4900). At each clinic visit, information concerning laser treatment for diabetic retinopathy-a prespecified tertiary endpoint of the main study-was gathered. Adjudication by ophthalmologists masked to treatment allocation defined instances of laser treatment for macular oedema, proliferative retinopathy, or other eye conditions. In a substudy of 1012 patients, standardised retinal photography was done and photographs graded with Early Treatment Diabetic Retinopathy Study (ETDRS) criteria to determine the cumulative incidence of diabetic retinopathy and its component lesions. Analyses were by intention to treat. This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN64783481.Laser treatment was needed more frequently in participants with poorer glycaemic or blood pressure control than in those with good control of these factors, and in those with a greater burden of clinical microvascular disease, but the need for such treatment was not affected by plasma lipid concentrations. The requirement for first laser treatment for all retinopathy was significantly lower in the fenofibrate group than in the placebo group (164 [3.4%] patients on fenofibrate vs 238 [4.9%] on placebo; hazard ratio [HR] 0.69, 95% CI 0.56-0.84; p=0.0002; absolute risk reduction 1.5% [0.7-2.3]). In the ophthalmology substudy, the primary endpoint of 2-step progression of retinopathy grade did not differ significantly between the two groups overall (46 [9.6%] patients on fenofibrate vs 57 [12.3%] on placebo; p=0.19) or in the subset of patients without pre-existing retinopathy (43 [11.4%] vs 43 [11.7%]; p=0.87). By contrast, in patients with pre-existing retinopathy, significantly fewer patients on fenofibrate had a 2-step progression than did those on placebo (three [3.1%] patients vs 14 [14.6%]; p=0.004). An exploratory composite endpoint of 2-step progression of retinopathy grade, macular oedema, or laser treatments was significantly lower in the fenofibrate group than in the placebo group (HR 0.66, 95% CI 0.47-0.94; p=0.022).Treatment with fenofibrate in individuals with type 2 diabetes mellitus reduces the need for laser treatment for diabetic retinopathy, although the mechanism of this effect does not seem to be related to plasma concentrations of lipids.","Effect of fenofibrate on the need for laser treatment for diabetic retinopathy (FIELD study): a randomised controlled trial."
"837","American Journal of Epidemiology.68","1.00E-04",17998277,2007,"A large health survey was combined with a simulation study to contrast the reduction in bias achieved by double sampling versus two weighting methods based on propensity scores. The survey used a census of one New York county and double sampling in six others. Propensity scores were modeled as a logistic function of demographic variables and were used in conjunction with a random uniform variate to simulate response in the census. These data were used to estimate the prevalence of chronic disease in a population whose parameters were defined as values from the census. Significant (p < 0.0001) predictors in the logistic function included multiple (vs. single) occupancy (odds ratio (OR) = 1.3), bank card ownership (OR = 2.1), gender (OR = 1.5), home ownership (OR = 1.3), head of household's age (OR = 1.4), and income >$18,000 (OR = 0.8). The model likelihood ratio chi-square was significant (p < 0.0001), with the area under the receiver operating characteristic curve = 0.59. Double-sampling estimates were marginally closer to population values than those from either weighting method. However, the variance was also greater (p < 0.01). The reduction in bias for point estimation from double sampling may be more than offset by the increased variance associated with this method.","Handling nonresponse in surveys: analytic corrections compared with converting nonresponders."
"838","American Journal of Epidemiology.69","1.00E-04",17998277,2007,"A large health survey was combined with a simulation study to contrast the reduction in bias achieved by double sampling versus two weighting methods based on propensity scores. The survey used a census of one New York county and double sampling in six others. Propensity scores were modeled as a logistic function of demographic variables and were used in conjunction with a random uniform variate to simulate response in the census. These data were used to estimate the prevalence of chronic disease in a population whose parameters were defined as values from the census. Significant (p < 0.0001) predictors in the logistic function included multiple (vs. single) occupancy (odds ratio (OR) = 1.3), bank card ownership (OR = 2.1), gender (OR = 1.5), home ownership (OR = 1.3), head of household's age (OR = 1.4), and income >$18,000 (OR = 0.8). The model likelihood ratio chi-square was significant (p < 0.0001), with the area under the receiver operating characteristic curve = 0.59. Double-sampling estimates were marginally closer to population values than those from either weighting method. However, the variance was also greater (p < 0.01). The reduction in bias for point estimation from double sampling may be more than offset by the increased variance associated with this method.","Handling nonresponse in surveys: analytic corrections compared with converting nonresponders."
"839","American Journal of Epidemiology.70","1.00E-04",17998277,2007,"A large health survey was combined with a simulation study to contrast the reduction in bias achieved by double sampling versus two weighting methods based on propensity scores. The survey used a census of one New York county and double sampling in six others. Propensity scores were modeled as a logistic function of demographic variables and were used in conjunction with a random uniform variate to simulate response in the census. These data were used to estimate the prevalence of chronic disease in a population whose parameters were defined as values from the census. Significant (p < 0.0001) predictors in the logistic function included multiple (vs. single) occupancy (odds ratio (OR) = 1.3), bank card ownership (OR = 2.1), gender (OR = 1.5), home ownership (OR = 1.3), head of household's age (OR = 1.4), and income >$18,000 (OR = 0.8). The model likelihood ratio chi-square was significant (p < 0.0001), with the area under the receiver operating characteristic curve = 0.59. Double-sampling estimates were marginally closer to population values than those from either weighting method. However, the variance was also greater (p < 0.01). The reduction in bias for point estimation from double sampling may be more than offset by the increased variance associated with this method.","Handling nonresponse in surveys: analytic corrections compared with converting nonresponders."
"840","American Journal of Epidemiology.76","1.00E-04",17998277,2008,"A large health survey was combined with a simulation study to contrast the reduction in bias achieved by double sampling versus two weighting methods based on propensity scores. The survey used a census of one New York county and double sampling in six others. Propensity scores were modeled as a logistic function of demographic variables and were used in conjunction with a random uniform variate to simulate response in the census. These data were used to estimate the prevalence of chronic disease in a population whose parameters were defined as values from the census. Significant (p < 0.0001) predictors in the logistic function included multiple (vs. single) occupancy (odds ratio (OR) = 1.3), bank card ownership (OR = 2.1), gender (OR = 1.5), home ownership (OR = 1.3), head of household's age (OR = 1.4), and income >$18,000 (OR = 0.8). The model likelihood ratio chi-square was significant (p < 0.0001), with the area under the receiver operating characteristic curve = 0.59. Double-sampling estimates were marginally closer to population values than those from either weighting method. However, the variance was also greater (p < 0.01). The reduction in bias for point estimation from double sampling may be more than offset by the increased variance associated with this method.","Handling nonresponse in surveys: analytic corrections compared with converting nonresponders."
"841","American Journal of Epidemiology.77","1.00E-04",17998277,2008,"A large health survey was combined with a simulation study to contrast the reduction in bias achieved by double sampling versus two weighting methods based on propensity scores. The survey used a census of one New York county and double sampling in six others. Propensity scores were modeled as a logistic function of demographic variables and were used in conjunction with a random uniform variate to simulate response in the census. These data were used to estimate the prevalence of chronic disease in a population whose parameters were defined as values from the census. Significant (p < 0.0001) predictors in the logistic function included multiple (vs. single) occupancy (odds ratio (OR) = 1.3), bank card ownership (OR = 2.1), gender (OR = 1.5), home ownership (OR = 1.3), head of household's age (OR = 1.4), and income >$18,000 (OR = 0.8). The model likelihood ratio chi-square was significant (p < 0.0001), with the area under the receiver operating characteristic curve = 0.59. Double-sampling estimates were marginally closer to population values than those from either weighting method. However, the variance was also greater (p < 0.01). The reduction in bias for point estimation from double sampling may be more than offset by the increased variance associated with this method.","Handling nonresponse in surveys: analytic corrections compared with converting nonresponders."
"842","Lancet.50","7.00E-04",18022033,2007,"Since the prevalence of obesity continues to increase, there is a demand for effective and safe anti-obesity agents that can produce and maintain weight loss and improve comorbidity. We did a meta-analysis of all published randomised controlled trials to assess the efficacy and safety of the newly approved anti-obesity agent rimonabant.We searched The Cochrane database and Controlled Trials Register, Medline via Pubmed, Embase via WebSpirs, Web of Science, Scopus, and reference lists up to July, 2007. We collected data from four double-blind, randomised controlled trials (including 4105 participants) that compared 20 mg per day rimonabant with placebo.Patients given rimonabant had a 4.7 kg (95% CI 4.1-5.3 kg; p<0.0001) greater weight reduction after 1 year than did those given placebo. Rimonabant caused significantly more adverse events than did placebo (OR=1.4; p=0.0007; number needed to harm=25 individuals [95% CI 17-58]), and 1.4 times more serious adverse events (OR=1.4; p=0.03; number needed to harm=59 [27-830]). Patients given rimonabant were 2.5 times more likely to discontinue the treatment because of depressive mood disorders than were those given placebo (OR=2.5; p=0.01; number needed to harm=49 [19-316]). Furthermore, anxiety caused more patients to discontinue treatment in rimonabant groups than in placebo groups (OR=3.0; p=0.03; number needed to harm=166 [47-3716]).Our findings suggest that 20 mg per day rimonabant increases the risk of psychiatric adverse events--ie, depressed mood disorders and anxiety-despite depressed mood being an exclusion criterion in these trials. Taken together with the recent US Food and Drug Administration finding of increased risk of suicide during treatment with rimonabant, we recommend increased alertness by physicians to these potentially severe psychiatric adverse reactions.","Efficacy and safety of the weight-loss drug rimonabant: a meta-analysis of randomised trials."
"843","Lancet.51","0.03",18022033,2007,"Since the prevalence of obesity continues to increase, there is a demand for effective and safe anti-obesity agents that can produce and maintain weight loss and improve comorbidity. We did a meta-analysis of all published randomised controlled trials to assess the efficacy and safety of the newly approved anti-obesity agent rimonabant.We searched The Cochrane database and Controlled Trials Register, Medline via Pubmed, Embase via WebSpirs, Web of Science, Scopus, and reference lists up to July, 2007. We collected data from four double-blind, randomised controlled trials (including 4105 participants) that compared 20 mg per day rimonabant with placebo.Patients given rimonabant had a 4.7 kg (95% CI 4.1-5.3 kg; p<0.0001) greater weight reduction after 1 year than did those given placebo. Rimonabant caused significantly more adverse events than did placebo (OR=1.4; p=0.0007; number needed to harm=25 individuals [95% CI 17-58]), and 1.4 times more serious adverse events (OR=1.4; p=0.03; number needed to harm=59 [27-830]). Patients given rimonabant were 2.5 times more likely to discontinue the treatment because of depressive mood disorders than were those given placebo (OR=2.5; p=0.01; number needed to harm=49 [19-316]). Furthermore, anxiety caused more patients to discontinue treatment in rimonabant groups than in placebo groups (OR=3.0; p=0.03; number needed to harm=166 [47-3716]).Our findings suggest that 20 mg per day rimonabant increases the risk of psychiatric adverse events--ie, depressed mood disorders and anxiety-despite depressed mood being an exclusion criterion in these trials. Taken together with the recent US Food and Drug Administration finding of increased risk of suicide during treatment with rimonabant, we recommend increased alertness by physicians to these potentially severe psychiatric adverse reactions.","Efficacy and safety of the weight-loss drug rimonabant: a meta-analysis of randomised trials."
"844","Lancet.52","0.01",18022033,2007,"Since the prevalence of obesity continues to increase, there is a demand for effective and safe anti-obesity agents that can produce and maintain weight loss and improve comorbidity. We did a meta-analysis of all published randomised controlled trials to assess the efficacy and safety of the newly approved anti-obesity agent rimonabant.We searched The Cochrane database and Controlled Trials Register, Medline via Pubmed, Embase via WebSpirs, Web of Science, Scopus, and reference lists up to July, 2007. We collected data from four double-blind, randomised controlled trials (including 4105 participants) that compared 20 mg per day rimonabant with placebo.Patients given rimonabant had a 4.7 kg (95% CI 4.1-5.3 kg; p<0.0001) greater weight reduction after 1 year than did those given placebo. Rimonabant caused significantly more adverse events than did placebo (OR=1.4; p=0.0007; number needed to harm=25 individuals [95% CI 17-58]), and 1.4 times more serious adverse events (OR=1.4; p=0.03; number needed to harm=59 [27-830]). Patients given rimonabant were 2.5 times more likely to discontinue the treatment because of depressive mood disorders than were those given placebo (OR=2.5; p=0.01; number needed to harm=49 [19-316]). Furthermore, anxiety caused more patients to discontinue treatment in rimonabant groups than in placebo groups (OR=3.0; p=0.03; number needed to harm=166 [47-3716]).Our findings suggest that 20 mg per day rimonabant increases the risk of psychiatric adverse events--ie, depressed mood disorders and anxiety-despite depressed mood being an exclusion criterion in these trials. Taken together with the recent US Food and Drug Administration finding of increased risk of suicide during treatment with rimonabant, we recommend increased alertness by physicians to these potentially severe psychiatric adverse reactions.","Efficacy and safety of the weight-loss drug rimonabant: a meta-analysis of randomised trials."
"845","Lancet.53","0.03",18022033,2007,"Since the prevalence of obesity continues to increase, there is a demand for effective and safe anti-obesity agents that can produce and maintain weight loss and improve comorbidity. We did a meta-analysis of all published randomised controlled trials to assess the efficacy and safety of the newly approved anti-obesity agent rimonabant.We searched The Cochrane database and Controlled Trials Register, Medline via Pubmed, Embase via WebSpirs, Web of Science, Scopus, and reference lists up to July, 2007. We collected data from four double-blind, randomised controlled trials (including 4105 participants) that compared 20 mg per day rimonabant with placebo.Patients given rimonabant had a 4.7 kg (95% CI 4.1-5.3 kg; p<0.0001) greater weight reduction after 1 year than did those given placebo. Rimonabant caused significantly more adverse events than did placebo (OR=1.4; p=0.0007; number needed to harm=25 individuals [95% CI 17-58]), and 1.4 times more serious adverse events (OR=1.4; p=0.03; number needed to harm=59 [27-830]). Patients given rimonabant were 2.5 times more likely to discontinue the treatment because of depressive mood disorders than were those given placebo (OR=2.5; p=0.01; number needed to harm=49 [19-316]). Furthermore, anxiety caused more patients to discontinue treatment in rimonabant groups than in placebo groups (OR=3.0; p=0.03; number needed to harm=166 [47-3716]).Our findings suggest that 20 mg per day rimonabant increases the risk of psychiatric adverse events--ie, depressed mood disorders and anxiety-despite depressed mood being an exclusion criterion in these trials. Taken together with the recent US Food and Drug Administration finding of increased risk of suicide during treatment with rimonabant, we recommend increased alertness by physicians to these potentially severe psychiatric adverse reactions.","Efficacy and safety of the weight-loss drug rimonabant: a meta-analysis of randomised trials."
"846","JAMA.3841","0.72",18042917,2007,"The clinical benefit of glucose-insulin-potassium (GIK) infusion in patients with ST-segment elevation myocardial infarction (STEMI) is unclear. While some smaller trials suggest benefit, in the CREATE-ECLA trial, GIK infusion had no effect on 30-day mortality in 20,201 patients.To determine the association between GIK infusion therapy and 30-day and 6-month outcomes in patients with STEMI.Primary analysis of the OASIS-6 GIK randomized controlled trial of 2748 patients with acute STEMI; prespecified analyses of the combined trial data from the OASIS-6 GIK and CREATE-ECLA GIK trial populations of 22,943 patients with acute STEMI; subgroup analysis on the timing of initiation of GIK infusion therapy and outcomes; and post hoc analyses exploring whether GIK infusion may cause early harm by increasing glucose and potassium levels and net fluid gain.High-dose GIK solution consisting of 25% glucose, 50 U/L of regular insulin, and 80 mEq/L of potassium infused at 1.5 mL/kg per hour for 24 hours.Mortality rates at 30 days and 6 months in the OASIS-6 GIK trial and rates of death, heart failure, and the composite of death or heart failure at 3 and 30 days in the combined OASIS-6 GIK and CREATE-ECLA GIK trial populations.At 6 months, 148 (10.8%) GIK infusion patients and 143 (10.4%) control patients died in the OASIS-6 trial (hazard ratio [HR], 1.04; 95% CI, 0.83-1.31; P = .72); 153 (11.1%) GIK patients and 185 (13.5%) control patients had heart failure (HR, 0.83; 95% CI, 0.67-1.02; P = .08); and 240 (17.5%) GIK patients and 264 (19.2%) control patients had a composite of death or heart failure (HR, 0.91; 95% CI, 0.76-1.08; P = .27). In the prespecified analyses of the combined trial data, there were 712 deaths (6.2%) in the GIK group and 632 deaths (5.5%) in the control group at 3 days (HR, 1.13; 95% CI, 1.02-1.26; P = .03). This difference disappeared by 30 days, with 1108 deaths (9.7%) in the GIK group and 1068 (9.3%) in the control group (HR, 1.04; 95% CI, 0.96-1.13; P = .33). GIK therapy increased levels of glucose, potassium, and net fluid gain postinfusion, all 3 of which predicted death after adjusting for multiple confounders. Adjusting for glucose, potassium, and net fluid gain eliminated the apparent increase in mortality at 3 days observed with GIK infusion, suggesting a direct association with these factors. Administration of GIK infusion within 4 hours of symptom onset yielded no benefit compared with later initiation.Infusion of GIK provided no benefit and may cause early harm following STEMI. Avoidance of infusion-related hyperglycemia, hyperkalemia, and net fluid gain may be advisable in future studies of metabolic modulation in patients with STEMI.clinicaltrials.gov Identifier: NCT00064428.","Glucose-insulin-potassium therapy in patients with ST-segment elevation myocardial infarction."
"847","JAMA.3841","0.08",18042917,2007,"The clinical benefit of glucose-insulin-potassium (GIK) infusion in patients with ST-segment elevation myocardial infarction (STEMI) is unclear. While some smaller trials suggest benefit, in the CREATE-ECLA trial, GIK infusion had no effect on 30-day mortality in 20,201 patients.To determine the association between GIK infusion therapy and 30-day and 6-month outcomes in patients with STEMI.Primary analysis of the OASIS-6 GIK randomized controlled trial of 2748 patients with acute STEMI; prespecified analyses of the combined trial data from the OASIS-6 GIK and CREATE-ECLA GIK trial populations of 22,943 patients with acute STEMI; subgroup analysis on the timing of initiation of GIK infusion therapy and outcomes; and post hoc analyses exploring whether GIK infusion may cause early harm by increasing glucose and potassium levels and net fluid gain.High-dose GIK solution consisting of 25% glucose, 50 U/L of regular insulin, and 80 mEq/L of potassium infused at 1.5 mL/kg per hour for 24 hours.Mortality rates at 30 days and 6 months in the OASIS-6 GIK trial and rates of death, heart failure, and the composite of death or heart failure at 3 and 30 days in the combined OASIS-6 GIK and CREATE-ECLA GIK trial populations.At 6 months, 148 (10.8%) GIK infusion patients and 143 (10.4%) control patients died in the OASIS-6 trial (hazard ratio [HR], 1.04; 95% CI, 0.83-1.31; P = .72); 153 (11.1%) GIK patients and 185 (13.5%) control patients had heart failure (HR, 0.83; 95% CI, 0.67-1.02; P = .08); and 240 (17.5%) GIK patients and 264 (19.2%) control patients had a composite of death or heart failure (HR, 0.91; 95% CI, 0.76-1.08; P = .27). In the prespecified analyses of the combined trial data, there were 712 deaths (6.2%) in the GIK group and 632 deaths (5.5%) in the control group at 3 days (HR, 1.13; 95% CI, 1.02-1.26; P = .03). This difference disappeared by 30 days, with 1108 deaths (9.7%) in the GIK group and 1068 (9.3%) in the control group (HR, 1.04; 95% CI, 0.96-1.13; P = .33). GIK therapy increased levels of glucose, potassium, and net fluid gain postinfusion, all 3 of which predicted death after adjusting for multiple confounders. Adjusting for glucose, potassium, and net fluid gain eliminated the apparent increase in mortality at 3 days observed with GIK infusion, suggesting a direct association with these factors. Administration of GIK infusion within 4 hours of symptom onset yielded no benefit compared with later initiation.Infusion of GIK provided no benefit and may cause early harm following STEMI. Avoidance of infusion-related hyperglycemia, hyperkalemia, and net fluid gain may be advisable in future studies of metabolic modulation in patients with STEMI.clinicaltrials.gov Identifier: NCT00064428.","Glucose-insulin-potassium therapy in patients with ST-segment elevation myocardial infarction."
"848","JAMA.3851","0.27",18042917,2007,"The clinical benefit of glucose-insulin-potassium (GIK) infusion in patients with ST-segment elevation myocardial infarction (STEMI) is unclear. While some smaller trials suggest benefit, in the CREATE-ECLA trial, GIK infusion had no effect on 30-day mortality in 20,201 patients.To determine the association between GIK infusion therapy and 30-day and 6-month outcomes in patients with STEMI.Primary analysis of the OASIS-6 GIK randomized controlled trial of 2748 patients with acute STEMI; prespecified analyses of the combined trial data from the OASIS-6 GIK and CREATE-ECLA GIK trial populations of 22,943 patients with acute STEMI; subgroup analysis on the timing of initiation of GIK infusion therapy and outcomes; and post hoc analyses exploring whether GIK infusion may cause early harm by increasing glucose and potassium levels and net fluid gain.High-dose GIK solution consisting of 25% glucose, 50 U/L of regular insulin, and 80 mEq/L of potassium infused at 1.5 mL/kg per hour for 24 hours.Mortality rates at 30 days and 6 months in the OASIS-6 GIK trial and rates of death, heart failure, and the composite of death or heart failure at 3 and 30 days in the combined OASIS-6 GIK and CREATE-ECLA GIK trial populations.At 6 months, 148 (10.8%) GIK infusion patients and 143 (10.4%) control patients died in the OASIS-6 trial (hazard ratio [HR], 1.04; 95% CI, 0.83-1.31; P = .72); 153 (11.1%) GIK patients and 185 (13.5%) control patients had heart failure (HR, 0.83; 95% CI, 0.67-1.02; P = .08); and 240 (17.5%) GIK patients and 264 (19.2%) control patients had a composite of death or heart failure (HR, 0.91; 95% CI, 0.76-1.08; P = .27). In the prespecified analyses of the combined trial data, there were 712 deaths (6.2%) in the GIK group and 632 deaths (5.5%) in the control group at 3 days (HR, 1.13; 95% CI, 1.02-1.26; P = .03). This difference disappeared by 30 days, with 1108 deaths (9.7%) in the GIK group and 1068 (9.3%) in the control group (HR, 1.04; 95% CI, 0.96-1.13; P = .33). GIK therapy increased levels of glucose, potassium, and net fluid gain postinfusion, all 3 of which predicted death after adjusting for multiple confounders. Adjusting for glucose, potassium, and net fluid gain eliminated the apparent increase in mortality at 3 days observed with GIK infusion, suggesting a direct association with these factors. Administration of GIK infusion within 4 hours of symptom onset yielded no benefit compared with later initiation.Infusion of GIK provided no benefit and may cause early harm following STEMI. Avoidance of infusion-related hyperglycemia, hyperkalemia, and net fluid gain may be advisable in future studies of metabolic modulation in patients with STEMI.clinicaltrials.gov Identifier: NCT00064428.","Glucose-insulin-potassium therapy in patients with ST-segment elevation myocardial infarction."
"849","JAMA.3861","0.03",18042917,2007,"The clinical benefit of glucose-insulin-potassium (GIK) infusion in patients with ST-segment elevation myocardial infarction (STEMI) is unclear. While some smaller trials suggest benefit, in the CREATE-ECLA trial, GIK infusion had no effect on 30-day mortality in 20,201 patients.To determine the association between GIK infusion therapy and 30-day and 6-month outcomes in patients with STEMI.Primary analysis of the OASIS-6 GIK randomized controlled trial of 2748 patients with acute STEMI; prespecified analyses of the combined trial data from the OASIS-6 GIK and CREATE-ECLA GIK trial populations of 22,943 patients with acute STEMI; subgroup analysis on the timing of initiation of GIK infusion therapy and outcomes; and post hoc analyses exploring whether GIK infusion may cause early harm by increasing glucose and potassium levels and net fluid gain.High-dose GIK solution consisting of 25% glucose, 50 U/L of regular insulin, and 80 mEq/L of potassium infused at 1.5 mL/kg per hour for 24 hours.Mortality rates at 30 days and 6 months in the OASIS-6 GIK trial and rates of death, heart failure, and the composite of death or heart failure at 3 and 30 days in the combined OASIS-6 GIK and CREATE-ECLA GIK trial populations.At 6 months, 148 (10.8%) GIK infusion patients and 143 (10.4%) control patients died in the OASIS-6 trial (hazard ratio [HR], 1.04; 95% CI, 0.83-1.31; P = .72); 153 (11.1%) GIK patients and 185 (13.5%) control patients had heart failure (HR, 0.83; 95% CI, 0.67-1.02; P = .08); and 240 (17.5%) GIK patients and 264 (19.2%) control patients had a composite of death or heart failure (HR, 0.91; 95% CI, 0.76-1.08; P = .27). In the prespecified analyses of the combined trial data, there were 712 deaths (6.2%) in the GIK group and 632 deaths (5.5%) in the control group at 3 days (HR, 1.13; 95% CI, 1.02-1.26; P = .03). This difference disappeared by 30 days, with 1108 deaths (9.7%) in the GIK group and 1068 (9.3%) in the control group (HR, 1.04; 95% CI, 0.96-1.13; P = .33). GIK therapy increased levels of glucose, potassium, and net fluid gain postinfusion, all 3 of which predicted death after adjusting for multiple confounders. Adjusting for glucose, potassium, and net fluid gain eliminated the apparent increase in mortality at 3 days observed with GIK infusion, suggesting a direct association with these factors. Administration of GIK infusion within 4 hours of symptom onset yielded no benefit compared with later initiation.Infusion of GIK provided no benefit and may cause early harm following STEMI. Avoidance of infusion-related hyperglycemia, hyperkalemia, and net fluid gain may be advisable in future studies of metabolic modulation in patients with STEMI.clinicaltrials.gov Identifier: NCT00064428.","Glucose-insulin-potassium therapy in patients with ST-segment elevation myocardial infarction."
"850","JAMA.3871","0.33",18042917,2007,"The clinical benefit of glucose-insulin-potassium (GIK) infusion in patients with ST-segment elevation myocardial infarction (STEMI) is unclear. While some smaller trials suggest benefit, in the CREATE-ECLA trial, GIK infusion had no effect on 30-day mortality in 20,201 patients.To determine the association between GIK infusion therapy and 30-day and 6-month outcomes in patients with STEMI.Primary analysis of the OASIS-6 GIK randomized controlled trial of 2748 patients with acute STEMI; prespecified analyses of the combined trial data from the OASIS-6 GIK and CREATE-ECLA GIK trial populations of 22,943 patients with acute STEMI; subgroup analysis on the timing of initiation of GIK infusion therapy and outcomes; and post hoc analyses exploring whether GIK infusion may cause early harm by increasing glucose and potassium levels and net fluid gain.High-dose GIK solution consisting of 25% glucose, 50 U/L of regular insulin, and 80 mEq/L of potassium infused at 1.5 mL/kg per hour for 24 hours.Mortality rates at 30 days and 6 months in the OASIS-6 GIK trial and rates of death, heart failure, and the composite of death or heart failure at 3 and 30 days in the combined OASIS-6 GIK and CREATE-ECLA GIK trial populations.At 6 months, 148 (10.8%) GIK infusion patients and 143 (10.4%) control patients died in the OASIS-6 trial (hazard ratio [HR], 1.04; 95% CI, 0.83-1.31; P = .72); 153 (11.1%) GIK patients and 185 (13.5%) control patients had heart failure (HR, 0.83; 95% CI, 0.67-1.02; P = .08); and 240 (17.5%) GIK patients and 264 (19.2%) control patients had a composite of death or heart failure (HR, 0.91; 95% CI, 0.76-1.08; P = .27). In the prespecified analyses of the combined trial data, there were 712 deaths (6.2%) in the GIK group and 632 deaths (5.5%) in the control group at 3 days (HR, 1.13; 95% CI, 1.02-1.26; P = .03). This difference disappeared by 30 days, with 1108 deaths (9.7%) in the GIK group and 1068 (9.3%) in the control group (HR, 1.04; 95% CI, 0.96-1.13; P = .33). GIK therapy increased levels of glucose, potassium, and net fluid gain postinfusion, all 3 of which predicted death after adjusting for multiple confounders. Adjusting for glucose, potassium, and net fluid gain eliminated the apparent increase in mortality at 3 days observed with GIK infusion, suggesting a direct association with these factors. Administration of GIK infusion within 4 hours of symptom onset yielded no benefit compared with later initiation.Infusion of GIK provided no benefit and may cause early harm following STEMI. Avoidance of infusion-related hyperglycemia, hyperkalemia, and net fluid gain may be advisable in future studies of metabolic modulation in patients with STEMI.clinicaltrials.gov Identifier: NCT00064428.","Glucose-insulin-potassium therapy in patients with ST-segment elevation myocardial infarction."
"851","JAMA.3791","0.35",18056903,2007,"At 30-day follow-up, patients with moderate- and high-risk acute coronary syndromes (ACS) undergoing early invasive treatment in the ACUITY trial with bivalirudin monotherapy vs heparin plus glycoprotein (GP) IIb/IIIa inhibitors had noninferior rates of adverse ischemic events with reduced rates of major bleeding. Deferred upstream use of GP IIb/IIIa inhibitors for selective administration to patients undergoing percutaneous coronary intervention (PCI) resulted in a significant reduction in major bleeding, although a small increase in composite ischemia could not be excluded.To determine 1-year ischemic outcomes for patients in the ACUITY trial.A prospective, randomized, open-label trial with 1-year clinical follow-up at 450 academic and community-based institutions in 17 countries. A total of 13,819 patients with moderate- and high-risk ACS undergoing invasive treatment were enrolled between August 23, 2003, and December 5, 2005.Patients were assigned to heparin plus GP IIb/IIIa inhibitors (n = 4603), bivalirudin plus GP IIb/IIIa inhibitors (n = 4604), or bivalirudin monotherapy (n = 4612). Of these patients, 4605 were assigned to routine upstream GP IIb/IIIa administration and 4602 were deferred to selective GP IIb/IIIa inhibitor administration.Composite ischemia (death, myocardial infarction, or unplanned revascularization for ischemia) at 1 year.Composite ischemia at 1 year occurred in 15.4% of patients assigned to heparin plus GP IIb/IIIa inhibitors and 16.0% assigned to bivalirudin plus GP IIb/IIIa inhibitors (compared with heparin plus GP IIb/IIIa inhibitors, HR, 1.05; 95% CI, 0.95-1.16; P = .35), and 16.2% assigned to bivalirudin monotherapy (HR, 1.06; 95% CI, 0.95-1.17; P = .29). Mortality at 1 year occurred in an estimated 3.9% of patients assigned to heparin plus GP IIb/IIIa inhibitors, 3.9% assigned to bivalirudin plus GP IIb/IIIa inhibitors (HR, 0.99; 95% CI, 0.80-1.22; P = .92), and 3.8% assigned to bivalirudin monotherapy (HR, 0.96; 95% CI, 0.77-1.18; P = .67). Composite ischemia occurred in 16.3% of patients assigned to deferred use compared with 15.2% of patients assigned to upstream administration (HR, 1.08; 95% CI, 0.97-1.20; P = .15).At 1 year, no statistically significant difference in rates of composite ischemia or mortality among patients with moderate- and high-risk ACS undergoing invasive treatment with the 3 therapies was found. There was no statistically significant difference in the rates of composite ischemia between patients receiving routine upstream administration of GP IIb/IIIa inhibitors vs deferring their use for patients undergoing PCI.clinicaltrials.gov Identifier: NCT00093158.","Antithrombotic strategies in patients with acute coronary syndromes undergoing early invasive management: one-year results from the ACUITY trial."
"852","JAMA.3801","0.29",18056903,2007,"At 30-day follow-up, patients with moderate- and high-risk acute coronary syndromes (ACS) undergoing early invasive treatment in the ACUITY trial with bivalirudin monotherapy vs heparin plus glycoprotein (GP) IIb/IIIa inhibitors had noninferior rates of adverse ischemic events with reduced rates of major bleeding. Deferred upstream use of GP IIb/IIIa inhibitors for selective administration to patients undergoing percutaneous coronary intervention (PCI) resulted in a significant reduction in major bleeding, although a small increase in composite ischemia could not be excluded.To determine 1-year ischemic outcomes for patients in the ACUITY trial.A prospective, randomized, open-label trial with 1-year clinical follow-up at 450 academic and community-based institutions in 17 countries. A total of 13,819 patients with moderate- and high-risk ACS undergoing invasive treatment were enrolled between August 23, 2003, and December 5, 2005.Patients were assigned to heparin plus GP IIb/IIIa inhibitors (n = 4603), bivalirudin plus GP IIb/IIIa inhibitors (n = 4604), or bivalirudin monotherapy (n = 4612). Of these patients, 4605 were assigned to routine upstream GP IIb/IIIa administration and 4602 were deferred to selective GP IIb/IIIa inhibitor administration.Composite ischemia (death, myocardial infarction, or unplanned revascularization for ischemia) at 1 year.Composite ischemia at 1 year occurred in 15.4% of patients assigned to heparin plus GP IIb/IIIa inhibitors and 16.0% assigned to bivalirudin plus GP IIb/IIIa inhibitors (compared with heparin plus GP IIb/IIIa inhibitors, HR, 1.05; 95% CI, 0.95-1.16; P = .35), and 16.2% assigned to bivalirudin monotherapy (HR, 1.06; 95% CI, 0.95-1.17; P = .29). Mortality at 1 year occurred in an estimated 3.9% of patients assigned to heparin plus GP IIb/IIIa inhibitors, 3.9% assigned to bivalirudin plus GP IIb/IIIa inhibitors (HR, 0.99; 95% CI, 0.80-1.22; P = .92), and 3.8% assigned to bivalirudin monotherapy (HR, 0.96; 95% CI, 0.77-1.18; P = .67). Composite ischemia occurred in 16.3% of patients assigned to deferred use compared with 15.2% of patients assigned to upstream administration (HR, 1.08; 95% CI, 0.97-1.20; P = .15).At 1 year, no statistically significant difference in rates of composite ischemia or mortality among patients with moderate- and high-risk ACS undergoing invasive treatment with the 3 therapies was found. There was no statistically significant difference in the rates of composite ischemia between patients receiving routine upstream administration of GP IIb/IIIa inhibitors vs deferring their use for patients undergoing PCI.clinicaltrials.gov Identifier: NCT00093158.","Antithrombotic strategies in patients with acute coronary syndromes undergoing early invasive management: one-year results from the ACUITY trial."
"853","JAMA.3811","0.92",18056903,2007,"At 30-day follow-up, patients with moderate- and high-risk acute coronary syndromes (ACS) undergoing early invasive treatment in the ACUITY trial with bivalirudin monotherapy vs heparin plus glycoprotein (GP) IIb/IIIa inhibitors had noninferior rates of adverse ischemic events with reduced rates of major bleeding. Deferred upstream use of GP IIb/IIIa inhibitors for selective administration to patients undergoing percutaneous coronary intervention (PCI) resulted in a significant reduction in major bleeding, although a small increase in composite ischemia could not be excluded.To determine 1-year ischemic outcomes for patients in the ACUITY trial.A prospective, randomized, open-label trial with 1-year clinical follow-up at 450 academic and community-based institutions in 17 countries. A total of 13,819 patients with moderate- and high-risk ACS undergoing invasive treatment were enrolled between August 23, 2003, and December 5, 2005.Patients were assigned to heparin plus GP IIb/IIIa inhibitors (n = 4603), bivalirudin plus GP IIb/IIIa inhibitors (n = 4604), or bivalirudin monotherapy (n = 4612). Of these patients, 4605 were assigned to routine upstream GP IIb/IIIa administration and 4602 were deferred to selective GP IIb/IIIa inhibitor administration.Composite ischemia (death, myocardial infarction, or unplanned revascularization for ischemia) at 1 year.Composite ischemia at 1 year occurred in 15.4% of patients assigned to heparin plus GP IIb/IIIa inhibitors and 16.0% assigned to bivalirudin plus GP IIb/IIIa inhibitors (compared with heparin plus GP IIb/IIIa inhibitors, HR, 1.05; 95% CI, 0.95-1.16; P = .35), and 16.2% assigned to bivalirudin monotherapy (HR, 1.06; 95% CI, 0.95-1.17; P = .29). Mortality at 1 year occurred in an estimated 3.9% of patients assigned to heparin plus GP IIb/IIIa inhibitors, 3.9% assigned to bivalirudin plus GP IIb/IIIa inhibitors (HR, 0.99; 95% CI, 0.80-1.22; P = .92), and 3.8% assigned to bivalirudin monotherapy (HR, 0.96; 95% CI, 0.77-1.18; P = .67). Composite ischemia occurred in 16.3% of patients assigned to deferred use compared with 15.2% of patients assigned to upstream administration (HR, 1.08; 95% CI, 0.97-1.20; P = .15).At 1 year, no statistically significant difference in rates of composite ischemia or mortality among patients with moderate- and high-risk ACS undergoing invasive treatment with the 3 therapies was found. There was no statistically significant difference in the rates of composite ischemia between patients receiving routine upstream administration of GP IIb/IIIa inhibitors vs deferring their use for patients undergoing PCI.clinicaltrials.gov Identifier: NCT00093158.","Antithrombotic strategies in patients with acute coronary syndromes undergoing early invasive management: one-year results from the ACUITY trial."
"854","JAMA.3821","0.67",18056903,2007,"At 30-day follow-up, patients with moderate- and high-risk acute coronary syndromes (ACS) undergoing early invasive treatment in the ACUITY trial with bivalirudin monotherapy vs heparin plus glycoprotein (GP) IIb/IIIa inhibitors had noninferior rates of adverse ischemic events with reduced rates of major bleeding. Deferred upstream use of GP IIb/IIIa inhibitors for selective administration to patients undergoing percutaneous coronary intervention (PCI) resulted in a significant reduction in major bleeding, although a small increase in composite ischemia could not be excluded.To determine 1-year ischemic outcomes for patients in the ACUITY trial.A prospective, randomized, open-label trial with 1-year clinical follow-up at 450 academic and community-based institutions in 17 countries. A total of 13,819 patients with moderate- and high-risk ACS undergoing invasive treatment were enrolled between August 23, 2003, and December 5, 2005.Patients were assigned to heparin plus GP IIb/IIIa inhibitors (n = 4603), bivalirudin plus GP IIb/IIIa inhibitors (n = 4604), or bivalirudin monotherapy (n = 4612). Of these patients, 4605 were assigned to routine upstream GP IIb/IIIa administration and 4602 were deferred to selective GP IIb/IIIa inhibitor administration.Composite ischemia (death, myocardial infarction, or unplanned revascularization for ischemia) at 1 year.Composite ischemia at 1 year occurred in 15.4% of patients assigned to heparin plus GP IIb/IIIa inhibitors and 16.0% assigned to bivalirudin plus GP IIb/IIIa inhibitors (compared with heparin plus GP IIb/IIIa inhibitors, HR, 1.05; 95% CI, 0.95-1.16; P = .35), and 16.2% assigned to bivalirudin monotherapy (HR, 1.06; 95% CI, 0.95-1.17; P = .29). Mortality at 1 year occurred in an estimated 3.9% of patients assigned to heparin plus GP IIb/IIIa inhibitors, 3.9% assigned to bivalirudin plus GP IIb/IIIa inhibitors (HR, 0.99; 95% CI, 0.80-1.22; P = .92), and 3.8% assigned to bivalirudin monotherapy (HR, 0.96; 95% CI, 0.77-1.18; P = .67). Composite ischemia occurred in 16.3% of patients assigned to deferred use compared with 15.2% of patients assigned to upstream administration (HR, 1.08; 95% CI, 0.97-1.20; P = .15).At 1 year, no statistically significant difference in rates of composite ischemia or mortality among patients with moderate- and high-risk ACS undergoing invasive treatment with the 3 therapies was found. There was no statistically significant difference in the rates of composite ischemia between patients receiving routine upstream administration of GP IIb/IIIa inhibitors vs deferring their use for patients undergoing PCI.clinicaltrials.gov Identifier: NCT00093158.","Antithrombotic strategies in patients with acute coronary syndromes undergoing early invasive management: one-year results from the ACUITY trial."
"855","JAMA.3831","0.15",18056903,2007,"At 30-day follow-up, patients with moderate- and high-risk acute coronary syndromes (ACS) undergoing early invasive treatment in the ACUITY trial with bivalirudin monotherapy vs heparin plus glycoprotein (GP) IIb/IIIa inhibitors had noninferior rates of adverse ischemic events with reduced rates of major bleeding. Deferred upstream use of GP IIb/IIIa inhibitors for selective administration to patients undergoing percutaneous coronary intervention (PCI) resulted in a significant reduction in major bleeding, although a small increase in composite ischemia could not be excluded.To determine 1-year ischemic outcomes for patients in the ACUITY trial.A prospective, randomized, open-label trial with 1-year clinical follow-up at 450 academic and community-based institutions in 17 countries. A total of 13,819 patients with moderate- and high-risk ACS undergoing invasive treatment were enrolled between August 23, 2003, and December 5, 2005.Patients were assigned to heparin plus GP IIb/IIIa inhibitors (n = 4603), bivalirudin plus GP IIb/IIIa inhibitors (n = 4604), or bivalirudin monotherapy (n = 4612). Of these patients, 4605 were assigned to routine upstream GP IIb/IIIa administration and 4602 were deferred to selective GP IIb/IIIa inhibitor administration.Composite ischemia (death, myocardial infarction, or unplanned revascularization for ischemia) at 1 year.Composite ischemia at 1 year occurred in 15.4% of patients assigned to heparin plus GP IIb/IIIa inhibitors and 16.0% assigned to bivalirudin plus GP IIb/IIIa inhibitors (compared with heparin plus GP IIb/IIIa inhibitors, HR, 1.05; 95% CI, 0.95-1.16; P = .35), and 16.2% assigned to bivalirudin monotherapy (HR, 1.06; 95% CI, 0.95-1.17; P = .29). Mortality at 1 year occurred in an estimated 3.9% of patients assigned to heparin plus GP IIb/IIIa inhibitors, 3.9% assigned to bivalirudin plus GP IIb/IIIa inhibitors (HR, 0.99; 95% CI, 0.80-1.22; P = .92), and 3.8% assigned to bivalirudin monotherapy (HR, 0.96; 95% CI, 0.77-1.18; P = .67). Composite ischemia occurred in 16.3% of patients assigned to deferred use compared with 15.2% of patients assigned to upstream administration (HR, 1.08; 95% CI, 0.97-1.20; P = .15).At 1 year, no statistically significant difference in rates of composite ischemia or mortality among patients with moderate- and high-risk ACS undergoing invasive treatment with the 3 therapies was found. There was no statistically significant difference in the rates of composite ischemia between patients receiving routine upstream administration of GP IIb/IIIa inhibitors vs deferring their use for patients undergoing PCI.clinicaltrials.gov Identifier: NCT00093158.","Antithrombotic strategies in patients with acute coronary syndromes undergoing early invasive management: one-year results from the ACUITY trial."
"856","Lancet.691","1.00E-04",18156031,2007,"Vascular endothelial growth factor (VEGF) inhibition is a valid therapeutic approach in renal cell carcinoma. Therefore, an investigation of the combination treatment of the humanised anti-VEGF monoclonal antibody bevacizumab with interferon alfa was warranted.In a multicentre, randomised, double-blind, phase III trial, 649 patients with previously untreated metastatic renal cell carcinoma were randomised to receive interferon alfa-2a (9 MIU subcutaneously three times weekly) and bevacizumab (10 mg/kg every 2 weeks; n=327) or placebo and interferon alfa-2a (n=322). The primary endpoint was overall survival. Secondary endpoints included progression-free survival and safety. An interim analysis of overall survival was prespecified after 250 deaths. On the basis of new second-line therapies that became available while the trial was in progress, which could have confounded analyses of overall survival data, we agreed with regulatory agencies that the pre-planned final analysis of progression-free survival would be acceptable for regulatory submission. The protocol was amended to allow the study to be unblinded at this point. The final analysis of progression-free survival is reported here. Efficacy analyses were done by intention to treat. This trial is registered with centerwatch.com, number BO17705E.325 patients in the bevacizumab plus interferon alfa group and 316 in the placebo plus interferon alfa group received at least one dose of study treatment. At the time of unblinding, 230 progression events had occurred in the bevacizumab plus interferon alfa group and 275 in the control group; there were 114 deaths in the bevacizumab plus interferon alfa group and 137 in the control group. Median duration of progression-free survival was significantly longer in the bevacizumab plus interferon alfa group than it was in the control group (10.2 months vs 5.4 months; HR 0.63, 95% CI 0.52-0.75; p=0.0001). Increases in progression-free survival were seen with bevacizumab plus interferon alfa irrespective of risk group or whether reduced-dose interferon alfa was received. Deaths due to adverse events were reported in eight (2%) patients who received one or more doses of bevacizumab and seven (2%) of those who did not receive the drug. Only three deaths in the bevacizumab arm were considered by investigators to be possibly related to bevacizumab. The most commonly reported grade 3 or worse adverse events were fatigue (40 [12%] patients in the bevacizumab group vs 25 [8%] in the control group) and asthenia (34 [10%] vs 20 [7%]).The combination of bevacizumab with interferon alfa as first-line treatment in patients with metastatic renal cell carcinoma results in a significant improvement in progression-free survival, compared with interferon alfa alone.","Bevacizumab plus interferon alfa-2a for treatment of metastatic renal cell carcinoma: a randomised, double-blind phase III trial."
"857","Lancet.1601","0.01",18191684,2008,"Approaches to removal of sedation and mechanical ventilation for critically ill patients vary widely. Our aim was to assess a protocol that paired spontaneous awakening trials (SATs)-ie, daily interruption of sedatives-with spontaneous breathing trials (SBTs).In four tertiary-care hospitals, we randomly assigned 336 mechanically ventilated patients in intensive care to management with a daily SAT followed by an SBT (intervention group; n=168) or with sedation per usual care plus a daily SBT (control group; n=168). The primary endpoint was time breathing without assistance. Data were analysed by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00097630.One patient in the intervention group did not begin their assigned treatment protocol because of withdrawal of consent and thus was excluded from analyses and lost to follow-up. Seven patients in the control group discontinued their assigned protocol, and two of these patients were lost to follow-up. Patients in the intervention group spent more days breathing without assistance during the 28-day study period than did those in the control group (14.7 days vs 11.6 days; mean difference 3.1 days, 95% CI 0.7 to 5.6; p=0.02) and were discharged from intensive care (median time in intensive care 9.1 days vs 12.9 days; p=0.01) and the hospital earlier (median time in the hospital 14.9 days vs 19.2 days; p=0.04). More patients in the intervention group self-extubated than in the control group (16 patients vs six patients; 6.0% difference, 95% CI 0.6% to 11.8%; p=0.03), but the number of patients who required reintubation after self-extubation was similar (five patients vs three patients; 1.2% difference, 95% CI -5.2% to 2.5%; p=0.47), as were total reintubation rates (13.8%vs 12.5%; 1.3% difference, 95% CI -8.6% to 6.1%; p=0.73). At any instant during the year after enrolment, patients in the intervention group were less likely to die than were patients in the control group (HR 0.68, 95% CI 0.50 to 0.92; p=0.01). For every seven patients treated with the intervention, one life was saved (number needed to treat was 7.4, 95% CI 4.2 to 35.5).Our results suggest that a wake up and breathe protocol that pairs daily spontaneous awakening trials (ie, interruption of sedatives) with daily spontaneous breathing trials results in better outcomes for mechanically ventilated patients in intensive care than current standard approaches and should become routine practice.","Efficacy and safety of a paired sedation and ventilator weaning protocol for mechanically ventilated patients in intensive care (Awakening and Breathing Controlled trial): a randomised controlled trial."
"858","JAMA.4441","0.001",18212313,2008,"Comorbidities may increase the negative effects of specific anticancer treatments such as androgen suppression therapy (AST).To compare 6 months of AST and radiation therapy (RT) to RT alone and to assess the interaction between level of comorbidity and all-cause mortality.At academic and community-based medical centers in Massachusetts, between December 1, 1995, and April 15, 2001, 206 men with localized but unfavorable-risk prostate cancer were randomized to receive RT alone or RT and AST combined. All-cause mortality estimates stratified by randomized treatment group and further stratified in a postrandomization analysis by the Adult Comorbidity Evaluation 27 comorbidity score were compared using a log-rank test.Time to all-cause mortality.As of January 15, 2007, with a median follow-up of 7.6 (range, 0.5-11.0) years, 74 deaths have occurred. A significant increase in the risk of all-cause mortality (44 vs 30 deaths; hazard ratio [HR], 1.8; 95% confidence interval [CI], 1.1-2.9; P = .01) was observed in men randomized to RT compared with RT and AST. However, the increased risk in all-cause mortality appeared to apply only to men randomized to RT with no or minimal comorbidity (31 vs 11 deaths; HR, 4.2; 95% CI, 2.1-8.5; P < .001). Among men with moderate or severe comorbidity, those randomized to RT alone vs RT and AST did not have an increased risk of all-cause mortality (13 vs 19 deaths; HR, 0.54; 95% CI, 0.27-1.10; P = .08).The addition of 6 months of AST to RT resulted in increased overall survival in men with localized but unfavorable-risk prostate cancer. This result may pertain only to men without moderate or severe comorbidity, but this requires further assessment in a clinical trial specifically designed to assess this interaction.clinicaltrials.gov Identifier: NCT00116220.","Androgen suppression and radiation vs radiation alone for prostate cancer: a randomized trial."
"859","JAMA.4901","0.01",18212313,2008,"Comorbidities may increase the negative effects of specific anticancer treatments such as androgen suppression therapy (AST).To compare 6 months of AST and radiation therapy (RT) to RT alone and to assess the interaction between level of comorbidity and all-cause mortality.At academic and community-based medical centers in Massachusetts, between December 1, 1995, and April 15, 2001, 206 men with localized but unfavorable-risk prostate cancer were randomized to receive RT alone or RT and AST combined. All-cause mortality estimates stratified by randomized treatment group and further stratified in a postrandomization analysis by the Adult Comorbidity Evaluation 27 comorbidity score were compared using a log-rank test.Time to all-cause mortality.As of January 15, 2007, with a median follow-up of 7.6 (range, 0.5-11.0) years, 74 deaths have occurred. A significant increase in the risk of all-cause mortality (44 vs 30 deaths; hazard ratio [HR], 1.8; 95% confidence interval [CI], 1.1-2.9; P = .01) was observed in men randomized to RT compared with RT and AST. However, the increased risk in all-cause mortality appeared to apply only to men randomized to RT with no or minimal comorbidity (31 vs 11 deaths; HR, 4.2; 95% CI, 2.1-8.5; P < .001). Among men with moderate or severe comorbidity, those randomized to RT alone vs RT and AST did not have an increased risk of all-cause mortality (13 vs 19 deaths; HR, 0.54; 95% CI, 0.27-1.10; P = .08).The addition of 6 months of AST to RT resulted in increased overall survival in men with localized but unfavorable-risk prostate cancer. This result may pertain only to men without moderate or severe comorbidity, but this requires further assessment in a clinical trial specifically designed to assess this interaction.clinicaltrials.gov Identifier: NCT00116220.","Androgen suppression and radiation vs radiation alone for prostate cancer: a randomized trial."
"860","JAMA.4911","0.08",18212313,2008,"Comorbidities may increase the negative effects of specific anticancer treatments such as androgen suppression therapy (AST).To compare 6 months of AST and radiation therapy (RT) to RT alone and to assess the interaction between level of comorbidity and all-cause mortality.At academic and community-based medical centers in Massachusetts, between December 1, 1995, and April 15, 2001, 206 men with localized but unfavorable-risk prostate cancer were randomized to receive RT alone or RT and AST combined. All-cause mortality estimates stratified by randomized treatment group and further stratified in a postrandomization analysis by the Adult Comorbidity Evaluation 27 comorbidity score were compared using a log-rank test.Time to all-cause mortality.As of January 15, 2007, with a median follow-up of 7.6 (range, 0.5-11.0) years, 74 deaths have occurred. A significant increase in the risk of all-cause mortality (44 vs 30 deaths; hazard ratio [HR], 1.8; 95% confidence interval [CI], 1.1-2.9; P = .01) was observed in men randomized to RT compared with RT and AST. However, the increased risk in all-cause mortality appeared to apply only to men randomized to RT with no or minimal comorbidity (31 vs 11 deaths; HR, 4.2; 95% CI, 2.1-8.5; P < .001). Among men with moderate or severe comorbidity, those randomized to RT alone vs RT and AST did not have an increased risk of all-cause mortality (13 vs 19 deaths; HR, 0.54; 95% CI, 0.27-1.10; P = .08).The addition of 6 months of AST to RT resulted in increased overall survival in men with localized but unfavorable-risk prostate cancer. This result may pertain only to men without moderate or severe comorbidity, but this requires further assessment in a clinical trial specifically designed to assess this interaction.clinicaltrials.gov Identifier: NCT00116220.","Androgen suppression and radiation vs radiation alone for prostate cancer: a randomized trial."
"861","JAMA.481","0.01",18212315,2008,"Maintaining independence of older persons is a public health priority, and identifying the factors that contribute to decline in physical function is needed to prevent or postpone the disablement process. The potential deleterious effect of poor nutrition on decline in physical function in older persons is unclear.To determine whether a low serum concentration of micronutrients is associated with subsequent decline in physical function among older men and women living in the community.Longitudinal study of 698 community-living persons 65 years or older who were randomly selected from a population registry in Tuscany, Italy. Participants completed the baseline examination from November 1, 1998, through May 28, 2000, and the 3-year follow-up assessments from November 1, 2001, through March 30, 2003.Decline in physical function was defined as a loss of at least 1 point in the Short Physical Performance Battery during the 3-year follow-up. Odds ratios (ORs) were calculated for the lowest quartile of each nutrient using the other 3 quartiles combined as the reference group. Two additional and complementary analytical approaches were used to confirm the validity of the results.The mean decline in the Short Physical Performance Battery score was 1.1 point. In a logistic regression analysis that was adjusted for potential confounders, only a low concentration of vitamin E (<1.1 microg/mL [<24.9 micromol/L]) was significantly associated with subsequent decline in physical function (OR, 1.62; 95% confidence interval, 1.11-2.36; P = .01 for association of lowest alpha-tocopherol quartile with at least a 1-point decline in physical function). In a general linear model, the concentration of vitamin E at baseline, when analyzed as a continuous measure, was significantly associated with the Short Physical Performance Battery score at follow-up after adjustment for potential confounders and Short Physical Performance Battery score at baseline (beta = .023; P = .01). In a classification and regression tree analysis, age older than 81 years and vitamin E (in participants aged 70-80 years) were identified as the strongest determinants of decline in physical function (physical decline in 84% and 60%, respectively; misclassification error rate, 0.33).These results provide empirical evidence that a low serum concentration of vitamin E is associated with subsequent decline in physical function among community-living older adults. Clinical trials may be warranted to determine whether an optimal concentration of vitamin E reduces functional decline and the onset of disability in older persons.","Serum micronutrient concentrations and decline in physical function among older persons."
"862","Lancet.109","0.162",18262039,2008,"Aprotinin is used during cardiac surgery for its blood-saving effects. However, reports suggest a possible association between use of this drug and increased renal dysfunction and mortality. We investigated the effect of aprotinin on renal dysfunction in cardiac surgery, considering the cofactors on-pump versus off-pump surgery and co-medication with angiotensin-converting enzyme (ACE) inhibitors.Our analysis included 9875 patients undergoing on-pump or off-pump cardiac surgery from Jan 1, 2000, to Sept 30, 2007. Of these patients, 9106 were included in the retrospective observational study analysis. With propensity-adjusted, multivariate staged logistic regression, we analysed separately the incidence of renal dysfunction in patients receiving aprotinin, tranexamic acid, or no antifibrinolytic treatment in the presence or absence of preoperative ACE inhibitor treatment, for both on-pump and off-pump surgical techniques.In 5434 patients undergoing on-pump cardiac surgery, the odds ratio (OR) between aprotinin and an increased risk of renal dysfunction without ACE inhibitor was 1.81 (95% CI 0.79-4.13, p=0.162) and with ACE inhibitor 1.73 (0.56-5.32, p=0.342). In the 848 patients taking ACE inhibitors and undergoing off-pump cardiac surgery, aprotinin was associated with a greater than two-fold increase in the risk of renal dysfunction after off-pump cardiac surgery (OR 2.87 [1.25-6.58], p=0.013).Our results have shown that aprotinin seems to be safe during on-pump cardiac surgery. However, the combination of aprotinin and ACE inhibitors during off-pump cardiac surgery is associated with a significant risk of postoperative renal dysfunction.","Effect of aprotinin on renal dysfunction in patients undergoing on-pump and off-pump cardiac surgery: a retrospective observational study."
"863","Lancet.110","0.342",18262039,2008,"Aprotinin is used during cardiac surgery for its blood-saving effects. However, reports suggest a possible association between use of this drug and increased renal dysfunction and mortality. We investigated the effect of aprotinin on renal dysfunction in cardiac surgery, considering the cofactors on-pump versus off-pump surgery and co-medication with angiotensin-converting enzyme (ACE) inhibitors.Our analysis included 9875 patients undergoing on-pump or off-pump cardiac surgery from Jan 1, 2000, to Sept 30, 2007. Of these patients, 9106 were included in the retrospective observational study analysis. With propensity-adjusted, multivariate staged logistic regression, we analysed separately the incidence of renal dysfunction in patients receiving aprotinin, tranexamic acid, or no antifibrinolytic treatment in the presence or absence of preoperative ACE inhibitor treatment, for both on-pump and off-pump surgical techniques.In 5434 patients undergoing on-pump cardiac surgery, the odds ratio (OR) between aprotinin and an increased risk of renal dysfunction without ACE inhibitor was 1.81 (95% CI 0.79-4.13, p=0.162) and with ACE inhibitor 1.73 (0.56-5.32, p=0.342). In the 848 patients taking ACE inhibitors and undergoing off-pump cardiac surgery, aprotinin was associated with a greater than two-fold increase in the risk of renal dysfunction after off-pump cardiac surgery (OR 2.87 [1.25-6.58], p=0.013).Our results have shown that aprotinin seems to be safe during on-pump cardiac surgery. However, the combination of aprotinin and ACE inhibitors during off-pump cardiac surgery is associated with a significant risk of postoperative renal dysfunction.","Effect of aprotinin on renal dysfunction in patients undergoing on-pump and off-pump cardiac surgery: a retrospective observational study."
"864","Lancet.111","0.013",18262039,2008,"Aprotinin is used during cardiac surgery for its blood-saving effects. However, reports suggest a possible association between use of this drug and increased renal dysfunction and mortality. We investigated the effect of aprotinin on renal dysfunction in cardiac surgery, considering the cofactors on-pump versus off-pump surgery and co-medication with angiotensin-converting enzyme (ACE) inhibitors.Our analysis included 9875 patients undergoing on-pump or off-pump cardiac surgery from Jan 1, 2000, to Sept 30, 2007. Of these patients, 9106 were included in the retrospective observational study analysis. With propensity-adjusted, multivariate staged logistic regression, we analysed separately the incidence of renal dysfunction in patients receiving aprotinin, tranexamic acid, or no antifibrinolytic treatment in the presence or absence of preoperative ACE inhibitor treatment, for both on-pump and off-pump surgical techniques.In 5434 patients undergoing on-pump cardiac surgery, the odds ratio (OR) between aprotinin and an increased risk of renal dysfunction without ACE inhibitor was 1.81 (95% CI 0.79-4.13, p=0.162) and with ACE inhibitor 1.73 (0.56-5.32, p=0.342). In the 848 patients taking ACE inhibitors and undergoing off-pump cardiac surgery, aprotinin was associated with a greater than two-fold increase in the risk of renal dysfunction after off-pump cardiac surgery (OR 2.87 [1.25-6.58], p=0.013).Our results have shown that aprotinin seems to be safe during on-pump cardiac surgery. However, the combination of aprotinin and ACE inhibitors during off-pump cardiac surgery is associated with a significant risk of postoperative renal dysfunction.","Effect of aprotinin on renal dysfunction in patients undergoing on-pump and off-pump cardiac surgery: a retrospective observational study."
"865","Lancet.79","1.00E-04",18342686,2008,"The Heart of Soweto Study aims to increase our understanding of the characteristics and burden imposed by heart disease in an urban African community in probable epidemiological transition. We aimed to investigate the clinical range of disorders related to cardiovascular disease in patients presenting for the first time to a tertiary-care centre.From Jan 1 to Dec 31, 2006, we recorded data for 4162 patients with confirmed cases of cardiovascular disease (1593 newly diagnosed and 2569 previously diagnosed and under treatment) who attended the cardiology unit at the Chris Hani Baragwanath Hospital in Soweto, South Africa. We developed a prospectively designed registry and gathered detailed clinical data relating to the presentation, investigations, and treatment of all 1593 patients with newly diagnosed cardiovascular disease.Most patients were black Africans (n=1359 [85%]), and the study population contained more women (n=939 [59%]) than men. Women were slightly younger than were men (mean 53 [SD 16] years vs 55 [15] years; p=0.031), with 399 (25%) patients younger than 40 years. Heart failure was the most common primary diagnosis (704 cases, 44% of total). Moderate to severe systolic dysfunction was evident in 415 (53%) of 844 identified cases of heart failure, 577 (68%) of which were attributable to dilated cardiomyopathy or hypertensive heart disease, or both. Black Africans were more likely to be diagnosed with heart failure than were the rest of the cohort (739 [54%] vs 105 [45%]; odds ratio [OR] 1.46, 95% CI 1.11-1.94; p=0.009) but were less likely to be diagnosed with coronary artery disease (77 [6%] vs 88 [38%]; OR 0.10, 0.07-0.14; p<0.0001). Prevalence of cardiovascular risk factors was very high, with 897 (56%) patients diagnosed with hypertension (190 [44%] of whom were also obese). Only 209 (13%) patients had no identifiable risk factors, whereas 933 (59%) had several risk factors.We noted many threats to the present and future cardiac health of Soweto, including a high prevalence of modifiable risk factors for atherosclerotic disease and a combination of infectious and non-communicable forms of heart disease, with late clinical presentations. Overall, our findings provide strong evidence that epidemiological transition in Soweto, South Africa has broadened the complexity and spectrum of heart disease in this community. This registry will enable continued monitoring of the range of heart disease.","Spectrum of heart disease and risk factors in a black urban population in South Africa (the Heart of Soweto Study): a cohort study."
"866","Lancet.108","0.009",18342686,2008,"The Heart of Soweto Study aims to increase our understanding of the characteristics and burden imposed by heart disease in an urban African community in probable epidemiological transition. We aimed to investigate the clinical range of disorders related to cardiovascular disease in patients presenting for the first time to a tertiary-care centre.From Jan 1 to Dec 31, 2006, we recorded data for 4162 patients with confirmed cases of cardiovascular disease (1593 newly diagnosed and 2569 previously diagnosed and under treatment) who attended the cardiology unit at the Chris Hani Baragwanath Hospital in Soweto, South Africa. We developed a prospectively designed registry and gathered detailed clinical data relating to the presentation, investigations, and treatment of all 1593 patients with newly diagnosed cardiovascular disease.Most patients were black Africans (n=1359 [85%]), and the study population contained more women (n=939 [59%]) than men. Women were slightly younger than were men (mean 53 [SD 16] years vs 55 [15] years; p=0.031), with 399 (25%) patients younger than 40 years. Heart failure was the most common primary diagnosis (704 cases, 44% of total). Moderate to severe systolic dysfunction was evident in 415 (53%) of 844 identified cases of heart failure, 577 (68%) of which were attributable to dilated cardiomyopathy or hypertensive heart disease, or both. Black Africans were more likely to be diagnosed with heart failure than were the rest of the cohort (739 [54%] vs 105 [45%]; odds ratio [OR] 1.46, 95% CI 1.11-1.94; p=0.009) but were less likely to be diagnosed with coronary artery disease (77 [6%] vs 88 [38%]; OR 0.10, 0.07-0.14; p<0.0001). Prevalence of cardiovascular risk factors was very high, with 897 (56%) patients diagnosed with hypertension (190 [44%] of whom were also obese). Only 209 (13%) patients had no identifiable risk factors, whereas 933 (59%) had several risk factors.We noted many threats to the present and future cardiac health of Soweto, including a high prevalence of modifiable risk factors for atherosclerotic disease and a combination of infectious and non-communicable forms of heart disease, with late clinical presentations. Overall, our findings provide strong evidence that epidemiological transition in Soweto, South Africa has broadened the complexity and spectrum of heart disease in this community. This registry will enable continued monitoring of the range of heart disease.","Spectrum of heart disease and risk factors in a black urban population in South Africa (the Heart of Soweto Study): a cohort study."
"867","Lancet.1551","0.058",18358928,2008,"Surgical resection alone is regarded as the standard of care for patients with liver metastases from colorectal cancer, but relapse is common. We assessed the combination of perioperative chemotherapy and surgery compared with surgery alone for patients with initially resectable liver metastases from colorectal cancer.This parallel-group study reports the trial's final data for progression-free survival for a protocol unspecified interim time-point, while overall survival is still being monitored. 364 patients with histologically proven colorectal cancer and up to four liver metastases were randomly assigned to either six cycles of FOLFOX4 before and six cycles after surgery or to surgery alone (182 in perioperative chemotherapy group vs 182 in surgery group). Patients were centrally randomised by minimisation, adjusting for centre and risk score. The primary objective was to detect a hazard ratio (HR) of 0.71 or less for progression-free survival. Primary analysis was by intention to treat. Analyses were repeated for all eligible (171 vs 171) and resected patients (151 vs 152). This trial is registered with ClinicalTrials.gov, number NCT00006479.In the perioperative chemotherapy group, 151 (83%) patients were resected after a median of six (range 1-6) preoperative cycles and 115 (63%) patients received a median six (1-8) postoperative cycles. 152 (84%) patients were resected in the surgery group. The absolute increase in rate of progression-free survival at 3 years was 7.3% (from 28.1% [95.66% CI 21.3-35.5] to 35.4% [28.1-42.7]; HR 0.79 [0.62-1.02]; p=0.058) in randomised patients; 8.1% (from 28.1% [21.2-36.6] to 36.2% [28.7-43.8]; HR 0.77 [0.60-1.00]; p=0.041) in eligible patients; and 9.2% (from 33.2% [25.3-41.2] to 42.4% [34.0-50.5]; HR 0.73 [0.55-0.97]; p=0.025) in patients undergoing resection. 139 patients died (64 in perioperative chemotherapy group vs 75 in surgery group). Reversible postoperative complications occurred more often after chemotherapy than after surgery (40/159 [25%] vs 27/170 [16%]; p=0.04). After surgery we recorded two deaths in the surgery alone group and one in the perioperative chemotherapy group.Perioperative chemotherapy with FOLFOX4 is compatible with major liver surgery and reduces the risk of events of progression-free survival in eligible and resected patients.","Perioperative chemotherapy with FOLFOX4 and surgery versus surgery alone for resectable liver metastases from colorectal cancer (EORTC Intergroup trial 40983): a randomised controlled trial."
"868","Lancet.1561","0.041",18358928,2008,"Surgical resection alone is regarded as the standard of care for patients with liver metastases from colorectal cancer, but relapse is common. We assessed the combination of perioperative chemotherapy and surgery compared with surgery alone for patients with initially resectable liver metastases from colorectal cancer.This parallel-group study reports the trial's final data for progression-free survival for a protocol unspecified interim time-point, while overall survival is still being monitored. 364 patients with histologically proven colorectal cancer and up to four liver metastases were randomly assigned to either six cycles of FOLFOX4 before and six cycles after surgery or to surgery alone (182 in perioperative chemotherapy group vs 182 in surgery group). Patients were centrally randomised by minimisation, adjusting for centre and risk score. The primary objective was to detect a hazard ratio (HR) of 0.71 or less for progression-free survival. Primary analysis was by intention to treat. Analyses were repeated for all eligible (171 vs 171) and resected patients (151 vs 152). This trial is registered with ClinicalTrials.gov, number NCT00006479.In the perioperative chemotherapy group, 151 (83%) patients were resected after a median of six (range 1-6) preoperative cycles and 115 (63%) patients received a median six (1-8) postoperative cycles. 152 (84%) patients were resected in the surgery group. The absolute increase in rate of progression-free survival at 3 years was 7.3% (from 28.1% [95.66% CI 21.3-35.5] to 35.4% [28.1-42.7]; HR 0.79 [0.62-1.02]; p=0.058) in randomised patients; 8.1% (from 28.1% [21.2-36.6] to 36.2% [28.7-43.8]; HR 0.77 [0.60-1.00]; p=0.041) in eligible patients; and 9.2% (from 33.2% [25.3-41.2] to 42.4% [34.0-50.5]; HR 0.73 [0.55-0.97]; p=0.025) in patients undergoing resection. 139 patients died (64 in perioperative chemotherapy group vs 75 in surgery group). Reversible postoperative complications occurred more often after chemotherapy than after surgery (40/159 [25%] vs 27/170 [16%]; p=0.04). After surgery we recorded two deaths in the surgery alone group and one in the perioperative chemotherapy group.Perioperative chemotherapy with FOLFOX4 is compatible with major liver surgery and reduces the risk of events of progression-free survival in eligible and resected patients.","Perioperative chemotherapy with FOLFOX4 and surgery versus surgery alone for resectable liver metastases from colorectal cancer (EORTC Intergroup trial 40983): a randomised controlled trial."
"869","Lancet.1571","0.025",18358928,2008,"Surgical resection alone is regarded as the standard of care for patients with liver metastases from colorectal cancer, but relapse is common. We assessed the combination of perioperative chemotherapy and surgery compared with surgery alone for patients with initially resectable liver metastases from colorectal cancer.This parallel-group study reports the trial's final data for progression-free survival for a protocol unspecified interim time-point, while overall survival is still being monitored. 364 patients with histologically proven colorectal cancer and up to four liver metastases were randomly assigned to either six cycles of FOLFOX4 before and six cycles after surgery or to surgery alone (182 in perioperative chemotherapy group vs 182 in surgery group). Patients were centrally randomised by minimisation, adjusting for centre and risk score. The primary objective was to detect a hazard ratio (HR) of 0.71 or less for progression-free survival. Primary analysis was by intention to treat. Analyses were repeated for all eligible (171 vs 171) and resected patients (151 vs 152). This trial is registered with ClinicalTrials.gov, number NCT00006479.In the perioperative chemotherapy group, 151 (83%) patients were resected after a median of six (range 1-6) preoperative cycles and 115 (63%) patients received a median six (1-8) postoperative cycles. 152 (84%) patients were resected in the surgery group. The absolute increase in rate of progression-free survival at 3 years was 7.3% (from 28.1% [95.66% CI 21.3-35.5] to 35.4% [28.1-42.7]; HR 0.79 [0.62-1.02]; p=0.058) in randomised patients; 8.1% (from 28.1% [21.2-36.6] to 36.2% [28.7-43.8]; HR 0.77 [0.60-1.00]; p=0.041) in eligible patients; and 9.2% (from 33.2% [25.3-41.2] to 42.4% [34.0-50.5]; HR 0.73 [0.55-0.97]; p=0.025) in patients undergoing resection. 139 patients died (64 in perioperative chemotherapy group vs 75 in surgery group). Reversible postoperative complications occurred more often after chemotherapy than after surgery (40/159 [25%] vs 27/170 [16%]; p=0.04). After surgery we recorded two deaths in the surgery alone group and one in the perioperative chemotherapy group.Perioperative chemotherapy with FOLFOX4 is compatible with major liver surgery and reduces the risk of events of progression-free survival in eligible and resected patients.","Perioperative chemotherapy with FOLFOX4 and surgery versus surgery alone for resectable liver metastases from colorectal cancer (EORTC Intergroup trial 40983): a randomised controlled trial."
"870","American Journal of Epidemiology.85","0.02",18367467,2008,"Between 1987 and 2005, the authors conducted a nested case-control study based on the Swedish Multi-Generation Register to investigate whether early life exposures, namely, maternal age at delivery and exposure to siblings, are associated with an increased risk of amyotrophic lateral sclerosis (ALS). The study comprised 768 ALS cases and five controls per case matched by birth year and gender. Odds ratios and their corresponding 95% confidence intervals for ALS were estimated by conditional logistic regression modeling. Low maternal age (< or =20 years) and high maternal age (> or =41 years) were both associated with higher risk of ALS (odds ratio (OR) = 1.5, 95% confidence interval (CI): 1.1, 2.0 and OR = 1.7, 95% CI: 1.1, 2.4, respectively). The relative risk of ALS increased slightly with increasing number of younger siblings (OR = 1.1, 95% CI: 1.0, 1.1; p = 0.02). Children whose first younger sibling was born after the age of 6 years had the greatest relative risk (OR = 1.8, 95% CI: 1.2, 2.7). Exposure to older siblings was not associated with the risk of ALS. Although the strength of the observed associations was modest, these results provided further support for the theory that early life exposures might contribute to the disease pathogenesis.","Maternal age, exposure to siblings, and risk of amyotrophic lateral sclerosis."
"871","Lancet.1121","1.00E-04",18377975,2008,"Intracoronary stenting can improve procedural success and reduce restenosis compared with balloon angioplasty in patients with acute coronary syndromes, but can also increase the rate of thrombotic complications including stent thrombosis. The TRITON-TIMI 38 trial has shown that prasugrel-a novel, potent thienopyridine-can reduce ischaemic events compared with standard clopidogrel therapy. We assessed the rate, outcomes, and prevention of ischaemic events in patients treated with prasugrel or clopidogrel with stents in the TRITON-TIMI 38 study.Patients with moderate-risk to high-risk acute coronary syndromes were included in our analysis if they had received at least one coronary stent at the time of the index procedure following randomisation in TRITON-TIMI 38, and were further subdivided by type of stent received. Patients were randomly assigned in a 1 to 1 fashion to receive a loading dose of study drug (prasugrel 60 mg or clopidogrel 300 mg) as soon as possible after randomisation, followed by daily maintenance therapy (prasugrel 10 mg or clopidogrel 75 mg). All patients were to receive aspirin therapy. Treatment was to be continued for a minimum of 6 months and a maximum of 15 months. Randomisation was not stratified by stents used or stent type. The primary endpoint was the composite of cardiovascular death, non-fatal myocardial infarction, or non-fatal stroke. Stent thrombosis was assessed using Academic Research Consortium definitions, and analysis was by intention to treat. TRITON-TIMI 38 is registered with ClinicalTrials.gov, number NCT00097591.12,844 patients received at least one coronary stent; 5743 received only drug-eluting stents, and 6461 received only bare-metal stents. Prasugrel compared with clopidogrel reduced the primary endpoint (9.7 vs 11.9%, HR 0.81, p=0.0001) in the stented cohort, in patients with only drug-eluting stents (9.0 vs 11.1%, HR 0.82, p=0.019), and in patients with only bare-metal stents (10.0 vs 12.2%, HR 0.80, p=0.003). Stent thrombosis was associated with death or myocardial infarction in 89% (186/210) of patients. Stent thrombosis was reduced with prasugrel overall (1.13 vs 2.35%, HR 0.48, p<0.0001), in patients with drug-eluting stents only (0.84 vs 2.31%, HR 0.36, p<0.0001), and in those with bare-metal stents only (1.27 vs 2.41%, HR 0.52, p=0.0009).Intensive antiplatelet therapy with prasugrel resulted in fewer ischaemic outcomes including stent thrombosis than with standard clopidogrel. These findings were statistically robust irrespective of stent type, and the data affirm the importance of intensive platelet inhibition in patients with intracoronary stents.","Intensive oral antiplatelet therapy for reduction of ischaemic events including stent thrombosis in patients with acute coronary syndromes treated with percutaneous coronary intervention and stenting in the TRITON-TIMI 38 trial: a subanalysis of a randomised trial."
"872","Lancet.1131","1.00E-04",18377975,2008,"Intracoronary stenting can improve procedural success and reduce restenosis compared with balloon angioplasty in patients with acute coronary syndromes, but can also increase the rate of thrombotic complications including stent thrombosis. The TRITON-TIMI 38 trial has shown that prasugrel-a novel, potent thienopyridine-can reduce ischaemic events compared with standard clopidogrel therapy. We assessed the rate, outcomes, and prevention of ischaemic events in patients treated with prasugrel or clopidogrel with stents in the TRITON-TIMI 38 study.Patients with moderate-risk to high-risk acute coronary syndromes were included in our analysis if they had received at least one coronary stent at the time of the index procedure following randomisation in TRITON-TIMI 38, and were further subdivided by type of stent received. Patients were randomly assigned in a 1 to 1 fashion to receive a loading dose of study drug (prasugrel 60 mg or clopidogrel 300 mg) as soon as possible after randomisation, followed by daily maintenance therapy (prasugrel 10 mg or clopidogrel 75 mg). All patients were to receive aspirin therapy. Treatment was to be continued for a minimum of 6 months and a maximum of 15 months. Randomisation was not stratified by stents used or stent type. The primary endpoint was the composite of cardiovascular death, non-fatal myocardial infarction, or non-fatal stroke. Stent thrombosis was assessed using Academic Research Consortium definitions, and analysis was by intention to treat. TRITON-TIMI 38 is registered with ClinicalTrials.gov, number NCT00097591.12,844 patients received at least one coronary stent; 5743 received only drug-eluting stents, and 6461 received only bare-metal stents. Prasugrel compared with clopidogrel reduced the primary endpoint (9.7 vs 11.9%, HR 0.81, p=0.0001) in the stented cohort, in patients with only drug-eluting stents (9.0 vs 11.1%, HR 0.82, p=0.019), and in patients with only bare-metal stents (10.0 vs 12.2%, HR 0.80, p=0.003). Stent thrombosis was associated with death or myocardial infarction in 89% (186/210) of patients. Stent thrombosis was reduced with prasugrel overall (1.13 vs 2.35%, HR 0.48, p<0.0001), in patients with drug-eluting stents only (0.84 vs 2.31%, HR 0.36, p<0.0001), and in those with bare-metal stents only (1.27 vs 2.41%, HR 0.52, p=0.0009).Intensive antiplatelet therapy with prasugrel resulted in fewer ischaemic outcomes including stent thrombosis than with standard clopidogrel. These findings were statistically robust irrespective of stent type, and the data affirm the importance of intensive platelet inhibition in patients with intracoronary stents.","Intensive oral antiplatelet therapy for reduction of ischaemic events including stent thrombosis in patients with acute coronary syndromes treated with percutaneous coronary intervention and stenting in the TRITON-TIMI 38 trial: a subanalysis of a randomised trial."
"873","Lancet.1511","1.00E-04",18377975,2008,"Intracoronary stenting can improve procedural success and reduce restenosis compared with balloon angioplasty in patients with acute coronary syndromes, but can also increase the rate of thrombotic complications including stent thrombosis. The TRITON-TIMI 38 trial has shown that prasugrel-a novel, potent thienopyridine-can reduce ischaemic events compared with standard clopidogrel therapy. We assessed the rate, outcomes, and prevention of ischaemic events in patients treated with prasugrel or clopidogrel with stents in the TRITON-TIMI 38 study.Patients with moderate-risk to high-risk acute coronary syndromes were included in our analysis if they had received at least one coronary stent at the time of the index procedure following randomisation in TRITON-TIMI 38, and were further subdivided by type of stent received. Patients were randomly assigned in a 1 to 1 fashion to receive a loading dose of study drug (prasugrel 60 mg or clopidogrel 300 mg) as soon as possible after randomisation, followed by daily maintenance therapy (prasugrel 10 mg or clopidogrel 75 mg). All patients were to receive aspirin therapy. Treatment was to be continued for a minimum of 6 months and a maximum of 15 months. Randomisation was not stratified by stents used or stent type. The primary endpoint was the composite of cardiovascular death, non-fatal myocardial infarction, or non-fatal stroke. Stent thrombosis was assessed using Academic Research Consortium definitions, and analysis was by intention to treat. TRITON-TIMI 38 is registered with ClinicalTrials.gov, number NCT00097591.12,844 patients received at least one coronary stent; 5743 received only drug-eluting stents, and 6461 received only bare-metal stents. Prasugrel compared with clopidogrel reduced the primary endpoint (9.7 vs 11.9%, HR 0.81, p=0.0001) in the stented cohort, in patients with only drug-eluting stents (9.0 vs 11.1%, HR 0.82, p=0.019), and in patients with only bare-metal stents (10.0 vs 12.2%, HR 0.80, p=0.003). Stent thrombosis was associated with death or myocardial infarction in 89% (186/210) of patients. Stent thrombosis was reduced with prasugrel overall (1.13 vs 2.35%, HR 0.48, p<0.0001), in patients with drug-eluting stents only (0.84 vs 2.31%, HR 0.36, p<0.0001), and in those with bare-metal stents only (1.27 vs 2.41%, HR 0.52, p=0.0009).Intensive antiplatelet therapy with prasugrel resulted in fewer ischaemic outcomes including stent thrombosis than with standard clopidogrel. These findings were statistically robust irrespective of stent type, and the data affirm the importance of intensive platelet inhibition in patients with intracoronary stents.","Intensive oral antiplatelet therapy for reduction of ischaemic events including stent thrombosis in patients with acute coronary syndromes treated with percutaneous coronary intervention and stenting in the TRITON-TIMI 38 trial: a subanalysis of a randomised trial."
"874","Lancet.1521","0.019",18377975,2008,"Intracoronary stenting can improve procedural success and reduce restenosis compared with balloon angioplasty in patients with acute coronary syndromes, but can also increase the rate of thrombotic complications including stent thrombosis. The TRITON-TIMI 38 trial has shown that prasugrel-a novel, potent thienopyridine-can reduce ischaemic events compared with standard clopidogrel therapy. We assessed the rate, outcomes, and prevention of ischaemic events in patients treated with prasugrel or clopidogrel with stents in the TRITON-TIMI 38 study.Patients with moderate-risk to high-risk acute coronary syndromes were included in our analysis if they had received at least one coronary stent at the time of the index procedure following randomisation in TRITON-TIMI 38, and were further subdivided by type of stent received. Patients were randomly assigned in a 1 to 1 fashion to receive a loading dose of study drug (prasugrel 60 mg or clopidogrel 300 mg) as soon as possible after randomisation, followed by daily maintenance therapy (prasugrel 10 mg or clopidogrel 75 mg). All patients were to receive aspirin therapy. Treatment was to be continued for a minimum of 6 months and a maximum of 15 months. Randomisation was not stratified by stents used or stent type. The primary endpoint was the composite of cardiovascular death, non-fatal myocardial infarction, or non-fatal stroke. Stent thrombosis was assessed using Academic Research Consortium definitions, and analysis was by intention to treat. TRITON-TIMI 38 is registered with ClinicalTrials.gov, number NCT00097591.12,844 patients received at least one coronary stent; 5743 received only drug-eluting stents, and 6461 received only bare-metal stents. Prasugrel compared with clopidogrel reduced the primary endpoint (9.7 vs 11.9%, HR 0.81, p=0.0001) in the stented cohort, in patients with only drug-eluting stents (9.0 vs 11.1%, HR 0.82, p=0.019), and in patients with only bare-metal stents (10.0 vs 12.2%, HR 0.80, p=0.003). Stent thrombosis was associated with death or myocardial infarction in 89% (186/210) of patients. Stent thrombosis was reduced with prasugrel overall (1.13 vs 2.35%, HR 0.48, p<0.0001), in patients with drug-eluting stents only (0.84 vs 2.31%, HR 0.36, p<0.0001), and in those with bare-metal stents only (1.27 vs 2.41%, HR 0.52, p=0.0009).Intensive antiplatelet therapy with prasugrel resulted in fewer ischaemic outcomes including stent thrombosis than with standard clopidogrel. These findings were statistically robust irrespective of stent type, and the data affirm the importance of intensive platelet inhibition in patients with intracoronary stents.","Intensive oral antiplatelet therapy for reduction of ischaemic events including stent thrombosis in patients with acute coronary syndromes treated with percutaneous coronary intervention and stenting in the TRITON-TIMI 38 trial: a subanalysis of a randomised trial."
"875","Lancet.1531","0.003",18377975,2008,"Intracoronary stenting can improve procedural success and reduce restenosis compared with balloon angioplasty in patients with acute coronary syndromes, but can also increase the rate of thrombotic complications including stent thrombosis. The TRITON-TIMI 38 trial has shown that prasugrel-a novel, potent thienopyridine-can reduce ischaemic events compared with standard clopidogrel therapy. We assessed the rate, outcomes, and prevention of ischaemic events in patients treated with prasugrel or clopidogrel with stents in the TRITON-TIMI 38 study.Patients with moderate-risk to high-risk acute coronary syndromes were included in our analysis if they had received at least one coronary stent at the time of the index procedure following randomisation in TRITON-TIMI 38, and were further subdivided by type of stent received. Patients were randomly assigned in a 1 to 1 fashion to receive a loading dose of study drug (prasugrel 60 mg or clopidogrel 300 mg) as soon as possible after randomisation, followed by daily maintenance therapy (prasugrel 10 mg or clopidogrel 75 mg). All patients were to receive aspirin therapy. Treatment was to be continued for a minimum of 6 months and a maximum of 15 months. Randomisation was not stratified by stents used or stent type. The primary endpoint was the composite of cardiovascular death, non-fatal myocardial infarction, or non-fatal stroke. Stent thrombosis was assessed using Academic Research Consortium definitions, and analysis was by intention to treat. TRITON-TIMI 38 is registered with ClinicalTrials.gov, number NCT00097591.12,844 patients received at least one coronary stent; 5743 received only drug-eluting stents, and 6461 received only bare-metal stents. Prasugrel compared with clopidogrel reduced the primary endpoint (9.7 vs 11.9%, HR 0.81, p=0.0001) in the stented cohort, in patients with only drug-eluting stents (9.0 vs 11.1%, HR 0.82, p=0.019), and in patients with only bare-metal stents (10.0 vs 12.2%, HR 0.80, p=0.003). Stent thrombosis was associated with death or myocardial infarction in 89% (186/210) of patients. Stent thrombosis was reduced with prasugrel overall (1.13 vs 2.35%, HR 0.48, p<0.0001), in patients with drug-eluting stents only (0.84 vs 2.31%, HR 0.36, p<0.0001), and in those with bare-metal stents only (1.27 vs 2.41%, HR 0.52, p=0.0009).Intensive antiplatelet therapy with prasugrel resulted in fewer ischaemic outcomes including stent thrombosis than with standard clopidogrel. These findings were statistically robust irrespective of stent type, and the data affirm the importance of intensive platelet inhibition in patients with intracoronary stents.","Intensive oral antiplatelet therapy for reduction of ischaemic events including stent thrombosis in patients with acute coronary syndromes treated with percutaneous coronary intervention and stenting in the TRITON-TIMI 38 trial: a subanalysis of a randomised trial."
"876","Lancet.1541","9.00E-04",18377975,2008,"Intracoronary stenting can improve procedural success and reduce restenosis compared with balloon angioplasty in patients with acute coronary syndromes, but can also increase the rate of thrombotic complications including stent thrombosis. The TRITON-TIMI 38 trial has shown that prasugrel-a novel, potent thienopyridine-can reduce ischaemic events compared with standard clopidogrel therapy. We assessed the rate, outcomes, and prevention of ischaemic events in patients treated with prasugrel or clopidogrel with stents in the TRITON-TIMI 38 study.Patients with moderate-risk to high-risk acute coronary syndromes were included in our analysis if they had received at least one coronary stent at the time of the index procedure following randomisation in TRITON-TIMI 38, and were further subdivided by type of stent received. Patients were randomly assigned in a 1 to 1 fashion to receive a loading dose of study drug (prasugrel 60 mg or clopidogrel 300 mg) as soon as possible after randomisation, followed by daily maintenance therapy (prasugrel 10 mg or clopidogrel 75 mg). All patients were to receive aspirin therapy. Treatment was to be continued for a minimum of 6 months and a maximum of 15 months. Randomisation was not stratified by stents used or stent type. The primary endpoint was the composite of cardiovascular death, non-fatal myocardial infarction, or non-fatal stroke. Stent thrombosis was assessed using Academic Research Consortium definitions, and analysis was by intention to treat. TRITON-TIMI 38 is registered with ClinicalTrials.gov, number NCT00097591.12,844 patients received at least one coronary stent; 5743 received only drug-eluting stents, and 6461 received only bare-metal stents. Prasugrel compared with clopidogrel reduced the primary endpoint (9.7 vs 11.9%, HR 0.81, p=0.0001) in the stented cohort, in patients with only drug-eluting stents (9.0 vs 11.1%, HR 0.82, p=0.019), and in patients with only bare-metal stents (10.0 vs 12.2%, HR 0.80, p=0.003). Stent thrombosis was associated with death or myocardial infarction in 89% (186/210) of patients. Stent thrombosis was reduced with prasugrel overall (1.13 vs 2.35%, HR 0.48, p<0.0001), in patients with drug-eluting stents only (0.84 vs 2.31%, HR 0.36, p<0.0001), and in those with bare-metal stents only (1.27 vs 2.41%, HR 0.52, p=0.0009).Intensive antiplatelet therapy with prasugrel resulted in fewer ischaemic outcomes including stent thrombosis than with standard clopidogrel. These findings were statistically robust irrespective of stent type, and the data affirm the importance of intensive platelet inhibition in patients with intracoronary stents.","Intensive oral antiplatelet therapy for reduction of ischaemic events including stent thrombosis in patients with acute coronary syndromes treated with percutaneous coronary intervention and stenting in the TRITON-TIMI 38 trial: a subanalysis of a randomised trial."
"877","JAMA.4411","0.001",18398079,2008,"Transarterial chemoembolization (TACE) combined with radiofrequency ablation (RFA) therapy has been used for patients with large hepatocellular carcinoma tumors, but the survival benefits of combined treatment are not known.To compare rates of survival of patients with large hepatocellular carcinoma tumors who received treatment with TACE combined with RFA therapy (TACE-RFA), TACE alone, and RFA alone.Randomized controlled trial conducted from January 2001 to May 2004 among 291 consecutive patients with hepatocellular carcinoma larger than 3 cm at a single center in China.Patients were randomly assigned to treatment with combined TACE-RFA (n = 96), TACE alone (n = 95), or RFA alone (n = 100).The primary end point was survival and the secondary end point was objective response rate.During a median 28.5 months of follow-up, median survival times were 24 months in the TACE group (3.4 courses), 22 months in the RFA group (3.6 courses), and 37 months in the TACE-RFA group (4.4 courses). Patients treated with TACE-RFA had better overall survival than those treated with TACE alone (hazard ratio [HR], 1.87; 95% confidence interval [CI], 1.33-2.63; P < .001) or RFA (HR, 1.88; 95% CI, 1.34-2.65; P < .001). In a preplanned substratification analysis, survival was also better in the TACE-RFA group than in the RFA group for patients with uninodular hepatocellular carcinoma (HR, 2.50; 95% CI, 1.42-4.42; P = .001) and in the TACE-RFA group than the TACE group for patients with multinodular hepatocellular carcinoma (HR, 1.99; 95% CI, 1.31-3.00; P < .001). The rate of objective response sustained for at least 6 months was higher in the TACE-RFA group (54%) than with either TACE (35%; rate difference, 0.19; 95% CI, 0.06-0.33; P = .009) or RFA (36%; rate difference, 0.18; 95% CI, 0.05-0.32; P = .01) treatment alone.In this patient group, TACE-RFA was superior to TACE alone or RFA alone in improving survival for patients with hepatocellular carcinoma larger than 3 cm.clinicaltrials.gov Identifier: NCT00479050.","Chemoembolization combined with radiofrequency ablation for patients with hepatocellular carcinoma larger than 3 cm: a randomized controlled trial."
"878","JAMA.4421","0.001",18398079,2008,"Transarterial chemoembolization (TACE) combined with radiofrequency ablation (RFA) therapy has been used for patients with large hepatocellular carcinoma tumors, but the survival benefits of combined treatment are not known.To compare rates of survival of patients with large hepatocellular carcinoma tumors who received treatment with TACE combined with RFA therapy (TACE-RFA), TACE alone, and RFA alone.Randomized controlled trial conducted from January 2001 to May 2004 among 291 consecutive patients with hepatocellular carcinoma larger than 3 cm at a single center in China.Patients were randomly assigned to treatment with combined TACE-RFA (n = 96), TACE alone (n = 95), or RFA alone (n = 100).The primary end point was survival and the secondary end point was objective response rate.During a median 28.5 months of follow-up, median survival times were 24 months in the TACE group (3.4 courses), 22 months in the RFA group (3.6 courses), and 37 months in the TACE-RFA group (4.4 courses). Patients treated with TACE-RFA had better overall survival than those treated with TACE alone (hazard ratio [HR], 1.87; 95% confidence interval [CI], 1.33-2.63; P < .001) or RFA (HR, 1.88; 95% CI, 1.34-2.65; P < .001). In a preplanned substratification analysis, survival was also better in the TACE-RFA group than in the RFA group for patients with uninodular hepatocellular carcinoma (HR, 2.50; 95% CI, 1.42-4.42; P = .001) and in the TACE-RFA group than the TACE group for patients with multinodular hepatocellular carcinoma (HR, 1.99; 95% CI, 1.31-3.00; P < .001). The rate of objective response sustained for at least 6 months was higher in the TACE-RFA group (54%) than with either TACE (35%; rate difference, 0.19; 95% CI, 0.06-0.33; P = .009) or RFA (36%; rate difference, 0.18; 95% CI, 0.05-0.32; P = .01) treatment alone.In this patient group, TACE-RFA was superior to TACE alone or RFA alone in improving survival for patients with hepatocellular carcinoma larger than 3 cm.clinicaltrials.gov Identifier: NCT00479050.","Chemoembolization combined with radiofrequency ablation for patients with hepatocellular carcinoma larger than 3 cm: a randomized controlled trial."
"879","JAMA.4431","0.001",18398079,2008,"Transarterial chemoembolization (TACE) combined with radiofrequency ablation (RFA) therapy has been used for patients with large hepatocellular carcinoma tumors, but the survival benefits of combined treatment are not known.To compare rates of survival of patients with large hepatocellular carcinoma tumors who received treatment with TACE combined with RFA therapy (TACE-RFA), TACE alone, and RFA alone.Randomized controlled trial conducted from January 2001 to May 2004 among 291 consecutive patients with hepatocellular carcinoma larger than 3 cm at a single center in China.Patients were randomly assigned to treatment with combined TACE-RFA (n = 96), TACE alone (n = 95), or RFA alone (n = 100).The primary end point was survival and the secondary end point was objective response rate.During a median 28.5 months of follow-up, median survival times were 24 months in the TACE group (3.4 courses), 22 months in the RFA group (3.6 courses), and 37 months in the TACE-RFA group (4.4 courses). Patients treated with TACE-RFA had better overall survival than those treated with TACE alone (hazard ratio [HR], 1.87; 95% confidence interval [CI], 1.33-2.63; P < .001) or RFA (HR, 1.88; 95% CI, 1.34-2.65; P < .001). In a preplanned substratification analysis, survival was also better in the TACE-RFA group than in the RFA group for patients with uninodular hepatocellular carcinoma (HR, 2.50; 95% CI, 1.42-4.42; P = .001) and in the TACE-RFA group than the TACE group for patients with multinodular hepatocellular carcinoma (HR, 1.99; 95% CI, 1.31-3.00; P < .001). The rate of objective response sustained for at least 6 months was higher in the TACE-RFA group (54%) than with either TACE (35%; rate difference, 0.19; 95% CI, 0.06-0.33; P = .009) or RFA (36%; rate difference, 0.18; 95% CI, 0.05-0.32; P = .01) treatment alone.In this patient group, TACE-RFA was superior to TACE alone or RFA alone in improving survival for patients with hepatocellular carcinoma larger than 3 cm.clinicaltrials.gov Identifier: NCT00479050.","Chemoembolization combined with radiofrequency ablation for patients with hepatocellular carcinoma larger than 3 cm: a randomized controlled trial."
"880","JAMA.4871","0.001",18398079,2008,"Transarterial chemoembolization (TACE) combined with radiofrequency ablation (RFA) therapy has been used for patients with large hepatocellular carcinoma tumors, but the survival benefits of combined treatment are not known.To compare rates of survival of patients with large hepatocellular carcinoma tumors who received treatment with TACE combined with RFA therapy (TACE-RFA), TACE alone, and RFA alone.Randomized controlled trial conducted from January 2001 to May 2004 among 291 consecutive patients with hepatocellular carcinoma larger than 3 cm at a single center in China.Patients were randomly assigned to treatment with combined TACE-RFA (n = 96), TACE alone (n = 95), or RFA alone (n = 100).The primary end point was survival and the secondary end point was objective response rate.During a median 28.5 months of follow-up, median survival times were 24 months in the TACE group (3.4 courses), 22 months in the RFA group (3.6 courses), and 37 months in the TACE-RFA group (4.4 courses). Patients treated with TACE-RFA had better overall survival than those treated with TACE alone (hazard ratio [HR], 1.87; 95% confidence interval [CI], 1.33-2.63; P < .001) or RFA (HR, 1.88; 95% CI, 1.34-2.65; P < .001). In a preplanned substratification analysis, survival was also better in the TACE-RFA group than in the RFA group for patients with uninodular hepatocellular carcinoma (HR, 2.50; 95% CI, 1.42-4.42; P = .001) and in the TACE-RFA group than the TACE group for patients with multinodular hepatocellular carcinoma (HR, 1.99; 95% CI, 1.31-3.00; P < .001). The rate of objective response sustained for at least 6 months was higher in the TACE-RFA group (54%) than with either TACE (35%; rate difference, 0.19; 95% CI, 0.06-0.33; P = .009) or RFA (36%; rate difference, 0.18; 95% CI, 0.05-0.32; P = .01) treatment alone.In this patient group, TACE-RFA was superior to TACE alone or RFA alone in improving survival for patients with hepatocellular carcinoma larger than 3 cm.clinicaltrials.gov Identifier: NCT00479050.","Chemoembolization combined with radiofrequency ablation for patients with hepatocellular carcinoma larger than 3 cm: a randomized controlled trial."
"881","JAMA.441","0.001",18430911,2008,"Cost-related medication nonadherence (CRN) has been a persistent problem for individuals who are elderly and disabled in the United States. The impact of Medicare prescription drug coverage (Part D) on CRN is unknown.To estimate changes in CRN and forgoing basic needs to pay for drugs following Part D implementation.In a population-level study design, changes in study outcomes between 2005 and 2006 before and after Medicare Part D implementation were compared with historical changes between 2004 and 2005. The community-dwelling sample of the nationally representative Medicare Current Beneficiary Survey (unweighted unique n = 24,234; response rate, 72.3%) was used, and logistic regression analyses were controlled for demographic characteristics, health status, and historical trends.Self-reports of CRN (skipping or reducing doses, not obtaining prescriptions) and spending less on basic needs to afford medicines.The unadjusted, weighted prevalence of CRN was 15.2% in 2004, 14.1% in 2005, and 11.5% after Part D implementation in 2006. The prevalence of spending less on basic needs was 10.6% in 2004, 11.1% in 2005, and 7.6% in 2006. Adjusted analyses comparing 2006 with 2005 and controlling for historical changes (2005 vs 2004) demonstrated significant decreases in the odds of CRN (ratio of odds ratios [ORs], 0.85; 95% confidence interval [CI], 0.74-0.98; P = .03) and spending less on basic needs (ratio of ORs, 0.59; 95% CI, 0.48-0.72; P < .001). No significant changes in CRN were observed among beneficiaries with fair to poor health (ratio of ORs, 1.00; 95% CI, 0.82-1.21; P = .97), despite high baseline CRN prevalence for this group (22.2% in 2005) and significant decreases among beneficiaries with good to excellent health (ratio of ORs, 0.77; 95% CI, 0.63-0.95; P = .02). However, significant reductions in spending less on basic needs were observed in both groups (fair to poor health: ratio of ORs, 0.60; 95% CI, 0.47-0.75; P < .001; and good to excellent health: ratio of ORs, 0.57; 95% CI, 0.44-0.75; P < .001).In this survey population, there was evidence for a small but significant overall decrease in CRN and forgoing basic needs following Part D implementation. However, no net decrease in CRN after Part D was observed among the sickest beneficiaries, who continued to experience higher rates of CRN.","Cost-related medication nonadherence and spending on basic needs following implementation of Medicare Part D."
"882","JAMA.442","0.001",18430911,2008,"Cost-related medication nonadherence (CRN) has been a persistent problem for individuals who are elderly and disabled in the United States. The impact of Medicare prescription drug coverage (Part D) on CRN is unknown.To estimate changes in CRN and forgoing basic needs to pay for drugs following Part D implementation.In a population-level study design, changes in study outcomes between 2005 and 2006 before and after Medicare Part D implementation were compared with historical changes between 2004 and 2005. The community-dwelling sample of the nationally representative Medicare Current Beneficiary Survey (unweighted unique n = 24,234; response rate, 72.3%) was used, and logistic regression analyses were controlled for demographic characteristics, health status, and historical trends.Self-reports of CRN (skipping or reducing doses, not obtaining prescriptions) and spending less on basic needs to afford medicines.The unadjusted, weighted prevalence of CRN was 15.2% in 2004, 14.1% in 2005, and 11.5% after Part D implementation in 2006. The prevalence of spending less on basic needs was 10.6% in 2004, 11.1% in 2005, and 7.6% in 2006. Adjusted analyses comparing 2006 with 2005 and controlling for historical changes (2005 vs 2004) demonstrated significant decreases in the odds of CRN (ratio of odds ratios [ORs], 0.85; 95% confidence interval [CI], 0.74-0.98; P = .03) and spending less on basic needs (ratio of ORs, 0.59; 95% CI, 0.48-0.72; P < .001). No significant changes in CRN were observed among beneficiaries with fair to poor health (ratio of ORs, 1.00; 95% CI, 0.82-1.21; P = .97), despite high baseline CRN prevalence for this group (22.2% in 2005) and significant decreases among beneficiaries with good to excellent health (ratio of ORs, 0.77; 95% CI, 0.63-0.95; P = .02). However, significant reductions in spending less on basic needs were observed in both groups (fair to poor health: ratio of ORs, 0.60; 95% CI, 0.47-0.75; P < .001; and good to excellent health: ratio of ORs, 0.57; 95% CI, 0.44-0.75; P < .001).In this survey population, there was evidence for a small but significant overall decrease in CRN and forgoing basic needs following Part D implementation. However, no net decrease in CRN after Part D was observed among the sickest beneficiaries, who continued to experience higher rates of CRN.","Cost-related medication nonadherence and spending on basic needs following implementation of Medicare Part D."
"883","JAMA.443","0.001",18430911,2008,"Cost-related medication nonadherence (CRN) has been a persistent problem for individuals who are elderly and disabled in the United States. The impact of Medicare prescription drug coverage (Part D) on CRN is unknown.To estimate changes in CRN and forgoing basic needs to pay for drugs following Part D implementation.In a population-level study design, changes in study outcomes between 2005 and 2006 before and after Medicare Part D implementation were compared with historical changes between 2004 and 2005. The community-dwelling sample of the nationally representative Medicare Current Beneficiary Survey (unweighted unique n = 24,234; response rate, 72.3%) was used, and logistic regression analyses were controlled for demographic characteristics, health status, and historical trends.Self-reports of CRN (skipping or reducing doses, not obtaining prescriptions) and spending less on basic needs to afford medicines.The unadjusted, weighted prevalence of CRN was 15.2% in 2004, 14.1% in 2005, and 11.5% after Part D implementation in 2006. The prevalence of spending less on basic needs was 10.6% in 2004, 11.1% in 2005, and 7.6% in 2006. Adjusted analyses comparing 2006 with 2005 and controlling for historical changes (2005 vs 2004) demonstrated significant decreases in the odds of CRN (ratio of odds ratios [ORs], 0.85; 95% confidence interval [CI], 0.74-0.98; P = .03) and spending less on basic needs (ratio of ORs, 0.59; 95% CI, 0.48-0.72; P < .001). No significant changes in CRN were observed among beneficiaries with fair to poor health (ratio of ORs, 1.00; 95% CI, 0.82-1.21; P = .97), despite high baseline CRN prevalence for this group (22.2% in 2005) and significant decreases among beneficiaries with good to excellent health (ratio of ORs, 0.77; 95% CI, 0.63-0.95; P = .02). However, significant reductions in spending less on basic needs were observed in both groups (fair to poor health: ratio of ORs, 0.60; 95% CI, 0.47-0.75; P < .001; and good to excellent health: ratio of ORs, 0.57; 95% CI, 0.44-0.75; P < .001).In this survey population, there was evidence for a small but significant overall decrease in CRN and forgoing basic needs following Part D implementation. However, no net decrease in CRN after Part D was observed among the sickest beneficiaries, who continued to experience higher rates of CRN.","Cost-related medication nonadherence and spending on basic needs following implementation of Medicare Part D."
"884","JAMA.474","0.03",18430911,2008,"Cost-related medication nonadherence (CRN) has been a persistent problem for individuals who are elderly and disabled in the United States. The impact of Medicare prescription drug coverage (Part D) on CRN is unknown.To estimate changes in CRN and forgoing basic needs to pay for drugs following Part D implementation.In a population-level study design, changes in study outcomes between 2005 and 2006 before and after Medicare Part D implementation were compared with historical changes between 2004 and 2005. The community-dwelling sample of the nationally representative Medicare Current Beneficiary Survey (unweighted unique n = 24,234; response rate, 72.3%) was used, and logistic regression analyses were controlled for demographic characteristics, health status, and historical trends.Self-reports of CRN (skipping or reducing doses, not obtaining prescriptions) and spending less on basic needs to afford medicines.The unadjusted, weighted prevalence of CRN was 15.2% in 2004, 14.1% in 2005, and 11.5% after Part D implementation in 2006. The prevalence of spending less on basic needs was 10.6% in 2004, 11.1% in 2005, and 7.6% in 2006. Adjusted analyses comparing 2006 with 2005 and controlling for historical changes (2005 vs 2004) demonstrated significant decreases in the odds of CRN (ratio of odds ratios [ORs], 0.85; 95% confidence interval [CI], 0.74-0.98; P = .03) and spending less on basic needs (ratio of ORs, 0.59; 95% CI, 0.48-0.72; P < .001). No significant changes in CRN were observed among beneficiaries with fair to poor health (ratio of ORs, 1.00; 95% CI, 0.82-1.21; P = .97), despite high baseline CRN prevalence for this group (22.2% in 2005) and significant decreases among beneficiaries with good to excellent health (ratio of ORs, 0.77; 95% CI, 0.63-0.95; P = .02). However, significant reductions in spending less on basic needs were observed in both groups (fair to poor health: ratio of ORs, 0.60; 95% CI, 0.47-0.75; P < .001; and good to excellent health: ratio of ORs, 0.57; 95% CI, 0.44-0.75; P < .001).In this survey population, there was evidence for a small but significant overall decrease in CRN and forgoing basic needs following Part D implementation. However, no net decrease in CRN after Part D was observed among the sickest beneficiaries, who continued to experience higher rates of CRN.","Cost-related medication nonadherence and spending on basic needs following implementation of Medicare Part D."
"885","JAMA.475","0.97",18430911,2008,"Cost-related medication nonadherence (CRN) has been a persistent problem for individuals who are elderly and disabled in the United States. The impact of Medicare prescription drug coverage (Part D) on CRN is unknown.To estimate changes in CRN and forgoing basic needs to pay for drugs following Part D implementation.In a population-level study design, changes in study outcomes between 2005 and 2006 before and after Medicare Part D implementation were compared with historical changes between 2004 and 2005. The community-dwelling sample of the nationally representative Medicare Current Beneficiary Survey (unweighted unique n = 24,234; response rate, 72.3%) was used, and logistic regression analyses were controlled for demographic characteristics, health status, and historical trends.Self-reports of CRN (skipping or reducing doses, not obtaining prescriptions) and spending less on basic needs to afford medicines.The unadjusted, weighted prevalence of CRN was 15.2% in 2004, 14.1% in 2005, and 11.5% after Part D implementation in 2006. The prevalence of spending less on basic needs was 10.6% in 2004, 11.1% in 2005, and 7.6% in 2006. Adjusted analyses comparing 2006 with 2005 and controlling for historical changes (2005 vs 2004) demonstrated significant decreases in the odds of CRN (ratio of odds ratios [ORs], 0.85; 95% confidence interval [CI], 0.74-0.98; P = .03) and spending less on basic needs (ratio of ORs, 0.59; 95% CI, 0.48-0.72; P < .001). No significant changes in CRN were observed among beneficiaries with fair to poor health (ratio of ORs, 1.00; 95% CI, 0.82-1.21; P = .97), despite high baseline CRN prevalence for this group (22.2% in 2005) and significant decreases among beneficiaries with good to excellent health (ratio of ORs, 0.77; 95% CI, 0.63-0.95; P = .02). However, significant reductions in spending less on basic needs were observed in both groups (fair to poor health: ratio of ORs, 0.60; 95% CI, 0.47-0.75; P < .001; and good to excellent health: ratio of ORs, 0.57; 95% CI, 0.44-0.75; P < .001).In this survey population, there was evidence for a small but significant overall decrease in CRN and forgoing basic needs following Part D implementation. However, no net decrease in CRN after Part D was observed among the sickest beneficiaries, who continued to experience higher rates of CRN.","Cost-related medication nonadherence and spending on basic needs following implementation of Medicare Part D."
"886","JAMA.476","0.02",18430911,2008,"Cost-related medication nonadherence (CRN) has been a persistent problem for individuals who are elderly and disabled in the United States. The impact of Medicare prescription drug coverage (Part D) on CRN is unknown.To estimate changes in CRN and forgoing basic needs to pay for drugs following Part D implementation.In a population-level study design, changes in study outcomes between 2005 and 2006 before and after Medicare Part D implementation were compared with historical changes between 2004 and 2005. The community-dwelling sample of the nationally representative Medicare Current Beneficiary Survey (unweighted unique n = 24,234; response rate, 72.3%) was used, and logistic regression analyses were controlled for demographic characteristics, health status, and historical trends.Self-reports of CRN (skipping or reducing doses, not obtaining prescriptions) and spending less on basic needs to afford medicines.The unadjusted, weighted prevalence of CRN was 15.2% in 2004, 14.1% in 2005, and 11.5% after Part D implementation in 2006. The prevalence of spending less on basic needs was 10.6% in 2004, 11.1% in 2005, and 7.6% in 2006. Adjusted analyses comparing 2006 with 2005 and controlling for historical changes (2005 vs 2004) demonstrated significant decreases in the odds of CRN (ratio of odds ratios [ORs], 0.85; 95% confidence interval [CI], 0.74-0.98; P = .03) and spending less on basic needs (ratio of ORs, 0.59; 95% CI, 0.48-0.72; P < .001). No significant changes in CRN were observed among beneficiaries with fair to poor health (ratio of ORs, 1.00; 95% CI, 0.82-1.21; P = .97), despite high baseline CRN prevalence for this group (22.2% in 2005) and significant decreases among beneficiaries with good to excellent health (ratio of ORs, 0.77; 95% CI, 0.63-0.95; P = .02). However, significant reductions in spending less on basic needs were observed in both groups (fair to poor health: ratio of ORs, 0.60; 95% CI, 0.47-0.75; P < .001; and good to excellent health: ratio of ORs, 0.57; 95% CI, 0.44-0.75; P < .001).In this survey population, there was evidence for a small but significant overall decrease in CRN and forgoing basic needs following Part D implementation. However, no net decrease in CRN after Part D was observed among the sickest beneficiaries, who continued to experience higher rates of CRN.","Cost-related medication nonadherence and spending on basic needs following implementation of Medicare Part D."
"887","Lancet.100","0.002",18455228,2008,"Osteoporosis is diagnosed by the measurement of bone mineral density, which is a highly heritable and multifactorial trait. We aimed to identify genetic loci that are associated with bone mineral density.In this genome-wide association study, we identified the most promising of 314 075 single nucleotide polymorphisms (SNPs) in 2094 women in a UK study. We then tested these SNPs for replication in 6463 people from three other cohorts in western Europe. We also investigated allelic expression in lymphoblast cell lines. We tested the association between the replicated SNPs and osteoporotic fractures with data from two studies.We identified genome-wide evidence for an association between bone mineral density and two SNPs (p<5x10(-8)). The SNPs were rs4355801, on chromosome 8, near to the TNFRSF11B (osteoprotegerin) gene, and rs3736228, on chromosome 11 in the LRP5 (lipoprotein-receptor-related protein) gene. A non-synonymous SNP in the LRP5 gene was associated with decreased bone mineral density (rs3736228, p=6.3x10(-12) for lumbar spine and p=1.9x10(-4) for femoral neck) and an increased risk of both osteoporotic fractures (odds ratio [OR] 1.3, 95% CI 1.09-1.52, p=0.002) and osteoporosis (OR 1.3, 1.08-1.63, p=0.008). Three SNPs near the TNFRSF11B gene were associated with decreased bone mineral density (top SNP, rs4355801: p=7.6x10(-10) for lumbar spine and p=3.3x10(-8) for femoral neck) and increased risk of osteoporosis (OR 1.2, 95% CI 1.01-1.42, p=0.038). For carriers of the risk allele at rs4355801, expression of TNFRSF11B in lymphoblast cell lines was halved (p=3.0x10(-6)). 1883 (22%) of 8557 people were at least heterozygous for these risk alleles, and these alleles had a cumulative association with bone mineral density (trend p=2.3x10(-17)). The presence of both risk alleles increased the risk of osteoporotic fractures (OR 1.3, 1.08-1.63, p=0.006) and this effect was independent of bone mineral density.Two gene variants of key biological proteins increase the risk of osteoporosis and osteoporotic fracture. The combined effect of these risk alleles on fractures is similar to that of most well-replicated environmental risk factors, and they are present in more than one in five white people, suggesting a potential role in screening.","Bone mineral density, osteoporosis, and osteoporotic fractures: a genome-wide association study."
"888","Lancet.101","0.008",18455228,2008,"Osteoporosis is diagnosed by the measurement of bone mineral density, which is a highly heritable and multifactorial trait. We aimed to identify genetic loci that are associated with bone mineral density.In this genome-wide association study, we identified the most promising of 314 075 single nucleotide polymorphisms (SNPs) in 2094 women in a UK study. We then tested these SNPs for replication in 6463 people from three other cohorts in western Europe. We also investigated allelic expression in lymphoblast cell lines. We tested the association between the replicated SNPs and osteoporotic fractures with data from two studies.We identified genome-wide evidence for an association between bone mineral density and two SNPs (p<5x10(-8)). The SNPs were rs4355801, on chromosome 8, near to the TNFRSF11B (osteoprotegerin) gene, and rs3736228, on chromosome 11 in the LRP5 (lipoprotein-receptor-related protein) gene. A non-synonymous SNP in the LRP5 gene was associated with decreased bone mineral density (rs3736228, p=6.3x10(-12) for lumbar spine and p=1.9x10(-4) for femoral neck) and an increased risk of both osteoporotic fractures (odds ratio [OR] 1.3, 95% CI 1.09-1.52, p=0.002) and osteoporosis (OR 1.3, 1.08-1.63, p=0.008). Three SNPs near the TNFRSF11B gene were associated with decreased bone mineral density (top SNP, rs4355801: p=7.6x10(-10) for lumbar spine and p=3.3x10(-8) for femoral neck) and increased risk of osteoporosis (OR 1.2, 95% CI 1.01-1.42, p=0.038). For carriers of the risk allele at rs4355801, expression of TNFRSF11B in lymphoblast cell lines was halved (p=3.0x10(-6)). 1883 (22%) of 8557 people were at least heterozygous for these risk alleles, and these alleles had a cumulative association with bone mineral density (trend p=2.3x10(-17)). The presence of both risk alleles increased the risk of osteoporotic fractures (OR 1.3, 1.08-1.63, p=0.006) and this effect was independent of bone mineral density.Two gene variants of key biological proteins increase the risk of osteoporosis and osteoporotic fracture. The combined effect of these risk alleles on fractures is similar to that of most well-replicated environmental risk factors, and they are present in more than one in five white people, suggesting a potential role in screening.","Bone mineral density, osteoporosis, and osteoporotic fractures: a genome-wide association study."
"889","Lancet.104","0.038",18455228,2008,"Osteoporosis is diagnosed by the measurement of bone mineral density, which is a highly heritable and multifactorial trait. We aimed to identify genetic loci that are associated with bone mineral density.In this genome-wide association study, we identified the most promising of 314 075 single nucleotide polymorphisms (SNPs) in 2094 women in a UK study. We then tested these SNPs for replication in 6463 people from three other cohorts in western Europe. We also investigated allelic expression in lymphoblast cell lines. We tested the association between the replicated SNPs and osteoporotic fractures with data from two studies.We identified genome-wide evidence for an association between bone mineral density and two SNPs (p<5x10(-8)). The SNPs were rs4355801, on chromosome 8, near to the TNFRSF11B (osteoprotegerin) gene, and rs3736228, on chromosome 11 in the LRP5 (lipoprotein-receptor-related protein) gene. A non-synonymous SNP in the LRP5 gene was associated with decreased bone mineral density (rs3736228, p=6.3x10(-12) for lumbar spine and p=1.9x10(-4) for femoral neck) and an increased risk of both osteoporotic fractures (odds ratio [OR] 1.3, 95% CI 1.09-1.52, p=0.002) and osteoporosis (OR 1.3, 1.08-1.63, p=0.008). Three SNPs near the TNFRSF11B gene were associated with decreased bone mineral density (top SNP, rs4355801: p=7.6x10(-10) for lumbar spine and p=3.3x10(-8) for femoral neck) and increased risk of osteoporosis (OR 1.2, 95% CI 1.01-1.42, p=0.038). For carriers of the risk allele at rs4355801, expression of TNFRSF11B in lymphoblast cell lines was halved (p=3.0x10(-6)). 1883 (22%) of 8557 people were at least heterozygous for these risk alleles, and these alleles had a cumulative association with bone mineral density (trend p=2.3x10(-17)). The presence of both risk alleles increased the risk of osteoporotic fractures (OR 1.3, 1.08-1.63, p=0.006) and this effect was independent of bone mineral density.Two gene variants of key biological proteins increase the risk of osteoporosis and osteoporotic fracture. The combined effect of these risk alleles on fractures is similar to that of most well-replicated environmental risk factors, and they are present in more than one in five white people, suggesting a potential role in screening.","Bone mineral density, osteoporosis, and osteoporotic fractures: a genome-wide association study."
"890","Lancet.106","0.006",18455228,2008,"Osteoporosis is diagnosed by the measurement of bone mineral density, which is a highly heritable and multifactorial trait. We aimed to identify genetic loci that are associated with bone mineral density.In this genome-wide association study, we identified the most promising of 314 075 single nucleotide polymorphisms (SNPs) in 2094 women in a UK study. We then tested these SNPs for replication in 6463 people from three other cohorts in western Europe. We also investigated allelic expression in lymphoblast cell lines. We tested the association between the replicated SNPs and osteoporotic fractures with data from two studies.We identified genome-wide evidence for an association between bone mineral density and two SNPs (p<5x10(-8)). The SNPs were rs4355801, on chromosome 8, near to the TNFRSF11B (osteoprotegerin) gene, and rs3736228, on chromosome 11 in the LRP5 (lipoprotein-receptor-related protein) gene. A non-synonymous SNP in the LRP5 gene was associated with decreased bone mineral density (rs3736228, p=6.3x10(-12) for lumbar spine and p=1.9x10(-4) for femoral neck) and an increased risk of both osteoporotic fractures (odds ratio [OR] 1.3, 95% CI 1.09-1.52, p=0.002) and osteoporosis (OR 1.3, 1.08-1.63, p=0.008). Three SNPs near the TNFRSF11B gene were associated with decreased bone mineral density (top SNP, rs4355801: p=7.6x10(-10) for lumbar spine and p=3.3x10(-8) for femoral neck) and increased risk of osteoporosis (OR 1.2, 95% CI 1.01-1.42, p=0.038). For carriers of the risk allele at rs4355801, expression of TNFRSF11B in lymphoblast cell lines was halved (p=3.0x10(-6)). 1883 (22%) of 8557 people were at least heterozygous for these risk alleles, and these alleles had a cumulative association with bone mineral density (trend p=2.3x10(-17)). The presence of both risk alleles increased the risk of osteoporotic fractures (OR 1.3, 1.08-1.63, p=0.006) and this effect was independent of bone mineral density.Two gene variants of key biological proteins increase the risk of osteoporosis and osteoporotic fracture. The combined effect of these risk alleles on fractures is similar to that of most well-replicated environmental risk factors, and they are present in more than one in five white people, suggesting a potential role in screening.","Bone mineral density, osteoporosis, and osteoporotic fractures: a genome-wide association study."
"891","Lancet.1481","0.29",18486741,2008,"Malignant pleural mesothelioma is almost always fatal, and few treatment options are available. Although active symptom control (ASC) has been recommended for the management of this disease, no consensus exists for the role of chemotherapy. We investigated whether the addition of chemotherapy to ASC improved survival and quality of life.409 patients with malignant pleural mesothelioma, from 76 centres in the UK and two in Australia, were randomly assigned to ASC alone (treatment could include steroids, analgesic drugs, bronchodilators, palliative radiotherapy [n=136]); to ASC plus MVP (four cycles of mitomycin 6 mg/m2, vinblastine 6 mg/m2, and cisplatin 50 mg/m2 every 3 weeks [n=137]); or to ASC plus vinorelbine (one injection of vinorelbine 30 mg/m2 every week for 12 weeks [n=136]). Randomisation was done by minimisation, with stratification for WHO performance status, histology, and centre. Follow-up was every 3 weeks to 21 weeks after randomisation, and every 8 weeks thereafter. Because of slow accrual, the two chemotherapy groups were combined and compared with ASC alone for the primary outcome of overall survival. Analysis was by intention to treat. This study is registered, number ISRCTN54469112.At the time of analysis, 393 (96%) patients had died (ASC 132 [97%], ASC plus MVP 132 [96%], ASC plus vinorelbine 129 [95%]). Compared with ASC alone, we noted a small, non-significant survival benefit for ASC plus chemotherapy (hazard ratio [HR] 0.89 [95% CI 0.72-1.10]; p=0.29). Median survival was 7.6 months in the ASC alone group and 8.5 months in the ASC plus chemotherapy group. Exploratory analyses suggested a survival advantage for ASC plus vinorelbine compared with ASC alone (HR 0.80 [0.63-1.02]; p=0.08), with a median survival of 9.5 months. There was no evidence of a survival benefit with ASC plus MVP (HR 0.99 [0.78-1.27]; p=0.95). We observed no between-group differences in four predefined quality-of-life subscales (physical functioning, pain, dyspnoea, and global health status) at any of the assessments in the first 6 months.The addition of chemotherapy to ASC offers no significant benefits in terms of overall survival or quality of life. However, exploratory analyses suggested that vinorelbine merits further investigation.","Active symptom control with or without chemotherapy in the treatment of patients with malignant pleural mesothelioma (MS01): a multicentre randomised trial."
"892","Lancet.1491","0.08",18486741,2008,"Malignant pleural mesothelioma is almost always fatal, and few treatment options are available. Although active symptom control (ASC) has been recommended for the management of this disease, no consensus exists for the role of chemotherapy. We investigated whether the addition of chemotherapy to ASC improved survival and quality of life.409 patients with malignant pleural mesothelioma, from 76 centres in the UK and two in Australia, were randomly assigned to ASC alone (treatment could include steroids, analgesic drugs, bronchodilators, palliative radiotherapy [n=136]); to ASC plus MVP (four cycles of mitomycin 6 mg/m2, vinblastine 6 mg/m2, and cisplatin 50 mg/m2 every 3 weeks [n=137]); or to ASC plus vinorelbine (one injection of vinorelbine 30 mg/m2 every week for 12 weeks [n=136]). Randomisation was done by minimisation, with stratification for WHO performance status, histology, and centre. Follow-up was every 3 weeks to 21 weeks after randomisation, and every 8 weeks thereafter. Because of slow accrual, the two chemotherapy groups were combined and compared with ASC alone for the primary outcome of overall survival. Analysis was by intention to treat. This study is registered, number ISRCTN54469112.At the time of analysis, 393 (96%) patients had died (ASC 132 [97%], ASC plus MVP 132 [96%], ASC plus vinorelbine 129 [95%]). Compared with ASC alone, we noted a small, non-significant survival benefit for ASC plus chemotherapy (hazard ratio [HR] 0.89 [95% CI 0.72-1.10]; p=0.29). Median survival was 7.6 months in the ASC alone group and 8.5 months in the ASC plus chemotherapy group. Exploratory analyses suggested a survival advantage for ASC plus vinorelbine compared with ASC alone (HR 0.80 [0.63-1.02]; p=0.08), with a median survival of 9.5 months. There was no evidence of a survival benefit with ASC plus MVP (HR 0.99 [0.78-1.27]; p=0.95). We observed no between-group differences in four predefined quality-of-life subscales (physical functioning, pain, dyspnoea, and global health status) at any of the assessments in the first 6 months.The addition of chemotherapy to ASC offers no significant benefits in terms of overall survival or quality of life. However, exploratory analyses suggested that vinorelbine merits further investigation.","Active symptom control with or without chemotherapy in the treatment of patients with malignant pleural mesothelioma (MS01): a multicentre randomised trial."
"893","Lancet.1501","0.95",18486741,2008,"Malignant pleural mesothelioma is almost always fatal, and few treatment options are available. Although active symptom control (ASC) has been recommended for the management of this disease, no consensus exists for the role of chemotherapy. We investigated whether the addition of chemotherapy to ASC improved survival and quality of life.409 patients with malignant pleural mesothelioma, from 76 centres in the UK and two in Australia, were randomly assigned to ASC alone (treatment could include steroids, analgesic drugs, bronchodilators, palliative radiotherapy [n=136]); to ASC plus MVP (four cycles of mitomycin 6 mg/m2, vinblastine 6 mg/m2, and cisplatin 50 mg/m2 every 3 weeks [n=137]); or to ASC plus vinorelbine (one injection of vinorelbine 30 mg/m2 every week for 12 weeks [n=136]). Randomisation was done by minimisation, with stratification for WHO performance status, histology, and centre. Follow-up was every 3 weeks to 21 weeks after randomisation, and every 8 weeks thereafter. Because of slow accrual, the two chemotherapy groups were combined and compared with ASC alone for the primary outcome of overall survival. Analysis was by intention to treat. This study is registered, number ISRCTN54469112.At the time of analysis, 393 (96%) patients had died (ASC 132 [97%], ASC plus MVP 132 [96%], ASC plus vinorelbine 129 [95%]). Compared with ASC alone, we noted a small, non-significant survival benefit for ASC plus chemotherapy (hazard ratio [HR] 0.89 [95% CI 0.72-1.10]; p=0.29). Median survival was 7.6 months in the ASC alone group and 8.5 months in the ASC plus chemotherapy group. Exploratory analyses suggested a survival advantage for ASC plus vinorelbine compared with ASC alone (HR 0.80 [0.63-1.02]; p=0.08), with a median survival of 9.5 months. There was no evidence of a survival benefit with ASC plus MVP (HR 0.99 [0.78-1.27]; p=0.95). We observed no between-group differences in four predefined quality-of-life subscales (physical functioning, pain, dyspnoea, and global health status) at any of the assessments in the first 6 months.The addition of chemotherapy to ASC offers no significant benefits in terms of overall survival or quality of life. However, exploratory analyses suggested that vinorelbine merits further investigation.","Active symptom control with or without chemotherapy in the treatment of patients with malignant pleural mesothelioma (MS01): a multicentre randomised trial."
"894","JAMA.438","0.001",18492969,2008,"Donations by minors (16- and 17-year-olds) now account for approximately 8% of the whole blood collected by the American Red Cross, but young age and first-time donation status are known to be independent risk factors for donation-related complications.To evaluate adverse reactions to allogeneic whole blood donation by 16- and 17-year-olds compared with older donors in American Red Cross blood centers.Prospective documentation of adverse events among 16- and 17-year-old donors using standardized collection protocols, definitions, and reporting methods in 2006. Data were from 9 American Red Cross blood centers that routinely collect from 16- and 17-year-olds, a population that provides 80% of its donations at high school blood drives.Rate of systemic (syncopal-type) and phlebotomy-related donor complications per 10,000 collections.In 2006, 9 American Red Cross regions collected 145,678 whole blood donations from 16- and 17-year-olds, 113,307 from 18- and 19-year-olds, and 1,517,460 from donors aged 20 years or older. Complications were recorded in 15,632 (10.7%), 9359 (8.3%), and 42,987 (2.8%) donations in each corresponding age group. In a multivariate logistic regression model, young age had the strongest association with complications (odds ratio [OR], 3.05; 95% confidence interval [CI], 2.52-3.69; P < .001), followed by first-time donation status (OR, 2.63; 95% CI, 2.24-3.09; P < .001) and female sex (OR, 1.87; 95% CI, 1.62-2.16; P < .001). Infrequent but medically relevant complications, in particular physical injury from syncope-related falls, were significantly more likely in 16- and 17-year-old donors (86 events; 5.9/10,000 collections) compared with 18- and 19-year-old donors (27 events; 2.4/10,000 collections; OR, 2.48; 95% CI, 1.61-3.82) or adults aged 20 years or older (62 events; 0.4/10,000 collections; OR, 14.46; 95% CI, 10.43 -20.04). Sixteen-year-old donors who experienced even a minor complication were less likely to return to donate within 12 months than 16-year-olds who experienced uncomplicated donations (52% vs 73% return rate; OR, 0.40; 95% CI, 0.36-0.44).A higher incidence of donation-related complications and injury occurs among 16- and 17-year-old blood donors compared with older donors. The increasing dependence on recruiting and retaining young blood donors requires a committed approach to donor safety, especially at high school blood drives.","Adverse reactions to allogeneic whole blood donation by 16- and 17-year-olds."
"895","JAMA.439","0.001",18492969,2008,"Donations by minors (16- and 17-year-olds) now account for approximately 8% of the whole blood collected by the American Red Cross, but young age and first-time donation status are known to be independent risk factors for donation-related complications.To evaluate adverse reactions to allogeneic whole blood donation by 16- and 17-year-olds compared with older donors in American Red Cross blood centers.Prospective documentation of adverse events among 16- and 17-year-old donors using standardized collection protocols, definitions, and reporting methods in 2006. Data were from 9 American Red Cross blood centers that routinely collect from 16- and 17-year-olds, a population that provides 80% of its donations at high school blood drives.Rate of systemic (syncopal-type) and phlebotomy-related donor complications per 10,000 collections.In 2006, 9 American Red Cross regions collected 145,678 whole blood donations from 16- and 17-year-olds, 113,307 from 18- and 19-year-olds, and 1,517,460 from donors aged 20 years or older. Complications were recorded in 15,632 (10.7%), 9359 (8.3%), and 42,987 (2.8%) donations in each corresponding age group. In a multivariate logistic regression model, young age had the strongest association with complications (odds ratio [OR], 3.05; 95% confidence interval [CI], 2.52-3.69; P < .001), followed by first-time donation status (OR, 2.63; 95% CI, 2.24-3.09; P < .001) and female sex (OR, 1.87; 95% CI, 1.62-2.16; P < .001). Infrequent but medically relevant complications, in particular physical injury from syncope-related falls, were significantly more likely in 16- and 17-year-old donors (86 events; 5.9/10,000 collections) compared with 18- and 19-year-old donors (27 events; 2.4/10,000 collections; OR, 2.48; 95% CI, 1.61-3.82) or adults aged 20 years or older (62 events; 0.4/10,000 collections; OR, 14.46; 95% CI, 10.43 -20.04). Sixteen-year-old donors who experienced even a minor complication were less likely to return to donate within 12 months than 16-year-olds who experienced uncomplicated donations (52% vs 73% return rate; OR, 0.40; 95% CI, 0.36-0.44).A higher incidence of donation-related complications and injury occurs among 16- and 17-year-old blood donors compared with older donors. The increasing dependence on recruiting and retaining young blood donors requires a committed approach to donor safety, especially at high school blood drives.","Adverse reactions to allogeneic whole blood donation by 16- and 17-year-olds."
"896","JAMA.440","0.001",18492969,2008,"Donations by minors (16- and 17-year-olds) now account for approximately 8% of the whole blood collected by the American Red Cross, but young age and first-time donation status are known to be independent risk factors for donation-related complications.To evaluate adverse reactions to allogeneic whole blood donation by 16- and 17-year-olds compared with older donors in American Red Cross blood centers.Prospective documentation of adverse events among 16- and 17-year-old donors using standardized collection protocols, definitions, and reporting methods in 2006. Data were from 9 American Red Cross blood centers that routinely collect from 16- and 17-year-olds, a population that provides 80% of its donations at high school blood drives.Rate of systemic (syncopal-type) and phlebotomy-related donor complications per 10,000 collections.In 2006, 9 American Red Cross regions collected 145,678 whole blood donations from 16- and 17-year-olds, 113,307 from 18- and 19-year-olds, and 1,517,460 from donors aged 20 years or older. Complications were recorded in 15,632 (10.7%), 9359 (8.3%), and 42,987 (2.8%) donations in each corresponding age group. In a multivariate logistic regression model, young age had the strongest association with complications (odds ratio [OR], 3.05; 95% confidence interval [CI], 2.52-3.69; P < .001), followed by first-time donation status (OR, 2.63; 95% CI, 2.24-3.09; P < .001) and female sex (OR, 1.87; 95% CI, 1.62-2.16; P < .001). Infrequent but medically relevant complications, in particular physical injury from syncope-related falls, were significantly more likely in 16- and 17-year-old donors (86 events; 5.9/10,000 collections) compared with 18- and 19-year-old donors (27 events; 2.4/10,000 collections; OR, 2.48; 95% CI, 1.61-3.82) or adults aged 20 years or older (62 events; 0.4/10,000 collections; OR, 14.46; 95% CI, 10.43 -20.04). Sixteen-year-old donors who experienced even a minor complication were less likely to return to donate within 12 months than 16-year-olds who experienced uncomplicated donations (52% vs 73% return rate; OR, 0.40; 95% CI, 0.36-0.44).A higher incidence of donation-related complications and injury occurs among 16- and 17-year-old blood donors compared with older donors. The increasing dependence on recruiting and retaining young blood donors requires a committed approach to donor safety, especially at high school blood drives.","Adverse reactions to allogeneic whole blood donation by 16- and 17-year-olds."
"897","JAMA.4391","0.001",18505948,2008,"Depression occurs in more than half of patients who have experienced a stroke. Poststroke depression has been shown in numerous studies to be associated with both impaired recovery in activities of daily living and increased mortality. Prevention of depression thus represents a potentially important goal.To determine whether treatment with escitalopram or problem-solving therapy over the first year following acute stroke will decrease the number of depression cases that develop compared with placebo medication.A multisite randomized controlled trial for prevention of depression among 176 nondepressed patients was conducted within 3 months following acute stroke from July 9, 2003, to October 1, 2007. The 12-month trial included 3 groups: a double-blind placebo-controlled comparison of escitalopram (n = 59) with placebo (n = 58), and a nonblinded problem-solving therapy group (n = 59).The main outcome measure was the development of major or minor poststroke depression based on symptoms elicited by the Structured Clinical Interview for the Diagnostic and Statistical Manual of Mental Disorders (Fourth Edition) (DSM-IV) and the diagnostic criteria from DSM-IV for depression due to stroke with major depressive-like episode or minor depression (ie, research criteria).Patients who received placebo were significantly more likely to develop depression than individuals who received escitalopram (11 major and 2 minor cases of depression [22.4%] vs 3 major and 2 minor cases of depression [8.5%], adjusted hazard ratio [HR], 4.5; 95% confidence interval [CI], 2.4-8.2; P < .001) and also more likely than individuals who received problem-solving therapy (5 major and 2 minor cases of depression [11.9%], adjusted HR, 2.2; 95% CI, 1.4-3.5; P < .001). These results were adjusted for history of mood disorders and remained significant after considering possible confounders such as age, sex, treatment site, and severity of impairment in the model. Using an intention-to-treat conservative method of analyzing the data, which assumed that all 27 patients who did not start randomized treatment would have developed depression, and controlling for prior history of mood disorders, escitalopram was superior to placebo (23.1% vs 34.5%; adjusted HR, 2.2; 95% CI, 1.2-3.9; P = .007), while problem-solving therapy was not significantly better than placebo (30.5% vs 34.5%; adjusted HR, 1.1; 95% CI, 0.8-1.5; P = .51). Adverse events, including all-cause hospitalizations, nausea, and adverse effects associated with escitalopram were not significantly different between the 3 groups.In this study of nondepressed patients with recent stroke, the use of escitalopram or problem-solving therapy resulted in a significantly lower incidence of depression over 12 months of treatment compared with placebo, but problem-solving therapy did not achieve significant results over placebo using the intention-to-treat conservative method of analysis.clinicaltrials.gov Identifier: NCT00071643.","Escitalopram and problem-solving therapy for prevention of poststroke depression: a randomized controlled trial."
"898","JAMA.4401","0.001",18505948,2008,"Depression occurs in more than half of patients who have experienced a stroke. Poststroke depression has been shown in numerous studies to be associated with both impaired recovery in activities of daily living and increased mortality. Prevention of depression thus represents a potentially important goal.To determine whether treatment with escitalopram or problem-solving therapy over the first year following acute stroke will decrease the number of depression cases that develop compared with placebo medication.A multisite randomized controlled trial for prevention of depression among 176 nondepressed patients was conducted within 3 months following acute stroke from July 9, 2003, to October 1, 2007. The 12-month trial included 3 groups: a double-blind placebo-controlled comparison of escitalopram (n = 59) with placebo (n = 58), and a nonblinded problem-solving therapy group (n = 59).The main outcome measure was the development of major or minor poststroke depression based on symptoms elicited by the Structured Clinical Interview for the Diagnostic and Statistical Manual of Mental Disorders (Fourth Edition) (DSM-IV) and the diagnostic criteria from DSM-IV for depression due to stroke with major depressive-like episode or minor depression (ie, research criteria).Patients who received placebo were significantly more likely to develop depression than individuals who received escitalopram (11 major and 2 minor cases of depression [22.4%] vs 3 major and 2 minor cases of depression [8.5%], adjusted hazard ratio [HR], 4.5; 95% confidence interval [CI], 2.4-8.2; P < .001) and also more likely than individuals who received problem-solving therapy (5 major and 2 minor cases of depression [11.9%], adjusted HR, 2.2; 95% CI, 1.4-3.5; P < .001). These results were adjusted for history of mood disorders and remained significant after considering possible confounders such as age, sex, treatment site, and severity of impairment in the model. Using an intention-to-treat conservative method of analyzing the data, which assumed that all 27 patients who did not start randomized treatment would have developed depression, and controlling for prior history of mood disorders, escitalopram was superior to placebo (23.1% vs 34.5%; adjusted HR, 2.2; 95% CI, 1.2-3.9; P = .007), while problem-solving therapy was not significantly better than placebo (30.5% vs 34.5%; adjusted HR, 1.1; 95% CI, 0.8-1.5; P = .51). Adverse events, including all-cause hospitalizations, nausea, and adverse effects associated with escitalopram were not significantly different between the 3 groups.In this study of nondepressed patients with recent stroke, the use of escitalopram or problem-solving therapy resulted in a significantly lower incidence of depression over 12 months of treatment compared with placebo, but problem-solving therapy did not achieve significant results over placebo using the intention-to-treat conservative method of analysis.clinicaltrials.gov Identifier: NCT00071643.","Escitalopram and problem-solving therapy for prevention of poststroke depression: a randomized controlled trial."
"899","JAMA.4821","0.007",18505948,2008,"Depression occurs in more than half of patients who have experienced a stroke. Poststroke depression has been shown in numerous studies to be associated with both impaired recovery in activities of daily living and increased mortality. Prevention of depression thus represents a potentially important goal.To determine whether treatment with escitalopram or problem-solving therapy over the first year following acute stroke will decrease the number of depression cases that develop compared with placebo medication.A multisite randomized controlled trial for prevention of depression among 176 nondepressed patients was conducted within 3 months following acute stroke from July 9, 2003, to October 1, 2007. The 12-month trial included 3 groups: a double-blind placebo-controlled comparison of escitalopram (n = 59) with placebo (n = 58), and a nonblinded problem-solving therapy group (n = 59).The main outcome measure was the development of major or minor poststroke depression based on symptoms elicited by the Structured Clinical Interview for the Diagnostic and Statistical Manual of Mental Disorders (Fourth Edition) (DSM-IV) and the diagnostic criteria from DSM-IV for depression due to stroke with major depressive-like episode or minor depression (ie, research criteria).Patients who received placebo were significantly more likely to develop depression than individuals who received escitalopram (11 major and 2 minor cases of depression [22.4%] vs 3 major and 2 minor cases of depression [8.5%], adjusted hazard ratio [HR], 4.5; 95% confidence interval [CI], 2.4-8.2; P < .001) and also more likely than individuals who received problem-solving therapy (5 major and 2 minor cases of depression [11.9%], adjusted HR, 2.2; 95% CI, 1.4-3.5; P < .001). These results were adjusted for history of mood disorders and remained significant after considering possible confounders such as age, sex, treatment site, and severity of impairment in the model. Using an intention-to-treat conservative method of analyzing the data, which assumed that all 27 patients who did not start randomized treatment would have developed depression, and controlling for prior history of mood disorders, escitalopram was superior to placebo (23.1% vs 34.5%; adjusted HR, 2.2; 95% CI, 1.2-3.9; P = .007), while problem-solving therapy was not significantly better than placebo (30.5% vs 34.5%; adjusted HR, 1.1; 95% CI, 0.8-1.5; P = .51). Adverse events, including all-cause hospitalizations, nausea, and adverse effects associated with escitalopram were not significantly different between the 3 groups.In this study of nondepressed patients with recent stroke, the use of escitalopram or problem-solving therapy resulted in a significantly lower incidence of depression over 12 months of treatment compared with placebo, but problem-solving therapy did not achieve significant results over placebo using the intention-to-treat conservative method of analysis.clinicaltrials.gov Identifier: NCT00071643.","Escitalopram and problem-solving therapy for prevention of poststroke depression: a randomized controlled trial."
"900","JAMA.4831","0.51",18505948,2008,"Depression occurs in more than half of patients who have experienced a stroke. Poststroke depression has been shown in numerous studies to be associated with both impaired recovery in activities of daily living and increased mortality. Prevention of depression thus represents a potentially important goal.To determine whether treatment with escitalopram or problem-solving therapy over the first year following acute stroke will decrease the number of depression cases that develop compared with placebo medication.A multisite randomized controlled trial for prevention of depression among 176 nondepressed patients was conducted within 3 months following acute stroke from July 9, 2003, to October 1, 2007. The 12-month trial included 3 groups: a double-blind placebo-controlled comparison of escitalopram (n = 59) with placebo (n = 58), and a nonblinded problem-solving therapy group (n = 59).The main outcome measure was the development of major or minor poststroke depression based on symptoms elicited by the Structured Clinical Interview for the Diagnostic and Statistical Manual of Mental Disorders (Fourth Edition) (DSM-IV) and the diagnostic criteria from DSM-IV for depression due to stroke with major depressive-like episode or minor depression (ie, research criteria).Patients who received placebo were significantly more likely to develop depression than individuals who received escitalopram (11 major and 2 minor cases of depression [22.4%] vs 3 major and 2 minor cases of depression [8.5%], adjusted hazard ratio [HR], 4.5; 95% confidence interval [CI], 2.4-8.2; P < .001) and also more likely than individuals who received problem-solving therapy (5 major and 2 minor cases of depression [11.9%], adjusted HR, 2.2; 95% CI, 1.4-3.5; P < .001). These results were adjusted for history of mood disorders and remained significant after considering possible confounders such as age, sex, treatment site, and severity of impairment in the model. Using an intention-to-treat conservative method of analyzing the data, which assumed that all 27 patients who did not start randomized treatment would have developed depression, and controlling for prior history of mood disorders, escitalopram was superior to placebo (23.1% vs 34.5%; adjusted HR, 2.2; 95% CI, 1.2-3.9; P = .007), while problem-solving therapy was not significantly better than placebo (30.5% vs 34.5%; adjusted HR, 1.1; 95% CI, 0.8-1.5; P = .51). Adverse events, including all-cause hospitalizations, nausea, and adverse effects associated with escitalopram were not significantly different between the 3 groups.In this study of nondepressed patients with recent stroke, the use of escitalopram or problem-solving therapy resulted in a significantly lower incidence of depression over 12 months of treatment compared with placebo, but problem-solving therapy did not achieve significant results over placebo using the intention-to-treat conservative method of analysis.clinicaltrials.gov Identifier: NCT00071643.","Escitalopram and problem-solving therapy for prevention of poststroke depression: a randomized controlled trial."
"901","JAMA.4381","0.001",18505951,2008,"Based on concerns about the risk of infection, the jugular site is often preferred over the femoral site for short-term dialysis vascular access.To determine whether jugular catheterization decreases the risk of nosocomial complications compared with femoral catheterization.A concealed, randomized, multicenter, evaluator-blinded, parallel-group trial (the Cathedia Study) of 750 patients from a network of 9 tertiary care university medical centers and 3 general hospitals in France conducted between May 2004 and May 2007. The severely ill, bed-bound adults had a body mass index (BMI) of less than 45 and required a first catheter insertion for renal replacement therapy.Patients were randomized to receive jugular or femoral vein catheterization by operators experienced in placement at both sites.Rates of infectious complications, defined as catheter colonization on removal (primary end point), and catheter-related bloodstream infection.Patient and catheter characteristics, including duration of catheterization, were similar in both groups. More hematomas occurred in the jugular group than in the femoral group (13/366 patients [3.6%] vs 4/370 patients [1.1%], respectively; P = .03). The risk of catheter colonization at removal did not differ significantly between the femoral and jugular groups (incidence of 40.8 vs 35.7 per 1000 catheter-days; hazard ratio [HR], 0.85; 95% confidence interval [CI], 0.62-1.16; P = .31). A prespecified subgroup analysis demonstrated significant qualitative heterogeneity by BMI (P for the interaction term < .001). Jugular catheterization significantly increased incidence of catheter colonization vs femoral catheterization (45.4 vs 23.7 per 1000 catheter-days; HR, 2.10; 95% CI, 1.13-3.91; P = .017) in the lowest tercile (BMI <24.2), whereas jugular catheterization significantly decreased this incidence (24.5 vs 50.9 per 1000 catheter-days; HR, 0.40; 95% CI, 0.23-0.69; P < .001) in the highest tercile (BMI >28.4). The rate of catheter-related bloodstream infection was similar in both groups (2.3 vs 1.5 per 1000 catheter-days, respectively; P = .42).Jugular venous catheterization access does not appear to reduce the risk of infection compared with femoral access, except among adults with a high BMI, and may have a higher risk of hematoma.clinicaltrials.gov Identifier: NCT00277888.","Femoral vs jugular venous catheterization and risk of nosocomial events in adults requiring acute renal replacement therapy: a randomized controlled trial."
"902","JAMA.4791","0.31",18505951,2008,"Based on concerns about the risk of infection, the jugular site is often preferred over the femoral site for short-term dialysis vascular access.To determine whether jugular catheterization decreases the risk of nosocomial complications compared with femoral catheterization.A concealed, randomized, multicenter, evaluator-blinded, parallel-group trial (the Cathedia Study) of 750 patients from a network of 9 tertiary care university medical centers and 3 general hospitals in France conducted between May 2004 and May 2007. The severely ill, bed-bound adults had a body mass index (BMI) of less than 45 and required a first catheter insertion for renal replacement therapy.Patients were randomized to receive jugular or femoral vein catheterization by operators experienced in placement at both sites.Rates of infectious complications, defined as catheter colonization on removal (primary end point), and catheter-related bloodstream infection.Patient and catheter characteristics, including duration of catheterization, were similar in both groups. More hematomas occurred in the jugular group than in the femoral group (13/366 patients [3.6%] vs 4/370 patients [1.1%], respectively; P = .03). The risk of catheter colonization at removal did not differ significantly between the femoral and jugular groups (incidence of 40.8 vs 35.7 per 1000 catheter-days; hazard ratio [HR], 0.85; 95% confidence interval [CI], 0.62-1.16; P = .31). A prespecified subgroup analysis demonstrated significant qualitative heterogeneity by BMI (P for the interaction term < .001). Jugular catheterization significantly increased incidence of catheter colonization vs femoral catheterization (45.4 vs 23.7 per 1000 catheter-days; HR, 2.10; 95% CI, 1.13-3.91; P = .017) in the lowest tercile (BMI <24.2), whereas jugular catheterization significantly decreased this incidence (24.5 vs 50.9 per 1000 catheter-days; HR, 0.40; 95% CI, 0.23-0.69; P < .001) in the highest tercile (BMI >28.4). The rate of catheter-related bloodstream infection was similar in both groups (2.3 vs 1.5 per 1000 catheter-days, respectively; P = .42).Jugular venous catheterization access does not appear to reduce the risk of infection compared with femoral access, except among adults with a high BMI, and may have a higher risk of hematoma.clinicaltrials.gov Identifier: NCT00277888.","Femoral vs jugular venous catheterization and risk of nosocomial events in adults requiring acute renal replacement therapy: a randomized controlled trial."
"903","JAMA.4801","0.017",18505951,2008,"Based on concerns about the risk of infection, the jugular site is often preferred over the femoral site for short-term dialysis vascular access.To determine whether jugular catheterization decreases the risk of nosocomial complications compared with femoral catheterization.A concealed, randomized, multicenter, evaluator-blinded, parallel-group trial (the Cathedia Study) of 750 patients from a network of 9 tertiary care university medical centers and 3 general hospitals in France conducted between May 2004 and May 2007. The severely ill, bed-bound adults had a body mass index (BMI) of less than 45 and required a first catheter insertion for renal replacement therapy.Patients were randomized to receive jugular or femoral vein catheterization by operators experienced in placement at both sites.Rates of infectious complications, defined as catheter colonization on removal (primary end point), and catheter-related bloodstream infection.Patient and catheter characteristics, including duration of catheterization, were similar in both groups. More hematomas occurred in the jugular group than in the femoral group (13/366 patients [3.6%] vs 4/370 patients [1.1%], respectively; P = .03). The risk of catheter colonization at removal did not differ significantly between the femoral and jugular groups (incidence of 40.8 vs 35.7 per 1000 catheter-days; hazard ratio [HR], 0.85; 95% confidence interval [CI], 0.62-1.16; P = .31). A prespecified subgroup analysis demonstrated significant qualitative heterogeneity by BMI (P for the interaction term < .001). Jugular catheterization significantly increased incidence of catheter colonization vs femoral catheterization (45.4 vs 23.7 per 1000 catheter-days; HR, 2.10; 95% CI, 1.13-3.91; P = .017) in the lowest tercile (BMI <24.2), whereas jugular catheterization significantly decreased this incidence (24.5 vs 50.9 per 1000 catheter-days; HR, 0.40; 95% CI, 0.23-0.69; P < .001) in the highest tercile (BMI >28.4). The rate of catheter-related bloodstream infection was similar in both groups (2.3 vs 1.5 per 1000 catheter-days, respectively; P = .42).Jugular venous catheterization access does not appear to reduce the risk of infection compared with femoral access, except among adults with a high BMI, and may have a higher risk of hematoma.clinicaltrials.gov Identifier: NCT00277888.","Femoral vs jugular venous catheterization and risk of nosocomial events in adults requiring acute renal replacement therapy: a randomized controlled trial."
"904","JAMA.470","1.90E-14",18505952,2008,"Continuing advances in genotyping technologies and the inclusion of DNA collection in observational studies have resulted in an increasing number of genetic association studies.To evaluate the overall progress and contribution of candidate gene association studies to current understanding of the genetic susceptibility to cancer.We systematically examined the results of meta-analyses and pooled analyses for genetic polymorphisms and cancer risk published through March 2008.We identified 161 meta-analyses and pooled analyses, encompassing 18 cancer sites and 99 genes. Analyses had to meet the following criteria: include at least 500 cases, have cancer risk as outcome, not be focused on HLA antigen genetic markers, and be published in English.Information on cancer site, gene name, variant, point estimate and 95% confidence interval (CI), allelic frequency, number of studies and cases, tests of study heterogeneity, and publication bias were extracted by 1 investigator and reviewed by other investigators.These 161 analyses evaluated 344 gene-variant cancer associations and included on average 7.3 studies and 3551 cases (range, 508-19 729 cases) per investigated association. The summary odds ratio (OR) for 98 (28%) statistically significant associations (P value <.05) were further evaluated by estimating the false-positive report probability (FPRP) at a given prior probability and statistical power. At a prior probability level of 0.001 and statistical power to detect an OR of 1.5, 13 gene-variant cancer associations remained noteworthy (FPRP <0.2). Assuming a very low prior probability of 0.000001, similar to a probability assumed for a randomly selected single-nucleotide polymorphism in a genome-wide association study, and statistical power to detect an OR of 1.5, 4 associations were considered noteworthy as denoted by an FPRP value <0.2: GSTM1 null and bladder cancer (OR, 1.5; 95% CI, 1.3-1.6; P = 1.9 x 10(-14)), NAT2 slow acetylator and bladder cancer (OR, 1.46; 95% CI, 1.26-1.68; P = 2.5 x 10(-7)), MTHFR C677T and gastric cancer (OR, 1.52; 95% CI, 1.31-1.77; P = 4.9 x 10(-8)), and GSTM1 null and acute leukemia (OR, 1.20; 95% CI, 1.14-1.25; P = 8.6 x 10(-15)). When the OR used to determine statistical power was lowered to 1.2, 2 of the 4 noteworthy associations remained so: GSTM1 null with bladder cancer and acute leukemia.In this review of candidate gene association studies, nearly one-third of gene-variant cancer associations were statistically significant, with variants in genes encoding for metabolizing enzymes among the most consistent and highly significant associations.","Genetic susceptibility to cancer: the role of polymorphisms in candidate genes."
"905","JAMA.471","2.50E-07",18505952,2008,"Continuing advances in genotyping technologies and the inclusion of DNA collection in observational studies have resulted in an increasing number of genetic association studies.To evaluate the overall progress and contribution of candidate gene association studies to current understanding of the genetic susceptibility to cancer.We systematically examined the results of meta-analyses and pooled analyses for genetic polymorphisms and cancer risk published through March 2008.We identified 161 meta-analyses and pooled analyses, encompassing 18 cancer sites and 99 genes. Analyses had to meet the following criteria: include at least 500 cases, have cancer risk as outcome, not be focused on HLA antigen genetic markers, and be published in English.Information on cancer site, gene name, variant, point estimate and 95% confidence interval (CI), allelic frequency, number of studies and cases, tests of study heterogeneity, and publication bias were extracted by 1 investigator and reviewed by other investigators.These 161 analyses evaluated 344 gene-variant cancer associations and included on average 7.3 studies and 3551 cases (range, 508-19 729 cases) per investigated association. The summary odds ratio (OR) for 98 (28%) statistically significant associations (P value <.05) were further evaluated by estimating the false-positive report probability (FPRP) at a given prior probability and statistical power. At a prior probability level of 0.001 and statistical power to detect an OR of 1.5, 13 gene-variant cancer associations remained noteworthy (FPRP <0.2). Assuming a very low prior probability of 0.000001, similar to a probability assumed for a randomly selected single-nucleotide polymorphism in a genome-wide association study, and statistical power to detect an OR of 1.5, 4 associations were considered noteworthy as denoted by an FPRP value <0.2: GSTM1 null and bladder cancer (OR, 1.5; 95% CI, 1.3-1.6; P = 1.9 x 10(-14)), NAT2 slow acetylator and bladder cancer (OR, 1.46; 95% CI, 1.26-1.68; P = 2.5 x 10(-7)), MTHFR C677T and gastric cancer (OR, 1.52; 95% CI, 1.31-1.77; P = 4.9 x 10(-8)), and GSTM1 null and acute leukemia (OR, 1.20; 95% CI, 1.14-1.25; P = 8.6 x 10(-15)). When the OR used to determine statistical power was lowered to 1.2, 2 of the 4 noteworthy associations remained so: GSTM1 null with bladder cancer and acute leukemia.In this review of candidate gene association studies, nearly one-third of gene-variant cancer associations were statistically significant, with variants in genes encoding for metabolizing enzymes among the most consistent and highly significant associations.","Genetic susceptibility to cancer: the role of polymorphisms in candidate genes."
"906","JAMA.472","4.90E-08",18505952,2008,"Continuing advances in genotyping technologies and the inclusion of DNA collection in observational studies have resulted in an increasing number of genetic association studies.To evaluate the overall progress and contribution of candidate gene association studies to current understanding of the genetic susceptibility to cancer.We systematically examined the results of meta-analyses and pooled analyses for genetic polymorphisms and cancer risk published through March 2008.We identified 161 meta-analyses and pooled analyses, encompassing 18 cancer sites and 99 genes. Analyses had to meet the following criteria: include at least 500 cases, have cancer risk as outcome, not be focused on HLA antigen genetic markers, and be published in English.Information on cancer site, gene name, variant, point estimate and 95% confidence interval (CI), allelic frequency, number of studies and cases, tests of study heterogeneity, and publication bias were extracted by 1 investigator and reviewed by other investigators.These 161 analyses evaluated 344 gene-variant cancer associations and included on average 7.3 studies and 3551 cases (range, 508-19 729 cases) per investigated association. The summary odds ratio (OR) for 98 (28%) statistically significant associations (P value <.05) were further evaluated by estimating the false-positive report probability (FPRP) at a given prior probability and statistical power. At a prior probability level of 0.001 and statistical power to detect an OR of 1.5, 13 gene-variant cancer associations remained noteworthy (FPRP <0.2). Assuming a very low prior probability of 0.000001, similar to a probability assumed for a randomly selected single-nucleotide polymorphism in a genome-wide association study, and statistical power to detect an OR of 1.5, 4 associations were considered noteworthy as denoted by an FPRP value <0.2: GSTM1 null and bladder cancer (OR, 1.5; 95% CI, 1.3-1.6; P = 1.9 x 10(-14)), NAT2 slow acetylator and bladder cancer (OR, 1.46; 95% CI, 1.26-1.68; P = 2.5 x 10(-7)), MTHFR C677T and gastric cancer (OR, 1.52; 95% CI, 1.31-1.77; P = 4.9 x 10(-8)), and GSTM1 null and acute leukemia (OR, 1.20; 95% CI, 1.14-1.25; P = 8.6 x 10(-15)). When the OR used to determine statistical power was lowered to 1.2, 2 of the 4 noteworthy associations remained so: GSTM1 null with bladder cancer and acute leukemia.In this review of candidate gene association studies, nearly one-third of gene-variant cancer associations were statistically significant, with variants in genes encoding for metabolizing enzymes among the most consistent and highly significant associations.","Genetic susceptibility to cancer: the role of polymorphisms in candidate genes."
"907","JAMA.473","8.60E-15",18505952,2008,"Continuing advances in genotyping technologies and the inclusion of DNA collection in observational studies have resulted in an increasing number of genetic association studies.To evaluate the overall progress and contribution of candidate gene association studies to current understanding of the genetic susceptibility to cancer.We systematically examined the results of meta-analyses and pooled analyses for genetic polymorphisms and cancer risk published through March 2008.We identified 161 meta-analyses and pooled analyses, encompassing 18 cancer sites and 99 genes. Analyses had to meet the following criteria: include at least 500 cases, have cancer risk as outcome, not be focused on HLA antigen genetic markers, and be published in English.Information on cancer site, gene name, variant, point estimate and 95% confidence interval (CI), allelic frequency, number of studies and cases, tests of study heterogeneity, and publication bias were extracted by 1 investigator and reviewed by other investigators.These 161 analyses evaluated 344 gene-variant cancer associations and included on average 7.3 studies and 3551 cases (range, 508-19 729 cases) per investigated association. The summary odds ratio (OR) for 98 (28%) statistically significant associations (P value <.05) were further evaluated by estimating the false-positive report probability (FPRP) at a given prior probability and statistical power. At a prior probability level of 0.001 and statistical power to detect an OR of 1.5, 13 gene-variant cancer associations remained noteworthy (FPRP <0.2). Assuming a very low prior probability of 0.000001, similar to a probability assumed for a randomly selected single-nucleotide polymorphism in a genome-wide association study, and statistical power to detect an OR of 1.5, 4 associations were considered noteworthy as denoted by an FPRP value <0.2: GSTM1 null and bladder cancer (OR, 1.5; 95% CI, 1.3-1.6; P = 1.9 x 10(-14)), NAT2 slow acetylator and bladder cancer (OR, 1.46; 95% CI, 1.26-1.68; P = 2.5 x 10(-7)), MTHFR C677T and gastric cancer (OR, 1.52; 95% CI, 1.31-1.77; P = 4.9 x 10(-8)), and GSTM1 null and acute leukemia (OR, 1.20; 95% CI, 1.14-1.25; P = 8.6 x 10(-15)). When the OR used to determine statistical power was lowered to 1.2, 2 of the 4 noteworthy associations remained so: GSTM1 null with bladder cancer and acute leukemia.In this review of candidate gene association studies, nearly one-third of gene-variant cancer associations were statistically significant, with variants in genes encoding for metabolizing enzymes among the most consistent and highly significant associations.","Genetic susceptibility to cancer: the role of polymorphisms in candidate genes."
"908","Lancet.1471","0.02",18539223,2008,"Percutaneous coronary intervention (PCI) for ST-elevation myocardial infarction can be complicated by spontaneous or angioplasty-induced embolisation of atherothrombotic material. Distal blockage induces microvascular obstruction and can result in less than optimum reperfusion of viable myocardium. The Thrombus Aspiration during Percutaneous coronary intervention in Acute myocardial infarction Study (TAPAS) found that thrombus aspiration resulted in improved myocardial reperfusion compared with conventional PCI, but whether this benefit improves clinical outcome is unknown. We aimed to investigate whether the early efficacy of thrombus aspiration seen in TAPAS translated into clinical benefit after 1 year.Patients with ST-elevation myocardial infarction enrolled at the University Medical Centre Groningen were randomly assigned in a 1:1 ratio to either thrombus aspiration or conventional treatment, before undergoing initial coronary angiography. Exclusion criteria were rescue PCI after thrombolysis and known existence of a concomitant disease with life expectancy less than 6 months. Of the 1071 patients enrolled between January, 2005, and December, 2006, vital status at or beyond 1 year after randomisation was available for 1060 (99%). The primary endpoint was cardiac death or non-fatal reinfarction after 1 year, and analysis was by intention to treat. The TAPAS trial is registered with Current Controlled Trials number ISRCTN16716833.Cardiac death at 1 year was 3.6% (19 of 535 patients) in the thrombus aspiration group and 6.7% (36 of 536) in the conventional PCI group (hazard ratio [HR] 1.93; 95% CI 1.11-3.37; p=0.020). 1-year cardiac death or non-fatal reinfarction occurred in 5.6% (30 of 535) of patients in the thrombus aspiration group and 9.9% (53 of 536) of patients in the conventional PCI group (HR 1.81; 95% CI 1.16-2.84; p=0.009).Compared with conventional PCI, thrombus aspiration before stenting of the infarcted artery seems to improve the 1-year clinical outcome after PCI for ST-elevation myocardial infarction.","Cardiac death and reinfarction after 1 year in the Thrombus Aspiration during Percutaneous coronary intervention in Acute myocardial infarction Study (TAPAS): a 1-year follow-up study."
"909","Lancet.1471","0.009",18539223,2008,"Percutaneous coronary intervention (PCI) for ST-elevation myocardial infarction can be complicated by spontaneous or angioplasty-induced embolisation of atherothrombotic material. Distal blockage induces microvascular obstruction and can result in less than optimum reperfusion of viable myocardium. The Thrombus Aspiration during Percutaneous coronary intervention in Acute myocardial infarction Study (TAPAS) found that thrombus aspiration resulted in improved myocardial reperfusion compared with conventional PCI, but whether this benefit improves clinical outcome is unknown. We aimed to investigate whether the early efficacy of thrombus aspiration seen in TAPAS translated into clinical benefit after 1 year.Patients with ST-elevation myocardial infarction enrolled at the University Medical Centre Groningen were randomly assigned in a 1:1 ratio to either thrombus aspiration or conventional treatment, before undergoing initial coronary angiography. Exclusion criteria were rescue PCI after thrombolysis and known existence of a concomitant disease with life expectancy less than 6 months. Of the 1071 patients enrolled between January, 2005, and December, 2006, vital status at or beyond 1 year after randomisation was available for 1060 (99%). The primary endpoint was cardiac death or non-fatal reinfarction after 1 year, and analysis was by intention to treat. The TAPAS trial is registered with Current Controlled Trials number ISRCTN16716833.Cardiac death at 1 year was 3.6% (19 of 535 patients) in the thrombus aspiration group and 6.7% (36 of 536) in the conventional PCI group (hazard ratio [HR] 1.93; 95% CI 1.11-3.37; p=0.020). 1-year cardiac death or non-fatal reinfarction occurred in 5.6% (30 of 535) of patients in the thrombus aspiration group and 9.9% (53 of 536) of patients in the conventional PCI group (HR 1.81; 95% CI 1.16-2.84; p=0.009).Compared with conventional PCI, thrombus aspiration before stenting of the infarcted artery seems to improve the 1-year clinical outcome after PCI for ST-elevation myocardial infarction.","Cardiac death and reinfarction after 1 year in the Thrombus Aspiration during Percutaneous coronary intervention in Acute myocardial infarction Study (TAPAS): a 1-year follow-up study."
"910","JAMA.4371","0.001",18560003,2008,"Biochemical disease recurrence after radical prostatectomy often prompts salvage radiotherapy, but no studies to date have had sufficient numbers of patients or follow-up to determine whether radiotherapy improves survival, and if so, the subgroup of men most likely to benefit.To quantify the relative improvement in prostate cancer-specific survival of salvage radiotherapy vs no therapy after biochemical recurrence following prostatectomy, and to identify subgroups for whom salvage treatment is most beneficial.Retrospective analysis of a cohort of 635 US men undergoing prostatectomy from 1982-2004, followed up through December 28, 2007, who experienced biochemical and/or local recurrence and received no salvage treatment (n = 397), salvage radiotherapy alone (n = 160), or salvage radiotherapy combined with hormonal therapy (n = 78).Prostate cancer-specific survival defined from time of recurrence until death from disease.With a median follow-up of 6 years after recurrence and 9 years after prostatectomy, 116 men (18%) died from prostate cancer, including 89 (22%) who received no salvage treatment, 18 (11%) who received salvage radiotherapy alone, and 9 (12%) who received salvage radiotherapy and hormonal therapy. Salvage radiotherapy alone was associated with a significant 3-fold increase in prostate cancer-specific survival relative to those who received no salvage treatment (hazard ratio [HR], 0.32 [95% confidence interval {CI}, 0.19-0.54]; P<.001). Addition of hormonal therapy to salvage radiotherapy was not associated with any additional increase in prostate cancer-specific survival (HR, 0.34 [95% CI, 0.17-0.69]; P = .003). The increase in prostate cancer-specific survival associated with salvage radiotherapy was limited to men with a prostate-specific antigen doubling time of less than 6 months and remained after adjustment for pathological stage and other established prognostic factors. Salvage radiotherapy initiated more than 2 years after recurrence provided no significant increase in prostate cancer-specific survival. Men whose prostate-specific antigen level never became undetectable after salvage radiotherapy did not experience a significant increase in prostate cancer-specific survival. Salvage radiotherapy also was associated with a significant increase in overall survival.Salvage radiotherapy administered within 2 years of biochemical recurrence was associated with a significant increase in prostate cancer-specific survival among men with a prostate-specific antigen doubling time of less than 6 months, independent of other prognostic features such as pathological stage or Gleason score. These preliminary findings should be validated in other settings, and ultimately, in a randomized controlled trial.","Prostate cancer-specific survival following salvage radiotherapy vs observation in men with biochemical recurrence after radical prostatectomy."
"911","JAMA.4771","0.003",18560003,2008,"Biochemical disease recurrence after radical prostatectomy often prompts salvage radiotherapy, but no studies to date have had sufficient numbers of patients or follow-up to determine whether radiotherapy improves survival, and if so, the subgroup of men most likely to benefit.To quantify the relative improvement in prostate cancer-specific survival of salvage radiotherapy vs no therapy after biochemical recurrence following prostatectomy, and to identify subgroups for whom salvage treatment is most beneficial.Retrospective analysis of a cohort of 635 US men undergoing prostatectomy from 1982-2004, followed up through December 28, 2007, who experienced biochemical and/or local recurrence and received no salvage treatment (n = 397), salvage radiotherapy alone (n = 160), or salvage radiotherapy combined with hormonal therapy (n = 78).Prostate cancer-specific survival defined from time of recurrence until death from disease.With a median follow-up of 6 years after recurrence and 9 years after prostatectomy, 116 men (18%) died from prostate cancer, including 89 (22%) who received no salvage treatment, 18 (11%) who received salvage radiotherapy alone, and 9 (12%) who received salvage radiotherapy and hormonal therapy. Salvage radiotherapy alone was associated with a significant 3-fold increase in prostate cancer-specific survival relative to those who received no salvage treatment (hazard ratio [HR], 0.32 [95% confidence interval {CI}, 0.19-0.54]; P<.001). Addition of hormonal therapy to salvage radiotherapy was not associated with any additional increase in prostate cancer-specific survival (HR, 0.34 [95% CI, 0.17-0.69]; P = .003). The increase in prostate cancer-specific survival associated with salvage radiotherapy was limited to men with a prostate-specific antigen doubling time of less than 6 months and remained after adjustment for pathological stage and other established prognostic factors. Salvage radiotherapy initiated more than 2 years after recurrence provided no significant increase in prostate cancer-specific survival. Men whose prostate-specific antigen level never became undetectable after salvage radiotherapy did not experience a significant increase in prostate cancer-specific survival. Salvage radiotherapy also was associated with a significant increase in overall survival.Salvage radiotherapy administered within 2 years of biochemical recurrence was associated with a significant increase in prostate cancer-specific survival among men with a prostate-specific antigen doubling time of less than 6 months, independent of other prognostic features such as pathological stage or Gleason score. These preliminary findings should be validated in other settings, and ultimately, in a randomized controlled trial.","Prostate cancer-specific survival following salvage radiotherapy vs observation in men with biochemical recurrence after radical prostatectomy."
"912","Lancet.1111","0.001",18603158,2008,"In haematopoietic stem-cell transplantation, male recipients of female grafts have an increased risk of graft-versus-host disease and female recipients have both an increased risk of rejection of male grafts and of specific T-cell and antibody reactivity against H-Y encoded gene products. By contrast, in kidney transplantation, the role of H-Y as a minor histocompatibility antigen has been disputed. We aimed to investigate whether an immunological H-Y effect occurs in kidney transplantation.We did a retrospective cohort study between 1985 and 2004 in 195 516 recipients of allografts from deceased donors. We used multivariate statistical methods to compare graft survival and death-censored graft survival rates for female and male donor kidneys in female and male recipients at 1 and 10 years.Graft loss was more common with kidneys from female donors than with those from male donors (p<0.001) after both 1 and 10 years. Female recipients had a lower rate of graft failure between the end of the first year and the end of the tenth year (p<0.001). Compared with all other combinations of sex, transplantation of male donor kidneys into female recipients was associated with an increased risk of graft failure during the first year (hazard ratio [HR] 1.08, 95% CI 1.03-1.14, p=0.003; death censored HR 1.11, 1.04-1.19, p=0.003) and between 2 and 10 years (HR 1.06, 1.01-1.10, p=0.008; death censored HR 1.10, 1.05-1.16, p<0.001).H-Y minor histocompatibility affects human kidney transplantation.","H-Y as a minor histocompatibility antigen in kidney transplantation: a retrospective cohort study."
"913","Lancet.1441","0.003",18603158,2008,"In haematopoietic stem-cell transplantation, male recipients of female grafts have an increased risk of graft-versus-host disease and female recipients have both an increased risk of rejection of male grafts and of specific T-cell and antibody reactivity against H-Y encoded gene products. By contrast, in kidney transplantation, the role of H-Y as a minor histocompatibility antigen has been disputed. We aimed to investigate whether an immunological H-Y effect occurs in kidney transplantation.We did a retrospective cohort study between 1985 and 2004 in 195 516 recipients of allografts from deceased donors. We used multivariate statistical methods to compare graft survival and death-censored graft survival rates for female and male donor kidneys in female and male recipients at 1 and 10 years.Graft loss was more common with kidneys from female donors than with those from male donors (p<0.001) after both 1 and 10 years. Female recipients had a lower rate of graft failure between the end of the first year and the end of the tenth year (p<0.001). Compared with all other combinations of sex, transplantation of male donor kidneys into female recipients was associated with an increased risk of graft failure during the first year (hazard ratio [HR] 1.08, 95% CI 1.03-1.14, p=0.003; death censored HR 1.11, 1.04-1.19, p=0.003) and between 2 and 10 years (HR 1.06, 1.01-1.10, p=0.008; death censored HR 1.10, 1.05-1.16, p<0.001).H-Y minor histocompatibility affects human kidney transplantation.","H-Y as a minor histocompatibility antigen in kidney transplantation: a retrospective cohort study."
"914","Lancet.1451","0.003",18603158,2008,"In haematopoietic stem-cell transplantation, male recipients of female grafts have an increased risk of graft-versus-host disease and female recipients have both an increased risk of rejection of male grafts and of specific T-cell and antibody reactivity against H-Y encoded gene products. By contrast, in kidney transplantation, the role of H-Y as a minor histocompatibility antigen has been disputed. We aimed to investigate whether an immunological H-Y effect occurs in kidney transplantation.We did a retrospective cohort study between 1985 and 2004 in 195 516 recipients of allografts from deceased donors. We used multivariate statistical methods to compare graft survival and death-censored graft survival rates for female and male donor kidneys in female and male recipients at 1 and 10 years.Graft loss was more common with kidneys from female donors than with those from male donors (p<0.001) after both 1 and 10 years. Female recipients had a lower rate of graft failure between the end of the first year and the end of the tenth year (p<0.001). Compared with all other combinations of sex, transplantation of male donor kidneys into female recipients was associated with an increased risk of graft failure during the first year (hazard ratio [HR] 1.08, 95% CI 1.03-1.14, p=0.003; death censored HR 1.11, 1.04-1.19, p=0.003) and between 2 and 10 years (HR 1.06, 1.01-1.10, p=0.008; death censored HR 1.10, 1.05-1.16, p<0.001).H-Y minor histocompatibility affects human kidney transplantation.","H-Y as a minor histocompatibility antigen in kidney transplantation: a retrospective cohort study."
"915","Lancet.1461","0.008",18603158,2008,"In haematopoietic stem-cell transplantation, male recipients of female grafts have an increased risk of graft-versus-host disease and female recipients have both an increased risk of rejection of male grafts and of specific T-cell and antibody reactivity against H-Y encoded gene products. By contrast, in kidney transplantation, the role of H-Y as a minor histocompatibility antigen has been disputed. We aimed to investigate whether an immunological H-Y effect occurs in kidney transplantation.We did a retrospective cohort study between 1985 and 2004 in 195 516 recipients of allografts from deceased donors. We used multivariate statistical methods to compare graft survival and death-censored graft survival rates for female and male donor kidneys in female and male recipients at 1 and 10 years.Graft loss was more common with kidneys from female donors than with those from male donors (p<0.001) after both 1 and 10 years. Female recipients had a lower rate of graft failure between the end of the first year and the end of the tenth year (p<0.001). Compared with all other combinations of sex, transplantation of male donor kidneys into female recipients was associated with an increased risk of graft failure during the first year (hazard ratio [HR] 1.08, 95% CI 1.03-1.14, p=0.003; death censored HR 1.11, 1.04-1.19, p=0.003) and between 2 and 10 years (HR 1.06, 1.01-1.10, p=0.008; death censored HR 1.10, 1.05-1.16, p<0.001).H-Y minor histocompatibility affects human kidney transplantation.","H-Y as a minor histocompatibility antigen in kidney transplantation: a retrospective cohort study."
"916","Lancet.1081","1.00E-04",18603291,2008,"Extracorporeal life-support as an adjunct to cardiac resuscitation has shown encouraging outcomes in patients with cardiac arrest. However, there is little evidence about the benefit of the procedure compared with conventional cardiopulmonary resuscitation (CPR), especially when continued for more than 10 min. We aimed to assess whether extracorporeal CPR was better than conventional CPR for patients with in-hospital cardiac arrest of cardiac origin.We did a 3-year prospective observational study on the use of extracorporeal life-support for patients aged 18-75 years with witnessed in-hospital cardiac arrest of cardiac origin undergoing CPR of more than 10 min compared with patients receiving conventional CPR. A matching process based on propensity-score was done to equalise potential prognostic factors in both groups, and to formulate a balanced 1:1 matched cohort study. The primary endpoint was survival to hospital discharge, and analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00173615.Of the 975 patients with in-hospital cardiac arrest events who underwent CPR for longer than 10 min, 113 were enrolled in the conventional CPR group and 59 were enrolled in the extracorporeal CPR group. Unmatched patients who underwent extracorporeal CPR had a higher survival rate to discharge (log-rank p<0.0001) and a better 1-year survival than those who received conventional CPR (log rank p=0.007). Between the propensity-score matched groups, there was still a significant difference in survival to discharge (hazard ratio [HR] 0.51, 95% CI 0.35-0.74, p<0.0001), 30-day survival (HR 0.47, 95% CI 0.28-0.77, p=0.003), and 1-year survival (HR 0.53, 95% CI 0.33-0.83, p=0.006) favouring extracorporeal CPR over conventional CPR.Extracorporeal CPR had a short-term and long-term survival benefit over conventional CPR in patients with in-hospital cardiac arrest of cardiac origin.","Cardiopulmonary resuscitation with assisted extracorporeal life-support versus conventional cardiopulmonary resuscitation in adults with in-hospital cardiac arrest: an observational study and propensity analysis."
"917","Lancet.1421","0.003",18603291,2008,"Extracorporeal life-support as an adjunct to cardiac resuscitation has shown encouraging outcomes in patients with cardiac arrest. However, there is little evidence about the benefit of the procedure compared with conventional cardiopulmonary resuscitation (CPR), especially when continued for more than 10 min. We aimed to assess whether extracorporeal CPR was better than conventional CPR for patients with in-hospital cardiac arrest of cardiac origin.We did a 3-year prospective observational study on the use of extracorporeal life-support for patients aged 18-75 years with witnessed in-hospital cardiac arrest of cardiac origin undergoing CPR of more than 10 min compared with patients receiving conventional CPR. A matching process based on propensity-score was done to equalise potential prognostic factors in both groups, and to formulate a balanced 1:1 matched cohort study. The primary endpoint was survival to hospital discharge, and analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00173615.Of the 975 patients with in-hospital cardiac arrest events who underwent CPR for longer than 10 min, 113 were enrolled in the conventional CPR group and 59 were enrolled in the extracorporeal CPR group. Unmatched patients who underwent extracorporeal CPR had a higher survival rate to discharge (log-rank p<0.0001) and a better 1-year survival than those who received conventional CPR (log rank p=0.007). Between the propensity-score matched groups, there was still a significant difference in survival to discharge (hazard ratio [HR] 0.51, 95% CI 0.35-0.74, p<0.0001), 30-day survival (HR 0.47, 95% CI 0.28-0.77, p=0.003), and 1-year survival (HR 0.53, 95% CI 0.33-0.83, p=0.006) favouring extracorporeal CPR over conventional CPR.Extracorporeal CPR had a short-term and long-term survival benefit over conventional CPR in patients with in-hospital cardiac arrest of cardiac origin.","Cardiopulmonary resuscitation with assisted extracorporeal life-support versus conventional cardiopulmonary resuscitation in adults with in-hospital cardiac arrest: an observational study and propensity analysis."
"918","Lancet.1431","0.006",18603291,2008,"Extracorporeal life-support as an adjunct to cardiac resuscitation has shown encouraging outcomes in patients with cardiac arrest. However, there is little evidence about the benefit of the procedure compared with conventional cardiopulmonary resuscitation (CPR), especially when continued for more than 10 min. We aimed to assess whether extracorporeal CPR was better than conventional CPR for patients with in-hospital cardiac arrest of cardiac origin.We did a 3-year prospective observational study on the use of extracorporeal life-support for patients aged 18-75 years with witnessed in-hospital cardiac arrest of cardiac origin undergoing CPR of more than 10 min compared with patients receiving conventional CPR. A matching process based on propensity-score was done to equalise potential prognostic factors in both groups, and to formulate a balanced 1:1 matched cohort study. The primary endpoint was survival to hospital discharge, and analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00173615.Of the 975 patients with in-hospital cardiac arrest events who underwent CPR for longer than 10 min, 113 were enrolled in the conventional CPR group and 59 were enrolled in the extracorporeal CPR group. Unmatched patients who underwent extracorporeal CPR had a higher survival rate to discharge (log-rank p<0.0001) and a better 1-year survival than those who received conventional CPR (log rank p=0.007). Between the propensity-score matched groups, there was still a significant difference in survival to discharge (hazard ratio [HR] 0.51, 95% CI 0.35-0.74, p<0.0001), 30-day survival (HR 0.47, 95% CI 0.28-0.77, p=0.003), and 1-year survival (HR 0.53, 95% CI 0.33-0.83, p=0.006) favouring extracorporeal CPR over conventional CPR.Extracorporeal CPR had a short-term and long-term survival benefit over conventional CPR in patients with in-hospital cardiac arrest of cardiac origin.","Cardiopulmonary resuscitation with assisted extracorporeal life-support versus conventional cardiopulmonary resuscitation in adults with in-hospital cardiac arrest: an observational study and propensity analysis."
"919","JAMA.4761","0.049",18612114,2008,"Despite a lack of data, increasing numbers of patients are receiving primary androgen deprivation therapy (PADT) as an alternative to surgery, radiation, or conservative management for the treatment of localized prostate cancer.To evaluate the association between PADT and survival in elderly men with localized prostate cancer.A population-based cohort study of 19,271 men aged 66 years or older receiving Medicare who did not receive definitive local therapy for clinical stage T1-T2 prostate cancer. These patients were diagnosed in 1992-2002 within predefined US geographical areas, with follow-up through December 31, 2006, for all-cause mortality and through December 31, 2004, for prostate cancer-specific mortality. Instrumental variable analysis was used to address potential biases associated with unmeasured confounding variables.Prostate cancer-specific survival and overall survival.Among patients with localized prostate cancer (median age, 77 years), 7867 (41%) received PADT, and 11,404 were treated with conservative management, not including PADT. During the follow-up period, there were 1560 prostate cancer deaths and 11,045 deaths from all causes. Primary androgen deprivation therapy was associated with lower 10-year prostate cancer-specific survival (80.1% vs 82.6%; hazard ratio [HR], 1.17; 95% confidence interval [CI], 1.03-1.33) and no increase in 10-year overall survival (30.2% vs 30.3%; HR, 1.00; 95% CI, 0.96-1.05) compared with conservative management. However, in a prespecified subset analysis, PADT use in men with poorly differentiated cancer was associated with improved prostate cancer-specific survival (59.8% vs 54.3%; HR, 0.84; 95% CI, 0.70-1.00; P = .049) but not overall survival (17.3% vs 15.3%; HR, 0.92; 95% CI, 0.84-1.01).Primary androgen deprivation therapy is not associated with improved survival among the majority of elderly men with localized prostate cancer when compared with conservative management.","Survival following primary androgen deprivation therapy among men with localized prostate cancer."
"920","JAMA.434","0.001",18647984,2008,"Cytomegalovirus (CMV) infection is associated with adverse clinical outcomes in immunosuppressed persons, but the incidence and association of CMV reactivation with adverse outcomes in critically ill persons lacking evidence of immunosuppression have not been well defined.To determine the association of CMV reactivation with intensive care unit (ICU) and hospital length of stay in critically ill immunocompetent persons.We prospectively assessed CMV plasma DNAemia by thrice-weekly real-time polymerase chain reaction (PCR) and clinical outcomes in a cohort of 120 CMV-seropositive, immunocompetent adults admitted to 1 of 6 ICUs at 2 separate hospitals at a large US tertiary care academic medical center between 2004 and 2006. Clinical measurements were assessed by personnel blinded to CMV PCR results. Risk factors for CMV reactivation and association with hospital and ICU length of stay were assessed by multivariable logistic regression and proportional odds models.Association of CMV reactivation with prolonged hospital length of stay or death.The primary composite end point of continued hospitalization (n = 35) or death (n = 10) by 30 days occurred in 45 (35%) of the 120 patients. Cytomegalovirus viremia at any level occurred in 33% (39/120; 95% confidence interval [CI], 24%-41%) at a median of 12 days (range, 3-57 days) and CMV viremia greater than 1000 copies/mL occurred in 20% (24/120; 95% CI, 13%-28%) at a median of 26 days (range, 9-56 days). By logistic regression, CMV infection at any level (adjusted odds ratio [OR], 4.3; 95% CI, 1.6-11.9; P = .005) and at greater than 1000 copies/mL (adjusted OR, 13.9; 95% CI, 3.2-60; P < .001) and the average CMV area under the curve (AUC) in log(10) copies per milliliter (adjusted OR, 2.1; 95% CI, 1.3-3.2; P < .001) were independently associated with hospitalization or death by 30 days. In multivariable partial proportional odds models, both CMV 7-day moving average (OR, 5.1; 95% CI, 2.9-9.1; P < .001) and CMV AUC (OR, 3.2; 95% CI, 2.1-4.7; P < .001) were independently associated with a hospital length of stay of at least 14 days.These preliminary findings suggest that reactivation of CMV occurs frequently in critically ill immunocompetent patients and is associated with prolonged hospitalization or death. A controlled trial of CMV prophylaxis in this setting is warranted.","Cytomegalovirus reactivation in critically ill immunocompetent patients."
"921","JAMA.435","0.001",18647984,2008,"Cytomegalovirus (CMV) infection is associated with adverse clinical outcomes in immunosuppressed persons, but the incidence and association of CMV reactivation with adverse outcomes in critically ill persons lacking evidence of immunosuppression have not been well defined.To determine the association of CMV reactivation with intensive care unit (ICU) and hospital length of stay in critically ill immunocompetent persons.We prospectively assessed CMV plasma DNAemia by thrice-weekly real-time polymerase chain reaction (PCR) and clinical outcomes in a cohort of 120 CMV-seropositive, immunocompetent adults admitted to 1 of 6 ICUs at 2 separate hospitals at a large US tertiary care academic medical center between 2004 and 2006. Clinical measurements were assessed by personnel blinded to CMV PCR results. Risk factors for CMV reactivation and association with hospital and ICU length of stay were assessed by multivariable logistic regression and proportional odds models.Association of CMV reactivation with prolonged hospital length of stay or death.The primary composite end point of continued hospitalization (n = 35) or death (n = 10) by 30 days occurred in 45 (35%) of the 120 patients. Cytomegalovirus viremia at any level occurred in 33% (39/120; 95% confidence interval [CI], 24%-41%) at a median of 12 days (range, 3-57 days) and CMV viremia greater than 1000 copies/mL occurred in 20% (24/120; 95% CI, 13%-28%) at a median of 26 days (range, 9-56 days). By logistic regression, CMV infection at any level (adjusted odds ratio [OR], 4.3; 95% CI, 1.6-11.9; P = .005) and at greater than 1000 copies/mL (adjusted OR, 13.9; 95% CI, 3.2-60; P < .001) and the average CMV area under the curve (AUC) in log(10) copies per milliliter (adjusted OR, 2.1; 95% CI, 1.3-3.2; P < .001) were independently associated with hospitalization or death by 30 days. In multivariable partial proportional odds models, both CMV 7-day moving average (OR, 5.1; 95% CI, 2.9-9.1; P < .001) and CMV AUC (OR, 3.2; 95% CI, 2.1-4.7; P < .001) were independently associated with a hospital length of stay of at least 14 days.These preliminary findings suggest that reactivation of CMV occurs frequently in critically ill immunocompetent patients and is associated with prolonged hospitalization or death. A controlled trial of CMV prophylaxis in this setting is warranted.","Cytomegalovirus reactivation in critically ill immunocompetent patients."
"922","JAMA.436","0.001",18647984,2008,"Cytomegalovirus (CMV) infection is associated with adverse clinical outcomes in immunosuppressed persons, but the incidence and association of CMV reactivation with adverse outcomes in critically ill persons lacking evidence of immunosuppression have not been well defined.To determine the association of CMV reactivation with intensive care unit (ICU) and hospital length of stay in critically ill immunocompetent persons.We prospectively assessed CMV plasma DNAemia by thrice-weekly real-time polymerase chain reaction (PCR) and clinical outcomes in a cohort of 120 CMV-seropositive, immunocompetent adults admitted to 1 of 6 ICUs at 2 separate hospitals at a large US tertiary care academic medical center between 2004 and 2006. Clinical measurements were assessed by personnel blinded to CMV PCR results. Risk factors for CMV reactivation and association with hospital and ICU length of stay were assessed by multivariable logistic regression and proportional odds models.Association of CMV reactivation with prolonged hospital length of stay or death.The primary composite end point of continued hospitalization (n = 35) or death (n = 10) by 30 days occurred in 45 (35%) of the 120 patients. Cytomegalovirus viremia at any level occurred in 33% (39/120; 95% confidence interval [CI], 24%-41%) at a median of 12 days (range, 3-57 days) and CMV viremia greater than 1000 copies/mL occurred in 20% (24/120; 95% CI, 13%-28%) at a median of 26 days (range, 9-56 days). By logistic regression, CMV infection at any level (adjusted odds ratio [OR], 4.3; 95% CI, 1.6-11.9; P = .005) and at greater than 1000 copies/mL (adjusted OR, 13.9; 95% CI, 3.2-60; P < .001) and the average CMV area under the curve (AUC) in log(10) copies per milliliter (adjusted OR, 2.1; 95% CI, 1.3-3.2; P < .001) were independently associated with hospitalization or death by 30 days. In multivariable partial proportional odds models, both CMV 7-day moving average (OR, 5.1; 95% CI, 2.9-9.1; P < .001) and CMV AUC (OR, 3.2; 95% CI, 2.1-4.7; P < .001) were independently associated with a hospital length of stay of at least 14 days.These preliminary findings suggest that reactivation of CMV occurs frequently in critically ill immunocompetent patients and is associated with prolonged hospitalization or death. A controlled trial of CMV prophylaxis in this setting is warranted.","Cytomegalovirus reactivation in critically ill immunocompetent patients."
"923","JAMA.437","0.001",18647984,2008,"Cytomegalovirus (CMV) infection is associated with adverse clinical outcomes in immunosuppressed persons, but the incidence and association of CMV reactivation with adverse outcomes in critically ill persons lacking evidence of immunosuppression have not been well defined.To determine the association of CMV reactivation with intensive care unit (ICU) and hospital length of stay in critically ill immunocompetent persons.We prospectively assessed CMV plasma DNAemia by thrice-weekly real-time polymerase chain reaction (PCR) and clinical outcomes in a cohort of 120 CMV-seropositive, immunocompetent adults admitted to 1 of 6 ICUs at 2 separate hospitals at a large US tertiary care academic medical center between 2004 and 2006. Clinical measurements were assessed by personnel blinded to CMV PCR results. Risk factors for CMV reactivation and association with hospital and ICU length of stay were assessed by multivariable logistic regression and proportional odds models.Association of CMV reactivation with prolonged hospital length of stay or death.The primary composite end point of continued hospitalization (n = 35) or death (n = 10) by 30 days occurred in 45 (35%) of the 120 patients. Cytomegalovirus viremia at any level occurred in 33% (39/120; 95% confidence interval [CI], 24%-41%) at a median of 12 days (range, 3-57 days) and CMV viremia greater than 1000 copies/mL occurred in 20% (24/120; 95% CI, 13%-28%) at a median of 26 days (range, 9-56 days). By logistic regression, CMV infection at any level (adjusted odds ratio [OR], 4.3; 95% CI, 1.6-11.9; P = .005) and at greater than 1000 copies/mL (adjusted OR, 13.9; 95% CI, 3.2-60; P < .001) and the average CMV area under the curve (AUC) in log(10) copies per milliliter (adjusted OR, 2.1; 95% CI, 1.3-3.2; P < .001) were independently associated with hospitalization or death by 30 days. In multivariable partial proportional odds models, both CMV 7-day moving average (OR, 5.1; 95% CI, 2.9-9.1; P < .001) and CMV AUC (OR, 3.2; 95% CI, 2.1-4.7; P < .001) were independently associated with a hospital length of stay of at least 14 days.These preliminary findings suggest that reactivation of CMV occurs frequently in critically ill immunocompetent patients and is associated with prolonged hospitalization or death. A controlled trial of CMV prophylaxis in this setting is warranted.","Cytomegalovirus reactivation in critically ill immunocompetent patients."
"924","JAMA.469","0.005",18647984,2008,"Cytomegalovirus (CMV) infection is associated with adverse clinical outcomes in immunosuppressed persons, but the incidence and association of CMV reactivation with adverse outcomes in critically ill persons lacking evidence of immunosuppression have not been well defined.To determine the association of CMV reactivation with intensive care unit (ICU) and hospital length of stay in critically ill immunocompetent persons.We prospectively assessed CMV plasma DNAemia by thrice-weekly real-time polymerase chain reaction (PCR) and clinical outcomes in a cohort of 120 CMV-seropositive, immunocompetent adults admitted to 1 of 6 ICUs at 2 separate hospitals at a large US tertiary care academic medical center between 2004 and 2006. Clinical measurements were assessed by personnel blinded to CMV PCR results. Risk factors for CMV reactivation and association with hospital and ICU length of stay were assessed by multivariable logistic regression and proportional odds models.Association of CMV reactivation with prolonged hospital length of stay or death.The primary composite end point of continued hospitalization (n = 35) or death (n = 10) by 30 days occurred in 45 (35%) of the 120 patients. Cytomegalovirus viremia at any level occurred in 33% (39/120; 95% confidence interval [CI], 24%-41%) at a median of 12 days (range, 3-57 days) and CMV viremia greater than 1000 copies/mL occurred in 20% (24/120; 95% CI, 13%-28%) at a median of 26 days (range, 9-56 days). By logistic regression, CMV infection at any level (adjusted odds ratio [OR], 4.3; 95% CI, 1.6-11.9; P = .005) and at greater than 1000 copies/mL (adjusted OR, 13.9; 95% CI, 3.2-60; P < .001) and the average CMV area under the curve (AUC) in log(10) copies per milliliter (adjusted OR, 2.1; 95% CI, 1.3-3.2; P < .001) were independently associated with hospitalization or death by 30 days. In multivariable partial proportional odds models, both CMV 7-day moving average (OR, 5.1; 95% CI, 2.9-9.1; P < .001) and CMV AUC (OR, 3.2; 95% CI, 2.1-4.7; P < .001) were independently associated with a hospital length of stay of at least 14 days.These preliminary findings suggest that reactivation of CMV occurs frequently in critically ill immunocompetent patients and is associated with prolonged hospitalization or death. A controlled trial of CMV prophylaxis in this setting is warranted.","Cytomegalovirus reactivation in critically ill immunocompetent patients."
"925","Lancet.76","1.00E-04",18653228,2008,"Everolimus (RAD001) is an orally administered inhibitor of the mammalian target of rapamycin (mTOR), a therapeutic target for metastatic renal cell carcinoma. We did a phase III, randomised, double-blind, placebo-controlled trial of everolimus in patients with metastatic renal cell carcinoma whose disease had progressed on vascular endothelial growth factor-targeted therapy.Patients with metastatic renal cell carcinoma which had progressed on sunitinib, sorafenib, or both, were randomly assigned in a two to one ratio to receive everolimus 10 mg once daily (n=272) or placebo (n=138), in conjunction with best supportive care. Randomisation was done centrally via an interactive voice response system using a validated computer system, and was stratified by Memorial Sloan-Kettering Cancer Center prognostic score and previous anticancer therapy, with a permuted block size of six. The primary endpoint was progression-free survival, assessed via a blinded, independent central review. The study was designed to be terminated after 290 events of progression. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00410124.All randomised patients were included in efficacy analyses. The results of the second interim analysis indicated a significant difference in efficacy between arms and the trial was thus halted early after 191 progression events had been observed (101 [37%] events in the everolimus group, 90 [65%] in the placebo group; hazard ratio 0.30, 95% CI 0.22-0.40, p<0.0001; median progression-free survival 4.0 [95% CI 3.7-5.5] vs 1.9 [1.8-1.9] months). Stomatitis (107 [40%] patients in the everolimus group vs 11 [8%] in the placebo group), rash (66 [25%] vs six [4%]), and fatigue (53 [20%] vs 22 [16%]) were the most commonly reported adverse events, but were mostly mild or moderate in severity. Pneumonitis (any grade) was detected in 22 (8%) patients in the everolimus group, of whom eight had pneumonitis of grade 3 severity.Treatment with everolimus prolongs progression-free survival relative to placebo in patients with metastatic renal cell carcinoma that had progressed on other targeted therapies.","Efficacy of everolimus in advanced renal cell carcinoma: a double-blind, randomised, placebo-controlled phase III trial."
"926","JAMA.468","0.01",18698068,2008,"Despite reductions in prevalence of human immunodeficiency virus (HIV) infection among the general population of India, women account for a rising percentage of all HIV cases with husbands' risk behavior described as the major source of women's infection. Intimate partner violence (IPV) has been described as being associated with heterosexual transmission of HIV to women in India and elsewhere.To assess the relationship between experiencing IPV and the occurrence of HIV infection in a nationally representative sample of married Indian women tested for HIV.The Indian National Family Health Survey 3 was conducted across all Indian states in 2005 through 2006. The nationally representative sample included 124,385 married women; analyses conducted in 2007 and 2008 were limited to 28,139 married women who provided IPV data and HIV test results via systematic selection into respective subsamples.Prevalence estimates of lifetime IPV and HIV infection were calculated and demographic differences assessed. Intimate partner violence was conceptualized as physical violence with or without sexual violence and then was further categorized as physical violence only vs physical and sexual violence. Regression models were used to estimate the odds ratios (ORs) and 95% confidence intervals (CIs) for HIV infection among Indian women based on experiences of IPV after adjusting for demographics and women's HIV risk behaviors.One-third of married Indian women (35.49%) reported experiencing physical IPV with or without sexual violence from their husbands; 7.68% reported both physical and sexual IPV, and 27.80% reported experiencing physical IPV in the absence of sexual violence. Approximately 1 in 450 women (0.22%) tested positive for HIV. In adjusted models, married Indian women experiencing both physical and sexual violence from husbands demonstrated elevated HIV infection prevalence vs those not experiencing IPV (0.73% vs 0.19%; adjusted OR, 3.92; 95% CI, 1.41-10.94; P = .01). Physical IPV alone was not associated with risk of HIV infection. Women's personal sexual risk behaviors were not associated with HIV infection.Among married Indian women, physical violence combined with sexual violence from husbands was associated with an increased prevalence of HIV infection. Prevention of IPV may augment efforts to reduce the spread of HIV/AIDS.","Intimate partner violence and HIV infection among married Indian women."
"927","Lancet.1371","0.037",18707986,2008,"Angiotensin receptor blockers (ARB) and angiotensin converting enzyme (ACE) inhibitors are known to reduce proteinuria. Their combination might be more effective than either treatment alone, but long-term data for comparative changes in renal function are not available. We investigated the renal effects of ramipril (an ACE inhibitor), telmisartan (an ARB), and their combination in patients aged 55 years or older with established atherosclerotic vascular disease or with diabetes with end-organ damage.The trial ran from 2001 to 2007. After a 3-week run-in period, 25 620 participants were randomly assigned to ramipril 10 mg a day (n=8576), telmisartan 80 mg a day (n=8542), or to a combination of both drugs (n=8502; median follow-up was 56 months), and renal function and proteinuria were measured. The primary renal outcome was a composite of dialysis, doubling of serum creatinine, and death. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00153101.784 patients permanently discontinued randomised therapy during the trial because of hypotensive symptoms (406 on combination therapy, 149 on ramipril, and 229 on telmisartan). The number of events for the composite primary outcome was similar for telmisartan (n=1147 [13.4%]) and ramipril (1150 [13.5%]; hazard ratio [HR] 1.00, 95% CI 0.92-1.09), but was increased with combination therapy (1233 [14.5%]; HR 1.09, 1.01-1.18, p=0.037). The secondary renal outcome, dialysis or doubling of serum creatinine, was similar with telmisartan (189 [2.21%]) and ramipril (174 [2.03%]; HR 1.09, 0.89-1.34) and more frequent with combination therapy (212 [2.49%]: HR 1.24, 1.01-1.51, p=0.038). Estimated glomerular filtration rate (eGFR) declined least with ramipril compared with telmisartan (-2.82 [SD 17.2] mL/min/1.73 m(2)vs -4.12 [17.4], p<0.0001) or combination therapy (-6.11 [17.9], p<0.0001). The increase in urinary albumin excretion was less with telmisartan (p=0.004) or with combination therapy (p=0.001) than with ramipril.In people at high vascular risk, telmisartan's effects on major renal outcomes are similar to ramipril. Although combination therapy reduces proteinuria to a greater extent than monotherapy, overall it worsens major renal outcomes.","Renal outcomes with telmisartan, ramipril, or both, in people at high vascular risk (the ONTARGET study): a multicentre, randomised, double-blind, controlled trial."
"928","Lancet.1381","0.038",18707986,2008,"Angiotensin receptor blockers (ARB) and angiotensin converting enzyme (ACE) inhibitors are known to reduce proteinuria. Their combination might be more effective than either treatment alone, but long-term data for comparative changes in renal function are not available. We investigated the renal effects of ramipril (an ACE inhibitor), telmisartan (an ARB), and their combination in patients aged 55 years or older with established atherosclerotic vascular disease or with diabetes with end-organ damage.The trial ran from 2001 to 2007. After a 3-week run-in period, 25 620 participants were randomly assigned to ramipril 10 mg a day (n=8576), telmisartan 80 mg a day (n=8542), or to a combination of both drugs (n=8502; median follow-up was 56 months), and renal function and proteinuria were measured. The primary renal outcome was a composite of dialysis, doubling of serum creatinine, and death. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00153101.784 patients permanently discontinued randomised therapy during the trial because of hypotensive symptoms (406 on combination therapy, 149 on ramipril, and 229 on telmisartan). The number of events for the composite primary outcome was similar for telmisartan (n=1147 [13.4%]) and ramipril (1150 [13.5%]; hazard ratio [HR] 1.00, 95% CI 0.92-1.09), but was increased with combination therapy (1233 [14.5%]; HR 1.09, 1.01-1.18, p=0.037). The secondary renal outcome, dialysis or doubling of serum creatinine, was similar with telmisartan (189 [2.21%]) and ramipril (174 [2.03%]; HR 1.09, 0.89-1.34) and more frequent with combination therapy (212 [2.49%]: HR 1.24, 1.01-1.51, p=0.038). Estimated glomerular filtration rate (eGFR) declined least with ramipril compared with telmisartan (-2.82 [SD 17.2] mL/min/1.73 m(2)vs -4.12 [17.4], p<0.0001) or combination therapy (-6.11 [17.9], p<0.0001). The increase in urinary albumin excretion was less with telmisartan (p=0.004) or with combination therapy (p=0.001) than with ramipril.In people at high vascular risk, telmisartan's effects on major renal outcomes are similar to ramipril. Although combination therapy reduces proteinuria to a greater extent than monotherapy, overall it worsens major renal outcomes.","Renal outcomes with telmisartan, ramipril, or both, in people at high vascular risk (the ONTARGET study): a multicentre, randomised, double-blind, controlled trial."
"929","Lancet.1361","0.943",18757089,2008,"Large observational studies, small prospective studies and post-hoc analyses of randomised clinical trials have suggested that statins could be beneficial in patients with chronic heart failure. However, previous studies have been methodologically weak. We investigated the efficacy and safety of the statin rosuvastatin in patients with heart failure.We undertook a randomised, double-blind, placebo-controlled trial in 326 cardiology and 31 internal medicine centres in Italy. We enrolled patients aged 18 years or older with chronic heart failure of New York Heart Association class II-IV, irrespective of cause and left ventricular ejection fraction, and randomly assigned them to rosuvastatin 10 mg daily (n=2285) or placebo (n=2289) by a concealed, computerised telephone randomisation system. Patients were followed up for a median of 3.9 years (IQR 3.0-4.4). Primary endpoints were time to death, and time to death or admission to hospital for cardiovascular reasons. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00336336.We analysed all randomised patients. 657 (29%) patients died from any cause in the rosuvastatin group and 644 (28%) in the placebo group (adjusted hazard ratio [HR] 1.00 [95.5% CI 0.898-1.122], p=0.943). 1305 (57%) patients in the rosuvastatin group and 1283 (56%) in the placebo group died or were admitted to hospital for cardiovascular reasons (adjusted HR 1.01 [99% CI 0.908-1.112], p=0.903). In both groups, gastrointestinal disorders were the most frequent adverse reaction (34 [1%] rosuvastatin group vs 44 [2%] placebo group).Rosuvastatin 10 mg daily did not affect clinical outcomes in patients with chronic heart failure of any cause, in whom the drug was safe.","Effect of rosuvastatin in patients with chronic heart failure (the GISSI-HF trial): a randomised, double-blind, placebo-controlled trial."
"930","Lancet.1361","0.903",18757089,2008,"Large observational studies, small prospective studies and post-hoc analyses of randomised clinical trials have suggested that statins could be beneficial in patients with chronic heart failure. However, previous studies have been methodologically weak. We investigated the efficacy and safety of the statin rosuvastatin in patients with heart failure.We undertook a randomised, double-blind, placebo-controlled trial in 326 cardiology and 31 internal medicine centres in Italy. We enrolled patients aged 18 years or older with chronic heart failure of New York Heart Association class II-IV, irrespective of cause and left ventricular ejection fraction, and randomly assigned them to rosuvastatin 10 mg daily (n=2285) or placebo (n=2289) by a concealed, computerised telephone randomisation system. Patients were followed up for a median of 3.9 years (IQR 3.0-4.4). Primary endpoints were time to death, and time to death or admission to hospital for cardiovascular reasons. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00336336.We analysed all randomised patients. 657 (29%) patients died from any cause in the rosuvastatin group and 644 (28%) in the placebo group (adjusted hazard ratio [HR] 1.00 [95.5% CI 0.898-1.122], p=0.943). 1305 (57%) patients in the rosuvastatin group and 1283 (56%) in the placebo group died or were admitted to hospital for cardiovascular reasons (adjusted HR 1.01 [99% CI 0.908-1.112], p=0.903). In both groups, gastrointestinal disorders were the most frequent adverse reaction (34 [1%] rosuvastatin group vs 44 [2%] placebo group).Rosuvastatin 10 mg daily did not affect clinical outcomes in patients with chronic heart failure of any cause, in whom the drug was safe.","Effect of rosuvastatin in patients with chronic heart failure (the GISSI-HF trial): a randomised, double-blind, placebo-controlled trial."
"931","Lancet.1351","0.041",18757090,2008,"Several epidemiological and experimental studies suggest that n-3 polyunsaturated fatty acids (PUFA) can exert favourable effects on atherothrombotic cardiovascular disease, including arrhythmias. We investigated whether n-3 PUFA could improve morbidity and mortality in a large population of patients with symptomatic heart failure of any cause.We undertook a randomised, double-blind, placebo-controlled trial in 326 cardiology and 31 internal medicine centres in Italy. We enrolled patients with chronic heart failure of New York Heart Association class II-IV, irrespective of cause and left ventricular ejection fraction, and randomly assigned them to n-3 PUFA 1 g daily (n=3494) or placebo (n=3481) by a concealed, computerised telephone randomisation system. Patients were followed up for a median of 3.9 years (IQR 3.0-4.5). Primary endpoints were time to death, and time to death or admission to hospital for cardiovascular reasons. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00336336.We analysed all randomised patients. 955 (27%) patients died from any cause in the n-3 PUFA group and 1014 (29%) in the placebo group (adjusted hazard ratio [HR] 0.91 [95.5% CI 0.833-0.998], p=0.041). 1981 (57%) patients in the n-3 PUFA group and 2053 (59%) in the placebo group died or were admitted to hospital for cardiovascular reasons (adjusted HR 0.92 [99% CI 0.849-0.999], p=0.009). In absolute terms, 56 patients needed to be treated for a median duration of 3.9 years to avoid one death or 44 to avoid one event like death or admission to hospital for cardiovascular reasons. In both groups, gastrointestinal disorders were the most frequent adverse reaction (96 [3%] n-3 PUFA group vs 92 [3%] placebo group).A simple and safe treatment with n-3 PUFA can provide a small beneficial advantage in terms of mortality and admission to hospital for cardiovascular reasons in patients with heart failure in a context of usual care.","Effect of n-3 polyunsaturated fatty acids in patients with chronic heart failure (the GISSI-HF trial): a randomised, double-blind, placebo-controlled trial."
"932","Lancet.1351","0.009",18757090,2008,"Several epidemiological and experimental studies suggest that n-3 polyunsaturated fatty acids (PUFA) can exert favourable effects on atherothrombotic cardiovascular disease, including arrhythmias. We investigated whether n-3 PUFA could improve morbidity and mortality in a large population of patients with symptomatic heart failure of any cause.We undertook a randomised, double-blind, placebo-controlled trial in 326 cardiology and 31 internal medicine centres in Italy. We enrolled patients with chronic heart failure of New York Heart Association class II-IV, irrespective of cause and left ventricular ejection fraction, and randomly assigned them to n-3 PUFA 1 g daily (n=3494) or placebo (n=3481) by a concealed, computerised telephone randomisation system. Patients were followed up for a median of 3.9 years (IQR 3.0-4.5). Primary endpoints were time to death, and time to death or admission to hospital for cardiovascular reasons. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00336336.We analysed all randomised patients. 955 (27%) patients died from any cause in the n-3 PUFA group and 1014 (29%) in the placebo group (adjusted hazard ratio [HR] 0.91 [95.5% CI 0.833-0.998], p=0.041). 1981 (57%) patients in the n-3 PUFA group and 2053 (59%) in the placebo group died or were admitted to hospital for cardiovascular reasons (adjusted HR 0.92 [99% CI 0.849-0.999], p=0.009). In absolute terms, 56 patients needed to be treated for a median duration of 3.9 years to avoid one death or 44 to avoid one event like death or admission to hospital for cardiovascular reasons. In both groups, gastrointestinal disorders were the most frequent adverse reaction (96 [3%] n-3 PUFA group vs 92 [3%] placebo group).A simple and safe treatment with n-3 PUFA can provide a small beneficial advantage in terms of mortality and admission to hospital for cardiovascular reasons in patients with heart failure in a context of usual care.","Effect of n-3 polyunsaturated fatty acids in patients with chronic heart failure (the GISSI-HF trial): a randomised, double-blind, placebo-controlled trial."
"933","JAMA.431","0.001",18780842,2008,"Many medical schools assert that a racially and ethnically diverse student body is an important element in educating physicians to meet the needs of a diverse society. However, there is limited evidence addressing the educational effects of student body racial diversity.To determine whether student body racial and ethnic diversity is associated with diversity-related outcomes among US medical students.A Web-based survey (Graduation Questionnaire) administered by the Association of American Medical Colleges of 20,112 graduating medical students (64% of all graduating students in 2003 and 2004) from 118 allopathic medical schools in the United States. Historically black and Puerto Rican medical schools were excluded.Students' self-rated preparedness to care for patients from other racial and ethnic backgrounds, attitudes about equity and access to care, and intent to practice in an underserved area.White students within the highest quintile for student body racial and ethnic diversity, measured by the proportion of underrepresented minority (URM) students, were more likely to rate themselves as highly prepared to care for minority populations than those in the lowest diversity quintile (61.1% vs 53.9%, respectively; P < .001; adjusted odds ratio [OR], 1.33; 95% confidence interval [CI], 1.13-1.57). This association was strongest in schools in which students perceived a positive climate for interracial interaction. White students in the highest URM quintile were also more likely to have strong attitudes endorsing equitable access to care (54.8% vs 44.2%, respectively; P < .001; adjusted OR, 1.42; 95% CI, 1.15-1.74). For nonwhite students, after adjustment there were no significant associations between student body URM proportions and diversity-related outcomes. Student body URM proportions were not associated with white or nonwhite students' plans to practice in underserved communities, although URM students were substantially more likely than white or nonwhite/non-URM students to plan to serve the underserved (48.7% vs 18.8% vs 16.2%, respectively; P < .001).Student body racial and ethnic diversity within US medical schools is associated with outcomes consistent with the goal of preparing students to meet the needs of a diverse population.","Student body racial and ethnic composition and diversity-related outcomes in US medical schools."
"934","JAMA.432","0.001",18780842,2008,"Many medical schools assert that a racially and ethnically diverse student body is an important element in educating physicians to meet the needs of a diverse society. However, there is limited evidence addressing the educational effects of student body racial diversity.To determine whether student body racial and ethnic diversity is associated with diversity-related outcomes among US medical students.A Web-based survey (Graduation Questionnaire) administered by the Association of American Medical Colleges of 20,112 graduating medical students (64% of all graduating students in 2003 and 2004) from 118 allopathic medical schools in the United States. Historically black and Puerto Rican medical schools were excluded.Students' self-rated preparedness to care for patients from other racial and ethnic backgrounds, attitudes about equity and access to care, and intent to practice in an underserved area.White students within the highest quintile for student body racial and ethnic diversity, measured by the proportion of underrepresented minority (URM) students, were more likely to rate themselves as highly prepared to care for minority populations than those in the lowest diversity quintile (61.1% vs 53.9%, respectively; P < .001; adjusted odds ratio [OR], 1.33; 95% confidence interval [CI], 1.13-1.57). This association was strongest in schools in which students perceived a positive climate for interracial interaction. White students in the highest URM quintile were also more likely to have strong attitudes endorsing equitable access to care (54.8% vs 44.2%, respectively; P < .001; adjusted OR, 1.42; 95% CI, 1.15-1.74). For nonwhite students, after adjustment there were no significant associations between student body URM proportions and diversity-related outcomes. Student body URM proportions were not associated with white or nonwhite students' plans to practice in underserved communities, although URM students were substantially more likely than white or nonwhite/non-URM students to plan to serve the underserved (48.7% vs 18.8% vs 16.2%, respectively; P < .001).Student body racial and ethnic diversity within US medical schools is associated with outcomes consistent with the goal of preparing students to meet the needs of a diverse population.","Student body racial and ethnic composition and diversity-related outcomes in US medical schools."
"935","Lancet.74","1.00E-04",18790313,2008,"The treatment of perinatal depression is a public-health priority because of its high prevalence and association with disability and poor infant development. We integrated a cognitive behaviour therapy-based intervention into the routine work of community-based primary health workers in rural Pakistan and assessed the effect of this intervention on maternal depression and infant outcomes.We randomly assigned 40 Union Council clusters in rural Rawalpindi, Pakistan, in equal numbers to intervention or control. Married women (aged 16-45 years) in their third trimester of pregnancy with perinatal depression were eligible to participate. In the intervention group, primary health workers were trained to deliver the psychological intervention, whereas in the control group untrained health workers made an equal number of visits to the depressed mothers. The primary outcomes were infant weight and height at 6 months and 12 months, and secondary outcome was maternal depression. The interviewers were unaware of what group the participants were assigned to. Analysis was by intention to treat. The study is registered as ISRCTN65316374.The number of clusters per group was 20, with 463 mothers in the intervention group and 440 in the control group. At 6 months, 97 (23%) of 418 and 211 (53%) of 400 mothers in the intervention and control groups, respectively, met the criteria for major depression (adjusted odds ratio (OR) 0.22, 95% CI 0.14 to 0.36, p<0.0001). These effects were sustained at 12 months (111/412 [27%] vs 226/386 [59%], adjusted OR 0.23, 95% CI 0.15 to 0.36, p<0.0001). The differences in weight-for-age and height-for-age Z scores for infants in the two groups were not significant at 6 months (-0.83 vs -0.86, p=0.7 and -2.03 vs -2.16, p=0.3, respectively) or 12 months (-0.64 vs -0.8, p=0.3 and -1.10 vs -1.36, p=0.07, respectively).This psychological intervention delivered by community-based primary health workers has the potential to be integrated into health systems in resource-poor settings.","Cognitive behaviour therapy-based intervention by community health workers for mothers with depression and their infants in rural Pakistan: a cluster-randomised controlled trial."
"936","Lancet.75","1.00E-04",18790313,2008,"The treatment of perinatal depression is a public-health priority because of its high prevalence and association with disability and poor infant development. We integrated a cognitive behaviour therapy-based intervention into the routine work of community-based primary health workers in rural Pakistan and assessed the effect of this intervention on maternal depression and infant outcomes.We randomly assigned 40 Union Council clusters in rural Rawalpindi, Pakistan, in equal numbers to intervention or control. Married women (aged 16-45 years) in their third trimester of pregnancy with perinatal depression were eligible to participate. In the intervention group, primary health workers were trained to deliver the psychological intervention, whereas in the control group untrained health workers made an equal number of visits to the depressed mothers. The primary outcomes were infant weight and height at 6 months and 12 months, and secondary outcome was maternal depression. The interviewers were unaware of what group the participants were assigned to. Analysis was by intention to treat. The study is registered as ISRCTN65316374.The number of clusters per group was 20, with 463 mothers in the intervention group and 440 in the control group. At 6 months, 97 (23%) of 418 and 211 (53%) of 400 mothers in the intervention and control groups, respectively, met the criteria for major depression (adjusted odds ratio (OR) 0.22, 95% CI 0.14 to 0.36, p<0.0001). These effects were sustained at 12 months (111/412 [27%] vs 226/386 [59%], adjusted OR 0.23, 95% CI 0.15 to 0.36, p<0.0001). The differences in weight-for-age and height-for-age Z scores for infants in the two groups were not significant at 6 months (-0.83 vs -0.86, p=0.7 and -2.03 vs -2.16, p=0.3, respectively) or 12 months (-0.64 vs -0.8, p=0.3 and -1.10 vs -1.36, p=0.07, respectively).This psychological intervention delivered by community-based primary health workers has the potential to be integrated into health systems in resource-poor settings.","Cognitive behaviour therapy-based intervention by community health workers for mothers with depression and their infants in rural Pakistan: a cluster-randomised controlled trial."
"937","Lancet.88","0.24",18790527,2008,"Intravenous alteplase is approved for use within 3 h of ischaemic stroke onset, although a meta-analysis of randomised controlled trials suggests treatment benefit up to 4.5 h. We compared outcome in patients treated between 3 h and 4.5 h versus those treated within 3 h, who were recorded in the in the Safe Implementation of Treatments in Stroke (SITS), a prospective internet-based audit of the International Stroke Thrombolysis Registry (ISTR).We compared 664 patients presenting with ischaemic stroke and given intravenous altepase (0.9 mg/kg total dose) between 3 h and 4.5 h with 11 865 patients treated within 3 h. All patients were otherwise compliant with European summary of product characteristics criteria and had been documented in the international stroke treatment registry between Dec 25, 2002, and Nov 15, 2007. Outcome measures were symptomatic intracerebral haemorrhage within 24 h (haemorrhage type 2 associated with National Institutes of Health Stroke Scale [NIHSS] > or = 4 points deterioration), and mortality and independence (modified Rankin scale of 0-2) at 3 months.In the 3-4.5-h cohort, treatment was started at a median of 55 min later after symptom onset (195 min [IQR 187-210] vs 140 min [115-165], p<0.0001), median age was 3 years younger (65 years [55-73] vs 68 years [58-74], p<0.0001), and stroke severity was lower (NIHSS score 11 [7-16] vs 12 [8-17], p<0.0001) than in the 3-h cohort. We recorded no significant differences between the 3-4.5-h cohort and the within 3-h cohort for any outcome measure--rate of symptomatic intracerebral haemorrhage: 2.2% (14 of 649) versus 1.6% (183 of 11 681) (odds ratio [OR] 1.18 [95% CI 0.89-1.55], p=0.24; adjusted OR 1.32 [1.00-1.75], p=0.052); mortality: 12.7% (70 of 551) versus 12.2% (1263 of 10 368) (OR 1.02 [0.90-1.17]; p=0.72; adjusted OR 1.15 [1.00-1.33]; p=0.053); and independence: 58.0% (314 of 541) versus 56.3% (5756 of 10231) (OR 1.04 [0.95-1.13], p=0.42; adjusted OR 0.93 [0.84-1.03], p=0.18).Alteplase remains safe when given at 3-4.5 h after ischaemic stroke, offering an opportunity for patients who cannot be treated within the standard 3-h timeframe.Boehringer-Ingelheim, European Union Public Health Executive Authority.","Thrombolysis with alteplase 3-4.5 h after acute ischaemic stroke (SITS-ISTR): an observational study."
"938","Lancet.89","0.052",18790527,2008,"Intravenous alteplase is approved for use within 3 h of ischaemic stroke onset, although a meta-analysis of randomised controlled trials suggests treatment benefit up to 4.5 h. We compared outcome in patients treated between 3 h and 4.5 h versus those treated within 3 h, who were recorded in the in the Safe Implementation of Treatments in Stroke (SITS), a prospective internet-based audit of the International Stroke Thrombolysis Registry (ISTR).We compared 664 patients presenting with ischaemic stroke and given intravenous altepase (0.9 mg/kg total dose) between 3 h and 4.5 h with 11 865 patients treated within 3 h. All patients were otherwise compliant with European summary of product characteristics criteria and had been documented in the international stroke treatment registry between Dec 25, 2002, and Nov 15, 2007. Outcome measures were symptomatic intracerebral haemorrhage within 24 h (haemorrhage type 2 associated with National Institutes of Health Stroke Scale [NIHSS] > or = 4 points deterioration), and mortality and independence (modified Rankin scale of 0-2) at 3 months.In the 3-4.5-h cohort, treatment was started at a median of 55 min later after symptom onset (195 min [IQR 187-210] vs 140 min [115-165], p<0.0001), median age was 3 years younger (65 years [55-73] vs 68 years [58-74], p<0.0001), and stroke severity was lower (NIHSS score 11 [7-16] vs 12 [8-17], p<0.0001) than in the 3-h cohort. We recorded no significant differences between the 3-4.5-h cohort and the within 3-h cohort for any outcome measure--rate of symptomatic intracerebral haemorrhage: 2.2% (14 of 649) versus 1.6% (183 of 11 681) (odds ratio [OR] 1.18 [95% CI 0.89-1.55], p=0.24; adjusted OR 1.32 [1.00-1.75], p=0.052); mortality: 12.7% (70 of 551) versus 12.2% (1263 of 10 368) (OR 1.02 [0.90-1.17]; p=0.72; adjusted OR 1.15 [1.00-1.33]; p=0.053); and independence: 58.0% (314 of 541) versus 56.3% (5756 of 10231) (OR 1.04 [0.95-1.13], p=0.42; adjusted OR 0.93 [0.84-1.03], p=0.18).Alteplase remains safe when given at 3-4.5 h after ischaemic stroke, offering an opportunity for patients who cannot be treated within the standard 3-h timeframe.Boehringer-Ingelheim, European Union Public Health Executive Authority.","Thrombolysis with alteplase 3-4.5 h after acute ischaemic stroke (SITS-ISTR): an observational study."
"939","Lancet.90","0.72",18790527,2008,"Intravenous alteplase is approved for use within 3 h of ischaemic stroke onset, although a meta-analysis of randomised controlled trials suggests treatment benefit up to 4.5 h. We compared outcome in patients treated between 3 h and 4.5 h versus those treated within 3 h, who were recorded in the in the Safe Implementation of Treatments in Stroke (SITS), a prospective internet-based audit of the International Stroke Thrombolysis Registry (ISTR).We compared 664 patients presenting with ischaemic stroke and given intravenous altepase (0.9 mg/kg total dose) between 3 h and 4.5 h with 11 865 patients treated within 3 h. All patients were otherwise compliant with European summary of product characteristics criteria and had been documented in the international stroke treatment registry between Dec 25, 2002, and Nov 15, 2007. Outcome measures were symptomatic intracerebral haemorrhage within 24 h (haemorrhage type 2 associated with National Institutes of Health Stroke Scale [NIHSS] > or = 4 points deterioration), and mortality and independence (modified Rankin scale of 0-2) at 3 months.In the 3-4.5-h cohort, treatment was started at a median of 55 min later after symptom onset (195 min [IQR 187-210] vs 140 min [115-165], p<0.0001), median age was 3 years younger (65 years [55-73] vs 68 years [58-74], p<0.0001), and stroke severity was lower (NIHSS score 11 [7-16] vs 12 [8-17], p<0.0001) than in the 3-h cohort. We recorded no significant differences between the 3-4.5-h cohort and the within 3-h cohort for any outcome measure--rate of symptomatic intracerebral haemorrhage: 2.2% (14 of 649) versus 1.6% (183 of 11 681) (odds ratio [OR] 1.18 [95% CI 0.89-1.55], p=0.24; adjusted OR 1.32 [1.00-1.75], p=0.052); mortality: 12.7% (70 of 551) versus 12.2% (1263 of 10 368) (OR 1.02 [0.90-1.17]; p=0.72; adjusted OR 1.15 [1.00-1.33]; p=0.053); and independence: 58.0% (314 of 541) versus 56.3% (5756 of 10231) (OR 1.04 [0.95-1.13], p=0.42; adjusted OR 0.93 [0.84-1.03], p=0.18).Alteplase remains safe when given at 3-4.5 h after ischaemic stroke, offering an opportunity for patients who cannot be treated within the standard 3-h timeframe.Boehringer-Ingelheim, European Union Public Health Executive Authority.","Thrombolysis with alteplase 3-4.5 h after acute ischaemic stroke (SITS-ISTR): an observational study."
"940","Lancet.91","0.053",18790527,2008,"Intravenous alteplase is approved for use within 3 h of ischaemic stroke onset, although a meta-analysis of randomised controlled trials suggests treatment benefit up to 4.5 h. We compared outcome in patients treated between 3 h and 4.5 h versus those treated within 3 h, who were recorded in the in the Safe Implementation of Treatments in Stroke (SITS), a prospective internet-based audit of the International Stroke Thrombolysis Registry (ISTR).We compared 664 patients presenting with ischaemic stroke and given intravenous altepase (0.9 mg/kg total dose) between 3 h and 4.5 h with 11 865 patients treated within 3 h. All patients were otherwise compliant with European summary of product characteristics criteria and had been documented in the international stroke treatment registry between Dec 25, 2002, and Nov 15, 2007. Outcome measures were symptomatic intracerebral haemorrhage within 24 h (haemorrhage type 2 associated with National Institutes of Health Stroke Scale [NIHSS] > or = 4 points deterioration), and mortality and independence (modified Rankin scale of 0-2) at 3 months.In the 3-4.5-h cohort, treatment was started at a median of 55 min later after symptom onset (195 min [IQR 187-210] vs 140 min [115-165], p<0.0001), median age was 3 years younger (65 years [55-73] vs 68 years [58-74], p<0.0001), and stroke severity was lower (NIHSS score 11 [7-16] vs 12 [8-17], p<0.0001) than in the 3-h cohort. We recorded no significant differences between the 3-4.5-h cohort and the within 3-h cohort for any outcome measure--rate of symptomatic intracerebral haemorrhage: 2.2% (14 of 649) versus 1.6% (183 of 11 681) (odds ratio [OR] 1.18 [95% CI 0.89-1.55], p=0.24; adjusted OR 1.32 [1.00-1.75], p=0.052); mortality: 12.7% (70 of 551) versus 12.2% (1263 of 10 368) (OR 1.02 [0.90-1.17]; p=0.72; adjusted OR 1.15 [1.00-1.33]; p=0.053); and independence: 58.0% (314 of 541) versus 56.3% (5756 of 10231) (OR 1.04 [0.95-1.13], p=0.42; adjusted OR 0.93 [0.84-1.03], p=0.18).Alteplase remains safe when given at 3-4.5 h after ischaemic stroke, offering an opportunity for patients who cannot be treated within the standard 3-h timeframe.Boehringer-Ingelheim, European Union Public Health Executive Authority.","Thrombolysis with alteplase 3-4.5 h after acute ischaemic stroke (SITS-ISTR): an observational study."
"941","Lancet.92","0.42",18790527,2008,"Intravenous alteplase is approved for use within 3 h of ischaemic stroke onset, although a meta-analysis of randomised controlled trials suggests treatment benefit up to 4.5 h. We compared outcome in patients treated between 3 h and 4.5 h versus those treated within 3 h, who were recorded in the in the Safe Implementation of Treatments in Stroke (SITS), a prospective internet-based audit of the International Stroke Thrombolysis Registry (ISTR).We compared 664 patients presenting with ischaemic stroke and given intravenous altepase (0.9 mg/kg total dose) between 3 h and 4.5 h with 11 865 patients treated within 3 h. All patients were otherwise compliant with European summary of product characteristics criteria and had been documented in the international stroke treatment registry between Dec 25, 2002, and Nov 15, 2007. Outcome measures were symptomatic intracerebral haemorrhage within 24 h (haemorrhage type 2 associated with National Institutes of Health Stroke Scale [NIHSS] > or = 4 points deterioration), and mortality and independence (modified Rankin scale of 0-2) at 3 months.In the 3-4.5-h cohort, treatment was started at a median of 55 min later after symptom onset (195 min [IQR 187-210] vs 140 min [115-165], p<0.0001), median age was 3 years younger (65 years [55-73] vs 68 years [58-74], p<0.0001), and stroke severity was lower (NIHSS score 11 [7-16] vs 12 [8-17], p<0.0001) than in the 3-h cohort. We recorded no significant differences between the 3-4.5-h cohort and the within 3-h cohort for any outcome measure--rate of symptomatic intracerebral haemorrhage: 2.2% (14 of 649) versus 1.6% (183 of 11 681) (odds ratio [OR] 1.18 [95% CI 0.89-1.55], p=0.24; adjusted OR 1.32 [1.00-1.75], p=0.052); mortality: 12.7% (70 of 551) versus 12.2% (1263 of 10 368) (OR 1.02 [0.90-1.17]; p=0.72; adjusted OR 1.15 [1.00-1.33]; p=0.053); and independence: 58.0% (314 of 541) versus 56.3% (5756 of 10231) (OR 1.04 [0.95-1.13], p=0.42; adjusted OR 0.93 [0.84-1.03], p=0.18).Alteplase remains safe when given at 3-4.5 h after ischaemic stroke, offering an opportunity for patients who cannot be treated within the standard 3-h timeframe.Boehringer-Ingelheim, European Union Public Health Executive Authority.","Thrombolysis with alteplase 3-4.5 h after acute ischaemic stroke (SITS-ISTR): an observational study."
"942","Lancet.93","0.18",18790527,2008,"Intravenous alteplase is approved for use within 3 h of ischaemic stroke onset, although a meta-analysis of randomised controlled trials suggests treatment benefit up to 4.5 h. We compared outcome in patients treated between 3 h and 4.5 h versus those treated within 3 h, who were recorded in the in the Safe Implementation of Treatments in Stroke (SITS), a prospective internet-based audit of the International Stroke Thrombolysis Registry (ISTR).We compared 664 patients presenting with ischaemic stroke and given intravenous altepase (0.9 mg/kg total dose) between 3 h and 4.5 h with 11 865 patients treated within 3 h. All patients were otherwise compliant with European summary of product characteristics criteria and had been documented in the international stroke treatment registry between Dec 25, 2002, and Nov 15, 2007. Outcome measures were symptomatic intracerebral haemorrhage within 24 h (haemorrhage type 2 associated with National Institutes of Health Stroke Scale [NIHSS] > or = 4 points deterioration), and mortality and independence (modified Rankin scale of 0-2) at 3 months.In the 3-4.5-h cohort, treatment was started at a median of 55 min later after symptom onset (195 min [IQR 187-210] vs 140 min [115-165], p<0.0001), median age was 3 years younger (65 years [55-73] vs 68 years [58-74], p<0.0001), and stroke severity was lower (NIHSS score 11 [7-16] vs 12 [8-17], p<0.0001) than in the 3-h cohort. We recorded no significant differences between the 3-4.5-h cohort and the within 3-h cohort for any outcome measure--rate of symptomatic intracerebral haemorrhage: 2.2% (14 of 649) versus 1.6% (183 of 11 681) (odds ratio [OR] 1.18 [95% CI 0.89-1.55], p=0.24; adjusted OR 1.32 [1.00-1.75], p=0.052); mortality: 12.7% (70 of 551) versus 12.2% (1263 of 10 368) (OR 1.02 [0.90-1.17]; p=0.72; adjusted OR 1.15 [1.00-1.33]; p=0.053); and independence: 58.0% (314 of 541) versus 56.3% (5756 of 10231) (OR 1.04 [0.95-1.13], p=0.42; adjusted OR 0.93 [0.84-1.03], p=0.18).Alteplase remains safe when given at 3-4.5 h after ischaemic stroke, offering an opportunity for patients who cannot be treated within the standard 3-h timeframe.Boehringer-Ingelheim, European Union Public Health Executive Authority.","Thrombolysis with alteplase 3-4.5 h after acute ischaemic stroke (SITS-ISTR): an observational study."
"943","JAMA.429","0.001",18799442,2008,"Bisphenol A (BPA) is widely used in epoxy resins lining food and beverage containers. Evidence of effects in animals has generated concern over low-level chronic exposures in humans.To examine associations between urinary BPA concentrations and adult health status.Cross-sectional analysis of BPA concentrations and health status in the general adult population of the United States, using data from the National Health and Nutrition Examination Survey 2003-2004. Participants were 1455 adults aged 18 through 74 years with measured urinary BPA and urine creatinine concentrations. Regression models were adjusted for age, sex, race/ethnicity, education, income, smoking, body mass index, waist circumference, and urinary creatinine concentration. The sample provided 80% power to detect unadjusted odds ratios (ORs) of 1.4 for diagnoses of 5% prevalence per 1-SD change in BPA concentration, or standardized regression coefficients of 0.075 for liver enzyme concentrations, at a significance level of P < .05.Chronic disease diagnoses plus blood markers of liver function, glucose homeostasis, inflammation, and lipid changes.Higher urinary BPA concentrations were associated with cardiovascular diagnoses in age-, sex-, and fully adjusted models (OR per 1-SD increase in BPA concentration, 1.39; 95% confidence interval [CI], 1.18-1.63; P = .001 with full adjustment). Higher BPA concentrations were also associated with diabetes (OR per 1-SD increase in BPA concentration, 1.39; 95% confidence interval [CI], 1.21-1.60; P < .001) but not with other studied common diseases. In addition, higher BPA concentrations were associated with clinically abnormal concentrations of the liver enzymes gamma-glutamyltransferase (OR per 1-SD increase in BPA concentration, 1.29; 95% CI, 1.14-1.46; P < .001) and alkaline phosphatase (OR per 1-SD increase in BPA concentration, 1.48; 95% CI, 1.18-1.85; P = .002).Higher BPA exposure, reflected in higher urinary concentrations of BPA, may be associated with avoidable morbidity in the community-dwelling adult population.","Association of urinary bisphenol A concentration with medical disorders and laboratory abnormalities in adults."
"944","JAMA.430","0.001",18799442,2008,"Bisphenol A (BPA) is widely used in epoxy resins lining food and beverage containers. Evidence of effects in animals has generated concern over low-level chronic exposures in humans.To examine associations between urinary BPA concentrations and adult health status.Cross-sectional analysis of BPA concentrations and health status in the general adult population of the United States, using data from the National Health and Nutrition Examination Survey 2003-2004. Participants were 1455 adults aged 18 through 74 years with measured urinary BPA and urine creatinine concentrations. Regression models were adjusted for age, sex, race/ethnicity, education, income, smoking, body mass index, waist circumference, and urinary creatinine concentration. The sample provided 80% power to detect unadjusted odds ratios (ORs) of 1.4 for diagnoses of 5% prevalence per 1-SD change in BPA concentration, or standardized regression coefficients of 0.075 for liver enzyme concentrations, at a significance level of P < .05.Chronic disease diagnoses plus blood markers of liver function, glucose homeostasis, inflammation, and lipid changes.Higher urinary BPA concentrations were associated with cardiovascular diagnoses in age-, sex-, and fully adjusted models (OR per 1-SD increase in BPA concentration, 1.39; 95% confidence interval [CI], 1.18-1.63; P = .001 with full adjustment). Higher BPA concentrations were also associated with diabetes (OR per 1-SD increase in BPA concentration, 1.39; 95% confidence interval [CI], 1.21-1.60; P < .001) but not with other studied common diseases. In addition, higher BPA concentrations were associated with clinically abnormal concentrations of the liver enzymes gamma-glutamyltransferase (OR per 1-SD increase in BPA concentration, 1.29; 95% CI, 1.14-1.46; P < .001) and alkaline phosphatase (OR per 1-SD increase in BPA concentration, 1.48; 95% CI, 1.18-1.85; P = .002).Higher BPA exposure, reflected in higher urinary concentrations of BPA, may be associated with avoidable morbidity in the community-dwelling adult population.","Association of urinary bisphenol A concentration with medical disorders and laboratory abnormalities in adults."
"945","JAMA.466","0.001",18799442,2008,"Bisphenol A (BPA) is widely used in epoxy resins lining food and beverage containers. Evidence of effects in animals has generated concern over low-level chronic exposures in humans.To examine associations between urinary BPA concentrations and adult health status.Cross-sectional analysis of BPA concentrations and health status in the general adult population of the United States, using data from the National Health and Nutrition Examination Survey 2003-2004. Participants were 1455 adults aged 18 through 74 years with measured urinary BPA and urine creatinine concentrations. Regression models were adjusted for age, sex, race/ethnicity, education, income, smoking, body mass index, waist circumference, and urinary creatinine concentration. The sample provided 80% power to detect unadjusted odds ratios (ORs) of 1.4 for diagnoses of 5% prevalence per 1-SD change in BPA concentration, or standardized regression coefficients of 0.075 for liver enzyme concentrations, at a significance level of P < .05.Chronic disease diagnoses plus blood markers of liver function, glucose homeostasis, inflammation, and lipid changes.Higher urinary BPA concentrations were associated with cardiovascular diagnoses in age-, sex-, and fully adjusted models (OR per 1-SD increase in BPA concentration, 1.39; 95% confidence interval [CI], 1.18-1.63; P = .001 with full adjustment). Higher BPA concentrations were also associated with diabetes (OR per 1-SD increase in BPA concentration, 1.39; 95% confidence interval [CI], 1.21-1.60; P < .001) but not with other studied common diseases. In addition, higher BPA concentrations were associated with clinically abnormal concentrations of the liver enzymes gamma-glutamyltransferase (OR per 1-SD increase in BPA concentration, 1.29; 95% CI, 1.14-1.46; P < .001) and alkaline phosphatase (OR per 1-SD increase in BPA concentration, 1.48; 95% CI, 1.18-1.85; P = .002).Higher BPA exposure, reflected in higher urinary concentrations of BPA, may be associated with avoidable morbidity in the community-dwelling adult population.","Association of urinary bisphenol A concentration with medical disorders and laboratory abnormalities in adults."
"946","JAMA.467","0.002",18799442,2008,"Bisphenol A (BPA) is widely used in epoxy resins lining food and beverage containers. Evidence of effects in animals has generated concern over low-level chronic exposures in humans.To examine associations between urinary BPA concentrations and adult health status.Cross-sectional analysis of BPA concentrations and health status in the general adult population of the United States, using data from the National Health and Nutrition Examination Survey 2003-2004. Participants were 1455 adults aged 18 through 74 years with measured urinary BPA and urine creatinine concentrations. Regression models were adjusted for age, sex, race/ethnicity, education, income, smoking, body mass index, waist circumference, and urinary creatinine concentration. The sample provided 80% power to detect unadjusted odds ratios (ORs) of 1.4 for diagnoses of 5% prevalence per 1-SD change in BPA concentration, or standardized regression coefficients of 0.075 for liver enzyme concentrations, at a significance level of P < .05.Chronic disease diagnoses plus blood markers of liver function, glucose homeostasis, inflammation, and lipid changes.Higher urinary BPA concentrations were associated with cardiovascular diagnoses in age-, sex-, and fully adjusted models (OR per 1-SD increase in BPA concentration, 1.39; 95% confidence interval [CI], 1.18-1.63; P = .001 with full adjustment). Higher BPA concentrations were also associated with diabetes (OR per 1-SD increase in BPA concentration, 1.39; 95% confidence interval [CI], 1.21-1.60; P < .001) but not with other studied common diseases. In addition, higher BPA concentrations were associated with clinically abnormal concentrations of the liver enzymes gamma-glutamyltransferase (OR per 1-SD increase in BPA concentration, 1.29; 95% CI, 1.14-1.46; P < .001) and alkaline phosphatase (OR per 1-SD increase in BPA concentration, 1.48; 95% CI, 1.18-1.85; P = .002).Higher BPA exposure, reflected in higher urinary concentrations of BPA, may be associated with avoidable morbidity in the community-dwelling adult population.","Association of urinary bisphenol A concentration with medical disorders and laboratory abnormalities in adults."
"947","JAMA.4341","0.001",18799444,2008,"Bicuspid aortic valve is the most common congenital cardiac anomaly in the adult population. Cardiac outcomes in a contemporary population of adults with bicuspid aortic valve have not been systematically determined.To determine the frequency and predictors of cardiac outcomes in a large consecutive series of adults with bicuspid aortic valve.Cohort study examining cardiac outcomes in 642 consecutive ambulatory adults (mean [SD] age, 35 [16] years; 68% male) with bicuspid aortic valve presenting to a Canadian congenital cardiac center from 1994 through 2001 and followed up for a mean (SD) period of 9 (5) years. Frequency and predictors of major cardiac events were determined by multivariate analysis. Mortality rate in the study group was compared with age- and sex-matched population estimates.Mortality and cause of death were determined. Primary cardiac events were defined as the occurrence of any of the following complications: cardiac death, intervention on the aortic valve or ascending aorta, aortic dissection or aneurysm, or congestive heart failure requiring hospital admission during the follow-up period.During the follow-up period, there were 28 deaths (mean [SD], 4% [1%]). One or more primary cardiac events occurred in 161 patients (mean [SD], 25% [2%]), which included cardiac death in 17 patients (mean [SD], 3% [1%]), intervention on aortic valve or ascending aorta in 142 patients (mean [SD], 22% [2%]), aortic dissection or aneurysm in 11 patients (mean [SD], 2% [1%]), or congestive heart failure requiring hospital admission in 16 patients (mean [SD], 2% [1%]). Independent predictors of primary cardiac events were age older than 30 years (hazard ratio [HR], 3.01; 95% confidence interval [CI], 2.15-4.19; P<.001), moderate or severe aortic stenosis (HR, 5.67; 95% CI, 4.16-7.80; P<.001), and moderate or severe aortic regurgitation (HR, 2.68; 95% CI, 1.93-3.76; P<.001). The 10-year survival rate of the study group (mean [SD], 96% [1%]) was not significantly different from population estimates (mean [SD], 97% [1%]; P = .71). At last follow-up, 280 patients (mean [SD], 45% [2%]) had dilated aortic sinus and/or ascending aorta.In this study population of young adults with bicuspid aortic valve, age, severity of aortic stenosis, and severity of aortic regurgitation were independently associated with primary cardiac events. Over the mean follow-up duration of 9 years, survival rates were not lower than for the general population.","Outcomes in adults with bicuspid aortic valves."
"948","JAMA.4351","0.001",18799444,2008,"Bicuspid aortic valve is the most common congenital cardiac anomaly in the adult population. Cardiac outcomes in a contemporary population of adults with bicuspid aortic valve have not been systematically determined.To determine the frequency and predictors of cardiac outcomes in a large consecutive series of adults with bicuspid aortic valve.Cohort study examining cardiac outcomes in 642 consecutive ambulatory adults (mean [SD] age, 35 [16] years; 68% male) with bicuspid aortic valve presenting to a Canadian congenital cardiac center from 1994 through 2001 and followed up for a mean (SD) period of 9 (5) years. Frequency and predictors of major cardiac events were determined by multivariate analysis. Mortality rate in the study group was compared with age- and sex-matched population estimates.Mortality and cause of death were determined. Primary cardiac events were defined as the occurrence of any of the following complications: cardiac death, intervention on the aortic valve or ascending aorta, aortic dissection or aneurysm, or congestive heart failure requiring hospital admission during the follow-up period.During the follow-up period, there were 28 deaths (mean [SD], 4% [1%]). One or more primary cardiac events occurred in 161 patients (mean [SD], 25% [2%]), which included cardiac death in 17 patients (mean [SD], 3% [1%]), intervention on aortic valve or ascending aorta in 142 patients (mean [SD], 22% [2%]), aortic dissection or aneurysm in 11 patients (mean [SD], 2% [1%]), or congestive heart failure requiring hospital admission in 16 patients (mean [SD], 2% [1%]). Independent predictors of primary cardiac events were age older than 30 years (hazard ratio [HR], 3.01; 95% confidence interval [CI], 2.15-4.19; P<.001), moderate or severe aortic stenosis (HR, 5.67; 95% CI, 4.16-7.80; P<.001), and moderate or severe aortic regurgitation (HR, 2.68; 95% CI, 1.93-3.76; P<.001). The 10-year survival rate of the study group (mean [SD], 96% [1%]) was not significantly different from population estimates (mean [SD], 97% [1%]; P = .71). At last follow-up, 280 patients (mean [SD], 45% [2%]) had dilated aortic sinus and/or ascending aorta.In this study population of young adults with bicuspid aortic valve, age, severity of aortic stenosis, and severity of aortic regurgitation were independently associated with primary cardiac events. Over the mean follow-up duration of 9 years, survival rates were not lower than for the general population.","Outcomes in adults with bicuspid aortic valves."
"949","JAMA.4361","0.001",18799444,2008,"Bicuspid aortic valve is the most common congenital cardiac anomaly in the adult population. Cardiac outcomes in a contemporary population of adults with bicuspid aortic valve have not been systematically determined.To determine the frequency and predictors of cardiac outcomes in a large consecutive series of adults with bicuspid aortic valve.Cohort study examining cardiac outcomes in 642 consecutive ambulatory adults (mean [SD] age, 35 [16] years; 68% male) with bicuspid aortic valve presenting to a Canadian congenital cardiac center from 1994 through 2001 and followed up for a mean (SD) period of 9 (5) years. Frequency and predictors of major cardiac events were determined by multivariate analysis. Mortality rate in the study group was compared with age- and sex-matched population estimates.Mortality and cause of death were determined. Primary cardiac events were defined as the occurrence of any of the following complications: cardiac death, intervention on the aortic valve or ascending aorta, aortic dissection or aneurysm, or congestive heart failure requiring hospital admission during the follow-up period.During the follow-up period, there were 28 deaths (mean [SD], 4% [1%]). One or more primary cardiac events occurred in 161 patients (mean [SD], 25% [2%]), which included cardiac death in 17 patients (mean [SD], 3% [1%]), intervention on aortic valve or ascending aorta in 142 patients (mean [SD], 22% [2%]), aortic dissection or aneurysm in 11 patients (mean [SD], 2% [1%]), or congestive heart failure requiring hospital admission in 16 patients (mean [SD], 2% [1%]). Independent predictors of primary cardiac events were age older than 30 years (hazard ratio [HR], 3.01; 95% confidence interval [CI], 2.15-4.19; P<.001), moderate or severe aortic stenosis (HR, 5.67; 95% CI, 4.16-7.80; P<.001), and moderate or severe aortic regurgitation (HR, 2.68; 95% CI, 1.93-3.76; P<.001). The 10-year survival rate of the study group (mean [SD], 96% [1%]) was not significantly different from population estimates (mean [SD], 97% [1%]; P = .71). At last follow-up, 280 patients (mean [SD], 45% [2%]) had dilated aortic sinus and/or ascending aorta.In this study population of young adults with bicuspid aortic valve, age, severity of aortic stenosis, and severity of aortic regurgitation were independently associated with primary cardiac events. Over the mean follow-up duration of 9 years, survival rates were not lower than for the general population.","Outcomes in adults with bicuspid aortic valves."
"950","JAMA.463","0.046",18799445,2008,"Unprofessional behaviors in medical school predict high stakes consequences for practicing physicians, yet little is known about specific behaviors associated with professionalism during residency.To identify behaviors that distinguish highly professional residents from their peers.Comparative study of 148 first-year internal medicine residents at Mayo Clinic from July 1, 2004, through June 30, 2007.Professionalism as determined by multiple observation-based assessments by peers, senior residents, faculty, medical students, and nonphysician professionals over 1 year. Highly professional residents were defined as those who received a total professionalism score at the 80th percentile or higher of observation-based assessments on a 5-point scale (1, needs improvement; 5, exceptional). They were compared with residents who received professionalism scores below the 80th percentile according to In-Training Examination (ITE) scores, Mini-Clinical Evaluation Exercise (mini-CEX) scores, conscientious behaviors (percentage of completed evaluations and conference attendance), and receipt of a warning or probation from the residency program.The median total professionalism score among highly professional residents was 4.39 (interquartile range [IQR], 4.32-4.44) vs 4.07 (IQR, 3.91-4.17) among comparison residents. Highly professional residents achieved higher median scores on the ITE (65.5; IQR, 60.5-73.0 vs 63.0; IQR, 59.0-67.0; P = .03) and on the mini-CEX (3.95; IQR, 3.63-4.20 vs 3.69; IQR, 3.36-3.90; P = .002), and they completed a greater percentage of required evaluations (95.6%; IQR, 88.1%-99.0% vs 86.1%; IQR, 70.6%-95.0%; P < .001) compared with residents with lower professionalism scores. In multivariate analysis, a professionalism score in the top 20% of residents was independently associated with ITE scores (odds ratio [OR] per 1-point increase, 1.07; 95% confidence interval [CI], 1.01-1.14; P = .046), mini-CEX scores (OR, 4.64; 95% CI, 1.23-17.48; P = .02), and completion of evaluations (OR, 1.07; 95% CI, 1.01-1.13; P = .02). Six of the 8 residents who received a warning or probation had total professionalism scores in the bottom 20% of residents.Observation-based assessments of professionalism were associated with residents' knowledge, clinical skills, and conscientious behaviors.","Behaviors of highly professional resident physicians."
"951","JAMA.464","0.02",18799445,2008,"Unprofessional behaviors in medical school predict high stakes consequences for practicing physicians, yet little is known about specific behaviors associated with professionalism during residency.To identify behaviors that distinguish highly professional residents from their peers.Comparative study of 148 first-year internal medicine residents at Mayo Clinic from July 1, 2004, through June 30, 2007.Professionalism as determined by multiple observation-based assessments by peers, senior residents, faculty, medical students, and nonphysician professionals over 1 year. Highly professional residents were defined as those who received a total professionalism score at the 80th percentile or higher of observation-based assessments on a 5-point scale (1, needs improvement; 5, exceptional). They were compared with residents who received professionalism scores below the 80th percentile according to In-Training Examination (ITE) scores, Mini-Clinical Evaluation Exercise (mini-CEX) scores, conscientious behaviors (percentage of completed evaluations and conference attendance), and receipt of a warning or probation from the residency program.The median total professionalism score among highly professional residents was 4.39 (interquartile range [IQR], 4.32-4.44) vs 4.07 (IQR, 3.91-4.17) among comparison residents. Highly professional residents achieved higher median scores on the ITE (65.5; IQR, 60.5-73.0 vs 63.0; IQR, 59.0-67.0; P = .03) and on the mini-CEX (3.95; IQR, 3.63-4.20 vs 3.69; IQR, 3.36-3.90; P = .002), and they completed a greater percentage of required evaluations (95.6%; IQR, 88.1%-99.0% vs 86.1%; IQR, 70.6%-95.0%; P < .001) compared with residents with lower professionalism scores. In multivariate analysis, a professionalism score in the top 20% of residents was independently associated with ITE scores (odds ratio [OR] per 1-point increase, 1.07; 95% confidence interval [CI], 1.01-1.14; P = .046), mini-CEX scores (OR, 4.64; 95% CI, 1.23-17.48; P = .02), and completion of evaluations (OR, 1.07; 95% CI, 1.01-1.13; P = .02). Six of the 8 residents who received a warning or probation had total professionalism scores in the bottom 20% of residents.Observation-based assessments of professionalism were associated with residents' knowledge, clinical skills, and conscientious behaviors.","Behaviors of highly professional resident physicians."
"952","JAMA.465","0.02",18799445,2008,"Unprofessional behaviors in medical school predict high stakes consequences for practicing physicians, yet little is known about specific behaviors associated with professionalism during residency.To identify behaviors that distinguish highly professional residents from their peers.Comparative study of 148 first-year internal medicine residents at Mayo Clinic from July 1, 2004, through June 30, 2007.Professionalism as determined by multiple observation-based assessments by peers, senior residents, faculty, medical students, and nonphysician professionals over 1 year. Highly professional residents were defined as those who received a total professionalism score at the 80th percentile or higher of observation-based assessments on a 5-point scale (1, needs improvement; 5, exceptional). They were compared with residents who received professionalism scores below the 80th percentile according to In-Training Examination (ITE) scores, Mini-Clinical Evaluation Exercise (mini-CEX) scores, conscientious behaviors (percentage of completed evaluations and conference attendance), and receipt of a warning or probation from the residency program.The median total professionalism score among highly professional residents was 4.39 (interquartile range [IQR], 4.32-4.44) vs 4.07 (IQR, 3.91-4.17) among comparison residents. Highly professional residents achieved higher median scores on the ITE (65.5; IQR, 60.5-73.0 vs 63.0; IQR, 59.0-67.0; P = .03) and on the mini-CEX (3.95; IQR, 3.63-4.20 vs 3.69; IQR, 3.36-3.90; P = .002), and they completed a greater percentage of required evaluations (95.6%; IQR, 88.1%-99.0% vs 86.1%; IQR, 70.6%-95.0%; P < .001) compared with residents with lower professionalism scores. In multivariate analysis, a professionalism score in the top 20% of residents was independently associated with ITE scores (odds ratio [OR] per 1-point increase, 1.07; 95% confidence interval [CI], 1.01-1.14; P = .046), mini-CEX scores (OR, 4.64; 95% CI, 1.23-17.48; P = .02), and completion of evaluations (OR, 1.07; 95% CI, 1.01-1.13; P = .02). Six of the 8 residents who received a warning or probation had total professionalism scores in the bottom 20% of residents.Observation-based assessments of professionalism were associated with residents' knowledge, clinical skills, and conscientious behaviors.","Behaviors of highly professional resident physicians."
"953","Lancet.87","0.008",18805334,2008,"Incidence of asthma increases during early adulthood. We aimed to estimate the contributions of sex and early life factors to asthma diagnosed in young adults.1246 healthy newborn babies were enrolled in the Tucson Children's Respiratory Study. Parental characteristics, early-life wheezing phenotypes, airway function, and bronchial hyper-responsiveness to cold dry air and sensitisation to Alternaria alternata were determined before age 6 years. Physician-diagnosed asthma, both chronic and newly diagnosed, and airway function were recorded at age 22 years.Of 1246 babies enrolled, 849 had follow-up data at 22 years. Average incidence of asthma at age 16-22 years was 12.6 per thousand person-years. 49 (27%) of all 181 cases of active asthma at 22 years were newly diagnosed, of which 35 (71%) were women. Asthma remittance by 22 years was higher in men than in women (multinomial odds ratio [M-OR] 2.0, 95% CI 1.2-3.2, p=0.008). Age at diagnosis was linearly associated with the ratio of forced expiratory volume at 1 s to forced vital capacity at age 22 years. Factors independently associated with chronic asthma at 22 years included onset at 6 years (7.4, 3.9-14.0) and persistent wheezing (14.0, 6.8-28.0) in early life, sensitisation to A alternata (3.6, 2.1-6.4), low airway function at age 6 years (2.1, 1.1-3.9), and bronchial hyper-responsiveness at 6 years (4.5, 1.9-10.0). Bronchial hyper-responsiveness (6.9, 2.3-21.0), low airway function at 6 years (2.8, 1.1-6.9), and late-onset (4.6, 1.7-12.0) and persistent wheezing (4.0, 1.2-14.0) predicted newly diagnosed asthma at age 22 years.Asthma with onset in early adulthood has its origins in early childhood.","Wheezing and bronchial hyper-responsiveness in early childhood as predictors of newly diagnosed asthma in early adulthood: a longitudinal birth-cohort study."
"954","Lancet.1341","0.91",18814906,2008,"In mouse models of diabetes, prophylactic administration of insulin reduced incidence of the disease. We investigated whether administration of nasal insulin decreased the incidence of type 1 diabetes, in children with HLA genotypes and autoantibodies increasing the risk of the disease.At three university hospitals in Turku, Oulu, and Tampere (Finland), we analysed cord blood samples of 116 720 consecutively born infants, and 3430 of their siblings, for the HLA-DQB1 susceptibility alleles for type 1 diabetes. 17 397 infants and 1613 siblings had increased genetic risk, of whom 11 225 and 1574, respectively, consented to screening of diabetes-associated autoantibodies at every 3-12 months. In a double-blind trial, we randomly assigned 224 infants and 40 siblings positive for two or more autoantibodies, in consecutive samples, to receive short-acting human insulin (1 unit/kg; n=115 and n=22) or placebo (n=109 and n=18) once a day intranasally. We used a restricted randomisation, stratified by site, with permuted blocks of size two. Primary endpoint was diagnosis of diabetes. Analysis was by intention to treat. The study was terminated early because insulin had no beneficial effect. This study is registered with ClinicalTrials.gov, number NCT00223613.Median duration of the intervention was 1.8 years (range 0-9.7). Diabetes was diagnosed in 49 index children randomised to receive insulin, and in 47 randomised to placebo (hazard ratio [HR] 1.14; 95% CI 0.73-1.77). 42 and 38 of these children, respectively, continued treatment until diagnosis, with yearly rates of diabetes onset of 16.8% (95% CI 11.7-21.9) and 15.3% (10.5-20.2). Seven siblings were diagnosed with diabetes in the insulin group, versus six in the placebo group (HR 1.93; 0.56-6.77). In all randomised children, diabetes was diagnosed in 56 in the insulin group, and 53 in the placebo group (HR 0.98; 0.67-1.43, p=0.91).In children with HLA-conferred susceptibility to diabetes, administration of nasal insulin, started soon after detection of autoantibodies, could not be shown to prevent or delay type 1 diabetes.","Nasal insulin to prevent type 1 diabetes in children with HLA genotypes and autoantibodies conferring increased risk of disease: a double-blind, randomised controlled trial."
"955","Lancet.1281","0.0508",18823656,2008,"Results of previous studies suggest that renin-angiotensin system blockers might reduce the burden of diabetic retinopathy. We therefore designed the DIabetic REtinopathy Candesartan Trials (DIRECT) Programme to assess whether candesartan could reduce the incidence and progression of retinopathy in type 1 diabetes.Two randomised, double-blind, parallel-design, placebo-controlled trials were done in 309 centres worldwide. Participants with normotensive, normoalbuminuric type 1 diabetes without retinopathy were recruited to the DIRECT-Prevent 1 trial and those with existing retinopathy were recruited to DIRECT-Protect 1, and were assigned to candesartan 16 mg once a day or matching placebo. After 1 month, the dose was doubled to 32 mg. Investigators and participants were unaware of the treatment allocation status. The primary endpoints were incidence and progression of retinopathy and were defined as at least a two-step and at least a three-step increase on the Early Treatment Diabetic Retinopathy Study (ETDRS) scale, respectively. These trials are registered with ClinicalTrials.gov, numbers NCT00252733 for DIRECT-Prevent 1 and NCT00252720 for DIRECT-Protect 1.1421 participants (aged 18-50 years) were randomly assigned to candesartan (n=711) or to placebo (n=710) in DIRECT-Prevent 1, and 1905 (aged 18-55 years) to candesartan (n=951) or to placebo (n=954) in DIRECT-Protect 1. Incidence of retinopathy was seen in 178 (25%) participants in the candesartan group versus 217 (31%) in the placebo group. Progression of retinopathy occurred in 127 (13%) participants in the candesartan group versus 124 (13%) in the placebo group. Hazard ratio (HR for candesartan vs placebo) was 0.82 (95% CI 0.67-1.00, p=0.0508) for incidence of retinopathy and 1.02 (0.80-1.31, p=0.85) for progression of retinopathy. The post-hoc outcome of at least a three-step increase for incidence yielded an HR of 0.65 (0.48-0.87, p=0.0034), which was attenuated but still significant after adjustment for baseline characteristics (0.71, 0.53-0.95, p=0.046). Final ETDRS level was more likely to have improved with candesartan treatment in both DIRECT-Prevent 1 (odds 1.16, 95% CI 1.05-1.30, p=0.0048) and DIRECT-Protect 1 (1.12, 95% CI 1.01-1.25, p=0.0264). Adverse events did not differ between the treatment groups.Although candesartan reduces the incidence of retinopathy, we did not see a beneficial effect on retinopathy progression.","Effect of candesartan on prevention (DIRECT-Prevent 1) and progression (DIRECT-Protect 1) of retinopathy in type 1 diabetes: randomised, placebo-controlled trials."
"956","Lancet.1291","0.85",18823656,2008,"Results of previous studies suggest that renin-angiotensin system blockers might reduce the burden of diabetic retinopathy. We therefore designed the DIabetic REtinopathy Candesartan Trials (DIRECT) Programme to assess whether candesartan could reduce the incidence and progression of retinopathy in type 1 diabetes.Two randomised, double-blind, parallel-design, placebo-controlled trials were done in 309 centres worldwide. Participants with normotensive, normoalbuminuric type 1 diabetes without retinopathy were recruited to the DIRECT-Prevent 1 trial and those with existing retinopathy were recruited to DIRECT-Protect 1, and were assigned to candesartan 16 mg once a day or matching placebo. After 1 month, the dose was doubled to 32 mg. Investigators and participants were unaware of the treatment allocation status. The primary endpoints were incidence and progression of retinopathy and were defined as at least a two-step and at least a three-step increase on the Early Treatment Diabetic Retinopathy Study (ETDRS) scale, respectively. These trials are registered with ClinicalTrials.gov, numbers NCT00252733 for DIRECT-Prevent 1 and NCT00252720 for DIRECT-Protect 1.1421 participants (aged 18-50 years) were randomly assigned to candesartan (n=711) or to placebo (n=710) in DIRECT-Prevent 1, and 1905 (aged 18-55 years) to candesartan (n=951) or to placebo (n=954) in DIRECT-Protect 1. Incidence of retinopathy was seen in 178 (25%) participants in the candesartan group versus 217 (31%) in the placebo group. Progression of retinopathy occurred in 127 (13%) participants in the candesartan group versus 124 (13%) in the placebo group. Hazard ratio (HR for candesartan vs placebo) was 0.82 (95% CI 0.67-1.00, p=0.0508) for incidence of retinopathy and 1.02 (0.80-1.31, p=0.85) for progression of retinopathy. The post-hoc outcome of at least a three-step increase for incidence yielded an HR of 0.65 (0.48-0.87, p=0.0034), which was attenuated but still significant after adjustment for baseline characteristics (0.71, 0.53-0.95, p=0.046). Final ETDRS level was more likely to have improved with candesartan treatment in both DIRECT-Prevent 1 (odds 1.16, 95% CI 1.05-1.30, p=0.0048) and DIRECT-Protect 1 (1.12, 95% CI 1.01-1.25, p=0.0264). Adverse events did not differ between the treatment groups.Although candesartan reduces the incidence of retinopathy, we did not see a beneficial effect on retinopathy progression.","Effect of candesartan on prevention (DIRECT-Prevent 1) and progression (DIRECT-Protect 1) of retinopathy in type 1 diabetes: randomised, placebo-controlled trials."
"957","Lancet.1301","0.0034",18823656,2008,"Results of previous studies suggest that renin-angiotensin system blockers might reduce the burden of diabetic retinopathy. We therefore designed the DIabetic REtinopathy Candesartan Trials (DIRECT) Programme to assess whether candesartan could reduce the incidence and progression of retinopathy in type 1 diabetes.Two randomised, double-blind, parallel-design, placebo-controlled trials were done in 309 centres worldwide. Participants with normotensive, normoalbuminuric type 1 diabetes without retinopathy were recruited to the DIRECT-Prevent 1 trial and those with existing retinopathy were recruited to DIRECT-Protect 1, and were assigned to candesartan 16 mg once a day or matching placebo. After 1 month, the dose was doubled to 32 mg. Investigators and participants were unaware of the treatment allocation status. The primary endpoints were incidence and progression of retinopathy and were defined as at least a two-step and at least a three-step increase on the Early Treatment Diabetic Retinopathy Study (ETDRS) scale, respectively. These trials are registered with ClinicalTrials.gov, numbers NCT00252733 for DIRECT-Prevent 1 and NCT00252720 for DIRECT-Protect 1.1421 participants (aged 18-50 years) were randomly assigned to candesartan (n=711) or to placebo (n=710) in DIRECT-Prevent 1, and 1905 (aged 18-55 years) to candesartan (n=951) or to placebo (n=954) in DIRECT-Protect 1. Incidence of retinopathy was seen in 178 (25%) participants in the candesartan group versus 217 (31%) in the placebo group. Progression of retinopathy occurred in 127 (13%) participants in the candesartan group versus 124 (13%) in the placebo group. Hazard ratio (HR for candesartan vs placebo) was 0.82 (95% CI 0.67-1.00, p=0.0508) for incidence of retinopathy and 1.02 (0.80-1.31, p=0.85) for progression of retinopathy. The post-hoc outcome of at least a three-step increase for incidence yielded an HR of 0.65 (0.48-0.87, p=0.0034), which was attenuated but still significant after adjustment for baseline characteristics (0.71, 0.53-0.95, p=0.046). Final ETDRS level was more likely to have improved with candesartan treatment in both DIRECT-Prevent 1 (odds 1.16, 95% CI 1.05-1.30, p=0.0048) and DIRECT-Protect 1 (1.12, 95% CI 1.01-1.25, p=0.0264). Adverse events did not differ between the treatment groups.Although candesartan reduces the incidence of retinopathy, we did not see a beneficial effect on retinopathy progression.","Effect of candesartan on prevention (DIRECT-Prevent 1) and progression (DIRECT-Protect 1) of retinopathy in type 1 diabetes: randomised, placebo-controlled trials."
"958","Lancet.1311","0.046",18823656,2008,"Results of previous studies suggest that renin-angiotensin system blockers might reduce the burden of diabetic retinopathy. We therefore designed the DIabetic REtinopathy Candesartan Trials (DIRECT) Programme to assess whether candesartan could reduce the incidence and progression of retinopathy in type 1 diabetes.Two randomised, double-blind, parallel-design, placebo-controlled trials were done in 309 centres worldwide. Participants with normotensive, normoalbuminuric type 1 diabetes without retinopathy were recruited to the DIRECT-Prevent 1 trial and those with existing retinopathy were recruited to DIRECT-Protect 1, and were assigned to candesartan 16 mg once a day or matching placebo. After 1 month, the dose was doubled to 32 mg. Investigators and participants were unaware of the treatment allocation status. The primary endpoints were incidence and progression of retinopathy and were defined as at least a two-step and at least a three-step increase on the Early Treatment Diabetic Retinopathy Study (ETDRS) scale, respectively. These trials are registered with ClinicalTrials.gov, numbers NCT00252733 for DIRECT-Prevent 1 and NCT00252720 for DIRECT-Protect 1.1421 participants (aged 18-50 years) were randomly assigned to candesartan (n=711) or to placebo (n=710) in DIRECT-Prevent 1, and 1905 (aged 18-55 years) to candesartan (n=951) or to placebo (n=954) in DIRECT-Protect 1. Incidence of retinopathy was seen in 178 (25%) participants in the candesartan group versus 217 (31%) in the placebo group. Progression of retinopathy occurred in 127 (13%) participants in the candesartan group versus 124 (13%) in the placebo group. Hazard ratio (HR for candesartan vs placebo) was 0.82 (95% CI 0.67-1.00, p=0.0508) for incidence of retinopathy and 1.02 (0.80-1.31, p=0.85) for progression of retinopathy. The post-hoc outcome of at least a three-step increase for incidence yielded an HR of 0.65 (0.48-0.87, p=0.0034), which was attenuated but still significant after adjustment for baseline characteristics (0.71, 0.53-0.95, p=0.046). Final ETDRS level was more likely to have improved with candesartan treatment in both DIRECT-Prevent 1 (odds 1.16, 95% CI 1.05-1.30, p=0.0048) and DIRECT-Protect 1 (1.12, 95% CI 1.01-1.25, p=0.0264). Adverse events did not differ between the treatment groups.Although candesartan reduces the incidence of retinopathy, we did not see a beneficial effect on retinopathy progression.","Effect of candesartan on prevention (DIRECT-Prevent 1) and progression (DIRECT-Protect 1) of retinopathy in type 1 diabetes: randomised, placebo-controlled trials."
"959","Lancet.1321","0.0048",18823656,2008,"Results of previous studies suggest that renin-angiotensin system blockers might reduce the burden of diabetic retinopathy. We therefore designed the DIabetic REtinopathy Candesartan Trials (DIRECT) Programme to assess whether candesartan could reduce the incidence and progression of retinopathy in type 1 diabetes.Two randomised, double-blind, parallel-design, placebo-controlled trials were done in 309 centres worldwide. Participants with normotensive, normoalbuminuric type 1 diabetes without retinopathy were recruited to the DIRECT-Prevent 1 trial and those with existing retinopathy were recruited to DIRECT-Protect 1, and were assigned to candesartan 16 mg once a day or matching placebo. After 1 month, the dose was doubled to 32 mg. Investigators and participants were unaware of the treatment allocation status. The primary endpoints were incidence and progression of retinopathy and were defined as at least a two-step and at least a three-step increase on the Early Treatment Diabetic Retinopathy Study (ETDRS) scale, respectively. These trials are registered with ClinicalTrials.gov, numbers NCT00252733 for DIRECT-Prevent 1 and NCT00252720 for DIRECT-Protect 1.1421 participants (aged 18-50 years) were randomly assigned to candesartan (n=711) or to placebo (n=710) in DIRECT-Prevent 1, and 1905 (aged 18-55 years) to candesartan (n=951) or to placebo (n=954) in DIRECT-Protect 1. Incidence of retinopathy was seen in 178 (25%) participants in the candesartan group versus 217 (31%) in the placebo group. Progression of retinopathy occurred in 127 (13%) participants in the candesartan group versus 124 (13%) in the placebo group. Hazard ratio (HR for candesartan vs placebo) was 0.82 (95% CI 0.67-1.00, p=0.0508) for incidence of retinopathy and 1.02 (0.80-1.31, p=0.85) for progression of retinopathy. The post-hoc outcome of at least a three-step increase for incidence yielded an HR of 0.65 (0.48-0.87, p=0.0034), which was attenuated but still significant after adjustment for baseline characteristics (0.71, 0.53-0.95, p=0.046). Final ETDRS level was more likely to have improved with candesartan treatment in both DIRECT-Prevent 1 (odds 1.16, 95% CI 1.05-1.30, p=0.0048) and DIRECT-Protect 1 (1.12, 95% CI 1.01-1.25, p=0.0264). Adverse events did not differ between the treatment groups.Although candesartan reduces the incidence of retinopathy, we did not see a beneficial effect on retinopathy progression.","Effect of candesartan on prevention (DIRECT-Prevent 1) and progression (DIRECT-Protect 1) of retinopathy in type 1 diabetes: randomised, placebo-controlled trials."
"960","Lancet.1331","0.0264",18823656,2008,"Results of previous studies suggest that renin-angiotensin system blockers might reduce the burden of diabetic retinopathy. We therefore designed the DIabetic REtinopathy Candesartan Trials (DIRECT) Programme to assess whether candesartan could reduce the incidence and progression of retinopathy in type 1 diabetes.Two randomised, double-blind, parallel-design, placebo-controlled trials were done in 309 centres worldwide. Participants with normotensive, normoalbuminuric type 1 diabetes without retinopathy were recruited to the DIRECT-Prevent 1 trial and those with existing retinopathy were recruited to DIRECT-Protect 1, and were assigned to candesartan 16 mg once a day or matching placebo. After 1 month, the dose was doubled to 32 mg. Investigators and participants were unaware of the treatment allocation status. The primary endpoints were incidence and progression of retinopathy and were defined as at least a two-step and at least a three-step increase on the Early Treatment Diabetic Retinopathy Study (ETDRS) scale, respectively. These trials are registered with ClinicalTrials.gov, numbers NCT00252733 for DIRECT-Prevent 1 and NCT00252720 for DIRECT-Protect 1.1421 participants (aged 18-50 years) were randomly assigned to candesartan (n=711) or to placebo (n=710) in DIRECT-Prevent 1, and 1905 (aged 18-55 years) to candesartan (n=951) or to placebo (n=954) in DIRECT-Protect 1. Incidence of retinopathy was seen in 178 (25%) participants in the candesartan group versus 217 (31%) in the placebo group. Progression of retinopathy occurred in 127 (13%) participants in the candesartan group versus 124 (13%) in the placebo group. Hazard ratio (HR for candesartan vs placebo) was 0.82 (95% CI 0.67-1.00, p=0.0508) for incidence of retinopathy and 1.02 (0.80-1.31, p=0.85) for progression of retinopathy. The post-hoc outcome of at least a three-step increase for incidence yielded an HR of 0.65 (0.48-0.87, p=0.0034), which was attenuated but still significant after adjustment for baseline characteristics (0.71, 0.53-0.95, p=0.046). Final ETDRS level was more likely to have improved with candesartan treatment in both DIRECT-Prevent 1 (odds 1.16, 95% CI 1.05-1.30, p=0.0048) and DIRECT-Protect 1 (1.12, 95% CI 1.01-1.25, p=0.0264). Adverse events did not differ between the treatment groups.Although candesartan reduces the incidence of retinopathy, we did not see a beneficial effect on retinopathy progression.","Effect of candesartan on prevention (DIRECT-Prevent 1) and progression (DIRECT-Protect 1) of retinopathy in type 1 diabetes: randomised, placebo-controlled trials."
"961","Lancet.1251","0.2",18823658,2008,"Diabetic retinopathy remains a leading cause of visual loss in people of working age. We examined whether candesartan treatment could slow the progression and, secondly, induce regression of retinopathy in people with type 2 diabetes.We did a randomised, double-blind, parallel-group, placebo-controlled trial in 309 centres worldwide. We recruited normoalbuminuric, normotensive, or treated hypertensive people with type 2 diabetes with mild to moderately severe retinopathy and assigned them to candesartan 16 mg once a day or placebo. After a month, the dose was doubled to 32 mg once per day. Investigators and patients were unaware of the treatment allocation status. Progression of retinopathy was the primary endpoint, and regression was a secondary endpoint. Analysis was by intention to treat. The trial is registered with ClinicalTrials.gov, number NCT00252694.1905 participants (aged 37-75 years) were randomised to candesartan (n=951) or placebo (n=954). 161 (17%) patients in the candesartan group and 182 (19%) in the placebo group had progression of retinopathy by three steps or more on the Early Treatment Diabetic Retinopathy Study scale. The risk of progression of retinopathy was non-significantly reduced by 13% in patients on candesartan compared with those on placebo (hazard ratio [HR] 0.87, 95% CI 0.70-1.08, p=0.20). Regression on active treatment was increased by 34% (1.34, 1.08-1.68, p=0.009). HRs were not attenuated by adjustment for baseline risk factors or changes in blood pressure during the trial. An overall change towards less severe retinopathy by the end of the trial was observed in the candesartan group (odds 1.17, 95% CI 1.05-1.30, p=0.003). Adverse events did not differ between the treatment groups.Treatment with candesartan in type 2 diabetic patients with mild to moderate retinopathy might induce improvement of retinopathy.","Effect of candesartan on progression and regression of retinopathy in type 2 diabetes (DIRECT-Protect 2): a randomised placebo-controlled trial."
"962","Lancet.1261","0.009",18823658,2008,"Diabetic retinopathy remains a leading cause of visual loss in people of working age. We examined whether candesartan treatment could slow the progression and, secondly, induce regression of retinopathy in people with type 2 diabetes.We did a randomised, double-blind, parallel-group, placebo-controlled trial in 309 centres worldwide. We recruited normoalbuminuric, normotensive, or treated hypertensive people with type 2 diabetes with mild to moderately severe retinopathy and assigned them to candesartan 16 mg once a day or placebo. After a month, the dose was doubled to 32 mg once per day. Investigators and patients were unaware of the treatment allocation status. Progression of retinopathy was the primary endpoint, and regression was a secondary endpoint. Analysis was by intention to treat. The trial is registered with ClinicalTrials.gov, number NCT00252694.1905 participants (aged 37-75 years) were randomised to candesartan (n=951) or placebo (n=954). 161 (17%) patients in the candesartan group and 182 (19%) in the placebo group had progression of retinopathy by three steps or more on the Early Treatment Diabetic Retinopathy Study scale. The risk of progression of retinopathy was non-significantly reduced by 13% in patients on candesartan compared with those on placebo (hazard ratio [HR] 0.87, 95% CI 0.70-1.08, p=0.20). Regression on active treatment was increased by 34% (1.34, 1.08-1.68, p=0.009). HRs were not attenuated by adjustment for baseline risk factors or changes in blood pressure during the trial. An overall change towards less severe retinopathy by the end of the trial was observed in the candesartan group (odds 1.17, 95% CI 1.05-1.30, p=0.003). Adverse events did not differ between the treatment groups.Treatment with candesartan in type 2 diabetic patients with mild to moderate retinopathy might induce improvement of retinopathy.","Effect of candesartan on progression and regression of retinopathy in type 2 diabetes (DIRECT-Protect 2): a randomised placebo-controlled trial."
"963","Lancet.1271","0.003",18823658,2008,"Diabetic retinopathy remains a leading cause of visual loss in people of working age. We examined whether candesartan treatment could slow the progression and, secondly, induce regression of retinopathy in people with type 2 diabetes.We did a randomised, double-blind, parallel-group, placebo-controlled trial in 309 centres worldwide. We recruited normoalbuminuric, normotensive, or treated hypertensive people with type 2 diabetes with mild to moderately severe retinopathy and assigned them to candesartan 16 mg once a day or placebo. After a month, the dose was doubled to 32 mg once per day. Investigators and patients were unaware of the treatment allocation status. Progression of retinopathy was the primary endpoint, and regression was a secondary endpoint. Analysis was by intention to treat. The trial is registered with ClinicalTrials.gov, number NCT00252694.1905 participants (aged 37-75 years) were randomised to candesartan (n=951) or placebo (n=954). 161 (17%) patients in the candesartan group and 182 (19%) in the placebo group had progression of retinopathy by three steps or more on the Early Treatment Diabetic Retinopathy Study scale. The risk of progression of retinopathy was non-significantly reduced by 13% in patients on candesartan compared with those on placebo (hazard ratio [HR] 0.87, 95% CI 0.70-1.08, p=0.20). Regression on active treatment was increased by 34% (1.34, 1.08-1.68, p=0.009). HRs were not attenuated by adjustment for baseline risk factors or changes in blood pressure during the trial. An overall change towards less severe retinopathy by the end of the trial was observed in the candesartan group (odds 1.17, 95% CI 1.05-1.30, p=0.003). Adverse events did not differ between the treatment groups.Treatment with candesartan in type 2 diabetic patients with mild to moderate retinopathy might induce improvement of retinopathy.","Effect of candesartan on progression and regression of retinopathy in type 2 diabetes (DIRECT-Protect 2): a randomised placebo-controlled trial."
"964","Lancet.83","7.00E-14",18834626,2008,"Hyperuricaemia, a highly heritable trait, is a key risk factor for gout. We aimed to identify novel genes associated with serum uric acid concentration and gout.Genome-wide association studies were done for serum uric acid in 7699 participants in the Framingham cohort and in 4148 participants in the Rotterdam cohort. Genome-wide significant single nucleotide polymorphisms (SNPs) were replicated in white (n=11 024) and black (n=3843) individuals who took part in the study of Atherosclerosis Risk in Communities (ARIC). The SNPs that reached genome-wide significant association with uric acid in either the Framingham cohort (p<5.0 x 10(-8)) or the Rotterdam cohort (p<1.0 x 10(-7)) were evaluated with gout. The results obtained in white participants were combined using meta-analysis.Three loci in the Framingham cohort and two in the Rotterdam cohort showed genome-wide association with uric acid. Top SNPs in each locus were: missense rs16890979 in SLC2A9 (p=7.0 x 10(-168) and 2.9 x 10(-18) for white and black participants, respectively); missense rs2231142 in ABCG2 (p=2.5 x 10(-60) and 9.8 x 10(-4)), and rs1165205 in SLC17A3 (p=3.3 x 10(-26) and 0.33). All SNPs were direction-consistent with gout in white participants: rs16890979 (OR 0.59 per T allele, 95% CI 0.52-0.68, p=7.0 x 10(-14)), rs2231142 (1.74, 1.51-1.99, p=3.3 x 10(-15)), and rs1165205 (0.85, 0.77-0.94, p=0.002). In black participants of the ARIC study, rs2231142 was direction-consistent with gout (1.71, 1.06-2.77, p=0.028). An additive genetic risk score of high-risk alleles at the three loci showed graded associations with uric acid (272-351 mumol/L in the Framingham cohort, 269-386 mumol/L in the Rotterdam cohort, and 303-426 mumol/L in white participants of the ARIC study) and gout (frequency 2-13% in the Framingham cohort, 2-8% in the Rotterdam cohort, and 1-18% in white participants in the ARIC study).We identified three genetic loci associated with uric acid concentration and gout. A score based on genes with a putative role in renal urate handling showed a substantial risk for gout.","Association of three genetic loci with uric acid concentration and risk of gout: a genome-wide association study."
"965","Lancet.84","3.30E-15",18834626,2008,"Hyperuricaemia, a highly heritable trait, is a key risk factor for gout. We aimed to identify novel genes associated with serum uric acid concentration and gout.Genome-wide association studies were done for serum uric acid in 7699 participants in the Framingham cohort and in 4148 participants in the Rotterdam cohort. Genome-wide significant single nucleotide polymorphisms (SNPs) were replicated in white (n=11 024) and black (n=3843) individuals who took part in the study of Atherosclerosis Risk in Communities (ARIC). The SNPs that reached genome-wide significant association with uric acid in either the Framingham cohort (p<5.0 x 10(-8)) or the Rotterdam cohort (p<1.0 x 10(-7)) were evaluated with gout. The results obtained in white participants were combined using meta-analysis.Three loci in the Framingham cohort and two in the Rotterdam cohort showed genome-wide association with uric acid. Top SNPs in each locus were: missense rs16890979 in SLC2A9 (p=7.0 x 10(-168) and 2.9 x 10(-18) for white and black participants, respectively); missense rs2231142 in ABCG2 (p=2.5 x 10(-60) and 9.8 x 10(-4)), and rs1165205 in SLC17A3 (p=3.3 x 10(-26) and 0.33). All SNPs were direction-consistent with gout in white participants: rs16890979 (OR 0.59 per T allele, 95% CI 0.52-0.68, p=7.0 x 10(-14)), rs2231142 (1.74, 1.51-1.99, p=3.3 x 10(-15)), and rs1165205 (0.85, 0.77-0.94, p=0.002). In black participants of the ARIC study, rs2231142 was direction-consistent with gout (1.71, 1.06-2.77, p=0.028). An additive genetic risk score of high-risk alleles at the three loci showed graded associations with uric acid (272-351 mumol/L in the Framingham cohort, 269-386 mumol/L in the Rotterdam cohort, and 303-426 mumol/L in white participants of the ARIC study) and gout (frequency 2-13% in the Framingham cohort, 2-8% in the Rotterdam cohort, and 1-18% in white participants in the ARIC study).We identified three genetic loci associated with uric acid concentration and gout. A score based on genes with a putative role in renal urate handling showed a substantial risk for gout.","Association of three genetic loci with uric acid concentration and risk of gout: a genome-wide association study."
"966","Lancet.85","0.002",18834626,2008,"Hyperuricaemia, a highly heritable trait, is a key risk factor for gout. We aimed to identify novel genes associated with serum uric acid concentration and gout.Genome-wide association studies were done for serum uric acid in 7699 participants in the Framingham cohort and in 4148 participants in the Rotterdam cohort. Genome-wide significant single nucleotide polymorphisms (SNPs) were replicated in white (n=11 024) and black (n=3843) individuals who took part in the study of Atherosclerosis Risk in Communities (ARIC). The SNPs that reached genome-wide significant association with uric acid in either the Framingham cohort (p<5.0 x 10(-8)) or the Rotterdam cohort (p<1.0 x 10(-7)) were evaluated with gout. The results obtained in white participants were combined using meta-analysis.Three loci in the Framingham cohort and two in the Rotterdam cohort showed genome-wide association with uric acid. Top SNPs in each locus were: missense rs16890979 in SLC2A9 (p=7.0 x 10(-168) and 2.9 x 10(-18) for white and black participants, respectively); missense rs2231142 in ABCG2 (p=2.5 x 10(-60) and 9.8 x 10(-4)), and rs1165205 in SLC17A3 (p=3.3 x 10(-26) and 0.33). All SNPs were direction-consistent with gout in white participants: rs16890979 (OR 0.59 per T allele, 95% CI 0.52-0.68, p=7.0 x 10(-14)), rs2231142 (1.74, 1.51-1.99, p=3.3 x 10(-15)), and rs1165205 (0.85, 0.77-0.94, p=0.002). In black participants of the ARIC study, rs2231142 was direction-consistent with gout (1.71, 1.06-2.77, p=0.028). An additive genetic risk score of high-risk alleles at the three loci showed graded associations with uric acid (272-351 mumol/L in the Framingham cohort, 269-386 mumol/L in the Rotterdam cohort, and 303-426 mumol/L in white participants of the ARIC study) and gout (frequency 2-13% in the Framingham cohort, 2-8% in the Rotterdam cohort, and 1-18% in white participants in the ARIC study).We identified three genetic loci associated with uric acid concentration and gout. A score based on genes with a putative role in renal urate handling showed a substantial risk for gout.","Association of three genetic loci with uric acid concentration and risk of gout: a genome-wide association study."
"967","Lancet.86","0.028",18834626,2008,"Hyperuricaemia, a highly heritable trait, is a key risk factor for gout. We aimed to identify novel genes associated with serum uric acid concentration and gout.Genome-wide association studies were done for serum uric acid in 7699 participants in the Framingham cohort and in 4148 participants in the Rotterdam cohort. Genome-wide significant single nucleotide polymorphisms (SNPs) were replicated in white (n=11 024) and black (n=3843) individuals who took part in the study of Atherosclerosis Risk in Communities (ARIC). The SNPs that reached genome-wide significant association with uric acid in either the Framingham cohort (p<5.0 x 10(-8)) or the Rotterdam cohort (p<1.0 x 10(-7)) were evaluated with gout. The results obtained in white participants were combined using meta-analysis.Three loci in the Framingham cohort and two in the Rotterdam cohort showed genome-wide association with uric acid. Top SNPs in each locus were: missense rs16890979 in SLC2A9 (p=7.0 x 10(-168) and 2.9 x 10(-18) for white and black participants, respectively); missense rs2231142 in ABCG2 (p=2.5 x 10(-60) and 9.8 x 10(-4)), and rs1165205 in SLC17A3 (p=3.3 x 10(-26) and 0.33). All SNPs were direction-consistent with gout in white participants: rs16890979 (OR 0.59 per T allele, 95% CI 0.52-0.68, p=7.0 x 10(-14)), rs2231142 (1.74, 1.51-1.99, p=3.3 x 10(-15)), and rs1165205 (0.85, 0.77-0.94, p=0.002). In black participants of the ARIC study, rs2231142 was direction-consistent with gout (1.71, 1.06-2.77, p=0.028). An additive genetic risk score of high-risk alleles at the three loci showed graded associations with uric acid (272-351 mumol/L in the Framingham cohort, 269-386 mumol/L in the Rotterdam cohort, and 303-426 mumol/L in white participants of the ARIC study) and gout (frequency 2-13% in the Framingham cohort, 2-8% in the Rotterdam cohort, and 1-18% in white participants in the ARIC study).We identified three genetic loci associated with uric acid concentration and gout. A score based on genes with a putative role in renal urate handling showed a substantial risk for gout.","Association of three genetic loci with uric acid concentration and risk of gout: a genome-wide association study."
"968","JAMA.4721","0.75",18984888,2008,"Folate, vitamin B(6), and vitamin B(12) are thought to play an important role in cancer prevention.To evaluate the effect of combined folic acid, vitamin B(6), and vitamin B(12) treatment on cancer risk in women at high risk for cardiovascular disease.In the Women's Antioxidant and Folic Acid Cardiovascular Study, 5442 US female health professionals aged 42 years or older, with preexisting cardiovascular disease or 3 or more coronary risk factors, were randomly assigned to receive either a daily combination of folic acid, vitamin B(6), and vitamin B(12) or a matching placebo. They were treated for 7.3 years from April 1998 through July 31, 2005.Daily supplementation of a combination of 2.5 mg of folic acid, 50 mg of vitamin B(6), and 1 mg of vitamin B(12) (n = 2721) or placebo (n = 2721).Confirmed newly diagnosed total invasive cancer or breast cancer.A total of 379 women developed invasive cancer (187 in the active treatment group and 192 in the placebo group). Compared with placebo, women receiving the active treatment had similar risk of developing total invasive cancer (101.1/10,000 person-years for the active treatment group vs 104.3/10,000 person-years for placebo group; hazard ratio [HR], 0.97; 95% confidence interval [CI], 0.79-1.18; P = .75), breast cancer (37.8/10,000 person-years vs 45.6/10,000 person-years, respectively; HR, 0.83; 95% CI, 0.60-1.14; P = .24), or any cancer death (24.6/10,000 person-years vs 30.1/10,000 person-years, respectively; HR, 0.82; 95% CI, 0.56-1.21; P = .32).Combined folic acid, vitamin B(6), and vitamin B(12) treatment had no significant effect on overall risk of total invasive cancer or breast cancer among women during the folic acid fortification era.clinicaltrials.gov Identifier: NCT00000541.","Effect of combined folic acid, vitamin B6, and vitamin B12 on cancer risk in women: a randomized trial."
"969","JAMA.4731","0.24",18984888,2008,"Folate, vitamin B(6), and vitamin B(12) are thought to play an important role in cancer prevention.To evaluate the effect of combined folic acid, vitamin B(6), and vitamin B(12) treatment on cancer risk in women at high risk for cardiovascular disease.In the Women's Antioxidant and Folic Acid Cardiovascular Study, 5442 US female health professionals aged 42 years or older, with preexisting cardiovascular disease or 3 or more coronary risk factors, were randomly assigned to receive either a daily combination of folic acid, vitamin B(6), and vitamin B(12) or a matching placebo. They were treated for 7.3 years from April 1998 through July 31, 2005.Daily supplementation of a combination of 2.5 mg of folic acid, 50 mg of vitamin B(6), and 1 mg of vitamin B(12) (n = 2721) or placebo (n = 2721).Confirmed newly diagnosed total invasive cancer or breast cancer.A total of 379 women developed invasive cancer (187 in the active treatment group and 192 in the placebo group). Compared with placebo, women receiving the active treatment had similar risk of developing total invasive cancer (101.1/10,000 person-years for the active treatment group vs 104.3/10,000 person-years for placebo group; hazard ratio [HR], 0.97; 95% confidence interval [CI], 0.79-1.18; P = .75), breast cancer (37.8/10,000 person-years vs 45.6/10,000 person-years, respectively; HR, 0.83; 95% CI, 0.60-1.14; P = .24), or any cancer death (24.6/10,000 person-years vs 30.1/10,000 person-years, respectively; HR, 0.82; 95% CI, 0.56-1.21; P = .32).Combined folic acid, vitamin B(6), and vitamin B(12) treatment had no significant effect on overall risk of total invasive cancer or breast cancer among women during the folic acid fortification era.clinicaltrials.gov Identifier: NCT00000541.","Effect of combined folic acid, vitamin B6, and vitamin B12 on cancer risk in women: a randomized trial."
"970","JAMA.4741","0.32",18984888,2008,"Folate, vitamin B(6), and vitamin B(12) are thought to play an important role in cancer prevention.To evaluate the effect of combined folic acid, vitamin B(6), and vitamin B(12) treatment on cancer risk in women at high risk for cardiovascular disease.In the Women's Antioxidant and Folic Acid Cardiovascular Study, 5442 US female health professionals aged 42 years or older, with preexisting cardiovascular disease or 3 or more coronary risk factors, were randomly assigned to receive either a daily combination of folic acid, vitamin B(6), and vitamin B(12) or a matching placebo. They were treated for 7.3 years from April 1998 through July 31, 2005.Daily supplementation of a combination of 2.5 mg of folic acid, 50 mg of vitamin B(6), and 1 mg of vitamin B(12) (n = 2721) or placebo (n = 2721).Confirmed newly diagnosed total invasive cancer or breast cancer.A total of 379 women developed invasive cancer (187 in the active treatment group and 192 in the placebo group). Compared with placebo, women receiving the active treatment had similar risk of developing total invasive cancer (101.1/10,000 person-years for the active treatment group vs 104.3/10,000 person-years for placebo group; hazard ratio [HR], 0.97; 95% confidence interval [CI], 0.79-1.18; P = .75), breast cancer (37.8/10,000 person-years vs 45.6/10,000 person-years, respectively; HR, 0.83; 95% CI, 0.60-1.14; P = .24), or any cancer death (24.6/10,000 person-years vs 30.1/10,000 person-years, respectively; HR, 0.82; 95% CI, 0.56-1.21; P = .32).Combined folic acid, vitamin B(6), and vitamin B(12) treatment had no significant effect on overall risk of total invasive cancer or breast cancer among women during the folic acid fortification era.clinicaltrials.gov Identifier: NCT00000541.","Effect of combined folic acid, vitamin B6, and vitamin B12 on cancer risk in women: a randomized trial."
"971","JAMA.4331","0.001",18984889,2008,"Sudden cardiac death after myocardial infarction (MI) has not been assessed recently in the community. Risk stratification for sudden cardiac death after MI commonly relies on baseline characteristics and little is known about the relationship between recurrent ischemia or heart failure and sudden cardiac death.To evaluate the risk of sudden cardiac death after MI and the impact of recurrent ischemia and heart failure on sudden cardiac death.Population-based surveillance study of 2997 residents (mean [SD] age, 67 [14] years; 59% were men) experiencing an MI in Olmsted County, Minnesota, between 1979 and 2005, and followed up through February 29, 2008.Sudden cardiac death defined as out-of-hospital death due to coronary disease; and observed survival free of sudden cardiac death compared with that expected in Olmsted County, Minnesota.During a median follow-up of 4.7 years (25th-75th percentile, 1.6-7.1 years), 1160 deaths occurred, 282 from sudden cardiac death (24%). The 30-day cumulative incidence of sudden cardiac death was 1.2% (95% confidence interval [CI], 0.8%-1.6%). Thereafter, the rate of sudden cardiac death was constant at 1.2% per year yielding a 5-year cumulative incidence of 6.9% (95% CI, 5.9%-7.9%). The 30-day incidence of sudden cardiac death was 4-fold higher than expected (standardized mortality ratio, 4.2; 95% CI, 2.9-5.8). The risk of sudden cardiac death has declined significantly over time (hazard ratio [HR], 0.62 [95% CI, 0.44-0.88] for MIs that occurred between 1997 and 2005 compared with between 1979 and 1987; P = .03). The recurrent events of ischemia (n = 842), heart failure (n = 365), or both (n = 873) occurred in 2080 patients. After adjustment for baseline characteristics, recurrent ischemia was not associated with sudden cardiac death (HR, 1.26 [95% CI, 0.96-1.65]; P = .09), while heart failure markedly increased the risk of sudden cardiac death (HR, 4.20 [95% CI, 3.10-5.69]; P < .001).The risk of sudden cardiac death following MI in community practice has declined significantly over the past 30 years. Sudden cardiac death is independently associated with heart failure but not with recurrent ischemia.","Sudden death after myocardial infarction."
"972","JAMA.4701","0.03",18984889,2008,"Sudden cardiac death after myocardial infarction (MI) has not been assessed recently in the community. Risk stratification for sudden cardiac death after MI commonly relies on baseline characteristics and little is known about the relationship between recurrent ischemia or heart failure and sudden cardiac death.To evaluate the risk of sudden cardiac death after MI and the impact of recurrent ischemia and heart failure on sudden cardiac death.Population-based surveillance study of 2997 residents (mean [SD] age, 67 [14] years; 59% were men) experiencing an MI in Olmsted County, Minnesota, between 1979 and 2005, and followed up through February 29, 2008.Sudden cardiac death defined as out-of-hospital death due to coronary disease; and observed survival free of sudden cardiac death compared with that expected in Olmsted County, Minnesota.During a median follow-up of 4.7 years (25th-75th percentile, 1.6-7.1 years), 1160 deaths occurred, 282 from sudden cardiac death (24%). The 30-day cumulative incidence of sudden cardiac death was 1.2% (95% confidence interval [CI], 0.8%-1.6%). Thereafter, the rate of sudden cardiac death was constant at 1.2% per year yielding a 5-year cumulative incidence of 6.9% (95% CI, 5.9%-7.9%). The 30-day incidence of sudden cardiac death was 4-fold higher than expected (standardized mortality ratio, 4.2; 95% CI, 2.9-5.8). The risk of sudden cardiac death has declined significantly over time (hazard ratio [HR], 0.62 [95% CI, 0.44-0.88] for MIs that occurred between 1997 and 2005 compared with between 1979 and 1987; P = .03). The recurrent events of ischemia (n = 842), heart failure (n = 365), or both (n = 873) occurred in 2080 patients. After adjustment for baseline characteristics, recurrent ischemia was not associated with sudden cardiac death (HR, 1.26 [95% CI, 0.96-1.65]; P = .09), while heart failure markedly increased the risk of sudden cardiac death (HR, 4.20 [95% CI, 3.10-5.69]; P < .001).The risk of sudden cardiac death following MI in community practice has declined significantly over the past 30 years. Sudden cardiac death is independently associated with heart failure but not with recurrent ischemia.","Sudden death after myocardial infarction."
"973","JAMA.4711","0.09",18984889,2008,"Sudden cardiac death after myocardial infarction (MI) has not been assessed recently in the community. Risk stratification for sudden cardiac death after MI commonly relies on baseline characteristics and little is known about the relationship between recurrent ischemia or heart failure and sudden cardiac death.To evaluate the risk of sudden cardiac death after MI and the impact of recurrent ischemia and heart failure on sudden cardiac death.Population-based surveillance study of 2997 residents (mean [SD] age, 67 [14] years; 59% were men) experiencing an MI in Olmsted County, Minnesota, between 1979 and 2005, and followed up through February 29, 2008.Sudden cardiac death defined as out-of-hospital death due to coronary disease; and observed survival free of sudden cardiac death compared with that expected in Olmsted County, Minnesota.During a median follow-up of 4.7 years (25th-75th percentile, 1.6-7.1 years), 1160 deaths occurred, 282 from sudden cardiac death (24%). The 30-day cumulative incidence of sudden cardiac death was 1.2% (95% confidence interval [CI], 0.8%-1.6%). Thereafter, the rate of sudden cardiac death was constant at 1.2% per year yielding a 5-year cumulative incidence of 6.9% (95% CI, 5.9%-7.9%). The 30-day incidence of sudden cardiac death was 4-fold higher than expected (standardized mortality ratio, 4.2; 95% CI, 2.9-5.8). The risk of sudden cardiac death has declined significantly over time (hazard ratio [HR], 0.62 [95% CI, 0.44-0.88] for MIs that occurred between 1997 and 2005 compared with between 1979 and 1987; P = .03). The recurrent events of ischemia (n = 842), heart failure (n = 365), or both (n = 873) occurred in 2080 patients. After adjustment for baseline characteristics, recurrent ischemia was not associated with sudden cardiac death (HR, 1.26 [95% CI, 0.96-1.65]; P = .09), while heart failure markedly increased the risk of sudden cardiac death (HR, 4.20 [95% CI, 3.10-5.69]; P < .001).The risk of sudden cardiac death following MI in community practice has declined significantly over the past 30 years. Sudden cardiac death is independently associated with heart failure but not with recurrent ischemia.","Sudden death after myocardial infarction."
"974","JAMA.4591","0.86",18997197,2008,"Basic research and observational studies suggest vitamin E or vitamin C may reduce the risk of cardiovascular disease. However, few long-term trials have evaluated men at initially low risk of cardiovascular disease, and no previous trial in men has examined vitamin C alone in the prevention of cardiovascular disease.To evaluate whether long-term vitamin E or vitamin C supplementation decreases the risk of major cardiovascular events among men.The Physicians' Health Study II was a randomized, double-blind, placebo-controlled factorial trial of vitamin E and vitamin C that began in 1997 and continued until its scheduled completion on August 31, 2007. There were 14,641 US male physicians enrolled, who were initially aged 50 years or older, including 754 men (5.1%) with prevalent cardiovascular disease at randomization.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.A composite end point of major cardiovascular events (nonfatal myocardial infarction, nonfatal stroke, and cardiovascular disease death).During a mean follow-up of 8 years, there were 1245 confirmed major cardiovascular events. Compared with placebo, vitamin E had no effect on the incidence of major cardiovascular events (both active and placebo vitamin E groups, 10.9 events per 1000 person-years; hazard ratio [HR], 1.01 [95% confidence interval {CI}, 0.90-1.13]; P = .86), as well as total myocardial infarction (HR, 0.90 [95% CI, 0.75-1.07]; P = .22), total stroke (HR, 1.07 [95% CI, 0.89-1.29]; P = .45), and cardiovascular mortality (HR, 1.07 [95% CI, 0.90-1.28]; P = .43). There also was no significant effect of vitamin C on major cardiovascular events (active and placebo vitamin E groups, 10.8 and 10.9 events per 1000 person-years, respectively; HR, 0.99 [95% CI, 0.89-1.11]; P = .91), as well as total myocardial infarction (HR, 1.04 [95% CI, 0.87-1.24]; P = .65), total stroke (HR, 0.89 [95% CI, 0.74-1.07]; P = .21), and cardiovascular mortality (HR, 1.02 [95% CI, 0.85-1.21]; P = .86). Neither vitamin E (HR, 1.07 [95% CI, 0.97-1.18]; P = .15) nor vitamin C (HR, 1.07 [95% CI, 0.97-1.18]; P = .16) had a significant effect on total mortality but vitamin E was associated with an increased risk of hemorrhagic stroke (HR, 1.74 [95% CI, 1.04-2.91]; P = .04).In this large, long-term trial of male physicians, neither vitamin E nor vitamin C supplementation reduced the risk of major cardiovascular events. These data provide no support for the use of these supplements for the prevention of cardiovascular disease in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of cardiovascular disease in men: the Physicians' Health Study II randomized controlled trial."
"975","JAMA.4601","0.22",18997197,2008,"Basic research and observational studies suggest vitamin E or vitamin C may reduce the risk of cardiovascular disease. However, few long-term trials have evaluated men at initially low risk of cardiovascular disease, and no previous trial in men has examined vitamin C alone in the prevention of cardiovascular disease.To evaluate whether long-term vitamin E or vitamin C supplementation decreases the risk of major cardiovascular events among men.The Physicians' Health Study II was a randomized, double-blind, placebo-controlled factorial trial of vitamin E and vitamin C that began in 1997 and continued until its scheduled completion on August 31, 2007. There were 14,641 US male physicians enrolled, who were initially aged 50 years or older, including 754 men (5.1%) with prevalent cardiovascular disease at randomization.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.A composite end point of major cardiovascular events (nonfatal myocardial infarction, nonfatal stroke, and cardiovascular disease death).During a mean follow-up of 8 years, there were 1245 confirmed major cardiovascular events. Compared with placebo, vitamin E had no effect on the incidence of major cardiovascular events (both active and placebo vitamin E groups, 10.9 events per 1000 person-years; hazard ratio [HR], 1.01 [95% confidence interval {CI}, 0.90-1.13]; P = .86), as well as total myocardial infarction (HR, 0.90 [95% CI, 0.75-1.07]; P = .22), total stroke (HR, 1.07 [95% CI, 0.89-1.29]; P = .45), and cardiovascular mortality (HR, 1.07 [95% CI, 0.90-1.28]; P = .43). There also was no significant effect of vitamin C on major cardiovascular events (active and placebo vitamin E groups, 10.8 and 10.9 events per 1000 person-years, respectively; HR, 0.99 [95% CI, 0.89-1.11]; P = .91), as well as total myocardial infarction (HR, 1.04 [95% CI, 0.87-1.24]; P = .65), total stroke (HR, 0.89 [95% CI, 0.74-1.07]; P = .21), and cardiovascular mortality (HR, 1.02 [95% CI, 0.85-1.21]; P = .86). Neither vitamin E (HR, 1.07 [95% CI, 0.97-1.18]; P = .15) nor vitamin C (HR, 1.07 [95% CI, 0.97-1.18]; P = .16) had a significant effect on total mortality but vitamin E was associated with an increased risk of hemorrhagic stroke (HR, 1.74 [95% CI, 1.04-2.91]; P = .04).In this large, long-term trial of male physicians, neither vitamin E nor vitamin C supplementation reduced the risk of major cardiovascular events. These data provide no support for the use of these supplements for the prevention of cardiovascular disease in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of cardiovascular disease in men: the Physicians' Health Study II randomized controlled trial."
"976","JAMA.4611","0.45",18997197,2008,"Basic research and observational studies suggest vitamin E or vitamin C may reduce the risk of cardiovascular disease. However, few long-term trials have evaluated men at initially low risk of cardiovascular disease, and no previous trial in men has examined vitamin C alone in the prevention of cardiovascular disease.To evaluate whether long-term vitamin E or vitamin C supplementation decreases the risk of major cardiovascular events among men.The Physicians' Health Study II was a randomized, double-blind, placebo-controlled factorial trial of vitamin E and vitamin C that began in 1997 and continued until its scheduled completion on August 31, 2007. There were 14,641 US male physicians enrolled, who were initially aged 50 years or older, including 754 men (5.1%) with prevalent cardiovascular disease at randomization.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.A composite end point of major cardiovascular events (nonfatal myocardial infarction, nonfatal stroke, and cardiovascular disease death).During a mean follow-up of 8 years, there were 1245 confirmed major cardiovascular events. Compared with placebo, vitamin E had no effect on the incidence of major cardiovascular events (both active and placebo vitamin E groups, 10.9 events per 1000 person-years; hazard ratio [HR], 1.01 [95% confidence interval {CI}, 0.90-1.13]; P = .86), as well as total myocardial infarction (HR, 0.90 [95% CI, 0.75-1.07]; P = .22), total stroke (HR, 1.07 [95% CI, 0.89-1.29]; P = .45), and cardiovascular mortality (HR, 1.07 [95% CI, 0.90-1.28]; P = .43). There also was no significant effect of vitamin C on major cardiovascular events (active and placebo vitamin E groups, 10.8 and 10.9 events per 1000 person-years, respectively; HR, 0.99 [95% CI, 0.89-1.11]; P = .91), as well as total myocardial infarction (HR, 1.04 [95% CI, 0.87-1.24]; P = .65), total stroke (HR, 0.89 [95% CI, 0.74-1.07]; P = .21), and cardiovascular mortality (HR, 1.02 [95% CI, 0.85-1.21]; P = .86). Neither vitamin E (HR, 1.07 [95% CI, 0.97-1.18]; P = .15) nor vitamin C (HR, 1.07 [95% CI, 0.97-1.18]; P = .16) had a significant effect on total mortality but vitamin E was associated with an increased risk of hemorrhagic stroke (HR, 1.74 [95% CI, 1.04-2.91]; P = .04).In this large, long-term trial of male physicians, neither vitamin E nor vitamin C supplementation reduced the risk of major cardiovascular events. These data provide no support for the use of these supplements for the prevention of cardiovascular disease in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of cardiovascular disease in men: the Physicians' Health Study II randomized controlled trial."
"977","JAMA.4621","0.43",18997197,2008,"Basic research and observational studies suggest vitamin E or vitamin C may reduce the risk of cardiovascular disease. However, few long-term trials have evaluated men at initially low risk of cardiovascular disease, and no previous trial in men has examined vitamin C alone in the prevention of cardiovascular disease.To evaluate whether long-term vitamin E or vitamin C supplementation decreases the risk of major cardiovascular events among men.The Physicians' Health Study II was a randomized, double-blind, placebo-controlled factorial trial of vitamin E and vitamin C that began in 1997 and continued until its scheduled completion on August 31, 2007. There were 14,641 US male physicians enrolled, who were initially aged 50 years or older, including 754 men (5.1%) with prevalent cardiovascular disease at randomization.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.A composite end point of major cardiovascular events (nonfatal myocardial infarction, nonfatal stroke, and cardiovascular disease death).During a mean follow-up of 8 years, there were 1245 confirmed major cardiovascular events. Compared with placebo, vitamin E had no effect on the incidence of major cardiovascular events (both active and placebo vitamin E groups, 10.9 events per 1000 person-years; hazard ratio [HR], 1.01 [95% confidence interval {CI}, 0.90-1.13]; P = .86), as well as total myocardial infarction (HR, 0.90 [95% CI, 0.75-1.07]; P = .22), total stroke (HR, 1.07 [95% CI, 0.89-1.29]; P = .45), and cardiovascular mortality (HR, 1.07 [95% CI, 0.90-1.28]; P = .43). There also was no significant effect of vitamin C on major cardiovascular events (active and placebo vitamin E groups, 10.8 and 10.9 events per 1000 person-years, respectively; HR, 0.99 [95% CI, 0.89-1.11]; P = .91), as well as total myocardial infarction (HR, 1.04 [95% CI, 0.87-1.24]; P = .65), total stroke (HR, 0.89 [95% CI, 0.74-1.07]; P = .21), and cardiovascular mortality (HR, 1.02 [95% CI, 0.85-1.21]; P = .86). Neither vitamin E (HR, 1.07 [95% CI, 0.97-1.18]; P = .15) nor vitamin C (HR, 1.07 [95% CI, 0.97-1.18]; P = .16) had a significant effect on total mortality but vitamin E was associated with an increased risk of hemorrhagic stroke (HR, 1.74 [95% CI, 1.04-2.91]; P = .04).In this large, long-term trial of male physicians, neither vitamin E nor vitamin C supplementation reduced the risk of major cardiovascular events. These data provide no support for the use of these supplements for the prevention of cardiovascular disease in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of cardiovascular disease in men: the Physicians' Health Study II randomized controlled trial."
"978","JAMA.4631","0.91",18997197,2008,"Basic research and observational studies suggest vitamin E or vitamin C may reduce the risk of cardiovascular disease. However, few long-term trials have evaluated men at initially low risk of cardiovascular disease, and no previous trial in men has examined vitamin C alone in the prevention of cardiovascular disease.To evaluate whether long-term vitamin E or vitamin C supplementation decreases the risk of major cardiovascular events among men.The Physicians' Health Study II was a randomized, double-blind, placebo-controlled factorial trial of vitamin E and vitamin C that began in 1997 and continued until its scheduled completion on August 31, 2007. There were 14,641 US male physicians enrolled, who were initially aged 50 years or older, including 754 men (5.1%) with prevalent cardiovascular disease at randomization.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.A composite end point of major cardiovascular events (nonfatal myocardial infarction, nonfatal stroke, and cardiovascular disease death).During a mean follow-up of 8 years, there were 1245 confirmed major cardiovascular events. Compared with placebo, vitamin E had no effect on the incidence of major cardiovascular events (both active and placebo vitamin E groups, 10.9 events per 1000 person-years; hazard ratio [HR], 1.01 [95% confidence interval {CI}, 0.90-1.13]; P = .86), as well as total myocardial infarction (HR, 0.90 [95% CI, 0.75-1.07]; P = .22), total stroke (HR, 1.07 [95% CI, 0.89-1.29]; P = .45), and cardiovascular mortality (HR, 1.07 [95% CI, 0.90-1.28]; P = .43). There also was no significant effect of vitamin C on major cardiovascular events (active and placebo vitamin E groups, 10.8 and 10.9 events per 1000 person-years, respectively; HR, 0.99 [95% CI, 0.89-1.11]; P = .91), as well as total myocardial infarction (HR, 1.04 [95% CI, 0.87-1.24]; P = .65), total stroke (HR, 0.89 [95% CI, 0.74-1.07]; P = .21), and cardiovascular mortality (HR, 1.02 [95% CI, 0.85-1.21]; P = .86). Neither vitamin E (HR, 1.07 [95% CI, 0.97-1.18]; P = .15) nor vitamin C (HR, 1.07 [95% CI, 0.97-1.18]; P = .16) had a significant effect on total mortality but vitamin E was associated with an increased risk of hemorrhagic stroke (HR, 1.74 [95% CI, 1.04-2.91]; P = .04).In this large, long-term trial of male physicians, neither vitamin E nor vitamin C supplementation reduced the risk of major cardiovascular events. These data provide no support for the use of these supplements for the prevention of cardiovascular disease in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of cardiovascular disease in men: the Physicians' Health Study II randomized controlled trial."
"979","JAMA.4641","0.65",18997197,2008,"Basic research and observational studies suggest vitamin E or vitamin C may reduce the risk of cardiovascular disease. However, few long-term trials have evaluated men at initially low risk of cardiovascular disease, and no previous trial in men has examined vitamin C alone in the prevention of cardiovascular disease.To evaluate whether long-term vitamin E or vitamin C supplementation decreases the risk of major cardiovascular events among men.The Physicians' Health Study II was a randomized, double-blind, placebo-controlled factorial trial of vitamin E and vitamin C that began in 1997 and continued until its scheduled completion on August 31, 2007. There were 14,641 US male physicians enrolled, who were initially aged 50 years or older, including 754 men (5.1%) with prevalent cardiovascular disease at randomization.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.A composite end point of major cardiovascular events (nonfatal myocardial infarction, nonfatal stroke, and cardiovascular disease death).During a mean follow-up of 8 years, there were 1245 confirmed major cardiovascular events. Compared with placebo, vitamin E had no effect on the incidence of major cardiovascular events (both active and placebo vitamin E groups, 10.9 events per 1000 person-years; hazard ratio [HR], 1.01 [95% confidence interval {CI}, 0.90-1.13]; P = .86), as well as total myocardial infarction (HR, 0.90 [95% CI, 0.75-1.07]; P = .22), total stroke (HR, 1.07 [95% CI, 0.89-1.29]; P = .45), and cardiovascular mortality (HR, 1.07 [95% CI, 0.90-1.28]; P = .43). There also was no significant effect of vitamin C on major cardiovascular events (active and placebo vitamin E groups, 10.8 and 10.9 events per 1000 person-years, respectively; HR, 0.99 [95% CI, 0.89-1.11]; P = .91), as well as total myocardial infarction (HR, 1.04 [95% CI, 0.87-1.24]; P = .65), total stroke (HR, 0.89 [95% CI, 0.74-1.07]; P = .21), and cardiovascular mortality (HR, 1.02 [95% CI, 0.85-1.21]; P = .86). Neither vitamin E (HR, 1.07 [95% CI, 0.97-1.18]; P = .15) nor vitamin C (HR, 1.07 [95% CI, 0.97-1.18]; P = .16) had a significant effect on total mortality but vitamin E was associated with an increased risk of hemorrhagic stroke (HR, 1.74 [95% CI, 1.04-2.91]; P = .04).In this large, long-term trial of male physicians, neither vitamin E nor vitamin C supplementation reduced the risk of major cardiovascular events. These data provide no support for the use of these supplements for the prevention of cardiovascular disease in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of cardiovascular disease in men: the Physicians' Health Study II randomized controlled trial."
"980","JAMA.4651","0.21",18997197,2008,"Basic research and observational studies suggest vitamin E or vitamin C may reduce the risk of cardiovascular disease. However, few long-term trials have evaluated men at initially low risk of cardiovascular disease, and no previous trial in men has examined vitamin C alone in the prevention of cardiovascular disease.To evaluate whether long-term vitamin E or vitamin C supplementation decreases the risk of major cardiovascular events among men.The Physicians' Health Study II was a randomized, double-blind, placebo-controlled factorial trial of vitamin E and vitamin C that began in 1997 and continued until its scheduled completion on August 31, 2007. There were 14,641 US male physicians enrolled, who were initially aged 50 years or older, including 754 men (5.1%) with prevalent cardiovascular disease at randomization.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.A composite end point of major cardiovascular events (nonfatal myocardial infarction, nonfatal stroke, and cardiovascular disease death).During a mean follow-up of 8 years, there were 1245 confirmed major cardiovascular events. Compared with placebo, vitamin E had no effect on the incidence of major cardiovascular events (both active and placebo vitamin E groups, 10.9 events per 1000 person-years; hazard ratio [HR], 1.01 [95% confidence interval {CI}, 0.90-1.13]; P = .86), as well as total myocardial infarction (HR, 0.90 [95% CI, 0.75-1.07]; P = .22), total stroke (HR, 1.07 [95% CI, 0.89-1.29]; P = .45), and cardiovascular mortality (HR, 1.07 [95% CI, 0.90-1.28]; P = .43). There also was no significant effect of vitamin C on major cardiovascular events (active and placebo vitamin E groups, 10.8 and 10.9 events per 1000 person-years, respectively; HR, 0.99 [95% CI, 0.89-1.11]; P = .91), as well as total myocardial infarction (HR, 1.04 [95% CI, 0.87-1.24]; P = .65), total stroke (HR, 0.89 [95% CI, 0.74-1.07]; P = .21), and cardiovascular mortality (HR, 1.02 [95% CI, 0.85-1.21]; P = .86). Neither vitamin E (HR, 1.07 [95% CI, 0.97-1.18]; P = .15) nor vitamin C (HR, 1.07 [95% CI, 0.97-1.18]; P = .16) had a significant effect on total mortality but vitamin E was associated with an increased risk of hemorrhagic stroke (HR, 1.74 [95% CI, 1.04-2.91]; P = .04).In this large, long-term trial of male physicians, neither vitamin E nor vitamin C supplementation reduced the risk of major cardiovascular events. These data provide no support for the use of these supplements for the prevention of cardiovascular disease in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of cardiovascular disease in men: the Physicians' Health Study II randomized controlled trial."
"981","JAMA.4661","0.86",18997197,2008,"Basic research and observational studies suggest vitamin E or vitamin C may reduce the risk of cardiovascular disease. However, few long-term trials have evaluated men at initially low risk of cardiovascular disease, and no previous trial in men has examined vitamin C alone in the prevention of cardiovascular disease.To evaluate whether long-term vitamin E or vitamin C supplementation decreases the risk of major cardiovascular events among men.The Physicians' Health Study II was a randomized, double-blind, placebo-controlled factorial trial of vitamin E and vitamin C that began in 1997 and continued until its scheduled completion on August 31, 2007. There were 14,641 US male physicians enrolled, who were initially aged 50 years or older, including 754 men (5.1%) with prevalent cardiovascular disease at randomization.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.A composite end point of major cardiovascular events (nonfatal myocardial infarction, nonfatal stroke, and cardiovascular disease death).During a mean follow-up of 8 years, there were 1245 confirmed major cardiovascular events. Compared with placebo, vitamin E had no effect on the incidence of major cardiovascular events (both active and placebo vitamin E groups, 10.9 events per 1000 person-years; hazard ratio [HR], 1.01 [95% confidence interval {CI}, 0.90-1.13]; P = .86), as well as total myocardial infarction (HR, 0.90 [95% CI, 0.75-1.07]; P = .22), total stroke (HR, 1.07 [95% CI, 0.89-1.29]; P = .45), and cardiovascular mortality (HR, 1.07 [95% CI, 0.90-1.28]; P = .43). There also was no significant effect of vitamin C on major cardiovascular events (active and placebo vitamin E groups, 10.8 and 10.9 events per 1000 person-years, respectively; HR, 0.99 [95% CI, 0.89-1.11]; P = .91), as well as total myocardial infarction (HR, 1.04 [95% CI, 0.87-1.24]; P = .65), total stroke (HR, 0.89 [95% CI, 0.74-1.07]; P = .21), and cardiovascular mortality (HR, 1.02 [95% CI, 0.85-1.21]; P = .86). Neither vitamin E (HR, 1.07 [95% CI, 0.97-1.18]; P = .15) nor vitamin C (HR, 1.07 [95% CI, 0.97-1.18]; P = .16) had a significant effect on total mortality but vitamin E was associated with an increased risk of hemorrhagic stroke (HR, 1.74 [95% CI, 1.04-2.91]; P = .04).In this large, long-term trial of male physicians, neither vitamin E nor vitamin C supplementation reduced the risk of major cardiovascular events. These data provide no support for the use of these supplements for the prevention of cardiovascular disease in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of cardiovascular disease in men: the Physicians' Health Study II randomized controlled trial."
"982","JAMA.4671","0.15",18997197,2008,"Basic research and observational studies suggest vitamin E or vitamin C may reduce the risk of cardiovascular disease. However, few long-term trials have evaluated men at initially low risk of cardiovascular disease, and no previous trial in men has examined vitamin C alone in the prevention of cardiovascular disease.To evaluate whether long-term vitamin E or vitamin C supplementation decreases the risk of major cardiovascular events among men.The Physicians' Health Study II was a randomized, double-blind, placebo-controlled factorial trial of vitamin E and vitamin C that began in 1997 and continued until its scheduled completion on August 31, 2007. There were 14,641 US male physicians enrolled, who were initially aged 50 years or older, including 754 men (5.1%) with prevalent cardiovascular disease at randomization.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.A composite end point of major cardiovascular events (nonfatal myocardial infarction, nonfatal stroke, and cardiovascular disease death).During a mean follow-up of 8 years, there were 1245 confirmed major cardiovascular events. Compared with placebo, vitamin E had no effect on the incidence of major cardiovascular events (both active and placebo vitamin E groups, 10.9 events per 1000 person-years; hazard ratio [HR], 1.01 [95% confidence interval {CI}, 0.90-1.13]; P = .86), as well as total myocardial infarction (HR, 0.90 [95% CI, 0.75-1.07]; P = .22), total stroke (HR, 1.07 [95% CI, 0.89-1.29]; P = .45), and cardiovascular mortality (HR, 1.07 [95% CI, 0.90-1.28]; P = .43). There also was no significant effect of vitamin C on major cardiovascular events (active and placebo vitamin E groups, 10.8 and 10.9 events per 1000 person-years, respectively; HR, 0.99 [95% CI, 0.89-1.11]; P = .91), as well as total myocardial infarction (HR, 1.04 [95% CI, 0.87-1.24]; P = .65), total stroke (HR, 0.89 [95% CI, 0.74-1.07]; P = .21), and cardiovascular mortality (HR, 1.02 [95% CI, 0.85-1.21]; P = .86). Neither vitamin E (HR, 1.07 [95% CI, 0.97-1.18]; P = .15) nor vitamin C (HR, 1.07 [95% CI, 0.97-1.18]; P = .16) had a significant effect on total mortality but vitamin E was associated with an increased risk of hemorrhagic stroke (HR, 1.74 [95% CI, 1.04-2.91]; P = .04).In this large, long-term trial of male physicians, neither vitamin E nor vitamin C supplementation reduced the risk of major cardiovascular events. These data provide no support for the use of these supplements for the prevention of cardiovascular disease in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of cardiovascular disease in men: the Physicians' Health Study II randomized controlled trial."
"983","JAMA.4681","0.16",18997197,2008,"Basic research and observational studies suggest vitamin E or vitamin C may reduce the risk of cardiovascular disease. However, few long-term trials have evaluated men at initially low risk of cardiovascular disease, and no previous trial in men has examined vitamin C alone in the prevention of cardiovascular disease.To evaluate whether long-term vitamin E or vitamin C supplementation decreases the risk of major cardiovascular events among men.The Physicians' Health Study II was a randomized, double-blind, placebo-controlled factorial trial of vitamin E and vitamin C that began in 1997 and continued until its scheduled completion on August 31, 2007. There were 14,641 US male physicians enrolled, who were initially aged 50 years or older, including 754 men (5.1%) with prevalent cardiovascular disease at randomization.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.A composite end point of major cardiovascular events (nonfatal myocardial infarction, nonfatal stroke, and cardiovascular disease death).During a mean follow-up of 8 years, there were 1245 confirmed major cardiovascular events. Compared with placebo, vitamin E had no effect on the incidence of major cardiovascular events (both active and placebo vitamin E groups, 10.9 events per 1000 person-years; hazard ratio [HR], 1.01 [95% confidence interval {CI}, 0.90-1.13]; P = .86), as well as total myocardial infarction (HR, 0.90 [95% CI, 0.75-1.07]; P = .22), total stroke (HR, 1.07 [95% CI, 0.89-1.29]; P = .45), and cardiovascular mortality (HR, 1.07 [95% CI, 0.90-1.28]; P = .43). There also was no significant effect of vitamin C on major cardiovascular events (active and placebo vitamin E groups, 10.8 and 10.9 events per 1000 person-years, respectively; HR, 0.99 [95% CI, 0.89-1.11]; P = .91), as well as total myocardial infarction (HR, 1.04 [95% CI, 0.87-1.24]; P = .65), total stroke (HR, 0.89 [95% CI, 0.74-1.07]; P = .21), and cardiovascular mortality (HR, 1.02 [95% CI, 0.85-1.21]; P = .86). Neither vitamin E (HR, 1.07 [95% CI, 0.97-1.18]; P = .15) nor vitamin C (HR, 1.07 [95% CI, 0.97-1.18]; P = .16) had a significant effect on total mortality but vitamin E was associated with an increased risk of hemorrhagic stroke (HR, 1.74 [95% CI, 1.04-2.91]; P = .04).In this large, long-term trial of male physicians, neither vitamin E nor vitamin C supplementation reduced the risk of major cardiovascular events. These data provide no support for the use of these supplements for the prevention of cardiovascular disease in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of cardiovascular disease in men: the Physicians' Health Study II randomized controlled trial."
"984","JAMA.4691","0.04",18997197,2008,"Basic research and observational studies suggest vitamin E or vitamin C may reduce the risk of cardiovascular disease. However, few long-term trials have evaluated men at initially low risk of cardiovascular disease, and no previous trial in men has examined vitamin C alone in the prevention of cardiovascular disease.To evaluate whether long-term vitamin E or vitamin C supplementation decreases the risk of major cardiovascular events among men.The Physicians' Health Study II was a randomized, double-blind, placebo-controlled factorial trial of vitamin E and vitamin C that began in 1997 and continued until its scheduled completion on August 31, 2007. There were 14,641 US male physicians enrolled, who were initially aged 50 years or older, including 754 men (5.1%) with prevalent cardiovascular disease at randomization.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.A composite end point of major cardiovascular events (nonfatal myocardial infarction, nonfatal stroke, and cardiovascular disease death).During a mean follow-up of 8 years, there were 1245 confirmed major cardiovascular events. Compared with placebo, vitamin E had no effect on the incidence of major cardiovascular events (both active and placebo vitamin E groups, 10.9 events per 1000 person-years; hazard ratio [HR], 1.01 [95% confidence interval {CI}, 0.90-1.13]; P = .86), as well as total myocardial infarction (HR, 0.90 [95% CI, 0.75-1.07]; P = .22), total stroke (HR, 1.07 [95% CI, 0.89-1.29]; P = .45), and cardiovascular mortality (HR, 1.07 [95% CI, 0.90-1.28]; P = .43). There also was no significant effect of vitamin C on major cardiovascular events (active and placebo vitamin E groups, 10.8 and 10.9 events per 1000 person-years, respectively; HR, 0.99 [95% CI, 0.89-1.11]; P = .91), as well as total myocardial infarction (HR, 1.04 [95% CI, 0.87-1.24]; P = .65), total stroke (HR, 0.89 [95% CI, 0.74-1.07]; P = .21), and cardiovascular mortality (HR, 1.02 [95% CI, 0.85-1.21]; P = .86). Neither vitamin E (HR, 1.07 [95% CI, 0.97-1.18]; P = .15) nor vitamin C (HR, 1.07 [95% CI, 0.97-1.18]; P = .16) had a significant effect on total mortality but vitamin E was associated with an increased risk of hemorrhagic stroke (HR, 1.74 [95% CI, 1.04-2.91]; P = .04).In this large, long-term trial of male physicians, neither vitamin E nor vitamin C supplementation reduced the risk of major cardiovascular events. These data provide no support for the use of these supplements for the prevention of cardiovascular disease in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of cardiovascular disease in men: the Physicians' Health Study II randomized controlled trial."
"985","JAMA.4561","0.16",18997198,2008,"Previous trials have investigated the effects of low-dose aspirin on primary prevention of cardiovascular events, but not in patients with type 2 diabetes.To examine the efficacy of low-dose aspirin for the primary prevention of atherosclerotic events in patients with type 2 diabetes.Multicenter, prospective, randomized, open-label, blinded, end-point trial conducted from December 2002 through April 2008 at 163 institutions throughout Japan, which enrolled 2539 patients with type 2 diabetes without a history of atherosclerotic disease and had a median follow-up of 4.37 years.Patients were assigned to the low-dose aspirin group (81 or 100 mg per day) or the nonaspirin group.Primary end points were atherosclerotic events, including fatal or nonfatal ischemic heart disease, fatal or nonfatal stroke, and peripheral arterial disease. Secondary end points included each primary end point and combinations of primary end points as well as death from any cause.A total of 154 atherosclerotic events occurred: 68 in the aspirin group (13.6 per 1000 person-years) and 86 in the nonaspirin group (17.0 per 1000 person-years) (hazard ratio [HR], 0.80; 95% confidence interval [CI], 0.58-1.10; log-rank test, P = .16). The combined end point of fatal coronary events and fatal cerebrovascular events occurred in 1 patient (stroke) in the aspirin group and 10 patients (5 fatal myocardial infarctions and 5 fatal strokes) in the nonaspirin group (HR, 0.10; 95% CI, 0.01-0.79; P = .0037). A total of 34 patients in the aspirin group and 38 patients in the nonaspirin group died from any cause (HR, 0.90; 95% CI, 0.57-1.14; log-rank test, P = .67). The composite of hemorrhagic stroke and significant gastrointestinal bleeding was not significantly different between the aspirin and nonaspirin groups.In this study of patients with type 2 diabetes, low-dose aspirin as primary prevention did not reduce the risk of cardiovascular events.clinicaltrials.gov Identifier: NCT00110448.","Low-dose aspirin for primary prevention of atherosclerotic events in patients with type 2 diabetes: a randomized controlled trial."
"986","JAMA.4571","0.0037",18997198,2008,"Previous trials have investigated the effects of low-dose aspirin on primary prevention of cardiovascular events, but not in patients with type 2 diabetes.To examine the efficacy of low-dose aspirin for the primary prevention of atherosclerotic events in patients with type 2 diabetes.Multicenter, prospective, randomized, open-label, blinded, end-point trial conducted from December 2002 through April 2008 at 163 institutions throughout Japan, which enrolled 2539 patients with type 2 diabetes without a history of atherosclerotic disease and had a median follow-up of 4.37 years.Patients were assigned to the low-dose aspirin group (81 or 100 mg per day) or the nonaspirin group.Primary end points were atherosclerotic events, including fatal or nonfatal ischemic heart disease, fatal or nonfatal stroke, and peripheral arterial disease. Secondary end points included each primary end point and combinations of primary end points as well as death from any cause.A total of 154 atherosclerotic events occurred: 68 in the aspirin group (13.6 per 1000 person-years) and 86 in the nonaspirin group (17.0 per 1000 person-years) (hazard ratio [HR], 0.80; 95% confidence interval [CI], 0.58-1.10; log-rank test, P = .16). The combined end point of fatal coronary events and fatal cerebrovascular events occurred in 1 patient (stroke) in the aspirin group and 10 patients (5 fatal myocardial infarctions and 5 fatal strokes) in the nonaspirin group (HR, 0.10; 95% CI, 0.01-0.79; P = .0037). A total of 34 patients in the aspirin group and 38 patients in the nonaspirin group died from any cause (HR, 0.90; 95% CI, 0.57-1.14; log-rank test, P = .67). The composite of hemorrhagic stroke and significant gastrointestinal bleeding was not significantly different between the aspirin and nonaspirin groups.In this study of patients with type 2 diabetes, low-dose aspirin as primary prevention did not reduce the risk of cardiovascular events.clinicaltrials.gov Identifier: NCT00110448.","Low-dose aspirin for primary prevention of atherosclerotic events in patients with type 2 diabetes: a randomized controlled trial."
"987","JAMA.4581","0.67",18997198,2008,"Previous trials have investigated the effects of low-dose aspirin on primary prevention of cardiovascular events, but not in patients with type 2 diabetes.To examine the efficacy of low-dose aspirin for the primary prevention of atherosclerotic events in patients with type 2 diabetes.Multicenter, prospective, randomized, open-label, blinded, end-point trial conducted from December 2002 through April 2008 at 163 institutions throughout Japan, which enrolled 2539 patients with type 2 diabetes without a history of atherosclerotic disease and had a median follow-up of 4.37 years.Patients were assigned to the low-dose aspirin group (81 or 100 mg per day) or the nonaspirin group.Primary end points were atherosclerotic events, including fatal or nonfatal ischemic heart disease, fatal or nonfatal stroke, and peripheral arterial disease. Secondary end points included each primary end point and combinations of primary end points as well as death from any cause.A total of 154 atherosclerotic events occurred: 68 in the aspirin group (13.6 per 1000 person-years) and 86 in the nonaspirin group (17.0 per 1000 person-years) (hazard ratio [HR], 0.80; 95% confidence interval [CI], 0.58-1.10; log-rank test, P = .16). The combined end point of fatal coronary events and fatal cerebrovascular events occurred in 1 patient (stroke) in the aspirin group and 10 patients (5 fatal myocardial infarctions and 5 fatal strokes) in the nonaspirin group (HR, 0.10; 95% CI, 0.01-0.79; P = .0037). A total of 34 patients in the aspirin group and 38 patients in the nonaspirin group died from any cause (HR, 0.90; 95% CI, 0.57-1.14; log-rank test, P = .67). The composite of hemorrhagic stroke and significant gastrointestinal bleeding was not significantly different between the aspirin and nonaspirin groups.In this study of patients with type 2 diabetes, low-dose aspirin as primary prevention did not reduce the risk of cardiovascular events.clinicaltrials.gov Identifier: NCT00110448.","Low-dose aspirin for primary prevention of atherosclerotic events in patients with type 2 diabetes: a randomized controlled trial."
"988","JAMA.4531","0.21",19017911,2008,"Ginkgo biloba is widely used for its potential effects on memory and cognition. To date, adequately powered clinical trials testing the effect of G. biloba on dementia incidence are lacking.To determine effectiveness of G. biloba vs placebo in reducing the incidence of all-cause dementia and Alzheimer disease (AD) in elderly individuals with normal cognition and those with mild cognitive impairment (MCI).Randomized, double-blind, placebo-controlled clinical trial conducted in 5 academic medical centers in the United States between 2000 and 2008 with a median follow-up of 6.1 years. Three thousand sixty-nine community volunteers aged 75 years or older with normal cognition (n = 2587) or MCI (n = 482) at study entry were assessed every 6 months for incident dementia.Twice-daily dose of 120-mg extract of G. biloba (n = 1545) or placebo (n = 1524).Incident dementia and AD determined by expert panel consensus.Five hundred twenty-three individuals developed dementia (246 receiving placebo and 277 receiving G. biloba) with 92% of the dementia cases classified as possible or probable AD, or AD with evidence of vascular disease of the brain. Rates of dropout and loss to follow-up were low (6.3%), and the adverse effect profiles were similar for both groups. The overall dementia rate was 3.3 per 100 person-years in participants assigned to G. biloba and 2.9 per 100 person-years in the placebo group. The hazard ratio (HR) for G. biloba compared with placebo for all-cause dementia was 1.12 (95% confidence interval [CI], 0.94-1.33; P = .21) and for AD, 1.16 (95% CI, 0.97-1.39; P = .11). G. biloba also had no effect on the rate of progression to dementia in participants with MCI (HR, 1.13; 95% CI, 0.85-1.50; P = .39).In this study, G. biloba at 120 mg twice a day was not effective in reducing either the overall incidence rate of dementia or AD incidence in elderly individuals with normal cognition or those with MCI. Trial Registration clinicaltrials.gov Identifier: NCT00010803.","Ginkgo biloba for prevention of dementia: a randomized controlled trial."
"989","JAMA.4541","0.11",19017911,2008,"Ginkgo biloba is widely used for its potential effects on memory and cognition. To date, adequately powered clinical trials testing the effect of G. biloba on dementia incidence are lacking.To determine effectiveness of G. biloba vs placebo in reducing the incidence of all-cause dementia and Alzheimer disease (AD) in elderly individuals with normal cognition and those with mild cognitive impairment (MCI).Randomized, double-blind, placebo-controlled clinical trial conducted in 5 academic medical centers in the United States between 2000 and 2008 with a median follow-up of 6.1 years. Three thousand sixty-nine community volunteers aged 75 years or older with normal cognition (n = 2587) or MCI (n = 482) at study entry were assessed every 6 months for incident dementia.Twice-daily dose of 120-mg extract of G. biloba (n = 1545) or placebo (n = 1524).Incident dementia and AD determined by expert panel consensus.Five hundred twenty-three individuals developed dementia (246 receiving placebo and 277 receiving G. biloba) with 92% of the dementia cases classified as possible or probable AD, or AD with evidence of vascular disease of the brain. Rates of dropout and loss to follow-up were low (6.3%), and the adverse effect profiles were similar for both groups. The overall dementia rate was 3.3 per 100 person-years in participants assigned to G. biloba and 2.9 per 100 person-years in the placebo group. The hazard ratio (HR) for G. biloba compared with placebo for all-cause dementia was 1.12 (95% confidence interval [CI], 0.94-1.33; P = .21) and for AD, 1.16 (95% CI, 0.97-1.39; P = .11). G. biloba also had no effect on the rate of progression to dementia in participants with MCI (HR, 1.13; 95% CI, 0.85-1.50; P = .39).In this study, G. biloba at 120 mg twice a day was not effective in reducing either the overall incidence rate of dementia or AD incidence in elderly individuals with normal cognition or those with MCI. Trial Registration clinicaltrials.gov Identifier: NCT00010803.","Ginkgo biloba for prevention of dementia: a randomized controlled trial."
"990","JAMA.4551","0.39",19017911,2008,"Ginkgo biloba is widely used for its potential effects on memory and cognition. To date, adequately powered clinical trials testing the effect of G. biloba on dementia incidence are lacking.To determine effectiveness of G. biloba vs placebo in reducing the incidence of all-cause dementia and Alzheimer disease (AD) in elderly individuals with normal cognition and those with mild cognitive impairment (MCI).Randomized, double-blind, placebo-controlled clinical trial conducted in 5 academic medical centers in the United States between 2000 and 2008 with a median follow-up of 6.1 years. Three thousand sixty-nine community volunteers aged 75 years or older with normal cognition (n = 2587) or MCI (n = 482) at study entry were assessed every 6 months for incident dementia.Twice-daily dose of 120-mg extract of G. biloba (n = 1545) or placebo (n = 1524).Incident dementia and AD determined by expert panel consensus.Five hundred twenty-three individuals developed dementia (246 receiving placebo and 277 receiving G. biloba) with 92% of the dementia cases classified as possible or probable AD, or AD with evidence of vascular disease of the brain. Rates of dropout and loss to follow-up were low (6.3%), and the adverse effect profiles were similar for both groups. The overall dementia rate was 3.3 per 100 person-years in participants assigned to G. biloba and 2.9 per 100 person-years in the placebo group. The hazard ratio (HR) for G. biloba compared with placebo for all-cause dementia was 1.12 (95% confidence interval [CI], 0.94-1.33; P = .21) and for AD, 1.16 (95% CI, 0.97-1.39; P = .11). G. biloba also had no effect on the rate of progression to dementia in participants with MCI (HR, 1.13; 95% CI, 0.85-1.50; P = .39).In this study, G. biloba at 120 mg twice a day was not effective in reducing either the overall incidence rate of dementia or AD incidence in elderly individuals with normal cognition or those with MCI. Trial Registration clinicaltrials.gov Identifier: NCT00010803.","Ginkgo biloba for prevention of dementia: a randomized controlled trial."
"991","Lancet.1241","0.62",19027483,2008,"Two phase II trials in patients with previously-treated advanced non-small-cell lung cancer suggested that gefitinib was efficacious and less toxic than was chemotherapy. We compared gefitinib with docetaxel in patients with locally advanced or metastatic non-small-cell lung cancer who had been pretreated with platinum-based chemotherapy.We undertook an open-label phase III study with recruitment between March 1, 2004, and Feb 17, 2006, at 149 centres in 24 countries. 1466 patients with pretreated (>/=one platinum-based regimen) advanced non-small-cell lung cancer were randomly assigned with dynamic balancing to receive gefitinib (250 mg per day orally; n=733) or docetaxel (75 mg/m(2) intravenously in 1-h infusion every 3 weeks; n=733). The primary objective was to compare overall survival between the groups with co-primary analyses to assess non-inferiority in the overall per-protocol population and superiority in patients with high epidermal growth factor receptor (EGFR)-gene-copy number in the intention-to-treat population. This study is registered with ClinicalTrials.gov, number NCT00076388.1433 patients were analysed per protocol (723 in gefitinib group and 710 in docetaxel group). Non-inferiority of gefitinib compared with docetaxel was confirmed for overall survival (593 vs 576 events; hazard ratio [HR] 1.020, 96% CI 0.905-1.150, meeting the predefined non-inferiority criterion; median survival 7.6 vs 8.0 months). Superiority of gefitinib in patients with high EGFR-gene-copy number (85 vs 89 patients) was not proven (72 vs 71 events; HR 1.09, 95% CI 0.78-1.51; p=0.62; median survival 8.4 vs 7.5 months). In the gefitinib group, the most common adverse events were rash or acne (360 [49%] vs 73 [10%]) and diarrhoea (255 [35%] vs 177 [25%]); whereas in the docetaxel group, neutropenia (35 [5%] vs 514 [74%]), asthenic disorders (182 [25%] vs 334 [47%]), and alopecia (23 [3%] vs 254 [36%]) were most common.INTEREST established non-inferior survival of gefitinib compared with docetaxel, suggesting that gefitinib is a valid treatment for pretreated patients with advanced non-small-cell lung cancer.","Gefitinib versus docetaxel in previously treated non-small-cell lung cancer (INTEREST): a randomised phase III trial."
"992","JAMA.424","0.001",19033587,2008,"In February 2002, the allocation system for liver transplantation became based on the Model for End-Stage Liver Disease (MELD) score. Before MELD, black patients were more likely to die or become too sick to undergo liver transplantation compared with white patients. Little information exists regarding sex and access to liver transplantation.To determine the association between race, sex, and liver transplantation following introduction of the MELD system.A retrospective cohort of black and white patients (> or = 18 years) registered on the United Network for Organ Sharing liver transplantation waiting list between January 1, 1996, and December 31, 2000 (pre-MELD cohort, n = 21 895) and between February 28, 2002, and March 31, 2006 (post-MELD cohort, n = 23 793).Association between race, sex, and receipt of a liver transplant. Separate multivariable analyses evaluated cohorts within each period to identify predictors of time to death and the odds of dying or receiving liver transplantation within 3 years of listing. Patients with hepatocellular carcinoma were analyzed separately.Black patients were younger (mean [SD], 49.2 [10.7] vs 52.4 [9.2] years; P < .001) and sicker (MELD score at listing: median [interquartile range], 16 [12-22] vs 14 [11-19]; P < .001) than white patients on the waiting list for both periods. In the pre-MELD cohort, black patients were more likely to die or become too sick for liver transplantation than white patients (27.0% vs 21.7%) within 3 years of registering on the waiting list (odds ratio [OR], 1.51; 95% confidence interval (CI), 1.15-1.98; P = .003). In the post-MELD cohort, black race was no longer associated with increased likelihood of death or becoming too sick for liver transplantation (26.5% vs 22.0%, respectively; OR, 0.96; 95% CI, 0.74-1.26; P = .76). Black patients were also less likely to receive a liver transplant than white patients within 3 years of registering on the waiting list pre-MELD (61.6% vs 66.9%; OR, 0.75; 95% CI, 0.59-0.97; P = .03), whereas post-MELD, race was no longer significantly associated with receipt of a liver transplant (47.5% vs 45.5%, respectively; OR, 1.04; 95% CI, 0.84-1.28; P = .75). Women were more likely than men to die or become too sick for liver transplantation post-MELD (23.7% vs 21.4%; OR, 1.30; 95% CI, 1.08-1.47; P = .003) vs pre-MELD (22.4% vs 21.9%; OR, 1.08; 95% CI, 0.91-1.26; P = .37). Similarly, women were less likely than men to receive a liver transplant within 3 years both pre-MELD (64.8% vs 67.6%; OR, 0.80; 95% CI, 0.70-0.92; P = .002) and post-MELD (39.9% vs 48.7%; OR, 0.70; 95% CI, 0.62-0.79; P < .001).Following introduction of the MELD score to the liver transplantation allocation system, race was no longer associated with receipt of a liver transplant or death on the waiting list, but disparities based on sex remain.","Disparities in liver transplantation before and after introduction of the MELD score."
"993","JAMA.449","0.003",19033587,2008,"In February 2002, the allocation system for liver transplantation became based on the Model for End-Stage Liver Disease (MELD) score. Before MELD, black patients were more likely to die or become too sick to undergo liver transplantation compared with white patients. Little information exists regarding sex and access to liver transplantation.To determine the association between race, sex, and liver transplantation following introduction of the MELD system.A retrospective cohort of black and white patients (> or = 18 years) registered on the United Network for Organ Sharing liver transplantation waiting list between January 1, 1996, and December 31, 2000 (pre-MELD cohort, n = 21 895) and between February 28, 2002, and March 31, 2006 (post-MELD cohort, n = 23 793).Association between race, sex, and receipt of a liver transplant. Separate multivariable analyses evaluated cohorts within each period to identify predictors of time to death and the odds of dying or receiving liver transplantation within 3 years of listing. Patients with hepatocellular carcinoma were analyzed separately.Black patients were younger (mean [SD], 49.2 [10.7] vs 52.4 [9.2] years; P < .001) and sicker (MELD score at listing: median [interquartile range], 16 [12-22] vs 14 [11-19]; P < .001) than white patients on the waiting list for both periods. In the pre-MELD cohort, black patients were more likely to die or become too sick for liver transplantation than white patients (27.0% vs 21.7%) within 3 years of registering on the waiting list (odds ratio [OR], 1.51; 95% confidence interval (CI), 1.15-1.98; P = .003). In the post-MELD cohort, black race was no longer associated with increased likelihood of death or becoming too sick for liver transplantation (26.5% vs 22.0%, respectively; OR, 0.96; 95% CI, 0.74-1.26; P = .76). Black patients were also less likely to receive a liver transplant than white patients within 3 years of registering on the waiting list pre-MELD (61.6% vs 66.9%; OR, 0.75; 95% CI, 0.59-0.97; P = .03), whereas post-MELD, race was no longer significantly associated with receipt of a liver transplant (47.5% vs 45.5%, respectively; OR, 1.04; 95% CI, 0.84-1.28; P = .75). Women were more likely than men to die or become too sick for liver transplantation post-MELD (23.7% vs 21.4%; OR, 1.30; 95% CI, 1.08-1.47; P = .003) vs pre-MELD (22.4% vs 21.9%; OR, 1.08; 95% CI, 0.91-1.26; P = .37). Similarly, women were less likely than men to receive a liver transplant within 3 years both pre-MELD (64.8% vs 67.6%; OR, 0.80; 95% CI, 0.70-0.92; P = .002) and post-MELD (39.9% vs 48.7%; OR, 0.70; 95% CI, 0.62-0.79; P < .001).Following introduction of the MELD score to the liver transplantation allocation system, race was no longer associated with receipt of a liver transplant or death on the waiting list, but disparities based on sex remain.","Disparities in liver transplantation before and after introduction of the MELD score."
"994","JAMA.450","0.76",19033587,2008,"In February 2002, the allocation system for liver transplantation became based on the Model for End-Stage Liver Disease (MELD) score. Before MELD, black patients were more likely to die or become too sick to undergo liver transplantation compared with white patients. Little information exists regarding sex and access to liver transplantation.To determine the association between race, sex, and liver transplantation following introduction of the MELD system.A retrospective cohort of black and white patients (> or = 18 years) registered on the United Network for Organ Sharing liver transplantation waiting list between January 1, 1996, and December 31, 2000 (pre-MELD cohort, n = 21 895) and between February 28, 2002, and March 31, 2006 (post-MELD cohort, n = 23 793).Association between race, sex, and receipt of a liver transplant. Separate multivariable analyses evaluated cohorts within each period to identify predictors of time to death and the odds of dying or receiving liver transplantation within 3 years of listing. Patients with hepatocellular carcinoma were analyzed separately.Black patients were younger (mean [SD], 49.2 [10.7] vs 52.4 [9.2] years; P < .001) and sicker (MELD score at listing: median [interquartile range], 16 [12-22] vs 14 [11-19]; P < .001) than white patients on the waiting list for both periods. In the pre-MELD cohort, black patients were more likely to die or become too sick for liver transplantation than white patients (27.0% vs 21.7%) within 3 years of registering on the waiting list (odds ratio [OR], 1.51; 95% confidence interval (CI), 1.15-1.98; P = .003). In the post-MELD cohort, black race was no longer associated with increased likelihood of death or becoming too sick for liver transplantation (26.5% vs 22.0%, respectively; OR, 0.96; 95% CI, 0.74-1.26; P = .76). Black patients were also less likely to receive a liver transplant than white patients within 3 years of registering on the waiting list pre-MELD (61.6% vs 66.9%; OR, 0.75; 95% CI, 0.59-0.97; P = .03), whereas post-MELD, race was no longer significantly associated with receipt of a liver transplant (47.5% vs 45.5%, respectively; OR, 1.04; 95% CI, 0.84-1.28; P = .75). Women were more likely than men to die or become too sick for liver transplantation post-MELD (23.7% vs 21.4%; OR, 1.30; 95% CI, 1.08-1.47; P = .003) vs pre-MELD (22.4% vs 21.9%; OR, 1.08; 95% CI, 0.91-1.26; P = .37). Similarly, women were less likely than men to receive a liver transplant within 3 years both pre-MELD (64.8% vs 67.6%; OR, 0.80; 95% CI, 0.70-0.92; P = .002) and post-MELD (39.9% vs 48.7%; OR, 0.70; 95% CI, 0.62-0.79; P < .001).Following introduction of the MELD score to the liver transplantation allocation system, race was no longer associated with receipt of a liver transplant or death on the waiting list, but disparities based on sex remain.","Disparities in liver transplantation before and after introduction of the MELD score."
"995","JAMA.451","0.03",19033587,2008,"In February 2002, the allocation system for liver transplantation became based on the Model for End-Stage Liver Disease (MELD) score. Before MELD, black patients were more likely to die or become too sick to undergo liver transplantation compared with white patients. Little information exists regarding sex and access to liver transplantation.To determine the association between race, sex, and liver transplantation following introduction of the MELD system.A retrospective cohort of black and white patients (> or = 18 years) registered on the United Network for Organ Sharing liver transplantation waiting list between January 1, 1996, and December 31, 2000 (pre-MELD cohort, n = 21 895) and between February 28, 2002, and March 31, 2006 (post-MELD cohort, n = 23 793).Association between race, sex, and receipt of a liver transplant. Separate multivariable analyses evaluated cohorts within each period to identify predictors of time to death and the odds of dying or receiving liver transplantation within 3 years of listing. Patients with hepatocellular carcinoma were analyzed separately.Black patients were younger (mean [SD], 49.2 [10.7] vs 52.4 [9.2] years; P < .001) and sicker (MELD score at listing: median [interquartile range], 16 [12-22] vs 14 [11-19]; P < .001) than white patients on the waiting list for both periods. In the pre-MELD cohort, black patients were more likely to die or become too sick for liver transplantation than white patients (27.0% vs 21.7%) within 3 years of registering on the waiting list (odds ratio [OR], 1.51; 95% confidence interval (CI), 1.15-1.98; P = .003). In the post-MELD cohort, black race was no longer associated with increased likelihood of death or becoming too sick for liver transplantation (26.5% vs 22.0%, respectively; OR, 0.96; 95% CI, 0.74-1.26; P = .76). Black patients were also less likely to receive a liver transplant than white patients within 3 years of registering on the waiting list pre-MELD (61.6% vs 66.9%; OR, 0.75; 95% CI, 0.59-0.97; P = .03), whereas post-MELD, race was no longer significantly associated with receipt of a liver transplant (47.5% vs 45.5%, respectively; OR, 1.04; 95% CI, 0.84-1.28; P = .75). Women were more likely than men to die or become too sick for liver transplantation post-MELD (23.7% vs 21.4%; OR, 1.30; 95% CI, 1.08-1.47; P = .003) vs pre-MELD (22.4% vs 21.9%; OR, 1.08; 95% CI, 0.91-1.26; P = .37). Similarly, women were less likely than men to receive a liver transplant within 3 years both pre-MELD (64.8% vs 67.6%; OR, 0.80; 95% CI, 0.70-0.92; P = .002) and post-MELD (39.9% vs 48.7%; OR, 0.70; 95% CI, 0.62-0.79; P < .001).Following introduction of the MELD score to the liver transplantation allocation system, race was no longer associated with receipt of a liver transplant or death on the waiting list, but disparities based on sex remain.","Disparities in liver transplantation before and after introduction of the MELD score."
"996","JAMA.452","0.75",19033587,2008,"In February 2002, the allocation system for liver transplantation became based on the Model for End-Stage Liver Disease (MELD) score. Before MELD, black patients were more likely to die or become too sick to undergo liver transplantation compared with white patients. Little information exists regarding sex and access to liver transplantation.To determine the association between race, sex, and liver transplantation following introduction of the MELD system.A retrospective cohort of black and white patients (> or = 18 years) registered on the United Network for Organ Sharing liver transplantation waiting list between January 1, 1996, and December 31, 2000 (pre-MELD cohort, n = 21 895) and between February 28, 2002, and March 31, 2006 (post-MELD cohort, n = 23 793).Association between race, sex, and receipt of a liver transplant. Separate multivariable analyses evaluated cohorts within each period to identify predictors of time to death and the odds of dying or receiving liver transplantation within 3 years of listing. Patients with hepatocellular carcinoma were analyzed separately.Black patients were younger (mean [SD], 49.2 [10.7] vs 52.4 [9.2] years; P < .001) and sicker (MELD score at listing: median [interquartile range], 16 [12-22] vs 14 [11-19]; P < .001) than white patients on the waiting list for both periods. In the pre-MELD cohort, black patients were more likely to die or become too sick for liver transplantation than white patients (27.0% vs 21.7%) within 3 years of registering on the waiting list (odds ratio [OR], 1.51; 95% confidence interval (CI), 1.15-1.98; P = .003). In the post-MELD cohort, black race was no longer associated with increased likelihood of death or becoming too sick for liver transplantation (26.5% vs 22.0%, respectively; OR, 0.96; 95% CI, 0.74-1.26; P = .76). Black patients were also less likely to receive a liver transplant than white patients within 3 years of registering on the waiting list pre-MELD (61.6% vs 66.9%; OR, 0.75; 95% CI, 0.59-0.97; P = .03), whereas post-MELD, race was no longer significantly associated with receipt of a liver transplant (47.5% vs 45.5%, respectively; OR, 1.04; 95% CI, 0.84-1.28; P = .75). Women were more likely than men to die or become too sick for liver transplantation post-MELD (23.7% vs 21.4%; OR, 1.30; 95% CI, 1.08-1.47; P = .003) vs pre-MELD (22.4% vs 21.9%; OR, 1.08; 95% CI, 0.91-1.26; P = .37). Similarly, women were less likely than men to receive a liver transplant within 3 years both pre-MELD (64.8% vs 67.6%; OR, 0.80; 95% CI, 0.70-0.92; P = .002) and post-MELD (39.9% vs 48.7%; OR, 0.70; 95% CI, 0.62-0.79; P < .001).Following introduction of the MELD score to the liver transplantation allocation system, race was no longer associated with receipt of a liver transplant or death on the waiting list, but disparities based on sex remain.","Disparities in liver transplantation before and after introduction of the MELD score."
"997","JAMA.453","0.003",19033587,2008,"In February 2002, the allocation system for liver transplantation became based on the Model for End-Stage Liver Disease (MELD) score. Before MELD, black patients were more likely to die or become too sick to undergo liver transplantation compared with white patients. Little information exists regarding sex and access to liver transplantation.To determine the association between race, sex, and liver transplantation following introduction of the MELD system.A retrospective cohort of black and white patients (> or = 18 years) registered on the United Network for Organ Sharing liver transplantation waiting list between January 1, 1996, and December 31, 2000 (pre-MELD cohort, n = 21 895) and between February 28, 2002, and March 31, 2006 (post-MELD cohort, n = 23 793).Association between race, sex, and receipt of a liver transplant. Separate multivariable analyses evaluated cohorts within each period to identify predictors of time to death and the odds of dying or receiving liver transplantation within 3 years of listing. Patients with hepatocellular carcinoma were analyzed separately.Black patients were younger (mean [SD], 49.2 [10.7] vs 52.4 [9.2] years; P < .001) and sicker (MELD score at listing: median [interquartile range], 16 [12-22] vs 14 [11-19]; P < .001) than white patients on the waiting list for both periods. In the pre-MELD cohort, black patients were more likely to die or become too sick for liver transplantation than white patients (27.0% vs 21.7%) within 3 years of registering on the waiting list (odds ratio [OR], 1.51; 95% confidence interval (CI), 1.15-1.98; P = .003). In the post-MELD cohort, black race was no longer associated with increased likelihood of death or becoming too sick for liver transplantation (26.5% vs 22.0%, respectively; OR, 0.96; 95% CI, 0.74-1.26; P = .76). Black patients were also less likely to receive a liver transplant than white patients within 3 years of registering on the waiting list pre-MELD (61.6% vs 66.9%; OR, 0.75; 95% CI, 0.59-0.97; P = .03), whereas post-MELD, race was no longer significantly associated with receipt of a liver transplant (47.5% vs 45.5%, respectively; OR, 1.04; 95% CI, 0.84-1.28; P = .75). Women were more likely than men to die or become too sick for liver transplantation post-MELD (23.7% vs 21.4%; OR, 1.30; 95% CI, 1.08-1.47; P = .003) vs pre-MELD (22.4% vs 21.9%; OR, 1.08; 95% CI, 0.91-1.26; P = .37). Similarly, women were less likely than men to receive a liver transplant within 3 years both pre-MELD (64.8% vs 67.6%; OR, 0.80; 95% CI, 0.70-0.92; P = .002) and post-MELD (39.9% vs 48.7%; OR, 0.70; 95% CI, 0.62-0.79; P < .001).Following introduction of the MELD score to the liver transplantation allocation system, race was no longer associated with receipt of a liver transplant or death on the waiting list, but disparities based on sex remain.","Disparities in liver transplantation before and after introduction of the MELD score."
"998","JAMA.454","0.37",19033587,2008,"In February 2002, the allocation system for liver transplantation became based on the Model for End-Stage Liver Disease (MELD) score. Before MELD, black patients were more likely to die or become too sick to undergo liver transplantation compared with white patients. Little information exists regarding sex and access to liver transplantation.To determine the association between race, sex, and liver transplantation following introduction of the MELD system.A retrospective cohort of black and white patients (> or = 18 years) registered on the United Network for Organ Sharing liver transplantation waiting list between January 1, 1996, and December 31, 2000 (pre-MELD cohort, n = 21 895) and between February 28, 2002, and March 31, 2006 (post-MELD cohort, n = 23 793).Association between race, sex, and receipt of a liver transplant. Separate multivariable analyses evaluated cohorts within each period to identify predictors of time to death and the odds of dying or receiving liver transplantation within 3 years of listing. Patients with hepatocellular carcinoma were analyzed separately.Black patients were younger (mean [SD], 49.2 [10.7] vs 52.4 [9.2] years; P < .001) and sicker (MELD score at listing: median [interquartile range], 16 [12-22] vs 14 [11-19]; P < .001) than white patients on the waiting list for both periods. In the pre-MELD cohort, black patients were more likely to die or become too sick for liver transplantation than white patients (27.0% vs 21.7%) within 3 years of registering on the waiting list (odds ratio [OR], 1.51; 95% confidence interval (CI), 1.15-1.98; P = .003). In the post-MELD cohort, black race was no longer associated with increased likelihood of death or becoming too sick for liver transplantation (26.5% vs 22.0%, respectively; OR, 0.96; 95% CI, 0.74-1.26; P = .76). Black patients were also less likely to receive a liver transplant than white patients within 3 years of registering on the waiting list pre-MELD (61.6% vs 66.9%; OR, 0.75; 95% CI, 0.59-0.97; P = .03), whereas post-MELD, race was no longer significantly associated with receipt of a liver transplant (47.5% vs 45.5%, respectively; OR, 1.04; 95% CI, 0.84-1.28; P = .75). Women were more likely than men to die or become too sick for liver transplantation post-MELD (23.7% vs 21.4%; OR, 1.30; 95% CI, 1.08-1.47; P = .003) vs pre-MELD (22.4% vs 21.9%; OR, 1.08; 95% CI, 0.91-1.26; P = .37). Similarly, women were less likely than men to receive a liver transplant within 3 years both pre-MELD (64.8% vs 67.6%; OR, 0.80; 95% CI, 0.70-0.92; P = .002) and post-MELD (39.9% vs 48.7%; OR, 0.70; 95% CI, 0.62-0.79; P < .001).Following introduction of the MELD score to the liver transplantation allocation system, race was no longer associated with receipt of a liver transplant or death on the waiting list, but disparities based on sex remain.","Disparities in liver transplantation before and after introduction of the MELD score."
"999","JAMA.455","0.002",19033587,2008,"In February 2002, the allocation system for liver transplantation became based on the Model for End-Stage Liver Disease (MELD) score. Before MELD, black patients were more likely to die or become too sick to undergo liver transplantation compared with white patients. Little information exists regarding sex and access to liver transplantation.To determine the association between race, sex, and liver transplantation following introduction of the MELD system.A retrospective cohort of black and white patients (> or = 18 years) registered on the United Network for Organ Sharing liver transplantation waiting list between January 1, 1996, and December 31, 2000 (pre-MELD cohort, n = 21 895) and between February 28, 2002, and March 31, 2006 (post-MELD cohort, n = 23 793).Association between race, sex, and receipt of a liver transplant. Separate multivariable analyses evaluated cohorts within each period to identify predictors of time to death and the odds of dying or receiving liver transplantation within 3 years of listing. Patients with hepatocellular carcinoma were analyzed separately.Black patients were younger (mean [SD], 49.2 [10.7] vs 52.4 [9.2] years; P < .001) and sicker (MELD score at listing: median [interquartile range], 16 [12-22] vs 14 [11-19]; P < .001) than white patients on the waiting list for both periods. In the pre-MELD cohort, black patients were more likely to die or become too sick for liver transplantation than white patients (27.0% vs 21.7%) within 3 years of registering on the waiting list (odds ratio [OR], 1.51; 95% confidence interval (CI), 1.15-1.98; P = .003). In the post-MELD cohort, black race was no longer associated with increased likelihood of death or becoming too sick for liver transplantation (26.5% vs 22.0%, respectively; OR, 0.96; 95% CI, 0.74-1.26; P = .76). Black patients were also less likely to receive a liver transplant than white patients within 3 years of registering on the waiting list pre-MELD (61.6% vs 66.9%; OR, 0.75; 95% CI, 0.59-0.97; P = .03), whereas post-MELD, race was no longer significantly associated with receipt of a liver transplant (47.5% vs 45.5%, respectively; OR, 1.04; 95% CI, 0.84-1.28; P = .75). Women were more likely than men to die or become too sick for liver transplantation post-MELD (23.7% vs 21.4%; OR, 1.30; 95% CI, 1.08-1.47; P = .003) vs pre-MELD (22.4% vs 21.9%; OR, 1.08; 95% CI, 0.91-1.26; P = .37). Similarly, women were less likely than men to receive a liver transplant within 3 years both pre-MELD (64.8% vs 67.6%; OR, 0.80; 95% CI, 0.70-0.92; P = .002) and post-MELD (39.9% vs 48.7%; OR, 0.70; 95% CI, 0.62-0.79; P < .001).Following introduction of the MELD score to the liver transplantation allocation system, race was no longer associated with receipt of a liver transplant or death on the waiting list, but disparities based on sex remain.","Disparities in liver transplantation before and after introduction of the MELD score."
"1000","JAMA.4491","0.002",19033588,2008,"Depressive symptoms predict adverse cardiovascular outcomes in patients with coronary heart disease, but the mechanisms responsible for this association are unknown.To determine why depressive symptoms are associated with an increased risk of cardiovascular events.The Heart and Soul Study is a prospective cohort study of 1017 outpatients with stable coronary heart disease followed up for a mean (SD) of 4.8 (1.4) years.Participants were recruited between September 11, 2000, and December 20, 2002, from 12 outpatient clinics in the San Francisco Bay Area and were followed up to January 12, 2008.Baseline depressive symptoms were assessed using the Patient Health Questionnaire (PHQ). We used proportional hazards models to evaluate the extent to which the association of depressive symptoms with subsequent cardiovascular events (heart failure, myocardial infarction, stroke, transient ischemic attack, or death) was explained by baseline disease severity and potential biological or behavioral mediators.A total of 341 cardiovascular events occurred during 4876 person-years of follow-up. The age-adjusted annual rate of cardiovascular events was 10.0% among the 199 participants with depressive symptoms (PHQ score > or = 10) and 6.7% among the 818 participants without depressive symptoms (hazard ratio [HR], 1.50; 95% confidence interval, [CI], 1.16-1.95; P = .002). After adjustment for comorbid conditions and disease severity, depressive symptoms were associated with a 31% higher rate of cardiovascular events (HR, 1.31; 95% CI, 1.00-1.71; P = .04). Additional adjustment for potential biological mediators attenuated this association (HR, 1.24; 95% CI, 0.94-1.63; P = .12). After further adjustment for potential behavioral mediators, including physical inactivity, there was no significant association (HR, 1.05; 95% CI, 0.79-1.40; P = .75).In this sample of outpatients with coronary heart disease, the association between depressive symptoms and adverse cardiovascular events was largely explained by behavioral factors, particularly physical inactivity.","Depressive symptoms, health behaviors, and risk of cardiovascular events in patients with coronary heart disease."
"1001","JAMA.4501","0.04",19033588,2008,"Depressive symptoms predict adverse cardiovascular outcomes in patients with coronary heart disease, but the mechanisms responsible for this association are unknown.To determine why depressive symptoms are associated with an increased risk of cardiovascular events.The Heart and Soul Study is a prospective cohort study of 1017 outpatients with stable coronary heart disease followed up for a mean (SD) of 4.8 (1.4) years.Participants were recruited between September 11, 2000, and December 20, 2002, from 12 outpatient clinics in the San Francisco Bay Area and were followed up to January 12, 2008.Baseline depressive symptoms were assessed using the Patient Health Questionnaire (PHQ). We used proportional hazards models to evaluate the extent to which the association of depressive symptoms with subsequent cardiovascular events (heart failure, myocardial infarction, stroke, transient ischemic attack, or death) was explained by baseline disease severity and potential biological or behavioral mediators.A total of 341 cardiovascular events occurred during 4876 person-years of follow-up. The age-adjusted annual rate of cardiovascular events was 10.0% among the 199 participants with depressive symptoms (PHQ score > or = 10) and 6.7% among the 818 participants without depressive symptoms (hazard ratio [HR], 1.50; 95% confidence interval, [CI], 1.16-1.95; P = .002). After adjustment for comorbid conditions and disease severity, depressive symptoms were associated with a 31% higher rate of cardiovascular events (HR, 1.31; 95% CI, 1.00-1.71; P = .04). Additional adjustment for potential biological mediators attenuated this association (HR, 1.24; 95% CI, 0.94-1.63; P = .12). After further adjustment for potential behavioral mediators, including physical inactivity, there was no significant association (HR, 1.05; 95% CI, 0.79-1.40; P = .75).In this sample of outpatients with coronary heart disease, the association between depressive symptoms and adverse cardiovascular events was largely explained by behavioral factors, particularly physical inactivity.","Depressive symptoms, health behaviors, and risk of cardiovascular events in patients with coronary heart disease."
"1002","JAMA.4511","0.12",19033588,2008,"Depressive symptoms predict adverse cardiovascular outcomes in patients with coronary heart disease, but the mechanisms responsible for this association are unknown.To determine why depressive symptoms are associated with an increased risk of cardiovascular events.The Heart and Soul Study is a prospective cohort study of 1017 outpatients with stable coronary heart disease followed up for a mean (SD) of 4.8 (1.4) years.Participants were recruited between September 11, 2000, and December 20, 2002, from 12 outpatient clinics in the San Francisco Bay Area and were followed up to January 12, 2008.Baseline depressive symptoms were assessed using the Patient Health Questionnaire (PHQ). We used proportional hazards models to evaluate the extent to which the association of depressive symptoms with subsequent cardiovascular events (heart failure, myocardial infarction, stroke, transient ischemic attack, or death) was explained by baseline disease severity and potential biological or behavioral mediators.A total of 341 cardiovascular events occurred during 4876 person-years of follow-up. The age-adjusted annual rate of cardiovascular events was 10.0% among the 199 participants with depressive symptoms (PHQ score > or = 10) and 6.7% among the 818 participants without depressive symptoms (hazard ratio [HR], 1.50; 95% confidence interval, [CI], 1.16-1.95; P = .002). After adjustment for comorbid conditions and disease severity, depressive symptoms were associated with a 31% higher rate of cardiovascular events (HR, 1.31; 95% CI, 1.00-1.71; P = .04). Additional adjustment for potential biological mediators attenuated this association (HR, 1.24; 95% CI, 0.94-1.63; P = .12). After further adjustment for potential behavioral mediators, including physical inactivity, there was no significant association (HR, 1.05; 95% CI, 0.79-1.40; P = .75).In this sample of outpatients with coronary heart disease, the association between depressive symptoms and adverse cardiovascular events was largely explained by behavioral factors, particularly physical inactivity.","Depressive symptoms, health behaviors, and risk of cardiovascular events in patients with coronary heart disease."
"1003","JAMA.4521","0.75",19033588,2008,"Depressive symptoms predict adverse cardiovascular outcomes in patients with coronary heart disease, but the mechanisms responsible for this association are unknown.To determine why depressive symptoms are associated with an increased risk of cardiovascular events.The Heart and Soul Study is a prospective cohort study of 1017 outpatients with stable coronary heart disease followed up for a mean (SD) of 4.8 (1.4) years.Participants were recruited between September 11, 2000, and December 20, 2002, from 12 outpatient clinics in the San Francisco Bay Area and were followed up to January 12, 2008.Baseline depressive symptoms were assessed using the Patient Health Questionnaire (PHQ). We used proportional hazards models to evaluate the extent to which the association of depressive symptoms with subsequent cardiovascular events (heart failure, myocardial infarction, stroke, transient ischemic attack, or death) was explained by baseline disease severity and potential biological or behavioral mediators.A total of 341 cardiovascular events occurred during 4876 person-years of follow-up. The age-adjusted annual rate of cardiovascular events was 10.0% among the 199 participants with depressive symptoms (PHQ score > or = 10) and 6.7% among the 818 participants without depressive symptoms (hazard ratio [HR], 1.50; 95% confidence interval, [CI], 1.16-1.95; P = .002). After adjustment for comorbid conditions and disease severity, depressive symptoms were associated with a 31% higher rate of cardiovascular events (HR, 1.31; 95% CI, 1.00-1.71; P = .04). Additional adjustment for potential biological mediators attenuated this association (HR, 1.24; 95% CI, 0.94-1.63; P = .12). After further adjustment for potential behavioral mediators, including physical inactivity, there was no significant association (HR, 1.05; 95% CI, 0.79-1.40; P = .75).In this sample of outpatients with coronary heart disease, the association between depressive symptoms and adverse cardiovascular events was largely explained by behavioral factors, particularly physical inactivity.","Depressive symptoms, health behaviors, and risk of cardiovascular events in patients with coronary heart disease."
"1004","JAMA.445","0.06",19050194,2008,"Rapid response teams have been shown in adult inpatients to decrease cardiopulmonary arrest (code) rates outside of the intensive care unit (ICU). Because a primary action of rapid response teams is to transfer patients to the ICU, their ability to reduce hospital-wide code rates and mortality remains unknown.To determine rates of hospital-wide codes and mortality before and after implementation of a long-term rapid response team intervention.A prospective cohort design of adult inpatients admitted between January 1, 2004, and August 31, 2007, at Saint Luke's Hospital, a 404-bed tertiary care academic hospital in Kansas City, Missouri. Rapid response team education and program rollout occurred from September 1 to December 31, 2005. A total of 24 193 patient admissions were evaluated prior to the intervention (January 1, 2004, to August 31, 2005), and 24 978 admissions were evaluated after the intervention (January 1, 2006, to August 31, 2007).Using standard activation criteria, a 3-member rapid response team composed of experienced ICU staff and a respiratory therapist performed the evaluation, treatment, and triage of inpatients with evidence of acute physiological decline.Hospital-wide code rates and mortality, adjusted for preintervention trends.There were a total of 376 rapid response team activations. After rapid response team implementation, mean hospital-wide code rates decreased from 11.2 to 7.5 per 1000 admissions. This was not associated with a reduction in the primary end point of hospital-wide code rates (adjusted odds ratio [AOR], 0.76 [95% confidence interval {CI}, 0.57-1.01]; P = .06), although lower rates of non-ICU codes were observed (non-ICU AOR, 0.59 [95% CI, 0.40-0.89] vs ICU AOR, 0.95 [95% CI, 0.64-1.43]; P = .03 for interaction). Similarly, hospital-wide mortality did not differ between the preintervention and postintervention periods (3.22 vs 3.09 per 100 admissions; AOR, 0.95 [95% CI, 0.81-1.11]; P = .52). Secondary analyses revealed few instances of rapid response team undertreatment or underuse that may have affected the mortality findings.In this large single-institution study, rapid response team implementation was not associated with reductions in hospital-wide code rates or mortality.","Hospital-wide code rates and mortality before and after implementation of a rapid response team."
"1005","JAMA.447","0.52",19050194,2008,"Rapid response teams have been shown in adult inpatients to decrease cardiopulmonary arrest (code) rates outside of the intensive care unit (ICU). Because a primary action of rapid response teams is to transfer patients to the ICU, their ability to reduce hospital-wide code rates and mortality remains unknown.To determine rates of hospital-wide codes and mortality before and after implementation of a long-term rapid response team intervention.A prospective cohort design of adult inpatients admitted between January 1, 2004, and August 31, 2007, at Saint Luke's Hospital, a 404-bed tertiary care academic hospital in Kansas City, Missouri. Rapid response team education and program rollout occurred from September 1 to December 31, 2005. A total of 24 193 patient admissions were evaluated prior to the intervention (January 1, 2004, to August 31, 2005), and 24 978 admissions were evaluated after the intervention (January 1, 2006, to August 31, 2007).Using standard activation criteria, a 3-member rapid response team composed of experienced ICU staff and a respiratory therapist performed the evaluation, treatment, and triage of inpatients with evidence of acute physiological decline.Hospital-wide code rates and mortality, adjusted for preintervention trends.There were a total of 376 rapid response team activations. After rapid response team implementation, mean hospital-wide code rates decreased from 11.2 to 7.5 per 1000 admissions. This was not associated with a reduction in the primary end point of hospital-wide code rates (adjusted odds ratio [AOR], 0.76 [95% confidence interval {CI}, 0.57-1.01]; P = .06), although lower rates of non-ICU codes were observed (non-ICU AOR, 0.59 [95% CI, 0.40-0.89] vs ICU AOR, 0.95 [95% CI, 0.64-1.43]; P = .03 for interaction). Similarly, hospital-wide mortality did not differ between the preintervention and postintervention periods (3.22 vs 3.09 per 100 admissions; AOR, 0.95 [95% CI, 0.81-1.11]; P = .52). Secondary analyses revealed few instances of rapid response team undertreatment or underuse that may have affected the mortality findings.In this large single-institution study, rapid response team implementation was not associated with reductions in hospital-wide code rates or mortality.","Hospital-wide code rates and mortality before and after implementation of a rapid response team."
"1006","American Journal of Epidemiology.72","1.00E-04",19064644,2008,"The authors pooled data from 15 case-control studies of head and neck cancer (9,107 cases, 14,219 controls) to investigate the independent associations with consumption of beer, wine, and liquor. In particular, they calculated associations with different measures of beverage consumption separately for subjects who drank beer only (858 cases, 986 controls), for liquor-only drinkers (499 cases, 527 controls), and for wine-only drinkers (1,021 cases, 2,460 controls), with alcohol never drinkers (1,124 cases, 3,487 controls) used as a common reference group. The authors observed similar associations with ethanol-standardized consumption frequency for beer-only drinkers (odds ratios (ORs) = 1.6, 1.9, 2.2, and 5.4 for < or =5, 6-15, 16-30, and >30 drinks per week, respectively; P(trend) < 0.0001) and liquor-only drinkers (ORs = 1.6, 1.5, 2.3, and 3.6; P < 0.0001). Among wine-only drinkers, the odds ratios for moderate levels of consumption frequency approached the null, whereas those for higher consumption levels were comparable to those of drinkers of other beverage types (ORs = 1.1, 1.2, 1.9, and 6.3; P < 0.0001). Study findings suggest that the relative risks of head and neck cancer for beer and liquor are comparable. The authors observed weaker associations with moderate wine consumption, although they cannot rule out confounding from diet and other lifestyle factors as an explanation for this finding. Given the presence of heterogeneity in study-specific results, their findings should be interpreted with caution.","Type of alcoholic beverage and risk of head and neck cancer--a pooled analysis within the INHANCE Consortium."
"1007","American Journal of Epidemiology.73","1.00E-04",19064644,2008,"The authors pooled data from 15 case-control studies of head and neck cancer (9,107 cases, 14,219 controls) to investigate the independent associations with consumption of beer, wine, and liquor. In particular, they calculated associations with different measures of beverage consumption separately for subjects who drank beer only (858 cases, 986 controls), for liquor-only drinkers (499 cases, 527 controls), and for wine-only drinkers (1,021 cases, 2,460 controls), with alcohol never drinkers (1,124 cases, 3,487 controls) used as a common reference group. The authors observed similar associations with ethanol-standardized consumption frequency for beer-only drinkers (odds ratios (ORs) = 1.6, 1.9, 2.2, and 5.4 for < or =5, 6-15, 16-30, and >30 drinks per week, respectively; P(trend) < 0.0001) and liquor-only drinkers (ORs = 1.6, 1.5, 2.3, and 3.6; P < 0.0001). Among wine-only drinkers, the odds ratios for moderate levels of consumption frequency approached the null, whereas those for higher consumption levels were comparable to those of drinkers of other beverage types (ORs = 1.1, 1.2, 1.9, and 6.3; P < 0.0001). Study findings suggest that the relative risks of head and neck cancer for beer and liquor are comparable. The authors observed weaker associations with moderate wine consumption, although they cannot rule out confounding from diet and other lifestyle factors as an explanation for this finding. Given the presence of heterogeneity in study-specific results, their findings should be interpreted with caution.","Type of alcoholic beverage and risk of head and neck cancer--a pooled analysis within the INHANCE Consortium."
"1008","American Journal of Epidemiology.87","1.00E-04",19064644,2009,"The authors pooled data from 15 case-control studies of head and neck cancer (9,107 cases, 14,219 controls) to investigate the independent associations with consumption of beer, wine, and liquor. In particular, they calculated associations with different measures of beverage consumption separately for subjects who drank beer only (858 cases, 986 controls), for liquor-only drinkers (499 cases, 527 controls), and for wine-only drinkers (1,021 cases, 2,460 controls), with alcohol never drinkers (1,124 cases, 3,487 controls) used as a common reference group. The authors observed similar associations with ethanol-standardized consumption frequency for beer-only drinkers (odds ratios (ORs) = 1.6, 1.9, 2.2, and 5.4 for < or =5, 6-15, 16-30, and >30 drinks per week, respectively; P(trend) < 0.0001) and liquor-only drinkers (ORs = 1.6, 1.5, 2.3, and 3.6; P < 0.0001). Among wine-only drinkers, the odds ratios for moderate levels of consumption frequency approached the null, whereas those for higher consumption levels were comparable to those of drinkers of other beverage types (ORs = 1.1, 1.2, 1.9, and 6.3; P < 0.0001). Study findings suggest that the relative risks of head and neck cancer for beer and liquor are comparable. The authors observed weaker associations with moderate wine consumption, although they cannot rule out confounding from diet and other lifestyle factors as an explanation for this finding. Given the presence of heterogeneity in study-specific results, their findings should be interpreted with caution.","Type of alcoholic beverage and risk of head and neck cancer--a pooled analysis within the INHANCE Consortium."
"1009","American Journal of Epidemiology.88","1.00E-04",19064644,2009,"The authors pooled data from 15 case-control studies of head and neck cancer (9,107 cases, 14,219 controls) to investigate the independent associations with consumption of beer, wine, and liquor. In particular, they calculated associations with different measures of beverage consumption separately for subjects who drank beer only (858 cases, 986 controls), for liquor-only drinkers (499 cases, 527 controls), and for wine-only drinkers (1,021 cases, 2,460 controls), with alcohol never drinkers (1,124 cases, 3,487 controls) used as a common reference group. The authors observed similar associations with ethanol-standardized consumption frequency for beer-only drinkers (odds ratios (ORs) = 1.6, 1.9, 2.2, and 5.4 for < or =5, 6-15, 16-30, and >30 drinks per week, respectively; P(trend) < 0.0001) and liquor-only drinkers (ORs = 1.6, 1.5, 2.3, and 3.6; P < 0.0001). Among wine-only drinkers, the odds ratios for moderate levels of consumption frequency approached the null, whereas those for higher consumption levels were comparable to those of drinkers of other beverage types (ORs = 1.1, 1.2, 1.9, and 6.3; P < 0.0001). Study findings suggest that the relative risks of head and neck cancer for beer and liquor are comparable. The authors observed weaker associations with moderate wine consumption, although they cannot rule out confounding from diet and other lifestyle factors as an explanation for this finding. Given the presence of heterogeneity in study-specific results, their findings should be interpreted with caution.","Type of alcoholic beverage and risk of head and neck cancer--a pooled analysis within the INHANCE Consortium."
"1010","JAMA.4451","0.58",19066368,2008,"Many individuals take vitamins in the hopes of preventing chronic diseases such as cancer, and vitamins E and C are among the most common individual supplements. A large-scale randomized trial suggested that vitamin E may reduce risk of prostate cancer; however, few trials have been powered to address this relationship. No previous trial in men at usual risk has examined vitamin C alone in the prevention of cancer.To evaluate whether long-term vitamin E or C supplementation decreases risk of prostate and total cancer events among men.The Physicians' Health Study II is a randomized, double-blind, placebo-controlled factorial trial of vitamins E and C that began in 1997 and continued until its scheduled completion on August 31, 2007. A total of 14,641 male physicians in the United States initially aged 50 years or older, including 1307 men with a history of prior cancer at randomization, were enrolled.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.Prostate and total cancer.During a mean follow-up of 8.0 years, there were 1008 confirmed incident cases of prostate cancer and 1943 total cancers. Compared with placebo, vitamin E had no effect on the incidence of prostate cancer (active and placebo vitamin E groups, 9.1 and 9.5 events per 1000 person-years; hazard ratio [HR], 0.97; 95% confidence interval [CI], 0.85-1.09; P = .58) or total cancer (active and placebo vitamin E groups, 17.8 and 17.3 cases per 1000 person-years; HR, 1.04; 95% CI, 0.95-1.13; P = .41). There was also no significant effect of vitamin C on total cancer (active and placebo vitamin C groups, 17.6 and 17.5 events per 1000 person-years; HR, 1.01; 95% CI, 0.92-1.10; P = .86) or prostate cancer (active and placebo vitamin C groups, 9.4 and 9.2 cases per 1000 person-years; HR, 1.02; 95% CI, 0.90-1.15; P = .80). Neither vitamin E nor vitamin C had a significant effect on colorectal, lung, or other site-specific cancers. Adjustment for adherence and exclusion of the first 4 or 6 years of follow-up did not alter the results. Stratification by various cancer risk factors demonstrated no significant modification of the effect of vitamin E on prostate cancer risk or either agent on total cancer risk.In this large, long-term trial of male physicians, neither vitamin E nor C supplementation reduced the risk of prostate or total cancer. These data provide no support for the use of these supplements for the prevention of cancer in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of prostate and total cancer in men: the Physicians' Health Study II randomized controlled trial."
"1011","JAMA.4461","0.41",19066368,2008,"Many individuals take vitamins in the hopes of preventing chronic diseases such as cancer, and vitamins E and C are among the most common individual supplements. A large-scale randomized trial suggested that vitamin E may reduce risk of prostate cancer; however, few trials have been powered to address this relationship. No previous trial in men at usual risk has examined vitamin C alone in the prevention of cancer.To evaluate whether long-term vitamin E or C supplementation decreases risk of prostate and total cancer events among men.The Physicians' Health Study II is a randomized, double-blind, placebo-controlled factorial trial of vitamins E and C that began in 1997 and continued until its scheduled completion on August 31, 2007. A total of 14,641 male physicians in the United States initially aged 50 years or older, including 1307 men with a history of prior cancer at randomization, were enrolled.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.Prostate and total cancer.During a mean follow-up of 8.0 years, there were 1008 confirmed incident cases of prostate cancer and 1943 total cancers. Compared with placebo, vitamin E had no effect on the incidence of prostate cancer (active and placebo vitamin E groups, 9.1 and 9.5 events per 1000 person-years; hazard ratio [HR], 0.97; 95% confidence interval [CI], 0.85-1.09; P = .58) or total cancer (active and placebo vitamin E groups, 17.8 and 17.3 cases per 1000 person-years; HR, 1.04; 95% CI, 0.95-1.13; P = .41). There was also no significant effect of vitamin C on total cancer (active and placebo vitamin C groups, 17.6 and 17.5 events per 1000 person-years; HR, 1.01; 95% CI, 0.92-1.10; P = .86) or prostate cancer (active and placebo vitamin C groups, 9.4 and 9.2 cases per 1000 person-years; HR, 1.02; 95% CI, 0.90-1.15; P = .80). Neither vitamin E nor vitamin C had a significant effect on colorectal, lung, or other site-specific cancers. Adjustment for adherence and exclusion of the first 4 or 6 years of follow-up did not alter the results. Stratification by various cancer risk factors demonstrated no significant modification of the effect of vitamin E on prostate cancer risk or either agent on total cancer risk.In this large, long-term trial of male physicians, neither vitamin E nor C supplementation reduced the risk of prostate or total cancer. These data provide no support for the use of these supplements for the prevention of cancer in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of prostate and total cancer in men: the Physicians' Health Study II randomized controlled trial."
"1012","JAMA.4471","0.86",19066368,2008,"Many individuals take vitamins in the hopes of preventing chronic diseases such as cancer, and vitamins E and C are among the most common individual supplements. A large-scale randomized trial suggested that vitamin E may reduce risk of prostate cancer; however, few trials have been powered to address this relationship. No previous trial in men at usual risk has examined vitamin C alone in the prevention of cancer.To evaluate whether long-term vitamin E or C supplementation decreases risk of prostate and total cancer events among men.The Physicians' Health Study II is a randomized, double-blind, placebo-controlled factorial trial of vitamins E and C that began in 1997 and continued until its scheduled completion on August 31, 2007. A total of 14,641 male physicians in the United States initially aged 50 years or older, including 1307 men with a history of prior cancer at randomization, were enrolled.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.Prostate and total cancer.During a mean follow-up of 8.0 years, there were 1008 confirmed incident cases of prostate cancer and 1943 total cancers. Compared with placebo, vitamin E had no effect on the incidence of prostate cancer (active and placebo vitamin E groups, 9.1 and 9.5 events per 1000 person-years; hazard ratio [HR], 0.97; 95% confidence interval [CI], 0.85-1.09; P = .58) or total cancer (active and placebo vitamin E groups, 17.8 and 17.3 cases per 1000 person-years; HR, 1.04; 95% CI, 0.95-1.13; P = .41). There was also no significant effect of vitamin C on total cancer (active and placebo vitamin C groups, 17.6 and 17.5 events per 1000 person-years; HR, 1.01; 95% CI, 0.92-1.10; P = .86) or prostate cancer (active and placebo vitamin C groups, 9.4 and 9.2 cases per 1000 person-years; HR, 1.02; 95% CI, 0.90-1.15; P = .80). Neither vitamin E nor vitamin C had a significant effect on colorectal, lung, or other site-specific cancers. Adjustment for adherence and exclusion of the first 4 or 6 years of follow-up did not alter the results. Stratification by various cancer risk factors demonstrated no significant modification of the effect of vitamin E on prostate cancer risk or either agent on total cancer risk.In this large, long-term trial of male physicians, neither vitamin E nor C supplementation reduced the risk of prostate or total cancer. These data provide no support for the use of these supplements for the prevention of cancer in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of prostate and total cancer in men: the Physicians' Health Study II randomized controlled trial."
"1013","JAMA.4481","0.8",19066368,2008,"Many individuals take vitamins in the hopes of preventing chronic diseases such as cancer, and vitamins E and C are among the most common individual supplements. A large-scale randomized trial suggested that vitamin E may reduce risk of prostate cancer; however, few trials have been powered to address this relationship. No previous trial in men at usual risk has examined vitamin C alone in the prevention of cancer.To evaluate whether long-term vitamin E or C supplementation decreases risk of prostate and total cancer events among men.The Physicians' Health Study II is a randomized, double-blind, placebo-controlled factorial trial of vitamins E and C that began in 1997 and continued until its scheduled completion on August 31, 2007. A total of 14,641 male physicians in the United States initially aged 50 years or older, including 1307 men with a history of prior cancer at randomization, were enrolled.Individual supplements of 400 IU of vitamin E every other day and 500 mg of vitamin C daily.Prostate and total cancer.During a mean follow-up of 8.0 years, there were 1008 confirmed incident cases of prostate cancer and 1943 total cancers. Compared with placebo, vitamin E had no effect on the incidence of prostate cancer (active and placebo vitamin E groups, 9.1 and 9.5 events per 1000 person-years; hazard ratio [HR], 0.97; 95% confidence interval [CI], 0.85-1.09; P = .58) or total cancer (active and placebo vitamin E groups, 17.8 and 17.3 cases per 1000 person-years; HR, 1.04; 95% CI, 0.95-1.13; P = .41). There was also no significant effect of vitamin C on total cancer (active and placebo vitamin C groups, 17.6 and 17.5 events per 1000 person-years; HR, 1.01; 95% CI, 0.92-1.10; P = .86) or prostate cancer (active and placebo vitamin C groups, 9.4 and 9.2 cases per 1000 person-years; HR, 1.02; 95% CI, 0.90-1.15; P = .80). Neither vitamin E nor vitamin C had a significant effect on colorectal, lung, or other site-specific cancers. Adjustment for adherence and exclusion of the first 4 or 6 years of follow-up did not alter the results. Stratification by various cancer risk factors demonstrated no significant modification of the effect of vitamin E on prostate cancer risk or either agent on total cancer risk.In this large, long-term trial of male physicians, neither vitamin E nor C supplementation reduced the risk of prostate or total cancer. These data provide no support for the use of these supplements for the prevention of cancer in middle-aged and older men.clinicaltrials.gov Identifier: NCT00270647.","Vitamins E and C in the prevention of prostate and total cancer in men: the Physicians' Health Study II randomized controlled trial."
"1014","Lancet.1201","0.31",19070889,2008,"Hysterectomy and bilateral salpingo-oophorectomy (BSO) is the standard surgery for stage I endometrial cancer. Systematic pelvic lymphadenectomy has been used to establish whether there is extra-uterine disease and as a therapeutic procedure; however, randomised trials need to be done to assess therapeutic efficacy. The ASTEC surgical trial investigated whether pelvic lymphadenectomy could improve survival of women with endometrial cancer.From 85 centres in four countries, 1408 women with histologically proven endometrial carcinoma thought preoperatively to be confined to the corpus were randomly allocated by a minimisation method to standard surgery (hysterectomy and BSO, peritoneal washings, and palpation of para-aortic nodes; n=704) or standard surgery plus lymphadenectomy (n=704). The primary outcome measure was overall survival. To control for postsurgical treatment, women with early-stage disease at intermediate or high risk of recurrence were randomised (independent of lymph-node status) into the ASTEC radiotherapy trial. Analysis was by intention to treat. This study is registered, number ISRCTN 16571884.After a median follow-up of 37 months (IQR 24-58), 191 women (88 standard surgery group, 103 lymphadenectomy group) had died, with a hazard ratio (HR) of 1.16 (95% CI 0.87-1.54; p=0.31) in favour of standard surgery and an absolute difference in 5-year overall survival of 1% (95% CI -4 to 6). 251 women died or had recurrent disease (107 standard surgery group, 144 lymphadenectomy group), with an HR of 1.35 (1.06-1.73; p=0.017) in favour of standard surgery and an absolute difference in 5-year recurrence-free survival of 6% (1-12). With adjustment for baseline characteristics and pathology details, the HR for overall survival was 1.04 (0.74-1.45; p=0.83) and for recurrence-free survival was 1.25 (0.93-1.66; p=0.14).Our results show no evidence of benefit in terms of overall or recurrence-free survival for pelvic lymphadenectomy in women with early endometrial cancer. Pelvic lymphadenectomy cannot be recommended as routine procedure for therapeutic purposes outside of clinical trials.","Efficacy of systematic pelvic lymphadenectomy in endometrial cancer (MRC ASTEC trial): a randomised study."
"1015","Lancet.1211","0.017",19070889,2008,"Hysterectomy and bilateral salpingo-oophorectomy (BSO) is the standard surgery for stage I endometrial cancer. Systematic pelvic lymphadenectomy has been used to establish whether there is extra-uterine disease and as a therapeutic procedure; however, randomised trials need to be done to assess therapeutic efficacy. The ASTEC surgical trial investigated whether pelvic lymphadenectomy could improve survival of women with endometrial cancer.From 85 centres in four countries, 1408 women with histologically proven endometrial carcinoma thought preoperatively to be confined to the corpus were randomly allocated by a minimisation method to standard surgery (hysterectomy and BSO, peritoneal washings, and palpation of para-aortic nodes; n=704) or standard surgery plus lymphadenectomy (n=704). The primary outcome measure was overall survival. To control for postsurgical treatment, women with early-stage disease at intermediate or high risk of recurrence were randomised (independent of lymph-node status) into the ASTEC radiotherapy trial. Analysis was by intention to treat. This study is registered, number ISRCTN 16571884.After a median follow-up of 37 months (IQR 24-58), 191 women (88 standard surgery group, 103 lymphadenectomy group) had died, with a hazard ratio (HR) of 1.16 (95% CI 0.87-1.54; p=0.31) in favour of standard surgery and an absolute difference in 5-year overall survival of 1% (95% CI -4 to 6). 251 women died or had recurrent disease (107 standard surgery group, 144 lymphadenectomy group), with an HR of 1.35 (1.06-1.73; p=0.017) in favour of standard surgery and an absolute difference in 5-year recurrence-free survival of 6% (1-12). With adjustment for baseline characteristics and pathology details, the HR for overall survival was 1.04 (0.74-1.45; p=0.83) and for recurrence-free survival was 1.25 (0.93-1.66; p=0.14).Our results show no evidence of benefit in terms of overall or recurrence-free survival for pelvic lymphadenectomy in women with early endometrial cancer. Pelvic lymphadenectomy cannot be recommended as routine procedure for therapeutic purposes outside of clinical trials.","Efficacy of systematic pelvic lymphadenectomy in endometrial cancer (MRC ASTEC trial): a randomised study."
"1016","Lancet.1221","0.83",19070889,2008,"Hysterectomy and bilateral salpingo-oophorectomy (BSO) is the standard surgery for stage I endometrial cancer. Systematic pelvic lymphadenectomy has been used to establish whether there is extra-uterine disease and as a therapeutic procedure; however, randomised trials need to be done to assess therapeutic efficacy. The ASTEC surgical trial investigated whether pelvic lymphadenectomy could improve survival of women with endometrial cancer.From 85 centres in four countries, 1408 women with histologically proven endometrial carcinoma thought preoperatively to be confined to the corpus were randomly allocated by a minimisation method to standard surgery (hysterectomy and BSO, peritoneal washings, and palpation of para-aortic nodes; n=704) or standard surgery plus lymphadenectomy (n=704). The primary outcome measure was overall survival. To control for postsurgical treatment, women with early-stage disease at intermediate or high risk of recurrence were randomised (independent of lymph-node status) into the ASTEC radiotherapy trial. Analysis was by intention to treat. This study is registered, number ISRCTN 16571884.After a median follow-up of 37 months (IQR 24-58), 191 women (88 standard surgery group, 103 lymphadenectomy group) had died, with a hazard ratio (HR) of 1.16 (95% CI 0.87-1.54; p=0.31) in favour of standard surgery and an absolute difference in 5-year overall survival of 1% (95% CI -4 to 6). 251 women died or had recurrent disease (107 standard surgery group, 144 lymphadenectomy group), with an HR of 1.35 (1.06-1.73; p=0.017) in favour of standard surgery and an absolute difference in 5-year recurrence-free survival of 6% (1-12). With adjustment for baseline characteristics and pathology details, the HR for overall survival was 1.04 (0.74-1.45; p=0.83) and for recurrence-free survival was 1.25 (0.93-1.66; p=0.14).Our results show no evidence of benefit in terms of overall or recurrence-free survival for pelvic lymphadenectomy in women with early endometrial cancer. Pelvic lymphadenectomy cannot be recommended as routine procedure for therapeutic purposes outside of clinical trials.","Efficacy of systematic pelvic lymphadenectomy in endometrial cancer (MRC ASTEC trial): a randomised study."
"1017","Lancet.1231","0.14",19070889,2008,"Hysterectomy and bilateral salpingo-oophorectomy (BSO) is the standard surgery for stage I endometrial cancer. Systematic pelvic lymphadenectomy has been used to establish whether there is extra-uterine disease and as a therapeutic procedure; however, randomised trials need to be done to assess therapeutic efficacy. The ASTEC surgical trial investigated whether pelvic lymphadenectomy could improve survival of women with endometrial cancer.From 85 centres in four countries, 1408 women with histologically proven endometrial carcinoma thought preoperatively to be confined to the corpus were randomly allocated by a minimisation method to standard surgery (hysterectomy and BSO, peritoneal washings, and palpation of para-aortic nodes; n=704) or standard surgery plus lymphadenectomy (n=704). The primary outcome measure was overall survival. To control for postsurgical treatment, women with early-stage disease at intermediate or high risk of recurrence were randomised (independent of lymph-node status) into the ASTEC radiotherapy trial. Analysis was by intention to treat. This study is registered, number ISRCTN 16571884.After a median follow-up of 37 months (IQR 24-58), 191 women (88 standard surgery group, 103 lymphadenectomy group) had died, with a hazard ratio (HR) of 1.16 (95% CI 0.87-1.54; p=0.31) in favour of standard surgery and an absolute difference in 5-year overall survival of 1% (95% CI -4 to 6). 251 women died or had recurrent disease (107 standard surgery group, 144 lymphadenectomy group), with an HR of 1.35 (1.06-1.73; p=0.017) in favour of standard surgery and an absolute difference in 5-year recurrence-free survival of 6% (1-12). With adjustment for baseline characteristics and pathology details, the HR for overall survival was 1.04 (0.74-1.45; p=0.83) and for recurrence-free survival was 1.25 (0.93-1.66; p=0.14).Our results show no evidence of benefit in terms of overall or recurrence-free survival for pelvic lymphadenectomy in women with early endometrial cancer. Pelvic lymphadenectomy cannot be recommended as routine procedure for therapeutic purposes outside of clinical trials.","Efficacy of systematic pelvic lymphadenectomy in endometrial cancer (MRC ASTEC trial): a randomised study."
"1018","Lancet.1051","1.00E-04",19091394,2008,"Several studies have shown the efficacy of endocrine therapy in combination with radiotherapy in high-risk prostate cancer. To assess the effect of radiotherapy, we did an open phase III study comparing endocrine therapy with and without local radiotherapy, followed by castration on progression.This randomised trial included men from 47 centres in Norway, Sweden, and Denmark. Between February, 1996, and December, 2002, 875 patients with locally advanced prostate cancer (T3; 78%; PSA<70; N0; M0) were centrally randomly assigned by computer to endocrine treatment alone (3 months of total androgen blockade followed by continuous endocrine treatment using flutamide; 439 patients), or to the same endocrine treatment combined with radiotherapy (436 patients). The primary endpoint was prostate-cancer-specific survival, and analysis was by intention to treat. This study is registered as an international standard randomised controlled trial, number ISRCTN01534787.After a median follow-up of 7.6 years, 79 men in the endocrine alone group and 37 men in the endocrine plus radiotherapy group had died of prostate cancer. The cumulative incidence at 10 years for prostate-cancer-specific mortality was 23.9% in the endocrine alone group and 11.9% in the endocrine plus radiotherapy group (difference 12.0%, 95% CI 4.9-19.1%), for a relative risk of 0.44 (0.30-0.66). At 10 years, the cumulative incidence for overall mortality was 39.4% in the endocrine alone group and 29.6% in the endocrine plus radiotherapy group (difference 9.8%, 0.8-18.8%), for a relative risk of 0.68 (0.52-0.89). Cumulative incidence at 10 years for PSA recurrence was substantially higher in men in the endocrine-alone group (74.7%vs 25.9%, p<0.0001; HR 0.16; 0.12-0.20). After 5 years, urinary, rectal, and sexual problems were slightly more frequent in the endocrine plus radiotherapy group.In patients with locally advanced or high-risk local prostate cancer, addition of local radiotherapy to endocrine treatment halved the 10-year prostate-cancer-specific mortality, and substantially decreased overall mortality with fully acceptable risk of side-effects compared with endocrine treatment alone. In the light of these data, endocrine treatment plus radiotherapy should be the new standard.","Endocrine treatment, with or without radiotherapy, in locally advanced prostate cancer (SPCG-7/SFUO-3): an open randomised phase III trial."
"1019","American Journal of Epidemiology.201","0.056",19103608,2008,"The authors examined disparities in survival among women aged 66 years or older in association with census-tract-level poverty rate, racial distribution, and individual-level factors, including patient-, treatment-, and tumor-related factors, utilization of medical care, and mammography use. They used linked data from the 1992-1999 Surveillance, Epidemiology, and End Results (SEER) programs, 1991-1999 Medicare claims, and the 1990 US Census. A geographic information system and advanced statistics identified areas of increased or reduced breast cancer survival and possible reasons for geographic variation in survival in 2 of the 5 SEER areas studied. In the Detroit, Michigan, area, one geographic cluster of shorter-than-expected breast cancer survival was identified (hazard ratio (HR) = 1.60). An additional area where survival was longer than expected approached statistical significance (HR = 0.4; P = 0.056). In the Atlanta, Georgia, area, one cluster of shorter- (HR = 1.81) and one cluster of longer-than-expected (HR = 0.72) breast cancer survival were identified. Stage at diagnosis and census-tract poverty (and patient's race in Atlanta) explained the geographic variation in breast cancer survival. No geographic clusters were identified in the 3 other SEER programs. Interventions to reduce late-stage breast cancer, focusing on areas of high poverty and targeting African Americans, may reduce disparities in breast cancer survival in the Detroit and Atlanta areas.","The role of poverty rate and racial distribution in the geographic clustering of breast cancer survival among older women: a geographic and multilevel analysis."
"1020","Lancet.1161","5.00E-04",19108880,2008,"Clopidogrel and low-dose aspirin have become the mainstay oral antiplatelet regimen to prevent recurrent ischaemic events after acute coronary syndromes or stent placement. The frequent genetic functional variant 681 G>A (*2) of cytochrome P450 2C19 (CYP2C19) is an important contributor to the wide variability between individuals of the antiplatelet effect of clopidogrel. We assessed whether the CYP2C19*2 polymorphism affected long-term prognosis of patients who were chronically treated with clopidogrel.Between April 1, 1996, and April 1, 2008, 259 young patients (aged <45 years) who survived a first myocardial infarction and were exposed to clopidogrel treatment for at least a month, were enrolled in a multicentre registry and underwent CYP2C19*2 determination. The primary endpoint was a composite of death, myocardial infarction, and urgent coronary revascularisation occurring during exposure to clopidogrel. Follow-up was every 6 months. The key secondary endpoint was stent thrombosis proven by angiography.Median clopidogrel exposure time was 1.07 years (IQR 0.28-3.0). Baseline characteristics were balanced between carriers (heterozygous *1/*2, n=64; homozygous *2/*2, n=9) and non-carriers (n=186) of CYP2C19*2 variant. The primary endpoint occurred more frequently in carriers than in non-carriers (15 vs 11 events; hazard ratio [HR] 3.69 [95% CI 1.69-8.05], p=0.0005), as did stent thrombosis (eight vs four events; HR 6.02 [1.81-20.04], p=0.0009). The detrimental effect of the CYP2C19*2 genetic variant persisted from 6 months after clopidogrel initiation up to the end of follow-up (HR 3.00 [1.27-7.10], p=0.009). After multivariable analysis, the CYP2C19*2 genetic variant was the only independent predictor of cardiovascular events (HR 4.04 [1.81-9.02], p=0.0006).The CYP2C19*2 genetic variant is a major determinant of prognosis in young patients who are receiving clopidogrel treatment after myocardial infarction.","Cytochrome P450 2C19 polymorphism in young patients treated with clopidogrel after myocardial infarction: a cohort study."
"1021","Lancet.1171","9.00E-04",19108880,2008,"Clopidogrel and low-dose aspirin have become the mainstay oral antiplatelet regimen to prevent recurrent ischaemic events after acute coronary syndromes or stent placement. The frequent genetic functional variant 681 G>A (*2) of cytochrome P450 2C19 (CYP2C19) is an important contributor to the wide variability between individuals of the antiplatelet effect of clopidogrel. We assessed whether the CYP2C19*2 polymorphism affected long-term prognosis of patients who were chronically treated with clopidogrel.Between April 1, 1996, and April 1, 2008, 259 young patients (aged <45 years) who survived a first myocardial infarction and were exposed to clopidogrel treatment for at least a month, were enrolled in a multicentre registry and underwent CYP2C19*2 determination. The primary endpoint was a composite of death, myocardial infarction, and urgent coronary revascularisation occurring during exposure to clopidogrel. Follow-up was every 6 months. The key secondary endpoint was stent thrombosis proven by angiography.Median clopidogrel exposure time was 1.07 years (IQR 0.28-3.0). Baseline characteristics were balanced between carriers (heterozygous *1/*2, n=64; homozygous *2/*2, n=9) and non-carriers (n=186) of CYP2C19*2 variant. The primary endpoint occurred more frequently in carriers than in non-carriers (15 vs 11 events; hazard ratio [HR] 3.69 [95% CI 1.69-8.05], p=0.0005), as did stent thrombosis (eight vs four events; HR 6.02 [1.81-20.04], p=0.0009). The detrimental effect of the CYP2C19*2 genetic variant persisted from 6 months after clopidogrel initiation up to the end of follow-up (HR 3.00 [1.27-7.10], p=0.009). After multivariable analysis, the CYP2C19*2 genetic variant was the only independent predictor of cardiovascular events (HR 4.04 [1.81-9.02], p=0.0006).The CYP2C19*2 genetic variant is a major determinant of prognosis in young patients who are receiving clopidogrel treatment after myocardial infarction.","Cytochrome P450 2C19 polymorphism in young patients treated with clopidogrel after myocardial infarction: a cohort study."
"1022","Lancet.1181","0.009",19108880,2008,"Clopidogrel and low-dose aspirin have become the mainstay oral antiplatelet regimen to prevent recurrent ischaemic events after acute coronary syndromes or stent placement. The frequent genetic functional variant 681 G>A (*2) of cytochrome P450 2C19 (CYP2C19) is an important contributor to the wide variability between individuals of the antiplatelet effect of clopidogrel. We assessed whether the CYP2C19*2 polymorphism affected long-term prognosis of patients who were chronically treated with clopidogrel.Between April 1, 1996, and April 1, 2008, 259 young patients (aged <45 years) who survived a first myocardial infarction and were exposed to clopidogrel treatment for at least a month, were enrolled in a multicentre registry and underwent CYP2C19*2 determination. The primary endpoint was a composite of death, myocardial infarction, and urgent coronary revascularisation occurring during exposure to clopidogrel. Follow-up was every 6 months. The key secondary endpoint was stent thrombosis proven by angiography.Median clopidogrel exposure time was 1.07 years (IQR 0.28-3.0). Baseline characteristics were balanced between carriers (heterozygous *1/*2, n=64; homozygous *2/*2, n=9) and non-carriers (n=186) of CYP2C19*2 variant. The primary endpoint occurred more frequently in carriers than in non-carriers (15 vs 11 events; hazard ratio [HR] 3.69 [95% CI 1.69-8.05], p=0.0005), as did stent thrombosis (eight vs four events; HR 6.02 [1.81-20.04], p=0.0009). The detrimental effect of the CYP2C19*2 genetic variant persisted from 6 months after clopidogrel initiation up to the end of follow-up (HR 3.00 [1.27-7.10], p=0.009). After multivariable analysis, the CYP2C19*2 genetic variant was the only independent predictor of cardiovascular events (HR 4.04 [1.81-9.02], p=0.0006).The CYP2C19*2 genetic variant is a major determinant of prognosis in young patients who are receiving clopidogrel treatment after myocardial infarction.","Cytochrome P450 2C19 polymorphism in young patients treated with clopidogrel after myocardial infarction: a cohort study."
"1023","Lancet.1191","6.00E-04",19108880,2008,"Clopidogrel and low-dose aspirin have become the mainstay oral antiplatelet regimen to prevent recurrent ischaemic events after acute coronary syndromes or stent placement. The frequent genetic functional variant 681 G>A (*2) of cytochrome P450 2C19 (CYP2C19) is an important contributor to the wide variability between individuals of the antiplatelet effect of clopidogrel. We assessed whether the CYP2C19*2 polymorphism affected long-term prognosis of patients who were chronically treated with clopidogrel.Between April 1, 1996, and April 1, 2008, 259 young patients (aged <45 years) who survived a first myocardial infarction and were exposed to clopidogrel treatment for at least a month, were enrolled in a multicentre registry and underwent CYP2C19*2 determination. The primary endpoint was a composite of death, myocardial infarction, and urgent coronary revascularisation occurring during exposure to clopidogrel. Follow-up was every 6 months. The key secondary endpoint was stent thrombosis proven by angiography.Median clopidogrel exposure time was 1.07 years (IQR 0.28-3.0). Baseline characteristics were balanced between carriers (heterozygous *1/*2, n=64; homozygous *2/*2, n=9) and non-carriers (n=186) of CYP2C19*2 variant. The primary endpoint occurred more frequently in carriers than in non-carriers (15 vs 11 events; hazard ratio [HR] 3.69 [95% CI 1.69-8.05], p=0.0005), as did stent thrombosis (eight vs four events; HR 6.02 [1.81-20.04], p=0.0009). The detrimental effect of the CYP2C19*2 genetic variant persisted from 6 months after clopidogrel initiation up to the end of follow-up (HR 3.00 [1.27-7.10], p=0.009). After multivariable analysis, the CYP2C19*2 genetic variant was the only independent predictor of cardiovascular events (HR 4.04 [1.81-9.02], p=0.0006).The CYP2C19*2 genetic variant is a major determinant of prognosis in young patients who are receiving clopidogrel treatment after myocardial infarction.","Cytochrome P450 2C19 polymorphism in young patients treated with clopidogrel after myocardial infarction: a cohort study."
"1024","BMJ.13","0.036",19147636,2009,"To evaluate benefits for postnatal women of two psychologically informed interventions by health visitors.Prospective cluster trial randomised by general practice, with 18 month follow-up.101 general practices in Trent, England.2749 women allocated to intervention, 1335 to control.Health visitors (n=89 63 clusters) were trained to identify depressive symptoms at six to eight weeks postnatally using the Edinburgh postnatal depression scale (EPDS) and clinical assessment and also trained in providing psychologically informed sessions based on cognitive behavioural or person centred principles for an hour a week for eight weeks. Health visitors in the control group (n=49 38 clusters) provided usual care.Score >or=12 on the Edinburgh postnatal depression scale at six months. Secondary outcomes were mean Edinburgh postnatal depression scale, clinical outcomes in routine evaluation-outcome measure (CORE-OM), state-trait anxiety inventory (STAI), SF-12, and parenting stress index short form (PSI-SF) scores at six, 12, 18 months.4084 eligible women consented and 595 women had a six week EPDS score >or=12. Of these, 418 had EPDS scores available at six weeks and six months. At six months, 34% women (93/271) in the intervention group and 46% (67/147) in the control group had an EPDS score >or=12. The odds ratio for score >or=12 at six months was 0.62 (95% confidence interval 0.40 to 0.97, P=0.036) for women in the intervention group compared with women in the control group. After adjustment for covariates, the odds ratio was 0.60 (0.38 to 0.95, P=0.028). At six months, 12.4% (234/1880) of all women in the intervention group and 16.7% (166/995) of all women in the control group had scores >or=12 (0.67, 0.51 to 0.87, P=0.003). Benefit for women in the intervention group with a six week EPDS score >or=12 and for all women was maintained at 12 months postnatally. There was no differential benefit for either psychological approach over the other.Training health visitors to assess women, identify symptoms of postnatal depression, and deliver psychologically informed sessions was clinically effective at six and 12 months postnatally compared with usual care.ISRCTN92195776.","Clinical effectiveness of health visitor training in psychologically informed approaches for depression in postnatal women: pragmatic cluster randomised trial in primary care."
"1025","BMJ.14","0.028",19147636,2009,"To evaluate benefits for postnatal women of two psychologically informed interventions by health visitors.Prospective cluster trial randomised by general practice, with 18 month follow-up.101 general practices in Trent, England.2749 women allocated to intervention, 1335 to control.Health visitors (n=89 63 clusters) were trained to identify depressive symptoms at six to eight weeks postnatally using the Edinburgh postnatal depression scale (EPDS) and clinical assessment and also trained in providing psychologically informed sessions based on cognitive behavioural or person centred principles for an hour a week for eight weeks. Health visitors in the control group (n=49 38 clusters) provided usual care.Score >or=12 on the Edinburgh postnatal depression scale at six months. Secondary outcomes were mean Edinburgh postnatal depression scale, clinical outcomes in routine evaluation-outcome measure (CORE-OM), state-trait anxiety inventory (STAI), SF-12, and parenting stress index short form (PSI-SF) scores at six, 12, 18 months.4084 eligible women consented and 595 women had a six week EPDS score >or=12. Of these, 418 had EPDS scores available at six weeks and six months. At six months, 34% women (93/271) in the intervention group and 46% (67/147) in the control group had an EPDS score >or=12. The odds ratio for score >or=12 at six months was 0.62 (95% confidence interval 0.40 to 0.97, P=0.036) for women in the intervention group compared with women in the control group. After adjustment for covariates, the odds ratio was 0.60 (0.38 to 0.95, P=0.028). At six months, 12.4% (234/1880) of all women in the intervention group and 16.7% (166/995) of all women in the control group had scores >or=12 (0.67, 0.51 to 0.87, P=0.003). Benefit for women in the intervention group with a six week EPDS score >or=12 and for all women was maintained at 12 months postnatally. There was no differential benefit for either psychological approach over the other.Training health visitors to assess women, identify symptoms of postnatal depression, and deliver psychologically informed sessions was clinically effective at six and 12 months postnatally compared with usual care.ISRCTN92195776.","Clinical effectiveness of health visitor training in psychologically informed approaches for depression in postnatal women: pragmatic cluster randomised trial in primary care."
"1026","BMJ.15","0.003",19147636,2009,"To evaluate benefits for postnatal women of two psychologically informed interventions by health visitors.Prospective cluster trial randomised by general practice, with 18 month follow-up.101 general practices in Trent, England.2749 women allocated to intervention, 1335 to control.Health visitors (n=89 63 clusters) were trained to identify depressive symptoms at six to eight weeks postnatally using the Edinburgh postnatal depression scale (EPDS) and clinical assessment and also trained in providing psychologically informed sessions based on cognitive behavioural or person centred principles for an hour a week for eight weeks. Health visitors in the control group (n=49 38 clusters) provided usual care.Score >or=12 on the Edinburgh postnatal depression scale at six months. Secondary outcomes were mean Edinburgh postnatal depression scale, clinical outcomes in routine evaluation-outcome measure (CORE-OM), state-trait anxiety inventory (STAI), SF-12, and parenting stress index short form (PSI-SF) scores at six, 12, 18 months.4084 eligible women consented and 595 women had a six week EPDS score >or=12. Of these, 418 had EPDS scores available at six weeks and six months. At six months, 34% women (93/271) in the intervention group and 46% (67/147) in the control group had an EPDS score >or=12. The odds ratio for score >or=12 at six months was 0.62 (95% confidence interval 0.40 to 0.97, P=0.036) for women in the intervention group compared with women in the control group. After adjustment for covariates, the odds ratio was 0.60 (0.38 to 0.95, P=0.028). At six months, 12.4% (234/1880) of all women in the intervention group and 16.7% (166/995) of all women in the control group had scores >or=12 (0.67, 0.51 to 0.87, P=0.003). Benefit for women in the intervention group with a six week EPDS score >or=12 and for all women was maintained at 12 months postnatally. There was no differential benefit for either psychological approach over the other.Training health visitors to assess women, identify symptoms of postnatal depression, and deliver psychologically informed sessions was clinically effective at six and 12 months postnatally compared with usual care.ISRCTN92195776.","Clinical effectiveness of health visitor training in psychologically informed approaches for depression in postnatal women: pragmatic cluster randomised trial in primary care."
"1027","JAMA.5591","0.39",19176440,2009,"It is uncertain whether intensified heart failure therapy guided by N-terminal brain natriuretic peptide (BNP) is superior to symptom-guided therapy.To compare 18-month outcomes of N-terminal BNP-guided vs symptom-guided heart failure therapy.Randomized controlled multicenter Trial of Intensified vs Standard Medical Therapy in Elderly Patients With Congestive Heart Failure (TIME-CHF) of 499 patients aged 60 years or older with systolic heart failure (ejection fraction < or = 45%), New York Heart Association (NYHA) class of II or greater, prior hospitalization for heart failure within 1 year, and N-terminal BNP level of 2 or more times the upper limit of normal. The study had an 18-month follow-up and it was conducted at 15 outpatient centers in Switzerland and Germany between January 2003 and June 2008.Uptitration of guideline-based treatments to reduce symptoms to NYHA class of II or less (symptom-guided therapy) and BNP level of 2 times or less the upper limit of normal and symptoms to NYHA class of II or less (BNP-guided therapy).Primary outcomes were 18-month survival free of all-cause hospitalizations and quality of life as assessed by structured validated questionnaires.Heart failure therapy guided by N-terminal BNP and symptom-guided therapy resulted in similar rates of survival free of all-cause hospitalizations (41% vs 40%, respectively; hazard ratio [HR], 0.91 [95% CI, 0.72-1.14]; P = .39). Patients' quality-of-life metrics improved over 18 months of follow-up but these improvements were similar in both the N-terminal BNP-guided and symptom-guided strategies. Compared with the symptom-guided group, survival free of hospitalization for heart failure, a secondary end point, was higher among those in the N-terminal BNP-guided group (72% vs 62%, respectively; HR, 0.68 [95% CI, 0.50-0.92]; P = .01). Heart failure therapy guided by N-terminal BNP improved outcomes in patients aged 60 to 75 years but not in those aged 75 years or older (P < .02 for interaction)Heart failure therapy guided by N-terminal BNP did not improve overall clinical outcomes or quality of life compared with symptom-guided treatment.isrctn.org Identifier: ISRCTN43596477.","BNP-guided vs symptom-guided heart failure therapy: the Trial of Intensified vs Standard Medical Therapy in Elderly Patients With Congestive Heart Failure (TIME-CHF) randomized trial."
"1028","JAMA.5601","0.01",19176440,2009,"It is uncertain whether intensified heart failure therapy guided by N-terminal brain natriuretic peptide (BNP) is superior to symptom-guided therapy.To compare 18-month outcomes of N-terminal BNP-guided vs symptom-guided heart failure therapy.Randomized controlled multicenter Trial of Intensified vs Standard Medical Therapy in Elderly Patients With Congestive Heart Failure (TIME-CHF) of 499 patients aged 60 years or older with systolic heart failure (ejection fraction < or = 45%), New York Heart Association (NYHA) class of II or greater, prior hospitalization for heart failure within 1 year, and N-terminal BNP level of 2 or more times the upper limit of normal. The study had an 18-month follow-up and it was conducted at 15 outpatient centers in Switzerland and Germany between January 2003 and June 2008.Uptitration of guideline-based treatments to reduce symptoms to NYHA class of II or less (symptom-guided therapy) and BNP level of 2 times or less the upper limit of normal and symptoms to NYHA class of II or less (BNP-guided therapy).Primary outcomes were 18-month survival free of all-cause hospitalizations and quality of life as assessed by structured validated questionnaires.Heart failure therapy guided by N-terminal BNP and symptom-guided therapy resulted in similar rates of survival free of all-cause hospitalizations (41% vs 40%, respectively; hazard ratio [HR], 0.91 [95% CI, 0.72-1.14]; P = .39). Patients' quality-of-life metrics improved over 18 months of follow-up but these improvements were similar in both the N-terminal BNP-guided and symptom-guided strategies. Compared with the symptom-guided group, survival free of hospitalization for heart failure, a secondary end point, was higher among those in the N-terminal BNP-guided group (72% vs 62%, respectively; HR, 0.68 [95% CI, 0.50-0.92]; P = .01). Heart failure therapy guided by N-terminal BNP improved outcomes in patients aged 60 to 75 years but not in those aged 75 years or older (P < .02 for interaction)Heart failure therapy guided by N-terminal BNP did not improve overall clinical outcomes or quality of life compared with symptom-guided treatment.isrctn.org Identifier: ISRCTN43596477.","BNP-guided vs symptom-guided heart failure therapy: the Trial of Intensified vs Standard Medical Therapy in Elderly Patients With Congestive Heart Failure (TIME-CHF) randomized trial."
"1029","Lancet.116","1.00E-04",19231632,2009,"Eltrombopag is an oral, non-peptide, thrombopoietin-receptor agonist that stimulates thrombopoiesis, leading to increased platelet production. This study assessed the efficacy, safety, and tolerability of once daily eltrombopag 50 mg, and explored the efficacy of a dose increase to 75 mg.In this phase III, randomised, double-blind, placebo-controlled study, adults from 63 sites in 23 countries with chronic idiopathic thrombocytopenic purpura (ITP), platelet counts less than 30 000 per muL of blood, and one or more previous ITP treatment received standard care plus once-daily eltrombopag 50 mg (n=76) or placebo (n=38) for up to 6 weeks. Patients were randomly assigned in a 2:1 ratio of eltrombopag:placebo by a validated randomisation system. After 3 weeks, patients with platelet counts less than 50 000 per microL could increase study drug to 75 mg. The primary endpoint was the proportion of patients achieving platelet counts 50 000 per microL or more at day 43. All participants who received at least one dose of their allocated treatment were included in the analysis. This study is registered with ClinicalTrials.gov, number NCT00102739.73 patients in the eltrombopag group and 37 in the placebo group were included in the efficacy population and were evaluable for day-43 analyses. 43 (59%) eltrombopag patients and six (16%) placebo patients responded (ie, achieved platelet counts >/=50 000 per microL; odds ratio [OR] 9.61 [95% CI 3.31-27.86]; p<0.0001). Response to eltrombopag compared with placebo was not affected by predefined study stratification variables (baseline platelet counts, concomitant ITP drugs, and splenectomy status) or by the number of previous ITP treatments. Of the 34 patients in the efficacy analysis who increased their dose of eltrombopag, ten (29%) responded. Platelet counts generally returned to baseline values within 2 weeks after the end of treatment. Patients receiving eltrombopag had less bleeding at any time during the study than did those receiving placebo (OR 0.49 [95% CI 0.26-0.89]; p=0.021). The frequency of grade 3-4 adverse events during treatment (eltrombopag, two [3%]; placebo, one [3%]) and adverse events leading to study discontinuation (eltrombopag, three [4%]; placebo, two [5%]), were similar in both groups.Eltrombopag is an effective treatment for managment of thrombocytopenia in chronic ITP.","Effect of eltrombopag on platelet counts and bleeding during treatment of chronic idiopathic thrombocytopenic purpura: a randomised, double-blind, placebo-controlled trial."
"1030","Lancet.128","0.021",19231632,2009,"Eltrombopag is an oral, non-peptide, thrombopoietin-receptor agonist that stimulates thrombopoiesis, leading to increased platelet production. This study assessed the efficacy, safety, and tolerability of once daily eltrombopag 50 mg, and explored the efficacy of a dose increase to 75 mg.In this phase III, randomised, double-blind, placebo-controlled study, adults from 63 sites in 23 countries with chronic idiopathic thrombocytopenic purpura (ITP), platelet counts less than 30 000 per muL of blood, and one or more previous ITP treatment received standard care plus once-daily eltrombopag 50 mg (n=76) or placebo (n=38) for up to 6 weeks. Patients were randomly assigned in a 2:1 ratio of eltrombopag:placebo by a validated randomisation system. After 3 weeks, patients with platelet counts less than 50 000 per microL could increase study drug to 75 mg. The primary endpoint was the proportion of patients achieving platelet counts 50 000 per microL or more at day 43. All participants who received at least one dose of their allocated treatment were included in the analysis. This study is registered with ClinicalTrials.gov, number NCT00102739.73 patients in the eltrombopag group and 37 in the placebo group were included in the efficacy population and were evaluable for day-43 analyses. 43 (59%) eltrombopag patients and six (16%) placebo patients responded (ie, achieved platelet counts >/=50 000 per microL; odds ratio [OR] 9.61 [95% CI 3.31-27.86]; p<0.0001). Response to eltrombopag compared with placebo was not affected by predefined study stratification variables (baseline platelet counts, concomitant ITP drugs, and splenectomy status) or by the number of previous ITP treatments. Of the 34 patients in the efficacy analysis who increased their dose of eltrombopag, ten (29%) responded. Platelet counts generally returned to baseline values within 2 weeks after the end of treatment. Patients receiving eltrombopag had less bleeding at any time during the study than did those receiving placebo (OR 0.49 [95% CI 0.26-0.89]; p=0.021). The frequency of grade 3-4 adverse events during treatment (eltrombopag, two [3%]; placebo, one [3%]) and adverse events leading to study discontinuation (eltrombopag, three [4%]; placebo, two [5%]), were similar in both groups.Eltrombopag is an effective treatment for managment of thrombocytopenia in chronic ITP.","Effect of eltrombopag on platelet counts and bleeding during treatment of chronic idiopathic thrombocytopenic purpura: a randomised, double-blind, placebo-controlled trial."
"1031","Lancet.182","1.00E-04",19269519,2009,"Preoperative or postoperative radiotherapy reduces the risk of local recurrence in patients with operable rectal cancer. However, improvements in surgery and histopathological assessment mean that the role of radiotherapy needs to be reassessed. We compared short-course preoperative radiotherapy versus initial surgery with selective postoperative chemoradiotherapy.We undertook a randomised trial in 80 centres in four countries. 1350 patients with operable adenocarcinoma of the rectum were randomly assigned, by a minimisation procedure, to short-course preoperative radiotherapy (25 Gy in five fractions; n=674) or to initial surgery with selective postoperative chemoradiotherapy (45 Gy in 25 fractions with concurrent 5-fluorouracil) restricted to patients with involvement of the circumferential resection margin (n=676). The primary outcome measure was local recurrence. Analysis was by intention to treat. This study is registered, number ISRCTN 28785842.At the time of analysis, which included all participants, 330 patients had died (157 preoperative radiotherapy group vs 173 selective postoperative chemoradiotherapy), and median follow-up of surviving patients was 4 years. 99 patients had developed local recurrence (27 preoperative radiotherapy vs 72 selective postoperative chemoradiotherapy). We noted a reduction of 61% in the relative risk of local recurrence for patients receiving preoperative radiotherapy (hazard ratio [HR] 0.39, 95% CI 0.27-0.58, p<0.0001), and an absolute difference at 3 years of 6.2% (95% CI 5.3-7.1) (4.4% preoperative radiotherapy vs 10.6% selective postoperative chemoradiotherapy). We recorded a relative improvement in disease-free survival of 24% for patients receiving preoperative radiotherapy (HR 0.76, 95% CI 0.62-0.94, p=0.013), and an absolute difference at 3 years of 6.0% (95% CI 5.3-6.8) (77.5%vs 71.5%). Overall survival did not differ between the groups (HR 0.91, 95% CI 0.73-1.13, p=0.40).Taken with results from other randomised trials, our findings provide convincing and consistent evidence that short-course preoperative radiotherapy is an effective treatment for patients with operable rectal cancer.","Preoperative radiotherapy versus selective postoperative chemoradiotherapy in patients with rectal cancer (MRC CR07 and NCIC-CTG C016): a multicentre, randomised trial."
"1032","Lancet.225","0.013",19269519,2009,"Preoperative or postoperative radiotherapy reduces the risk of local recurrence in patients with operable rectal cancer. However, improvements in surgery and histopathological assessment mean that the role of radiotherapy needs to be reassessed. We compared short-course preoperative radiotherapy versus initial surgery with selective postoperative chemoradiotherapy.We undertook a randomised trial in 80 centres in four countries. 1350 patients with operable adenocarcinoma of the rectum were randomly assigned, by a minimisation procedure, to short-course preoperative radiotherapy (25 Gy in five fractions; n=674) or to initial surgery with selective postoperative chemoradiotherapy (45 Gy in 25 fractions with concurrent 5-fluorouracil) restricted to patients with involvement of the circumferential resection margin (n=676). The primary outcome measure was local recurrence. Analysis was by intention to treat. This study is registered, number ISRCTN 28785842.At the time of analysis, which included all participants, 330 patients had died (157 preoperative radiotherapy group vs 173 selective postoperative chemoradiotherapy), and median follow-up of surviving patients was 4 years. 99 patients had developed local recurrence (27 preoperative radiotherapy vs 72 selective postoperative chemoradiotherapy). We noted a reduction of 61% in the relative risk of local recurrence for patients receiving preoperative radiotherapy (hazard ratio [HR] 0.39, 95% CI 0.27-0.58, p<0.0001), and an absolute difference at 3 years of 6.2% (95% CI 5.3-7.1) (4.4% preoperative radiotherapy vs 10.6% selective postoperative chemoradiotherapy). We recorded a relative improvement in disease-free survival of 24% for patients receiving preoperative radiotherapy (HR 0.76, 95% CI 0.62-0.94, p=0.013), and an absolute difference at 3 years of 6.0% (95% CI 5.3-6.8) (77.5%vs 71.5%). Overall survival did not differ between the groups (HR 0.91, 95% CI 0.73-1.13, p=0.40).Taken with results from other randomised trials, our findings provide convincing and consistent evidence that short-course preoperative radiotherapy is an effective treatment for patients with operable rectal cancer.","Preoperative radiotherapy versus selective postoperative chemoradiotherapy in patients with rectal cancer (MRC CR07 and NCIC-CTG C016): a multicentre, randomised trial."
"1033","Lancet.226","0.4",19269519,2009,"Preoperative or postoperative radiotherapy reduces the risk of local recurrence in patients with operable rectal cancer. However, improvements in surgery and histopathological assessment mean that the role of radiotherapy needs to be reassessed. We compared short-course preoperative radiotherapy versus initial surgery with selective postoperative chemoradiotherapy.We undertook a randomised trial in 80 centres in four countries. 1350 patients with operable adenocarcinoma of the rectum were randomly assigned, by a minimisation procedure, to short-course preoperative radiotherapy (25 Gy in five fractions; n=674) or to initial surgery with selective postoperative chemoradiotherapy (45 Gy in 25 fractions with concurrent 5-fluorouracil) restricted to patients with involvement of the circumferential resection margin (n=676). The primary outcome measure was local recurrence. Analysis was by intention to treat. This study is registered, number ISRCTN 28785842.At the time of analysis, which included all participants, 330 patients had died (157 preoperative radiotherapy group vs 173 selective postoperative chemoradiotherapy), and median follow-up of surviving patients was 4 years. 99 patients had developed local recurrence (27 preoperative radiotherapy vs 72 selective postoperative chemoradiotherapy). We noted a reduction of 61% in the relative risk of local recurrence for patients receiving preoperative radiotherapy (hazard ratio [HR] 0.39, 95% CI 0.27-0.58, p<0.0001), and an absolute difference at 3 years of 6.2% (95% CI 5.3-7.1) (4.4% preoperative radiotherapy vs 10.6% selective postoperative chemoradiotherapy). We recorded a relative improvement in disease-free survival of 24% for patients receiving preoperative radiotherapy (HR 0.76, 95% CI 0.62-0.94, p=0.013), and an absolute difference at 3 years of 6.0% (95% CI 5.3-6.8) (77.5%vs 71.5%). Overall survival did not differ between the groups (HR 0.91, 95% CI 0.73-1.13, p=0.40).Taken with results from other randomised trials, our findings provide convincing and consistent evidence that short-course preoperative radiotherapy is an effective treatment for patients with operable rectal cancer.","Preoperative radiotherapy versus selective postoperative chemoradiotherapy in patients with rectal cancer (MRC CR07 and NCIC-CTG C016): a multicentre, randomised trial."
"1034","Lancet.223","0.0011",19269520,2009,"Local recurrence rates in operable rectal cancer are improved by radiotherapy (with or without chemotherapy) and surgical techniques such as total mesorectal excision. However, the contributions of surgery and radiotherapy to outcomes are unclear. We assessed the effect of the involvement of the circumferential resection margin and the plane of surgery achieved.In this prospective study, the plane of surgery achieved and the involvement of the circumferential resection margin were assessed by local pathologists, using a standard pathological protocol in 1156 patients with operable rectal cancer from the CR07 and NCIC-CTG CO16 trial, which compared short-course (5 days) preoperative radiotherapy and selective postoperative chemoradiotherapy, between March, 1998, and August, 2005. All analyses were by intention to treat. This trial is registered, number ISRCTN 28785842.128 patients (11%) had involvement of the circumferential resection margin, and the plane of surgery achieved was classified as good (mesorectal) in 604 (52%), intermediate (intramesorectal) in 398 (34%), and poor (muscularis propria plane) in 154 (13%). We found that both a negative circumferential resection margin and a superior plane of surgery achieved were associated with low local recurrence rates. Hazard ratio (HR) was 0.32 (95% CI 0.16-0.63, p=0.0011) with 3-year local recurrence rates of 6% (5-8%) and 17% (10-26%) for patients who were negative and positive for circumferential resection margin, respectively. For plane of surgery achieved, HRs for mesorectal and intramesorectal groups compared with the muscularis propria group were 0.32 (0.16-0.64) and 0.48 (0.25-0.93), respectively. At 3 years, the estimated local recurrence rates were 4% (3-6%) for mesorectal, 7% (5-11%) for intramesorectal, and 13% (8-21%) for muscularis propria groups. The benefit of short-course preoperative radiotherapy did not differ in the three plane of surgery groups (p=0.30 for trend). Patients in the short-course preoperative radiotherapy group who had a resection in the mesorectal plane had a 3-year local recurrence rate of only 1%.In rectal cancer, the plane of surgery achieved is an important prognostic factor for local recurrence. Short-course preoperative radiotherapy reduced the rate of local recurrence for all three plane of surgery groups, almost abolishing local recurrence in short-course preoperative radiotherapy patients who had a resection in the mesorectal plane. The plane of surgery achieved should therefore be assessed and reported routinely.","Effect of the plane of surgery achieved on local recurrence in patients with operable rectal cancer: a prospective study using data from the MRC CR07 and NCIC-CTG CO16 randomised clinical trial."
"1035","JAMA.537","0.04",19293414,2009,"Patients frequently rely on religious faith to cope with cancer, but little is known about the associations between religious coping and the use of intensive life-prolonging care at the end of life.To determine the way religious coping relates to the use of intensive life-prolonging end-of-life care among patients with advanced cancer.A US multisite, prospective, longitudinal cohort of 345 patients with advanced cancer, who were enrolled between January 1, 2003, and August 31, 2007. The Brief RCOPE assessed positive religious coping. Baseline interviews assessed psychosocial and religious/spiritual measures, advance care planning, and end-of-life treatment preferences. Patients were followed up until death, a median of 122 days after baseline assessment.Intensive life-prolonging care, defined as receipt of mechanical ventilation or resuscitation in the last week of life. Analyses were adjusted for demographic factors significantly associated with positive religious coping and any end-of-life outcome at P < .05 (ie, age and race/ethnicity). The main outcome was further adjusted for potential psychosocial confounders (eg, other coping styles, terminal illness acknowledgment, spiritual support, preference for heroics, and advance care planning).A high level of positive religious coping at baseline was significantly associated with receipt of mechanical ventilation compared with patients with a low level (11.3% vs 3.6%; adjusted odds ratio [AOR], 2.81 [95% confidence interval {CI}, 1.03-7.69]; P = .04) and intensive life-prolonging care during the last week of life (13.6% vs 4.2%; AOR, 2.90 [95% CI, 1.14-7.35]; P = .03) after adjusting for age and race. In the model that further adjusted for other coping styles, terminal illness acknowledgment, support of spiritual needs, preference for heroics, and advance care planning (do-not-resuscitate order, living will, and health care proxy/durable power of attorney), positive religious coping remained a significant predictor of receiving intensive life-prolonging care near death (AOR, 2.90 [95% CI, 1.07-7.89]; P = .04).Positive religious coping in patients with advanced cancer is associated with receipt of intensive life-prolonging medical care near death. Further research is needed to determine the mechanisms for this association.","Religious coping and use of intensive life-prolonging care near death in patients with advanced cancer."
"1036","JAMA.538","0.03",19293414,2009,"Patients frequently rely on religious faith to cope with cancer, but little is known about the associations between religious coping and the use of intensive life-prolonging care at the end of life.To determine the way religious coping relates to the use of intensive life-prolonging end-of-life care among patients with advanced cancer.A US multisite, prospective, longitudinal cohort of 345 patients with advanced cancer, who were enrolled between January 1, 2003, and August 31, 2007. The Brief RCOPE assessed positive religious coping. Baseline interviews assessed psychosocial and religious/spiritual measures, advance care planning, and end-of-life treatment preferences. Patients were followed up until death, a median of 122 days after baseline assessment.Intensive life-prolonging care, defined as receipt of mechanical ventilation or resuscitation in the last week of life. Analyses were adjusted for demographic factors significantly associated with positive religious coping and any end-of-life outcome at P < .05 (ie, age and race/ethnicity). The main outcome was further adjusted for potential psychosocial confounders (eg, other coping styles, terminal illness acknowledgment, spiritual support, preference for heroics, and advance care planning).A high level of positive religious coping at baseline was significantly associated with receipt of mechanical ventilation compared with patients with a low level (11.3% vs 3.6%; adjusted odds ratio [AOR], 2.81 [95% confidence interval {CI}, 1.03-7.69]; P = .04) and intensive life-prolonging care during the last week of life (13.6% vs 4.2%; AOR, 2.90 [95% CI, 1.14-7.35]; P = .03) after adjusting for age and race. In the model that further adjusted for other coping styles, terminal illness acknowledgment, support of spiritual needs, preference for heroics, and advance care planning (do-not-resuscitate order, living will, and health care proxy/durable power of attorney), positive religious coping remained a significant predictor of receiving intensive life-prolonging care near death (AOR, 2.90 [95% CI, 1.07-7.89]; P = .04).Positive religious coping in patients with advanced cancer is associated with receipt of intensive life-prolonging medical care near death. Further research is needed to determine the mechanisms for this association.","Religious coping and use of intensive life-prolonging care near death in patients with advanced cancer."
"1037","JAMA.539","0.04",19293414,2009,"Patients frequently rely on religious faith to cope with cancer, but little is known about the associations between religious coping and the use of intensive life-prolonging care at the end of life.To determine the way religious coping relates to the use of intensive life-prolonging end-of-life care among patients with advanced cancer.A US multisite, prospective, longitudinal cohort of 345 patients with advanced cancer, who were enrolled between January 1, 2003, and August 31, 2007. The Brief RCOPE assessed positive religious coping. Baseline interviews assessed psychosocial and religious/spiritual measures, advance care planning, and end-of-life treatment preferences. Patients were followed up until death, a median of 122 days after baseline assessment.Intensive life-prolonging care, defined as receipt of mechanical ventilation or resuscitation in the last week of life. Analyses were adjusted for demographic factors significantly associated with positive religious coping and any end-of-life outcome at P < .05 (ie, age and race/ethnicity). The main outcome was further adjusted for potential psychosocial confounders (eg, other coping styles, terminal illness acknowledgment, spiritual support, preference for heroics, and advance care planning).A high level of positive religious coping at baseline was significantly associated with receipt of mechanical ventilation compared with patients with a low level (11.3% vs 3.6%; adjusted odds ratio [AOR], 2.81 [95% confidence interval {CI}, 1.03-7.69]; P = .04) and intensive life-prolonging care during the last week of life (13.6% vs 4.2%; AOR, 2.90 [95% CI, 1.14-7.35]; P = .03) after adjusting for age and race. In the model that further adjusted for other coping styles, terminal illness acknowledgment, support of spiritual needs, preference for heroics, and advance care planning (do-not-resuscitate order, living will, and health care proxy/durable power of attorney), positive religious coping remained a significant predictor of receiving intensive life-prolonging care near death (AOR, 2.90 [95% CI, 1.07-7.89]; P = .04).Positive religious coping in patients with advanced cancer is associated with receipt of intensive life-prolonging medical care near death. Further research is needed to determine the mechanisms for this association.","Religious coping and use of intensive life-prolonging care near death in patients with advanced cancer."
"1038","Lancet.181","1.00E-04",19303137,2009,"Gastrointestinal stromal tumour is the most common sarcoma of the intestinal tract. Imatinib mesylate is a small molecule that inhibits activation of the KIT and platelet-derived growth factor receptor alpha proteins, and is effective in first-line treatment of metastatic gastrointestinal stromal tumour. We postulated that adjuvant treatment with imatinib would improve recurrence-free survival compared with placebo after resection of localised, primary gastrointestinal stromal tumour.We undertook a randomised phase III, double-blind, placebo-controlled, multicentre trial. Eligible patients had complete gross resection of a primary gastrointestinal stromal tumour at least 3 cm in size and positive for the KIT protein by immunohistochemistry. Patients were randomly assigned, by a stratified biased coin design, to imatinib 400 mg (n=359) or to placebo (n=354) daily for 1 year after surgical resection. Patients and investigators were blinded to the treatment group. Patients assigned to placebo were eligible to crossover to imatinib treatment in the event of tumour recurrence. The primary endpoint was recurrence-free survival, and analysis was by intention to treat. Accrual was stopped early because the trial results crossed the interim analysis efficacy boundary for recurrence-free survival. This study is registered with ClinicalTrials.gov, number NCT00041197.All randomised patients were included in the analysis. At median follow-up of 19.7 months (minimum-maximum 0-56.4), 30 (8%) patients in the imatinib group and 70 (20%) in the placebo group had had tumour recurrence or had died. Imatinib significantly improved recurrence-free survival compared with placebo (98% [95% CI 96-100] vs 83% [78-88] at 1 year; hazard ratio [HR] 0.35 [0.22-0.53]; one-sided p<0.0001). Adjuvant imatinib was well tolerated, with the most common serious events being dermatitis (11 [3%] vs 0), abdominal pain (12 [3%] vs six [1%]), and diarrhoea (ten [2%] vs five [1%]) in the imatinib group and hyperglycaemia (two [<1%] vs seven [2%]) in the placebo group.Adjuvant imatinib therapy is safe and seems to improve recurrence-free survival compared with placebo after the resection of primary gastrointestinal stromal tumour.US National Institutes of Health and Novartis Pharmaceuticals.","Adjuvant imatinib mesylate after resection of localised, primary gastrointestinal stromal tumour: a randomised, double-blind, placebo-controlled trial."
"1039","Lancet.220","0.12",19303634,2009,"Coronary artery bypass graft (CABG) and percutaneous coronary intervention (PCI) are alternative treatments for multivessel coronary disease. Although the procedures have been compared in several randomised trials, their long-term effects on mortality in key clinical subgroups are uncertain. We undertook a collaborative analysis of data from randomised trials to assess whether the effects of the procedures on mortality are modified by patient characteristics.We pooled individual patient data from ten randomised trials to compare the effectiveness of CABG with PCI according to patients' baseline clinical characteristics. We used stratified, random effects Cox proportional hazards models to test the effect on all-cause mortality of randomised treatment assignment and its interaction with clinical characteristics. All analyses were by intention to treat.Ten participating trials provided data on 7812 patients. PCI was done with balloon angioplasty in six trials and with bare-metal stents in four trials. Over a median follow-up of 5.9 years (IQR 5.0-10.0), 575 (15%) of 3889 patients assigned to CABG died compared with 628 (16%) of 3923 patients assigned to PCI (hazard ratio [HR] 0.91, 95% CI 0.82-1.02; p=0.12). In patients with diabetes (CABG, n=615; PCI, n=618), mortality was substantially lower in the CABG group than in the PCI group (HR 0.70, 0.56-0.87); however, mortality was similar between groups in patients without diabetes (HR 0.98, 0.86-1.12; p=0.014 for interaction). Patient age modified the effect of treatment on mortality, with hazard ratios of 1.25 (0.94-1.66) in patients younger than 55 years, 0.90 (0.75-1.09) in patients aged 55-64 years, and 0.82 (0.70-0.97) in patients 65 years and older (p=0.002 for interaction). Treatment effect was not modified by the number of diseased vessels or other baseline characteristics.Long-term mortality is similar after CABG and PCI in most patient subgroups with multivessel coronary artery disease, so choice of treatment should depend on patient preferences for other outcomes. CABG might be a better option for patients with diabetes and patients aged 65 years or older because we found mortality to be lower in these subgroups.","Coronary artery bypass surgery compared with percutaneous coronary interventions for multivessel disease: a collaborative analysis of individual patient data from ten randomised trials."
"1040","Lancet.221","0.014",19303634,2009,"Coronary artery bypass graft (CABG) and percutaneous coronary intervention (PCI) are alternative treatments for multivessel coronary disease. Although the procedures have been compared in several randomised trials, their long-term effects on mortality in key clinical subgroups are uncertain. We undertook a collaborative analysis of data from randomised trials to assess whether the effects of the procedures on mortality are modified by patient characteristics.We pooled individual patient data from ten randomised trials to compare the effectiveness of CABG with PCI according to patients' baseline clinical characteristics. We used stratified, random effects Cox proportional hazards models to test the effect on all-cause mortality of randomised treatment assignment and its interaction with clinical characteristics. All analyses were by intention to treat.Ten participating trials provided data on 7812 patients. PCI was done with balloon angioplasty in six trials and with bare-metal stents in four trials. Over a median follow-up of 5.9 years (IQR 5.0-10.0), 575 (15%) of 3889 patients assigned to CABG died compared with 628 (16%) of 3923 patients assigned to PCI (hazard ratio [HR] 0.91, 95% CI 0.82-1.02; p=0.12). In patients with diabetes (CABG, n=615; PCI, n=618), mortality was substantially lower in the CABG group than in the PCI group (HR 0.70, 0.56-0.87); however, mortality was similar between groups in patients without diabetes (HR 0.98, 0.86-1.12; p=0.014 for interaction). Patient age modified the effect of treatment on mortality, with hazard ratios of 1.25 (0.94-1.66) in patients younger than 55 years, 0.90 (0.75-1.09) in patients aged 55-64 years, and 0.82 (0.70-0.97) in patients 65 years and older (p=0.002 for interaction). Treatment effect was not modified by the number of diseased vessels or other baseline characteristics.Long-term mortality is similar after CABG and PCI in most patient subgroups with multivessel coronary artery disease, so choice of treatment should depend on patient preferences for other outcomes. CABG might be a better option for patients with diabetes and patients aged 65 years or older because we found mortality to be lower in these subgroups.","Coronary artery bypass surgery compared with percutaneous coronary interventions for multivessel disease: a collaborative analysis of individual patient data from ten randomised trials."
"1041","JAMA.5581","0.03",19318651,2009,"Use of a chlorhexidine gluconate-impregnated sponge (CHGIS) in intravascular catheter dressings may reduce catheter-related infections (CRIs). Changing catheter dressings every 3 days may be more frequent than necessary.To assess superiority of CHGIS dressings regarding the rate of major CRIs (clinical sepsis with or without bloodstream infection) and noninferiority (less than 3% colonization-rate increase) of 7-day vs 3-day dressing changes.Assessor-blind, 2 x 2 factorial, randomized controlled trial conducted from December 2006 through June 2008 and recruiting patients from 7 intensive care units in 3 university and 2 general hospitals in France. Patients were adults (>18 years) expected to require an arterial catheter, central-vein catheter, or both inserted for 48 hours or longer.Use of CHGIS vs standard dressings (controls). Scheduled change of unsoiled adherent dressings every 3 vs every 7 days, with immediate change of any soiled or leaking dressings.Major CRIs for comparison of CHGIS vs control dressings; colonization rate for comparison of 3- vs 7-day dressing changes.Of 2095 eligible patients, 1636 (3778 catheters, 28,931 catheter-days) could be evaluated. The median duration of catheter insertion was 6 (interquartile range [IQR], 4-10) days. There was no interaction between the interventions. Use of CHGIS dressings decreased the rates of major CRIs (10/1953 [0.5%], 0.6 per 1000 catheter-days vs 19/1825 [1.1%], 1.4 per 1000 catheter-days; hazard ratio [HR], 0.39 [95% confidence interval {CI}, 0.17-0.93]; P = .03) and catheter-related bloodstream infections (6/1953 catheters, 0.40 per 1000 catheter-days vs 17/1825 catheters, 1.3 per 1000 catheter-days; HR, 0.24 [95% CI, 0.09-0.65]). Use of CHGIS dressings was not associated with greater resistance of bacteria in skin samples at catheter removal. Severe CHGIS-associated contact dermatitis occurred in 8 patients (5.3 per 1000 catheters). Use of CHGIS dressings prevented 1 major CRI per 117 catheters. Catheter colonization rates were 142 of 1657 catheters (7.8%) in the 3-day group (10.4 per 1000 catheter-days) and 168 of 1828 catheters (8.6%) in the 7-day group (11.0 per 1000 catheter-days), a mean absolute difference of 0.8% (95% CI, -1.78% to 2.15%) (HR, 0.99; 95% CI, 0.77-1.28), indicating noninferiority of 7-day changes. The median number of dressing changes per catheter was 4 (IQR, 3-6) in the 3-day group and 3 (IQR, 2-5) in the 7-day group (P < .001).Use of CHGIS dressings with intravascular catheters in the intensive care unit reduced risk of infection even when background infection rates were low. Reducing the frequency of changing unsoiled adherent dressings from every 3 days to every 7 days modestly reduces the total number of dressing changes and appears safe.clinicaltrials.gov Identifier: NCT00417235.","Chlorhexidine-impregnated sponges and less frequent dressing changes for prevention of catheter-related infections in critically ill adults: a randomized controlled trial."
"1042","Lancet.179","1.00E-04",19329177,2009,"Statins lower high-sensitivity C-reactive protein (hsCRP) and cholesterol concentrations, and hypothesis generating analyses suggest that clinical outcomes improve in patients given statins who achieve hsCRP concentrations less than 2 mg/L in addition to LDL cholesterol less than 1.8 mmol/L (<70 mg/dL). However, the benefit of lowering both LDL cholesterol and hsCRP after the start of statin therapy is controversial. We prospectively tested this hypothesis.In an analysis of 15 548 initially healthy men and women participating in the JUPITER trial (87% of full cohort), we prospectively assessed the effects of rosuvastatin 20 mg versus placebo on rates of non-fatal myocardial infarction, non-fatal stroke, admission for unstable angina, arterial revascularisation, or cardiovascular death (prespecified endpoints) during a maximum follow-up of 5 years (median 1.9 years), according to on-treatment concentrations of LDL cholesterol (>/=1.8 mmol/L or <1.8 mmol/L) and hsCRP (>/=2 mg/L or <2 mg/L). We included all events occurring after randomisation. This trial is registered with ClinicalTrials.gov, number NCT00239681.Compared with placebo, participants allocated to rosuvastatin who achieved LDL cholesterol less than 1.8 mmol/L had a 55% reduction in vascular events (event rate 1.11 vs 0.51 per 100 person-years; hazard ratio [HR] 0.45, 95% CI 0.34-0.60, p<0.0001), and those achieving hsCRP less than 2 mg/L a 62% reduction (event rate 0.42 per 100 person-years; HR 0.38, 95% CI 0.26-0.56, p<0.0001). Although LDL cholesterol and hsCRP reductions were only weakly correlated in individual patients (r values <0.15), we recorded a 65% reduction in vascular events in participants allocated to rosuvastatin who achieved both LDL cholesterol less than 1.8 mmol/L and hsCRP less than 2 mg/L (event rate 0.38 per 100 person-years; adjusted HR 0.35, 95% CI 0.23-0.54), versus a 33% reduction in those who achieved one or neither target (event rate 0.74 per 100 person-years; HR 0.67, 95% CI 0.52-0.87) (p across treatment groups <0.0001). In participants who achieved LDL cholesterol less than 1.8 mmol/L and hsCRP less than 1 mg/L, we noted a 79% reduction (event rate 0.24 per 100 person-years; HR 0.21, 95% CI 0.09-0.52). Achieved hsCRP concentrations were predictive of event rates irrespective of the lipid endpoint used, including the apolipoprotein B to apolipoprotein AI ratio.For people choosing to start pharmacological prophylaxis, reduction in both LDL cholesterol and hsCRP are indicators of successful treatment with rosuvastatin.","Reduction in C-reactive protein and LDL cholesterol and cardiovascular event rates after initiation of rosuvastatin: a prospective study of the JUPITER trial."
"1043","Lancet.180","1.00E-04",19329177,2009,"Statins lower high-sensitivity C-reactive protein (hsCRP) and cholesterol concentrations, and hypothesis generating analyses suggest that clinical outcomes improve in patients given statins who achieve hsCRP concentrations less than 2 mg/L in addition to LDL cholesterol less than 1.8 mmol/L (<70 mg/dL). However, the benefit of lowering both LDL cholesterol and hsCRP after the start of statin therapy is controversial. We prospectively tested this hypothesis.In an analysis of 15 548 initially healthy men and women participating in the JUPITER trial (87% of full cohort), we prospectively assessed the effects of rosuvastatin 20 mg versus placebo on rates of non-fatal myocardial infarction, non-fatal stroke, admission for unstable angina, arterial revascularisation, or cardiovascular death (prespecified endpoints) during a maximum follow-up of 5 years (median 1.9 years), according to on-treatment concentrations of LDL cholesterol (>/=1.8 mmol/L or <1.8 mmol/L) and hsCRP (>/=2 mg/L or <2 mg/L). We included all events occurring after randomisation. This trial is registered with ClinicalTrials.gov, number NCT00239681.Compared with placebo, participants allocated to rosuvastatin who achieved LDL cholesterol less than 1.8 mmol/L had a 55% reduction in vascular events (event rate 1.11 vs 0.51 per 100 person-years; hazard ratio [HR] 0.45, 95% CI 0.34-0.60, p<0.0001), and those achieving hsCRP less than 2 mg/L a 62% reduction (event rate 0.42 per 100 person-years; HR 0.38, 95% CI 0.26-0.56, p<0.0001). Although LDL cholesterol and hsCRP reductions were only weakly correlated in individual patients (r values <0.15), we recorded a 65% reduction in vascular events in participants allocated to rosuvastatin who achieved both LDL cholesterol less than 1.8 mmol/L and hsCRP less than 2 mg/L (event rate 0.38 per 100 person-years; adjusted HR 0.35, 95% CI 0.23-0.54), versus a 33% reduction in those who achieved one or neither target (event rate 0.74 per 100 person-years; HR 0.67, 95% CI 0.52-0.87) (p across treatment groups <0.0001). In participants who achieved LDL cholesterol less than 1.8 mmol/L and hsCRP less than 1 mg/L, we noted a 79% reduction (event rate 0.24 per 100 person-years; HR 0.21, 95% CI 0.09-0.52). Achieved hsCRP concentrations were predictive of event rates irrespective of the lipid endpoint used, including the apolipoprotein B to apolipoprotein AI ratio.For people choosing to start pharmacological prophylaxis, reduction in both LDL cholesterol and hsCRP are indicators of successful treatment with rosuvastatin.","Reduction in C-reactive protein and LDL cholesterol and cardiovascular event rates after initiation of rosuvastatin: a prospective study of the JUPITER trial."
"1044","JAMA.5511","0.13",19351941,2009,"Guidelines recommend that exercise training be considered for medically stable outpatients with heart failure. Previous studies have not had adequate statistical power to measure the effects of exercise training on clinical outcomes.To test the efficacy and safety of exercise training among patients with heart failure.Multicenter, randomized controlled trial of 2331 medically stable outpatients with heart failure and reduced ejection fraction. Participants in Heart Failure: A Controlled Trial Investigating Outcomes of Exercise Training (HF-ACTION) were randomized from April 2003 through February 2007 at 82 centers within the United States, Canada, and France; median follow-up was 30 months.Usual care plus aerobic exercise training, consisting of 36 supervised sessions followed by home-based training, or usual care alone.Composite primary end point of all-cause mortality or hospitalization and prespecified secondary end points of all-cause mortality, cardiovascular mortality or cardiovascular hospitalization, and cardiovascular mortality or heart failure hospitalization.The median age was 59 years, 28% were women, and 37% had New York Heart Association class III or IV symptoms. Heart failure etiology was ischemic in 51%, and median left ventricular ejection fraction was 25%. Exercise adherence decreased from a median of 95 minutes per week during months 4 through 6 of follow-up to 74 minutes per week during months 10 through 12. A total of 759 patients (65%) in the exercise training group died or were hospitalized compared with 796 patients (68%) in the usual care group (hazard ratio [HR], 0.93 [95% confidence interval {CI}, 0.84-1.02]; P = .13). There were nonsignificant reductions in the exercise training group for mortality (189 patients [16%] in the exercise training group vs 198 patients [17%] in the usual care group; HR, 0.96 [95% CI, 0.79-1.17]; P = .70), cardiovascular mortality or cardiovascular hospitalization (632 [55%] in the exercise training group vs 677 [58%] in the usual care group; HR, 0.92 [95% CI, 0.83-1.03]; P = .14), and cardiovascular mortality or heart failure hospitalization (344 [30%] in the exercise training group vs 393 [34%] in the usual care group; HR, 0.87 [95% CI, 0.75-1.00]; P = .06). In prespecified supplementary analyses adjusting for highly prognostic baseline characteristics, the HRs were 0.89 (95% CI, 0.81-0.99; P = .03) for all-cause mortality or hospitalization, 0.91 (95% CI, 0.82-1.01; P = .09) for cardiovascular mortality or cardiovascular hospitalization, and 0.85 (95% CI, 0.74-0.99; P = .03) for cardiovascular mortality or heart failure hospitalization. Other adverse events were similar between the groups.In the protocol-specified primary analysis, exercise training resulted in nonsignificant reductions in the primary end point of all-cause mortality or hospitalization and in key secondary clinical end points. After adjustment for highly prognostic predictors of the primary end point, exercise training was associated with modest significant reductions for both all-cause mortality or hospitalization and cardiovascular mortality or heart failure hospitalization.clinicaltrials.gov Identifier: NCT00047437.","Efficacy and safety of exercise training in patients with chronic heart failure: HF-ACTION randomized controlled trial."
"1045","JAMA.5521","0.7",19351941,2009,"Guidelines recommend that exercise training be considered for medically stable outpatients with heart failure. Previous studies have not had adequate statistical power to measure the effects of exercise training on clinical outcomes.To test the efficacy and safety of exercise training among patients with heart failure.Multicenter, randomized controlled trial of 2331 medically stable outpatients with heart failure and reduced ejection fraction. Participants in Heart Failure: A Controlled Trial Investigating Outcomes of Exercise Training (HF-ACTION) were randomized from April 2003 through February 2007 at 82 centers within the United States, Canada, and France; median follow-up was 30 months.Usual care plus aerobic exercise training, consisting of 36 supervised sessions followed by home-based training, or usual care alone.Composite primary end point of all-cause mortality or hospitalization and prespecified secondary end points of all-cause mortality, cardiovascular mortality or cardiovascular hospitalization, and cardiovascular mortality or heart failure hospitalization.The median age was 59 years, 28% were women, and 37% had New York Heart Association class III or IV symptoms. Heart failure etiology was ischemic in 51%, and median left ventricular ejection fraction was 25%. Exercise adherence decreased from a median of 95 minutes per week during months 4 through 6 of follow-up to 74 minutes per week during months 10 through 12. A total of 759 patients (65%) in the exercise training group died or were hospitalized compared with 796 patients (68%) in the usual care group (hazard ratio [HR], 0.93 [95% confidence interval {CI}, 0.84-1.02]; P = .13). There were nonsignificant reductions in the exercise training group for mortality (189 patients [16%] in the exercise training group vs 198 patients [17%] in the usual care group; HR, 0.96 [95% CI, 0.79-1.17]; P = .70), cardiovascular mortality or cardiovascular hospitalization (632 [55%] in the exercise training group vs 677 [58%] in the usual care group; HR, 0.92 [95% CI, 0.83-1.03]; P = .14), and cardiovascular mortality or heart failure hospitalization (344 [30%] in the exercise training group vs 393 [34%] in the usual care group; HR, 0.87 [95% CI, 0.75-1.00]; P = .06). In prespecified supplementary analyses adjusting for highly prognostic baseline characteristics, the HRs were 0.89 (95% CI, 0.81-0.99; P = .03) for all-cause mortality or hospitalization, 0.91 (95% CI, 0.82-1.01; P = .09) for cardiovascular mortality or cardiovascular hospitalization, and 0.85 (95% CI, 0.74-0.99; P = .03) for cardiovascular mortality or heart failure hospitalization. Other adverse events were similar between the groups.In the protocol-specified primary analysis, exercise training resulted in nonsignificant reductions in the primary end point of all-cause mortality or hospitalization and in key secondary clinical end points. After adjustment for highly prognostic predictors of the primary end point, exercise training was associated with modest significant reductions for both all-cause mortality or hospitalization and cardiovascular mortality or heart failure hospitalization.clinicaltrials.gov Identifier: NCT00047437.","Efficacy and safety of exercise training in patients with chronic heart failure: HF-ACTION randomized controlled trial."
"1046","JAMA.5531","0.14",19351941,2009,"Guidelines recommend that exercise training be considered for medically stable outpatients with heart failure. Previous studies have not had adequate statistical power to measure the effects of exercise training on clinical outcomes.To test the efficacy and safety of exercise training among patients with heart failure.Multicenter, randomized controlled trial of 2331 medically stable outpatients with heart failure and reduced ejection fraction. Participants in Heart Failure: A Controlled Trial Investigating Outcomes of Exercise Training (HF-ACTION) were randomized from April 2003 through February 2007 at 82 centers within the United States, Canada, and France; median follow-up was 30 months.Usual care plus aerobic exercise training, consisting of 36 supervised sessions followed by home-based training, or usual care alone.Composite primary end point of all-cause mortality or hospitalization and prespecified secondary end points of all-cause mortality, cardiovascular mortality or cardiovascular hospitalization, and cardiovascular mortality or heart failure hospitalization.The median age was 59 years, 28% were women, and 37% had New York Heart Association class III or IV symptoms. Heart failure etiology was ischemic in 51%, and median left ventricular ejection fraction was 25%. Exercise adherence decreased from a median of 95 minutes per week during months 4 through 6 of follow-up to 74 minutes per week during months 10 through 12. A total of 759 patients (65%) in the exercise training group died or were hospitalized compared with 796 patients (68%) in the usual care group (hazard ratio [HR], 0.93 [95% confidence interval {CI}, 0.84-1.02]; P = .13). There were nonsignificant reductions in the exercise training group for mortality (189 patients [16%] in the exercise training group vs 198 patients [17%] in the usual care group; HR, 0.96 [95% CI, 0.79-1.17]; P = .70), cardiovascular mortality or cardiovascular hospitalization (632 [55%] in the exercise training group vs 677 [58%] in the usual care group; HR, 0.92 [95% CI, 0.83-1.03]; P = .14), and cardiovascular mortality or heart failure hospitalization (344 [30%] in the exercise training group vs 393 [34%] in the usual care group; HR, 0.87 [95% CI, 0.75-1.00]; P = .06). In prespecified supplementary analyses adjusting for highly prognostic baseline characteristics, the HRs were 0.89 (95% CI, 0.81-0.99; P = .03) for all-cause mortality or hospitalization, 0.91 (95% CI, 0.82-1.01; P = .09) for cardiovascular mortality or cardiovascular hospitalization, and 0.85 (95% CI, 0.74-0.99; P = .03) for cardiovascular mortality or heart failure hospitalization. Other adverse events were similar between the groups.In the protocol-specified primary analysis, exercise training resulted in nonsignificant reductions in the primary end point of all-cause mortality or hospitalization and in key secondary clinical end points. After adjustment for highly prognostic predictors of the primary end point, exercise training was associated with modest significant reductions for both all-cause mortality or hospitalization and cardiovascular mortality or heart failure hospitalization.clinicaltrials.gov Identifier: NCT00047437.","Efficacy and safety of exercise training in patients with chronic heart failure: HF-ACTION randomized controlled trial."
"1047","JAMA.5541","0.06",19351941,2009,"Guidelines recommend that exercise training be considered for medically stable outpatients with heart failure. Previous studies have not had adequate statistical power to measure the effects of exercise training on clinical outcomes.To test the efficacy and safety of exercise training among patients with heart failure.Multicenter, randomized controlled trial of 2331 medically stable outpatients with heart failure and reduced ejection fraction. Participants in Heart Failure: A Controlled Trial Investigating Outcomes of Exercise Training (HF-ACTION) were randomized from April 2003 through February 2007 at 82 centers within the United States, Canada, and France; median follow-up was 30 months.Usual care plus aerobic exercise training, consisting of 36 supervised sessions followed by home-based training, or usual care alone.Composite primary end point of all-cause mortality or hospitalization and prespecified secondary end points of all-cause mortality, cardiovascular mortality or cardiovascular hospitalization, and cardiovascular mortality or heart failure hospitalization.The median age was 59 years, 28% were women, and 37% had New York Heart Association class III or IV symptoms. Heart failure etiology was ischemic in 51%, and median left ventricular ejection fraction was 25%. Exercise adherence decreased from a median of 95 minutes per week during months 4 through 6 of follow-up to 74 minutes per week during months 10 through 12. A total of 759 patients (65%) in the exercise training group died or were hospitalized compared with 796 patients (68%) in the usual care group (hazard ratio [HR], 0.93 [95% confidence interval {CI}, 0.84-1.02]; P = .13). There were nonsignificant reductions in the exercise training group for mortality (189 patients [16%] in the exercise training group vs 198 patients [17%] in the usual care group; HR, 0.96 [95% CI, 0.79-1.17]; P = .70), cardiovascular mortality or cardiovascular hospitalization (632 [55%] in the exercise training group vs 677 [58%] in the usual care group; HR, 0.92 [95% CI, 0.83-1.03]; P = .14), and cardiovascular mortality or heart failure hospitalization (344 [30%] in the exercise training group vs 393 [34%] in the usual care group; HR, 0.87 [95% CI, 0.75-1.00]; P = .06). In prespecified supplementary analyses adjusting for highly prognostic baseline characteristics, the HRs were 0.89 (95% CI, 0.81-0.99; P = .03) for all-cause mortality or hospitalization, 0.91 (95% CI, 0.82-1.01; P = .09) for cardiovascular mortality or cardiovascular hospitalization, and 0.85 (95% CI, 0.74-0.99; P = .03) for cardiovascular mortality or heart failure hospitalization. Other adverse events were similar between the groups.In the protocol-specified primary analysis, exercise training resulted in nonsignificant reductions in the primary end point of all-cause mortality or hospitalization and in key secondary clinical end points. After adjustment for highly prognostic predictors of the primary end point, exercise training was associated with modest significant reductions for both all-cause mortality or hospitalization and cardiovascular mortality or heart failure hospitalization.clinicaltrials.gov Identifier: NCT00047437.","Efficacy and safety of exercise training in patients with chronic heart failure: HF-ACTION randomized controlled trial."
"1048","JAMA.5551","0.03",19351941,2009,"Guidelines recommend that exercise training be considered for medically stable outpatients with heart failure. Previous studies have not had adequate statistical power to measure the effects of exercise training on clinical outcomes.To test the efficacy and safety of exercise training among patients with heart failure.Multicenter, randomized controlled trial of 2331 medically stable outpatients with heart failure and reduced ejection fraction. Participants in Heart Failure: A Controlled Trial Investigating Outcomes of Exercise Training (HF-ACTION) were randomized from April 2003 through February 2007 at 82 centers within the United States, Canada, and France; median follow-up was 30 months.Usual care plus aerobic exercise training, consisting of 36 supervised sessions followed by home-based training, or usual care alone.Composite primary end point of all-cause mortality or hospitalization and prespecified secondary end points of all-cause mortality, cardiovascular mortality or cardiovascular hospitalization, and cardiovascular mortality or heart failure hospitalization.The median age was 59 years, 28% were women, and 37% had New York Heart Association class III or IV symptoms. Heart failure etiology was ischemic in 51%, and median left ventricular ejection fraction was 25%. Exercise adherence decreased from a median of 95 minutes per week during months 4 through 6 of follow-up to 74 minutes per week during months 10 through 12. A total of 759 patients (65%) in the exercise training group died or were hospitalized compared with 796 patients (68%) in the usual care group (hazard ratio [HR], 0.93 [95% confidence interval {CI}, 0.84-1.02]; P = .13). There were nonsignificant reductions in the exercise training group for mortality (189 patients [16%] in the exercise training group vs 198 patients [17%] in the usual care group; HR, 0.96 [95% CI, 0.79-1.17]; P = .70), cardiovascular mortality or cardiovascular hospitalization (632 [55%] in the exercise training group vs 677 [58%] in the usual care group; HR, 0.92 [95% CI, 0.83-1.03]; P = .14), and cardiovascular mortality or heart failure hospitalization (344 [30%] in the exercise training group vs 393 [34%] in the usual care group; HR, 0.87 [95% CI, 0.75-1.00]; P = .06). In prespecified supplementary analyses adjusting for highly prognostic baseline characteristics, the HRs were 0.89 (95% CI, 0.81-0.99; P = .03) for all-cause mortality or hospitalization, 0.91 (95% CI, 0.82-1.01; P = .09) for cardiovascular mortality or cardiovascular hospitalization, and 0.85 (95% CI, 0.74-0.99; P = .03) for cardiovascular mortality or heart failure hospitalization. Other adverse events were similar between the groups.In the protocol-specified primary analysis, exercise training resulted in nonsignificant reductions in the primary end point of all-cause mortality or hospitalization and in key secondary clinical end points. After adjustment for highly prognostic predictors of the primary end point, exercise training was associated with modest significant reductions for both all-cause mortality or hospitalization and cardiovascular mortality or heart failure hospitalization.clinicaltrials.gov Identifier: NCT00047437.","Efficacy and safety of exercise training in patients with chronic heart failure: HF-ACTION randomized controlled trial."
"1049","JAMA.5561","0.09",19351941,2009,"Guidelines recommend that exercise training be considered for medically stable outpatients with heart failure. Previous studies have not had adequate statistical power to measure the effects of exercise training on clinical outcomes.To test the efficacy and safety of exercise training among patients with heart failure.Multicenter, randomized controlled trial of 2331 medically stable outpatients with heart failure and reduced ejection fraction. Participants in Heart Failure: A Controlled Trial Investigating Outcomes of Exercise Training (HF-ACTION) were randomized from April 2003 through February 2007 at 82 centers within the United States, Canada, and France; median follow-up was 30 months.Usual care plus aerobic exercise training, consisting of 36 supervised sessions followed by home-based training, or usual care alone.Composite primary end point of all-cause mortality or hospitalization and prespecified secondary end points of all-cause mortality, cardiovascular mortality or cardiovascular hospitalization, and cardiovascular mortality or heart failure hospitalization.The median age was 59 years, 28% were women, and 37% had New York Heart Association class III or IV symptoms. Heart failure etiology was ischemic in 51%, and median left ventricular ejection fraction was 25%. Exercise adherence decreased from a median of 95 minutes per week during months 4 through 6 of follow-up to 74 minutes per week during months 10 through 12. A total of 759 patients (65%) in the exercise training group died or were hospitalized compared with 796 patients (68%) in the usual care group (hazard ratio [HR], 0.93 [95% confidence interval {CI}, 0.84-1.02]; P = .13). There were nonsignificant reductions in the exercise training group for mortality (189 patients [16%] in the exercise training group vs 198 patients [17%] in the usual care group; HR, 0.96 [95% CI, 0.79-1.17]; P = .70), cardiovascular mortality or cardiovascular hospitalization (632 [55%] in the exercise training group vs 677 [58%] in the usual care group; HR, 0.92 [95% CI, 0.83-1.03]; P = .14), and cardiovascular mortality or heart failure hospitalization (344 [30%] in the exercise training group vs 393 [34%] in the usual care group; HR, 0.87 [95% CI, 0.75-1.00]; P = .06). In prespecified supplementary analyses adjusting for highly prognostic baseline characteristics, the HRs were 0.89 (95% CI, 0.81-0.99; P = .03) for all-cause mortality or hospitalization, 0.91 (95% CI, 0.82-1.01; P = .09) for cardiovascular mortality or cardiovascular hospitalization, and 0.85 (95% CI, 0.74-0.99; P = .03) for cardiovascular mortality or heart failure hospitalization. Other adverse events were similar between the groups.In the protocol-specified primary analysis, exercise training resulted in nonsignificant reductions in the primary end point of all-cause mortality or hospitalization and in key secondary clinical end points. After adjustment for highly prognostic predictors of the primary end point, exercise training was associated with modest significant reductions for both all-cause mortality or hospitalization and cardiovascular mortality or heart failure hospitalization.clinicaltrials.gov Identifier: NCT00047437.","Efficacy and safety of exercise training in patients with chronic heart failure: HF-ACTION randomized controlled trial."
"1050","JAMA.5571","0.03",19351941,2009,"Guidelines recommend that exercise training be considered for medically stable outpatients with heart failure. Previous studies have not had adequate statistical power to measure the effects of exercise training on clinical outcomes.To test the efficacy and safety of exercise training among patients with heart failure.Multicenter, randomized controlled trial of 2331 medically stable outpatients with heart failure and reduced ejection fraction. Participants in Heart Failure: A Controlled Trial Investigating Outcomes of Exercise Training (HF-ACTION) were randomized from April 2003 through February 2007 at 82 centers within the United States, Canada, and France; median follow-up was 30 months.Usual care plus aerobic exercise training, consisting of 36 supervised sessions followed by home-based training, or usual care alone.Composite primary end point of all-cause mortality or hospitalization and prespecified secondary end points of all-cause mortality, cardiovascular mortality or cardiovascular hospitalization, and cardiovascular mortality or heart failure hospitalization.The median age was 59 years, 28% were women, and 37% had New York Heart Association class III or IV symptoms. Heart failure etiology was ischemic in 51%, and median left ventricular ejection fraction was 25%. Exercise adherence decreased from a median of 95 minutes per week during months 4 through 6 of follow-up to 74 minutes per week during months 10 through 12. A total of 759 patients (65%) in the exercise training group died or were hospitalized compared with 796 patients (68%) in the usual care group (hazard ratio [HR], 0.93 [95% confidence interval {CI}, 0.84-1.02]; P = .13). There were nonsignificant reductions in the exercise training group for mortality (189 patients [16%] in the exercise training group vs 198 patients [17%] in the usual care group; HR, 0.96 [95% CI, 0.79-1.17]; P = .70), cardiovascular mortality or cardiovascular hospitalization (632 [55%] in the exercise training group vs 677 [58%] in the usual care group; HR, 0.92 [95% CI, 0.83-1.03]; P = .14), and cardiovascular mortality or heart failure hospitalization (344 [30%] in the exercise training group vs 393 [34%] in the usual care group; HR, 0.87 [95% CI, 0.75-1.00]; P = .06). In prespecified supplementary analyses adjusting for highly prognostic baseline characteristics, the HRs were 0.89 (95% CI, 0.81-0.99; P = .03) for all-cause mortality or hospitalization, 0.91 (95% CI, 0.82-1.01; P = .09) for cardiovascular mortality or cardiovascular hospitalization, and 0.85 (95% CI, 0.74-0.99; P = .03) for cardiovascular mortality or heart failure hospitalization. Other adverse events were similar between the groups.In the protocol-specified primary analysis, exercise training resulted in nonsignificant reductions in the primary end point of all-cause mortality or hospitalization and in key secondary clinical end points. After adjustment for highly prognostic predictors of the primary end point, exercise training was associated with modest significant reductions for both all-cause mortality or hospitalization and cardiovascular mortality or heart failure hospitalization.clinicaltrials.gov Identifier: NCT00047437.","Efficacy and safety of exercise training in patients with chronic heart failure: HF-ACTION randomized controlled trial."
"1051","JAMA.5481","0.73",19366774,2009,"Coronary artery disease (CAD) is the major cause of mortality and morbidity in patients with type 2 diabetes. But the utility of screening patients with type 2 diabetes for asymptomatic CAD is controversial.To assess whether routine screening for CAD identifies patients with type 2 diabetes as being at high cardiac risk and whether it affects their cardiac outcomes.The Detection of Ischemia in Asymptomatic Diabetics (DIAD) study is a randomized controlled trial in which 1123 participants with type 2 diabetes and no symptoms of CAD were randomly assigned to be screened with adenosine-stress radionuclide myocardial perfusion imaging (MPI) or not to be screened. Participants were recruited from diabetes clinics and practices and prospectively followed up from August 2000 to September 2007.Cardiac death or nonfatal myocardial infarction (MI).The cumulative cardiac event rate was 2.9% over a mean (SD) follow-up of 4.8 (0.9) years for an average of 0.6% per year. Seven nonfatal MIs and 8 cardiac deaths (2.7%) occurred among the screened group and 10 nonfatal MIs and 7 cardiac deaths (3.0%) among the not-screened group (hazard ratio [HR], 0.88; 95% confidence interval [CI], 0.44-1.88; P = .73). Of those in the screened group, 409 participants with normal results and 50 with small MPI defects had lower event rates than the 33 with moderate or large MPI defects; 0.4% per year vs 2.4% per year (HR, 6.3; 95% CI, 1.9-20.1; P = .001). Nevertheless, the positive predictive value of having moderate or large MPI defects was only 12%. The overall rate of coronary revascularization was low in both groups: 31 (5.5%) in the screened group and 44 (7.8%) in the unscreened group (HR, 0.71; 95% CI, 0.45-1.1; P = .14). During the course of study there was a significant and equivalent increase in primary medical prevention in both groups.In this contemporary study population of patients with diabetes, the cardiac event rates were low and were not significantly reduced by MPI screening for myocardial ischemia over 4.8 years.clinicaltrials.gov Identifier: NCT00769275.","Cardiac outcomes after screening for asymptomatic coronary artery disease in patients with type 2 diabetes: the DIAD study: a randomized controlled trial."
"1052","JAMA.5491","0.001",19366774,2009,"Coronary artery disease (CAD) is the major cause of mortality and morbidity in patients with type 2 diabetes. But the utility of screening patients with type 2 diabetes for asymptomatic CAD is controversial.To assess whether routine screening for CAD identifies patients with type 2 diabetes as being at high cardiac risk and whether it affects their cardiac outcomes.The Detection of Ischemia in Asymptomatic Diabetics (DIAD) study is a randomized controlled trial in which 1123 participants with type 2 diabetes and no symptoms of CAD were randomly assigned to be screened with adenosine-stress radionuclide myocardial perfusion imaging (MPI) or not to be screened. Participants were recruited from diabetes clinics and practices and prospectively followed up from August 2000 to September 2007.Cardiac death or nonfatal myocardial infarction (MI).The cumulative cardiac event rate was 2.9% over a mean (SD) follow-up of 4.8 (0.9) years for an average of 0.6% per year. Seven nonfatal MIs and 8 cardiac deaths (2.7%) occurred among the screened group and 10 nonfatal MIs and 7 cardiac deaths (3.0%) among the not-screened group (hazard ratio [HR], 0.88; 95% confidence interval [CI], 0.44-1.88; P = .73). Of those in the screened group, 409 participants with normal results and 50 with small MPI defects had lower event rates than the 33 with moderate or large MPI defects; 0.4% per year vs 2.4% per year (HR, 6.3; 95% CI, 1.9-20.1; P = .001). Nevertheless, the positive predictive value of having moderate or large MPI defects was only 12%. The overall rate of coronary revascularization was low in both groups: 31 (5.5%) in the screened group and 44 (7.8%) in the unscreened group (HR, 0.71; 95% CI, 0.45-1.1; P = .14). During the course of study there was a significant and equivalent increase in primary medical prevention in both groups.In this contemporary study population of patients with diabetes, the cardiac event rates were low and were not significantly reduced by MPI screening for myocardial ischemia over 4.8 years.clinicaltrials.gov Identifier: NCT00769275.","Cardiac outcomes after screening for asymptomatic coronary artery disease in patients with type 2 diabetes: the DIAD study: a randomized controlled trial."
"1053","JAMA.5501","0.14",19366774,2009,"Coronary artery disease (CAD) is the major cause of mortality and morbidity in patients with type 2 diabetes. But the utility of screening patients with type 2 diabetes for asymptomatic CAD is controversial.To assess whether routine screening for CAD identifies patients with type 2 diabetes as being at high cardiac risk and whether it affects their cardiac outcomes.The Detection of Ischemia in Asymptomatic Diabetics (DIAD) study is a randomized controlled trial in which 1123 participants with type 2 diabetes and no symptoms of CAD were randomly assigned to be screened with adenosine-stress radionuclide myocardial perfusion imaging (MPI) or not to be screened. Participants were recruited from diabetes clinics and practices and prospectively followed up from August 2000 to September 2007.Cardiac death or nonfatal myocardial infarction (MI).The cumulative cardiac event rate was 2.9% over a mean (SD) follow-up of 4.8 (0.9) years for an average of 0.6% per year. Seven nonfatal MIs and 8 cardiac deaths (2.7%) occurred among the screened group and 10 nonfatal MIs and 7 cardiac deaths (3.0%) among the not-screened group (hazard ratio [HR], 0.88; 95% confidence interval [CI], 0.44-1.88; P = .73). Of those in the screened group, 409 participants with normal results and 50 with small MPI defects had lower event rates than the 33 with moderate or large MPI defects; 0.4% per year vs 2.4% per year (HR, 6.3; 95% CI, 1.9-20.1; P = .001). Nevertheless, the positive predictive value of having moderate or large MPI defects was only 12%. The overall rate of coronary revascularization was low in both groups: 31 (5.5%) in the screened group and 44 (7.8%) in the unscreened group (HR, 0.71; 95% CI, 0.45-1.1; P = .14). During the course of study there was a significant and equivalent increase in primary medical prevention in both groups.In this contemporary study population of patients with diabetes, the cardiac event rates were low and were not significantly reduced by MPI screening for myocardial ischemia over 4.8 years.clinicaltrials.gov Identifier: NCT00769275.","Cardiac outcomes after screening for asymptomatic coronary artery disease in patients with type 2 diabetes: the DIAD study: a randomized controlled trial."
"1054","JAMA.5051","0.001",19436016,2009,"Androgen deficiency is common in men with chronic heart failure (HF) and is associated with increased morbidity and mortality. Estrogens are formed by the aromatization of androgens; therefore, abnormal estrogen metabolism would be anticipated in HF.To examine the relationship between serum concentration of estradiol and mortality in men with chronic HF and reduced left ventricular ejection fraction (LVEF).A prospective observational study at 2 tertiary cardiology centers (Wroclaw and Zabrze, Poland) of 501 men (mean [SD] age, 58 [12] years) with chronic HF, LVEF of 28% (SD, 8%), and New York Heart Association [NYHA] classes 1, 2, 3, and 4 of 52, 231, 181, and 37, respectively, who were recruited between January 1, 2002, and May 31, 2006. Cohort was divided into quintiles of serum estradiol (quintile 1, < 12.90 pg/mL; quintile 2, 12.90-21.79 pg/mL; quintile 3, 21.80-30.11 pg/mL; quintile 4, 30.12-37.39 pg/mL; and quintile 5, > or = 37.40 pg/mL). Quintile 3 was considered prospectively as the reference group.Serum concentrations of estradiol and androgens (total testosterone and dehydroepiandrosterone sulfate [DHEA-S]) were measured using immunoassays.Among 501 men with chronic HF, 171 deaths (34%) occurred during the 3-year follow-up. Compared with quintile 3, men in the lowest and highest estradiol quintiles had increased mortality (adjusted hazard ratio [HR], 4.17; 95% confidence interval [CI], 2.33-7.45 and HR, 2.33; 95% CI, 1.30-4.18; respectively; P < .001). These 2 quintiles had different clinical characteristics (quintile 1: increased serum total testosterone, decreased serum DHEA-S, advanced NYHA class, impaired renal function, and decreased total fat tissue mass; and quintile 5: increased serum bilirubin and liver enzymes, and decreased serum sodium; all P < .05 vs quintile 3). For increasing estradiol quintiles, 3-year survival rates adjusted for clinical variables and androgens were 44.6% (95% CI, 24.4%-63.0%), 65.8% (95% CI, 47.3%-79.2%), 82.4% (95% CI, 69.4%-90.2%), 79.0% (95% CI, 65.5%-87.6%), and 63.6% (95% CI, 46.6%-76.5%); respectively (P < .001).Among men with chronic HF and reduced LVEF, high and low concentrations of estradiol compared with the middle quintile of estradiol are related to an increased mortality.","Circulating estradiol and mortality in men with systolic chronic heart failure."
"1055","JAMA.5061","0.05",19436016,2009,"Androgen deficiency is common in men with chronic heart failure (HF) and is associated with increased morbidity and mortality. Estrogens are formed by the aromatization of androgens; therefore, abnormal estrogen metabolism would be anticipated in HF.To examine the relationship between serum concentration of estradiol and mortality in men with chronic HF and reduced left ventricular ejection fraction (LVEF).A prospective observational study at 2 tertiary cardiology centers (Wroclaw and Zabrze, Poland) of 501 men (mean [SD] age, 58 [12] years) with chronic HF, LVEF of 28% (SD, 8%), and New York Heart Association [NYHA] classes 1, 2, 3, and 4 of 52, 231, 181, and 37, respectively, who were recruited between January 1, 2002, and May 31, 2006. Cohort was divided into quintiles of serum estradiol (quintile 1, < 12.90 pg/mL; quintile 2, 12.90-21.79 pg/mL; quintile 3, 21.80-30.11 pg/mL; quintile 4, 30.12-37.39 pg/mL; and quintile 5, > or = 37.40 pg/mL). Quintile 3 was considered prospectively as the reference group.Serum concentrations of estradiol and androgens (total testosterone and dehydroepiandrosterone sulfate [DHEA-S]) were measured using immunoassays.Among 501 men with chronic HF, 171 deaths (34%) occurred during the 3-year follow-up. Compared with quintile 3, men in the lowest and highest estradiol quintiles had increased mortality (adjusted hazard ratio [HR], 4.17; 95% confidence interval [CI], 2.33-7.45 and HR, 2.33; 95% CI, 1.30-4.18; respectively; P < .001). These 2 quintiles had different clinical characteristics (quintile 1: increased serum total testosterone, decreased serum DHEA-S, advanced NYHA class, impaired renal function, and decreased total fat tissue mass; and quintile 5: increased serum bilirubin and liver enzymes, and decreased serum sodium; all P < .05 vs quintile 3). For increasing estradiol quintiles, 3-year survival rates adjusted for clinical variables and androgens were 44.6% (95% CI, 24.4%-63.0%), 65.8% (95% CI, 47.3%-79.2%), 82.4% (95% CI, 69.4%-90.2%), 79.0% (95% CI, 65.5%-87.6%), and 63.6% (95% CI, 46.6%-76.5%); respectively (P < .001).Among men with chronic HF and reduced LVEF, high and low concentrations of estradiol compared with the middle quintile of estradiol are related to an increased mortality.","Circulating estradiol and mortality in men with systolic chronic heart failure."
"1056","Lancet.178","4.40E-01",19447249,2009,"Incorporation of a taxane as adjuvant treatment for early breast cancer offers potential for further improvement of anthracycline-based treatment. The UK TACT study (CRUK01/001) investigated whether sequential docetaxel after anthracycline chemotherapy would improve patient outcome compared with standard chemotherapy of similar duration.In this multicentre, open-label, phase III, randomised controlled trial, 4162 women (aged >18 years) with node-positive or high-risk node-negative operable early breast cancer were randomly assigned by computer-generated permuted block randomisation to receive FEC (fluorouracil 600 mg/m(2), epirubicin 60 mg/m(2), cyclophosphamide 600 mg/m(2) at 3-weekly intervals) for four cycles followed by docetaxel (100 mg/m(2) at 3-weekly intervals) for four cycles (n=2073) or control (n=2089). For the control regimen, centres chose either FEC for eight cycles (n=1265) or epirubicin (100 mg/m(2) at 3-weekly intervals) for four cycles followed by CMF (cyclophosphamide 600 mg/m(2), methotrexate 40 mg/m(2), and fluorouracil 600 mg/m(2) at 4-weekly intervals) for four cycles (n=824). The primary endpoint was disease-free survival. Analysis was by intention to treat (ITT). This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN79718493.All randomised patients were included in the ITT population. With a median follow-up of 62 months, disease-free survival events were seen in 517 of 2073 patients in the experimental group compared with 539 of 2089 controls (hazard ratio [HR] 0.95, 95% CI 0.85-1.08; p=0.44). 75.6% (95% CI 73.7-77.5) of patients in the experimental group and 74.3% (72.3-76.2) of controls were alive and disease-free at 5 years. The proportion of patients who reported any acute grade 3 or 4 adverse event was significantly greater in the experimental group than in the control group (p<0.0001); the most frequent events were neutropenia (937 events vs 797 events), leucopenia (507 vs 362), and lethargy (456 vs 272).This study did not show any overall gain from the addition of docetaxel to standard anthracycline chemotherapy. Exploration of predictive biomarker-defined subgroups might have the potential to better target the use of taxane-based therapy.Cancer Research UK (CRUK 01/001), Sanofi-Aventis, Pfizer, and Roche.","Sequential docetaxel as adjuvant chemotherapy for early breast cancer (TACT): an open-label, phase III, randomised controlled trial."
"1057","JAMA.500","0.001",19454640,2009,"Persons with schizophrenia are thought to be at increased risk of committing violent crime 4 to 6 times the level of general population individuals without this disorder. However, risk estimates vary substantially across studies, and considerable uncertainty exists as to what mediates this elevated risk. Despite this uncertainty, current guidelines recommend that violence risk assessment should be conducted for all patients with schizophrenia.To determine the risk of violent crime among patients diagnosed as having schizophrenia and the role of substance abuse in mediating this risk.Longitudinal designs were used to link data from nationwide Swedish registers of hospital admissions and criminal convictions in 1973-2006. Risk of violent crime in patients after diagnosis of schizophrenia (n = 8003) was compared with that among general population controls (n = 80 025). Potential confounders (age, sex, income, and marital and immigrant status) and mediators (substance abuse comorbidity) were measured at baseline. To study familial confounding, we also investigated risk of violence among unaffected siblings (n = 8123) of patients with schizophrenia. Information on treatment was not available.Violent crime (any criminal conviction for homicide, assault, robbery, arson, any sexual offense, illegal threats, or intimidation).In patients with schizophrenia, 1054 (13.2%) had at least 1 violent offense compared with 4276 (5.3%) of general population controls (adjusted odds ratio [OR], 2.0; 95% confidence interval [CI], 1.8-2.2). The risk was mostly confined to patients with substance abuse comorbidity (of whom 27.6% committed an offense), yielding an increased risk of violent crime among such patients (adjusted OR, 4.4; 95% CI, 3.9-5.0), whereas the risk increase was small in schizophrenia patients without substance abuse comorbidity (8.5% of whom had at least 1 violent offense; adjusted OR, 1.2; 95% CI, 1.1-1.4; P<.001 for interaction). The risk increase among those with substance abuse comorbidity was significantly less pronounced when unaffected siblings were used as controls (28.3% of those with schizophrenia had a violent offense compared with 17.9% of their unaffected siblings; adjusted OR, 1.8; 95% CI, 1.4-2.4; P<.001 for interaction), suggesting significant familial (genetic or early environmental) confounding of the association between schizophrenia and violence.Schizophrenia was associated with an increased risk of violent crime in this longitudinal study. This association was attenuated by adjustment for substance abuse, suggesting a mediating effect. The role of risk assessment, management, and treatment in individuals with comorbidity needs further examination.","Schizophrenia, substance abuse, and violent crime."
"1058","JAMA.501","0.001",19454640,2009,"Persons with schizophrenia are thought to be at increased risk of committing violent crime 4 to 6 times the level of general population individuals without this disorder. However, risk estimates vary substantially across studies, and considerable uncertainty exists as to what mediates this elevated risk. Despite this uncertainty, current guidelines recommend that violence risk assessment should be conducted for all patients with schizophrenia.To determine the risk of violent crime among patients diagnosed as having schizophrenia and the role of substance abuse in mediating this risk.Longitudinal designs were used to link data from nationwide Swedish registers of hospital admissions and criminal convictions in 1973-2006. Risk of violent crime in patients after diagnosis of schizophrenia (n = 8003) was compared with that among general population controls (n = 80 025). Potential confounders (age, sex, income, and marital and immigrant status) and mediators (substance abuse comorbidity) were measured at baseline. To study familial confounding, we also investigated risk of violence among unaffected siblings (n = 8123) of patients with schizophrenia. Information on treatment was not available.Violent crime (any criminal conviction for homicide, assault, robbery, arson, any sexual offense, illegal threats, or intimidation).In patients with schizophrenia, 1054 (13.2%) had at least 1 violent offense compared with 4276 (5.3%) of general population controls (adjusted odds ratio [OR], 2.0; 95% confidence interval [CI], 1.8-2.2). The risk was mostly confined to patients with substance abuse comorbidity (of whom 27.6% committed an offense), yielding an increased risk of violent crime among such patients (adjusted OR, 4.4; 95% CI, 3.9-5.0), whereas the risk increase was small in schizophrenia patients without substance abuse comorbidity (8.5% of whom had at least 1 violent offense; adjusted OR, 1.2; 95% CI, 1.1-1.4; P<.001 for interaction). The risk increase among those with substance abuse comorbidity was significantly less pronounced when unaffected siblings were used as controls (28.3% of those with schizophrenia had a violent offense compared with 17.9% of their unaffected siblings; adjusted OR, 1.8; 95% CI, 1.4-2.4; P<.001 for interaction), suggesting significant familial (genetic or early environmental) confounding of the association between schizophrenia and violence.Schizophrenia was associated with an increased risk of violent crime in this longitudinal study. This association was attenuated by adjustment for substance abuse, suggesting a mediating effect. The role of risk assessment, management, and treatment in individuals with comorbidity needs further examination.","Schizophrenia, substance abuse, and violent crime."
"1059","Lancet.215","0.02",19465233,2009,"Amputations in people with type 2 diabetes mellitus substantially impair their quality of life and impose high costs on health-care systems. Our aim was to assess the effect of fenofibrate on amputation events in a large cohort of patients with type 2 diabetes.In the Fenofibrate Intervention and Event Lowering in Diabetes (FIELD) study, 9795 patients aged 50-75 years with type 2 diabetes were randomly assigned by computer-generated randomisation sequence to receive fenofibrate 200 mg per day (n=4895) or matching placebo (n=4900) for 5 years' duration. Information about non-traumatic amputation-a prespecified tertiary endpoint of the study-was routinely gathered. Clinicians who were masked to treatment allocation adjudicated amputations as minor or major (below or above the ankle, respectively). Amputations were also classified on the basis of whether or not large-vessel disease was present in the limb, to distinguish those related to large-artery atherosclerosis from those predominantly related to microvascular disease. Analysis was by intention to treat (ITT). The FIELD study is registered as an International Standard Randomised Controlled Trial, number ISRCTN64783481.All 9795 patients were included in the ITT population. 115 patients had one or more non-traumatic lower-limb amputations due to diabetes. Previous cardiovascular disease, microvascular disease, previous non-traumatic amputation or skin ulcer, smoking, and longer duration of diabetes were more frequent in patients who had amputations during the trial than in those who had other cardiovascular events or in those who had neither event (all p<0.001 for three-way comparison). Mean lipid concentrations differed between patients who had on-study amputations and those who had other cardiovascular events or neither event, but by no more than 0.2 mmol/L. The risks of first amputation (45 vs 70 events; hazard ratio [HR] 0.64, 95% CI 0.44-0.94; p=0.02) and minor amputation events without known large-vessel disease (18 vs 34 events; 0.53, 0.30-0.94; p=0.027) were lower for patients assigned to fenofibrate than for patients assigned to placebo, with no difference between groups in risk of major amputations (24 vs 26 events; 0.93, 0.53-1.62; p=0.79).Classic markers of macrovascular and microvascular risk were associated with lower extremity amputations in patients with type 2 diabetes. Treatment with fenofibrate was associated with a lower risk of amputations, particularly minor amputations without known large-vessel disease, probably through non-lipid mechanisms. These findings could lead to a change in standard treatment for the prevention of diabetes-related lower-limb amputations.Laboratoires Fournier SA (now part of Solvay Pharmaceuticals) and National Health and Medical Research Council of Australia.","Effect of fenofibrate on amputation events in people with type 2 diabetes mellitus (FIELD study): a prespecified analysis of a randomised controlled trial."
"1060","Lancet.216","0.027",19465233,2009,"Amputations in people with type 2 diabetes mellitus substantially impair their quality of life and impose high costs on health-care systems. Our aim was to assess the effect of fenofibrate on amputation events in a large cohort of patients with type 2 diabetes.In the Fenofibrate Intervention and Event Lowering in Diabetes (FIELD) study, 9795 patients aged 50-75 years with type 2 diabetes were randomly assigned by computer-generated randomisation sequence to receive fenofibrate 200 mg per day (n=4895) or matching placebo (n=4900) for 5 years' duration. Information about non-traumatic amputation-a prespecified tertiary endpoint of the study-was routinely gathered. Clinicians who were masked to treatment allocation adjudicated amputations as minor or major (below or above the ankle, respectively). Amputations were also classified on the basis of whether or not large-vessel disease was present in the limb, to distinguish those related to large-artery atherosclerosis from those predominantly related to microvascular disease. Analysis was by intention to treat (ITT). The FIELD study is registered as an International Standard Randomised Controlled Trial, number ISRCTN64783481.All 9795 patients were included in the ITT population. 115 patients had one or more non-traumatic lower-limb amputations due to diabetes. Previous cardiovascular disease, microvascular disease, previous non-traumatic amputation or skin ulcer, smoking, and longer duration of diabetes were more frequent in patients who had amputations during the trial than in those who had other cardiovascular events or in those who had neither event (all p<0.001 for three-way comparison). Mean lipid concentrations differed between patients who had on-study amputations and those who had other cardiovascular events or neither event, but by no more than 0.2 mmol/L. The risks of first amputation (45 vs 70 events; hazard ratio [HR] 0.64, 95% CI 0.44-0.94; p=0.02) and minor amputation events without known large-vessel disease (18 vs 34 events; 0.53, 0.30-0.94; p=0.027) were lower for patients assigned to fenofibrate than for patients assigned to placebo, with no difference between groups in risk of major amputations (24 vs 26 events; 0.93, 0.53-1.62; p=0.79).Classic markers of macrovascular and microvascular risk were associated with lower extremity amputations in patients with type 2 diabetes. Treatment with fenofibrate was associated with a lower risk of amputations, particularly minor amputations without known large-vessel disease, probably through non-lipid mechanisms. These findings could lead to a change in standard treatment for the prevention of diabetes-related lower-limb amputations.Laboratoires Fournier SA (now part of Solvay Pharmaceuticals) and National Health and Medical Research Council of Australia.","Effect of fenofibrate on amputation events in people with type 2 diabetes mellitus (FIELD study): a prespecified analysis of a randomised controlled trial."
"1061","Lancet.217","0.79",19465233,2009,"Amputations in people with type 2 diabetes mellitus substantially impair their quality of life and impose high costs on health-care systems. Our aim was to assess the effect of fenofibrate on amputation events in a large cohort of patients with type 2 diabetes.In the Fenofibrate Intervention and Event Lowering in Diabetes (FIELD) study, 9795 patients aged 50-75 years with type 2 diabetes were randomly assigned by computer-generated randomisation sequence to receive fenofibrate 200 mg per day (n=4895) or matching placebo (n=4900) for 5 years' duration. Information about non-traumatic amputation-a prespecified tertiary endpoint of the study-was routinely gathered. Clinicians who were masked to treatment allocation adjudicated amputations as minor or major (below or above the ankle, respectively). Amputations were also classified on the basis of whether or not large-vessel disease was present in the limb, to distinguish those related to large-artery atherosclerosis from those predominantly related to microvascular disease. Analysis was by intention to treat (ITT). The FIELD study is registered as an International Standard Randomised Controlled Trial, number ISRCTN64783481.All 9795 patients were included in the ITT population. 115 patients had one or more non-traumatic lower-limb amputations due to diabetes. Previous cardiovascular disease, microvascular disease, previous non-traumatic amputation or skin ulcer, smoking, and longer duration of diabetes were more frequent in patients who had amputations during the trial than in those who had other cardiovascular events or in those who had neither event (all p<0.001 for three-way comparison). Mean lipid concentrations differed between patients who had on-study amputations and those who had other cardiovascular events or neither event, but by no more than 0.2 mmol/L. The risks of first amputation (45 vs 70 events; hazard ratio [HR] 0.64, 95% CI 0.44-0.94; p=0.02) and minor amputation events without known large-vessel disease (18 vs 34 events; 0.53, 0.30-0.94; p=0.027) were lower for patients assigned to fenofibrate than for patients assigned to placebo, with no difference between groups in risk of major amputations (24 vs 26 events; 0.93, 0.53-1.62; p=0.79).Classic markers of macrovascular and microvascular risk were associated with lower extremity amputations in patients with type 2 diabetes. Treatment with fenofibrate was associated with a lower risk of amputations, particularly minor amputations without known large-vessel disease, probably through non-lipid mechanisms. These findings could lead to a change in standard treatment for the prevention of diabetes-related lower-limb amputations.Laboratoires Fournier SA (now part of Solvay Pharmaceuticals) and National Health and Medical Research Council of Australia.","Effect of fenofibrate on amputation events in people with type 2 diabetes mellitus (FIELD study): a prespecified analysis of a randomised controlled trial."
"1062","JAMA.5471","0.001",19491183,2009,"Adolescent offspring of depressed parents are at markedly increased risk of developing depressive disorders. Although some smaller targeted prevention trials have found that depression risk can be reduced, these results have yet to be replicated and extended to large-scale, at-risk populations in different settings.To determine the effects of a group cognitive behavioral (CB) prevention program compared with usual care in preventing the onset of depression.A multicenter randomized controlled trial conducted in 4 US cities in which 316 adolescent (aged 13-17 years) offspring of parents with current or prior depressive disorders were recruited from August 2003 through February 2006. Adolescents had a past history of depression, current elevated but subdiagnostic depressive symptoms, or both. Assessments were conducted at baseline, after the 8-week intervention, and after the 6-month continuation phase.Adolescents were randomly assigned to the CB prevention program consisting of 8 weekly, 90-minute group sessions followed by 6 monthly continuation sessions or assigned to receive usual care alone.Rate and hazard ratio (HR) of a probable or definite depressive episode (ie, depressive symptom rating score of > or = 4) for at least 2 weeks as diagnosed by clinical interviewers.Through the postcontinuation session follow-up, the rate and HR of incident depressive episodes were lower for those in the CB prevention program than for those in usual care (21.4% vs 32.7%; HR, 0.63; 95% confidence interval [CI], 0.40-0.98). Adolescents in the CB prevention program also showed significantly greater improvement in self-reported depressive symptoms than those in usual care (coefficient, -1.1; z = -2.2; P = .03). Current parental depression at baseline moderated intervention effects (HR, 5.98; 95% CI, 2.29-15.58; P = .001). Among adolescents whose parents were not depressed at baseline, the CB prevention program was more effective in preventing onset of depression than usual care (11.7% vs 40.5%; HR, 0.24; 95% CI, 0.11-0.50), whereas for adolescents with a currently depressed parent, the CB prevention program was not more effective than usual care in preventing incident depression (31.2% vs 24.3%; HR, 1.43; 95% CI, 0.76-2.67).The CB prevention program had a significant prevention effect through the 9-month follow-up period based on both clinical diagnoses and self-reported depressive symptoms, but this effect was not evident for adolescents with a currently depressed parent.clinicaltrials.gov Identifier: NCT00073671.","Prevention of depression in at-risk adolescents: a randomized controlled trial."
"1063","Lancet.127","0.16",19523680,2009,"Women with twin pregnancy are at high risk for spontaneous preterm delivery. Progesterone seems to be effective in reducing preterm birth in selected high-risk singleton pregnancies, albeit with no significant reduction in perinatal mortality and little evidence of neonatal benefit. We investigated the use of progesterone for prevention of preterm birth in twin pregnancy.In this double-blind, placebo-controlled trial, 500 women with twin pregnancy were recruited from nine UK National Health Service clinics specialising in the management of twin pregnancy. Women were randomised, by permuted blocks of randomly mixed sizes, either to daily vaginal progesterone gel 90 mg (n=250) or to placebo gel (n=250) for 10 weeks from 24 weeks' gestation. All study personnel and participants were masked to treatment assignment for the duration of the study. The primary outcome was delivery or intrauterine death before 34 weeks' gestation. Analysis was by intention to treat. Additionally we undertook a meta-analysis of published and unpublished data to establish the efficacy of progesterone in prevention of early (<34 weeks' gestation) preterm birth or intrauterine death in women with twin pregnancy. This study is registered, number ISRCTN35782581.Three participants in each group were lost to follow-up, leaving 247 analysed per group. The combined proportion of intrauterine death or delivery before 34 weeks of pregnancy was 24.7% (61/247) in the progesterone group and 19.4% (48/247) in the placebo group (odds ratio [OR] 1.36, 95% CI 0.89-2.09; p=0.16). The rate of adverse events did not differ between the two groups. The meta-analysis confirmed that progesterone does not prevent early preterm birth in women with twin pregnancy (pooled OR 1.16, 95% CI 0.89-1.51).Progesterone, administered vaginally, does not prevent preterm birth in women with twin pregnancy.Chief Scientist Office of the Scottish Government Health Directorate.","Progesterone for the prevention of preterm birth in twin pregnancy (STOPPIT): a randomised, double-blind, placebo-controlled study and meta-analysis."
"1064","Lancet.175","1.00E-04",19539361,2009,"Rivaroxaban is an oral direct factor Xa inhibitor that has been effective in prevention of venous thromboembolism in patients undergoing elective orthopaedic surgery. However, its use after acute coronary syndromes has not been investigated. In this setting, we assessed the safety and efficacy of rivaroxaban and aimed to select the most favourable dose and dosing regimen.In this double-blind, dose-escalation, phase II study, undertaken at 297 sites in 27 countries, 3491 patients stabilised after an acute coronary syndrome were stratified on the basis of investigator decision to use aspirin only (stratum 1, n=761) or aspirin plus a thienopyridine (stratum 2, n=2730). Participants were randomised within each strata and dose tier with a block randomisation method at 1:1:1 to receive either placebo or rivaroxaban (at doses 5-20 mg) given once daily or the same total daily dose given twice daily. The primary safety endpoint was clinically significant bleeding (TIMI major, TIMI minor, or requiring medical attention); the primary efficacy endpoint was death, myocardial infarction, stroke, or severe recurrent ischaemia requiring revascularisation during 6 months. Safety analyses included all participants who received at least one dose of study drug; efficacy analyses were by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00402597.Three patients in stratum 1 and 26 in stratum 2 never received the study drug. The risk of clinically significant bleeding with rivaroxaban versus placebo increased in a dose-dependent manner (hazard ratios [HRs] 2.21 [95% CI 1.25-3.91] for 5 mg, 3.35 [2.31-4.87] for 10 mg, 3.60 [2.32-5.58] for 15 mg, and 5.06 [3.45-7.42] for 20 mg doses; p<0.0001). Rates of the primary efficacy endpoint were 5.6% (126/2331) for rivaroxaban versus 7.0% (79/1160) for placebo (HR 0.79 [0.60-1.05], p=0.10). Rivaroxaban reduced the main secondary efficacy endpoint of death, myocardial infarction, or stroke compared with placebo (87/2331 [3.9%] vs 62/1160 [5.5%]; HR 0.69, [95% CI 0.50-0.96], p=0.0270). The most common adverse event in both groups was chest pain (248/2309 [10.7%] vs 118/1153 [10.2%]).The use of an oral factor Xa inhibitor in patients stabilised after an acute coronary syndrome increases bleeding in a dose-dependent manner and might reduce major ischaemic outcomes. On the basis of these observations, a phase III study of low-dose rivaroxaban as adjunctive therapy in these patients is underway.Johnson & Johnson Pharmaceutical Research & Development and Bayer Healthcare AG.","Rivaroxaban versus placebo in patients with acute coronary syndromes (ATLAS ACS-TIMI 46): a randomised, double-blind, phase II trial."
"1065","Lancet.212","0.1",19539361,2009,"Rivaroxaban is an oral direct factor Xa inhibitor that has been effective in prevention of venous thromboembolism in patients undergoing elective orthopaedic surgery. However, its use after acute coronary syndromes has not been investigated. In this setting, we assessed the safety and efficacy of rivaroxaban and aimed to select the most favourable dose and dosing regimen.In this double-blind, dose-escalation, phase II study, undertaken at 297 sites in 27 countries, 3491 patients stabilised after an acute coronary syndrome were stratified on the basis of investigator decision to use aspirin only (stratum 1, n=761) or aspirin plus a thienopyridine (stratum 2, n=2730). Participants were randomised within each strata and dose tier with a block randomisation method at 1:1:1 to receive either placebo or rivaroxaban (at doses 5-20 mg) given once daily or the same total daily dose given twice daily. The primary safety endpoint was clinically significant bleeding (TIMI major, TIMI minor, or requiring medical attention); the primary efficacy endpoint was death, myocardial infarction, stroke, or severe recurrent ischaemia requiring revascularisation during 6 months. Safety analyses included all participants who received at least one dose of study drug; efficacy analyses were by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00402597.Three patients in stratum 1 and 26 in stratum 2 never received the study drug. The risk of clinically significant bleeding with rivaroxaban versus placebo increased in a dose-dependent manner (hazard ratios [HRs] 2.21 [95% CI 1.25-3.91] for 5 mg, 3.35 [2.31-4.87] for 10 mg, 3.60 [2.32-5.58] for 15 mg, and 5.06 [3.45-7.42] for 20 mg doses; p<0.0001). Rates of the primary efficacy endpoint were 5.6% (126/2331) for rivaroxaban versus 7.0% (79/1160) for placebo (HR 0.79 [0.60-1.05], p=0.10). Rivaroxaban reduced the main secondary efficacy endpoint of death, myocardial infarction, or stroke compared with placebo (87/2331 [3.9%] vs 62/1160 [5.5%]; HR 0.69, [95% CI 0.50-0.96], p=0.0270). The most common adverse event in both groups was chest pain (248/2309 [10.7%] vs 118/1153 [10.2%]).The use of an oral factor Xa inhibitor in patients stabilised after an acute coronary syndrome increases bleeding in a dose-dependent manner and might reduce major ischaemic outcomes. On the basis of these observations, a phase III study of low-dose rivaroxaban as adjunctive therapy in these patients is underway.Johnson & Johnson Pharmaceutical Research & Development and Bayer Healthcare AG.","Rivaroxaban versus placebo in patients with acute coronary syndromes (ATLAS ACS-TIMI 46): a randomised, double-blind, phase II trial."
"1066","Lancet.213","0.027",19539361,2009,"Rivaroxaban is an oral direct factor Xa inhibitor that has been effective in prevention of venous thromboembolism in patients undergoing elective orthopaedic surgery. However, its use after acute coronary syndromes has not been investigated. In this setting, we assessed the safety and efficacy of rivaroxaban and aimed to select the most favourable dose and dosing regimen.In this double-blind, dose-escalation, phase II study, undertaken at 297 sites in 27 countries, 3491 patients stabilised after an acute coronary syndrome were stratified on the basis of investigator decision to use aspirin only (stratum 1, n=761) or aspirin plus a thienopyridine (stratum 2, n=2730). Participants were randomised within each strata and dose tier with a block randomisation method at 1:1:1 to receive either placebo or rivaroxaban (at doses 5-20 mg) given once daily or the same total daily dose given twice daily. The primary safety endpoint was clinically significant bleeding (TIMI major, TIMI minor, or requiring medical attention); the primary efficacy endpoint was death, myocardial infarction, stroke, or severe recurrent ischaemia requiring revascularisation during 6 months. Safety analyses included all participants who received at least one dose of study drug; efficacy analyses were by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00402597.Three patients in stratum 1 and 26 in stratum 2 never received the study drug. The risk of clinically significant bleeding with rivaroxaban versus placebo increased in a dose-dependent manner (hazard ratios [HRs] 2.21 [95% CI 1.25-3.91] for 5 mg, 3.35 [2.31-4.87] for 10 mg, 3.60 [2.32-5.58] for 15 mg, and 5.06 [3.45-7.42] for 20 mg doses; p<0.0001). Rates of the primary efficacy endpoint were 5.6% (126/2331) for rivaroxaban versus 7.0% (79/1160) for placebo (HR 0.79 [0.60-1.05], p=0.10). Rivaroxaban reduced the main secondary efficacy endpoint of death, myocardial infarction, or stroke compared with placebo (87/2331 [3.9%] vs 62/1160 [5.5%]; HR 0.69, [95% CI 0.50-0.96], p=0.0270). The most common adverse event in both groups was chest pain (248/2309 [10.7%] vs 118/1153 [10.2%]).The use of an oral factor Xa inhibitor in patients stabilised after an acute coronary syndrome increases bleeding in a dose-dependent manner and might reduce major ischaemic outcomes. On the basis of these observations, a phase III study of low-dose rivaroxaban as adjunctive therapy in these patients is underway.Johnson & Johnson Pharmaceutical Research & Development and Bayer Healthcare AG.","Rivaroxaban versus placebo in patients with acute coronary syndromes (ATLAS ACS-TIMI 46): a randomised, double-blind, phase II trial."
"1067","JAMA.499","0.001",19549972,2009,"Obesity has been implicated as a risk factor for pancreatic cancer.To demonstrate the association of excess body weight across an age cohort and the risk, age of onset, and overall survival of patients with pancreatic cancer.A case-control study of 841 patients with pancreatic adenocarcinoma and 754 healthy individuals frequency matched by age, race, and sex. The study was conducted at a university cancer center in the United States from 2004 to 2008. Height and body weight histories were collected by personal interview starting at ages 14 to 19 years and over 10-year intervals progressing to the year prior to recruitment in the study.The associations between patients' body mass index (BMI) and risk of pancreatic cancer, age at onset, and overall survival were examined by unconditional logistic regression, linear regression, and Cox proportional hazard regression models, respectively.Individuals who were overweight (a BMI of 25-29.9) from the ages of 14 to 39 years (highest odds ratio [OR], 1.67; 95% confidence interval [CI], 1.20-2.34) or obese (a BMI > or = 30) from the ages of 20 to 49 years (highest OR, 2.58; 95% CI, 1.70-3.90) had an associated increased risk of pancreatic cancer, independent of diabetes status. The association was stronger in men (adjusted OR, 1.80; 95% CI, 1.45-2.23) by mean BMI from the ages of 14 to 59 years than in women (adjusted OR, 1.32; 95% CI, 1.02-1.70) and in ever smokers (adjusted OR, 1.75; 95% CI, 1.37-2.22) than in never smokers (adjusted OR, 1.46; 95% CI, 1.16-1.84). The population-attributable risk percentage of pancreatic cancer based on the mean BMI from the ages of 14 to 59 years was 10.3% for never smokers and 21.3% for ever smokers. Individuals who were overweight or obese from the ages of 20 to 49 years had an earlier onset of pancreatic cancer by 2 to 6 years (median age of onset was 64 years for patients with normal weight, 61 years for overweight patients [P = .02], and 59 years for obese patients [P < .001]). Compared with those with normal body weight and after adjusting for all clinical factors, individuals who were overweight or obese from the ages of 30 to 79 years or in the year prior to recruitment had reduced overall survival of pancreatic cancer regardless of disease stage and tumor resection status (overweight patients: hazard ratio, 1.26 [95% CI, 0.94-1.69], P = .04; obese patients: hazard ratio, 1.86 [95% CI, 1.35-2.56], P < .001).Overweight or obesity during early adulthood was associated with a greater risk of pancreatic cancer and a younger age of disease onset. Obesity at an older age was associated with a lower overall survival in patients with pancreatic cancer.","Body mass index and risk, age of onset, and survival in patients with pancreatic cancer."
"1068","JAMA.536","0.04",19549972,2009,"Obesity has been implicated as a risk factor for pancreatic cancer.To demonstrate the association of excess body weight across an age cohort and the risk, age of onset, and overall survival of patients with pancreatic cancer.A case-control study of 841 patients with pancreatic adenocarcinoma and 754 healthy individuals frequency matched by age, race, and sex. The study was conducted at a university cancer center in the United States from 2004 to 2008. Height and body weight histories were collected by personal interview starting at ages 14 to 19 years and over 10-year intervals progressing to the year prior to recruitment in the study.The associations between patients' body mass index (BMI) and risk of pancreatic cancer, age at onset, and overall survival were examined by unconditional logistic regression, linear regression, and Cox proportional hazard regression models, respectively.Individuals who were overweight (a BMI of 25-29.9) from the ages of 14 to 39 years (highest odds ratio [OR], 1.67; 95% confidence interval [CI], 1.20-2.34) or obese (a BMI > or = 30) from the ages of 20 to 49 years (highest OR, 2.58; 95% CI, 1.70-3.90) had an associated increased risk of pancreatic cancer, independent of diabetes status. The association was stronger in men (adjusted OR, 1.80; 95% CI, 1.45-2.23) by mean BMI from the ages of 14 to 59 years than in women (adjusted OR, 1.32; 95% CI, 1.02-1.70) and in ever smokers (adjusted OR, 1.75; 95% CI, 1.37-2.22) than in never smokers (adjusted OR, 1.46; 95% CI, 1.16-1.84). The population-attributable risk percentage of pancreatic cancer based on the mean BMI from the ages of 14 to 59 years was 10.3% for never smokers and 21.3% for ever smokers. Individuals who were overweight or obese from the ages of 20 to 49 years had an earlier onset of pancreatic cancer by 2 to 6 years (median age of onset was 64 years for patients with normal weight, 61 years for overweight patients [P = .02], and 59 years for obese patients [P < .001]). Compared with those with normal body weight and after adjusting for all clinical factors, individuals who were overweight or obese from the ages of 30 to 79 years or in the year prior to recruitment had reduced overall survival of pancreatic cancer regardless of disease stage and tumor resection status (overweight patients: hazard ratio, 1.26 [95% CI, 0.94-1.69], P = .04; obese patients: hazard ratio, 1.86 [95% CI, 1.35-2.56], P < .001).Overweight or obesity during early adulthood was associated with a greater risk of pancreatic cancer and a younger age of disease onset. Obesity at an older age was associated with a lower overall survival in patients with pancreatic cancer.","Body mass index and risk, age of onset, and survival in patients with pancreatic cancer."
"1069","JAMA.498","0.04",19549973,2009,"Migraine is considered to be an episodic condition with no long-term consequences. However, recent studies suggest that migraine attacks may be associated with pathologic changes in the brain, particularly in the cerebellum.To determine whether individuals not reporting headache compared with individuals reporting migraine symptoms, particularly aura, in midlife are at increased risk of late-life infarct-like lesions found on magnetic resonance imaging (MRI) without consideration of clinical symptoms.A population-based study of men and women in Reykjavik, Iceland (cohort born 1907-1935; n = 4689; 57% women) were followed up since 1967, examined, and interviewed about migraine symptoms in midlife (mean age, 51 years; range, 33-65 years). Between 2002 and 2006, more than 26 years later, brain MRIs were performed. Participants reporting headaches once or more per month were asked about migraine symptoms including nausea, unilateral location, photophobia, visual disturbance, and numbness. These individuals with headache were classified as having migraine without aura, migraine with aura, or nonmigraine headache. A comprehensive cardiovascular risk assessment was performed at both examinations.Presence of infarct-like lesions (total) and specifically located in the cortical, subcortical, and cerebellar regions.Infarct-like lesions were present in 39.3% of men and 24.6% of women. After adjusting for age, sex, and follow-up time, compared with those not reporting headaches once or more per month (n = 3243), those with midlife migraine with aura (n = 361) had an increased risk of late-life infarct-like lesions (adjusted odds ratio [OR], 1.4; 95% confidence interval [CI], 1.1-1.8) that specifically reflected an association with cerebellar lesions in women (prevalence of infarcts 23.0% for women with migraine with aura vs 14.5% for women not reporting headaches; adjusted OR, 1.9; 95% CI, 1.4-2.6 vs a 19.3% prevalence of infarcts for men with migraine with aura vs 21.3% for men not reporting headaches; adjusted OR, 1.0; 95% CI, 0.6-1.8; P<.04 for interaction by sex). Migraine without aura and nonmigraine headache were not associated with an increased risk.Migraine with aura in midlife was associated with late-life prevalence of cerebellar infarct-like lesions on MRI. This association was statistically significant only for women. This is consistent with the hypothesis that migraine with aura in midlife is associated with late-life vascular disease in the cerebellum and in women.","Migraine headache in middle age and late-life brain infarcts."
"1070","JAMA.4971","0.001",19549974,2009,"Prolongation of the electrocardiographic PR interval, known as first-degree atrioventricular block when the PR interval exceeds 200 milliseconds, is frequently encountered in clinical practice.To determine the clinical significance of PR prolongation in ambulatory individuals.Prospective, community-based cohort including 7575 individuals from the Framingham Heart Study (mean age, 47 years; 54% women) who underwent routine 12-lead electrocardiography. The study cohort underwent prospective follow-up through 2007 from baseline examinations in 1968-1974. Multivariable-adjusted Cox proportional hazards models were used to examine the associations of PR interval with the incidence of arrhythmic events and death.Incident atrial fibrillation (AF), pacemaker implantation, and all-cause mortality.During follow-up, 481 participants developed AF, 124 required pacemaker implantation, and 1739 died. At the baseline examination, 124 individuals had PR intervals longer than 200 milliseconds. For those with PR intervals longer than 200 milliseconds compared with those with PR intervals of 200 milliseconds or shorter, incidence rates per 10 000 person-years were 140 (95% confidence interval [CI], 95-208) vs 36 (95% CI, 32-39) for AF, 59 (95% CI, 40-87) vs 6 (95% CI, 5-7) for pacemaker implantation, and 334 (95% CI, 260-428) vs 129 (95% CI, 123-135) for all-cause mortality. Corresponding absolute risk increases were 1.04% (AF), 0.53% (pacemaker implantation), and 2.05% (all-cause mortality) per year. In multivariable analyses, each 20-millisecond increment in PR was associated with an adjusted hazard ratio (HR) of 1.11 (95% CI, 1.02-1.22; P = .02) for AF, 1.22 (95% CI, 1.14-1.30; P < .001) for pacemaker implantation, and 1.08 (95% CI, 1.02-1.13; P = .005) for all-cause mortality. Individuals with first-degree atrioventricular block had a 2-fold adjusted risk of AF (HR, 2.06; 95% CI, 1.36-3.12; P < .001), 3-fold adjusted risk of pacemaker implantation (HR, 2.89; 95% CI, 1.83-4.57; P < .001), and 1.4-fold adjusted risk of all-cause mortality (HR, 1.44, 95% CI, 1.09-1.91; P = .01).Prolongation of the PR interval is associated with increased risks of AF, pacemaker implantation, and all-cause mortality.","Long-term outcomes in individuals with prolonged PR interval or first-degree atrioventricular block."
"1071","JAMA.4971","0.001",19549974,2009,"Prolongation of the electrocardiographic PR interval, known as first-degree atrioventricular block when the PR interval exceeds 200 milliseconds, is frequently encountered in clinical practice.To determine the clinical significance of PR prolongation in ambulatory individuals.Prospective, community-based cohort including 7575 individuals from the Framingham Heart Study (mean age, 47 years; 54% women) who underwent routine 12-lead electrocardiography. The study cohort underwent prospective follow-up through 2007 from baseline examinations in 1968-1974. Multivariable-adjusted Cox proportional hazards models were used to examine the associations of PR interval with the incidence of arrhythmic events and death.Incident atrial fibrillation (AF), pacemaker implantation, and all-cause mortality.During follow-up, 481 participants developed AF, 124 required pacemaker implantation, and 1739 died. At the baseline examination, 124 individuals had PR intervals longer than 200 milliseconds. For those with PR intervals longer than 200 milliseconds compared with those with PR intervals of 200 milliseconds or shorter, incidence rates per 10 000 person-years were 140 (95% confidence interval [CI], 95-208) vs 36 (95% CI, 32-39) for AF, 59 (95% CI, 40-87) vs 6 (95% CI, 5-7) for pacemaker implantation, and 334 (95% CI, 260-428) vs 129 (95% CI, 123-135) for all-cause mortality. Corresponding absolute risk increases were 1.04% (AF), 0.53% (pacemaker implantation), and 2.05% (all-cause mortality) per year. In multivariable analyses, each 20-millisecond increment in PR was associated with an adjusted hazard ratio (HR) of 1.11 (95% CI, 1.02-1.22; P = .02) for AF, 1.22 (95% CI, 1.14-1.30; P < .001) for pacemaker implantation, and 1.08 (95% CI, 1.02-1.13; P = .005) for all-cause mortality. Individuals with first-degree atrioventricular block had a 2-fold adjusted risk of AF (HR, 2.06; 95% CI, 1.36-3.12; P < .001), 3-fold adjusted risk of pacemaker implantation (HR, 2.89; 95% CI, 1.83-4.57; P < .001), and 1.4-fold adjusted risk of all-cause mortality (HR, 1.44, 95% CI, 1.09-1.91; P = .01).Prolongation of the PR interval is associated with increased risks of AF, pacemaker implantation, and all-cause mortality.","Long-term outcomes in individuals with prolonged PR interval or first-degree atrioventricular block."
"1072","JAMA.4981","0.001",19549974,2009,"Prolongation of the electrocardiographic PR interval, known as first-degree atrioventricular block when the PR interval exceeds 200 milliseconds, is frequently encountered in clinical practice.To determine the clinical significance of PR prolongation in ambulatory individuals.Prospective, community-based cohort including 7575 individuals from the Framingham Heart Study (mean age, 47 years; 54% women) who underwent routine 12-lead electrocardiography. The study cohort underwent prospective follow-up through 2007 from baseline examinations in 1968-1974. Multivariable-adjusted Cox proportional hazards models were used to examine the associations of PR interval with the incidence of arrhythmic events and death.Incident atrial fibrillation (AF), pacemaker implantation, and all-cause mortality.During follow-up, 481 participants developed AF, 124 required pacemaker implantation, and 1739 died. At the baseline examination, 124 individuals had PR intervals longer than 200 milliseconds. For those with PR intervals longer than 200 milliseconds compared with those with PR intervals of 200 milliseconds or shorter, incidence rates per 10 000 person-years were 140 (95% confidence interval [CI], 95-208) vs 36 (95% CI, 32-39) for AF, 59 (95% CI, 40-87) vs 6 (95% CI, 5-7) for pacemaker implantation, and 334 (95% CI, 260-428) vs 129 (95% CI, 123-135) for all-cause mortality. Corresponding absolute risk increases were 1.04% (AF), 0.53% (pacemaker implantation), and 2.05% (all-cause mortality) per year. In multivariable analyses, each 20-millisecond increment in PR was associated with an adjusted hazard ratio (HR) of 1.11 (95% CI, 1.02-1.22; P = .02) for AF, 1.22 (95% CI, 1.14-1.30; P < .001) for pacemaker implantation, and 1.08 (95% CI, 1.02-1.13; P = .005) for all-cause mortality. Individuals with first-degree atrioventricular block had a 2-fold adjusted risk of AF (HR, 2.06; 95% CI, 1.36-3.12; P < .001), 3-fold adjusted risk of pacemaker implantation (HR, 2.89; 95% CI, 1.83-4.57; P < .001), and 1.4-fold adjusted risk of all-cause mortality (HR, 1.44, 95% CI, 1.09-1.91; P = .01).Prolongation of the PR interval is associated with increased risks of AF, pacemaker implantation, and all-cause mortality.","Long-term outcomes in individuals with prolonged PR interval or first-degree atrioventricular block."
"1073","JAMA.5361","0.02",19549974,2009,"Prolongation of the electrocardiographic PR interval, known as first-degree atrioventricular block when the PR interval exceeds 200 milliseconds, is frequently encountered in clinical practice.To determine the clinical significance of PR prolongation in ambulatory individuals.Prospective, community-based cohort including 7575 individuals from the Framingham Heart Study (mean age, 47 years; 54% women) who underwent routine 12-lead electrocardiography. The study cohort underwent prospective follow-up through 2007 from baseline examinations in 1968-1974. Multivariable-adjusted Cox proportional hazards models were used to examine the associations of PR interval with the incidence of arrhythmic events and death.Incident atrial fibrillation (AF), pacemaker implantation, and all-cause mortality.During follow-up, 481 participants developed AF, 124 required pacemaker implantation, and 1739 died. At the baseline examination, 124 individuals had PR intervals longer than 200 milliseconds. For those with PR intervals longer than 200 milliseconds compared with those with PR intervals of 200 milliseconds or shorter, incidence rates per 10 000 person-years were 140 (95% confidence interval [CI], 95-208) vs 36 (95% CI, 32-39) for AF, 59 (95% CI, 40-87) vs 6 (95% CI, 5-7) for pacemaker implantation, and 334 (95% CI, 260-428) vs 129 (95% CI, 123-135) for all-cause mortality. Corresponding absolute risk increases were 1.04% (AF), 0.53% (pacemaker implantation), and 2.05% (all-cause mortality) per year. In multivariable analyses, each 20-millisecond increment in PR was associated with an adjusted hazard ratio (HR) of 1.11 (95% CI, 1.02-1.22; P = .02) for AF, 1.22 (95% CI, 1.14-1.30; P < .001) for pacemaker implantation, and 1.08 (95% CI, 1.02-1.13; P = .005) for all-cause mortality. Individuals with first-degree atrioventricular block had a 2-fold adjusted risk of AF (HR, 2.06; 95% CI, 1.36-3.12; P < .001), 3-fold adjusted risk of pacemaker implantation (HR, 2.89; 95% CI, 1.83-4.57; P < .001), and 1.4-fold adjusted risk of all-cause mortality (HR, 1.44, 95% CI, 1.09-1.91; P = .01).Prolongation of the PR interval is associated with increased risks of AF, pacemaker implantation, and all-cause mortality.","Long-term outcomes in individuals with prolonged PR interval or first-degree atrioventricular block."
"1074","JAMA.5371","0.005",19549974,2009,"Prolongation of the electrocardiographic PR interval, known as first-degree atrioventricular block when the PR interval exceeds 200 milliseconds, is frequently encountered in clinical practice.To determine the clinical significance of PR prolongation in ambulatory individuals.Prospective, community-based cohort including 7575 individuals from the Framingham Heart Study (mean age, 47 years; 54% women) who underwent routine 12-lead electrocardiography. The study cohort underwent prospective follow-up through 2007 from baseline examinations in 1968-1974. Multivariable-adjusted Cox proportional hazards models were used to examine the associations of PR interval with the incidence of arrhythmic events and death.Incident atrial fibrillation (AF), pacemaker implantation, and all-cause mortality.During follow-up, 481 participants developed AF, 124 required pacemaker implantation, and 1739 died. At the baseline examination, 124 individuals had PR intervals longer than 200 milliseconds. For those with PR intervals longer than 200 milliseconds compared with those with PR intervals of 200 milliseconds or shorter, incidence rates per 10 000 person-years were 140 (95% confidence interval [CI], 95-208) vs 36 (95% CI, 32-39) for AF, 59 (95% CI, 40-87) vs 6 (95% CI, 5-7) for pacemaker implantation, and 334 (95% CI, 260-428) vs 129 (95% CI, 123-135) for all-cause mortality. Corresponding absolute risk increases were 1.04% (AF), 0.53% (pacemaker implantation), and 2.05% (all-cause mortality) per year. In multivariable analyses, each 20-millisecond increment in PR was associated with an adjusted hazard ratio (HR) of 1.11 (95% CI, 1.02-1.22; P = .02) for AF, 1.22 (95% CI, 1.14-1.30; P < .001) for pacemaker implantation, and 1.08 (95% CI, 1.02-1.13; P = .005) for all-cause mortality. Individuals with first-degree atrioventricular block had a 2-fold adjusted risk of AF (HR, 2.06; 95% CI, 1.36-3.12; P < .001), 3-fold adjusted risk of pacemaker implantation (HR, 2.89; 95% CI, 1.83-4.57; P < .001), and 1.4-fold adjusted risk of all-cause mortality (HR, 1.44, 95% CI, 1.09-1.91; P = .01).Prolongation of the PR interval is associated with increased risks of AF, pacemaker implantation, and all-cause mortality.","Long-term outcomes in individuals with prolonged PR interval or first-degree atrioventricular block."
"1075","JAMA.5381","0.01",19549974,2009,"Prolongation of the electrocardiographic PR interval, known as first-degree atrioventricular block when the PR interval exceeds 200 milliseconds, is frequently encountered in clinical practice.To determine the clinical significance of PR prolongation in ambulatory individuals.Prospective, community-based cohort including 7575 individuals from the Framingham Heart Study (mean age, 47 years; 54% women) who underwent routine 12-lead electrocardiography. The study cohort underwent prospective follow-up through 2007 from baseline examinations in 1968-1974. Multivariable-adjusted Cox proportional hazards models were used to examine the associations of PR interval with the incidence of arrhythmic events and death.Incident atrial fibrillation (AF), pacemaker implantation, and all-cause mortality.During follow-up, 481 participants developed AF, 124 required pacemaker implantation, and 1739 died. At the baseline examination, 124 individuals had PR intervals longer than 200 milliseconds. For those with PR intervals longer than 200 milliseconds compared with those with PR intervals of 200 milliseconds or shorter, incidence rates per 10 000 person-years were 140 (95% confidence interval [CI], 95-208) vs 36 (95% CI, 32-39) for AF, 59 (95% CI, 40-87) vs 6 (95% CI, 5-7) for pacemaker implantation, and 334 (95% CI, 260-428) vs 129 (95% CI, 123-135) for all-cause mortality. Corresponding absolute risk increases were 1.04% (AF), 0.53% (pacemaker implantation), and 2.05% (all-cause mortality) per year. In multivariable analyses, each 20-millisecond increment in PR was associated with an adjusted hazard ratio (HR) of 1.11 (95% CI, 1.02-1.22; P = .02) for AF, 1.22 (95% CI, 1.14-1.30; P < .001) for pacemaker implantation, and 1.08 (95% CI, 1.02-1.13; P = .005) for all-cause mortality. Individuals with first-degree atrioventricular block had a 2-fold adjusted risk of AF (HR, 2.06; 95% CI, 1.36-3.12; P < .001), 3-fold adjusted risk of pacemaker implantation (HR, 2.89; 95% CI, 1.83-4.57; P < .001), and 1.4-fold adjusted risk of all-cause mortality (HR, 1.44, 95% CI, 1.09-1.91; P = .01).Prolongation of the PR interval is associated with increased risks of AF, pacemaker implantation, and all-cause mortality.","Long-term outcomes in individuals with prolonged PR interval or first-degree atrioventricular block."
"1076","Lancet.115","1.00E-04",19577798,2009,"There are few therapeutic options for the prevention of gastrointestinal mucosal damage caused by low-dose aspirin. We therefore investigated the efficacy of famotidine, a well-tolerated histamine H(2)-receptor antagonist, in the prevention of peptic ulcers and erosive oesophagitis in patients receiving low-dose aspirin for vascular protection.Adult patients (aged >/=18 years) from the cardiovascular, cerebrovascular, and diabetes clinics at Crosshouse Hospital, Kilmarnock, UK, were eligible for enrolment in this phase III, randomised, double-blind, placebo-controlled trial if they were taking aspirin 75-325 mg per day with or without other cardioprotective drugs. Patients without ulcers or erosive oesophagitis on endoscopy at baseline were randomly assigned by computer-generated randomisation sequence to receive famotidine 20 mg twice daily (n=204) or placebo twice daily (n=200). Patients had a final endoscopic examination at 12 weeks. The primary endpoint was the development of new ulcers in the stomach or duodenum or erosive oesophagitis at 12 weeks after randomisation. Analysis was by intention to treat, including all randomised patients who received at least one dose of study drug (famotidine or placebo). This trial is registered as an International Standard Randomised Clinical Trial, number ISRCTN96975557.All randomised patients received at least one dose and were included in the ITT population. 82 patients (famotidine, n=33; placebo, n=49) did not have the final endoscopic examination and were assumed to have had normal findings; the main reason for participant withdrawal was refusal to continue. At 12 weeks, comparing patients assigned to famotidine with patients assigned to placebo, gastric ulcers had developed in seven (3.4%) of 204 patients compared with 30 (15.0%) of 200 patients (odds ratio [OR] 0.20, 95% CI 0.09-0.47; p=0.0002); duodenal ulcers had developed in one (0.5%) patient compared with 17 (8.5%; OR 0.05, 0.01-0.40; p=0.0045); and erosive oesophagitis in nine (4.4%) compared with 38 (19.0%; OR 0.20, 0.09-0.42; p<0.0001), respectively. There were fewer adverse events in the famotidine group than in the placebo group (nine vs 15); four patients in the placebo group were admitted to hospital with upper gastrointestinal haemorrhage. The other most common adverse event was angina (famotidine, n=2; placebo, n=4).Famotidine is effective in the prevention of gastric and duodenal ulcers, and erosive oesophagitis in patients taking low-dose aspirin. These findings widen the therapeutic options for the prevention of gastrointestinal damage in patients needing vascular protection.Merck Laboratories and Astellas Pharma.","Famotidine for the prevention of peptic ulcers and oesophagitis in patients taking low-dose aspirin (FAMOUS): a phase III, randomised, double-blind, placebo-controlled trial."
"1077","Lancet.123","2.00E-04",19577798,2009,"There are few therapeutic options for the prevention of gastrointestinal mucosal damage caused by low-dose aspirin. We therefore investigated the efficacy of famotidine, a well-tolerated histamine H(2)-receptor antagonist, in the prevention of peptic ulcers and erosive oesophagitis in patients receiving low-dose aspirin for vascular protection.Adult patients (aged >/=18 years) from the cardiovascular, cerebrovascular, and diabetes clinics at Crosshouse Hospital, Kilmarnock, UK, were eligible for enrolment in this phase III, randomised, double-blind, placebo-controlled trial if they were taking aspirin 75-325 mg per day with or without other cardioprotective drugs. Patients without ulcers or erosive oesophagitis on endoscopy at baseline were randomly assigned by computer-generated randomisation sequence to receive famotidine 20 mg twice daily (n=204) or placebo twice daily (n=200). Patients had a final endoscopic examination at 12 weeks. The primary endpoint was the development of new ulcers in the stomach or duodenum or erosive oesophagitis at 12 weeks after randomisation. Analysis was by intention to treat, including all randomised patients who received at least one dose of study drug (famotidine or placebo). This trial is registered as an International Standard Randomised Clinical Trial, number ISRCTN96975557.All randomised patients received at least one dose and were included in the ITT population. 82 patients (famotidine, n=33; placebo, n=49) did not have the final endoscopic examination and were assumed to have had normal findings; the main reason for participant withdrawal was refusal to continue. At 12 weeks, comparing patients assigned to famotidine with patients assigned to placebo, gastric ulcers had developed in seven (3.4%) of 204 patients compared with 30 (15.0%) of 200 patients (odds ratio [OR] 0.20, 95% CI 0.09-0.47; p=0.0002); duodenal ulcers had developed in one (0.5%) patient compared with 17 (8.5%; OR 0.05, 0.01-0.40; p=0.0045); and erosive oesophagitis in nine (4.4%) compared with 38 (19.0%; OR 0.20, 0.09-0.42; p<0.0001), respectively. There were fewer adverse events in the famotidine group than in the placebo group (nine vs 15); four patients in the placebo group were admitted to hospital with upper gastrointestinal haemorrhage. The other most common adverse event was angina (famotidine, n=2; placebo, n=4).Famotidine is effective in the prevention of gastric and duodenal ulcers, and erosive oesophagitis in patients taking low-dose aspirin. These findings widen the therapeutic options for the prevention of gastrointestinal damage in patients needing vascular protection.Merck Laboratories and Astellas Pharma.","Famotidine for the prevention of peptic ulcers and oesophagitis in patients taking low-dose aspirin (FAMOUS): a phase III, randomised, double-blind, placebo-controlled trial."
"1078","Lancet.124","0.0045",19577798,2009,"There are few therapeutic options for the prevention of gastrointestinal mucosal damage caused by low-dose aspirin. We therefore investigated the efficacy of famotidine, a well-tolerated histamine H(2)-receptor antagonist, in the prevention of peptic ulcers and erosive oesophagitis in patients receiving low-dose aspirin for vascular protection.Adult patients (aged >/=18 years) from the cardiovascular, cerebrovascular, and diabetes clinics at Crosshouse Hospital, Kilmarnock, UK, were eligible for enrolment in this phase III, randomised, double-blind, placebo-controlled trial if they were taking aspirin 75-325 mg per day with or without other cardioprotective drugs. Patients without ulcers or erosive oesophagitis on endoscopy at baseline were randomly assigned by computer-generated randomisation sequence to receive famotidine 20 mg twice daily (n=204) or placebo twice daily (n=200). Patients had a final endoscopic examination at 12 weeks. The primary endpoint was the development of new ulcers in the stomach or duodenum or erosive oesophagitis at 12 weeks after randomisation. Analysis was by intention to treat, including all randomised patients who received at least one dose of study drug (famotidine or placebo). This trial is registered as an International Standard Randomised Clinical Trial, number ISRCTN96975557.All randomised patients received at least one dose and were included in the ITT population. 82 patients (famotidine, n=33; placebo, n=49) did not have the final endoscopic examination and were assumed to have had normal findings; the main reason for participant withdrawal was refusal to continue. At 12 weeks, comparing patients assigned to famotidine with patients assigned to placebo, gastric ulcers had developed in seven (3.4%) of 204 patients compared with 30 (15.0%) of 200 patients (odds ratio [OR] 0.20, 95% CI 0.09-0.47; p=0.0002); duodenal ulcers had developed in one (0.5%) patient compared with 17 (8.5%; OR 0.05, 0.01-0.40; p=0.0045); and erosive oesophagitis in nine (4.4%) compared with 38 (19.0%; OR 0.20, 0.09-0.42; p<0.0001), respectively. There were fewer adverse events in the famotidine group than in the placebo group (nine vs 15); four patients in the placebo group were admitted to hospital with upper gastrointestinal haemorrhage. The other most common adverse event was angina (famotidine, n=2; placebo, n=4).Famotidine is effective in the prevention of gastric and duodenal ulcers, and erosive oesophagitis in patients taking low-dose aspirin. These findings widen the therapeutic options for the prevention of gastrointestinal damage in patients needing vascular protection.Merck Laboratories and Astellas Pharma.","Famotidine for the prevention of peptic ulcers and oesophagitis in patients taking low-dose aspirin (FAMOUS): a phase III, randomised, double-blind, placebo-controlled trial."
"1079","Lancet.211","0.0045",19595447,2009,"The introduction of second-generation antipsychotic drugs during the 1990s is widely believed to have adversely affected mortality of patients with schizophrenia. Our aim was to establish the long-term contribution of antipsychotic drugs to mortality in such patients.Nationwide registers in Finland were used to compare the cause-specific mortality in 66 881 patients versus the total population (5.2 million) between 1996, and 2006, and to link these data with the use of antipsychotic drugs. We measured the all-cause mortality of patients with schizophrenia in outpatient care during current and cumulative exposure to any antipsychotic drug versus no use of these drugs, and exposure to the six most frequently used antipsychotic drugs compared with perphenazine use.Although the proportional use of second-generation antipsychotic drugs rose from 13% to 64% during follow-up, the gap in life expectancy between patients with schizophrenia and the general population did not widen between 1996 (25 years), and 2006 (22.5 years). Compared with current use of perphenazine, the highest risk for overall mortality was recorded for quetiapine (adjusted hazard ratio [HR] 1.41, 95% CI 1.09-1.82), and the lowest risk for clozapine (0.74, 0.60-0.91; p=0.0045 for the difference between clozapine vs perphenazine, and p<0.0001 for all other antipsychotic drugs). Long-term cumulative exposure (7-11 years) to any antipsychotic treatment was associated with lower mortality than was no drug use (0.81, 0.77-0.84). In patients with one or more filled prescription for an antipsychotic drug, an inverse relation between mortality and duration of cumulative use was noted (HR for trend per exposure year 0.991; 0.985-0.997).Long-term treatment with antipsychotic drugs is associated with lower mortality compared with no antipsychotic use. Second-generation drugs are a highly heterogeneous group, and clozapine seems to be associated with a substantially lower mortality than any other antipsychotics. Restrictions on the use of clozapine should be reassessed.Annual EVO Financing (Special government subsidies from the Ministry of Health and Welfare, Finland).","11-year follow-up of mortality in patients with schizophrenia: a population-based cohort study (FIN11 study)."
"1080","JAMA.4961","0.001",19602686,2009,"Gliomas, particularly glioblastomas, are among the deadliest of human tumors. Gliomas emerge through the accumulation of recurrent chromosomal alterations, some of which target yet-to-be-discovered cancer genes. A persistent question concerns the biological basis for the coselection of these alterations during gliomagenesis.To describe a network model of a cooperative genetic landscape in gliomas and to evaluate its clinical relevance.Multidimensional genomic profiles and clinical profiles of 501 patients with gliomas (45 tumors in an initial discovery set collected between 2001 and 2004 and 456 tumors in validation sets made public between 2006 and 2008) from multiple academic centers in the United States and The Cancer Genome Atlas Pilot Project (TCGA).Identification of genes with coincident genetic alterations, correlated gene dosage and gene expression, and multiple functional interactions; association between those genes and patient survival.Gliomas select for a nonrandom genetic landscape-a consistent pattern of chromosomal alterations-that involves altered regions (""territories"") on chromosomes 1p, 7, 8q, 9p, 10, 12q, 13q, 19q, 20, and 22q (false-discovery rate-corrected P<.05). A network model shows that these territories harbor genes with putative synergistic, tumor-promoting relationships. The coalteration of the most interactive of these genes in glioblastoma is associated with unfavorable patient survival. A multigene risk scoring model based on 7 landscape genes (POLD2, CYCS, MYC, AKR1C3, YME1L1, ANXA7, and PDCD4) is associated with the duration of overall survival in 189 glioblastoma samples from TCGA (global log-rank P = .02 comparing 3 survival curves for patients with 0-2, 3-4, and 5-7 dosage-altered genes). Groups of patients with 0 to 2 (low-risk group) and 5 to 7 (high-risk group) dosage-altered genes experienced 49.24 and 79.56 deaths per 100 person-years (hazard ratio [HR], 1.63; 95% confidence interval [CI], 1.10-2.40; Cox regression model P = .02), respectively. These associations with survival are validated using gene expression data in 3 independent glioma studies, comprising 76 (global log-rank P = .003; 47.89 vs 15.13 deaths per 100 person-years for high risk vs low risk; Cox model HR, 3.04; 95% CI, 1.49-6.20; P = .002) and 70 (global log-rank P = .008; 83.43 vs 16.14 deaths per 100 person-years for high risk vs low risk; HR, 3.86; 95% CI, 1.59-9.35; P = .003) high-grade gliomas and 191 glioblastomas (global log-rank P = .002; 83.23 vs 34.16 deaths per 100 person-years for high risk vs low risk; HR, 2.27; 95% CI, 1.44-3.58; P<.001).The alteration of multiple networking genes by recurrent chromosomal aberrations in gliomas deregulates critical signaling pathways through multiple, cooperative mechanisms. These mutations, which are likely due to nonrandom selection of a distinct genetic landscape during gliomagenesis, are associated with patient prognosis.","A network model of a cooperative genetic landscape in brain tumors."
"1081","JAMA.5321","0.02",19602686,2009,"Gliomas, particularly glioblastomas, are among the deadliest of human tumors. Gliomas emerge through the accumulation of recurrent chromosomal alterations, some of which target yet-to-be-discovered cancer genes. A persistent question concerns the biological basis for the coselection of these alterations during gliomagenesis.To describe a network model of a cooperative genetic landscape in gliomas and to evaluate its clinical relevance.Multidimensional genomic profiles and clinical profiles of 501 patients with gliomas (45 tumors in an initial discovery set collected between 2001 and 2004 and 456 tumors in validation sets made public between 2006 and 2008) from multiple academic centers in the United States and The Cancer Genome Atlas Pilot Project (TCGA).Identification of genes with coincident genetic alterations, correlated gene dosage and gene expression, and multiple functional interactions; association between those genes and patient survival.Gliomas select for a nonrandom genetic landscape-a consistent pattern of chromosomal alterations-that involves altered regions (""territories"") on chromosomes 1p, 7, 8q, 9p, 10, 12q, 13q, 19q, 20, and 22q (false-discovery rate-corrected P<.05). A network model shows that these territories harbor genes with putative synergistic, tumor-promoting relationships. The coalteration of the most interactive of these genes in glioblastoma is associated with unfavorable patient survival. A multigene risk scoring model based on 7 landscape genes (POLD2, CYCS, MYC, AKR1C3, YME1L1, ANXA7, and PDCD4) is associated with the duration of overall survival in 189 glioblastoma samples from TCGA (global log-rank P = .02 comparing 3 survival curves for patients with 0-2, 3-4, and 5-7 dosage-altered genes). Groups of patients with 0 to 2 (low-risk group) and 5 to 7 (high-risk group) dosage-altered genes experienced 49.24 and 79.56 deaths per 100 person-years (hazard ratio [HR], 1.63; 95% confidence interval [CI], 1.10-2.40; Cox regression model P = .02), respectively. These associations with survival are validated using gene expression data in 3 independent glioma studies, comprising 76 (global log-rank P = .003; 47.89 vs 15.13 deaths per 100 person-years for high risk vs low risk; Cox model HR, 3.04; 95% CI, 1.49-6.20; P = .002) and 70 (global log-rank P = .008; 83.43 vs 16.14 deaths per 100 person-years for high risk vs low risk; HR, 3.86; 95% CI, 1.59-9.35; P = .003) high-grade gliomas and 191 glioblastomas (global log-rank P = .002; 83.23 vs 34.16 deaths per 100 person-years for high risk vs low risk; HR, 2.27; 95% CI, 1.44-3.58; P<.001).The alteration of multiple networking genes by recurrent chromosomal aberrations in gliomas deregulates critical signaling pathways through multiple, cooperative mechanisms. These mutations, which are likely due to nonrandom selection of a distinct genetic landscape during gliomagenesis, are associated with patient prognosis.","A network model of a cooperative genetic landscape in brain tumors."
"1082","JAMA.5341","0.002",19602686,2009,"Gliomas, particularly glioblastomas, are among the deadliest of human tumors. Gliomas emerge through the accumulation of recurrent chromosomal alterations, some of which target yet-to-be-discovered cancer genes. A persistent question concerns the biological basis for the coselection of these alterations during gliomagenesis.To describe a network model of a cooperative genetic landscape in gliomas and to evaluate its clinical relevance.Multidimensional genomic profiles and clinical profiles of 501 patients with gliomas (45 tumors in an initial discovery set collected between 2001 and 2004 and 456 tumors in validation sets made public between 2006 and 2008) from multiple academic centers in the United States and The Cancer Genome Atlas Pilot Project (TCGA).Identification of genes with coincident genetic alterations, correlated gene dosage and gene expression, and multiple functional interactions; association between those genes and patient survival.Gliomas select for a nonrandom genetic landscape-a consistent pattern of chromosomal alterations-that involves altered regions (""territories"") on chromosomes 1p, 7, 8q, 9p, 10, 12q, 13q, 19q, 20, and 22q (false-discovery rate-corrected P<.05). A network model shows that these territories harbor genes with putative synergistic, tumor-promoting relationships. The coalteration of the most interactive of these genes in glioblastoma is associated with unfavorable patient survival. A multigene risk scoring model based on 7 landscape genes (POLD2, CYCS, MYC, AKR1C3, YME1L1, ANXA7, and PDCD4) is associated with the duration of overall survival in 189 glioblastoma samples from TCGA (global log-rank P = .02 comparing 3 survival curves for patients with 0-2, 3-4, and 5-7 dosage-altered genes). Groups of patients with 0 to 2 (low-risk group) and 5 to 7 (high-risk group) dosage-altered genes experienced 49.24 and 79.56 deaths per 100 person-years (hazard ratio [HR], 1.63; 95% confidence interval [CI], 1.10-2.40; Cox regression model P = .02), respectively. These associations with survival are validated using gene expression data in 3 independent glioma studies, comprising 76 (global log-rank P = .003; 47.89 vs 15.13 deaths per 100 person-years for high risk vs low risk; Cox model HR, 3.04; 95% CI, 1.49-6.20; P = .002) and 70 (global log-rank P = .008; 83.43 vs 16.14 deaths per 100 person-years for high risk vs low risk; HR, 3.86; 95% CI, 1.59-9.35; P = .003) high-grade gliomas and 191 glioblastomas (global log-rank P = .002; 83.23 vs 34.16 deaths per 100 person-years for high risk vs low risk; HR, 2.27; 95% CI, 1.44-3.58; P<.001).The alteration of multiple networking genes by recurrent chromosomal aberrations in gliomas deregulates critical signaling pathways through multiple, cooperative mechanisms. These mutations, which are likely due to nonrandom selection of a distinct genetic landscape during gliomagenesis, are associated with patient prognosis.","A network model of a cooperative genetic landscape in brain tumors."
"1083","JAMA.5351","0.003",19602686,2009,"Gliomas, particularly glioblastomas, are among the deadliest of human tumors. Gliomas emerge through the accumulation of recurrent chromosomal alterations, some of which target yet-to-be-discovered cancer genes. A persistent question concerns the biological basis for the coselection of these alterations during gliomagenesis.To describe a network model of a cooperative genetic landscape in gliomas and to evaluate its clinical relevance.Multidimensional genomic profiles and clinical profiles of 501 patients with gliomas (45 tumors in an initial discovery set collected between 2001 and 2004 and 456 tumors in validation sets made public between 2006 and 2008) from multiple academic centers in the United States and The Cancer Genome Atlas Pilot Project (TCGA).Identification of genes with coincident genetic alterations, correlated gene dosage and gene expression, and multiple functional interactions; association between those genes and patient survival.Gliomas select for a nonrandom genetic landscape-a consistent pattern of chromosomal alterations-that involves altered regions (""territories"") on chromosomes 1p, 7, 8q, 9p, 10, 12q, 13q, 19q, 20, and 22q (false-discovery rate-corrected P<.05). A network model shows that these territories harbor genes with putative synergistic, tumor-promoting relationships. The coalteration of the most interactive of these genes in glioblastoma is associated with unfavorable patient survival. A multigene risk scoring model based on 7 landscape genes (POLD2, CYCS, MYC, AKR1C3, YME1L1, ANXA7, and PDCD4) is associated with the duration of overall survival in 189 glioblastoma samples from TCGA (global log-rank P = .02 comparing 3 survival curves for patients with 0-2, 3-4, and 5-7 dosage-altered genes). Groups of patients with 0 to 2 (low-risk group) and 5 to 7 (high-risk group) dosage-altered genes experienced 49.24 and 79.56 deaths per 100 person-years (hazard ratio [HR], 1.63; 95% confidence interval [CI], 1.10-2.40; Cox regression model P = .02), respectively. These associations with survival are validated using gene expression data in 3 independent glioma studies, comprising 76 (global log-rank P = .003; 47.89 vs 15.13 deaths per 100 person-years for high risk vs low risk; Cox model HR, 3.04; 95% CI, 1.49-6.20; P = .002) and 70 (global log-rank P = .008; 83.43 vs 16.14 deaths per 100 person-years for high risk vs low risk; HR, 3.86; 95% CI, 1.59-9.35; P = .003) high-grade gliomas and 191 glioblastomas (global log-rank P = .002; 83.23 vs 34.16 deaths per 100 person-years for high risk vs low risk; HR, 2.27; 95% CI, 1.44-3.58; P<.001).The alteration of multiple networking genes by recurrent chromosomal aberrations in gliomas deregulates critical signaling pathways through multiple, cooperative mechanisms. These mutations, which are likely due to nonrandom selection of a distinct genetic landscape during gliomagenesis, are associated with patient prognosis.","A network model of a cooperative genetic landscape in brain tumors."
"1084","JAMA.5291","0.008",19602687,2009,"Glioblastomas--uniformly fatal brain tumors--often have both monosomy of chromosome 10 and gains of the epidermal growth factor receptor (EGFR) gene locus on chromosome 7, an association for which the mechanism is poorly understood.To assess whether coselection of EGFR gains on 7p12 and monosomy 10 in glioblastomas promotes tumorigenic epidermal growth factor (EGF) signaling through loss of the annexin A7 (ANXA7) gene on 10q21.1-q21.2 and whether ANXA7 acts as a tumor suppressor gene by regulating EGFR in glioblastomas.Multidimensional analysis of gene, coding sequence, promoter methylation, messenger RNA (mRNA) transcript, protein data for ANXA7 (and EGFR), and clinical patient data profiles of 543 high-grade gliomas from US medical centers and The Cancer Genome Atlas pilot project (made public 2006-2008; and unpublished, tumors collected 2001-2008). Functional analyses using LN229 and U87 glioblastoma cells.Associations among ANXA7 gene dosage, coding sequence, promoter methylation, mRNA transcript, and protein expression. Effect of ANXA7 haploinsufficiency on EGFR signaling and patient survival. Joint effects of loss of ANXA7 and gain of EGFR expression on tumorigenesis.Heterozygous ANXA7 gene deletion is associated with significant loss of ANXA7 mRNA transcript expression (P = 1 x 10(-15); linear regression) and a reduction (mean [SEM]) of 91.5% (2.3%) of ANXA7 protein expression compared with ANXA7 wild-type glioblastomas (P = .004; unpaired t test). ANXA7 loss of function stabilizes the EGFR protein (72%-744% increase in EGFR protein abundance) and augments EGFR transforming signaling in glioblastoma cells. ANXA7 haploinsufficiency doubles tumorigenic potential of glioblastoma cells, and combined ANXA7 knockdown and EGFR overexpression promotes tumorigenicity synergistically. The heterozygous loss of ANXA7 in approximately 75% of glioblastomas in the The Cancer Genome Atlas plus infrequency of ANXA7 mutation (approximately 6% of tumors) indicates its role as a haploinsufficiency gene. ANXA7 mRNA transcript expression, dichotomized at the median, associates with patient survival in 191 glioblastomas (log-rank P = .008; hazard ratio [HR], 0.667; 95% confidence interval [CI], 0.493-0.902; 46.9 vs 74.8 deaths/100 person-years for high vs low ANXA7 mRNA expression) and with a separate group of 180 high-grade gliomas (log-rank P = .00003; HR, 0.476; 95% CI, 0.333-0.680; 21.8 vs 50.0 deaths/100 person-years for high vs low ANXA7 mRNA expression). Deletion of the ANXA7 gene associates with poor patient survival in 189 glioblastomas (log-rank P = .042; HR, 0.686; 95% CI, 0.476-0.989; 54.0 vs 80.1 deaths/100 person-years for wild-type ANXA7 vs ANXA7 deletion).Haploinsufficiency of the tumor suppressor ANXA7 due to monosomy of chromosome 10 provides a clinically relevant mechanism to augment EGFR signaling in glioblastomas beyond that resulting from amplification of the EGFR gene.","Monosomy of chromosome 10 associated with dysregulation of epidermal growth factor signaling in glioblastomas."
"1085","JAMA.5301","3.00E-05",19602687,2009,"Glioblastomas--uniformly fatal brain tumors--often have both monosomy of chromosome 10 and gains of the epidermal growth factor receptor (EGFR) gene locus on chromosome 7, an association for which the mechanism is poorly understood.To assess whether coselection of EGFR gains on 7p12 and monosomy 10 in glioblastomas promotes tumorigenic epidermal growth factor (EGF) signaling through loss of the annexin A7 (ANXA7) gene on 10q21.1-q21.2 and whether ANXA7 acts as a tumor suppressor gene by regulating EGFR in glioblastomas.Multidimensional analysis of gene, coding sequence, promoter methylation, messenger RNA (mRNA) transcript, protein data for ANXA7 (and EGFR), and clinical patient data profiles of 543 high-grade gliomas from US medical centers and The Cancer Genome Atlas pilot project (made public 2006-2008; and unpublished, tumors collected 2001-2008). Functional analyses using LN229 and U87 glioblastoma cells.Associations among ANXA7 gene dosage, coding sequence, promoter methylation, mRNA transcript, and protein expression. Effect of ANXA7 haploinsufficiency on EGFR signaling and patient survival. Joint effects of loss of ANXA7 and gain of EGFR expression on tumorigenesis.Heterozygous ANXA7 gene deletion is associated with significant loss of ANXA7 mRNA transcript expression (P = 1 x 10(-15); linear regression) and a reduction (mean [SEM]) of 91.5% (2.3%) of ANXA7 protein expression compared with ANXA7 wild-type glioblastomas (P = .004; unpaired t test). ANXA7 loss of function stabilizes the EGFR protein (72%-744% increase in EGFR protein abundance) and augments EGFR transforming signaling in glioblastoma cells. ANXA7 haploinsufficiency doubles tumorigenic potential of glioblastoma cells, and combined ANXA7 knockdown and EGFR overexpression promotes tumorigenicity synergistically. The heterozygous loss of ANXA7 in approximately 75% of glioblastomas in the The Cancer Genome Atlas plus infrequency of ANXA7 mutation (approximately 6% of tumors) indicates its role as a haploinsufficiency gene. ANXA7 mRNA transcript expression, dichotomized at the median, associates with patient survival in 191 glioblastomas (log-rank P = .008; hazard ratio [HR], 0.667; 95% confidence interval [CI], 0.493-0.902; 46.9 vs 74.8 deaths/100 person-years for high vs low ANXA7 mRNA expression) and with a separate group of 180 high-grade gliomas (log-rank P = .00003; HR, 0.476; 95% CI, 0.333-0.680; 21.8 vs 50.0 deaths/100 person-years for high vs low ANXA7 mRNA expression). Deletion of the ANXA7 gene associates with poor patient survival in 189 glioblastomas (log-rank P = .042; HR, 0.686; 95% CI, 0.476-0.989; 54.0 vs 80.1 deaths/100 person-years for wild-type ANXA7 vs ANXA7 deletion).Haploinsufficiency of the tumor suppressor ANXA7 due to monosomy of chromosome 10 provides a clinically relevant mechanism to augment EGFR signaling in glioblastomas beyond that resulting from amplification of the EGFR gene.","Monosomy of chromosome 10 associated with dysregulation of epidermal growth factor signaling in glioblastomas."
"1086","JAMA.5311","0.042",19602687,2009,"Glioblastomas--uniformly fatal brain tumors--often have both monosomy of chromosome 10 and gains of the epidermal growth factor receptor (EGFR) gene locus on chromosome 7, an association for which the mechanism is poorly understood.To assess whether coselection of EGFR gains on 7p12 and monosomy 10 in glioblastomas promotes tumorigenic epidermal growth factor (EGF) signaling through loss of the annexin A7 (ANXA7) gene on 10q21.1-q21.2 and whether ANXA7 acts as a tumor suppressor gene by regulating EGFR in glioblastomas.Multidimensional analysis of gene, coding sequence, promoter methylation, messenger RNA (mRNA) transcript, protein data for ANXA7 (and EGFR), and clinical patient data profiles of 543 high-grade gliomas from US medical centers and The Cancer Genome Atlas pilot project (made public 2006-2008; and unpublished, tumors collected 2001-2008). Functional analyses using LN229 and U87 glioblastoma cells.Associations among ANXA7 gene dosage, coding sequence, promoter methylation, mRNA transcript, and protein expression. Effect of ANXA7 haploinsufficiency on EGFR signaling and patient survival. Joint effects of loss of ANXA7 and gain of EGFR expression on tumorigenesis.Heterozygous ANXA7 gene deletion is associated with significant loss of ANXA7 mRNA transcript expression (P = 1 x 10(-15); linear regression) and a reduction (mean [SEM]) of 91.5% (2.3%) of ANXA7 protein expression compared with ANXA7 wild-type glioblastomas (P = .004; unpaired t test). ANXA7 loss of function stabilizes the EGFR protein (72%-744% increase in EGFR protein abundance) and augments EGFR transforming signaling in glioblastoma cells. ANXA7 haploinsufficiency doubles tumorigenic potential of glioblastoma cells, and combined ANXA7 knockdown and EGFR overexpression promotes tumorigenicity synergistically. The heterozygous loss of ANXA7 in approximately 75% of glioblastomas in the The Cancer Genome Atlas plus infrequency of ANXA7 mutation (approximately 6% of tumors) indicates its role as a haploinsufficiency gene. ANXA7 mRNA transcript expression, dichotomized at the median, associates with patient survival in 191 glioblastomas (log-rank P = .008; hazard ratio [HR], 0.667; 95% confidence interval [CI], 0.493-0.902; 46.9 vs 74.8 deaths/100 person-years for high vs low ANXA7 mRNA expression) and with a separate group of 180 high-grade gliomas (log-rank P = .00003; HR, 0.476; 95% CI, 0.333-0.680; 21.8 vs 50.0 deaths/100 person-years for high vs low ANXA7 mRNA expression). Deletion of the ANXA7 gene associates with poor patient survival in 189 glioblastomas (log-rank P = .042; HR, 0.686; 95% CI, 0.476-0.989; 54.0 vs 80.1 deaths/100 person-years for wild-type ANXA7 vs ANXA7 deletion).Haploinsufficiency of the tumor suppressor ANXA7 due to monosomy of chromosome 10 provides a clinically relevant mechanism to augment EGFR signaling in glioblastomas beyond that resulting from amplification of the EGFR gene.","Monosomy of chromosome 10 associated with dysregulation of epidermal growth factor signaling in glioblastomas."
"1087","Lancet.208","0.24",19632716,2009,"Results from phase II studies in patients with stage IIIA non-small-cell lung cancer with ipsilateral mediastinal nodal metastases (N2) have shown the feasibility of resection after concurrent chemotherapy and radiotherapy with promising rates of survival. We therefore did this phase III trial to compare concurrent chemotherapy and radiotherapy followed by resection with standard concurrent chemotherapy and definitive radiotherapy without resection.Patients with stage T1-3pN2M0 non-small-cell lung cancer were randomly assigned in a 1:1 ratio to concurrent induction chemotherapy (two cycles of cisplatin [50 mg/m(2) on days 1, 8, 29, and 36] and etoposide [50 mg/m(2) on days 1-5 and 29-33]) plus radiotherapy (45 Gy) in multiple academic and community hospitals. If no progression, patients in group 1 underwent resection and those in group 2 continued radiotherapy uninterrupted up to 61 Gy. Two additional cycles of cisplatin and etoposide were given in both groups. The primary endpoint was overall survival (OS). Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00002550.202 patients (median age 59 years, range 31-77) were assigned to group 1 and 194 (61 years, 32-78) to group 2. Median OS was 23.6 months (IQR 9.0-not reached) in group 1 versus 22.2 months (9.4-52.7) in group 2 (hazard ratio [HR] 0.87 [0.70-1.10]; p=0.24). Number of patients alive at 5 years was 37 (point estimate 27%) in group 1 and 24 (point estimate 20%) in group 2 (odds ratio 0.63 [0.36-1.10]; p=0.10). With N0 status at thoracotomy, the median OS was 34.4 months (IQR 15.7-not reached; 19 [point estimate 41%] patients alive at 5 years). Progression-free survival (PFS) was better in group 1 than in group 2, median 12.8 months (5.3-42.2) vs 10.5 months (4.8-20.6), HR 0.77 [0.62-0.96]; p=0.017); the number of patients without disease progression at 5 years was 32 (point estimate 22%) versus 13 (point estimate 11%), respectively. Neutropenia and oesophagitis were the main grade 3 or 4 toxicities associated with chemotherapy plus radiotherapy in group 1 (77 [38%] and 20 [10%], respectively) and group 2 (80 [41%] and 44 [23%], respectively). In group 1, 16 (8%) deaths were treatment related versus four (2%) in group 2. In an exploratory analysis, OS was improved for patients who underwent lobectomy, but not pneumonectomy, versus chemotherapy plus radiotherapy.Chemotherapy plus radiotherapy with or without resection (preferably lobectomy) are options for patients with stage IIIA(N2) non-small-cell lung cancer.National Cancer Institute, Canadian Cancer Society, and National Cancer Institute of Canada.","Radiotherapy plus chemotherapy with or without surgical resection for stage III non-small-cell lung cancer: a phase III randomised controlled trial."
"1088","Lancet.209","0.1",19632716,2009,"Results from phase II studies in patients with stage IIIA non-small-cell lung cancer with ipsilateral mediastinal nodal metastases (N2) have shown the feasibility of resection after concurrent chemotherapy and radiotherapy with promising rates of survival. We therefore did this phase III trial to compare concurrent chemotherapy and radiotherapy followed by resection with standard concurrent chemotherapy and definitive radiotherapy without resection.Patients with stage T1-3pN2M0 non-small-cell lung cancer were randomly assigned in a 1:1 ratio to concurrent induction chemotherapy (two cycles of cisplatin [50 mg/m(2) on days 1, 8, 29, and 36] and etoposide [50 mg/m(2) on days 1-5 and 29-33]) plus radiotherapy (45 Gy) in multiple academic and community hospitals. If no progression, patients in group 1 underwent resection and those in group 2 continued radiotherapy uninterrupted up to 61 Gy. Two additional cycles of cisplatin and etoposide were given in both groups. The primary endpoint was overall survival (OS). Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00002550.202 patients (median age 59 years, range 31-77) were assigned to group 1 and 194 (61 years, 32-78) to group 2. Median OS was 23.6 months (IQR 9.0-not reached) in group 1 versus 22.2 months (9.4-52.7) in group 2 (hazard ratio [HR] 0.87 [0.70-1.10]; p=0.24). Number of patients alive at 5 years was 37 (point estimate 27%) in group 1 and 24 (point estimate 20%) in group 2 (odds ratio 0.63 [0.36-1.10]; p=0.10). With N0 status at thoracotomy, the median OS was 34.4 months (IQR 15.7-not reached; 19 [point estimate 41%] patients alive at 5 years). Progression-free survival (PFS) was better in group 1 than in group 2, median 12.8 months (5.3-42.2) vs 10.5 months (4.8-20.6), HR 0.77 [0.62-0.96]; p=0.017); the number of patients without disease progression at 5 years was 32 (point estimate 22%) versus 13 (point estimate 11%), respectively. Neutropenia and oesophagitis were the main grade 3 or 4 toxicities associated with chemotherapy plus radiotherapy in group 1 (77 [38%] and 20 [10%], respectively) and group 2 (80 [41%] and 44 [23%], respectively). In group 1, 16 (8%) deaths were treatment related versus four (2%) in group 2. In an exploratory analysis, OS was improved for patients who underwent lobectomy, but not pneumonectomy, versus chemotherapy plus radiotherapy.Chemotherapy plus radiotherapy with or without resection (preferably lobectomy) are options for patients with stage IIIA(N2) non-small-cell lung cancer.National Cancer Institute, Canadian Cancer Society, and National Cancer Institute of Canada.","Radiotherapy plus chemotherapy with or without surgical resection for stage III non-small-cell lung cancer: a phase III randomised controlled trial."
"1089","Lancet.210","0.017",19632716,2009,"Results from phase II studies in patients with stage IIIA non-small-cell lung cancer with ipsilateral mediastinal nodal metastases (N2) have shown the feasibility of resection after concurrent chemotherapy and radiotherapy with promising rates of survival. We therefore did this phase III trial to compare concurrent chemotherapy and radiotherapy followed by resection with standard concurrent chemotherapy and definitive radiotherapy without resection.Patients with stage T1-3pN2M0 non-small-cell lung cancer were randomly assigned in a 1:1 ratio to concurrent induction chemotherapy (two cycles of cisplatin [50 mg/m(2) on days 1, 8, 29, and 36] and etoposide [50 mg/m(2) on days 1-5 and 29-33]) plus radiotherapy (45 Gy) in multiple academic and community hospitals. If no progression, patients in group 1 underwent resection and those in group 2 continued radiotherapy uninterrupted up to 61 Gy. Two additional cycles of cisplatin and etoposide were given in both groups. The primary endpoint was overall survival (OS). Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00002550.202 patients (median age 59 years, range 31-77) were assigned to group 1 and 194 (61 years, 32-78) to group 2. Median OS was 23.6 months (IQR 9.0-not reached) in group 1 versus 22.2 months (9.4-52.7) in group 2 (hazard ratio [HR] 0.87 [0.70-1.10]; p=0.24). Number of patients alive at 5 years was 37 (point estimate 27%) in group 1 and 24 (point estimate 20%) in group 2 (odds ratio 0.63 [0.36-1.10]; p=0.10). With N0 status at thoracotomy, the median OS was 34.4 months (IQR 15.7-not reached; 19 [point estimate 41%] patients alive at 5 years). Progression-free survival (PFS) was better in group 1 than in group 2, median 12.8 months (5.3-42.2) vs 10.5 months (4.8-20.6), HR 0.77 [0.62-0.96]; p=0.017); the number of patients without disease progression at 5 years was 32 (point estimate 22%) versus 13 (point estimate 11%), respectively. Neutropenia and oesophagitis were the main grade 3 or 4 toxicities associated with chemotherapy plus radiotherapy in group 1 (77 [38%] and 20 [10%], respectively) and group 2 (80 [41%] and 44 [23%], respectively). In group 1, 16 (8%) deaths were treatment related versus four (2%) in group 2. In an exploratory analysis, OS was improved for patients who underwent lobectomy, but not pneumonectomy, versus chemotherapy plus radiotherapy.Chemotherapy plus radiotherapy with or without resection (preferably lobectomy) are options for patients with stage IIIA(N2) non-small-cell lung cancer.National Cancer Institute, Canadian Cancer Society, and National Cancer Institute of Canada.","Radiotherapy plus chemotherapy with or without surgical resection for stage III non-small-cell lung cancer: a phase III randomised controlled trial."
"1090","JAMA.5241","0.008",19671904,2009,"Both higher adherence to a Mediterranean-type diet and more physical activity have been independently associated with lower Alzheimer disease (AD) risk but their combined association has not been investigated.To investigate the combined association of diet and physical activity with AD risk.Prospective cohort study of 2 cohorts comprising 1880 community-dwelling elders without dementia living in New York, New York, with both diet and physical activity information available. Standardized neurological and neuropsychological measures were administered approximately every 1.5 years from 1992 through 2006. Adherence to a Mediterranean-type diet (scale of 0-9; trichotomized into low, middle, or high; and dichotomized into low or high) and physical activity (sum of weekly participation in various physical activities, weighted by the type of physical activity [light, moderate, vigorous]; trichotomized into no physical activity, some, or much; and dichotomized into low or high), separately and combined, were the main predictors in Cox models. Models were adjusted for cohort, age, sex, ethnicity, education, apolipoprotein E genotype, caloric intake, body mass index, smoking status, depression, leisure activities, a comorbidity index, and baseline Clinical Dementia Rating score.Time to incident AD.A total of 282 incident AD cases occurred during a mean (SD) of 5.4 (3.3) years of follow-up. When considered simultaneously, both Mediterranean-type diet adherence (compared with low diet score, hazard ratio [HR] for middle diet score was 0.98 [95% confidence interval {CI}, 0.72-1.33]; the HR for high diet score was 0.60 [95% CI, 0.42-0.87]; P = .008 for trend) and physical activity (compared with no physical activity, the HR for some physical activity was 0.75 [95% CI, 0.54-1.04]; the HR for much physical activity was 0.67 [95% CI, 0.47-0.95]; P = .03 for trend) were associated with lower AD risk. Compared with individuals neither adhering to the diet nor participating in physical activity (low diet score and no physical activity; absolute AD risk of 19%), those both adhering to the diet and participating in physical activity (high diet score and high physical activity) had a lower risk of AD (absolute risk, 12%; HR, 0.65 [95% CI, 0.44-0.96]; P = .03 for trend).In this study, both higher Mediterranean-type diet adherence and higher physical activity were independently associated with reduced risk for AD.","Physical activity, diet, and risk of Alzheimer disease."
"1091","JAMA.5251","0.03",19671904,2009,"Both higher adherence to a Mediterranean-type diet and more physical activity have been independently associated with lower Alzheimer disease (AD) risk but their combined association has not been investigated.To investigate the combined association of diet and physical activity with AD risk.Prospective cohort study of 2 cohorts comprising 1880 community-dwelling elders without dementia living in New York, New York, with both diet and physical activity information available. Standardized neurological and neuropsychological measures were administered approximately every 1.5 years from 1992 through 2006. Adherence to a Mediterranean-type diet (scale of 0-9; trichotomized into low, middle, or high; and dichotomized into low or high) and physical activity (sum of weekly participation in various physical activities, weighted by the type of physical activity [light, moderate, vigorous]; trichotomized into no physical activity, some, or much; and dichotomized into low or high), separately and combined, were the main predictors in Cox models. Models were adjusted for cohort, age, sex, ethnicity, education, apolipoprotein E genotype, caloric intake, body mass index, smoking status, depression, leisure activities, a comorbidity index, and baseline Clinical Dementia Rating score.Time to incident AD.A total of 282 incident AD cases occurred during a mean (SD) of 5.4 (3.3) years of follow-up. When considered simultaneously, both Mediterranean-type diet adherence (compared with low diet score, hazard ratio [HR] for middle diet score was 0.98 [95% confidence interval {CI}, 0.72-1.33]; the HR for high diet score was 0.60 [95% CI, 0.42-0.87]; P = .008 for trend) and physical activity (compared with no physical activity, the HR for some physical activity was 0.75 [95% CI, 0.54-1.04]; the HR for much physical activity was 0.67 [95% CI, 0.47-0.95]; P = .03 for trend) were associated with lower AD risk. Compared with individuals neither adhering to the diet nor participating in physical activity (low diet score and no physical activity; absolute AD risk of 19%), those both adhering to the diet and participating in physical activity (high diet score and high physical activity) had a lower risk of AD (absolute risk, 12%; HR, 0.65 [95% CI, 0.44-0.96]; P = .03 for trend).In this study, both higher Mediterranean-type diet adherence and higher physical activity were independently associated with reduced risk for AD.","Physical activity, diet, and risk of Alzheimer disease."
"1092","JAMA.5261","0.03",19671904,2009,"Both higher adherence to a Mediterranean-type diet and more physical activity have been independently associated with lower Alzheimer disease (AD) risk but their combined association has not been investigated.To investigate the combined association of diet and physical activity with AD risk.Prospective cohort study of 2 cohorts comprising 1880 community-dwelling elders without dementia living in New York, New York, with both diet and physical activity information available. Standardized neurological and neuropsychological measures were administered approximately every 1.5 years from 1992 through 2006. Adherence to a Mediterranean-type diet (scale of 0-9; trichotomized into low, middle, or high; and dichotomized into low or high) and physical activity (sum of weekly participation in various physical activities, weighted by the type of physical activity [light, moderate, vigorous]; trichotomized into no physical activity, some, or much; and dichotomized into low or high), separately and combined, were the main predictors in Cox models. Models were adjusted for cohort, age, sex, ethnicity, education, apolipoprotein E genotype, caloric intake, body mass index, smoking status, depression, leisure activities, a comorbidity index, and baseline Clinical Dementia Rating score.Time to incident AD.A total of 282 incident AD cases occurred during a mean (SD) of 5.4 (3.3) years of follow-up. When considered simultaneously, both Mediterranean-type diet adherence (compared with low diet score, hazard ratio [HR] for middle diet score was 0.98 [95% confidence interval {CI}, 0.72-1.33]; the HR for high diet score was 0.60 [95% CI, 0.42-0.87]; P = .008 for trend) and physical activity (compared with no physical activity, the HR for some physical activity was 0.75 [95% CI, 0.54-1.04]; the HR for much physical activity was 0.67 [95% CI, 0.47-0.95]; P = .03 for trend) were associated with lower AD risk. Compared with individuals neither adhering to the diet nor participating in physical activity (low diet score and no physical activity; absolute AD risk of 19%), those both adhering to the diet and participating in physical activity (high diet score and high physical activity) had a lower risk of AD (absolute risk, 12%; HR, 0.65 [95% CI, 0.44-0.96]; P = .03 for trend).In this study, both higher Mediterranean-type diet adherence and higher physical activity were independently associated with reduced risk for AD.","Physical activity, diet, and risk of Alzheimer disease."
"1093","Lancet.171","1.00E-04",19683640,2009,"Increased excretion of albumin in urine might be a marker of the various pathophysiological changes that arise in patients with heart failure. Therefore our aim was to assess the prevalence and prognostic value of a spot urinary albumin to creatinine ratio (UACR) in patients with heart failure.UACR was measured at baseline and during follow-up of 2310 patients in the Candesartan in Heart failure: Assessment of Reduction in Mortality and morbidity (CHARM) Programme. The prevalence of microalbuminuria and macroalbuminuria, and the predictive value of UACR for the primary composite outcome of each CHARM study--ie, death from cardiovascular causes or admission to hospital with worsening heart failure--and death from any cause were assessed.1349 (58%) patients had a normal UACR, 704 (30%) had microalbuminuria, and 257 (11%) had macroalbuminuria. The prevalence of increased UACR was similar in patients with reduced and preserved left ventricular ejection fractions. Patients with an increased UACR were older, had more cardiovascular comorbidity, worse renal function, and a higher prevalence of diabetes mellitus than did those with normoalbuminuria. However, a high prevalence of increased UACR was still noted among patients without diabetes, hypertension, or renal dysfunction. Elevated UACR was associated with increased risk of the composite outcome and death even after adjustment for other prognostic variables including renal function, diabetes, and haemoglobin A1c. The adjusted hazard ratio (HR) for the composite outcome in patients with microalbuminuria versus normoalbuminuria was 1.43 (95% CI 1.21-1.69; p<0.0001) and for macroalbuminuria versus normoalbuminuria was 1.75 (1.39-2.20; p<0.0001). The adjusted values for death were 1.62 (1.32-1.99; p<0.0001) for microalbuminuria versus normoalbuminuria, and 1.76 (1.32-2.35; p=0.0001) for macroalbuminuria versus normoalbuminuria. Treatment with candesartan did not reduce or prevent the development of excessive excretion of urinary albumin.Increased UACR is a powerful and independent predictor of prognosis in heart failure.AstraZeneca.","Albuminuria in chronic heart failure: prevalence and prognostic importance."
"1094","Lancet.172","1.00E-04",19683640,2009,"Increased excretion of albumin in urine might be a marker of the various pathophysiological changes that arise in patients with heart failure. Therefore our aim was to assess the prevalence and prognostic value of a spot urinary albumin to creatinine ratio (UACR) in patients with heart failure.UACR was measured at baseline and during follow-up of 2310 patients in the Candesartan in Heart failure: Assessment of Reduction in Mortality and morbidity (CHARM) Programme. The prevalence of microalbuminuria and macroalbuminuria, and the predictive value of UACR for the primary composite outcome of each CHARM study--ie, death from cardiovascular causes or admission to hospital with worsening heart failure--and death from any cause were assessed.1349 (58%) patients had a normal UACR, 704 (30%) had microalbuminuria, and 257 (11%) had macroalbuminuria. The prevalence of increased UACR was similar in patients with reduced and preserved left ventricular ejection fractions. Patients with an increased UACR were older, had more cardiovascular comorbidity, worse renal function, and a higher prevalence of diabetes mellitus than did those with normoalbuminuria. However, a high prevalence of increased UACR was still noted among patients without diabetes, hypertension, or renal dysfunction. Elevated UACR was associated with increased risk of the composite outcome and death even after adjustment for other prognostic variables including renal function, diabetes, and haemoglobin A1c. The adjusted hazard ratio (HR) for the composite outcome in patients with microalbuminuria versus normoalbuminuria was 1.43 (95% CI 1.21-1.69; p<0.0001) and for macroalbuminuria versus normoalbuminuria was 1.75 (1.39-2.20; p<0.0001). The adjusted values for death were 1.62 (1.32-1.99; p<0.0001) for microalbuminuria versus normoalbuminuria, and 1.76 (1.32-2.35; p=0.0001) for macroalbuminuria versus normoalbuminuria. Treatment with candesartan did not reduce or prevent the development of excessive excretion of urinary albumin.Increased UACR is a powerful and independent predictor of prognosis in heart failure.AstraZeneca.","Albuminuria in chronic heart failure: prevalence and prognostic importance."
"1095","Lancet.173","1.00E-04",19683640,2009,"Increased excretion of albumin in urine might be a marker of the various pathophysiological changes that arise in patients with heart failure. Therefore our aim was to assess the prevalence and prognostic value of a spot urinary albumin to creatinine ratio (UACR) in patients with heart failure.UACR was measured at baseline and during follow-up of 2310 patients in the Candesartan in Heart failure: Assessment of Reduction in Mortality and morbidity (CHARM) Programme. The prevalence of microalbuminuria and macroalbuminuria, and the predictive value of UACR for the primary composite outcome of each CHARM study--ie, death from cardiovascular causes or admission to hospital with worsening heart failure--and death from any cause were assessed.1349 (58%) patients had a normal UACR, 704 (30%) had microalbuminuria, and 257 (11%) had macroalbuminuria. The prevalence of increased UACR was similar in patients with reduced and preserved left ventricular ejection fractions. Patients with an increased UACR were older, had more cardiovascular comorbidity, worse renal function, and a higher prevalence of diabetes mellitus than did those with normoalbuminuria. However, a high prevalence of increased UACR was still noted among patients without diabetes, hypertension, or renal dysfunction. Elevated UACR was associated with increased risk of the composite outcome and death even after adjustment for other prognostic variables including renal function, diabetes, and haemoglobin A1c. The adjusted hazard ratio (HR) for the composite outcome in patients with microalbuminuria versus normoalbuminuria was 1.43 (95% CI 1.21-1.69; p<0.0001) and for macroalbuminuria versus normoalbuminuria was 1.75 (1.39-2.20; p<0.0001). The adjusted values for death were 1.62 (1.32-1.99; p<0.0001) for microalbuminuria versus normoalbuminuria, and 1.76 (1.32-2.35; p=0.0001) for macroalbuminuria versus normoalbuminuria. Treatment with candesartan did not reduce or prevent the development of excessive excretion of urinary albumin.Increased UACR is a powerful and independent predictor of prognosis in heart failure.AstraZeneca.","Albuminuria in chronic heart failure: prevalence and prognostic importance."
"1096","Lancet.207","1.00E-04",19683640,2009,"Increased excretion of albumin in urine might be a marker of the various pathophysiological changes that arise in patients with heart failure. Therefore our aim was to assess the prevalence and prognostic value of a spot urinary albumin to creatinine ratio (UACR) in patients with heart failure.UACR was measured at baseline and during follow-up of 2310 patients in the Candesartan in Heart failure: Assessment of Reduction in Mortality and morbidity (CHARM) Programme. The prevalence of microalbuminuria and macroalbuminuria, and the predictive value of UACR for the primary composite outcome of each CHARM study--ie, death from cardiovascular causes or admission to hospital with worsening heart failure--and death from any cause were assessed.1349 (58%) patients had a normal UACR, 704 (30%) had microalbuminuria, and 257 (11%) had macroalbuminuria. The prevalence of increased UACR was similar in patients with reduced and preserved left ventricular ejection fractions. Patients with an increased UACR were older, had more cardiovascular comorbidity, worse renal function, and a higher prevalence of diabetes mellitus than did those with normoalbuminuria. However, a high prevalence of increased UACR was still noted among patients without diabetes, hypertension, or renal dysfunction. Elevated UACR was associated with increased risk of the composite outcome and death even after adjustment for other prognostic variables including renal function, diabetes, and haemoglobin A1c. The adjusted hazard ratio (HR) for the composite outcome in patients with microalbuminuria versus normoalbuminuria was 1.43 (95% CI 1.21-1.69; p<0.0001) and for macroalbuminuria versus normoalbuminuria was 1.75 (1.39-2.20; p<0.0001). The adjusted values for death were 1.62 (1.32-1.99; p<0.0001) for microalbuminuria versus normoalbuminuria, and 1.76 (1.32-2.35; p=0.0001) for macroalbuminuria versus normoalbuminuria. Treatment with candesartan did not reduce or prevent the development of excessive excretion of urinary albumin.Increased UACR is a powerful and independent predictor of prognosis in heart failure.AstraZeneca.","Albuminuria in chronic heart failure: prevalence and prognostic importance."
"1097","American Journal of Epidemiology.96","0.048",19696228,2009,"The authors aimed to determine whether 2 functional polymorphisms in the heme oxygenase-1 (HO-1) gene promoter are associated with type 2 diabetes mellitus (T2DM). A Chinese case-control study involving 1,103 newly diagnosed T2DM patients, 371 patients with impaired glucose regulation (IGR), and 1,615 controls was performed (December 2004-December 2007). A (GT)(n) microsatellite polymorphism and a single nucleotide polymorphism, T(-413)A, were genotyped, and their functional relevance was evaluated by examining the level of HO-1 protein expression. For the (GT)(n) microsatellite polymorphism, genotypes with the L (GT)(n) allele (>or=25 GT repeats) were associated with increased odds of IGR or T2DM compared with the S/S genotype (<25 GT repeats) (S/L genotype: odds ratio (OR) = 1.35, P = 0.048; L/L genotype: OR = 1.65, P = 0.006). Subsequent haplotype analysis showed that haplotype TL contributed to increased odds of IGR or T2DM compared with haplotype TS (OR = 1.56, P = 0.003). In functional analyses, HO-1 expression level was significantly reduced in persons with IGR and T2DM carrying the L/L (GT)(n) genotype compared with persons with the S/S genotype. Further haplotype combination assay confirmed the functional dominance of the (GT)(n) microsatellite polymorphism over the T(-413)A single nucleotide polymorphism. These results support an association between the HO-1 (GT)(n) microsatellite polymorphism, HO-1 expression levels, and the odds of T2DM.","Association between heme oxygenase-1 gene promoter polymorphisms and type 2 diabetes in a Chinese population."
"1098","American Journal of Epidemiology.97","0.006",19696228,2009,"The authors aimed to determine whether 2 functional polymorphisms in the heme oxygenase-1 (HO-1) gene promoter are associated with type 2 diabetes mellitus (T2DM). A Chinese case-control study involving 1,103 newly diagnosed T2DM patients, 371 patients with impaired glucose regulation (IGR), and 1,615 controls was performed (December 2004-December 2007). A (GT)(n) microsatellite polymorphism and a single nucleotide polymorphism, T(-413)A, were genotyped, and their functional relevance was evaluated by examining the level of HO-1 protein expression. For the (GT)(n) microsatellite polymorphism, genotypes with the L (GT)(n) allele (>or=25 GT repeats) were associated with increased odds of IGR or T2DM compared with the S/S genotype (<25 GT repeats) (S/L genotype: odds ratio (OR) = 1.35, P = 0.048; L/L genotype: OR = 1.65, P = 0.006). Subsequent haplotype analysis showed that haplotype TL contributed to increased odds of IGR or T2DM compared with haplotype TS (OR = 1.56, P = 0.003). In functional analyses, HO-1 expression level was significantly reduced in persons with IGR and T2DM carrying the L/L (GT)(n) genotype compared with persons with the S/S genotype. Further haplotype combination assay confirmed the functional dominance of the (GT)(n) microsatellite polymorphism over the T(-413)A single nucleotide polymorphism. These results support an association between the HO-1 (GT)(n) microsatellite polymorphism, HO-1 expression levels, and the odds of T2DM.","Association between heme oxygenase-1 gene promoter polymorphisms and type 2 diabetes in a Chinese population."
"1099","American Journal of Epidemiology.98","0.003",19696228,2009,"The authors aimed to determine whether 2 functional polymorphisms in the heme oxygenase-1 (HO-1) gene promoter are associated with type 2 diabetes mellitus (T2DM). A Chinese case-control study involving 1,103 newly diagnosed T2DM patients, 371 patients with impaired glucose regulation (IGR), and 1,615 controls was performed (December 2004-December 2007). A (GT)(n) microsatellite polymorphism and a single nucleotide polymorphism, T(-413)A, were genotyped, and their functional relevance was evaluated by examining the level of HO-1 protein expression. For the (GT)(n) microsatellite polymorphism, genotypes with the L (GT)(n) allele (>or=25 GT repeats) were associated with increased odds of IGR or T2DM compared with the S/S genotype (<25 GT repeats) (S/L genotype: odds ratio (OR) = 1.35, P = 0.048; L/L genotype: OR = 1.65, P = 0.006). Subsequent haplotype analysis showed that haplotype TL contributed to increased odds of IGR or T2DM compared with haplotype TS (OR = 1.56, P = 0.003). In functional analyses, HO-1 expression level was significantly reduced in persons with IGR and T2DM carrying the L/L (GT)(n) genotype compared with persons with the S/S genotype. Further haplotype combination assay confirmed the functional dominance of the (GT)(n) microsatellite polymorphism over the T(-413)A single nucleotide polymorphism. These results support an association between the HO-1 (GT)(n) microsatellite polymorphism, HO-1 expression levels, and the odds of T2DM.","Association between heme oxygenase-1 gene promoter polymorphisms and type 2 diabetes in a Chinese population."
"1100","JAMA.5211","0.86",19706860,2009,"Hormonal therapy (HT) when added to radiation therapy (RT) for treating unfavorable-risk prostate cancer leads to an increase in survival except possibly in men with moderate to severe comorbidity. However, it is unknown which comorbid conditions eliminate this survival benefit.To assess whether neoadjuvant HT use affects the risk of all-cause mortality in men with prostate cancer and coronary artery disease (CAD)-induced congestive heart failure (CHF) or myocardial infarction (MI), CAD risk factors, or no comorbidity.A total of 5077 men (median age, 69.5 years) with localized or locally advanced prostate cancer were consecutively treated with or without a median of 4 months of neoadjuvant HT followed by RT at a suburban cancer center between 1997 and 2006 and were followed up until July 1, 2008. Cox regression multivariable analyses were performed assessing whether neoadjuvant HT use affected the risk of all-cause mortality, adjusting for age, year and type of RT, treatment propensity score, and known prostate cancer prognostic factors in each comorbidity group.Risk of all-cause mortality.Neoadjuvant HT use was not associated with an increased risk of all-cause mortality in men with no comorbidity (9.6% vs 6.7%, adjusted hazard ratio [HR], 0.97; 95% confidence interval [CI], 0.72-1.32; P = .86) or a single CAD risk factor (10.7% vs 7.0%, adjusted HR, 1.04; 95% CI, 0.75-1.43; P = .82) after median follow-ups of 5.0 and 4.4 years, respectively. However, for men with CAD-induced CHF or MI, after a median follow-up of 5.1 years, neoadjuvant HT use was significantly associated with an increased risk of all-cause mortality (26.3% vs 11.2%, adjusted HR, 1.96; 95% CI, 1.04-3.71; P = .04).Neoadjuvant HT use is significantly associated with an increased risk of all-cause mortality among men with a history of CAD-induced CHF or MI but not among men with no comorbidity or a single CAD risk factor.","Hormonal therapy use for prostate cancer and mortality in men with coronary artery disease-induced congestive heart failure or myocardial infarction."
"1101","JAMA.5221","0.82",19706860,2009,"Hormonal therapy (HT) when added to radiation therapy (RT) for treating unfavorable-risk prostate cancer leads to an increase in survival except possibly in men with moderate to severe comorbidity. However, it is unknown which comorbid conditions eliminate this survival benefit.To assess whether neoadjuvant HT use affects the risk of all-cause mortality in men with prostate cancer and coronary artery disease (CAD)-induced congestive heart failure (CHF) or myocardial infarction (MI), CAD risk factors, or no comorbidity.A total of 5077 men (median age, 69.5 years) with localized or locally advanced prostate cancer were consecutively treated with or without a median of 4 months of neoadjuvant HT followed by RT at a suburban cancer center between 1997 and 2006 and were followed up until July 1, 2008. Cox regression multivariable analyses were performed assessing whether neoadjuvant HT use affected the risk of all-cause mortality, adjusting for age, year and type of RT, treatment propensity score, and known prostate cancer prognostic factors in each comorbidity group.Risk of all-cause mortality.Neoadjuvant HT use was not associated with an increased risk of all-cause mortality in men with no comorbidity (9.6% vs 6.7%, adjusted hazard ratio [HR], 0.97; 95% confidence interval [CI], 0.72-1.32; P = .86) or a single CAD risk factor (10.7% vs 7.0%, adjusted HR, 1.04; 95% CI, 0.75-1.43; P = .82) after median follow-ups of 5.0 and 4.4 years, respectively. However, for men with CAD-induced CHF or MI, after a median follow-up of 5.1 years, neoadjuvant HT use was significantly associated with an increased risk of all-cause mortality (26.3% vs 11.2%, adjusted HR, 1.96; 95% CI, 1.04-3.71; P = .04).Neoadjuvant HT use is significantly associated with an increased risk of all-cause mortality among men with a history of CAD-induced CHF or MI but not among men with no comorbidity or a single CAD risk factor.","Hormonal therapy use for prostate cancer and mortality in men with coronary artery disease-induced congestive heart failure or myocardial infarction."
"1102","JAMA.5231","0.04",19706860,2009,"Hormonal therapy (HT) when added to radiation therapy (RT) for treating unfavorable-risk prostate cancer leads to an increase in survival except possibly in men with moderate to severe comorbidity. However, it is unknown which comorbid conditions eliminate this survival benefit.To assess whether neoadjuvant HT use affects the risk of all-cause mortality in men with prostate cancer and coronary artery disease (CAD)-induced congestive heart failure (CHF) or myocardial infarction (MI), CAD risk factors, or no comorbidity.A total of 5077 men (median age, 69.5 years) with localized or locally advanced prostate cancer were consecutively treated with or without a median of 4 months of neoadjuvant HT followed by RT at a suburban cancer center between 1997 and 2006 and were followed up until July 1, 2008. Cox regression multivariable analyses were performed assessing whether neoadjuvant HT use affected the risk of all-cause mortality, adjusting for age, year and type of RT, treatment propensity score, and known prostate cancer prognostic factors in each comorbidity group.Risk of all-cause mortality.Neoadjuvant HT use was not associated with an increased risk of all-cause mortality in men with no comorbidity (9.6% vs 6.7%, adjusted hazard ratio [HR], 0.97; 95% confidence interval [CI], 0.72-1.32; P = .86) or a single CAD risk factor (10.7% vs 7.0%, adjusted HR, 1.04; 95% CI, 0.75-1.43; P = .82) after median follow-ups of 5.0 and 4.4 years, respectively. However, for men with CAD-induced CHF or MI, after a median follow-up of 5.1 years, neoadjuvant HT use was significantly associated with an increased risk of all-cause mortality (26.3% vs 11.2%, adjusted HR, 1.96; 95% CI, 1.04-3.71; P = .04).Neoadjuvant HT use is significantly associated with an increased risk of all-cause mortality among men with a history of CAD-induced CHF or MI but not among men with no comorbidity or a single CAD risk factor.","Hormonal therapy use for prostate cancer and mortality in men with coronary artery disease-induced congestive heart failure or myocardial infarction."
"1103","Lancet.114","1.00E-04",19717185,2009,"In the HORIZONS-AMI trial, patients with acute ST-segment elevation myocardial infarction (STEMI) undergoing percutaneous coronary intervention (PCI) who were treated with the thrombin inhibitor bivalirudin had substantially lower 30-day rates of major haemorrhagic complications and net adverse clinical events than did patients assigned to heparin plus a glycoprotein IIb/IIIa inhibitor (GPI). Here, we assess whether these initial benefits were maintained at 1 year of follow-up.Patients aged 18 years or older were eligible for enrolment in this multicentre, open-label, randomised controlled trial if they had STEMI, presented within 12 h after the onset of symptoms, and were undergoing primary PCI. 3602 eligible patients were randomly assigned by interactive voice response system in a 1:1 ratio to receive bivalirudin (0.75 mg/kg intravenous bolus followed by 1.75 mg/kg per h infusion; n=1800) or heparin plus a GPI (control; 60 IU/kg intravenous bolus followed by boluses with target activated clotting time 200-250 s; n=1802). The two primary trial endpoints were major bleeding and net adverse clinical events (NACE; consisting of major bleeding or composite major adverse cardiovascular events [MACE; death, reinfarction, target vessel revascularisation for ischaemia, or stroke]). This prespecified analysis reports data for the 1-year follow-up. Analysis was by intention to treat. Patients with missing data were censored at the time of withdrawal from the study or at last follow-up. This trial is registered with ClinicalTrials.gov, number NCT00433966.1-year data were available for 1696 patients in the bivalirudin group and 1702 patients in the control group. Reasons for participant dropout were loss to follow-up and withdrawal of consent. The rate of NACE was lower in the bivalirudin group than in the control group (15.6%vs 18.3%, hazard ratio [HR] 0.83, 95% CI 0.71-0.97, p=0.022), as a result of a lower rate of major bleeding in the bivalirudin group (5.8%vs 9.2%, HR 0.61, 0.48-0.78, p<0.0001). The rate of MACE was similar between groups (11.9%vs 11.9%, HR 1.00, 0.82-1.21, p=0.98). The 1-year rates of cardiac mortality (2.1%vs 3.8%, HR 0.57, 0.38-0.84, p=0.005) and all-cause mortality (3.5%vs 4.8%, HR 0.71, 0.51-0.98, p=0.037) were lower in the bivalirudin group than in the control group.In patients with STEMI undergoing primary PCI, anticoagulation with bivalirudin reduced the rates of net adverse clinical events and major bleeding at 1 year compared with treatment with heparin plus a GPI. This finding has important clinical implications for the selection of optimum treatment strategies for patients with STEMI.Cardiovascular Research Foundation, with unrestricted grant support from Boston Scientific Corporation and The Medicines Company.","Bivalirudin in patients undergoing primary angioplasty for acute myocardial infarction (HORIZONS-AMI): 1-year results of a randomised controlled trial."
"1104","Lancet.119","0.022",19717185,2009,"In the HORIZONS-AMI trial, patients with acute ST-segment elevation myocardial infarction (STEMI) undergoing percutaneous coronary intervention (PCI) who were treated with the thrombin inhibitor bivalirudin had substantially lower 30-day rates of major haemorrhagic complications and net adverse clinical events than did patients assigned to heparin plus a glycoprotein IIb/IIIa inhibitor (GPI). Here, we assess whether these initial benefits were maintained at 1 year of follow-up.Patients aged 18 years or older were eligible for enrolment in this multicentre, open-label, randomised controlled trial if they had STEMI, presented within 12 h after the onset of symptoms, and were undergoing primary PCI. 3602 eligible patients were randomly assigned by interactive voice response system in a 1:1 ratio to receive bivalirudin (0.75 mg/kg intravenous bolus followed by 1.75 mg/kg per h infusion; n=1800) or heparin plus a GPI (control; 60 IU/kg intravenous bolus followed by boluses with target activated clotting time 200-250 s; n=1802). The two primary trial endpoints were major bleeding and net adverse clinical events (NACE; consisting of major bleeding or composite major adverse cardiovascular events [MACE; death, reinfarction, target vessel revascularisation for ischaemia, or stroke]). This prespecified analysis reports data for the 1-year follow-up. Analysis was by intention to treat. Patients with missing data were censored at the time of withdrawal from the study or at last follow-up. This trial is registered with ClinicalTrials.gov, number NCT00433966.1-year data were available for 1696 patients in the bivalirudin group and 1702 patients in the control group. Reasons for participant dropout were loss to follow-up and withdrawal of consent. The rate of NACE was lower in the bivalirudin group than in the control group (15.6%vs 18.3%, hazard ratio [HR] 0.83, 95% CI 0.71-0.97, p=0.022), as a result of a lower rate of major bleeding in the bivalirudin group (5.8%vs 9.2%, HR 0.61, 0.48-0.78, p<0.0001). The rate of MACE was similar between groups (11.9%vs 11.9%, HR 1.00, 0.82-1.21, p=0.98). The 1-year rates of cardiac mortality (2.1%vs 3.8%, HR 0.57, 0.38-0.84, p=0.005) and all-cause mortality (3.5%vs 4.8%, HR 0.71, 0.51-0.98, p=0.037) were lower in the bivalirudin group than in the control group.In patients with STEMI undergoing primary PCI, anticoagulation with bivalirudin reduced the rates of net adverse clinical events and major bleeding at 1 year compared with treatment with heparin plus a GPI. This finding has important clinical implications for the selection of optimum treatment strategies for patients with STEMI.Cardiovascular Research Foundation, with unrestricted grant support from Boston Scientific Corporation and The Medicines Company.","Bivalirudin in patients undergoing primary angioplasty for acute myocardial infarction (HORIZONS-AMI): 1-year results of a randomised controlled trial."
"1105","Lancet.120","0.98",19717185,2009,"In the HORIZONS-AMI trial, patients with acute ST-segment elevation myocardial infarction (STEMI) undergoing percutaneous coronary intervention (PCI) who were treated with the thrombin inhibitor bivalirudin had substantially lower 30-day rates of major haemorrhagic complications and net adverse clinical events than did patients assigned to heparin plus a glycoprotein IIb/IIIa inhibitor (GPI). Here, we assess whether these initial benefits were maintained at 1 year of follow-up.Patients aged 18 years or older were eligible for enrolment in this multicentre, open-label, randomised controlled trial if they had STEMI, presented within 12 h after the onset of symptoms, and were undergoing primary PCI. 3602 eligible patients were randomly assigned by interactive voice response system in a 1:1 ratio to receive bivalirudin (0.75 mg/kg intravenous bolus followed by 1.75 mg/kg per h infusion; n=1800) or heparin plus a GPI (control; 60 IU/kg intravenous bolus followed by boluses with target activated clotting time 200-250 s; n=1802). The two primary trial endpoints were major bleeding and net adverse clinical events (NACE; consisting of major bleeding or composite major adverse cardiovascular events [MACE; death, reinfarction, target vessel revascularisation for ischaemia, or stroke]). This prespecified analysis reports data for the 1-year follow-up. Analysis was by intention to treat. Patients with missing data were censored at the time of withdrawal from the study or at last follow-up. This trial is registered with ClinicalTrials.gov, number NCT00433966.1-year data were available for 1696 patients in the bivalirudin group and 1702 patients in the control group. Reasons for participant dropout were loss to follow-up and withdrawal of consent. The rate of NACE was lower in the bivalirudin group than in the control group (15.6%vs 18.3%, hazard ratio [HR] 0.83, 95% CI 0.71-0.97, p=0.022), as a result of a lower rate of major bleeding in the bivalirudin group (5.8%vs 9.2%, HR 0.61, 0.48-0.78, p<0.0001). The rate of MACE was similar between groups (11.9%vs 11.9%, HR 1.00, 0.82-1.21, p=0.98). The 1-year rates of cardiac mortality (2.1%vs 3.8%, HR 0.57, 0.38-0.84, p=0.005) and all-cause mortality (3.5%vs 4.8%, HR 0.71, 0.51-0.98, p=0.037) were lower in the bivalirudin group than in the control group.In patients with STEMI undergoing primary PCI, anticoagulation with bivalirudin reduced the rates of net adverse clinical events and major bleeding at 1 year compared with treatment with heparin plus a GPI. This finding has important clinical implications for the selection of optimum treatment strategies for patients with STEMI.Cardiovascular Research Foundation, with unrestricted grant support from Boston Scientific Corporation and The Medicines Company.","Bivalirudin in patients undergoing primary angioplasty for acute myocardial infarction (HORIZONS-AMI): 1-year results of a randomised controlled trial."
"1106","Lancet.121","0.005",19717185,2009,"In the HORIZONS-AMI trial, patients with acute ST-segment elevation myocardial infarction (STEMI) undergoing percutaneous coronary intervention (PCI) who were treated with the thrombin inhibitor bivalirudin had substantially lower 30-day rates of major haemorrhagic complications and net adverse clinical events than did patients assigned to heparin plus a glycoprotein IIb/IIIa inhibitor (GPI). Here, we assess whether these initial benefits were maintained at 1 year of follow-up.Patients aged 18 years or older were eligible for enrolment in this multicentre, open-label, randomised controlled trial if they had STEMI, presented within 12 h after the onset of symptoms, and were undergoing primary PCI. 3602 eligible patients were randomly assigned by interactive voice response system in a 1:1 ratio to receive bivalirudin (0.75 mg/kg intravenous bolus followed by 1.75 mg/kg per h infusion; n=1800) or heparin plus a GPI (control; 60 IU/kg intravenous bolus followed by boluses with target activated clotting time 200-250 s; n=1802). The two primary trial endpoints were major bleeding and net adverse clinical events (NACE; consisting of major bleeding or composite major adverse cardiovascular events [MACE; death, reinfarction, target vessel revascularisation for ischaemia, or stroke]). This prespecified analysis reports data for the 1-year follow-up. Analysis was by intention to treat. Patients with missing data were censored at the time of withdrawal from the study or at last follow-up. This trial is registered with ClinicalTrials.gov, number NCT00433966.1-year data were available for 1696 patients in the bivalirudin group and 1702 patients in the control group. Reasons for participant dropout were loss to follow-up and withdrawal of consent. The rate of NACE was lower in the bivalirudin group than in the control group (15.6%vs 18.3%, hazard ratio [HR] 0.83, 95% CI 0.71-0.97, p=0.022), as a result of a lower rate of major bleeding in the bivalirudin group (5.8%vs 9.2%, HR 0.61, 0.48-0.78, p<0.0001). The rate of MACE was similar between groups (11.9%vs 11.9%, HR 1.00, 0.82-1.21, p=0.98). The 1-year rates of cardiac mortality (2.1%vs 3.8%, HR 0.57, 0.38-0.84, p=0.005) and all-cause mortality (3.5%vs 4.8%, HR 0.71, 0.51-0.98, p=0.037) were lower in the bivalirudin group than in the control group.In patients with STEMI undergoing primary PCI, anticoagulation with bivalirudin reduced the rates of net adverse clinical events and major bleeding at 1 year compared with treatment with heparin plus a GPI. This finding has important clinical implications for the selection of optimum treatment strategies for patients with STEMI.Cardiovascular Research Foundation, with unrestricted grant support from Boston Scientific Corporation and The Medicines Company.","Bivalirudin in patients undergoing primary angioplasty for acute myocardial infarction (HORIZONS-AMI): 1-year results of a randomised controlled trial."
"1107","Lancet.122","0.037",19717185,2009,"In the HORIZONS-AMI trial, patients with acute ST-segment elevation myocardial infarction (STEMI) undergoing percutaneous coronary intervention (PCI) who were treated with the thrombin inhibitor bivalirudin had substantially lower 30-day rates of major haemorrhagic complications and net adverse clinical events than did patients assigned to heparin plus a glycoprotein IIb/IIIa inhibitor (GPI). Here, we assess whether these initial benefits were maintained at 1 year of follow-up.Patients aged 18 years or older were eligible for enrolment in this multicentre, open-label, randomised controlled trial if they had STEMI, presented within 12 h after the onset of symptoms, and were undergoing primary PCI. 3602 eligible patients were randomly assigned by interactive voice response system in a 1:1 ratio to receive bivalirudin (0.75 mg/kg intravenous bolus followed by 1.75 mg/kg per h infusion; n=1800) or heparin plus a GPI (control; 60 IU/kg intravenous bolus followed by boluses with target activated clotting time 200-250 s; n=1802). The two primary trial endpoints were major bleeding and net adverse clinical events (NACE; consisting of major bleeding or composite major adverse cardiovascular events [MACE; death, reinfarction, target vessel revascularisation for ischaemia, or stroke]). This prespecified analysis reports data for the 1-year follow-up. Analysis was by intention to treat. Patients with missing data were censored at the time of withdrawal from the study or at last follow-up. This trial is registered with ClinicalTrials.gov, number NCT00433966.1-year data were available for 1696 patients in the bivalirudin group and 1702 patients in the control group. Reasons for participant dropout were loss to follow-up and withdrawal of consent. The rate of NACE was lower in the bivalirudin group than in the control group (15.6%vs 18.3%, hazard ratio [HR] 0.83, 95% CI 0.71-0.97, p=0.022), as a result of a lower rate of major bleeding in the bivalirudin group (5.8%vs 9.2%, HR 0.61, 0.48-0.78, p<0.0001). The rate of MACE was similar between groups (11.9%vs 11.9%, HR 1.00, 0.82-1.21, p=0.98). The 1-year rates of cardiac mortality (2.1%vs 3.8%, HR 0.57, 0.38-0.84, p=0.005) and all-cause mortality (3.5%vs 4.8%, HR 0.71, 0.51-0.98, p=0.037) were lower in the bivalirudin group than in the control group.In patients with STEMI undergoing primary PCI, anticoagulation with bivalirudin reduced the rates of net adverse clinical events and major bleeding at 1 year compared with treatment with heparin plus a GPI. This finding has important clinical implications for the selection of optimum treatment strategies for patients with STEMI.Cardiovascular Research Foundation, with unrestricted grant support from Boston Scientific Corporation and The Medicines Company.","Bivalirudin in patients undergoing primary angioplasty for acute myocardial infarction (HORIZONS-AMI): 1-year results of a randomised controlled trial."
"1108","Lancet.117","0.04",19732949,2009,"House screening should protect people against malaria. We assessed whether two types of house screening--full screening of windows, doors, and closing eaves, or installation of screened ceilings--could reduce house entry of malaria vectors and frequency of anaemia in children in an area of seasonal malaria transmission.During 2006 and 2007, 500 occupied houses in and near Farafenni town in The Gambia, an area with low use of insecticide-treated bednets, were randomly assigned to receive full screening, screened ceilings, or no screening (control). Randomisation was done by computer-generated list, in permuted blocks of five houses in the ratio 2:2:1. Screening was not treated with insecticide. Exposure to mosquitoes indoors was assessed by fortnightly light trap collections during the transmission season. Primary endpoints included the number of female Anopheles gambiae sensu lato mosquitoes collected per trap per night. Secondary endpoints included frequency of anaemia (haemoglobin concentration <80 g/L) and parasitaemia at the end of the transmission season in children (aged 6 months to 10 years) who were living in the study houses. Analysis was by modified intention to treat (ITT), including all randomised houses for which there were some outcome data and all children from those houses who were sampled for haemoglobin and parasitaemia. This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN51184253.462 houses were included in the modified ITT analysis (full screening, n=188; screened ceilings, n=178; control, n=96). The mean number of A gambiae caught in houses without screening was 37.5 per trap per night (95% CI 31.6-43.3), compared with 15.2 (12.9-17.4) in houses with full screening (ratio of means 0.41, 95% CI 0.31-0.54; p<0.0001) and 19.1 (16.1-22.1) in houses with screened ceilings (ratio 0.53, 0.40-0.70; p<0.0001). 755 children completed the study, of whom 731 had complete clinical and covariate data and were used in the analysis of clinical outcomes. 30 (19%) of 158 children from control houses had anaemia, compared with 38 (12%) of 309 from houses with full screening (adjusted odds ratio [OR] 0.53, 95% CI 0.29-0.97; p=0.04), and 31 (12%) of 264 from houses with screened ceilings (OR 0.51, 0.27-0.96; p=0.04). Frequency of parasitaemia did not differ between intervention and control groups.House screening substantially reduced the number of mosquitoes inside houses and could contribute to prevention of anaemia in children.Medical Research Council.","Effect of two different house screening interventions on exposure to malaria vectors and on anaemia in children in The Gambia: a randomised controlled trial."
"1109","Lancet.118","0.04",19732949,2009,"House screening should protect people against malaria. We assessed whether two types of house screening--full screening of windows, doors, and closing eaves, or installation of screened ceilings--could reduce house entry of malaria vectors and frequency of anaemia in children in an area of seasonal malaria transmission.During 2006 and 2007, 500 occupied houses in and near Farafenni town in The Gambia, an area with low use of insecticide-treated bednets, were randomly assigned to receive full screening, screened ceilings, or no screening (control). Randomisation was done by computer-generated list, in permuted blocks of five houses in the ratio 2:2:1. Screening was not treated with insecticide. Exposure to mosquitoes indoors was assessed by fortnightly light trap collections during the transmission season. Primary endpoints included the number of female Anopheles gambiae sensu lato mosquitoes collected per trap per night. Secondary endpoints included frequency of anaemia (haemoglobin concentration <80 g/L) and parasitaemia at the end of the transmission season in children (aged 6 months to 10 years) who were living in the study houses. Analysis was by modified intention to treat (ITT), including all randomised houses for which there were some outcome data and all children from those houses who were sampled for haemoglobin and parasitaemia. This study is registered as an International Standard Randomised Controlled Trial, number ISRCTN51184253.462 houses were included in the modified ITT analysis (full screening, n=188; screened ceilings, n=178; control, n=96). The mean number of A gambiae caught in houses without screening was 37.5 per trap per night (95% CI 31.6-43.3), compared with 15.2 (12.9-17.4) in houses with full screening (ratio of means 0.41, 95% CI 0.31-0.54; p<0.0001) and 19.1 (16.1-22.1) in houses with screened ceilings (ratio 0.53, 0.40-0.70; p<0.0001). 755 children completed the study, of whom 731 had complete clinical and covariate data and were used in the analysis of clinical outcomes. 30 (19%) of 158 children from control houses had anaemia, compared with 38 (12%) of 309 from houses with full screening (adjusted odds ratio [OR] 0.53, 95% CI 0.29-0.97; p=0.04), and 31 (12%) of 264 from houses with screened ceilings (OR 0.51, 0.27-0.96; p=0.04). Frequency of parasitaemia did not differ between intervention and control groups.House screening substantially reduced the number of mosquitoes inside houses and could contribute to prevention of anaemia in children.Medical Research Council.","Effect of two different house screening interventions on exposure to malaria vectors and on anaemia in children in The Gambia: a randomised controlled trial."
"1110","JAMA.494","0.001",19738091,2009,"Kidney graft function after transplantation can be improved through pharmacological donor pretreatment to limit organ injury from cold preservation.To determine whether pretreatment of brain-dead donors with low-dose dopamine improves early graft function in human renal transplant recipients.Randomized, open-label, multicenter, parallel-group trial of 264 deceased heart-beating donors and 487 subsequent renal transplants performed at 60 European centers between March 2004 and August 2007 (final follow-up, December 31, 2008). Eligible donors were stable under low-dose norepinephrine with a normal serum creatinine concentration on admission.Donors were randomized to receive low-dose dopamine (4 mug/kg/min).Dialysis requirement during first week after transplantation.Dopamine was infused for a median of 344 minutes (IQR, 215 minutes). Dialysis was significantly reduced in recipients of a dopamine-treated graft. Fewer recipients in the treatment group needed multiple dialyses (56/227; 24.7%; 95% CI, 19.0%-30.3%; vs 92/260; 35.4%; 95% CI, 29.5%-41.2%; P = .01). The need for multiple dialyses posttransplant was associated with allograft failure after 3 years (HR, 3.61; 95% CI, 2.39-5.45; P < .001), whereas a single dialysis was not (HR, 0.67; 95% CI, 0.21-2.18; P = .51). Besides donor dopamine (OR, 0.54; 95% CI, 0.35-0.83; P = .005), cold ischemic time (OR, 1.07; 95% CI, 1.02-1.11 per hour; P = .001), donor age (OR, 1.03; 95% CI, 1.01-1.05 per year; P < .001), and recipient body weight (OR, 1.02; 95% CI, 1.01-1.04 per kg; P = .009) were independent explanatory variables in a multiple logistic regression model. Dopamine resulted in significant but clinically meaningless increases in the donor's systolic blood pressure (3.8 mm Hg; 95% CI, 0.7-6.9 mm Hg; P = .02) and urine production before surgical recovery of the kidneys (29 mL; 95% CI, 7-51 mL; P = .009) but had no influence on outcome.Donor pretreatment with low-dose dopamine reduces the need for dialysis after kidney transplantation.clinicaltrials.gov Identifier: NCT00115115.","Effects of donor pretreatment with dopamine on graft function after kidney transplantation: a randomized controlled trial."
"1111","JAMA.495","0.001",19738091,2009,"Kidney graft function after transplantation can be improved through pharmacological donor pretreatment to limit organ injury from cold preservation.To determine whether pretreatment of brain-dead donors with low-dose dopamine improves early graft function in human renal transplant recipients.Randomized, open-label, multicenter, parallel-group trial of 264 deceased heart-beating donors and 487 subsequent renal transplants performed at 60 European centers between March 2004 and August 2007 (final follow-up, December 31, 2008). Eligible donors were stable under low-dose norepinephrine with a normal serum creatinine concentration on admission.Donors were randomized to receive low-dose dopamine (4 mug/kg/min).Dialysis requirement during first week after transplantation.Dopamine was infused for a median of 344 minutes (IQR, 215 minutes). Dialysis was significantly reduced in recipients of a dopamine-treated graft. Fewer recipients in the treatment group needed multiple dialyses (56/227; 24.7%; 95% CI, 19.0%-30.3%; vs 92/260; 35.4%; 95% CI, 29.5%-41.2%; P = .01). The need for multiple dialyses posttransplant was associated with allograft failure after 3 years (HR, 3.61; 95% CI, 2.39-5.45; P < .001), whereas a single dialysis was not (HR, 0.67; 95% CI, 0.21-2.18; P = .51). Besides donor dopamine (OR, 0.54; 95% CI, 0.35-0.83; P = .005), cold ischemic time (OR, 1.07; 95% CI, 1.02-1.11 per hour; P = .001), donor age (OR, 1.03; 95% CI, 1.01-1.05 per year; P < .001), and recipient body weight (OR, 1.02; 95% CI, 1.01-1.04 per kg; P = .009) were independent explanatory variables in a multiple logistic regression model. Dopamine resulted in significant but clinically meaningless increases in the donor's systolic blood pressure (3.8 mm Hg; 95% CI, 0.7-6.9 mm Hg; P = .02) and urine production before surgical recovery of the kidneys (29 mL; 95% CI, 7-51 mL; P = .009) but had no influence on outcome.Donor pretreatment with low-dose dopamine reduces the need for dialysis after kidney transplantation.clinicaltrials.gov Identifier: NCT00115115.","Effects of donor pretreatment with dopamine on graft function after kidney transplantation: a randomized controlled trial."
"1112","JAMA.525","0.51",19738091,2009,"Kidney graft function after transplantation can be improved through pharmacological donor pretreatment to limit organ injury from cold preservation.To determine whether pretreatment of brain-dead donors with low-dose dopamine improves early graft function in human renal transplant recipients.Randomized, open-label, multicenter, parallel-group trial of 264 deceased heart-beating donors and 487 subsequent renal transplants performed at 60 European centers between March 2004 and August 2007 (final follow-up, December 31, 2008). Eligible donors were stable under low-dose norepinephrine with a normal serum creatinine concentration on admission.Donors were randomized to receive low-dose dopamine (4 mug/kg/min).Dialysis requirement during first week after transplantation.Dopamine was infused for a median of 344 minutes (IQR, 215 minutes). Dialysis was significantly reduced in recipients of a dopamine-treated graft. Fewer recipients in the treatment group needed multiple dialyses (56/227; 24.7%; 95% CI, 19.0%-30.3%; vs 92/260; 35.4%; 95% CI, 29.5%-41.2%; P = .01). The need for multiple dialyses posttransplant was associated with allograft failure after 3 years (HR, 3.61; 95% CI, 2.39-5.45; P < .001), whereas a single dialysis was not (HR, 0.67; 95% CI, 0.21-2.18; P = .51). Besides donor dopamine (OR, 0.54; 95% CI, 0.35-0.83; P = .005), cold ischemic time (OR, 1.07; 95% CI, 1.02-1.11 per hour; P = .001), donor age (OR, 1.03; 95% CI, 1.01-1.05 per year; P < .001), and recipient body weight (OR, 1.02; 95% CI, 1.01-1.04 per kg; P = .009) were independent explanatory variables in a multiple logistic regression model. Dopamine resulted in significant but clinically meaningless increases in the donor's systolic blood pressure (3.8 mm Hg; 95% CI, 0.7-6.9 mm Hg; P = .02) and urine production before surgical recovery of the kidneys (29 mL; 95% CI, 7-51 mL; P = .009) but had no influence on outcome.Donor pretreatment with low-dose dopamine reduces the need for dialysis after kidney transplantation.clinicaltrials.gov Identifier: NCT00115115.","Effects of donor pretreatment with dopamine on graft function after kidney transplantation: a randomized controlled trial."
"1113","JAMA.526","0.005",19738091,2009,"Kidney graft function after transplantation can be improved through pharmacological donor pretreatment to limit organ injury from cold preservation.To determine whether pretreatment of brain-dead donors with low-dose dopamine improves early graft function in human renal transplant recipients.Randomized, open-label, multicenter, parallel-group trial of 264 deceased heart-beating donors and 487 subsequent renal transplants performed at 60 European centers between March 2004 and August 2007 (final follow-up, December 31, 2008). Eligible donors were stable under low-dose norepinephrine with a normal serum creatinine concentration on admission.Donors were randomized to receive low-dose dopamine (4 mug/kg/min).Dialysis requirement during first week after transplantation.Dopamine was infused for a median of 344 minutes (IQR, 215 minutes). Dialysis was significantly reduced in recipients of a dopamine-treated graft. Fewer recipients in the treatment group needed multiple dialyses (56/227; 24.7%; 95% CI, 19.0%-30.3%; vs 92/260; 35.4%; 95% CI, 29.5%-41.2%; P = .01). The need for multiple dialyses posttransplant was associated with allograft failure after 3 years (HR, 3.61; 95% CI, 2.39-5.45; P < .001), whereas a single dialysis was not (HR, 0.67; 95% CI, 0.21-2.18; P = .51). Besides donor dopamine (OR, 0.54; 95% CI, 0.35-0.83; P = .005), cold ischemic time (OR, 1.07; 95% CI, 1.02-1.11 per hour; P = .001), donor age (OR, 1.03; 95% CI, 1.01-1.05 per year; P < .001), and recipient body weight (OR, 1.02; 95% CI, 1.01-1.04 per kg; P = .009) were independent explanatory variables in a multiple logistic regression model. Dopamine resulted in significant but clinically meaningless increases in the donor's systolic blood pressure (3.8 mm Hg; 95% CI, 0.7-6.9 mm Hg; P = .02) and urine production before surgical recovery of the kidneys (29 mL; 95% CI, 7-51 mL; P = .009) but had no influence on outcome.Donor pretreatment with low-dose dopamine reduces the need for dialysis after kidney transplantation.clinicaltrials.gov Identifier: NCT00115115.","Effects of donor pretreatment with dopamine on graft function after kidney transplantation: a randomized controlled trial."
"1114","JAMA.527","0.001",19738091,2009,"Kidney graft function after transplantation can be improved through pharmacological donor pretreatment to limit organ injury from cold preservation.To determine whether pretreatment of brain-dead donors with low-dose dopamine improves early graft function in human renal transplant recipients.Randomized, open-label, multicenter, parallel-group trial of 264 deceased heart-beating donors and 487 subsequent renal transplants performed at 60 European centers between March 2004 and August 2007 (final follow-up, December 31, 2008). Eligible donors were stable under low-dose norepinephrine with a normal serum creatinine concentration on admission.Donors were randomized to receive low-dose dopamine (4 mug/kg/min).Dialysis requirement during first week after transplantation.Dopamine was infused for a median of 344 minutes (IQR, 215 minutes). Dialysis was significantly reduced in recipients of a dopamine-treated graft. Fewer recipients in the treatment group needed multiple dialyses (56/227; 24.7%; 95% CI, 19.0%-30.3%; vs 92/260; 35.4%; 95% CI, 29.5%-41.2%; P = .01). The need for multiple dialyses posttransplant was associated with allograft failure after 3 years (HR, 3.61; 95% CI, 2.39-5.45; P < .001), whereas a single dialysis was not (HR, 0.67; 95% CI, 0.21-2.18; P = .51). Besides donor dopamine (OR, 0.54; 95% CI, 0.35-0.83; P = .005), cold ischemic time (OR, 1.07; 95% CI, 1.02-1.11 per hour; P = .001), donor age (OR, 1.03; 95% CI, 1.01-1.05 per year; P < .001), and recipient body weight (OR, 1.02; 95% CI, 1.01-1.04 per kg; P = .009) were independent explanatory variables in a multiple logistic regression model. Dopamine resulted in significant but clinically meaningless increases in the donor's systolic blood pressure (3.8 mm Hg; 95% CI, 0.7-6.9 mm Hg; P = .02) and urine production before surgical recovery of the kidneys (29 mL; 95% CI, 7-51 mL; P = .009) but had no influence on outcome.Donor pretreatment with low-dose dopamine reduces the need for dialysis after kidney transplantation.clinicaltrials.gov Identifier: NCT00115115.","Effects of donor pretreatment with dopamine on graft function after kidney transplantation: a randomized controlled trial."
"1115","JAMA.528","0.009",19738091,2009,"Kidney graft function after transplantation can be improved through pharmacological donor pretreatment to limit organ injury from cold preservation.To determine whether pretreatment of brain-dead donors with low-dose dopamine improves early graft function in human renal transplant recipients.Randomized, open-label, multicenter, parallel-group trial of 264 deceased heart-beating donors and 487 subsequent renal transplants performed at 60 European centers between March 2004 and August 2007 (final follow-up, December 31, 2008). Eligible donors were stable under low-dose norepinephrine with a normal serum creatinine concentration on admission.Donors were randomized to receive low-dose dopamine (4 mug/kg/min).Dialysis requirement during first week after transplantation.Dopamine was infused for a median of 344 minutes (IQR, 215 minutes). Dialysis was significantly reduced in recipients of a dopamine-treated graft. Fewer recipients in the treatment group needed multiple dialyses (56/227; 24.7%; 95% CI, 19.0%-30.3%; vs 92/260; 35.4%; 95% CI, 29.5%-41.2%; P = .01). The need for multiple dialyses posttransplant was associated with allograft failure after 3 years (HR, 3.61; 95% CI, 2.39-5.45; P < .001), whereas a single dialysis was not (HR, 0.67; 95% CI, 0.21-2.18; P = .51). Besides donor dopamine (OR, 0.54; 95% CI, 0.35-0.83; P = .005), cold ischemic time (OR, 1.07; 95% CI, 1.02-1.11 per hour; P = .001), donor age (OR, 1.03; 95% CI, 1.01-1.05 per year; P < .001), and recipient body weight (OR, 1.02; 95% CI, 1.01-1.04 per kg; P = .009) were independent explanatory variables in a multiple logistic regression model. Dopamine resulted in significant but clinically meaningless increases in the donor's systolic blood pressure (3.8 mm Hg; 95% CI, 0.7-6.9 mm Hg; P = .02) and urine production before surgical recovery of the kidneys (29 mL; 95% CI, 7-51 mL; P = .009) but had no influence on outcome.Donor pretreatment with low-dose dopamine reduces the need for dialysis after kidney transplantation.clinicaltrials.gov Identifier: NCT00115115.","Effects of donor pretreatment with dopamine on graft function after kidney transplantation: a randomized controlled trial."
"1116","JAMA.520","3.30E-06",19738092,2009,"A subset (approximately 3%-5%) of patients with cystic fibrosis (CF) develops severe liver disease with portal hypertension.To assess whether any of 9 polymorphisms in 5 candidate genes (alpha(1)-antitrypsin or alpha(1)-antiprotease [SERPINA1], angiotensin-converting enzyme [ACE], glutathione S-transferase [GSTP1], mannose-binding lectin 2 [MBL2], and transforming growth factor beta1 [TGFB1]) are associated with severe liver disease in patients with CF.Two-stage case-control study enrolling patients with CF and severe liver disease with portal hypertension (CFLD) from 63 CF centers in the United States as well as 32 in Canada and 18 outside of North America, with the University of North Carolina at Chapel Hill as the coordinating site. In the initial study, 124 patients with CFLD (enrolled January 1999-December 2004) and 843 control patients without CFLD were studied by genotyping 9 polymorphisms in 5 genes previously studied as modifiers of liver disease in CF. In the second stage, the SERPINA1 Z allele and TGFB1 codon 10 genotype were tested in an additional 136 patients with CFLD (enrolled January 2005-February 2007) and 1088 with no CFLD.Differences in distribution of genotypes in patients with CFLD vs patients without CFLD.The initial study showed CFLD to be associated with the SERPINA1 Z allele (odds ratio [OR], 4.72; 95% confidence interval [CI], 2.31-9.61; P = 3.3 x 10(-6)) and with TGFB1 codon 10 CC genotype (OR, 1.53; 95% CI, 1.16-2.03; P = 2.8 x 10(-3)). In the replication study, CFLD was associated with the SERPINA1 Z allele (OR, 3.42; 95% CI, 1.54-7.59; P = 1.4 x 10(-3)) but not with TGFB1 codon 10. A combined analysis of the initial and replication studies by logistic regression showed CFLD to be associated with SERPINA1 Z allele (OR, 5.04; 95% CI, 2.88-8.83; P = 1.5 x 10(-8)).The SERPINA1 Z allele is a risk factor for liver disease in CF. Patients who carry the Z allele are at greater risk (OR, approximately 5) of developing severe liver disease with portal hypertension.","Genetic modifiers of liver disease in cystic fibrosis."
"1117","JAMA.521","0.0028",19738092,2009,"A subset (approximately 3%-5%) of patients with cystic fibrosis (CF) develops severe liver disease with portal hypertension.To assess whether any of 9 polymorphisms in 5 candidate genes (alpha(1)-antitrypsin or alpha(1)-antiprotease [SERPINA1], angiotensin-converting enzyme [ACE], glutathione S-transferase [GSTP1], mannose-binding lectin 2 [MBL2], and transforming growth factor beta1 [TGFB1]) are associated with severe liver disease in patients with CF.Two-stage case-control study enrolling patients with CF and severe liver disease with portal hypertension (CFLD) from 63 CF centers in the United States as well as 32 in Canada and 18 outside of North America, with the University of North Carolina at Chapel Hill as the coordinating site. In the initial study, 124 patients with CFLD (enrolled January 1999-December 2004) and 843 control patients without CFLD were studied by genotyping 9 polymorphisms in 5 genes previously studied as modifiers of liver disease in CF. In the second stage, the SERPINA1 Z allele and TGFB1 codon 10 genotype were tested in an additional 136 patients with CFLD (enrolled January 2005-February 2007) and 1088 with no CFLD.Differences in distribution of genotypes in patients with CFLD vs patients without CFLD.The initial study showed CFLD to be associated with the SERPINA1 Z allele (odds ratio [OR], 4.72; 95% confidence interval [CI], 2.31-9.61; P = 3.3 x 10(-6)) and with TGFB1 codon 10 CC genotype (OR, 1.53; 95% CI, 1.16-2.03; P = 2.8 x 10(-3)). In the replication study, CFLD was associated with the SERPINA1 Z allele (OR, 3.42; 95% CI, 1.54-7.59; P = 1.4 x 10(-3)) but not with TGFB1 codon 10. A combined analysis of the initial and replication studies by logistic regression showed CFLD to be associated with SERPINA1 Z allele (OR, 5.04; 95% CI, 2.88-8.83; P = 1.5 x 10(-8)).The SERPINA1 Z allele is a risk factor for liver disease in CF. Patients who carry the Z allele are at greater risk (OR, approximately 5) of developing severe liver disease with portal hypertension.","Genetic modifiers of liver disease in cystic fibrosis."
"1118","JAMA.522","0.0014",19738092,2009,"A subset (approximately 3%-5%) of patients with cystic fibrosis (CF) develops severe liver disease with portal hypertension.To assess whether any of 9 polymorphisms in 5 candidate genes (alpha(1)-antitrypsin or alpha(1)-antiprotease [SERPINA1], angiotensin-converting enzyme [ACE], glutathione S-transferase [GSTP1], mannose-binding lectin 2 [MBL2], and transforming growth factor beta1 [TGFB1]) are associated with severe liver disease in patients with CF.Two-stage case-control study enrolling patients with CF and severe liver disease with portal hypertension (CFLD) from 63 CF centers in the United States as well as 32 in Canada and 18 outside of North America, with the University of North Carolina at Chapel Hill as the coordinating site. In the initial study, 124 patients with CFLD (enrolled January 1999-December 2004) and 843 control patients without CFLD were studied by genotyping 9 polymorphisms in 5 genes previously studied as modifiers of liver disease in CF. In the second stage, the SERPINA1 Z allele and TGFB1 codon 10 genotype were tested in an additional 136 patients with CFLD (enrolled January 2005-February 2007) and 1088 with no CFLD.Differences in distribution of genotypes in patients with CFLD vs patients without CFLD.The initial study showed CFLD to be associated with the SERPINA1 Z allele (odds ratio [OR], 4.72; 95% confidence interval [CI], 2.31-9.61; P = 3.3 x 10(-6)) and with TGFB1 codon 10 CC genotype (OR, 1.53; 95% CI, 1.16-2.03; P = 2.8 x 10(-3)). In the replication study, CFLD was associated with the SERPINA1 Z allele (OR, 3.42; 95% CI, 1.54-7.59; P = 1.4 x 10(-3)) but not with TGFB1 codon 10. A combined analysis of the initial and replication studies by logistic regression showed CFLD to be associated with SERPINA1 Z allele (OR, 5.04; 95% CI, 2.88-8.83; P = 1.5 x 10(-8)).The SERPINA1 Z allele is a risk factor for liver disease in CF. Patients who carry the Z allele are at greater risk (OR, approximately 5) of developing severe liver disease with portal hypertension.","Genetic modifiers of liver disease in cystic fibrosis."
"1119","JAMA.523","1.50E-08",19738092,2009,"A subset (approximately 3%-5%) of patients with cystic fibrosis (CF) develops severe liver disease with portal hypertension.To assess whether any of 9 polymorphisms in 5 candidate genes (alpha(1)-antitrypsin or alpha(1)-antiprotease [SERPINA1], angiotensin-converting enzyme [ACE], glutathione S-transferase [GSTP1], mannose-binding lectin 2 [MBL2], and transforming growth factor beta1 [TGFB1]) are associated with severe liver disease in patients with CF.Two-stage case-control study enrolling patients with CF and severe liver disease with portal hypertension (CFLD) from 63 CF centers in the United States as well as 32 in Canada and 18 outside of North America, with the University of North Carolina at Chapel Hill as the coordinating site. In the initial study, 124 patients with CFLD (enrolled January 1999-December 2004) and 843 control patients without CFLD were studied by genotyping 9 polymorphisms in 5 genes previously studied as modifiers of liver disease in CF. In the second stage, the SERPINA1 Z allele and TGFB1 codon 10 genotype were tested in an additional 136 patients with CFLD (enrolled January 2005-February 2007) and 1088 with no CFLD.Differences in distribution of genotypes in patients with CFLD vs patients without CFLD.The initial study showed CFLD to be associated with the SERPINA1 Z allele (odds ratio [OR], 4.72; 95% confidence interval [CI], 2.31-9.61; P = 3.3 x 10(-6)) and with TGFB1 codon 10 CC genotype (OR, 1.53; 95% CI, 1.16-2.03; P = 2.8 x 10(-3)). In the replication study, CFLD was associated with the SERPINA1 Z allele (OR, 3.42; 95% CI, 1.54-7.59; P = 1.4 x 10(-3)) but not with TGFB1 codon 10. A combined analysis of the initial and replication studies by logistic regression showed CFLD to be associated with SERPINA1 Z allele (OR, 5.04; 95% CI, 2.88-8.83; P = 1.5 x 10(-8)).The SERPINA1 Z allele is a risk factor for liver disease in CF. Patients who carry the Z allele are at greater risk (OR, approximately 5) of developing severe liver disease with portal hypertension.","Genetic modifiers of liver disease in cystic fibrosis."
"1120","Lancet.198","0.12",19767090,2009,"In the post-intervention period of the Women's Health Initiative (WHI) trial, women assigned to treatment with oestrogen plus progestin had a higher risk of cancer than did those assigned to placebo. Results also suggested that the combined hormone therapy might increase mortality from lung cancer. To assess whether such an association exists, we undertook a post-hoc analysis of lung cancers diagnosed in the trial over the entire follow-up period.The WHI study was a randomised, double-blind, placebo-controlled trial undertaken in 40 centres in the USA. 16 608 postmenopausal women aged 50-79 years with an intact uterus were randomly assigned by a computerised, stratified, permuted block algorithm to receive a once-daily tablet of 0.625 mg conjugated equine oestrogen plus 2.5 mg medroxyprogesterone acetate (n=8506) or matching placebo (n=8102). We assessed incidence and mortality rates for all lung cancer, small-cell lung cancer, and non-small-cell lung cancer by use of data from treatment and post-intervention follow-up periods. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00000611.After a mean of 5.6 years (SD 1.3) of treatment and 2.4 years (0.4) of additional follow-up, 109 women in the combined hormone therapy group had been diagnosed with lung cancer compared with 85 in the placebo group (incidence per year 0.16%vs 0.13%; hazard ratio [HR] 1.23, 95% CI 0.92-1.63, p=0.16). 96 women assigned to combined therapy had non-small-cell lung cancer compared with 72 assigned to placebo (0.14%vs 0.11%; HR 1.28, 0.94-1.73, p=0.12). More women died from lung cancer in the combined hormone therapy group than in the placebo group (73 vs 40 deaths; 0.11%vs 0.06%; HR 1.71, 1.16-2.52, p=0.01), mainly as a result of a higher number of deaths from non-small-cell lung cancer in the combined therapy group (62 vs 31 deaths; 0.09%vs 0.05%; HR 1.87, 1.22-2.88, p=0.004). Incidence and mortality rates of small-cell lung cancer were similar between groups.Although treatment with oestrogen plus progestin in postmenopausal women did not increase incidence of lung cancer, it increased the number of deaths from lung cancer, in particular deaths from non-small-cell lung cancer. These findings should be incorporated into risk-benefit discussions with women considering combined hormone therapy, especially those with a high risk of lung cancer.National Heart, Lung and Blood Institute, National Institutes of Health.","Oestrogen plus progestin and lung cancer in postmenopausal women (Women's Health Initiative trial): a post-hoc analysis of a randomised controlled trial."
"1121","Lancet.199","0.01",19767090,2009,"In the post-intervention period of the Women's Health Initiative (WHI) trial, women assigned to treatment with oestrogen plus progestin had a higher risk of cancer than did those assigned to placebo. Results also suggested that the combined hormone therapy might increase mortality from lung cancer. To assess whether such an association exists, we undertook a post-hoc analysis of lung cancers diagnosed in the trial over the entire follow-up period.The WHI study was a randomised, double-blind, placebo-controlled trial undertaken in 40 centres in the USA. 16 608 postmenopausal women aged 50-79 years with an intact uterus were randomly assigned by a computerised, stratified, permuted block algorithm to receive a once-daily tablet of 0.625 mg conjugated equine oestrogen plus 2.5 mg medroxyprogesterone acetate (n=8506) or matching placebo (n=8102). We assessed incidence and mortality rates for all lung cancer, small-cell lung cancer, and non-small-cell lung cancer by use of data from treatment and post-intervention follow-up periods. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00000611.After a mean of 5.6 years (SD 1.3) of treatment and 2.4 years (0.4) of additional follow-up, 109 women in the combined hormone therapy group had been diagnosed with lung cancer compared with 85 in the placebo group (incidence per year 0.16%vs 0.13%; hazard ratio [HR] 1.23, 95% CI 0.92-1.63, p=0.16). 96 women assigned to combined therapy had non-small-cell lung cancer compared with 72 assigned to placebo (0.14%vs 0.11%; HR 1.28, 0.94-1.73, p=0.12). More women died from lung cancer in the combined hormone therapy group than in the placebo group (73 vs 40 deaths; 0.11%vs 0.06%; HR 1.71, 1.16-2.52, p=0.01), mainly as a result of a higher number of deaths from non-small-cell lung cancer in the combined therapy group (62 vs 31 deaths; 0.09%vs 0.05%; HR 1.87, 1.22-2.88, p=0.004). Incidence and mortality rates of small-cell lung cancer were similar between groups.Although treatment with oestrogen plus progestin in postmenopausal women did not increase incidence of lung cancer, it increased the number of deaths from lung cancer, in particular deaths from non-small-cell lung cancer. These findings should be incorporated into risk-benefit discussions with women considering combined hormone therapy, especially those with a high risk of lung cancer.National Heart, Lung and Blood Institute, National Institutes of Health.","Oestrogen plus progestin and lung cancer in postmenopausal women (Women's Health Initiative trial): a post-hoc analysis of a randomised controlled trial."
"1122","Lancet.200","0.004",19767090,2009,"In the post-intervention period of the Women's Health Initiative (WHI) trial, women assigned to treatment with oestrogen plus progestin had a higher risk of cancer than did those assigned to placebo. Results also suggested that the combined hormone therapy might increase mortality from lung cancer. To assess whether such an association exists, we undertook a post-hoc analysis of lung cancers diagnosed in the trial over the entire follow-up period.The WHI study was a randomised, double-blind, placebo-controlled trial undertaken in 40 centres in the USA. 16 608 postmenopausal women aged 50-79 years with an intact uterus were randomly assigned by a computerised, stratified, permuted block algorithm to receive a once-daily tablet of 0.625 mg conjugated equine oestrogen plus 2.5 mg medroxyprogesterone acetate (n=8506) or matching placebo (n=8102). We assessed incidence and mortality rates for all lung cancer, small-cell lung cancer, and non-small-cell lung cancer by use of data from treatment and post-intervention follow-up periods. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00000611.After a mean of 5.6 years (SD 1.3) of treatment and 2.4 years (0.4) of additional follow-up, 109 women in the combined hormone therapy group had been diagnosed with lung cancer compared with 85 in the placebo group (incidence per year 0.16%vs 0.13%; hazard ratio [HR] 1.23, 95% CI 0.92-1.63, p=0.16). 96 women assigned to combined therapy had non-small-cell lung cancer compared with 72 assigned to placebo (0.14%vs 0.11%; HR 1.28, 0.94-1.73, p=0.12). More women died from lung cancer in the combined hormone therapy group than in the placebo group (73 vs 40 deaths; 0.11%vs 0.06%; HR 1.71, 1.16-2.52, p=0.01), mainly as a result of a higher number of deaths from non-small-cell lung cancer in the combined therapy group (62 vs 31 deaths; 0.09%vs 0.05%; HR 1.87, 1.22-2.88, p=0.004). Incidence and mortality rates of small-cell lung cancer were similar between groups.Although treatment with oestrogen plus progestin in postmenopausal women did not increase incidence of lung cancer, it increased the number of deaths from lung cancer, in particular deaths from non-small-cell lung cancer. These findings should be incorporated into risk-benefit discussions with women considering combined hormone therapy, especially those with a high risk of lung cancer.National Heart, Lung and Blood Institute, National Institutes of Health.","Oestrogen plus progestin and lung cancer in postmenopausal women (Women's Health Initiative trial): a post-hoc analysis of a randomised controlled trial."
"1123","Lancet.169","3.00E-02",19767092,2009,"Paclitaxel and carboplatin given every 3 weeks is standard treatment for advanced ovarian carcinoma. Attempts to improve patient survival by including other drugs have yielded disappointing results. We compared a conventional regimen of paclitaxel and carboplatin with a dose-dense weekly regimen in women with advanced ovarian cancer.Patients with stage II to IV epithelial ovarian cancer, fallopian tube cancer, or primary peritoneal cancer were eligible for enrolment in this phase 3, open-label, randomised controlled trial at 85 centres in Japan. Patients were randomly assigned by computer-generated randomisation sequence to receive six cycles of either paclitaxel (180 mg/m(2); 3-h intravenous infusion) plus carboplatin (area under the curve [AUC] 6 mg/mL per min), given on day 1 of a 21-day cycle (conventional regimen; n=320), or dose-dense paclitaxel (80 mg/m(2); 1-h intravenous infusion) given on days 1, 8, and 15 plus carboplatin given on day 1 of a 21-day cycle (dose-dense regimen; n=317). The primary endpoint was progression-free survival. Analysis was by intention to treat (ITT). This trial is registered with ClinicalTrials.gov, number NCT00226915.631 of the 637 enrolled patients were eligible for treatment and were included in the ITT population (dose-dense regimen, n=312; conventional regimen, n=319). Median progression-free survival was longer in the dose-dense treatment group (28.0 months, 95% CI 22.3-35.4) than in the conventional treatment group (17.2 months, 15.7-21.1; hazard ratio [HR] 0.71; 95% CI 0.58-0.88; p=0.0015). Overall survival at 3 years was higher in the dose-dense regimen group (72.1%) than in the conventional treatment group (65.1%; HR 0.75, 0.57-0.98; p=0.03). 165 patients assigned to the dose-dense regimen and 117 assigned to the conventional regimen discontinued treatment early. Reasons for participant dropout were balanced between the groups, apart from withdrawal because of toxicity, which was higher in the dose-dense regimen group than in the conventional regimen group (n=113 vs n=69). The most common adverse event was neutropenia (dose-dense regimen, 286 [92%] of 312; conventional regimen, 276 [88%] of 314). The frequency of grade 3 and 4 anaemia was higher in the dose-dense treatment group (214 [69%]) than in the conventional treatment group (137 [44%]; p<0.0001). The frequencies of other toxic effects were similar between groups.Dose-dense weekly paclitaxel plus carboplatin improved survival compared with the conventional regimen and represents a new treatment option in women with advanced epithelial ovarian cancer.Bristol-Myers Squibb.","Dose-dense paclitaxel once a week in combination with carboplatin every 3 weeks for advanced ovarian cancer: a phase 3, open-label, randomised controlled trial."
"1124","Lancet.197","0.0015",19767092,2009,"Paclitaxel and carboplatin given every 3 weeks is standard treatment for advanced ovarian carcinoma. Attempts to improve patient survival by including other drugs have yielded disappointing results. We compared a conventional regimen of paclitaxel and carboplatin with a dose-dense weekly regimen in women with advanced ovarian cancer.Patients with stage II to IV epithelial ovarian cancer, fallopian tube cancer, or primary peritoneal cancer were eligible for enrolment in this phase 3, open-label, randomised controlled trial at 85 centres in Japan. Patients were randomly assigned by computer-generated randomisation sequence to receive six cycles of either paclitaxel (180 mg/m(2); 3-h intravenous infusion) plus carboplatin (area under the curve [AUC] 6 mg/mL per min), given on day 1 of a 21-day cycle (conventional regimen; n=320), or dose-dense paclitaxel (80 mg/m(2); 1-h intravenous infusion) given on days 1, 8, and 15 plus carboplatin given on day 1 of a 21-day cycle (dose-dense regimen; n=317). The primary endpoint was progression-free survival. Analysis was by intention to treat (ITT). This trial is registered with ClinicalTrials.gov, number NCT00226915.631 of the 637 enrolled patients were eligible for treatment and were included in the ITT population (dose-dense regimen, n=312; conventional regimen, n=319). Median progression-free survival was longer in the dose-dense treatment group (28.0 months, 95% CI 22.3-35.4) than in the conventional treatment group (17.2 months, 15.7-21.1; hazard ratio [HR] 0.71; 95% CI 0.58-0.88; p=0.0015). Overall survival at 3 years was higher in the dose-dense regimen group (72.1%) than in the conventional treatment group (65.1%; HR 0.75, 0.57-0.98; p=0.03). 165 patients assigned to the dose-dense regimen and 117 assigned to the conventional regimen discontinued treatment early. Reasons for participant dropout were balanced between the groups, apart from withdrawal because of toxicity, which was higher in the dose-dense regimen group than in the conventional regimen group (n=113 vs n=69). The most common adverse event was neutropenia (dose-dense regimen, 286 [92%] of 312; conventional regimen, 276 [88%] of 314). The frequency of grade 3 and 4 anaemia was higher in the dose-dense treatment group (214 [69%]) than in the conventional treatment group (137 [44%]; p<0.0001). The frequencies of other toxic effects were similar between groups.Dose-dense weekly paclitaxel plus carboplatin improved survival compared with the conventional regimen and represents a new treatment option in women with advanced epithelial ovarian cancer.Bristol-Myers Squibb.","Dose-dense paclitaxel once a week in combination with carboplatin every 3 weeks for advanced ovarian cancer: a phase 3, open-label, randomised controlled trial."
"1125","Lancet.167","1.00E-04",19767093,2009,"Several studies have shown the efficacy, tolerability, and ease of administration of pemetrexed-an antifolate antineoplastic agent-in patients with advanced non-small-cell lung cancer. We assessed pemetrexed as maintenance therapy in patients with this disease.This randomised double-blind study was undertaken in 83 centres in 20 countries. 663 patients with stage IIIB or IV disease who had not progressed on four cycles of platinum-based chemotherapy were randomly assigned (2:1 ratio) to receive pemetrexed (500 mg/m(2), day 1) plus best supportive care (n=441) or placebo plus best supportive care (n=222) in 21-day cycles until disease progression. Treatment was randomised with the Simon and Pocock minimisation method. Patients and investigators were masked to treatment. All patients received vitamin B(12), folic acid, and dexamethasone. The primary endpoint of progression-free survival and the secondary endpoint of overall survival were analysed by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00102804.All randomly assigned participants were analysed. Pemetrexed significantly improved progression-free survival (4.3 months [95% CI 4.1-4.7] vs 2.6 months [1.7-2.8]; hazard ratio [HR] 0.50, 95% CI 0.42-0.61, p<0.0001) and overall survival (13.4 months [11.9-15.9] vs 10.6 months [8.7-12.0]; HR 0.79, 0.65-0.95, p=0.012) compared with placebo. Treatment discontinuations due to drug-related toxic effects were higher in the pemetrexed group than in the placebo group (21 [5%] vs three [1%]). Drug-related grade three or higher toxic effects were higher with pemetrexed than with placebo (70 [16%] vs nine [4%]; p<0.0001), specifically fatigue (22 [5%] vs one [1%], p=0.001) and neutropenia (13 [3%] vs 0, p=0.006). No pemetrexed-related deaths occurred. Relatively fewer patients in the pemetrexed group than in the placebo group received systemic post-discontinuation therapy (227 [51%] vs 149 [67%]; p=0.0001).Maintenance therapy with pemetrexed is well tolerated and offers improved progression-free and overall survival compared with placebo in patients with advanced non-small-cell lung cancer.Eli Lilly.","Maintenance pemetrexed plus best supportive care versus placebo plus best supportive care for non-small-cell lung cancer: a randomised, double-blind, phase 3 study."
"1126","Lancet.193","0.012",19767093,2009,"Several studies have shown the efficacy, tolerability, and ease of administration of pemetrexed-an antifolate antineoplastic agent-in patients with advanced non-small-cell lung cancer. We assessed pemetrexed as maintenance therapy in patients with this disease.This randomised double-blind study was undertaken in 83 centres in 20 countries. 663 patients with stage IIIB or IV disease who had not progressed on four cycles of platinum-based chemotherapy were randomly assigned (2:1 ratio) to receive pemetrexed (500 mg/m(2), day 1) plus best supportive care (n=441) or placebo plus best supportive care (n=222) in 21-day cycles until disease progression. Treatment was randomised with the Simon and Pocock minimisation method. Patients and investigators were masked to treatment. All patients received vitamin B(12), folic acid, and dexamethasone. The primary endpoint of progression-free survival and the secondary endpoint of overall survival were analysed by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00102804.All randomly assigned participants were analysed. Pemetrexed significantly improved progression-free survival (4.3 months [95% CI 4.1-4.7] vs 2.6 months [1.7-2.8]; hazard ratio [HR] 0.50, 95% CI 0.42-0.61, p<0.0001) and overall survival (13.4 months [11.9-15.9] vs 10.6 months [8.7-12.0]; HR 0.79, 0.65-0.95, p=0.012) compared with placebo. Treatment discontinuations due to drug-related toxic effects were higher in the pemetrexed group than in the placebo group (21 [5%] vs three [1%]). Drug-related grade three or higher toxic effects were higher with pemetrexed than with placebo (70 [16%] vs nine [4%]; p<0.0001), specifically fatigue (22 [5%] vs one [1%], p=0.001) and neutropenia (13 [3%] vs 0, p=0.006). No pemetrexed-related deaths occurred. Relatively fewer patients in the pemetrexed group than in the placebo group received systemic post-discontinuation therapy (227 [51%] vs 149 [67%]; p=0.0001).Maintenance therapy with pemetrexed is well tolerated and offers improved progression-free and overall survival compared with placebo in patients with advanced non-small-cell lung cancer.Eli Lilly.","Maintenance pemetrexed plus best supportive care versus placebo plus best supportive care for non-small-cell lung cancer: a randomised, double-blind, phase 3 study."
"1127","JAMA.488","0.001",19773564,2009,"Fatigue and distress have been separately shown to be associated with medical errors. The contribution of each factor when assessed simultaneously is unknown.To determine the association of fatigue and distress with self-perceived major medical errors among resident physicians using validated metrics.Prospective longitudinal cohort study of categorical and preliminary internal medicine residents at Mayo Clinic, Rochester, Minnesota. Data were provided by 380 of 430 eligible residents (88.3%). Participants began training from 2003 to 2008 and completed surveys quarterly through February 2009. Surveys included self-assessment of medical errors, linear analog self-assessment of overall quality of life (QOL) and fatigue, the Maslach Burnout Inventory, the PRIME-MD depression screening instrument, and the Epworth Sleepiness Scale.Frequency of self-perceived, self-defined major medical errors was recorded. Associations of fatigue, QOL, burnout, and symptoms of depression with a subsequently reported major medical error were determined using generalized estimating equations for repeated measures.The mean response rate to individual surveys was 67.5%. Of the 356 participants providing error data (93.7%), 139 (39%) reported making at least 1 major medical error during the study period. In univariate analyses, there was an association of subsequent self-reported error with the Epworth Sleepiness Scale score (odds ratio [OR], 1.10 per unit increase; 95% confidence interval [CI], 1.03-1.16; P = .002) and fatigue score (OR, 1.14 per unit increase; 95% CI, 1.08-1.21; P < .001). Subsequent error was also associated with burnout (ORs per 1-unit change: depersonalization OR, 1.09; 95% CI, 1.05-1.12; P < .001; emotional exhaustion OR, 1.06; 95% CI, 1.04-1.08; P < .001; lower personal accomplishment OR, 0.94; 95% CI, 0.92-0.97; P < .001), a positive depression screen (OR, 2.56; 95% CI, 1.76-3.72; P < .001), and overall QOL (OR, 0.84 per unit increase; 95% CI, 0.79-0.91; P < .001). Fatigue and distress variables remained statistically significant when modeled together with little change in the point estimates of effect. Sleepiness and distress, when modeled together, showed little change in point estimates of effect, but sleepiness no longer had a statistically significant association with errors when adjusted for burnout or depression.Among internal medicine residents, higher levels of fatigue and distress are independently associated with self-perceived medical errors.","Association of resident fatigue and distress with perceived medical errors."
"1128","JAMA.489","0.001",19773564,2009,"Fatigue and distress have been separately shown to be associated with medical errors. The contribution of each factor when assessed simultaneously is unknown.To determine the association of fatigue and distress with self-perceived major medical errors among resident physicians using validated metrics.Prospective longitudinal cohort study of categorical and preliminary internal medicine residents at Mayo Clinic, Rochester, Minnesota. Data were provided by 380 of 430 eligible residents (88.3%). Participants began training from 2003 to 2008 and completed surveys quarterly through February 2009. Surveys included self-assessment of medical errors, linear analog self-assessment of overall quality of life (QOL) and fatigue, the Maslach Burnout Inventory, the PRIME-MD depression screening instrument, and the Epworth Sleepiness Scale.Frequency of self-perceived, self-defined major medical errors was recorded. Associations of fatigue, QOL, burnout, and symptoms of depression with a subsequently reported major medical error were determined using generalized estimating equations for repeated measures.The mean response rate to individual surveys was 67.5%. Of the 356 participants providing error data (93.7%), 139 (39%) reported making at least 1 major medical error during the study period. In univariate analyses, there was an association of subsequent self-reported error with the Epworth Sleepiness Scale score (odds ratio [OR], 1.10 per unit increase; 95% confidence interval [CI], 1.03-1.16; P = .002) and fatigue score (OR, 1.14 per unit increase; 95% CI, 1.08-1.21; P < .001). Subsequent error was also associated with burnout (ORs per 1-unit change: depersonalization OR, 1.09; 95% CI, 1.05-1.12; P < .001; emotional exhaustion OR, 1.06; 95% CI, 1.04-1.08; P < .001; lower personal accomplishment OR, 0.94; 95% CI, 0.92-0.97; P < .001), a positive depression screen (OR, 2.56; 95% CI, 1.76-3.72; P < .001), and overall QOL (OR, 0.84 per unit increase; 95% CI, 0.79-0.91; P < .001). Fatigue and distress variables remained statistically significant when modeled together with little change in the point estimates of effect. Sleepiness and distress, when modeled together, showed little change in point estimates of effect, but sleepiness no longer had a statistically significant association with errors when adjusted for burnout or depression.Among internal medicine residents, higher levels of fatigue and distress are independently associated with self-perceived medical errors.","Association of resident fatigue and distress with perceived medical errors."
"1129","JAMA.490","0.001",19773564,2009,"Fatigue and distress have been separately shown to be associated with medical errors. The contribution of each factor when assessed simultaneously is unknown.To determine the association of fatigue and distress with self-perceived major medical errors among resident physicians using validated metrics.Prospective longitudinal cohort study of categorical and preliminary internal medicine residents at Mayo Clinic, Rochester, Minnesota. Data were provided by 380 of 430 eligible residents (88.3%). Participants began training from 2003 to 2008 and completed surveys quarterly through February 2009. Surveys included self-assessment of medical errors, linear analog self-assessment of overall quality of life (QOL) and fatigue, the Maslach Burnout Inventory, the PRIME-MD depression screening instrument, and the Epworth Sleepiness Scale.Frequency of self-perceived, self-defined major medical errors was recorded. Associations of fatigue, QOL, burnout, and symptoms of depression with a subsequently reported major medical error were determined using generalized estimating equations for repeated measures.The mean response rate to individual surveys was 67.5%. Of the 356 participants providing error data (93.7%), 139 (39%) reported making at least 1 major medical error during the study period. In univariate analyses, there was an association of subsequent self-reported error with the Epworth Sleepiness Scale score (odds ratio [OR], 1.10 per unit increase; 95% confidence interval [CI], 1.03-1.16; P = .002) and fatigue score (OR, 1.14 per unit increase; 95% CI, 1.08-1.21; P < .001). Subsequent error was also associated with burnout (ORs per 1-unit change: depersonalization OR, 1.09; 95% CI, 1.05-1.12; P < .001; emotional exhaustion OR, 1.06; 95% CI, 1.04-1.08; P < .001; lower personal accomplishment OR, 0.94; 95% CI, 0.92-0.97; P < .001), a positive depression screen (OR, 2.56; 95% CI, 1.76-3.72; P < .001), and overall QOL (OR, 0.84 per unit increase; 95% CI, 0.79-0.91; P < .001). Fatigue and distress variables remained statistically significant when modeled together with little change in the point estimates of effect. Sleepiness and distress, when modeled together, showed little change in point estimates of effect, but sleepiness no longer had a statistically significant association with errors when adjusted for burnout or depression.Among internal medicine residents, higher levels of fatigue and distress are independently associated with self-perceived medical errors.","Association of resident fatigue and distress with perceived medical errors."
"1130","JAMA.491","0.001",19773564,2009,"Fatigue and distress have been separately shown to be associated with medical errors. The contribution of each factor when assessed simultaneously is unknown.To determine the association of fatigue and distress with self-perceived major medical errors among resident physicians using validated metrics.Prospective longitudinal cohort study of categorical and preliminary internal medicine residents at Mayo Clinic, Rochester, Minnesota. Data were provided by 380 of 430 eligible residents (88.3%). Participants began training from 2003 to 2008 and completed surveys quarterly through February 2009. Surveys included self-assessment of medical errors, linear analog self-assessment of overall quality of life (QOL) and fatigue, the Maslach Burnout Inventory, the PRIME-MD depression screening instrument, and the Epworth Sleepiness Scale.Frequency of self-perceived, self-defined major medical errors was recorded. Associations of fatigue, QOL, burnout, and symptoms of depression with a subsequently reported major medical error were determined using generalized estimating equations for repeated measures.The mean response rate to individual surveys was 67.5%. Of the 356 participants providing error data (93.7%), 139 (39%) reported making at least 1 major medical error during the study period. In univariate analyses, there was an association of subsequent self-reported error with the Epworth Sleepiness Scale score (odds ratio [OR], 1.10 per unit increase; 95% confidence interval [CI], 1.03-1.16; P = .002) and fatigue score (OR, 1.14 per unit increase; 95% CI, 1.08-1.21; P < .001). Subsequent error was also associated with burnout (ORs per 1-unit change: depersonalization OR, 1.09; 95% CI, 1.05-1.12; P < .001; emotional exhaustion OR, 1.06; 95% CI, 1.04-1.08; P < .001; lower personal accomplishment OR, 0.94; 95% CI, 0.92-0.97; P < .001), a positive depression screen (OR, 2.56; 95% CI, 1.76-3.72; P < .001), and overall QOL (OR, 0.84 per unit increase; 95% CI, 0.79-0.91; P < .001). Fatigue and distress variables remained statistically significant when modeled together with little change in the point estimates of effect. Sleepiness and distress, when modeled together, showed little change in point estimates of effect, but sleepiness no longer had a statistically significant association with errors when adjusted for burnout or depression.Among internal medicine residents, higher levels of fatigue and distress are independently associated with self-perceived medical errors.","Association of resident fatigue and distress with perceived medical errors."
"1131","JAMA.492","0.001",19773564,2009,"Fatigue and distress have been separately shown to be associated with medical errors. The contribution of each factor when assessed simultaneously is unknown.To determine the association of fatigue and distress with self-perceived major medical errors among resident physicians using validated metrics.Prospective longitudinal cohort study of categorical and preliminary internal medicine residents at Mayo Clinic, Rochester, Minnesota. Data were provided by 380 of 430 eligible residents (88.3%). Participants began training from 2003 to 2008 and completed surveys quarterly through February 2009. Surveys included self-assessment of medical errors, linear analog self-assessment of overall quality of life (QOL) and fatigue, the Maslach Burnout Inventory, the PRIME-MD depression screening instrument, and the Epworth Sleepiness Scale.Frequency of self-perceived, self-defined major medical errors was recorded. Associations of fatigue, QOL, burnout, and symptoms of depression with a subsequently reported major medical error were determined using generalized estimating equations for repeated measures.The mean response rate to individual surveys was 67.5%. Of the 356 participants providing error data (93.7%), 139 (39%) reported making at least 1 major medical error during the study period. In univariate analyses, there was an association of subsequent self-reported error with the Epworth Sleepiness Scale score (odds ratio [OR], 1.10 per unit increase; 95% confidence interval [CI], 1.03-1.16; P = .002) and fatigue score (OR, 1.14 per unit increase; 95% CI, 1.08-1.21; P < .001). Subsequent error was also associated with burnout (ORs per 1-unit change: depersonalization OR, 1.09; 95% CI, 1.05-1.12; P < .001; emotional exhaustion OR, 1.06; 95% CI, 1.04-1.08; P < .001; lower personal accomplishment OR, 0.94; 95% CI, 0.92-0.97; P < .001), a positive depression screen (OR, 2.56; 95% CI, 1.76-3.72; P < .001), and overall QOL (OR, 0.84 per unit increase; 95% CI, 0.79-0.91; P < .001). Fatigue and distress variables remained statistically significant when modeled together with little change in the point estimates of effect. Sleepiness and distress, when modeled together, showed little change in point estimates of effect, but sleepiness no longer had a statistically significant association with errors when adjusted for burnout or depression.Among internal medicine residents, higher levels of fatigue and distress are independently associated with self-perceived medical errors.","Association of resident fatigue and distress with perceived medical errors."
"1132","JAMA.493","0.001",19773564,2009,"Fatigue and distress have been separately shown to be associated with medical errors. The contribution of each factor when assessed simultaneously is unknown.To determine the association of fatigue and distress with self-perceived major medical errors among resident physicians using validated metrics.Prospective longitudinal cohort study of categorical and preliminary internal medicine residents at Mayo Clinic, Rochester, Minnesota. Data were provided by 380 of 430 eligible residents (88.3%). Participants began training from 2003 to 2008 and completed surveys quarterly through February 2009. Surveys included self-assessment of medical errors, linear analog self-assessment of overall quality of life (QOL) and fatigue, the Maslach Burnout Inventory, the PRIME-MD depression screening instrument, and the Epworth Sleepiness Scale.Frequency of self-perceived, self-defined major medical errors was recorded. Associations of fatigue, QOL, burnout, and symptoms of depression with a subsequently reported major medical error were determined using generalized estimating equations for repeated measures.The mean response rate to individual surveys was 67.5%. Of the 356 participants providing error data (93.7%), 139 (39%) reported making at least 1 major medical error during the study period. In univariate analyses, there was an association of subsequent self-reported error with the Epworth Sleepiness Scale score (odds ratio [OR], 1.10 per unit increase; 95% confidence interval [CI], 1.03-1.16; P = .002) and fatigue score (OR, 1.14 per unit increase; 95% CI, 1.08-1.21; P < .001). Subsequent error was also associated with burnout (ORs per 1-unit change: depersonalization OR, 1.09; 95% CI, 1.05-1.12; P < .001; emotional exhaustion OR, 1.06; 95% CI, 1.04-1.08; P < .001; lower personal accomplishment OR, 0.94; 95% CI, 0.92-0.97; P < .001), a positive depression screen (OR, 2.56; 95% CI, 1.76-3.72; P < .001), and overall QOL (OR, 0.84 per unit increase; 95% CI, 0.79-0.91; P < .001). Fatigue and distress variables remained statistically significant when modeled together with little change in the point estimates of effect. Sleepiness and distress, when modeled together, showed little change in point estimates of effect, but sleepiness no longer had a statistically significant association with errors when adjusted for burnout or depression.Among internal medicine residents, higher levels of fatigue and distress are independently associated with self-perceived medical errors.","Association of resident fatigue and distress with perceived medical errors."
"1133","JAMA.519","0.002",19773564,2009,"Fatigue and distress have been separately shown to be associated with medical errors. The contribution of each factor when assessed simultaneously is unknown.To determine the association of fatigue and distress with self-perceived major medical errors among resident physicians using validated metrics.Prospective longitudinal cohort study of categorical and preliminary internal medicine residents at Mayo Clinic, Rochester, Minnesota. Data were provided by 380 of 430 eligible residents (88.3%). Participants began training from 2003 to 2008 and completed surveys quarterly through February 2009. Surveys included self-assessment of medical errors, linear analog self-assessment of overall quality of life (QOL) and fatigue, the Maslach Burnout Inventory, the PRIME-MD depression screening instrument, and the Epworth Sleepiness Scale.Frequency of self-perceived, self-defined major medical errors was recorded. Associations of fatigue, QOL, burnout, and symptoms of depression with a subsequently reported major medical error were determined using generalized estimating equations for repeated measures.The mean response rate to individual surveys was 67.5%. Of the 356 participants providing error data (93.7%), 139 (39%) reported making at least 1 major medical error during the study period. In univariate analyses, there was an association of subsequent self-reported error with the Epworth Sleepiness Scale score (odds ratio [OR], 1.10 per unit increase; 95% confidence interval [CI], 1.03-1.16; P = .002) and fatigue score (OR, 1.14 per unit increase; 95% CI, 1.08-1.21; P < .001). Subsequent error was also associated with burnout (ORs per 1-unit change: depersonalization OR, 1.09; 95% CI, 1.05-1.12; P < .001; emotional exhaustion OR, 1.06; 95% CI, 1.04-1.08; P < .001; lower personal accomplishment OR, 0.94; 95% CI, 0.92-0.97; P < .001), a positive depression screen (OR, 2.56; 95% CI, 1.76-3.72; P < .001), and overall QOL (OR, 0.84 per unit increase; 95% CI, 0.79-0.91; P < .001). Fatigue and distress variables remained statistically significant when modeled together with little change in the point estimates of effect. Sleepiness and distress, when modeled together, showed little change in point estimates of effect, but sleepiness no longer had a statistically significant association with errors when adjusted for burnout or depression.Among internal medicine residents, higher levels of fatigue and distress are independently associated with self-perceived medical errors.","Association of resident fatigue and distress with perceived medical errors."
"1134","JAMA.514","0.64",19826023,2009,"Use of 80% oxygen during surgery has been suggested to reduce the risk of surgical wound infections, but this effect has not been consistently identified. The effect of 80% oxygen on pulmonary complications has not been well defined.To assess whether use of 80% oxygen reduces the frequency of surgical site infection without increasing the frequency of pulmonary complications in patients undergoing abdominal surgery.The PROXI trial, a patient- and observer-blinded randomized clinical trial conducted in 14 Danish hospitals between October 2006 and October 2008 among 1400 patients undergoing acute or elective laparotomy.Patients were randomly assigned to receive either 80% or 30% oxygen during and for 2 hours after surgery.Surgical site infection within 14 days, defined according to the Centers for Disease Control and Prevention. Secondary outcomes included atelectasis, pneumonia, respiratory failure, and mortality.Surgical site infection occurred in 131 of 685 patients (19.1%) assigned to receive 80% oxygen vs 141 of 701 (20.1%) assigned to receive 30% oxygen (odds ratio [OR], 0.94; 95% confidence interval [CI], 0.72-1.22; P = .64). Atelectasis occurred in 54 of 685 patients (7.9%) assigned to receive 80% oxygen vs 50 of 701 (7.1%) assigned to receive 30% oxygen (OR, 1.11; 95% CI, 0.75-1.66; P = .60), pneumonia in 41 (6.0%) vs 44 (6.3%) (OR, 0.95; 95% CI, 0.61-1.48; P = .82), respiratory failure in 38 (5.5%) vs 31 (4.4%) (OR, 1.27; 95% CI, 0.78-2.07; P = .34), and mortality within 30 days in 30 (4.4%) vs 20 (2.9%) (OR, 1.56; 95% CI, 0.88-2.77; P = .13).Administration of 80% oxygen compared with 30% oxygen did not result in a difference in risk of surgical site infection after abdominal surgery.clinicaltrials.gov Identifier: NCT00364741.","Effect of high perioperative oxygen fraction on surgical site infection and pulmonary complications after abdominal surgery: the PROXI randomized clinical trial."
"1135","JAMA.515","0.6",19826023,2009,"Use of 80% oxygen during surgery has been suggested to reduce the risk of surgical wound infections, but this effect has not been consistently identified. The effect of 80% oxygen on pulmonary complications has not been well defined.To assess whether use of 80% oxygen reduces the frequency of surgical site infection without increasing the frequency of pulmonary complications in patients undergoing abdominal surgery.The PROXI trial, a patient- and observer-blinded randomized clinical trial conducted in 14 Danish hospitals between October 2006 and October 2008 among 1400 patients undergoing acute or elective laparotomy.Patients were randomly assigned to receive either 80% or 30% oxygen during and for 2 hours after surgery.Surgical site infection within 14 days, defined according to the Centers for Disease Control and Prevention. Secondary outcomes included atelectasis, pneumonia, respiratory failure, and mortality.Surgical site infection occurred in 131 of 685 patients (19.1%) assigned to receive 80% oxygen vs 141 of 701 (20.1%) assigned to receive 30% oxygen (odds ratio [OR], 0.94; 95% confidence interval [CI], 0.72-1.22; P = .64). Atelectasis occurred in 54 of 685 patients (7.9%) assigned to receive 80% oxygen vs 50 of 701 (7.1%) assigned to receive 30% oxygen (OR, 1.11; 95% CI, 0.75-1.66; P = .60), pneumonia in 41 (6.0%) vs 44 (6.3%) (OR, 0.95; 95% CI, 0.61-1.48; P = .82), respiratory failure in 38 (5.5%) vs 31 (4.4%) (OR, 1.27; 95% CI, 0.78-2.07; P = .34), and mortality within 30 days in 30 (4.4%) vs 20 (2.9%) (OR, 1.56; 95% CI, 0.88-2.77; P = .13).Administration of 80% oxygen compared with 30% oxygen did not result in a difference in risk of surgical site infection after abdominal surgery.clinicaltrials.gov Identifier: NCT00364741.","Effect of high perioperative oxygen fraction on surgical site infection and pulmonary complications after abdominal surgery: the PROXI randomized clinical trial."
"1136","JAMA.516","0.82",19826023,2009,"Use of 80% oxygen during surgery has been suggested to reduce the risk of surgical wound infections, but this effect has not been consistently identified. The effect of 80% oxygen on pulmonary complications has not been well defined.To assess whether use of 80% oxygen reduces the frequency of surgical site infection without increasing the frequency of pulmonary complications in patients undergoing abdominal surgery.The PROXI trial, a patient- and observer-blinded randomized clinical trial conducted in 14 Danish hospitals between October 2006 and October 2008 among 1400 patients undergoing acute or elective laparotomy.Patients were randomly assigned to receive either 80% or 30% oxygen during and for 2 hours after surgery.Surgical site infection within 14 days, defined according to the Centers for Disease Control and Prevention. Secondary outcomes included atelectasis, pneumonia, respiratory failure, and mortality.Surgical site infection occurred in 131 of 685 patients (19.1%) assigned to receive 80% oxygen vs 141 of 701 (20.1%) assigned to receive 30% oxygen (odds ratio [OR], 0.94; 95% confidence interval [CI], 0.72-1.22; P = .64). Atelectasis occurred in 54 of 685 patients (7.9%) assigned to receive 80% oxygen vs 50 of 701 (7.1%) assigned to receive 30% oxygen (OR, 1.11; 95% CI, 0.75-1.66; P = .60), pneumonia in 41 (6.0%) vs 44 (6.3%) (OR, 0.95; 95% CI, 0.61-1.48; P = .82), respiratory failure in 38 (5.5%) vs 31 (4.4%) (OR, 1.27; 95% CI, 0.78-2.07; P = .34), and mortality within 30 days in 30 (4.4%) vs 20 (2.9%) (OR, 1.56; 95% CI, 0.88-2.77; P = .13).Administration of 80% oxygen compared with 30% oxygen did not result in a difference in risk of surgical site infection after abdominal surgery.clinicaltrials.gov Identifier: NCT00364741.","Effect of high perioperative oxygen fraction on surgical site infection and pulmonary complications after abdominal surgery: the PROXI randomized clinical trial."
"1137","JAMA.517","0.34",19826023,2009,"Use of 80% oxygen during surgery has been suggested to reduce the risk of surgical wound infections, but this effect has not been consistently identified. The effect of 80% oxygen on pulmonary complications has not been well defined.To assess whether use of 80% oxygen reduces the frequency of surgical site infection without increasing the frequency of pulmonary complications in patients undergoing abdominal surgery.The PROXI trial, a patient- and observer-blinded randomized clinical trial conducted in 14 Danish hospitals between October 2006 and October 2008 among 1400 patients undergoing acute or elective laparotomy.Patients were randomly assigned to receive either 80% or 30% oxygen during and for 2 hours after surgery.Surgical site infection within 14 days, defined according to the Centers for Disease Control and Prevention. Secondary outcomes included atelectasis, pneumonia, respiratory failure, and mortality.Surgical site infection occurred in 131 of 685 patients (19.1%) assigned to receive 80% oxygen vs 141 of 701 (20.1%) assigned to receive 30% oxygen (odds ratio [OR], 0.94; 95% confidence interval [CI], 0.72-1.22; P = .64). Atelectasis occurred in 54 of 685 patients (7.9%) assigned to receive 80% oxygen vs 50 of 701 (7.1%) assigned to receive 30% oxygen (OR, 1.11; 95% CI, 0.75-1.66; P = .60), pneumonia in 41 (6.0%) vs 44 (6.3%) (OR, 0.95; 95% CI, 0.61-1.48; P = .82), respiratory failure in 38 (5.5%) vs 31 (4.4%) (OR, 1.27; 95% CI, 0.78-2.07; P = .34), and mortality within 30 days in 30 (4.4%) vs 20 (2.9%) (OR, 1.56; 95% CI, 0.88-2.77; P = .13).Administration of 80% oxygen compared with 30% oxygen did not result in a difference in risk of surgical site infection after abdominal surgery.clinicaltrials.gov Identifier: NCT00364741.","Effect of high perioperative oxygen fraction on surgical site infection and pulmonary complications after abdominal surgery: the PROXI randomized clinical trial."
"1138","JAMA.518","0.13",19826023,2009,"Use of 80% oxygen during surgery has been suggested to reduce the risk of surgical wound infections, but this effect has not been consistently identified. The effect of 80% oxygen on pulmonary complications has not been well defined.To assess whether use of 80% oxygen reduces the frequency of surgical site infection without increasing the frequency of pulmonary complications in patients undergoing abdominal surgery.The PROXI trial, a patient- and observer-blinded randomized clinical trial conducted in 14 Danish hospitals between October 2006 and October 2008 among 1400 patients undergoing acute or elective laparotomy.Patients were randomly assigned to receive either 80% or 30% oxygen during and for 2 hours after surgery.Surgical site infection within 14 days, defined according to the Centers for Disease Control and Prevention. Secondary outcomes included atelectasis, pneumonia, respiratory failure, and mortality.Surgical site infection occurred in 131 of 685 patients (19.1%) assigned to receive 80% oxygen vs 141 of 701 (20.1%) assigned to receive 30% oxygen (odds ratio [OR], 0.94; 95% confidence interval [CI], 0.72-1.22; P = .64). Atelectasis occurred in 54 of 685 patients (7.9%) assigned to receive 80% oxygen vs 50 of 701 (7.1%) assigned to receive 30% oxygen (OR, 1.11; 95% CI, 0.75-1.66; P = .60), pneumonia in 41 (6.0%) vs 44 (6.3%) (OR, 0.95; 95% CI, 0.61-1.48; P = .82), respiratory failure in 38 (5.5%) vs 31 (4.4%) (OR, 1.27; 95% CI, 0.78-2.07; P = .34), and mortality within 30 days in 30 (4.4%) vs 20 (2.9%) (OR, 1.56; 95% CI, 0.88-2.77; P = .13).Administration of 80% oxygen compared with 30% oxygen did not result in a difference in risk of surgical site infection after abdominal surgery.clinicaltrials.gov Identifier: NCT00364741.","Effect of high perioperative oxygen fraction on surgical site infection and pulmonary complications after abdominal surgery: the PROXI randomized clinical trial."
"1139","JAMA.509","0.91",19843899,2009,"Studies of depressed psychiatric patients have shown that antidepressant efficacy can be increased by augmentation with omega-3 fatty acids.To determine whether omega-3 improves the response to sertraline in patients with major depression and coronary heart disease (CHD).Randomized controlled trial. Between May 2005 and December 2008, 122 patients in St Louis, Missouri, with major depression and CHD were randomized.After a 2-week run-in period, all patients were given 50 mg/d of sertraline and randomized in double-blind fashion to receive 2 g/d of omega-3 acid ethyl esters (930 mg of eicosapentaenoic acid [EPA] and 750 mg of docosahexaenoic acid [DHA]) (n=62) or to corn oil placebo capsules (n=60) for 10 weeks.Scores on the Beck Depression Inventory (BDI-II) and the Hamilton Rating Scale for Depression (HAM-D).Adherence to the medication regimen was 97% or more in both groups for both medications. There were no differences in weekly BDI-II scores (treatment x time interaction = 0.02; 95% confidence interval [CI], -0.33 to 0.36; t(112) = 0.11; P = .91), pre-post BDI-II scores (placebo, 14.8 vs omega-3, 16.1; 95% difference-in-means CI, -4.5 to 2.0; t(116) = -0.77; P = .44), or HAM-D scores (placebo, 9.4 vs omega-3, 9.3; 95% difference-in-means CI, -2.2 to 2.4; t(115) = 0.12; P = .90). The groups did not differ on predefined indicators of depression remission (BDI-II < or = 8: placebo, 27.4% vs omega-3, 28.3%; odds ratio [OR], 0.96; 95% CI, 0.43-2.15; t(113) = -0.11; P = .91) or response (> 50% reduction in BDI-II from baseline: placebo, 49.0% vs omega-3, 47.7%; OR, 1.06; 95% CI, 0.51-2.19; t(112) = 0.15; P = .88).Treatment of patients with CHD and major depression with sertraline and omega-3 fatty acids did not result in superior depression outcomes at 10 weeks, compared with sertraline and placebo. Whether higher doses of omega-3 or sertraline, a different ratio of EPA to DHA, longer treatment, or omega-3 monotherapy can improve depression in patients with CHD remains to be determined.clinicaltrials.gov Identifier: NCT00116857.","Omega-3 augmentation of sertraline in treatment of depression in patients with coronary heart disease: a randomized controlled trial."
"1140","JAMA.513","0.88",19843899,2009,"Studies of depressed psychiatric patients have shown that antidepressant efficacy can be increased by augmentation with omega-3 fatty acids.To determine whether omega-3 improves the response to sertraline in patients with major depression and coronary heart disease (CHD).Randomized controlled trial. Between May 2005 and December 2008, 122 patients in St Louis, Missouri, with major depression and CHD were randomized.After a 2-week run-in period, all patients were given 50 mg/d of sertraline and randomized in double-blind fashion to receive 2 g/d of omega-3 acid ethyl esters (930 mg of eicosapentaenoic acid [EPA] and 750 mg of docosahexaenoic acid [DHA]) (n=62) or to corn oil placebo capsules (n=60) for 10 weeks.Scores on the Beck Depression Inventory (BDI-II) and the Hamilton Rating Scale for Depression (HAM-D).Adherence to the medication regimen was 97% or more in both groups for both medications. There were no differences in weekly BDI-II scores (treatment x time interaction = 0.02; 95% confidence interval [CI], -0.33 to 0.36; t(112) = 0.11; P = .91), pre-post BDI-II scores (placebo, 14.8 vs omega-3, 16.1; 95% difference-in-means CI, -4.5 to 2.0; t(116) = -0.77; P = .44), or HAM-D scores (placebo, 9.4 vs omega-3, 9.3; 95% difference-in-means CI, -2.2 to 2.4; t(115) = 0.12; P = .90). The groups did not differ on predefined indicators of depression remission (BDI-II < or = 8: placebo, 27.4% vs omega-3, 28.3%; odds ratio [OR], 0.96; 95% CI, 0.43-2.15; t(113) = -0.11; P = .91) or response (> 50% reduction in BDI-II from baseline: placebo, 49.0% vs omega-3, 47.7%; OR, 1.06; 95% CI, 0.51-2.19; t(112) = 0.15; P = .88).Treatment of patients with CHD and major depression with sertraline and omega-3 fatty acids did not result in superior depression outcomes at 10 weeks, compared with sertraline and placebo. Whether higher doses of omega-3 or sertraline, a different ratio of EPA to DHA, longer treatment, or omega-3 monotherapy can improve depression in patients with CHD remains to be determined.clinicaltrials.gov Identifier: NCT00116857.","Omega-3 augmentation of sertraline in treatment of depression in patients with coronary heart disease: a randomized controlled trial."
"1141","American Journal of Epidemiology.91","0.006",19864305,2009,"The ubiquitin carboxyl-terminal esterase L1 gene, UCHL1, located on chromosome 4p14, has been studied as a potential candidate gene for Parkinson's disease risk. The authors conducted a Human Genome Epidemiology review and meta-analysis of published case-control studies of the UCHL1 S18Y variant and Parkinson's disease in Asian and Caucasian samples. The meta-analysis of studies in populations of Asian ancestry showed a statistically significant association between the Y allele and reduced risk of Parkinson's disease under a recessive model (odds ratio (OR) for YY vs. SY + SS = 0.79, 95% confidence interval (CI): 0.67, 0.94; P = 0.006). For a dominant model, the association was not significant in Asian populations (OR for YY + SY vs. SS = 0.88, 95% CI: 0.68, 1.14; P = 0.33). For populations of European ancestry, the meta-analysis showed a significant association between the Y allele and decreased risk of Parkinson's disease under a dominant model (OR = 0.89, 95% CI: 0.81, 0.98; P = 0.02) but not under a recessive model (OR = 0.92, 95% CI: 0.66, 1.30; P = 0.65). Using the Venice criteria, developed by the Human Genome Epidemiology Network Working Group on the assessment of cumulative evidence, the authors concluded that moderate evidence exists for an association between the S18Y variant and Parkinson's disease.","Association between the ubiquitin carboxyl-terminal esterase L1 gene (UCHL1) S18Y variant and Parkinson's Disease: a HuGE review and meta-analysis."
"1142","American Journal of Epidemiology.92","0.33",19864305,2009,"The ubiquitin carboxyl-terminal esterase L1 gene, UCHL1, located on chromosome 4p14, has been studied as a potential candidate gene for Parkinson's disease risk. The authors conducted a Human Genome Epidemiology review and meta-analysis of published case-control studies of the UCHL1 S18Y variant and Parkinson's disease in Asian and Caucasian samples. The meta-analysis of studies in populations of Asian ancestry showed a statistically significant association between the Y allele and reduced risk of Parkinson's disease under a recessive model (odds ratio (OR) for YY vs. SY + SS = 0.79, 95% confidence interval (CI): 0.67, 0.94; P = 0.006). For a dominant model, the association was not significant in Asian populations (OR for YY + SY vs. SS = 0.88, 95% CI: 0.68, 1.14; P = 0.33). For populations of European ancestry, the meta-analysis showed a significant association between the Y allele and decreased risk of Parkinson's disease under a dominant model (OR = 0.89, 95% CI: 0.81, 0.98; P = 0.02) but not under a recessive model (OR = 0.92, 95% CI: 0.66, 1.30; P = 0.65). Using the Venice criteria, developed by the Human Genome Epidemiology Network Working Group on the assessment of cumulative evidence, the authors concluded that moderate evidence exists for an association between the S18Y variant and Parkinson's disease.","Association between the ubiquitin carboxyl-terminal esterase L1 gene (UCHL1) S18Y variant and Parkinson's Disease: a HuGE review and meta-analysis."
"1143","American Journal of Epidemiology.93","0.02",19864305,2009,"The ubiquitin carboxyl-terminal esterase L1 gene, UCHL1, located on chromosome 4p14, has been studied as a potential candidate gene for Parkinson's disease risk. The authors conducted a Human Genome Epidemiology review and meta-analysis of published case-control studies of the UCHL1 S18Y variant and Parkinson's disease in Asian and Caucasian samples. The meta-analysis of studies in populations of Asian ancestry showed a statistically significant association between the Y allele and reduced risk of Parkinson's disease under a recessive model (odds ratio (OR) for YY vs. SY + SS = 0.79, 95% confidence interval (CI): 0.67, 0.94; P = 0.006). For a dominant model, the association was not significant in Asian populations (OR for YY + SY vs. SS = 0.88, 95% CI: 0.68, 1.14; P = 0.33). For populations of European ancestry, the meta-analysis showed a significant association between the Y allele and decreased risk of Parkinson's disease under a dominant model (OR = 0.89, 95% CI: 0.81, 0.98; P = 0.02) but not under a recessive model (OR = 0.92, 95% CI: 0.66, 1.30; P = 0.65). Using the Venice criteria, developed by the Human Genome Epidemiology Network Working Group on the assessment of cumulative evidence, the authors concluded that moderate evidence exists for an association between the S18Y variant and Parkinson's disease.","Association between the ubiquitin carboxyl-terminal esterase L1 gene (UCHL1) S18Y variant and Parkinson's Disease: a HuGE review and meta-analysis."
"1144","American Journal of Epidemiology.94","0.65",19864305,2009,"The ubiquitin carboxyl-terminal esterase L1 gene, UCHL1, located on chromosome 4p14, has been studied as a potential candidate gene for Parkinson's disease risk. The authors conducted a Human Genome Epidemiology review and meta-analysis of published case-control studies of the UCHL1 S18Y variant and Parkinson's disease in Asian and Caucasian samples. The meta-analysis of studies in populations of Asian ancestry showed a statistically significant association between the Y allele and reduced risk of Parkinson's disease under a recessive model (odds ratio (OR) for YY vs. SY + SS = 0.79, 95% confidence interval (CI): 0.67, 0.94; P = 0.006). For a dominant model, the association was not significant in Asian populations (OR for YY + SY vs. SS = 0.88, 95% CI: 0.68, 1.14; P = 0.33). For populations of European ancestry, the meta-analysis showed a significant association between the Y allele and decreased risk of Parkinson's disease under a dominant model (OR = 0.89, 95% CI: 0.81, 0.98; P = 0.02) but not under a recessive model (OR = 0.92, 95% CI: 0.66, 1.30; P = 0.65). Using the Venice criteria, developed by the Human Genome Epidemiology Network Working Group on the assessment of cumulative evidence, the authors concluded that moderate evidence exists for an association between the S18Y variant and Parkinson's disease.","Association between the ubiquitin carboxyl-terminal esterase L1 gene (UCHL1) S18Y variant and Parkinson's Disease: a HuGE review and meta-analysis."
"1145","JAMA.483","0.001",19903919,2009,"Persistent pain and sensory disturbances following surgical treatment for breast cancer is a significant clinical problem. The pathogenic mechanisms are complex and may be related to patient characteristics, surgical technique, and adjuvant therapy.To examine prevalence of and factors associated with persistent pain after surgical treatment for breast cancer.A nationwide cross-sectional questionnaire study of 3754 women aged 18 to 70 years who received surgery and adjuvant therapy (if indicated) for primary breast cancer in Denmark between January 1, 2005, and December 31, 2006. A study questionnaire was sent to the women between January and April 2008.Prevalence, location, and severity of persistent pain and sensory disturbances in 12 well-defined treatment groups assessed an average of 26 months after surgery, and adjusted odds ratio (OR) of reported pain and sensory disturbances with respect to age, surgical technique, chemotherapy, and radiotherapy.By June 2008, 3253 of 3754 eligible women (87%) returned the questionnaire. A total of 1543 patients (47%) reported pain, of whom 201 (13%) had severe pain, 595 (39%) had moderate pain, and 733 (48%) had light pain. Factors associated with chronic pain included young age (18-39 years: OR, 3.62; 95% confidence interval [CI], 2.25-5.82; P < .001) and adjuvant radiotherapy (OR, 1.50; 95% CI, 1.08-2.07; P = .03), but not chemotherapy (OR, 1.01; 95% CI, 0.85-1.21; P = .91). Axillary lymph node dissection (ALND) was associated with increased likelihood of pain (OR, 1.77; 95% CI, 1.43-2.19; P < .001) compared with sentinel lymph node dissection. Risk of sensory disturbances was associated with young age (18-39 years: OR, 5.00; 95% CI, 2.87-8.69; P < .001) and ALND (OR, 4.97; 95% CI, 3.92-6.30; P < .001). Pain complaints from other parts of the body were associated with increased risk of pain in the surgical area (P < .001). A total of 306 patients (20%) with pain had contacted a physician within the prior 3 months for pain complaints in the surgical area.Two to 3 years after breast cancer treatment, persistent pain and sensory disturbances remain clinically significant problems among Danish women who received surgery in 2005 and 2006.","Prevalence of and factors associated with persistent pain following breast cancer surgery."
"1146","JAMA.484","0.001",19903919,2009,"Persistent pain and sensory disturbances following surgical treatment for breast cancer is a significant clinical problem. The pathogenic mechanisms are complex and may be related to patient characteristics, surgical technique, and adjuvant therapy.To examine prevalence of and factors associated with persistent pain after surgical treatment for breast cancer.A nationwide cross-sectional questionnaire study of 3754 women aged 18 to 70 years who received surgery and adjuvant therapy (if indicated) for primary breast cancer in Denmark between January 1, 2005, and December 31, 2006. A study questionnaire was sent to the women between January and April 2008.Prevalence, location, and severity of persistent pain and sensory disturbances in 12 well-defined treatment groups assessed an average of 26 months after surgery, and adjusted odds ratio (OR) of reported pain and sensory disturbances with respect to age, surgical technique, chemotherapy, and radiotherapy.By June 2008, 3253 of 3754 eligible women (87%) returned the questionnaire. A total of 1543 patients (47%) reported pain, of whom 201 (13%) had severe pain, 595 (39%) had moderate pain, and 733 (48%) had light pain. Factors associated with chronic pain included young age (18-39 years: OR, 3.62; 95% confidence interval [CI], 2.25-5.82; P < .001) and adjuvant radiotherapy (OR, 1.50; 95% CI, 1.08-2.07; P = .03), but not chemotherapy (OR, 1.01; 95% CI, 0.85-1.21; P = .91). Axillary lymph node dissection (ALND) was associated with increased likelihood of pain (OR, 1.77; 95% CI, 1.43-2.19; P < .001) compared with sentinel lymph node dissection. Risk of sensory disturbances was associated with young age (18-39 years: OR, 5.00; 95% CI, 2.87-8.69; P < .001) and ALND (OR, 4.97; 95% CI, 3.92-6.30; P < .001). Pain complaints from other parts of the body were associated with increased risk of pain in the surgical area (P < .001). A total of 306 patients (20%) with pain had contacted a physician within the prior 3 months for pain complaints in the surgical area.Two to 3 years after breast cancer treatment, persistent pain and sensory disturbances remain clinically significant problems among Danish women who received surgery in 2005 and 2006.","Prevalence of and factors associated with persistent pain following breast cancer surgery."
"1147","JAMA.485","0.001",19903919,2009,"Persistent pain and sensory disturbances following surgical treatment for breast cancer is a significant clinical problem. The pathogenic mechanisms are complex and may be related to patient characteristics, surgical technique, and adjuvant therapy.To examine prevalence of and factors associated with persistent pain after surgical treatment for breast cancer.A nationwide cross-sectional questionnaire study of 3754 women aged 18 to 70 years who received surgery and adjuvant therapy (if indicated) for primary breast cancer in Denmark between January 1, 2005, and December 31, 2006. A study questionnaire was sent to the women between January and April 2008.Prevalence, location, and severity of persistent pain and sensory disturbances in 12 well-defined treatment groups assessed an average of 26 months after surgery, and adjusted odds ratio (OR) of reported pain and sensory disturbances with respect to age, surgical technique, chemotherapy, and radiotherapy.By June 2008, 3253 of 3754 eligible women (87%) returned the questionnaire. A total of 1543 patients (47%) reported pain, of whom 201 (13%) had severe pain, 595 (39%) had moderate pain, and 733 (48%) had light pain. Factors associated with chronic pain included young age (18-39 years: OR, 3.62; 95% confidence interval [CI], 2.25-5.82; P < .001) and adjuvant radiotherapy (OR, 1.50; 95% CI, 1.08-2.07; P = .03), but not chemotherapy (OR, 1.01; 95% CI, 0.85-1.21; P = .91). Axillary lymph node dissection (ALND) was associated with increased likelihood of pain (OR, 1.77; 95% CI, 1.43-2.19; P < .001) compared with sentinel lymph node dissection. Risk of sensory disturbances was associated with young age (18-39 years: OR, 5.00; 95% CI, 2.87-8.69; P < .001) and ALND (OR, 4.97; 95% CI, 3.92-6.30; P < .001). Pain complaints from other parts of the body were associated with increased risk of pain in the surgical area (P < .001). A total of 306 patients (20%) with pain had contacted a physician within the prior 3 months for pain complaints in the surgical area.Two to 3 years after breast cancer treatment, persistent pain and sensory disturbances remain clinically significant problems among Danish women who received surgery in 2005 and 2006.","Prevalence of and factors associated with persistent pain following breast cancer surgery."
"1148","JAMA.486","0.001",19903919,2009,"Persistent pain and sensory disturbances following surgical treatment for breast cancer is a significant clinical problem. The pathogenic mechanisms are complex and may be related to patient characteristics, surgical technique, and adjuvant therapy.To examine prevalence of and factors associated with persistent pain after surgical treatment for breast cancer.A nationwide cross-sectional questionnaire study of 3754 women aged 18 to 70 years who received surgery and adjuvant therapy (if indicated) for primary breast cancer in Denmark between January 1, 2005, and December 31, 2006. A study questionnaire was sent to the women between January and April 2008.Prevalence, location, and severity of persistent pain and sensory disturbances in 12 well-defined treatment groups assessed an average of 26 months after surgery, and adjusted odds ratio (OR) of reported pain and sensory disturbances with respect to age, surgical technique, chemotherapy, and radiotherapy.By June 2008, 3253 of 3754 eligible women (87%) returned the questionnaire. A total of 1543 patients (47%) reported pain, of whom 201 (13%) had severe pain, 595 (39%) had moderate pain, and 733 (48%) had light pain. Factors associated with chronic pain included young age (18-39 years: OR, 3.62; 95% confidence interval [CI], 2.25-5.82; P < .001) and adjuvant radiotherapy (OR, 1.50; 95% CI, 1.08-2.07; P = .03), but not chemotherapy (OR, 1.01; 95% CI, 0.85-1.21; P = .91). Axillary lymph node dissection (ALND) was associated with increased likelihood of pain (OR, 1.77; 95% CI, 1.43-2.19; P < .001) compared with sentinel lymph node dissection. Risk of sensory disturbances was associated with young age (18-39 years: OR, 5.00; 95% CI, 2.87-8.69; P < .001) and ALND (OR, 4.97; 95% CI, 3.92-6.30; P < .001). Pain complaints from other parts of the body were associated with increased risk of pain in the surgical area (P < .001). A total of 306 patients (20%) with pain had contacted a physician within the prior 3 months for pain complaints in the surgical area.Two to 3 years after breast cancer treatment, persistent pain and sensory disturbances remain clinically significant problems among Danish women who received surgery in 2005 and 2006.","Prevalence of and factors associated with persistent pain following breast cancer surgery."
"1149","JAMA.507","0.03",19903919,2009,"Persistent pain and sensory disturbances following surgical treatment for breast cancer is a significant clinical problem. The pathogenic mechanisms are complex and may be related to patient characteristics, surgical technique, and adjuvant therapy.To examine prevalence of and factors associated with persistent pain after surgical treatment for breast cancer.A nationwide cross-sectional questionnaire study of 3754 women aged 18 to 70 years who received surgery and adjuvant therapy (if indicated) for primary breast cancer in Denmark between January 1, 2005, and December 31, 2006. A study questionnaire was sent to the women between January and April 2008.Prevalence, location, and severity of persistent pain and sensory disturbances in 12 well-defined treatment groups assessed an average of 26 months after surgery, and adjusted odds ratio (OR) of reported pain and sensory disturbances with respect to age, surgical technique, chemotherapy, and radiotherapy.By June 2008, 3253 of 3754 eligible women (87%) returned the questionnaire. A total of 1543 patients (47%) reported pain, of whom 201 (13%) had severe pain, 595 (39%) had moderate pain, and 733 (48%) had light pain. Factors associated with chronic pain included young age (18-39 years: OR, 3.62; 95% confidence interval [CI], 2.25-5.82; P < .001) and adjuvant radiotherapy (OR, 1.50; 95% CI, 1.08-2.07; P = .03), but not chemotherapy (OR, 1.01; 95% CI, 0.85-1.21; P = .91). Axillary lymph node dissection (ALND) was associated with increased likelihood of pain (OR, 1.77; 95% CI, 1.43-2.19; P < .001) compared with sentinel lymph node dissection. Risk of sensory disturbances was associated with young age (18-39 years: OR, 5.00; 95% CI, 2.87-8.69; P < .001) and ALND (OR, 4.97; 95% CI, 3.92-6.30; P < .001). Pain complaints from other parts of the body were associated with increased risk of pain in the surgical area (P < .001). A total of 306 patients (20%) with pain had contacted a physician within the prior 3 months for pain complaints in the surgical area.Two to 3 years after breast cancer treatment, persistent pain and sensory disturbances remain clinically significant problems among Danish women who received surgery in 2005 and 2006.","Prevalence of and factors associated with persistent pain following breast cancer surgery."
"1150","JAMA.508","0.91",19903919,2009,"Persistent pain and sensory disturbances following surgical treatment for breast cancer is a significant clinical problem. The pathogenic mechanisms are complex and may be related to patient characteristics, surgical technique, and adjuvant therapy.To examine prevalence of and factors associated with persistent pain after surgical treatment for breast cancer.A nationwide cross-sectional questionnaire study of 3754 women aged 18 to 70 years who received surgery and adjuvant therapy (if indicated) for primary breast cancer in Denmark between January 1, 2005, and December 31, 2006. A study questionnaire was sent to the women between January and April 2008.Prevalence, location, and severity of persistent pain and sensory disturbances in 12 well-defined treatment groups assessed an average of 26 months after surgery, and adjusted odds ratio (OR) of reported pain and sensory disturbances with respect to age, surgical technique, chemotherapy, and radiotherapy.By June 2008, 3253 of 3754 eligible women (87%) returned the questionnaire. A total of 1543 patients (47%) reported pain, of whom 201 (13%) had severe pain, 595 (39%) had moderate pain, and 733 (48%) had light pain. Factors associated with chronic pain included young age (18-39 years: OR, 3.62; 95% confidence interval [CI], 2.25-5.82; P < .001) and adjuvant radiotherapy (OR, 1.50; 95% CI, 1.08-2.07; P = .03), but not chemotherapy (OR, 1.01; 95% CI, 0.85-1.21; P = .91). Axillary lymph node dissection (ALND) was associated with increased likelihood of pain (OR, 1.77; 95% CI, 1.43-2.19; P < .001) compared with sentinel lymph node dissection. Risk of sensory disturbances was associated with young age (18-39 years: OR, 5.00; 95% CI, 2.87-8.69; P < .001) and ALND (OR, 4.97; 95% CI, 3.92-6.30; P < .001). Pain complaints from other parts of the body were associated with increased risk of pain in the surgical area (P < .001). A total of 306 patients (20%) with pain had contacted a physician within the prior 3 months for pain complaints in the surgical area.Two to 3 years after breast cancer treatment, persistent pain and sensory disturbances remain clinically significant problems among Danish women who received surgery in 2005 and 2006.","Prevalence of and factors associated with persistent pain following breast cancer surgery."
"1151","JAMA.5101","0.02",19920236,2009,"Recently, concern has been raised about the safety of folic acid, particularly in relation to cancer risk.To evaluate effects of treatment with B vitamins on cancer outcomes and all-cause mortality in 2 randomized controlled trials.Combined analysis and extended follow-up of participants from 2 randomized, double-blind, placebo-controlled clinical trials (Norwegian Vitamin Trial and Western Norway B Vitamin Intervention Trial). A total of 6837 patients with ischemic heart disease were treated with B vitamins or placebo between 1998 and 2005, and were followed up through December 31, 2007.Oral treatment with folic acid (0.8 mg/d) plus vitamin B(12) (0.4 mg/d) and vitamin B(6) (40 mg/d) (n = 1708); folic acid (0.8 mg/d) plus vitamin B(12) (0.4 mg/d) (n = 1703); vitamin B(6) alone (40 mg/d) (n = 1705); or placebo (n = 1721).Cancer incidence, cancer mortality, and all-cause mortality.During study treatment, median serum folate concentration increased more than 6-fold among participants given folic acid. After a median 39 months of treatment and an additional 38 months of posttrial observational follow-up, 341 participants (10.0%) who received folic acid plus vitamin B(12) vs 288 participants (8.4%) who did not receive such treatment were diagnosed with cancer (hazard ratio [HR], 1.21; 95% confidence interval [CI], 1.03-1.41; P = .02). A total of 136 (4.0%) who received folic acid plus vitamin B(12) vs 100 (2.9%) who did not receive such treatment died from cancer (HR, 1.38; 95% CI, 1.07-1.79; P = .01). A total of 548 patients (16.1%) who received folic acid plus vitamin B(12) vs 473 (13.8%) who did not receive such treatment died from any cause (HR, 1.18; 95% CI, 1.04-1.33; P = .01). Results were mainly driven by increased lung cancer incidence in participants who received folic acid plus vitamin B(12). Vitamin B(6) treatment was not associated with any significant effects.Treatment with folic acid plus vitamin B(12) was associated with increased cancer outcomes and all-cause mortality in patients with ischemic heart disease in Norway, where there is no folic acid fortification of foods.clinicaltrials.gov Identifier: NCT00671346.","Cancer incidence and mortality after treatment with folic acid and vitamin B12."
"1152","JAMA.5111","0.01",19920236,2009,"Recently, concern has been raised about the safety of folic acid, particularly in relation to cancer risk.To evaluate effects of treatment with B vitamins on cancer outcomes and all-cause mortality in 2 randomized controlled trials.Combined analysis and extended follow-up of participants from 2 randomized, double-blind, placebo-controlled clinical trials (Norwegian Vitamin Trial and Western Norway B Vitamin Intervention Trial). A total of 6837 patients with ischemic heart disease were treated with B vitamins or placebo between 1998 and 2005, and were followed up through December 31, 2007.Oral treatment with folic acid (0.8 mg/d) plus vitamin B(12) (0.4 mg/d) and vitamin B(6) (40 mg/d) (n = 1708); folic acid (0.8 mg/d) plus vitamin B(12) (0.4 mg/d) (n = 1703); vitamin B(6) alone (40 mg/d) (n = 1705); or placebo (n = 1721).Cancer incidence, cancer mortality, and all-cause mortality.During study treatment, median serum folate concentration increased more than 6-fold among participants given folic acid. After a median 39 months of treatment and an additional 38 months of posttrial observational follow-up, 341 participants (10.0%) who received folic acid plus vitamin B(12) vs 288 participants (8.4%) who did not receive such treatment were diagnosed with cancer (hazard ratio [HR], 1.21; 95% confidence interval [CI], 1.03-1.41; P = .02). A total of 136 (4.0%) who received folic acid plus vitamin B(12) vs 100 (2.9%) who did not receive such treatment died from cancer (HR, 1.38; 95% CI, 1.07-1.79; P = .01). A total of 548 patients (16.1%) who received folic acid plus vitamin B(12) vs 473 (13.8%) who did not receive such treatment died from any cause (HR, 1.18; 95% CI, 1.04-1.33; P = .01). Results were mainly driven by increased lung cancer incidence in participants who received folic acid plus vitamin B(12). Vitamin B(6) treatment was not associated with any significant effects.Treatment with folic acid plus vitamin B(12) was associated with increased cancer outcomes and all-cause mortality in patients with ischemic heart disease in Norway, where there is no folic acid fortification of foods.clinicaltrials.gov Identifier: NCT00671346.","Cancer incidence and mortality after treatment with folic acid and vitamin B12."
"1153","JAMA.5121","0.01",19920236,2009,"Recently, concern has been raised about the safety of folic acid, particularly in relation to cancer risk.To evaluate effects of treatment with B vitamins on cancer outcomes and all-cause mortality in 2 randomized controlled trials.Combined analysis and extended follow-up of participants from 2 randomized, double-blind, placebo-controlled clinical trials (Norwegian Vitamin Trial and Western Norway B Vitamin Intervention Trial). A total of 6837 patients with ischemic heart disease were treated with B vitamins or placebo between 1998 and 2005, and were followed up through December 31, 2007.Oral treatment with folic acid (0.8 mg/d) plus vitamin B(12) (0.4 mg/d) and vitamin B(6) (40 mg/d) (n = 1708); folic acid (0.8 mg/d) plus vitamin B(12) (0.4 mg/d) (n = 1703); vitamin B(6) alone (40 mg/d) (n = 1705); or placebo (n = 1721).Cancer incidence, cancer mortality, and all-cause mortality.During study treatment, median serum folate concentration increased more than 6-fold among participants given folic acid. After a median 39 months of treatment and an additional 38 months of posttrial observational follow-up, 341 participants (10.0%) who received folic acid plus vitamin B(12) vs 288 participants (8.4%) who did not receive such treatment were diagnosed with cancer (hazard ratio [HR], 1.21; 95% confidence interval [CI], 1.03-1.41; P = .02). A total of 136 (4.0%) who received folic acid plus vitamin B(12) vs 100 (2.9%) who did not receive such treatment died from cancer (HR, 1.38; 95% CI, 1.07-1.79; P = .01). A total of 548 patients (16.1%) who received folic acid plus vitamin B(12) vs 473 (13.8%) who did not receive such treatment died from any cause (HR, 1.18; 95% CI, 1.04-1.33; P = .01). Results were mainly driven by increased lung cancer incidence in participants who received folic acid plus vitamin B(12). Vitamin B(6) treatment was not associated with any significant effects.Treatment with folic acid plus vitamin B(12) was associated with increased cancer outcomes and all-cause mortality in patients with ischemic heart disease in Norway, where there is no folic acid fortification of foods.clinicaltrials.gov Identifier: NCT00671346.","Cancer incidence and mortality after treatment with folic acid and vitamin B12."
"1154","Lancet.190","0.027",19922995,2009,"Angiotensin-receptor blockers (ARBs) are effective treatments for patients with heart failure, but the relation between dose and clinical outcomes has not been explored. We compared the effects of high-dose versus low-dose losartan on clinical outcomes in patients with heart failure.This double-blind trial was undertaken in 255 sites in 30 countries. 3846 patients with heart failure of New York Heart Association class II-IV, left-ventricular ejection fraction 40% or less, and intolerance to angiotensin-converting-enzyme (ACE) inhibitors were randomly assigned to losartan 150 mg (n=1927) or 50 mg daily (n=1919). Allocation was by block randomisation stratified by centre and presence or absence of beta-blocker therapy, and all patients and investigators were masked to assignment. The primary endpoint was death or admission for heart failure. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00090259.Six patients in each group were excluded because of poor data quality. With 4.7-year median follow-up in each group (IQR 3.7-5.5 for losartan 150 mg; 3.4-5.5 for losartan 50 mg), 828 (43%) patients in the 150 mg group versus 889 (46%) in the 50 mg group died or were admitted for heart failure (hazard ratio [HR] 0.90, 95% CI 0.82-0.99; p=0.027). For the two primary endpoint components, 635 patients in the 150 mg group versus 665 in the 50 mg group died (HR 0.94, 95% CI 0.84-1.04; p=0.24), and 450 versus 503 patients were admitted for heart failure (0.87, 0.76-0.98; p=0.025). Renal impairment (n=454 vs 317), hypotension (203 vs 145), and hyperkalaemia (195 vs 131) were more common in the 150 mg group than in the 50 mg group, but these adverse events did not lead to significantly more treatment discontinuations in the 150 mg group.Losartan 150 mg daily reduced the rate of death or admission for heart failure in patients with heart failure, reduced left-ventricular ejection fraction, and intolerance to ACE inhibitors compared with losartan 50 mg daily. These findings show the value of up-titrating ARB doses to confer clinical benefit.Merck (USA).","Effects of high-dose versus low-dose losartan on clinical outcomes in patients with heart failure (HEAAL study): a randomised, double-blind trial."
"1155","Lancet.191","0.24",19922995,2009,"Angiotensin-receptor blockers (ARBs) are effective treatments for patients with heart failure, but the relation between dose and clinical outcomes has not been explored. We compared the effects of high-dose versus low-dose losartan on clinical outcomes in patients with heart failure.This double-blind trial was undertaken in 255 sites in 30 countries. 3846 patients with heart failure of New York Heart Association class II-IV, left-ventricular ejection fraction 40% or less, and intolerance to angiotensin-converting-enzyme (ACE) inhibitors were randomly assigned to losartan 150 mg (n=1927) or 50 mg daily (n=1919). Allocation was by block randomisation stratified by centre and presence or absence of beta-blocker therapy, and all patients and investigators were masked to assignment. The primary endpoint was death or admission for heart failure. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00090259.Six patients in each group were excluded because of poor data quality. With 4.7-year median follow-up in each group (IQR 3.7-5.5 for losartan 150 mg; 3.4-5.5 for losartan 50 mg), 828 (43%) patients in the 150 mg group versus 889 (46%) in the 50 mg group died or were admitted for heart failure (hazard ratio [HR] 0.90, 95% CI 0.82-0.99; p=0.027). For the two primary endpoint components, 635 patients in the 150 mg group versus 665 in the 50 mg group died (HR 0.94, 95% CI 0.84-1.04; p=0.24), and 450 versus 503 patients were admitted for heart failure (0.87, 0.76-0.98; p=0.025). Renal impairment (n=454 vs 317), hypotension (203 vs 145), and hyperkalaemia (195 vs 131) were more common in the 150 mg group than in the 50 mg group, but these adverse events did not lead to significantly more treatment discontinuations in the 150 mg group.Losartan 150 mg daily reduced the rate of death or admission for heart failure in patients with heart failure, reduced left-ventricular ejection fraction, and intolerance to ACE inhibitors compared with losartan 50 mg daily. These findings show the value of up-titrating ARB doses to confer clinical benefit.Merck (USA).","Effects of high-dose versus low-dose losartan on clinical outcomes in patients with heart failure (HEAAL study): a randomised, double-blind trial."
"1156","Lancet.192","0.025",19922995,2009,"Angiotensin-receptor blockers (ARBs) are effective treatments for patients with heart failure, but the relation between dose and clinical outcomes has not been explored. We compared the effects of high-dose versus low-dose losartan on clinical outcomes in patients with heart failure.This double-blind trial was undertaken in 255 sites in 30 countries. 3846 patients with heart failure of New York Heart Association class II-IV, left-ventricular ejection fraction 40% or less, and intolerance to angiotensin-converting-enzyme (ACE) inhibitors were randomly assigned to losartan 150 mg (n=1927) or 50 mg daily (n=1919). Allocation was by block randomisation stratified by centre and presence or absence of beta-blocker therapy, and all patients and investigators were masked to assignment. The primary endpoint was death or admission for heart failure. Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00090259.Six patients in each group were excluded because of poor data quality. With 4.7-year median follow-up in each group (IQR 3.7-5.5 for losartan 150 mg; 3.4-5.5 for losartan 50 mg), 828 (43%) patients in the 150 mg group versus 889 (46%) in the 50 mg group died or were admitted for heart failure (hazard ratio [HR] 0.90, 95% CI 0.82-0.99; p=0.027). For the two primary endpoint components, 635 patients in the 150 mg group versus 665 in the 50 mg group died (HR 0.94, 95% CI 0.84-1.04; p=0.24), and 450 versus 503 patients were admitted for heart failure (0.87, 0.76-0.98; p=0.025). Renal impairment (n=454 vs 317), hypotension (203 vs 145), and hyperkalaemia (195 vs 131) were more common in the 150 mg group than in the 50 mg group, but these adverse events did not lead to significantly more treatment discontinuations in the 150 mg group.Losartan 150 mg daily reduced the rate of death or admission for heart failure in patients with heart failure, reduced left-ventricular ejection fraction, and intolerance to ACE inhibitors compared with losartan 50 mg daily. These findings show the value of up-titrating ARB doses to confer clinical benefit.Merck (USA).","Effects of high-dose versus low-dose losartan on clinical outcomes in patients with heart failure (HEAAL study): a randomised, double-blind trial."
"1157","JAMA.505","0.38",19934421,2009,"Earlier studies indicate an inverse relationship between hospital volume and mortality after primary angioplasty for patients presenting with ST-segment elevation myocardial infarction (STEMI). However, contemporary data are lacking.To assess the relationship between hospital primary angioplasty volume and outcomes and quality of care measures in patients presenting with STEMI.An observational analysis of data on 29,513 patients presenting with STEMI and undergoing primary angioplasty in the American Heart Association's Get With the Guidelines registry. Patients were treated between July 5, 2001, and December 31, 2007, at 166 angioplasty-capable hospitals across the United States. Hospitals were divided into tertiles (<36 procedures per year, 36-70 procedures per year, and >70 procedures per year) based on their annual primary angioplasty volume.Door-to-balloon (DTB) times, length of hospital stay, adherence with evidence-based quality of care measures, and in-hospital mortality.Compared with low- and medium-volume centers, high-volume centers had better median DTB times (98 vs 90 vs 88 minutes, respectively; P for trend < .001). High-volume centers were more likely than low-volume centers to follow evidence-based guidelines at discharge. Length of stay was similar between the 3 groups (P for trend = .13). There was no significant difference in the crude mortality between the tertiles of volume (incidence rate, 3.9% vs 3.2% vs 3.0% for low-, medium-, and high-volume centers, respectively; P = .26 and P = .99 for low- and medium- vs high-volume hospitals, respectively). Sequential multivariable modeling using generalized estimating equations revealed no significant association between hospital primary angioplasty volume and in-hospital mortality (adjusted odds ratio [OR], 1.22; 95% confidence interval [CI], 0.78-1.91; P = .38 and adjusted OR, 1.14; 95% CI, 0.78-1.66; P = .49 for low- and medium- vs high-volume hospitals, respectively).In a contemporary registry of patients with STEMI, higher-volume primary angioplasty centers vs lower-volume centers were associated with shorter DTB times and more use of evidence-based therapies, but not with adjusted in-hospital mortality or length of hospital stay.","Association of hospital primary angioplasty volume in ST-segment elevation myocardial infarction with quality and outcomes."
"1158","JAMA.506","0.49",19934421,2009,"Earlier studies indicate an inverse relationship between hospital volume and mortality after primary angioplasty for patients presenting with ST-segment elevation myocardial infarction (STEMI). However, contemporary data are lacking.To assess the relationship between hospital primary angioplasty volume and outcomes and quality of care measures in patients presenting with STEMI.An observational analysis of data on 29,513 patients presenting with STEMI and undergoing primary angioplasty in the American Heart Association's Get With the Guidelines registry. Patients were treated between July 5, 2001, and December 31, 2007, at 166 angioplasty-capable hospitals across the United States. Hospitals were divided into tertiles (<36 procedures per year, 36-70 procedures per year, and >70 procedures per year) based on their annual primary angioplasty volume.Door-to-balloon (DTB) times, length of hospital stay, adherence with evidence-based quality of care measures, and in-hospital mortality.Compared with low- and medium-volume centers, high-volume centers had better median DTB times (98 vs 90 vs 88 minutes, respectively; P for trend < .001). High-volume centers were more likely than low-volume centers to follow evidence-based guidelines at discharge. Length of stay was similar between the 3 groups (P for trend = .13). There was no significant difference in the crude mortality between the tertiles of volume (incidence rate, 3.9% vs 3.2% vs 3.0% for low-, medium-, and high-volume centers, respectively; P = .26 and P = .99 for low- and medium- vs high-volume hospitals, respectively). Sequential multivariable modeling using generalized estimating equations revealed no significant association between hospital primary angioplasty volume and in-hospital mortality (adjusted odds ratio [OR], 1.22; 95% confidence interval [CI], 0.78-1.91; P = .38 and adjusted OR, 1.14; 95% CI, 0.78-1.66; P = .49 for low- and medium- vs high-volume hospitals, respectively).In a contemporary registry of patients with STEMI, higher-volume primary angioplasty centers vs lower-volume centers were associated with shorter DTB times and more use of evidence-based therapies, but not with adjusted in-hospital mortality or length of hospital stay.","Association of hospital primary angioplasty volume in ST-segment elevation myocardial infarction with quality and outcomes."
"1159","American Journal of Epidemiology.221","0.001",19955471,2009,"In 2007, the Wellcome Trust Case Control Consortium (WTCCC) performed a genome-wide association study in 2,000 British coronary heart disease (CHD) cases and 3,000 controls after genotyping 469,557 single nucleotide polymorphisms (SNPs). Seven variants associated with CHD were initially identified, and 5 SNPs were later found in replication studies. In the current study, the authors aimed to determine whether the 12 SNPs reported by the WTCCC predicted incident CHD through 2004 in a biracial, prospective cohort study (Atherosclerosis Risk in Communities) comprising 15,792 persons aged 45-64 years who had been selected by probability sampling from 4 different US communities in 1987-1989. Cox proportional hazards models with adjustment for age and gender were used to estimate CHD hazard rate ratios (HRRs) over a 17-year period (1,362 cases in whites and 397 cases in African Americans) under an additive genetic model. The results showed that 3 SNPs in whites (rs599839, rs1333049, and rs501120; HRRs were 1.10 (P = 0.044), 1.14 (P < 0.001), and 1.14 (P = 0.030), respectively) and 1 SNP in African Americans (rs7250581; HRR = 1.60, P = 0.05) were significantly associated with incident CHD. This study demonstrates that genetic variants revealed in a case-control genome-wide association study enriched for early disease onset may play a role in the genetic etiology of CHD in the general population.","Genetic variants identified in a European genome-wide association study that were found to predict incident coronary heart disease in the atherosclerosis risk in communities study."
"1160","American Journal of Epidemiology.231","0.03",19955471,2009,"In 2007, the Wellcome Trust Case Control Consortium (WTCCC) performed a genome-wide association study in 2,000 British coronary heart disease (CHD) cases and 3,000 controls after genotyping 469,557 single nucleotide polymorphisms (SNPs). Seven variants associated with CHD were initially identified, and 5 SNPs were later found in replication studies. In the current study, the authors aimed to determine whether the 12 SNPs reported by the WTCCC predicted incident CHD through 2004 in a biracial, prospective cohort study (Atherosclerosis Risk in Communities) comprising 15,792 persons aged 45-64 years who had been selected by probability sampling from 4 different US communities in 1987-1989. Cox proportional hazards models with adjustment for age and gender were used to estimate CHD hazard rate ratios (HRRs) over a 17-year period (1,362 cases in whites and 397 cases in African Americans) under an additive genetic model. The results showed that 3 SNPs in whites (rs599839, rs1333049, and rs501120; HRRs were 1.10 (P = 0.044), 1.14 (P < 0.001), and 1.14 (P = 0.030), respectively) and 1 SNP in African Americans (rs7250581; HRR = 1.60, P = 0.05) were significantly associated with incident CHD. This study demonstrates that genetic variants revealed in a case-control genome-wide association study enriched for early disease onset may play a role in the genetic etiology of CHD in the general population.","Genetic variants identified in a European genome-wide association study that were found to predict incident coronary heart disease in the atherosclerosis risk in communities study."
"1161","American Journal of Epidemiology.241","0.05",19955471,2009,"In 2007, the Wellcome Trust Case Control Consortium (WTCCC) performed a genome-wide association study in 2,000 British coronary heart disease (CHD) cases and 3,000 controls after genotyping 469,557 single nucleotide polymorphisms (SNPs). Seven variants associated with CHD were initially identified, and 5 SNPs were later found in replication studies. In the current study, the authors aimed to determine whether the 12 SNPs reported by the WTCCC predicted incident CHD through 2004 in a biracial, prospective cohort study (Atherosclerosis Risk in Communities) comprising 15,792 persons aged 45-64 years who had been selected by probability sampling from 4 different US communities in 1987-1989. Cox proportional hazards models with adjustment for age and gender were used to estimate CHD hazard rate ratios (HRRs) over a 17-year period (1,362 cases in whites and 397 cases in African Americans) under an additive genetic model. The results showed that 3 SNPs in whites (rs599839, rs1333049, and rs501120; HRRs were 1.10 (P = 0.044), 1.14 (P < 0.001), and 1.14 (P = 0.030), respectively) and 1 SNP in African Americans (rs7250581; HRR = 1.60, P = 0.05) were significantly associated with incident CHD. This study demonstrates that genetic variants revealed in a case-control genome-wide association study enriched for early disease onset may play a role in the genetic etiology of CHD in the general population.","Genetic variants identified in a European genome-wide association study that were found to predict incident coronary heart disease in the atherosclerosis risk in communities study."
"1162","American Journal of Epidemiology.271","0.044",19955471,2010,"In 2007, the Wellcome Trust Case Control Consortium (WTCCC) performed a genome-wide association study in 2,000 British coronary heart disease (CHD) cases and 3,000 controls after genotyping 469,557 single nucleotide polymorphisms (SNPs). Seven variants associated with CHD were initially identified, and 5 SNPs were later found in replication studies. In the current study, the authors aimed to determine whether the 12 SNPs reported by the WTCCC predicted incident CHD through 2004 in a biracial, prospective cohort study (Atherosclerosis Risk in Communities) comprising 15,792 persons aged 45-64 years who had been selected by probability sampling from 4 different US communities in 1987-1989. Cox proportional hazards models with adjustment for age and gender were used to estimate CHD hazard rate ratios (HRRs) over a 17-year period (1,362 cases in whites and 397 cases in African Americans) under an additive genetic model. The results showed that 3 SNPs in whites (rs599839, rs1333049, and rs501120; HRRs were 1.10 (P = 0.044), 1.14 (P < 0.001), and 1.14 (P = 0.030), respectively) and 1 SNP in African Americans (rs7250581; HRR = 1.60, P = 0.05) were significantly associated with incident CHD. This study demonstrates that genetic variants revealed in a case-control genome-wide association study enriched for early disease onset may play a role in the genetic etiology of CHD in the general population.","Genetic variants identified in a European genome-wide association study that were found to predict incident coronary heart disease in the atherosclerosis risk in communities study."
"1163","BMJ.121","0.001",19996459,2009,"To assess the incidence of and risks for congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities among adult survivors of childhood and adolescent cancers.Retrospective cohort study.26 institutions that participated in the Childhood Cancer Survivor Study.14,358 five year survivors of cancer diagnosed under the age of 21 with leukaemia, brain cancer, Hodgkin's lymphoma, non-Hodgkin's lymphoma, kidney cancer, neuroblastoma, soft tissue sarcoma, or bone cancer between 1970 and 1986. Comparison group included 3899 siblings of cancer survivors.Participants or their parents (in participants aged less than 18 years) completed a questionnaire collecting information on demographic characteristics, height, weight, health habits, medical conditions, and surgical procedures occurring since diagnosis. The main outcome measures were the incidence of and risk factors for congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities in survivors of cancer compared with siblings.Survivors of cancer were significantly more likely than siblings to report congestive heart failure (hazard ratio (HR) 5.9, 95% confidence interval 3.4 to 9.6; P<0.001), myocardial infarction (HR 5.0, 95% CI 2.3 to 10.4; P<0.001), pericardial disease (HR 6.3, 95% CI 3.3 to 11.9; P<0.001), or valvular abnormalities (HR 4.8, 95% CI 3.0 to 7.6; P<0.001). Exposure to 250 mg/m(2) or more of anthracyclines increased the relative hazard of congestive heart failure, pericardial disease, and valvular abnormalities by two to five times compared with survivors who had not been exposed to anthracyclines. Cardiac radiation exposure of 1500 centigray or more increased the relative hazard of congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities by twofold to sixfold compared to non-irradiated survivors. The cumulative incidence of adverse cardiac outcomes in cancer survivors continued to increase up to 30 years after diagnosis.Survivors of childhood and adolescent cancer are at substantial risk for cardiovascular disease. Healthcare professionals must be aware of these risks when caring for this growing population.","Cardiac outcomes in a cohort of adult survivors of childhood and adolescent cancer: retrospective analysis of the Childhood Cancer Survivor Study cohort."
"1164","BMJ.131","0.001",19996459,2009,"To assess the incidence of and risks for congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities among adult survivors of childhood and adolescent cancers.Retrospective cohort study.26 institutions that participated in the Childhood Cancer Survivor Study.14,358 five year survivors of cancer diagnosed under the age of 21 with leukaemia, brain cancer, Hodgkin's lymphoma, non-Hodgkin's lymphoma, kidney cancer, neuroblastoma, soft tissue sarcoma, or bone cancer between 1970 and 1986. Comparison group included 3899 siblings of cancer survivors.Participants or their parents (in participants aged less than 18 years) completed a questionnaire collecting information on demographic characteristics, height, weight, health habits, medical conditions, and surgical procedures occurring since diagnosis. The main outcome measures were the incidence of and risk factors for congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities in survivors of cancer compared with siblings.Survivors of cancer were significantly more likely than siblings to report congestive heart failure (hazard ratio (HR) 5.9, 95% confidence interval 3.4 to 9.6; P<0.001), myocardial infarction (HR 5.0, 95% CI 2.3 to 10.4; P<0.001), pericardial disease (HR 6.3, 95% CI 3.3 to 11.9; P<0.001), or valvular abnormalities (HR 4.8, 95% CI 3.0 to 7.6; P<0.001). Exposure to 250 mg/m(2) or more of anthracyclines increased the relative hazard of congestive heart failure, pericardial disease, and valvular abnormalities by two to five times compared with survivors who had not been exposed to anthracyclines. Cardiac radiation exposure of 1500 centigray or more increased the relative hazard of congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities by twofold to sixfold compared to non-irradiated survivors. The cumulative incidence of adverse cardiac outcomes in cancer survivors continued to increase up to 30 years after diagnosis.Survivors of childhood and adolescent cancer are at substantial risk for cardiovascular disease. Healthcare professionals must be aware of these risks when caring for this growing population.","Cardiac outcomes in a cohort of adult survivors of childhood and adolescent cancer: retrospective analysis of the Childhood Cancer Survivor Study cohort."
"1165","BMJ.141","0.001",19996459,2009,"To assess the incidence of and risks for congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities among adult survivors of childhood and adolescent cancers.Retrospective cohort study.26 institutions that participated in the Childhood Cancer Survivor Study.14,358 five year survivors of cancer diagnosed under the age of 21 with leukaemia, brain cancer, Hodgkin's lymphoma, non-Hodgkin's lymphoma, kidney cancer, neuroblastoma, soft tissue sarcoma, or bone cancer between 1970 and 1986. Comparison group included 3899 siblings of cancer survivors.Participants or their parents (in participants aged less than 18 years) completed a questionnaire collecting information on demographic characteristics, height, weight, health habits, medical conditions, and surgical procedures occurring since diagnosis. The main outcome measures were the incidence of and risk factors for congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities in survivors of cancer compared with siblings.Survivors of cancer were significantly more likely than siblings to report congestive heart failure (hazard ratio (HR) 5.9, 95% confidence interval 3.4 to 9.6; P<0.001), myocardial infarction (HR 5.0, 95% CI 2.3 to 10.4; P<0.001), pericardial disease (HR 6.3, 95% CI 3.3 to 11.9; P<0.001), or valvular abnormalities (HR 4.8, 95% CI 3.0 to 7.6; P<0.001). Exposure to 250 mg/m(2) or more of anthracyclines increased the relative hazard of congestive heart failure, pericardial disease, and valvular abnormalities by two to five times compared with survivors who had not been exposed to anthracyclines. Cardiac radiation exposure of 1500 centigray or more increased the relative hazard of congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities by twofold to sixfold compared to non-irradiated survivors. The cumulative incidence of adverse cardiac outcomes in cancer survivors continued to increase up to 30 years after diagnosis.Survivors of childhood and adolescent cancer are at substantial risk for cardiovascular disease. Healthcare professionals must be aware of these risks when caring for this growing population.","Cardiac outcomes in a cohort of adult survivors of childhood and adolescent cancer: retrospective analysis of the Childhood Cancer Survivor Study cohort."
"1166","BMJ.151","0.001",19996459,2009,"To assess the incidence of and risks for congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities among adult survivors of childhood and adolescent cancers.Retrospective cohort study.26 institutions that participated in the Childhood Cancer Survivor Study.14,358 five year survivors of cancer diagnosed under the age of 21 with leukaemia, brain cancer, Hodgkin's lymphoma, non-Hodgkin's lymphoma, kidney cancer, neuroblastoma, soft tissue sarcoma, or bone cancer between 1970 and 1986. Comparison group included 3899 siblings of cancer survivors.Participants or their parents (in participants aged less than 18 years) completed a questionnaire collecting information on demographic characteristics, height, weight, health habits, medical conditions, and surgical procedures occurring since diagnosis. The main outcome measures were the incidence of and risk factors for congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities in survivors of cancer compared with siblings.Survivors of cancer were significantly more likely than siblings to report congestive heart failure (hazard ratio (HR) 5.9, 95% confidence interval 3.4 to 9.6; P<0.001), myocardial infarction (HR 5.0, 95% CI 2.3 to 10.4; P<0.001), pericardial disease (HR 6.3, 95% CI 3.3 to 11.9; P<0.001), or valvular abnormalities (HR 4.8, 95% CI 3.0 to 7.6; P<0.001). Exposure to 250 mg/m(2) or more of anthracyclines increased the relative hazard of congestive heart failure, pericardial disease, and valvular abnormalities by two to five times compared with survivors who had not been exposed to anthracyclines. Cardiac radiation exposure of 1500 centigray or more increased the relative hazard of congestive heart failure, myocardial infarction, pericardial disease, and valvular abnormalities by twofold to sixfold compared to non-irradiated survivors. The cumulative incidence of adverse cardiac outcomes in cancer survivors continued to increase up to 30 years after diagnosis.Survivors of childhood and adolescent cancer are at substantial risk for cardiovascular disease. Healthcare professionals must be aware of these risks when caring for this growing population.","Cardiac outcomes in a cohort of adult survivors of childhood and adolescent cancer: retrospective analysis of the Childhood Cancer Survivor Study cohort."
"1167","Lancet.188","1.00E-04",20004464,2009,"HIV antiretroviral therapy (ART) is often managed without routine laboratory monitoring in Africa; however, the effect of this approach is unknown. This trial investigated whether routine toxicity and efficacy monitoring of HIV-infected patients receiving ART had an important long-term effect on clinical outcomes in Africa.In this open, non-inferiority trial in three centres in Uganda and one in Zimbabwe, 3321 symptomatic, ART-naive, HIV-infected adults with CD4 counts less than 200 cells per microL starting ART were randomly assigned to laboratory and clinical monitoring (LCM; n=1659) or clinically driven monitoring (CDM; n=1662) by a computer-generated list. Haematology, biochemistry, and CD4-cell counts were done every 12 weeks. In the LCM group, results were available to clinicians; in the CDM group, results (apart from CD4-cell count) could be requested if clinically indicated and grade 4 toxicities were available. Participants switched to second-line ART after new or recurrent WHO stage 4 events in both groups, or CD4 count less than 100 cells per microL (LCM only). Co-primary endpoints were new WHO stage 4 HIV events or death, and serious adverse events. Non-inferiority was defined as the upper 95% confidence limit for the hazard ratio (HR) for new WHO stage 4 events or death being no greater than 1.18. Analyses were by intention to treat. This study is registered, number ISRCTN13968779.Two participants assigned to CDM and three to LCM were excluded from analyses. 5-year survival was 87% (95% CI 85-88) in the CDM group and 90% (88-91) in the LCM group, and 122 (7%) and 112 (7%) participants, respectively, were lost to follow-up over median 4.9 years' follow-up. 459 (28%) participants receiving CDM versus 356 (21%) LCM had a new WHO stage 4 event or died (6.94 [95% CI 6.33-7.60] vs 5.24 [4.72-5.81] per 100 person-years; absolute difference 1.70 per 100 person-years [0.87-2.54]; HR 1.31 [1.14-1.51]; p=0.0001). Differences in disease progression occurred from the third year on ART, whereas higher rates of switch to second-line treatment occurred in LCM from the second year. 283 (17%) participants receiving CDM versus 260 (16%) LCM had a new serious adverse event (HR 1.12 [0.94-1.32]; p=0.19), with anaemia the most common (76 vs 61 cases).ART can be delivered safely without routine laboratory monitoring for toxic effects, but differences in disease progression suggest a role for monitoring of CD4-cell count from the second year of ART to guide the switch to second-line treatment.UK Medical Research Council, the UK Department for International Development, the Rockefeller Foundation, GlaxoSmithKline, Gilead Sciences, Boehringer-Ingelheim, and Abbott Laboratories.Copyright 2010 Elsevier Ltd. All rights reserved.","Routine versus clinically driven laboratory monitoring of HIV antiretroviral therapy in Africa (DART): a randomised non-inferiority trial."
"1168","Lancet.189","0.19",20004464,2009,"HIV antiretroviral therapy (ART) is often managed without routine laboratory monitoring in Africa; however, the effect of this approach is unknown. This trial investigated whether routine toxicity and efficacy monitoring of HIV-infected patients receiving ART had an important long-term effect on clinical outcomes in Africa.In this open, non-inferiority trial in three centres in Uganda and one in Zimbabwe, 3321 symptomatic, ART-naive, HIV-infected adults with CD4 counts less than 200 cells per microL starting ART were randomly assigned to laboratory and clinical monitoring (LCM; n=1659) or clinically driven monitoring (CDM; n=1662) by a computer-generated list. Haematology, biochemistry, and CD4-cell counts were done every 12 weeks. In the LCM group, results were available to clinicians; in the CDM group, results (apart from CD4-cell count) could be requested if clinically indicated and grade 4 toxicities were available. Participants switched to second-line ART after new or recurrent WHO stage 4 events in both groups, or CD4 count less than 100 cells per microL (LCM only). Co-primary endpoints were new WHO stage 4 HIV events or death, and serious adverse events. Non-inferiority was defined as the upper 95% confidence limit for the hazard ratio (HR) for new WHO stage 4 events or death being no greater than 1.18. Analyses were by intention to treat. This study is registered, number ISRCTN13968779.Two participants assigned to CDM and three to LCM were excluded from analyses. 5-year survival was 87% (95% CI 85-88) in the CDM group and 90% (88-91) in the LCM group, and 122 (7%) and 112 (7%) participants, respectively, were lost to follow-up over median 4.9 years' follow-up. 459 (28%) participants receiving CDM versus 356 (21%) LCM had a new WHO stage 4 event or died (6.94 [95% CI 6.33-7.60] vs 5.24 [4.72-5.81] per 100 person-years; absolute difference 1.70 per 100 person-years [0.87-2.54]; HR 1.31 [1.14-1.51]; p=0.0001). Differences in disease progression occurred from the third year on ART, whereas higher rates of switch to second-line treatment occurred in LCM from the second year. 283 (17%) participants receiving CDM versus 260 (16%) LCM had a new serious adverse event (HR 1.12 [0.94-1.32]; p=0.19), with anaemia the most common (76 vs 61 cases).ART can be delivered safely without routine laboratory monitoring for toxic effects, but differences in disease progression suggest a role for monitoring of CD4-cell count from the second year of ART to guide the switch to second-line treatment.UK Medical Research Council, the UK Department for International Development, the Rockefeller Foundation, GlaxoSmithKline, Gilead Sciences, Boehringer-Ingelheim, and Abbott Laboratories.Copyright 2010 Elsevier Ltd. All rights reserved.","Routine versus clinically driven laboratory monitoring of HIV antiretroviral therapy in Africa (DART): a randomised non-inferiority trial."
"1169","Lancet.184","0.002",20004966,2009,"Tamoxifen is standard adjuvant treatment for postmenopausal women with hormone-receptor-positive breast cancer. We assessed the benefit of adding chemotherapy to adjuvant tamoxifen and whether tamoxifen should be given concurrently or after chemotherapy.We undertook a phase 3, parallel, randomised trial (SWOG-8814, INT-0100) in postmenopausal women with hormone-receptor-positive, node-positive breast cancer to test two major objectives: whether the primary outcome, disease-free survival, was longer with cyclophosphamide, doxorubicin, and fluorouracil (CAF) given every 4 weeks for six cycles plus 5 years of daily tamoxifen than with tamoxifen alone; and whether disease-free survival was longer with CAF followed by tamoxifen (CAF-T) than with CAF plus concurrent tamoxifen (CAFT). Overall survival and toxicity were predefined, important secondary outcomes for each objective. Patients in this open-label trial were randomly assigned by a computer algorithm in a 2:3:3 ratio (tamoxifen:CAF-T:CAFT) and analysis was by intention to treat of eligible patients. Groups were compared by stratified log-rank tests, followed by Cox regression analyses adjusted for significant prognostic factors. This trial is registered with ClinicalTrials.gov, number NCT00929591.Of 1558 randomised women, 1477 (95%) were eligible for inclusion in the analysis. After a maximum of 13 years of follow-up (median 8.94 years), 637 women had a disease-free survival event (tamoxifen, 179 events in 361 patients; CAF-T, 216 events in 566 patients; CAFT, 242 events in 550 patients). For the first objective, therapy with the CAF plus tamoxifen groups combined (CAFT or CAF-T) was superior to tamoxifen alone for the primary endpoint of disease-free survival (adjusted Cox regression hazard ratio [HR] 0.76, 95% CI 0.64-0.91; p=0.002) but only marginally for the secondary endpoint of overall survival (HR 0.83, 0.68-1.01; p=0.057). For the second objective, the adjusted HRs favoured CAF-T over CAFT but did not reach significance for disease-free survival (HR 0.84, 0.70-1.01; p=0.061) or overall survival (HR 0.90, 0.73-1.10; p=0.30). Neutropenia, stomatitis, thromboembolism, congestive heart failure, and leukaemia were more frequent in the combined CAF plus tamoxifen groups than in the tamoxifen-alone group.Chemotherapy with CAF plus tamoxifen given sequentially is more effective adjuvant therapy for postmenopausal patients with endocrine-responsive, node-positive breast cancer than is tamoxifen alone. However, it might be possible to identify some subgroups that do not benefit from anthracycline-based chemotherapy despite positive nodes.National Cancer Institute (US National Institutes of Health).Copyright 2009 Elsevier Ltd. All rights reserved.","Adjuvant chemotherapy and timing of tamoxifen in postmenopausal patients with endocrine-responsive, node-positive breast cancer: a phase 3, open-label, randomised controlled trial."
"1170","Lancet.185","0.057",20004966,2009,"Tamoxifen is standard adjuvant treatment for postmenopausal women with hormone-receptor-positive breast cancer. We assessed the benefit of adding chemotherapy to adjuvant tamoxifen and whether tamoxifen should be given concurrently or after chemotherapy.We undertook a phase 3, parallel, randomised trial (SWOG-8814, INT-0100) in postmenopausal women with hormone-receptor-positive, node-positive breast cancer to test two major objectives: whether the primary outcome, disease-free survival, was longer with cyclophosphamide, doxorubicin, and fluorouracil (CAF) given every 4 weeks for six cycles plus 5 years of daily tamoxifen than with tamoxifen alone; and whether disease-free survival was longer with CAF followed by tamoxifen (CAF-T) than with CAF plus concurrent tamoxifen (CAFT). Overall survival and toxicity were predefined, important secondary outcomes for each objective. Patients in this open-label trial were randomly assigned by a computer algorithm in a 2:3:3 ratio (tamoxifen:CAF-T:CAFT) and analysis was by intention to treat of eligible patients. Groups were compared by stratified log-rank tests, followed by Cox regression analyses adjusted for significant prognostic factors. This trial is registered with ClinicalTrials.gov, number NCT00929591.Of 1558 randomised women, 1477 (95%) were eligible for inclusion in the analysis. After a maximum of 13 years of follow-up (median 8.94 years), 637 women had a disease-free survival event (tamoxifen, 179 events in 361 patients; CAF-T, 216 events in 566 patients; CAFT, 242 events in 550 patients). For the first objective, therapy with the CAF plus tamoxifen groups combined (CAFT or CAF-T) was superior to tamoxifen alone for the primary endpoint of disease-free survival (adjusted Cox regression hazard ratio [HR] 0.76, 95% CI 0.64-0.91; p=0.002) but only marginally for the secondary endpoint of overall survival (HR 0.83, 0.68-1.01; p=0.057). For the second objective, the adjusted HRs favoured CAF-T over CAFT but did not reach significance for disease-free survival (HR 0.84, 0.70-1.01; p=0.061) or overall survival (HR 0.90, 0.73-1.10; p=0.30). Neutropenia, stomatitis, thromboembolism, congestive heart failure, and leukaemia were more frequent in the combined CAF plus tamoxifen groups than in the tamoxifen-alone group.Chemotherapy with CAF plus tamoxifen given sequentially is more effective adjuvant therapy for postmenopausal patients with endocrine-responsive, node-positive breast cancer than is tamoxifen alone. However, it might be possible to identify some subgroups that do not benefit from anthracycline-based chemotherapy despite positive nodes.National Cancer Institute (US National Institutes of Health).Copyright 2009 Elsevier Ltd. All rights reserved.","Adjuvant chemotherapy and timing of tamoxifen in postmenopausal patients with endocrine-responsive, node-positive breast cancer: a phase 3, open-label, randomised controlled trial."
"1171","Lancet.186","0.061",20004966,2009,"Tamoxifen is standard adjuvant treatment for postmenopausal women with hormone-receptor-positive breast cancer. We assessed the benefit of adding chemotherapy to adjuvant tamoxifen and whether tamoxifen should be given concurrently or after chemotherapy.We undertook a phase 3, parallel, randomised trial (SWOG-8814, INT-0100) in postmenopausal women with hormone-receptor-positive, node-positive breast cancer to test two major objectives: whether the primary outcome, disease-free survival, was longer with cyclophosphamide, doxorubicin, and fluorouracil (CAF) given every 4 weeks for six cycles plus 5 years of daily tamoxifen than with tamoxifen alone; and whether disease-free survival was longer with CAF followed by tamoxifen (CAF-T) than with CAF plus concurrent tamoxifen (CAFT). Overall survival and toxicity were predefined, important secondary outcomes for each objective. Patients in this open-label trial were randomly assigned by a computer algorithm in a 2:3:3 ratio (tamoxifen:CAF-T:CAFT) and analysis was by intention to treat of eligible patients. Groups were compared by stratified log-rank tests, followed by Cox regression analyses adjusted for significant prognostic factors. This trial is registered with ClinicalTrials.gov, number NCT00929591.Of 1558 randomised women, 1477 (95%) were eligible for inclusion in the analysis. After a maximum of 13 years of follow-up (median 8.94 years), 637 women had a disease-free survival event (tamoxifen, 179 events in 361 patients; CAF-T, 216 events in 566 patients; CAFT, 242 events in 550 patients). For the first objective, therapy with the CAF plus tamoxifen groups combined (CAFT or CAF-T) was superior to tamoxifen alone for the primary endpoint of disease-free survival (adjusted Cox regression hazard ratio [HR] 0.76, 95% CI 0.64-0.91; p=0.002) but only marginally for the secondary endpoint of overall survival (HR 0.83, 0.68-1.01; p=0.057). For the second objective, the adjusted HRs favoured CAF-T over CAFT but did not reach significance for disease-free survival (HR 0.84, 0.70-1.01; p=0.061) or overall survival (HR 0.90, 0.73-1.10; p=0.30). Neutropenia, stomatitis, thromboembolism, congestive heart failure, and leukaemia were more frequent in the combined CAF plus tamoxifen groups than in the tamoxifen-alone group.Chemotherapy with CAF plus tamoxifen given sequentially is more effective adjuvant therapy for postmenopausal patients with endocrine-responsive, node-positive breast cancer than is tamoxifen alone. However, it might be possible to identify some subgroups that do not benefit from anthracycline-based chemotherapy despite positive nodes.National Cancer Institute (US National Institutes of Health).Copyright 2009 Elsevier Ltd. All rights reserved.","Adjuvant chemotherapy and timing of tamoxifen in postmenopausal patients with endocrine-responsive, node-positive breast cancer: a phase 3, open-label, randomised controlled trial."
"1172","Lancet.187","0.3",20004966,2009,"Tamoxifen is standard adjuvant treatment for postmenopausal women with hormone-receptor-positive breast cancer. We assessed the benefit of adding chemotherapy to adjuvant tamoxifen and whether tamoxifen should be given concurrently or after chemotherapy.We undertook a phase 3, parallel, randomised trial (SWOG-8814, INT-0100) in postmenopausal women with hormone-receptor-positive, node-positive breast cancer to test two major objectives: whether the primary outcome, disease-free survival, was longer with cyclophosphamide, doxorubicin, and fluorouracil (CAF) given every 4 weeks for six cycles plus 5 years of daily tamoxifen than with tamoxifen alone; and whether disease-free survival was longer with CAF followed by tamoxifen (CAF-T) than with CAF plus concurrent tamoxifen (CAFT). Overall survival and toxicity were predefined, important secondary outcomes for each objective. Patients in this open-label trial were randomly assigned by a computer algorithm in a 2:3:3 ratio (tamoxifen:CAF-T:CAFT) and analysis was by intention to treat of eligible patients. Groups were compared by stratified log-rank tests, followed by Cox regression analyses adjusted for significant prognostic factors. This trial is registered with ClinicalTrials.gov, number NCT00929591.Of 1558 randomised women, 1477 (95%) were eligible for inclusion in the analysis. After a maximum of 13 years of follow-up (median 8.94 years), 637 women had a disease-free survival event (tamoxifen, 179 events in 361 patients; CAF-T, 216 events in 566 patients; CAFT, 242 events in 550 patients). For the first objective, therapy with the CAF plus tamoxifen groups combined (CAFT or CAF-T) was superior to tamoxifen alone for the primary endpoint of disease-free survival (adjusted Cox regression hazard ratio [HR] 0.76, 95% CI 0.64-0.91; p=0.002) but only marginally for the secondary endpoint of overall survival (HR 0.83, 0.68-1.01; p=0.057). For the second objective, the adjusted HRs favoured CAF-T over CAFT but did not reach significance for disease-free survival (HR 0.84, 0.70-1.01; p=0.061) or overall survival (HR 0.90, 0.73-1.10; p=0.30). Neutropenia, stomatitis, thromboembolism, congestive heart failure, and leukaemia were more frequent in the combined CAF plus tamoxifen groups than in the tamoxifen-alone group.Chemotherapy with CAF plus tamoxifen given sequentially is more effective adjuvant therapy for postmenopausal patients with endocrine-responsive, node-positive breast cancer than is tamoxifen alone. However, it might be possible to identify some subgroups that do not benefit from anthracycline-based chemotherapy despite positive nodes.National Cancer Institute (US National Institutes of Health).Copyright 2009 Elsevier Ltd. All rights reserved.","Adjuvant chemotherapy and timing of tamoxifen in postmenopausal patients with endocrine-responsive, node-positive breast cancer: a phase 3, open-label, randomised controlled trial."
"1173","Lancet.166","1.00E-04",20006130,2009,"Combinations of aspirin, clopidogrel, and vitamin K antagonists are widely used in patients after myocardial infarction. However, data for the safety of combinations are sparse. We examined the risk of hospital admission for bleeding associated with different antithrombotic regimens.By use of nationwide registers from Denmark, we identified 40 812 patients aged 30 years or older who had been admitted to hospital with first-time myocardial infarction between 2000 and 2005. Claimed prescriptions starting at hospital discharge were used to determine the regimen prescribed according to the following groups: monotherapy with aspirin, clopidogrel, or vitamin K antagonist; dual therapy with aspirin plus clopidogrel, aspirin plus vitamin K antagonist, or clopidogrel plus vitamin K antagonist; or triple therapy including all three drugs. Risk of hospital admission for bleeding, recurrent myocardial infarction, and death were assessed by Cox proportional hazards models with the drug exposure groups as time-varying covariates.During a mean follow-up of 476.5 days (SD 142.0), 1891 (4.6%) patients were admitted to hospital with bleeding. The yearly incidence of bleeding was 2.6% for the aspirin group, 4.6% for clopidogrel, 4.3% for vitamin K antagonist, 3.7% for aspirin plus clopidogrel, 5.1% for aspirin plus vitamin K antagonist, 12.3% for clopidogrel plus vitamin K antagonist, and 12.0% for triple therapy. With aspirin as reference, adjusted hazard ratios for bleeding were 1.33 (95% CI 1.11-1.59) for clopidogrel, 1.23 (0.94-1.61) for vitamin K antagonist, 1.47 (1.28-1.69) for aspirin plus clopidogrel, 1.84 (1.51-2.23) for aspirin plus vitamin K antagonist, 3.52 (2.42-5.11) for clopidogrel plus vitamin K antagonist, and 4.05 (3.08-5.33) for triple therapy. Numbers needed to harm were 81.2 for aspirin plus clopidogrel, 45.4 for aspirin plus vitamin K antagonist, 15.2 for clopidogrel plus vitamin K antagonist, and 12.5 for triple therapy. 702 (37.9%) of 1852 patients with non-fatal bleeding had recurrent myocardial infarction or died during the study period compared with 7178 (18.4%) of 38 960 patients without non-fatal bleeding (HR 3.00, 2.75-3.27, p<0.0001).In patients with myocardial infarction, risk of hospital admission for bleeding increased with the number of antithrombotic drugs used. Treatment with triple therapy or dual therapy with clopidogrel plus vitamin K antagonist should be prescribed only after thorough individual risk assessment.Danish Heart Foundation and the Danish Medical Research Council.","Risk of bleeding in patients with acute myocardial infarction treated with different combinations of aspirin, clopidogrel, and vitamin K antagonists in Denmark: a retrospective analysis of nationwide registry data."
"1174","Lancet.251","1.00E-04",20092884,2010,"Congenital anomalies are a leading cause of perinatal and infant mortality. Advances in care have improved the prognosis for some congenital anomaly groups and subtypes, but there remains a paucity of knowledge about survival for many others, especially beyond the first year of life. We estimated survival up to 20 years of age for a range of congenital anomaly groups and subtypes.Information about children with at least one congenital anomaly, delivered between 1985 and 2003, was obtained from the UK Northern Congenital Abnormality Survey (NorCAS). Anomalies were categorised by group (the system affected), subtype (the individual disorder), and syndrome according to European Surveillance of Congenital Anomalies (EUROCAT) guidelines. Local hospital and national mortality records were used to identify the survival status of liveborn children. Survival up to 20 years of age was estimated by use of Kaplan-Meier methods. Cox proportional hazards regression was used to examine factors that affected survival.13,758 cases of congenital anomaly were notified to NorCAS between 1985 and 2003. Survival status was available for 10 850 (99.0%) of 10 964 livebirths. 20-year survival was 85.5% (95% CI 84.8-86.3) in individuals born with at least one congenital anomaly, 89.5% (88.4-90.6) for cardiovascular system anomalies, 79.1% (76.7-81.3) for chromosomal anomalies, 93.2% (91.6-94.5) for urinary system anomalies, 83.2% (79.8-86.0) for digestive system anomalies, 97.6% (95.9-98.6) for orofacial clefts, and 66.2% (61.5-70.5) for nervous system anomalies. Survival varied between subtypes within the same congenital anomaly group. The proportion of terminations for fetal anomaly increased throughout the study period (from 12.4%, 9.8-15.5, in 1985 to 18.3%, 15.6-21.2, in 2003; p<0.0001) and, together with year of birth, was an independent predictor of survival (adjusted hazard ratio [HR] for proportion of terminations 0.95, 95% CI 0.91-0.99, p=0.023; adjusted HR for year of birth 0.94, 0.92-0.96, p<0.0001).Estimates of survival for congenital anomaly groups and subtypes will be valuable for families and health professionals when a congenital anomaly is detected, and will assist in planning for the future care needs of affected individuals.BDF Newlife.Copyright 2010 Elsevier Ltd. All rights reserved.","20-year survival of children born with congenital anomalies: a population-based study."
"1175","Lancet.285","0.023",20092884,2010,"Congenital anomalies are a leading cause of perinatal and infant mortality. Advances in care have improved the prognosis for some congenital anomaly groups and subtypes, but there remains a paucity of knowledge about survival for many others, especially beyond the first year of life. We estimated survival up to 20 years of age for a range of congenital anomaly groups and subtypes.Information about children with at least one congenital anomaly, delivered between 1985 and 2003, was obtained from the UK Northern Congenital Abnormality Survey (NorCAS). Anomalies were categorised by group (the system affected), subtype (the individual disorder), and syndrome according to European Surveillance of Congenital Anomalies (EUROCAT) guidelines. Local hospital and national mortality records were used to identify the survival status of liveborn children. Survival up to 20 years of age was estimated by use of Kaplan-Meier methods. Cox proportional hazards regression was used to examine factors that affected survival.13,758 cases of congenital anomaly were notified to NorCAS between 1985 and 2003. Survival status was available for 10 850 (99.0%) of 10 964 livebirths. 20-year survival was 85.5% (95% CI 84.8-86.3) in individuals born with at least one congenital anomaly, 89.5% (88.4-90.6) for cardiovascular system anomalies, 79.1% (76.7-81.3) for chromosomal anomalies, 93.2% (91.6-94.5) for urinary system anomalies, 83.2% (79.8-86.0) for digestive system anomalies, 97.6% (95.9-98.6) for orofacial clefts, and 66.2% (61.5-70.5) for nervous system anomalies. Survival varied between subtypes within the same congenital anomaly group. The proportion of terminations for fetal anomaly increased throughout the study period (from 12.4%, 9.8-15.5, in 1985 to 18.3%, 15.6-21.2, in 2003; p<0.0001) and, together with year of birth, was an independent predictor of survival (adjusted hazard ratio [HR] for proportion of terminations 0.95, 95% CI 0.91-0.99, p=0.023; adjusted HR for year of birth 0.94, 0.92-0.96, p<0.0001).Estimates of survival for congenital anomaly groups and subtypes will be valuable for families and health professionals when a congenital anomaly is detected, and will assist in planning for the future care needs of affected individuals.BDF Newlife.Copyright 2010 Elsevier Ltd. All rights reserved.","20-year survival of children born with congenital anomalies: a population-based study."
"1176","Lancet.136","1.00E-04",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1177","Lancet.137","1.00E-04",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1178","Lancet.138","1.00E-04",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1179","Lancet.139","1.00E-04",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1180","Lancet.140","1.00E-04",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1181","Lancet.141","1.00E-04",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1182","Lancet.157","1.00E-04",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1183","Lancet.158","3.00E-04",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1184","Lancet.159","2.00E-04",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1185","Lancet.160","0.0083",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1186","Lancet.161","4.00E-04",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1187","Lancet.162","1.00E-04",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1188","Lancet.163","0.0069",20109957,2010,"Anticipation of the types of injuries that occur in modern warfare is essential to plan operations and maintain a healthy military. We aimed to identify the diagnoses that result in most medical evacuations, and ascertain which demographic and clinical variables were associated with return to duty.Demographic and clinical data were prospectively obtained for US military personnel who had been medically evacuated from Operation Iraqi Freedom or Operation Enduring Freedom (January, 2004-December, 2007). Diagnoses were categorised post hoc according to the International Classification of Diseases codes that were recorded at the time of transfer. The primary outcome measure was return to duty within 2 weeks.34 006 personnel were medically evacuated, of whom 89% were men, 91% were enlisted, 82% were in the army, and 86% sustained an injury in Iraq. The most common reasons for medical evacuation were: musculoskeletal and connective tissue disorders (n=8104 service members, 24%), combat injuries (n=4713, 14%), neurological disorders (n=3502, 10%), psychiatric diagnoses (n=3108, 9%), and spinal pain (n=2445, 7%). The factors most strongly associated with return to duty were being a senior officer (adjusted OR 2.01, 95% CI 1.71-2.35, p<0.0001), having a non-battle-related injury or disease (3.18, 2.77-3.67, p<0.0001), and presenting with chest or abdominal pain (2.48, 1.61-3.81, p<0.0001), a gastrointestinal disorder (non-surgical 2.32, 1.51-3.56, p=0.0001; surgical 2.62, 1.69-4.06, p<0.0001), or a genitourinary disorder (2.19, 1.43-3.36, p=0.0003). Covariates associated with a decreased probability of return to duty were serving in the navy or coast guard (0.59, 0.45-0.78, p=0.0002), or marines (0.86, 0.77-0.96, p=0.0083); and presenting with a combat injury (0.27, 0.17-0.44, p<0.0001), a psychiatric disorder (0.28, 0.18-0.43, p<0.0001), musculoskeletal or connective tissue disorder (0.46, 0.30-0.71, p=0.0004), spinal pain (0.41, 0.26-0.63, p=0.0001), or other wound (0.54, 0.34-0.84, p=0.0069).Implementation of preventive measures for service members who are at highest risk of evacuation, forward-deployed treatment, and therapeutic interventions could reduce the effect of non-battle-related injuries and disease on military readiness.John P Murtha Neuroscience and Pain Institute, and US Army Regional Anesthesia and Pain Management Initiative.Copyright 2010 Elsevier Ltd. All rights reserved.","Diagnoses and factors associated with medical evacuation and return to duty for service members participating in Operation Iraqi Freedom or Operation Enduring Freedom: a prospective cohort study."
"1189","BMJ.171","0.03",20110306,2010,"To determine the association of non-invasive cardiac stress testing before elective intermediate to high risk non-cardiac surgery with survival and hospital stay.Population based retrospective cohort study.Acute care hospitals in Ontario, Canada, between 1 April 1994 and 31 March 2004.Patients aged 40 years or older who underwent specific elective intermediate to high risk non-cardiac surgical procedures.Non-invasive cardiac stress testing performed within six months before surgery.Postoperative one year survival and length of stay in hospital.Of the 271 082 patients in the entire cohort, 23 991 (8.9%) underwent stress testing. After propensity score methods were used to reduce important differences between patients who did or did not undergo preoperative stress testing and assemble a matched cohort (n=46 120), testing was associated with improved one year survival (hazard ratio (HR) 0.92, 95% CI 0.86 to 0.99; P=0.03) and reduced mean hospital stay (difference -0.24 days, 95% CI -0.07 to -0.43; P<0.001). In an analysis of subgroups defined by Revised Cardiac Risk Index (RCRI) class, testing was associated with harm in low risk patients (RCRI 0 points: HR 1.35, 95% CI 1.05 to 1.74), but with benefit in patients who were at intermediate risk (RCRI 1-2 points: 0.92, 95% CI 0.85 to 0.99) or high risk (RCRI 3-6 points: 0.80, 95% CI 0.67 to 0.97).Preoperative non-invasive cardiac stress testing is associated with improved one year survival and length of hospital stay in patients undergoing elective intermediate to high risk non-cardiac surgery. These benefits principally apply to patients with risk factors for perioperative cardiac complications.","Non-invasive cardiac stress testing before elective major non-cardiac surgery: population based cohort study."
"1190","Lancet.156","0.046",20116841,2010,"Emergency contraception can prevent unintended pregnancies, but current methods are only effective if used as soon as possible after sexual intercourse and before ovulation. We compared the efficacy and safety of ulipristal acetate with levonorgestrel for emergency contraception.Women with regular menstrual cycles who presented to a participating family planning clinic requesting emergency contraception within 5 days of unprotected sexual intercourse were eligible for enrolment in this randomised, multicentre, non-inferiority trial. 2221 women were randomly assigned to receive a single, supervised dose of 30 mg ulipristal acetate (n=1104) or 1.5 mg levonorgestrel (n=1117) orally. Allocation was by block randomisation stratified by centre and time from unprotected sexual intercourse to treatment, with allocation concealment by identical opaque boxes labelled with a unique treatment number. Participants were masked to treatment assignment whereas investigators were not. Follow-up was done 5-7 days after expected onset of next menses. The primary endpoint was pregnancy rate in women who received emergency contraception within 72 h of unprotected sexual intercourse, with a non-inferiority margin of 1% point difference between groups (limit of 1.6 for odds ratio). Analysis was done on the efficacy-evaluable population, which excluded women lost to follow-up, those aged over 35 years, women with unknown follow-up pregnancy status, and those who had re-enrolled in the study. Additionally, we undertook a meta-analysis of our trial and an earlier study to assess the efficacy of ulipristal acetate compared with levonorgestrel. This trial is registered with ClinicalTrials.gov, number NCT00551616.In the efficacy-evaluable population, 1696 women received emergency contraception within 72 h of sexual intercourse (ulipristal acetate, n=844; levonorgestrel, n=852). There were 15 pregnancies in the ulipristal acetate group (1.8%, 95% CI 1.0-3.0) and 22 in the levonorgestrel group (2.6%, 1.7-3.9; odds ratio [OR] 0.68, 95% CI 0.35-1.31). In 203 women who received emergency contraception between 72 h and 120 h after sexual intercourse, there were three pregnancies, all of which were in the levonorgestrel group. The most frequent adverse event was headache (ulipristal acetate, 213 events [19.3%] in 1104 women; levonorgestrel, 211 events [18.9%] in 1117 women). Two serious adverse events were judged possibly related to use of emergency contraception; a case of dizziness in the ulipristal acetate group and a molar pregnancy in the levonorgestrel group. In the meta-analysis (0-72 h), there were 22 (1.4%) pregnancies in 1617 women in the ulipristal acetate group and 35 (2.2%) in 1625 women in the levonorgestrel group (OR 0.58, 0.33-0.99; p=0.046).Ulipristal acetate provides women and health-care providers with an effective alternative for emergency contraception that can be used up to 5 days after unprotected sexual intercourse.HRA Pharma.Copyright 2010 Elsevier Ltd. All rights reserved.","Ulipristal acetate versus levonorgestrel for emergency contraception: a randomised non-inferiority trial and meta-analysis."
"1191","Lancet.281","0.0316",20116842,2010,"Standard treatment of critically ill patients undergoing mechanical ventilation is continuous sedation. Daily interruption of sedation has a beneficial effect, and in the general intesive care unit of Odense University Hospital, Denmark, standard practice is a protocol of no sedation. We aimed to establish whether duration of mechanical ventilation could be reduced with a protocol of no sedation versus daily interruption of sedation.Of 428 patients assessed for eligibility, we enrolled 140 critically ill adult patients who were undergoing mechanical ventilation and were expected to need ventilation for more than 24 h. Patients were randomly assigned in a 1:1 ratio (unblinded) to receive: no sedation (n=70 patients); or sedation (20 mg/mL propofol for 48 h, 1 mg/mL midazolam thereafter) with daily interruption until awake (n=70, control group). Both groups were treated with bolus doses of morphine (2.5 or 5 mg). The primary outcome was the number of days without mechanical ventilation in a 28-day period, and we also recorded the length of stay in the intensive care unit (from admission to 28 days) and in hospital (from admission to 90 days). Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00466492.27 patients died or were successfully extubated within 48 h, and, as per our study design, were excluded from the study and statistical analysis. Patients receiving no sedation had significantly more days without ventilation (n=55; mean 13.8 days, SD 11.0) than did those receiving interrupted sedation (n=58; mean 9.6 days, SD 10.0; mean difference 4.2 days, 95% CI 0.3-8.1; p=0.0191). No sedation was also associated with a shorter stay in the intensive care unit (HR 1.86, 95% CI 1.05-3.23; p=0.0316), and, for the first 30 days studied, in hospital (3.57, 1.52-9.09; p=0.0039), than was interrupted sedation. No difference was recorded in the occurrences of accidental extubations, the need for CT or MRI brain scans, or ventilator-associated pneumonia. Agitated delirium was more frequent in the intervention group than in the control group (n=11, 20%vs n=4, 7%; p=0.0400).No sedation of critically ill patients receiving mechanical ventilation is associated with an increase in days without ventilation. A multicentre study is needed to establish whether this effect can be reproduced in other facilities.Danish Society of Anesthesiology and Intensive Care Medicine, the Fund of Danielsen, the Fund of Kirsten Jensa la Cour, and the Fund of Holger og Ruth Hess.Copyright 2010 Elsevier Ltd. All rights reserved.","A protocol of no sedation for critically ill patients receiving mechanical ventilation: a randomised trial."
"1192","Lancet.282","0.0039",20116842,2010,"Standard treatment of critically ill patients undergoing mechanical ventilation is continuous sedation. Daily interruption of sedation has a beneficial effect, and in the general intesive care unit of Odense University Hospital, Denmark, standard practice is a protocol of no sedation. We aimed to establish whether duration of mechanical ventilation could be reduced with a protocol of no sedation versus daily interruption of sedation.Of 428 patients assessed for eligibility, we enrolled 140 critically ill adult patients who were undergoing mechanical ventilation and were expected to need ventilation for more than 24 h. Patients were randomly assigned in a 1:1 ratio (unblinded) to receive: no sedation (n=70 patients); or sedation (20 mg/mL propofol for 48 h, 1 mg/mL midazolam thereafter) with daily interruption until awake (n=70, control group). Both groups were treated with bolus doses of morphine (2.5 or 5 mg). The primary outcome was the number of days without mechanical ventilation in a 28-day period, and we also recorded the length of stay in the intensive care unit (from admission to 28 days) and in hospital (from admission to 90 days). Analysis was by intention to treat. This study is registered with ClinicalTrials.gov, number NCT00466492.27 patients died or were successfully extubated within 48 h, and, as per our study design, were excluded from the study and statistical analysis. Patients receiving no sedation had significantly more days without ventilation (n=55; mean 13.8 days, SD 11.0) than did those receiving interrupted sedation (n=58; mean 9.6 days, SD 10.0; mean difference 4.2 days, 95% CI 0.3-8.1; p=0.0191). No sedation was also associated with a shorter stay in the intensive care unit (HR 1.86, 95% CI 1.05-3.23; p=0.0316), and, for the first 30 days studied, in hospital (3.57, 1.52-9.09; p=0.0039), than was interrupted sedation. No difference was recorded in the occurrences of accidental extubations, the need for CT or MRI brain scans, or ventilator-associated pneumonia. Agitated delirium was more frequent in the intervention group than in the control group (n=11, 20%vs n=4, 7%; p=0.0400).No sedation of critically ill patients receiving mechanical ventilation is associated with an increase in days without ventilation. A multicentre study is needed to establish whether this effect can be reproduced in other facilities.Danish Society of Anesthesiology and Intensive Care Medicine, the Fund of Danielsen, the Fund of Kirsten Jensa la Cour, and the Fund of Holger og Ruth Hess.Copyright 2010 Elsevier Ltd. All rights reserved.","A protocol of no sedation for critically ill patients receiving mechanical ventilation: a randomised trial."
"1193","JAMA.5841","0.001",20145230,2010,"Gene expression profiling may be useful in examining differences underlying age- and sex-specific outcomes in non-small cell lung cancer (NSCLC).To describe clinically relevant differences in the underlying biology of NSCLC based on patient age and sex.Retrospective analysis of 787 patients with predominantly early stage NSCLC performed at Duke University, Durham, North Carolina, from July 2008 to June 2009. Lung tumor samples with corresponding microarray and clinical data were used. All patients were divided into subgroups based on age (< 70 vs > or = 70 years old) or sex. Gene expression signatures representing oncogenic pathway activation and tumor biology/microenvironment status were applied to these samples to obtain patterns of activation/deregulation.Patterns of oncogenic and molecular signaling pathway activation that are reproducible and correlate with 5-year recurrence-free patient survival.Low- and high-risk patient clusters/cohorts were identified with the longest and shortest 5-year recurrence-free survival, respectively, within the age and sex NSCLC subgroups. These cohorts of NSCLC demonstrate similar patterns of pathway activation. In patients younger than 70 years, high-risk patients, with the shortest recurrence-free survival, demonstrated increased activation of the Src (25% vs 6%; P<.001) and tumor necrosis factor (76% vs 42%; P<.001) pathways compared with low-risk patients. High-risk patients aged 70 years or older demonstrated increased activation of the wound healing (40% vs 24%; P = .02) and invasiveness (64% vs 20%; P<.001) pathways compared with low-risk patients. In women, high-risk patients demonstrated increased activation of the invasiveness (99% vs 2%; P<.001) and STAT3 (72% vs 35%; P<.001) pathways while high-risk men demonstrated increased activation of the STAT3 (87% vs 18%; P<.001), tumor necrosis factor (90% vs 46%; P<.001), EGFR (13% vs 2%; P = .003), and wound healing (50% vs 22%; P<.001) pathways. Multivariate analyses confirmed the independent clinical relevance of the pathway-based subphenotypes in women (hazard ratio [HR], 2.02; 95% confidence interval [CI], 1.34-3.03; P<.001) and patients younger than 70 years (HR, 1.83; 95% CI, 1.24-2.71; P = .003). All observations were reproducible in split sample analyses.Among a cohort of patients with NSCLC, subgroups defined by oncogenic pathway activation profiles were associated with recurrence-free survival. These findings require validation in independent patient data sets.","Age- and sex-specific genomic profiles in non-small cell lung cancer."
"1194","JAMA.636","0.003",20145230,2010,"Gene expression profiling may be useful in examining differences underlying age- and sex-specific outcomes in non-small cell lung cancer (NSCLC).To describe clinically relevant differences in the underlying biology of NSCLC based on patient age and sex.Retrospective analysis of 787 patients with predominantly early stage NSCLC performed at Duke University, Durham, North Carolina, from July 2008 to June 2009. Lung tumor samples with corresponding microarray and clinical data were used. All patients were divided into subgroups based on age (< 70 vs > or = 70 years old) or sex. Gene expression signatures representing oncogenic pathway activation and tumor biology/microenvironment status were applied to these samples to obtain patterns of activation/deregulation.Patterns of oncogenic and molecular signaling pathway activation that are reproducible and correlate with 5-year recurrence-free patient survival.Low- and high-risk patient clusters/cohorts were identified with the longest and shortest 5-year recurrence-free survival, respectively, within the age and sex NSCLC subgroups. These cohorts of NSCLC demonstrate similar patterns of pathway activation. In patients younger than 70 years, high-risk patients, with the shortest recurrence-free survival, demonstrated increased activation of the Src (25% vs 6%; P<.001) and tumor necrosis factor (76% vs 42%; P<.001) pathways compared with low-risk patients. High-risk patients aged 70 years or older demonstrated increased activation of the wound healing (40% vs 24%; P = .02) and invasiveness (64% vs 20%; P<.001) pathways compared with low-risk patients. In women, high-risk patients demonstrated increased activation of the invasiveness (99% vs 2%; P<.001) and STAT3 (72% vs 35%; P<.001) pathways while high-risk men demonstrated increased activation of the STAT3 (87% vs 18%; P<.001), tumor necrosis factor (90% vs 46%; P<.001), EGFR (13% vs 2%; P = .003), and wound healing (50% vs 22%; P<.001) pathways. Multivariate analyses confirmed the independent clinical relevance of the pathway-based subphenotypes in women (hazard ratio [HR], 2.02; 95% confidence interval [CI], 1.34-3.03; P<.001) and patients younger than 70 years (HR, 1.83; 95% CI, 1.24-2.71; P = .003). All observations were reproducible in split sample analyses.Among a cohort of patients with NSCLC, subgroups defined by oncogenic pathway activation profiles were associated with recurrence-free survival. These findings require validation in independent patient data sets.","Age- and sex-specific genomic profiles in non-small cell lung cancer."
"1195","Lancet.278","0.03",20153888,2010,"Most people infected with HIV-1 are dually infected with herpes simplex virus type 2. Daily suppression of this herpes virus reduces plasma HIV-1 concentrations, but whether it delays HIV-1 disease progression is unknown. We investigated the effect of acyclovir on HIV-1 progression.In a trial with 14 sites in southern Africa and east Africa, 3381 heterosexual people who were dually infected with herpes simplex virus type 2 and HIV-1 were randomly assigned in a 1:1 ratio to acyclovir 400 mg orally twice daily or placebo, and were followed up for up to 24 months. Eligible participants had CD4 cell counts of 250 cells per mL or higher and were not taking antiretroviral therapy. We used block randomisation, and patients and investigators were masked to treatment allocation. Effect of acyclovir on HIV-1 disease progression was defined by a primary composite endpoint of first occurrence of CD4 cell counts of fewer than 200 cells per microL, antiretroviral therapy initiation, or non-trauma related death. As an exploratory analysis, we assessed the endpoint of CD4 falling to <350 cells per microL. Analysis was by intention to treat. The trial is registered with ClinicalTrials.gov, number NCT00194519.At enrollment, the median CD4 cell count was 462 cells per microL and median HIV-1 plasma RNA was 4.1 log(10) copies per microL. Acyclovir reduced risk of HIV-1 disease progression by 16%; 284 participants assigned acyclovir versus 324 assigned placebo reached the primary endpoint (hazard ratio [HR] 0.84, 95% CI 0.71-0.98, p=0.03). In those with CD4 counts >or=350 cells per microL, aciclovir delayed risk of CD4 cell counts falling to <350 cells per microL by 19% (0.81, 0.71-0.93, p=0.002)The role of suppression of herpes simplex virus type 2 in reduction of HIV-1 disease progression before initiation of antiretroviral therapy warrants consideration.Bill & Melinda Gates Foundation.Copyright 2010 Elsevier Ltd. All rights reserved.","Daily acyclovir for HIV-1 disease progression in people dually infected with HIV-1 and herpes simplex virus type 2: a randomised placebo-controlled trial."
"1196","Lancet.279","0.002",20153888,2010,"Most people infected with HIV-1 are dually infected with herpes simplex virus type 2. Daily suppression of this herpes virus reduces plasma HIV-1 concentrations, but whether it delays HIV-1 disease progression is unknown. We investigated the effect of acyclovir on HIV-1 progression.In a trial with 14 sites in southern Africa and east Africa, 3381 heterosexual people who were dually infected with herpes simplex virus type 2 and HIV-1 were randomly assigned in a 1:1 ratio to acyclovir 400 mg orally twice daily or placebo, and were followed up for up to 24 months. Eligible participants had CD4 cell counts of 250 cells per mL or higher and were not taking antiretroviral therapy. We used block randomisation, and patients and investigators were masked to treatment allocation. Effect of acyclovir on HIV-1 disease progression was defined by a primary composite endpoint of first occurrence of CD4 cell counts of fewer than 200 cells per microL, antiretroviral therapy initiation, or non-trauma related death. As an exploratory analysis, we assessed the endpoint of CD4 falling to <350 cells per microL. Analysis was by intention to treat. The trial is registered with ClinicalTrials.gov, number NCT00194519.At enrollment, the median CD4 cell count was 462 cells per microL and median HIV-1 plasma RNA was 4.1 log(10) copies per microL. Acyclovir reduced risk of HIV-1 disease progression by 16%; 284 participants assigned acyclovir versus 324 assigned placebo reached the primary endpoint (hazard ratio [HR] 0.84, 95% CI 0.71-0.98, p=0.03). In those with CD4 counts >or=350 cells per microL, aciclovir delayed risk of CD4 cell counts falling to <350 cells per microL by 19% (0.81, 0.71-0.93, p=0.002)The role of suppression of herpes simplex virus type 2 in reduction of HIV-1 disease progression before initiation of antiretroviral therapy warrants consideration.Bill & Melinda Gates Foundation.Copyright 2010 Elsevier Ltd. All rights reserved.","Daily acyclovir for HIV-1 disease progression in people dually infected with HIV-1 and herpes simplex virus type 2: a randomised placebo-controlled trial."
"1197","JAMA.633","0.006",20159871,2010,"While multiple genetic markers associated with cardiovascular disease have been identified by genome-wide association studies, their aggregate effect on risk beyond traditional factors is uncertain, particularly among women.To test the predictive ability of a literature-based genetic risk score for cardiovascular disease.Prospective cohort of 19,313 initially healthy white women in the Women's Genome Health Study followed up over a median of 12.3 years (interquartile range, 11.6-12.8 years). Genetic risk scores were constructed from the National Human Genome Research Institute's catalog of genome-wide association study results published between 2005 and June 2009.Incident myocardial infarction, stroke, arterial revascularization, and cardiovascular death.A total of 101 single nucleotide polymorphisms reported to be associated with cardiovascular disease or at least 1 intermediate cardiovascular disease phenotype at a published P value of less than 10(-7) were identified and risk alleles were added to create a genetic risk score. During follow-up, 777 cardiovascular disease events occurred (199 myocardial infarctions, 203 strokes, 63 cardiovascular deaths, 312 revascularizations). After adjustment for age, the genetic risk score had a hazard ratio (HR) for cardiovascular disease of 1.02 per risk allele (95% confidence interval [CI], 1.00-1.03/risk allele; P = .006). This corresponds to an absolute cardiovascular disease risk of 3% over 10 years in the lowest tertile of genetic risk (73-99 risk alleles) and 3.7% in the highest tertile (106-125 risk alleles). However, after adjustment for traditional factors, the genetic risk score did not improve discrimination or reclassification (change in c index from Expert Panel on Detection, Evaluation, and Treatment of High Blood Cholesterol in Adults [ATP III] risk score, 0; net reclassification improvement, 0.5%; [P = .24]). The genetic risk score was not associated with cardiovascular disease risk (ATP III-adjusted HR/allele, 1.00; 95% CI, 0.99-1.01). In contrast, self-reported family history remained significantly associated with cardiovascular disease in multivariable models.After adjustment for traditional cardiovascular risk factors, a genetic risk score comprising 101 single nucleotide polymorphisms was not significantly associated with the incidence of total cardiovascular disease.","Association between a literature-based genetic risk score and cardiovascular events in women."
"1198","Lancet.249","1.00E-04",20170948,2010,"The Avoiding Cardiovascular Events through Combination Therapy in Patients Living with Systolic Hypertension (ACCOMPLISH) trial showed that initial antihypertensive therapy with benazepril plus amlodipine was superior to benazepril plus hydrochlorothiazide in reducing cardiovascular morbidity and mortality. We assessed the effects of these drug combinations on progression of chronic kidney disease.ACCOMPLISH was a double-blind, randomised trial undertaken in five countries (USA, Sweden, Norway, Denmark, and Finland). 11 506 patients with hypertension who were at high risk for cardiovascular events were randomly assigned via a central, telephone-based interactive voice response system in a 1:1 ratio to receive benazepril (20 mg) plus amlodipine (5 mg; n=5744) or benazepril (20 mg) plus hydrochlorothiazide (12.5 mg; n=5762), orally once daily. Drug doses were force-titrated for patients to attain recommended blood pressure goals. Progression of chronic kidney disease, a prespecified endpoint, was defined as doubling of serum creatinine concentration or end-stage renal disease (estimated glomerular filtration rate <15 mL/min/1.73 m(2) or need for dialysis). Analysis was by intention to treat (ITT). This trial is registered with ClinicalTrials.gov, number NCT00170950.The trial was terminated early (mean follow-up 2.9 years [SD 0.4]) because of superior efficacy of benazepril plus amlodipine compared with benazepril plus hydrochlorothiazide. At trial completion, vital status was not known for 143 (1%) patients who were lost to follow-up (benazepril plus amlodipine, n=70; benazepril plus hydrochlorothiazide, n=73). All randomised patients were included in the ITT analysis. There were 113 (2.0%) events of chronic kidney disease progression in the benazepril plus amlodipine group compared with 215 (3.7%) in the benazepril plus hydrochlorothiazide group (HR 0.52, 0.41-0.65, p<0.0001). The most frequent adverse event in patients with chronic kidney disease was peripheral oedema (benazepril plus amlodipine, 189 of 561, 33.7%; benazepril plus hydrochlorothiazide, 85 of 532, 16.0%). In patients with chronic kidney disease, angio-oedema was more frequent in the benazepril plus amlodipine group than in the benazepril plus hydrochlorothiazide group. In patients without chronic kidney disease, dizziness, hypokalaemia, and hypotension were more frequent in the benazepril plus hydrochlorothiazide group than in the benazepril plus amlodipine group.Initial antihypertensive treatment with benazepril plus amlodipine should be considered in preference to benazepril plus hydrochlorothiazide since it slows progression of nephropathy to a greater extent.Novartis.Copyright 2010 Elsevier Ltd. All rights reserved.","Renal outcomes with different fixed-dose combination therapies in patients with hypertension at high risk for cardiovascular events (ACCOMPLISH): a prespecified secondary analysis of a randomised controlled trial."
"1199","Lancet.248","1.00E-04",20188410,2010,"In response to findings that pelvic lymphadenectomy does not have any therapeutic benefit for endometrial cancer, we aimed to establish whether complete, systematic lymphadenectomy, including the para-aortic lymph nodes, should be part of surgical therapy for patients at intermediate and high risk of recurrence.We selected 671 patients with endometrial carcinoma who had been treated with complete, systematic pelvic lymphadenectomy (n=325 patients) or combined pelvic and para-aortic lymphadenectomy (n=346) at two tertiary centres in Japan (January, 1986-June, 2004). Patients at intermediate or high risk of recurrence were offered adjuvant radiotherapy or chemotherapy. The primary outcome measure was overall survival.Overall survival was significantly longer in the pelvic and para-aortic lymphadenectomy group than in the pelvic lymphadenectomy group (HR 0.53, 95% CI 0.38-0.76; p=0.0005). This association was also recorded in 407 patients at intermediate or high risk (p=0.0009), but overall survival was not related to lymphadenectomy type in low-risk patients. Multivariate analysis of prognostic factors showed that in patients with intermediate or high risk of recurrence, pelvic and para-aortic lymphadenectomy reduced the risk of death compared with pelvic lymphadenectomy (0.44, 0.30-0.64; p<0.0001). Analysis of 328 patients with intermediate or high risk who were treated with adjuvant radiotherapy or chemotherapy showed that patient survival improved with pelvic and para-aortic lymphadenectomy (0.48, 0.29-0.83; p=0.0049) and with adjuvant chemotherapy (0.59, 0.37-1.00; p=0.0465) independently of one another.Combined pelvic and para-aortic lymphadenectomy is recommended as treatment for patients with endometrial carcinoma of intermediate or high risk of recurrence. If a prospective randomised or comparative cohort study is planned to validate the therapeutic effect of lymphadenectomy, it should include both pelvic and para-aortic lymphadenectomy in patients of intermediate or high risk of recurrence.Japanese Foundation for Multidisciplinary Treatment of Cancer, and the Japan Society for the Promotion of Science.Copyright 2010 Elsevier Ltd. All rights reserved.","Survival effect of para-aortic lymphadenectomy in endometrial cancer (SEPAL study): a retrospective cohort analysis."
"1200","Lancet.274","5.00E-04",20188410,2010,"In response to findings that pelvic lymphadenectomy does not have any therapeutic benefit for endometrial cancer, we aimed to establish whether complete, systematic lymphadenectomy, including the para-aortic lymph nodes, should be part of surgical therapy for patients at intermediate and high risk of recurrence.We selected 671 patients with endometrial carcinoma who had been treated with complete, systematic pelvic lymphadenectomy (n=325 patients) or combined pelvic and para-aortic lymphadenectomy (n=346) at two tertiary centres in Japan (January, 1986-June, 2004). Patients at intermediate or high risk of recurrence were offered adjuvant radiotherapy or chemotherapy. The primary outcome measure was overall survival.Overall survival was significantly longer in the pelvic and para-aortic lymphadenectomy group than in the pelvic lymphadenectomy group (HR 0.53, 95% CI 0.38-0.76; p=0.0005). This association was also recorded in 407 patients at intermediate or high risk (p=0.0009), but overall survival was not related to lymphadenectomy type in low-risk patients. Multivariate analysis of prognostic factors showed that in patients with intermediate or high risk of recurrence, pelvic and para-aortic lymphadenectomy reduced the risk of death compared with pelvic lymphadenectomy (0.44, 0.30-0.64; p<0.0001). Analysis of 328 patients with intermediate or high risk who were treated with adjuvant radiotherapy or chemotherapy showed that patient survival improved with pelvic and para-aortic lymphadenectomy (0.48, 0.29-0.83; p=0.0049) and with adjuvant chemotherapy (0.59, 0.37-1.00; p=0.0465) independently of one another.Combined pelvic and para-aortic lymphadenectomy is recommended as treatment for patients with endometrial carcinoma of intermediate or high risk of recurrence. If a prospective randomised or comparative cohort study is planned to validate the therapeutic effect of lymphadenectomy, it should include both pelvic and para-aortic lymphadenectomy in patients of intermediate or high risk of recurrence.Japanese Foundation for Multidisciplinary Treatment of Cancer, and the Japan Society for the Promotion of Science.Copyright 2010 Elsevier Ltd. All rights reserved.","Survival effect of para-aortic lymphadenectomy in endometrial cancer (SEPAL study): a retrospective cohort analysis."
"1201","Lancet.276","0.0049",20188410,2010,"In response to findings that pelvic lymphadenectomy does not have any therapeutic benefit for endometrial cancer, we aimed to establish whether complete, systematic lymphadenectomy, including the para-aortic lymph nodes, should be part of surgical therapy for patients at intermediate and high risk of recurrence.We selected 671 patients with endometrial carcinoma who had been treated with complete, systematic pelvic lymphadenectomy (n=325 patients) or combined pelvic and para-aortic lymphadenectomy (n=346) at two tertiary centres in Japan (January, 1986-June, 2004). Patients at intermediate or high risk of recurrence were offered adjuvant radiotherapy or chemotherapy. The primary outcome measure was overall survival.Overall survival was significantly longer in the pelvic and para-aortic lymphadenectomy group than in the pelvic lymphadenectomy group (HR 0.53, 95% CI 0.38-0.76; p=0.0005). This association was also recorded in 407 patients at intermediate or high risk (p=0.0009), but overall survival was not related to lymphadenectomy type in low-risk patients. Multivariate analysis of prognostic factors showed that in patients with intermediate or high risk of recurrence, pelvic and para-aortic lymphadenectomy reduced the risk of death compared with pelvic lymphadenectomy (0.44, 0.30-0.64; p<0.0001). Analysis of 328 patients with intermediate or high risk who were treated with adjuvant radiotherapy or chemotherapy showed that patient survival improved with pelvic and para-aortic lymphadenectomy (0.48, 0.29-0.83; p=0.0049) and with adjuvant chemotherapy (0.59, 0.37-1.00; p=0.0465) independently of one another.Combined pelvic and para-aortic lymphadenectomy is recommended as treatment for patients with endometrial carcinoma of intermediate or high risk of recurrence. If a prospective randomised or comparative cohort study is planned to validate the therapeutic effect of lymphadenectomy, it should include both pelvic and para-aortic lymphadenectomy in patients of intermediate or high risk of recurrence.Japanese Foundation for Multidisciplinary Treatment of Cancer, and the Japan Society for the Promotion of Science.Copyright 2010 Elsevier Ltd. All rights reserved.","Survival effect of para-aortic lymphadenectomy in endometrial cancer (SEPAL study): a retrospective cohort analysis."
"1202","Lancet.277","0.0465",20188410,2010,"In response to findings that pelvic lymphadenectomy does not have any therapeutic benefit for endometrial cancer, we aimed to establish whether complete, systematic lymphadenectomy, including the para-aortic lymph nodes, should be part of surgical therapy for patients at intermediate and high risk of recurrence.We selected 671 patients with endometrial carcinoma who had been treated with complete, systematic pelvic lymphadenectomy (n=325 patients) or combined pelvic and para-aortic lymphadenectomy (n=346) at two tertiary centres in Japan (January, 1986-June, 2004). Patients at intermediate or high risk of recurrence were offered adjuvant radiotherapy or chemotherapy. The primary outcome measure was overall survival.Overall survival was significantly longer in the pelvic and para-aortic lymphadenectomy group than in the pelvic lymphadenectomy group (HR 0.53, 95% CI 0.38-0.76; p=0.0005). This association was also recorded in 407 patients at intermediate or high risk (p=0.0009), but overall survival was not related to lymphadenectomy type in low-risk patients. Multivariate analysis of prognostic factors showed that in patients with intermediate or high risk of recurrence, pelvic and para-aortic lymphadenectomy reduced the risk of death compared with pelvic lymphadenectomy (0.44, 0.30-0.64; p<0.0001). Analysis of 328 patients with intermediate or high risk who were treated with adjuvant radiotherapy or chemotherapy showed that patient survival improved with pelvic and para-aortic lymphadenectomy (0.48, 0.29-0.83; p=0.0049) and with adjuvant chemotherapy (0.59, 0.37-1.00; p=0.0465) independently of one another.Combined pelvic and para-aortic lymphadenectomy is recommended as treatment for patients with endometrial carcinoma of intermediate or high risk of recurrence. If a prospective randomised or comparative cohort study is planned to validate the therapeutic effect of lymphadenectomy, it should include both pelvic and para-aortic lymphadenectomy in patients of intermediate or high risk of recurrence.Japanese Foundation for Multidisciplinary Treatment of Cancer, and the Japan Society for the Promotion of Science.Copyright 2010 Elsevier Ltd. All rights reserved.","Survival effect of para-aortic lymphadenectomy in endometrial cancer (SEPAL study): a retrospective cohort analysis."
"1203","Lancet.272","0.006",20189239,2010,"Stents are an alternative treatment to carotid endarterectomy for symptomatic carotid stenosis, but previous trials have not established equivalent safety and efficacy. We compared the safety of carotid artery stenting with that of carotid endarterectomy.The International Carotid Stenting Study (ICSS) is a multicentre, international, randomised controlled trial with blinded adjudication of outcomes. Patients with recently symptomatic carotid artery stenosis were randomly assigned in a 1:1 ratio to receive carotid artery stenting or carotid endarterectomy. Randomisation was by telephone call or fax to a central computerised service and was stratified by centre with minimisation for sex, age, contralateral occlusion, and side of the randomised artery. Patients and investigators were not masked to treatment assignment. Patients were followed up by independent clinicians not directly involved in delivering the randomised treatment. The primary outcome measure of the trial is the 3-year rate of fatal or disabling stroke in any territory, which has not been analysed yet. The main outcome measure for the interim safety analysis was the 120-day rate of stroke, death, or procedural myocardial infarction. Analysis was by intention to treat (ITT). This study is registered, number ISRCTN25337470.The trial enrolled 1713 patients (stenting group, n=855; endarterectomy group, n=858). Two patients in the stenting group and one in the endarterectomy group withdrew immediately after randomisation, and were not included in the ITT analysis. Between randomisation and 120 days, there were 34 (Kaplan-Meier estimate 4.0%) events of disabling stroke or death in the stenting group compared with 27 (3.2%) events in the endarterectomy group (hazard ratio [HR] 1.28, 95% CI 0.77-2.11). The incidence of stroke, death, or procedural myocardial infarction was 8.5% in the stenting group compared with 5.2% in the endarterectomy group (72 vs 44 events; HR 1.69, 1.16-2.45, p=0.006). Risks of any stroke (65 vs 35 events; HR 1.92, 1.27-2.89) and all-cause death (19 vs seven events; HR 2.76, 1.16-6.56) were higher in the stenting group than in the endarterectomy group. Three procedural myocardial infarctions were recorded in the stenting group, all of which were fatal, compared with four, all non-fatal, in the endarterectomy group. There was one event of cranial nerve palsy in the stenting group compared with 45 in the endarterectomy group. There were also fewer haematomas of any severity in the stenting group than in the endarterectomy group (31 vs 50 events; p=0.0197).Completion of long-term follow-up is needed to establish the efficacy of carotid artery stenting compared with endarterectomy. In the meantime, carotid endarterectomy should remain the treatment of choice for patients suitable for surgery.Medical Research Council, the Stroke Association, Sanofi-Synthlabo, European Union.Copyright 2010 Elsevier Ltd. All rights reserved.","Carotid artery stenting compared with endarterectomy in patients with symptomatic carotid stenosis (International Carotid Stenting Study): an interim analysis of a randomised controlled trial."
"1204","JAMA.5811","0.001",20197531,2010,"Although hospital mortality has decreased over time in the United States for patients who receive intensive care, little is known about subsequent outcomes for those discharged alive.To assess 3-year outcomes for Medicare beneficiaries who survive intensive care.A matched, retrospective cohort study was conducted using a 5% sample of Medicare beneficiaries older than 65 years. A random half of all patients were selected who received intensive care and survived to hospital discharge in 2003 with 3-year follow-up through 2006. From the other half of the sample, 2 matched control groups were generated: hospitalized patients who survived to discharge (hospital controls) and the general population (general controls), individually matched on age, sex, race, and whether they had surgery (for hospital controls).Three-year mortality after hospital discharge.There were 35,308 intensive care unit (ICU) patients who survived to hospital discharge. The ICU survivors had a higher 3-year mortality (39.5%; n = 13,950) than hospital controls (34.5%; n = 12,173) (adjusted hazard ratio [AHR], 1.07 [95% confidence interval {CI}, 1.04-1.10]; P < .001) and general controls (14.9%; n = 5266) (AHR, 2.39 [95% CI, 2.31-2.48]; P < .001). The ICU survivors who did not receive mechanical ventilation had minimal increased risk compared with hospital controls (3-year mortality, 38.3% [n = 12,716] vs 34.6% [n=11,470], respectively; AHR, 1.04 [95% CI, 1.02-1.07]). Those receiving mechanical ventilation had substantially increased mortality (57.6% [1234 ICU survivors] vs 32.8% [703 hospital controls]; AHR, 1.56 [95% CI, 1.40-1.73]), with risk concentrated in the 6 months after the quarter of hospital discharge (6-month mortality, 30.1% (n = 645) for those receiving mechanical ventilation vs 9.6% (n = 206) for hospital controls; AHR, 2.26 [95% CI, 1.90-2.69]). Discharge to a skilled care facility for ICU survivors (33.0%; n = 11,634) and hospital controls (26.4%; n = 9328) also was associated with high 6-month mortality (24.1% for ICU survivors and hospital controls discharged to a skilled care facility vs 7.5% for ICU survivors and hospital controls discharged home; AHR, 2.62 [95% CI, 2.50-2.74]; P < .001 for ICU survivors and hospital controls combined).There is a large US population of elderly individuals who survived the ICU stay to hospital discharge but who have a high mortality over the subsequent years in excess of that seen in comparable controls. The risk is concentrated early after hospital discharge among those who require mechanical ventilation.","Three-year outcomes for Medicare beneficiaries who survive intensive care."
"1205","JAMA.5821","0.001",20197531,2010,"Although hospital mortality has decreased over time in the United States for patients who receive intensive care, little is known about subsequent outcomes for those discharged alive.To assess 3-year outcomes for Medicare beneficiaries who survive intensive care.A matched, retrospective cohort study was conducted using a 5% sample of Medicare beneficiaries older than 65 years. A random half of all patients were selected who received intensive care and survived to hospital discharge in 2003 with 3-year follow-up through 2006. From the other half of the sample, 2 matched control groups were generated: hospitalized patients who survived to discharge (hospital controls) and the general population (general controls), individually matched on age, sex, race, and whether they had surgery (for hospital controls).Three-year mortality after hospital discharge.There were 35,308 intensive care unit (ICU) patients who survived to hospital discharge. The ICU survivors had a higher 3-year mortality (39.5%; n = 13,950) than hospital controls (34.5%; n = 12,173) (adjusted hazard ratio [AHR], 1.07 [95% confidence interval {CI}, 1.04-1.10]; P < .001) and general controls (14.9%; n = 5266) (AHR, 2.39 [95% CI, 2.31-2.48]; P < .001). The ICU survivors who did not receive mechanical ventilation had minimal increased risk compared with hospital controls (3-year mortality, 38.3% [n = 12,716] vs 34.6% [n=11,470], respectively; AHR, 1.04 [95% CI, 1.02-1.07]). Those receiving mechanical ventilation had substantially increased mortality (57.6% [1234 ICU survivors] vs 32.8% [703 hospital controls]; AHR, 1.56 [95% CI, 1.40-1.73]), with risk concentrated in the 6 months after the quarter of hospital discharge (6-month mortality, 30.1% (n = 645) for those receiving mechanical ventilation vs 9.6% (n = 206) for hospital controls; AHR, 2.26 [95% CI, 1.90-2.69]). Discharge to a skilled care facility for ICU survivors (33.0%; n = 11,634) and hospital controls (26.4%; n = 9328) also was associated with high 6-month mortality (24.1% for ICU survivors and hospital controls discharged to a skilled care facility vs 7.5% for ICU survivors and hospital controls discharged home; AHR, 2.62 [95% CI, 2.50-2.74]; P < .001 for ICU survivors and hospital controls combined).There is a large US population of elderly individuals who survived the ICU stay to hospital discharge but who have a high mortality over the subsequent years in excess of that seen in comparable controls. The risk is concentrated early after hospital discharge among those who require mechanical ventilation.","Three-year outcomes for Medicare beneficiaries who survive intensive care."
"1206","JAMA.5831","0.001",20197531,2010,"Although hospital mortality has decreased over time in the United States for patients who receive intensive care, little is known about subsequent outcomes for those discharged alive.To assess 3-year outcomes for Medicare beneficiaries who survive intensive care.A matched, retrospective cohort study was conducted using a 5% sample of Medicare beneficiaries older than 65 years. A random half of all patients were selected who received intensive care and survived to hospital discharge in 2003 with 3-year follow-up through 2006. From the other half of the sample, 2 matched control groups were generated: hospitalized patients who survived to discharge (hospital controls) and the general population (general controls), individually matched on age, sex, race, and whether they had surgery (for hospital controls).Three-year mortality after hospital discharge.There were 35,308 intensive care unit (ICU) patients who survived to hospital discharge. The ICU survivors had a higher 3-year mortality (39.5%; n = 13,950) than hospital controls (34.5%; n = 12,173) (adjusted hazard ratio [AHR], 1.07 [95% confidence interval {CI}, 1.04-1.10]; P < .001) and general controls (14.9%; n = 5266) (AHR, 2.39 [95% CI, 2.31-2.48]; P < .001). The ICU survivors who did not receive mechanical ventilation had minimal increased risk compared with hospital controls (3-year mortality, 38.3% [n = 12,716] vs 34.6% [n=11,470], respectively; AHR, 1.04 [95% CI, 1.02-1.07]). Those receiving mechanical ventilation had substantially increased mortality (57.6% [1234 ICU survivors] vs 32.8% [703 hospital controls]; AHR, 1.56 [95% CI, 1.40-1.73]), with risk concentrated in the 6 months after the quarter of hospital discharge (6-month mortality, 30.1% (n = 645) for those receiving mechanical ventilation vs 9.6% (n = 206) for hospital controls; AHR, 2.26 [95% CI, 1.90-2.69]). Discharge to a skilled care facility for ICU survivors (33.0%; n = 11,634) and hospital controls (26.4%; n = 9328) also was associated with high 6-month mortality (24.1% for ICU survivors and hospital controls discharged to a skilled care facility vs 7.5% for ICU survivors and hospital controls discharged home; AHR, 2.62 [95% CI, 2.50-2.74]; P < .001 for ICU survivors and hospital controls combined).There is a large US population of elderly individuals who survived the ICU stay to hospital discharge but who have a high mortality over the subsequent years in excess of that seen in comparable controls. The risk is concentrated early after hospital discharge among those who require mechanical ventilation.","Three-year outcomes for Medicare beneficiaries who survive intensive care."
"1207","Lancet.268","0.17",20206777,2010,"After surgery for intermediate-risk endometrial carcinoma, the vagina is the most frequent site of recurrence. This study established whether vaginal brachytherapy (VBT) is as effective as pelvic external beam radiotherapy (EBRT) in prevention of vaginal recurrence, with fewer adverse effects and improved quality of life.In this open-label, non-inferiority, randomised trial undertaken in 19 Dutch radiation oncology centres, 427 patients with stage I or IIA endometrial carcinoma with features of high-intermediate risk were randomly assigned by a computer-generated, biased coin minimisation procedure to pelvic EBRT (46 Gy in 23 fractions; n=214) or VBT (21 Gy high-dose rate in three fractions, or 30 Gy low-dose rate; n=213). All investigators were masked to the assignment of treatment group. The primary endpoint was vaginal recurrence. The predefined non-inferiority margin was an absolute difference of 6% in vaginal recurrence. Analysis was by intention to treat, with competing risk methods. The study is registered, number ISRCTN16228756.At median follow-up of 45 months (range 18-78), three vaginal recurrences had been diagnosed after VBT and four after EBRT. Estimated 5-year rates of vaginal recurrence were 1.8% (95% CI 0.6-5.9) for VBT and 1.6% (0.5-4.9) for EBRT (hazard ratio [HR] 0.78, 95% CI 0.17-3.49; p=0.74). 5-year rates of locoregional relapse (vaginal or pelvic recurrence, or both) were 5.1% (2.8-9.6) for VBT and 2.1% (0.8-5.8) for EBRT (HR 2.08, 0.71-6.09; p=0.17). 1.5% (0.5-4.5) versus 0.5% (0.1-3.4) of patients presented with isolated pelvic recurrence (HR 3.10, 0.32-29.9; p=0.30), and rates of distant metastases were similar (8.3% [5.1-13.4] vs 5.7% [3.3-9.9]; HR 1.32, 0.63-2.74; p=0.46). We recorded no differences in overall (84.8% [95% CI 79.3-90.3] vs 79.6% [71.2-88.0]; HR 1.17, 0.69-1.98; p=0.57) or disease-free survival (82.7% [76.9-88.6] vs 78.1% [69.7-86.5]; HR 1.09, 0.66-1.78; p=0.74). Rates of acute grade 1-2 gastrointestinal toxicity were significantly lower in the VBT group than in the EBRT group at completion of radiotherapy (12.6% [27/215] vs 53.8% [112/208]).VBT is effective in ensuring vaginal control, with fewer gastrointestinal toxic effects than with EBRT. VBT should be the adjuvant treatment of choice for patients with endometrial carcinoma of high-intermediate risk.Dutch Cancer Society.Copyright 2010 Elsevier Ltd. All rights reserved.","Vaginal brachytherapy versus pelvic external beam radiotherapy for patients with endometrial cancer of high-intermediate risk (PORTEC-2): an open-label, non-inferiority, randomised trial."
"1208","Lancet.269","0.3",20206777,2010,"After surgery for intermediate-risk endometrial carcinoma, the vagina is the most frequent site of recurrence. This study established whether vaginal brachytherapy (VBT) is as effective as pelvic external beam radiotherapy (EBRT) in prevention of vaginal recurrence, with fewer adverse effects and improved quality of life.In this open-label, non-inferiority, randomised trial undertaken in 19 Dutch radiation oncology centres, 427 patients with stage I or IIA endometrial carcinoma with features of high-intermediate risk were randomly assigned by a computer-generated, biased coin minimisation procedure to pelvic EBRT (46 Gy in 23 fractions; n=214) or VBT (21 Gy high-dose rate in three fractions, or 30 Gy low-dose rate; n=213). All investigators were masked to the assignment of treatment group. The primary endpoint was vaginal recurrence. The predefined non-inferiority margin was an absolute difference of 6% in vaginal recurrence. Analysis was by intention to treat, with competing risk methods. The study is registered, number ISRCTN16228756.At median follow-up of 45 months (range 18-78), three vaginal recurrences had been diagnosed after VBT and four after EBRT. Estimated 5-year rates of vaginal recurrence were 1.8% (95% CI 0.6-5.9) for VBT and 1.6% (0.5-4.9) for EBRT (hazard ratio [HR] 0.78, 95% CI 0.17-3.49; p=0.74). 5-year rates of locoregional relapse (vaginal or pelvic recurrence, or both) were 5.1% (2.8-9.6) for VBT and 2.1% (0.8-5.8) for EBRT (HR 2.08, 0.71-6.09; p=0.17). 1.5% (0.5-4.5) versus 0.5% (0.1-3.4) of patients presented with isolated pelvic recurrence (HR 3.10, 0.32-29.9; p=0.30), and rates of distant metastases were similar (8.3% [5.1-13.4] vs 5.7% [3.3-9.9]; HR 1.32, 0.63-2.74; p=0.46). We recorded no differences in overall (84.8% [95% CI 79.3-90.3] vs 79.6% [71.2-88.0]; HR 1.17, 0.69-1.98; p=0.57) or disease-free survival (82.7% [76.9-88.6] vs 78.1% [69.7-86.5]; HR 1.09, 0.66-1.78; p=0.74). Rates of acute grade 1-2 gastrointestinal toxicity were significantly lower in the VBT group than in the EBRT group at completion of radiotherapy (12.6% [27/215] vs 53.8% [112/208]).VBT is effective in ensuring vaginal control, with fewer gastrointestinal toxic effects than with EBRT. VBT should be the adjuvant treatment of choice for patients with endometrial carcinoma of high-intermediate risk.Dutch Cancer Society.Copyright 2010 Elsevier Ltd. All rights reserved.","Vaginal brachytherapy versus pelvic external beam radiotherapy for patients with endometrial cancer of high-intermediate risk (PORTEC-2): an open-label, non-inferiority, randomised trial."
"1209","Lancet.270","0.46",20206777,2010,"After surgery for intermediate-risk endometrial carcinoma, the vagina is the most frequent site of recurrence. This study established whether vaginal brachytherapy (VBT) is as effective as pelvic external beam radiotherapy (EBRT) in prevention of vaginal recurrence, with fewer adverse effects and improved quality of life.In this open-label, non-inferiority, randomised trial undertaken in 19 Dutch radiation oncology centres, 427 patients with stage I or IIA endometrial carcinoma with features of high-intermediate risk were randomly assigned by a computer-generated, biased coin minimisation procedure to pelvic EBRT (46 Gy in 23 fractions; n=214) or VBT (21 Gy high-dose rate in three fractions, or 30 Gy low-dose rate; n=213). All investigators were masked to the assignment of treatment group. The primary endpoint was vaginal recurrence. The predefined non-inferiority margin was an absolute difference of 6% in vaginal recurrence. Analysis was by intention to treat, with competing risk methods. The study is registered, number ISRCTN16228756.At median follow-up of 45 months (range 18-78), three vaginal recurrences had been diagnosed after VBT and four after EBRT. Estimated 5-year rates of vaginal recurrence were 1.8% (95% CI 0.6-5.9) for VBT and 1.6% (0.5-4.9) for EBRT (hazard ratio [HR] 0.78, 95% CI 0.17-3.49; p=0.74). 5-year rates of locoregional relapse (vaginal or pelvic recurrence, or both) were 5.1% (2.8-9.6) for VBT and 2.1% (0.8-5.8) for EBRT (HR 2.08, 0.71-6.09; p=0.17). 1.5% (0.5-4.5) versus 0.5% (0.1-3.4) of patients presented with isolated pelvic recurrence (HR 3.10, 0.32-29.9; p=0.30), and rates of distant metastases were similar (8.3% [5.1-13.4] vs 5.7% [3.3-9.9]; HR 1.32, 0.63-2.74; p=0.46). We recorded no differences in overall (84.8% [95% CI 79.3-90.3] vs 79.6% [71.2-88.0]; HR 1.17, 0.69-1.98; p=0.57) or disease-free survival (82.7% [76.9-88.6] vs 78.1% [69.7-86.5]; HR 1.09, 0.66-1.78; p=0.74). Rates of acute grade 1-2 gastrointestinal toxicity were significantly lower in the VBT group than in the EBRT group at completion of radiotherapy (12.6% [27/215] vs 53.8% [112/208]).VBT is effective in ensuring vaginal control, with fewer gastrointestinal toxic effects than with EBRT. VBT should be the adjuvant treatment of choice for patients with endometrial carcinoma of high-intermediate risk.Dutch Cancer Society.Copyright 2010 Elsevier Ltd. All rights reserved.","Vaginal brachytherapy versus pelvic external beam radiotherapy for patients with endometrial cancer of high-intermediate risk (PORTEC-2): an open-label, non-inferiority, randomised trial."
"1210","Lancet.269","0.74",20206777,2010,"After surgery for intermediate-risk endometrial carcinoma, the vagina is the most frequent site of recurrence. This study established whether vaginal brachytherapy (VBT) is as effective as pelvic external beam radiotherapy (EBRT) in prevention of vaginal recurrence, with fewer adverse effects and improved quality of life.In this open-label, non-inferiority, randomised trial undertaken in 19 Dutch radiation oncology centres, 427 patients with stage I or IIA endometrial carcinoma with features of high-intermediate risk were randomly assigned by a computer-generated, biased coin minimisation procedure to pelvic EBRT (46 Gy in 23 fractions; n=214) or VBT (21 Gy high-dose rate in three fractions, or 30 Gy low-dose rate; n=213). All investigators were masked to the assignment of treatment group. The primary endpoint was vaginal recurrence. The predefined non-inferiority margin was an absolute difference of 6% in vaginal recurrence. Analysis was by intention to treat, with competing risk methods. The study is registered, number ISRCTN16228756.At median follow-up of 45 months (range 18-78), three vaginal recurrences had been diagnosed after VBT and four after EBRT. Estimated 5-year rates of vaginal recurrence were 1.8% (95% CI 0.6-5.9) for VBT and 1.6% (0.5-4.9) for EBRT (hazard ratio [HR] 0.78, 95% CI 0.17-3.49; p=0.74). 5-year rates of locoregional relapse (vaginal or pelvic recurrence, or both) were 5.1% (2.8-9.6) for VBT and 2.1% (0.8-5.8) for EBRT (HR 2.08, 0.71-6.09; p=0.17). 1.5% (0.5-4.5) versus 0.5% (0.1-3.4) of patients presented with isolated pelvic recurrence (HR 3.10, 0.32-29.9; p=0.30), and rates of distant metastases were similar (8.3% [5.1-13.4] vs 5.7% [3.3-9.9]; HR 1.32, 0.63-2.74; p=0.46). We recorded no differences in overall (84.8% [95% CI 79.3-90.3] vs 79.6% [71.2-88.0]; HR 1.17, 0.69-1.98; p=0.57) or disease-free survival (82.7% [76.9-88.6] vs 78.1% [69.7-86.5]; HR 1.09, 0.66-1.78; p=0.74). Rates of acute grade 1-2 gastrointestinal toxicity were significantly lower in the VBT group than in the EBRT group at completion of radiotherapy (12.6% [27/215] vs 53.8% [112/208]).VBT is effective in ensuring vaginal control, with fewer gastrointestinal toxic effects than with EBRT. VBT should be the adjuvant treatment of choice for patients with endometrial carcinoma of high-intermediate risk.Dutch Cancer Society.Copyright 2010 Elsevier Ltd. All rights reserved.","Vaginal brachytherapy versus pelvic external beam radiotherapy for patients with endometrial cancer of high-intermediate risk (PORTEC-2): an open-label, non-inferiority, randomised trial."
"1211","Lancet.270","0.57",20206777,2010,"After surgery for intermediate-risk endometrial carcinoma, the vagina is the most frequent site of recurrence. This study established whether vaginal brachytherapy (VBT) is as effective as pelvic external beam radiotherapy (EBRT) in prevention of vaginal recurrence, with fewer adverse effects and improved quality of life.In this open-label, non-inferiority, randomised trial undertaken in 19 Dutch radiation oncology centres, 427 patients with stage I or IIA endometrial carcinoma with features of high-intermediate risk were randomly assigned by a computer-generated, biased coin minimisation procedure to pelvic EBRT (46 Gy in 23 fractions; n=214) or VBT (21 Gy high-dose rate in three fractions, or 30 Gy low-dose rate; n=213). All investigators were masked to the assignment of treatment group. The primary endpoint was vaginal recurrence. The predefined non-inferiority margin was an absolute difference of 6% in vaginal recurrence. Analysis was by intention to treat, with competing risk methods. The study is registered, number ISRCTN16228756.At median follow-up of 45 months (range 18-78), three vaginal recurrences had been diagnosed after VBT and four after EBRT. Estimated 5-year rates of vaginal recurrence were 1.8% (95% CI 0.6-5.9) for VBT and 1.6% (0.5-4.9) for EBRT (hazard ratio [HR] 0.78, 95% CI 0.17-3.49; p=0.74). 5-year rates of locoregional relapse (vaginal or pelvic recurrence, or both) were 5.1% (2.8-9.6) for VBT and 2.1% (0.8-5.8) for EBRT (HR 2.08, 0.71-6.09; p=0.17). 1.5% (0.5-4.5) versus 0.5% (0.1-3.4) of patients presented with isolated pelvic recurrence (HR 3.10, 0.32-29.9; p=0.30), and rates of distant metastases were similar (8.3% [5.1-13.4] vs 5.7% [3.3-9.9]; HR 1.32, 0.63-2.74; p=0.46). We recorded no differences in overall (84.8% [95% CI 79.3-90.3] vs 79.6% [71.2-88.0]; HR 1.17, 0.69-1.98; p=0.57) or disease-free survival (82.7% [76.9-88.6] vs 78.1% [69.7-86.5]; HR 1.09, 0.66-1.78; p=0.74). Rates of acute grade 1-2 gastrointestinal toxicity were significantly lower in the VBT group than in the EBRT group at completion of radiotherapy (12.6% [27/215] vs 53.8% [112/208]).VBT is effective in ensuring vaginal control, with fewer gastrointestinal toxic effects than with EBRT. VBT should be the adjuvant treatment of choice for patients with endometrial carcinoma of high-intermediate risk.Dutch Cancer Society.Copyright 2010 Elsevier Ltd. All rights reserved.","Vaginal brachytherapy versus pelvic external beam radiotherapy for patients with endometrial cancer of high-intermediate risk (PORTEC-2): an open-label, non-inferiority, randomised trial."
"1212","Lancet.244","1.00E-04",20226988,2010,"The mechanisms by which hypertension causes vascular events are unclear. Guidelines for diagnosis and treatment focus only on underlying mean blood pressure. We aimed to reliably establish the prognostic significance of visit-to-visit variability in blood pressure, maximum blood pressure reached, untreated episodic hypertension, and residual variability in treated patients.We determined the risk of stroke in relation to visit-to-visit variability in blood pressure (expressed as standard deviation [SD] and parameters independent of mean blood pressure) and maximum blood pressure in patients with previous transient ischaemic attack (TIA; UK-TIA trial and three validation cohorts) and in patients with treated hypertension (Anglo-Scandinavian Cardiac Outcomes Trial Blood Pressure Lowering Arm [ASCOT-BPLA]). In ASCOT-BPLA, 24-h ambulatory blood-pressure monitoring (ABPM) was also studied.In each TIA cohort, visit-to-visit variability in systolic blood pressure (SBP) was a strong predictor of subsequent stroke (eg, top-decile hazard ratio [HR] for SD SBP over seven visits in UK-TIA trial: 6.22, 95% CI 4.16-9.29, p<0.0001), independent of mean SBP, but dependent on precision of measurement (top-decile HR over ten visits: 12.08, 7.40-19.72, p<0.0001). Maximum SBP reached was also a strong predictor of stroke (HR for top-decile over seven visits: 15.01, 6.56-34.38, p<0.0001, after adjustment for mean SBP). In ASCOT-BPLA, residual visit-to-visit variability in SBP on treatment was also a strong predictor of stroke and coronary events (eg, top-decile HR for stroke: 3.25, 2.32-4.54, p<0.0001), independent of mean SBP in clinic or on ABPM. Variability on ABPM was a weaker predictor, but all measures of variability were most predictive in younger patients and at lower (<median) values of mean SBP in every cohort.Visit-to-visit variability in SBP and maximum SBP are strong predictors of stroke, independent of mean SBP. Increased residual variability in SBP in patients with treated hypertension is associated with a high risk of vascular events.None.Copyright 2010 Elsevier Ltd. All rights reserved.","Prognostic significance of visit-to-visit variability, maximum systolic blood pressure, and episodic hypertension."
"1213","Lancet.245","1.00E-04",20226988,2010,"The mechanisms by which hypertension causes vascular events are unclear. Guidelines for diagnosis and treatment focus only on underlying mean blood pressure. We aimed to reliably establish the prognostic significance of visit-to-visit variability in blood pressure, maximum blood pressure reached, untreated episodic hypertension, and residual variability in treated patients.We determined the risk of stroke in relation to visit-to-visit variability in blood pressure (expressed as standard deviation [SD] and parameters independent of mean blood pressure) and maximum blood pressure in patients with previous transient ischaemic attack (TIA; UK-TIA trial and three validation cohorts) and in patients with treated hypertension (Anglo-Scandinavian Cardiac Outcomes Trial Blood Pressure Lowering Arm [ASCOT-BPLA]). In ASCOT-BPLA, 24-h ambulatory blood-pressure monitoring (ABPM) was also studied.In each TIA cohort, visit-to-visit variability in systolic blood pressure (SBP) was a strong predictor of subsequent stroke (eg, top-decile hazard ratio [HR] for SD SBP over seven visits in UK-TIA trial: 6.22, 95% CI 4.16-9.29, p<0.0001), independent of mean SBP, but dependent on precision of measurement (top-decile HR over ten visits: 12.08, 7.40-19.72, p<0.0001). Maximum SBP reached was also a strong predictor of stroke (HR for top-decile over seven visits: 15.01, 6.56-34.38, p<0.0001, after adjustment for mean SBP). In ASCOT-BPLA, residual visit-to-visit variability in SBP on treatment was also a strong predictor of stroke and coronary events (eg, top-decile HR for stroke: 3.25, 2.32-4.54, p<0.0001), independent of mean SBP in clinic or on ABPM. Variability on ABPM was a weaker predictor, but all measures of variability were most predictive in younger patients and at lower (<median) values of mean SBP in every cohort.Visit-to-visit variability in SBP and maximum SBP are strong predictors of stroke, independent of mean SBP. Increased residual variability in SBP in patients with treated hypertension is associated with a high risk of vascular events.None.Copyright 2010 Elsevier Ltd. All rights reserved.","Prognostic significance of visit-to-visit variability, maximum systolic blood pressure, and episodic hypertension."
"1214","Lancet.246","1.00E-04",20226988,2010,"The mechanisms by which hypertension causes vascular events are unclear. Guidelines for diagnosis and treatment focus only on underlying mean blood pressure. We aimed to reliably establish the prognostic significance of visit-to-visit variability in blood pressure, maximum blood pressure reached, untreated episodic hypertension, and residual variability in treated patients.We determined the risk of stroke in relation to visit-to-visit variability in blood pressure (expressed as standard deviation [SD] and parameters independent of mean blood pressure) and maximum blood pressure in patients with previous transient ischaemic attack (TIA; UK-TIA trial and three validation cohorts) and in patients with treated hypertension (Anglo-Scandinavian Cardiac Outcomes Trial Blood Pressure Lowering Arm [ASCOT-BPLA]). In ASCOT-BPLA, 24-h ambulatory blood-pressure monitoring (ABPM) was also studied.In each TIA cohort, visit-to-visit variability in systolic blood pressure (SBP) was a strong predictor of subsequent stroke (eg, top-decile hazard ratio [HR] for SD SBP over seven visits in UK-TIA trial: 6.22, 95% CI 4.16-9.29, p<0.0001), independent of mean SBP, but dependent on precision of measurement (top-decile HR over ten visits: 12.08, 7.40-19.72, p<0.0001). Maximum SBP reached was also a strong predictor of stroke (HR for top-decile over seven visits: 15.01, 6.56-34.38, p<0.0001, after adjustment for mean SBP). In ASCOT-BPLA, residual visit-to-visit variability in SBP on treatment was also a strong predictor of stroke and coronary events (eg, top-decile HR for stroke: 3.25, 2.32-4.54, p<0.0001), independent of mean SBP in clinic or on ABPM. Variability on ABPM was a weaker predictor, but all measures of variability were most predictive in younger patients and at lower (<median) values of mean SBP in every cohort.Visit-to-visit variability in SBP and maximum SBP are strong predictors of stroke, independent of mean SBP. Increased residual variability in SBP in patients with treated hypertension is associated with a high risk of vascular events.None.Copyright 2010 Elsevier Ltd. All rights reserved.","Prognostic significance of visit-to-visit variability, maximum systolic blood pressure, and episodic hypertension."
"1215","Lancet.247","1.00E-04",20226988,2010,"The mechanisms by which hypertension causes vascular events are unclear. Guidelines for diagnosis and treatment focus only on underlying mean blood pressure. We aimed to reliably establish the prognostic significance of visit-to-visit variability in blood pressure, maximum blood pressure reached, untreated episodic hypertension, and residual variability in treated patients.We determined the risk of stroke in relation to visit-to-visit variability in blood pressure (expressed as standard deviation [SD] and parameters independent of mean blood pressure) and maximum blood pressure in patients with previous transient ischaemic attack (TIA; UK-TIA trial and three validation cohorts) and in patients with treated hypertension (Anglo-Scandinavian Cardiac Outcomes Trial Blood Pressure Lowering Arm [ASCOT-BPLA]). In ASCOT-BPLA, 24-h ambulatory blood-pressure monitoring (ABPM) was also studied.In each TIA cohort, visit-to-visit variability in systolic blood pressure (SBP) was a strong predictor of subsequent stroke (eg, top-decile hazard ratio [HR] for SD SBP over seven visits in UK-TIA trial: 6.22, 95% CI 4.16-9.29, p<0.0001), independent of mean SBP, but dependent on precision of measurement (top-decile HR over ten visits: 12.08, 7.40-19.72, p<0.0001). Maximum SBP reached was also a strong predictor of stroke (HR for top-decile over seven visits: 15.01, 6.56-34.38, p<0.0001, after adjustment for mean SBP). In ASCOT-BPLA, residual visit-to-visit variability in SBP on treatment was also a strong predictor of stroke and coronary events (eg, top-decile HR for stroke: 3.25, 2.32-4.54, p<0.0001), independent of mean SBP in clinic or on ABPM. Variability on ABPM was a weaker predictor, but all measures of variability were most predictive in younger patients and at lower (<median) values of mean SBP in every cohort.Visit-to-visit variability in SBP and maximum SBP are strong predictors of stroke, independent of mean SBP. Increased residual variability in SBP in patients with treated hypertension is associated with a high risk of vascular events.None.Copyright 2010 Elsevier Ltd. All rights reserved.","Prognostic significance of visit-to-visit variability, maximum systolic blood pressure, and episodic hypertension."
"1216","Lancet.243","1.00E-04",20231034,2010,"In low-risk patients, the zotarolimus-eluting stent has been shown to reduce rates of restenosis without increasing the risk of stent thrombosis. We compared the efficacy and safety of the zotarolimus-eluting stent versus the sirolimus-eluting stent in patients with coronary artery disease who were receiving routine clinical care with no direct follow-up.We did a single-blind, all-comer superiority trial in adult patients with chronic stable coronary artery disease or acute coronary syndromes, and at least one target lesion. Patients were treated at one of five percutaneous coronary intervention centres between January, 2006, and August, 2007. Computer-generated block randomisation and a telephone allocation service were used to randomly assign patients to receive the zotarolimus-eluting or the sirolimus-eluting stent. Data for follow-up were obtained from national Danish administrative and health-care registries. The primary endpoint was a composite of major adverse cardiac events within 9 months: cardiac death, myocardial infarction, and target vessel revascularisation. Intention-to-treat analyses were done at 9-month and 18-month follow-up. This trial is registered with ClinicalTrials.gov, number NCT00660478.1162 patients (1619 lesions) were assigned to receive the zotarolimus-eluting stent, and 1170 patients (1611 lesions) to receive the sirolimus-eluting stent. 67 patients (72 lesions) had stent failure, and six patients were lost to follow-up. All randomly assigned patients were included in analyses at 9-month follow-up; 2200 patients (94%) had completed 18-month follow-up by the time of our assessment. At 9 months, the primary endpoint had occurred in a higher proportion of patients treated with the zotarolimus-eluting stent than in those treated with the sirolimus-eluting stent (72 [6%] vs 34 [3%]; HR 2.15, 95% CI 1.43-3.23; p=0.0002). At 18-month follow-up, this difference was sustained (113 [10%] vs 53 [5%]; 2.19, 1.58-3.04; p<0.0001). For patients receiving the zotarolimus-eluting stent and those receiving the sirolimus-eluting stent, all cause-mortality was similar at 9-month follow-up (25 [2%] vs 18 [2%]; 1.40, 0.76-2.56; p=0.28), but was significantly different at 18-month follow-up (51 [4%] vs 32 [3%]; 1.61, 1.03-2.50; p=0.035).The sirolimus-eluting stent is superior to the zotarolimus-eluting stent for patients receiving routine clinical care.Cordis and Medtronic.Copyright 2010 Elsevier Ltd. All rights reserved.","Efficacy and safety of zotarolimus-eluting and sirolimus-eluting coronary stents in routine clinical care (SORT OUT III): a randomised controlled superiority trial."
"1217","Lancet.265","2.00E-04",20231034,2010,"In low-risk patients, the zotarolimus-eluting stent has been shown to reduce rates of restenosis without increasing the risk of stent thrombosis. We compared the efficacy and safety of the zotarolimus-eluting stent versus the sirolimus-eluting stent in patients with coronary artery disease who were receiving routine clinical care with no direct follow-up.We did a single-blind, all-comer superiority trial in adult patients with chronic stable coronary artery disease or acute coronary syndromes, and at least one target lesion. Patients were treated at one of five percutaneous coronary intervention centres between January, 2006, and August, 2007. Computer-generated block randomisation and a telephone allocation service were used to randomly assign patients to receive the zotarolimus-eluting or the sirolimus-eluting stent. Data for follow-up were obtained from national Danish administrative and health-care registries. The primary endpoint was a composite of major adverse cardiac events within 9 months: cardiac death, myocardial infarction, and target vessel revascularisation. Intention-to-treat analyses were done at 9-month and 18-month follow-up. This trial is registered with ClinicalTrials.gov, number NCT00660478.1162 patients (1619 lesions) were assigned to receive the zotarolimus-eluting stent, and 1170 patients (1611 lesions) to receive the sirolimus-eluting stent. 67 patients (72 lesions) had stent failure, and six patients were lost to follow-up. All randomly assigned patients were included in analyses at 9-month follow-up; 2200 patients (94%) had completed 18-month follow-up by the time of our assessment. At 9 months, the primary endpoint had occurred in a higher proportion of patients treated with the zotarolimus-eluting stent than in those treated with the sirolimus-eluting stent (72 [6%] vs 34 [3%]; HR 2.15, 95% CI 1.43-3.23; p=0.0002). At 18-month follow-up, this difference was sustained (113 [10%] vs 53 [5%]; 2.19, 1.58-3.04; p<0.0001). For patients receiving the zotarolimus-eluting stent and those receiving the sirolimus-eluting stent, all cause-mortality was similar at 9-month follow-up (25 [2%] vs 18 [2%]; 1.40, 0.76-2.56; p=0.28), but was significantly different at 18-month follow-up (51 [4%] vs 32 [3%]; 1.61, 1.03-2.50; p=0.035).The sirolimus-eluting stent is superior to the zotarolimus-eluting stent for patients receiving routine clinical care.Cordis and Medtronic.Copyright 2010 Elsevier Ltd. All rights reserved.","Efficacy and safety of zotarolimus-eluting and sirolimus-eluting coronary stents in routine clinical care (SORT OUT III): a randomised controlled superiority trial."
"1218","Lancet.266","0.28",20231034,2010,"In low-risk patients, the zotarolimus-eluting stent has been shown to reduce rates of restenosis without increasing the risk of stent thrombosis. We compared the efficacy and safety of the zotarolimus-eluting stent versus the sirolimus-eluting stent in patients with coronary artery disease who were receiving routine clinical care with no direct follow-up.We did a single-blind, all-comer superiority trial in adult patients with chronic stable coronary artery disease or acute coronary syndromes, and at least one target lesion. Patients were treated at one of five percutaneous coronary intervention centres between January, 2006, and August, 2007. Computer-generated block randomisation and a telephone allocation service were used to randomly assign patients to receive the zotarolimus-eluting or the sirolimus-eluting stent. Data for follow-up were obtained from national Danish administrative and health-care registries. The primary endpoint was a composite of major adverse cardiac events within 9 months: cardiac death, myocardial infarction, and target vessel revascularisation. Intention-to-treat analyses were done at 9-month and 18-month follow-up. This trial is registered with ClinicalTrials.gov, number NCT00660478.1162 patients (1619 lesions) were assigned to receive the zotarolimus-eluting stent, and 1170 patients (1611 lesions) to receive the sirolimus-eluting stent. 67 patients (72 lesions) had stent failure, and six patients were lost to follow-up. All randomly assigned patients were included in analyses at 9-month follow-up; 2200 patients (94%) had completed 18-month follow-up by the time of our assessment. At 9 months, the primary endpoint had occurred in a higher proportion of patients treated with the zotarolimus-eluting stent than in those treated with the sirolimus-eluting stent (72 [6%] vs 34 [3%]; HR 2.15, 95% CI 1.43-3.23; p=0.0002). At 18-month follow-up, this difference was sustained (113 [10%] vs 53 [5%]; 2.19, 1.58-3.04; p<0.0001). For patients receiving the zotarolimus-eluting stent and those receiving the sirolimus-eluting stent, all cause-mortality was similar at 9-month follow-up (25 [2%] vs 18 [2%]; 1.40, 0.76-2.56; p=0.28), but was significantly different at 18-month follow-up (51 [4%] vs 32 [3%]; 1.61, 1.03-2.50; p=0.035).The sirolimus-eluting stent is superior to the zotarolimus-eluting stent for patients receiving routine clinical care.Cordis and Medtronic.Copyright 2010 Elsevier Ltd. All rights reserved.","Efficacy and safety of zotarolimus-eluting and sirolimus-eluting coronary stents in routine clinical care (SORT OUT III): a randomised controlled superiority trial."
"1219","Lancet.267","0.035",20231034,2010,"In low-risk patients, the zotarolimus-eluting stent has been shown to reduce rates of restenosis without increasing the risk of stent thrombosis. We compared the efficacy and safety of the zotarolimus-eluting stent versus the sirolimus-eluting stent in patients with coronary artery disease who were receiving routine clinical care with no direct follow-up.We did a single-blind, all-comer superiority trial in adult patients with chronic stable coronary artery disease or acute coronary syndromes, and at least one target lesion. Patients were treated at one of five percutaneous coronary intervention centres between January, 2006, and August, 2007. Computer-generated block randomisation and a telephone allocation service were used to randomly assign patients to receive the zotarolimus-eluting or the sirolimus-eluting stent. Data for follow-up were obtained from national Danish administrative and health-care registries. The primary endpoint was a composite of major adverse cardiac events within 9 months: cardiac death, myocardial infarction, and target vessel revascularisation. Intention-to-treat analyses were done at 9-month and 18-month follow-up. This trial is registered with ClinicalTrials.gov, number NCT00660478.1162 patients (1619 lesions) were assigned to receive the zotarolimus-eluting stent, and 1170 patients (1611 lesions) to receive the sirolimus-eluting stent. 67 patients (72 lesions) had stent failure, and six patients were lost to follow-up. All randomly assigned patients were included in analyses at 9-month follow-up; 2200 patients (94%) had completed 18-month follow-up by the time of our assessment. At 9 months, the primary endpoint had occurred in a higher proportion of patients treated with the zotarolimus-eluting stent than in those treated with the sirolimus-eluting stent (72 [6%] vs 34 [3%]; HR 2.15, 95% CI 1.43-3.23; p=0.0002). At 18-month follow-up, this difference was sustained (113 [10%] vs 53 [5%]; 2.19, 1.58-3.04; p<0.0001). For patients receiving the zotarolimus-eluting stent and those receiving the sirolimus-eluting stent, all cause-mortality was similar at 9-month follow-up (25 [2%] vs 18 [2%]; 1.40, 0.76-2.56; p=0.28), but was significantly different at 18-month follow-up (51 [4%] vs 32 [3%]; 1.61, 1.03-2.50; p=0.035).The sirolimus-eluting stent is superior to the zotarolimus-eluting stent for patients receiving routine clinical care.Cordis and Medtronic.Copyright 2010 Elsevier Ltd. All rights reserved.","Efficacy and safety of zotarolimus-eluting and sirolimus-eluting coronary stents in routine clinical care (SORT OUT III): a randomised controlled superiority trial."
"1220","American Journal of Epidemiology.105","0.001",20332145,2010,"Diethylstilbestrol (DES) is an estrogenic endocrine disruptor with long-term health effects, possibly including depression, following exposure in utero. Understanding the relation between in utero DES exposure and depression will provide insight to the potential adverse effects of bisphenol A, a functionally similar and ubiquitous endocrine disruptor. The association between in utero DES exposure and depression was assessed among participants in the Nurses' Health Study II who first reported their history of antidepressant use in 1993 and lifetime history of depressive symptoms in 2001. DES exposure was reported by 1,612 (2.2%) women. A history of depression at baseline was higher among women exposed to DES in utero compared with those not exposed (age-adjusted odds ratio (OR) = 1.47, 95% confidence interval (CI): 1.26, 1.72) (P < 0.001). Incident depression (first use of antidepressants among women who also reported depressive symptoms) during follow-up (1995-2005) was reported by 19.7% of women exposed to DES and 15.9% unexposed (age-adjusted OR = 1.41, 95% CI: 1.22, 1.63) (P < 0.001). Adjustment for risk factors of depression and correlates of DES exposure moderately attenuated the association (multivariable-adjusted OR = 1.30, 95% CI: 1.13, 1.51) (P = 0.0004). These results suggest that the neurophysiologic effects of in utero exposure to DES could lead to an increased risk of depression in adult life. Further research should assess whether in utero exposure to bisphenol A has similar adverse effects.","Diethylstilbestrol exposure in utero and depression in women."
"1221","American Journal of Epidemiology.106","0.001",20332145,2010,"Diethylstilbestrol (DES) is an estrogenic endocrine disruptor with long-term health effects, possibly including depression, following exposure in utero. Understanding the relation between in utero DES exposure and depression will provide insight to the potential adverse effects of bisphenol A, a functionally similar and ubiquitous endocrine disruptor. The association between in utero DES exposure and depression was assessed among participants in the Nurses' Health Study II who first reported their history of antidepressant use in 1993 and lifetime history of depressive symptoms in 2001. DES exposure was reported by 1,612 (2.2%) women. A history of depression at baseline was higher among women exposed to DES in utero compared with those not exposed (age-adjusted odds ratio (OR) = 1.47, 95% confidence interval (CI): 1.26, 1.72) (P < 0.001). Incident depression (first use of antidepressants among women who also reported depressive symptoms) during follow-up (1995-2005) was reported by 19.7% of women exposed to DES and 15.9% unexposed (age-adjusted OR = 1.41, 95% CI: 1.22, 1.63) (P < 0.001). Adjustment for risk factors of depression and correlates of DES exposure moderately attenuated the association (multivariable-adjusted OR = 1.30, 95% CI: 1.13, 1.51) (P = 0.0004). These results suggest that the neurophysiologic effects of in utero exposure to DES could lead to an increased risk of depression in adult life. Further research should assess whether in utero exposure to bisphenol A has similar adverse effects.","Diethylstilbestrol exposure in utero and depression in women."
"1222","American Journal of Epidemiology.119","4.00E-04",20332145,2010,"Diethylstilbestrol (DES) is an estrogenic endocrine disruptor with long-term health effects, possibly including depression, following exposure in utero. Understanding the relation between in utero DES exposure and depression will provide insight to the potential adverse effects of bisphenol A, a functionally similar and ubiquitous endocrine disruptor. The association between in utero DES exposure and depression was assessed among participants in the Nurses' Health Study II who first reported their history of antidepressant use in 1993 and lifetime history of depressive symptoms in 2001. DES exposure was reported by 1,612 (2.2%) women. A history of depression at baseline was higher among women exposed to DES in utero compared with those not exposed (age-adjusted odds ratio (OR) = 1.47, 95% confidence interval (CI): 1.26, 1.72) (P < 0.001). Incident depression (first use of antidepressants among women who also reported depressive symptoms) during follow-up (1995-2005) was reported by 19.7% of women exposed to DES and 15.9% unexposed (age-adjusted OR = 1.41, 95% CI: 1.22, 1.63) (P < 0.001). Adjustment for risk factors of depression and correlates of DES exposure moderately attenuated the association (multivariable-adjusted OR = 1.30, 95% CI: 1.13, 1.51) (P = 0.0004). These results suggest that the neurophysiologic effects of in utero exposure to DES could lead to an increased risk of depression in adult life. Further research should assess whether in utero exposure to bisphenol A has similar adverse effects.","Diethylstilbestrol exposure in utero and depression in women."
"1223","Lancet.242","1.00E-04",20338627,2010,"Many randomised controlled trials have investigated the effect of adjuvant chemotherapy in operable non-small-cell lung cancer. We undertook two comprehensive systematic reviews and meta-analyses to establish the effects of adding adjuvant chemotherapy to surgery, or to surgery plus radiotherapy.We included randomised trials, not confounded by additional therapeutic differences between the two groups and that started randomisation on or after Jan 1, 1965, which compared surgery plus adjuvant chemotherapy versus surgery alone, or surgery plus adjuvant radiotherapy and chemotherapy versus surgery plus adjuvant radiotherapy. Updated individual patient data were collected, checked, and included in meta-analyses stratified by trial. The primary endpoint was overall survival, defined as time from randomisation until death by any cause. All analyses were by intention to treat.The first meta-analysis of surgery plus chemotherapy versus surgery alone was based on 34 trial comparisons and 8447 patients (3323 deaths). We recorded a benefit of adding chemotherapy after surgery (hazard ratio [HR] 0.86, 95% CI 0.81-0.92, p<0.0001), with an absolute increase in survival of 4% (95% CI 3-6) at 5 years (from 60% to 64%). The second meta-analysis of surgery plus radiotherapy and chemotherapy versus surgery plus radiotherapy was based on 13 trial comparisons and 2660 patients (1909 deaths). We recorded a benefit of adding chemotherapy to surgery plus radiotherapy (HR 0.88, 95% CI 0.81-0.97, p=0.009), representing an absolute improvement in survival of 4% (95% CI 1-8) at 5 years (from 29% to 33%). In both meta-analyses we noted little variation in effect according to the type of chemotherapy, other trial characteristics, or patient subgroup.The addition of adjuvant chemotherapy after surgery for patients with operable non-small-cell lung cancer improves survival, irrespective of whether chemotherapy was adjuvant to surgery alone or adjuvant to surgery plus radiotherapy.UK Medical Research Council, Institut Gustave-Roussy, Programme Hospitalier de Recherche Clinique (AOM 05 209), Ligue Nationale Contre le Cancer, and Sanofi-Aventis.Copyright 2010 Elsevier Ltd. All rights reserved.","Adjuvant chemotherapy, with or without postoperative radiotherapy, in operable non-small-cell lung cancer: two meta-analyses of individual patient data."
"1224","Lancet.264","0.009",20338627,2010,"Many randomised controlled trials have investigated the effect of adjuvant chemotherapy in operable non-small-cell lung cancer. We undertook two comprehensive systematic reviews and meta-analyses to establish the effects of adding adjuvant chemotherapy to surgery, or to surgery plus radiotherapy.We included randomised trials, not confounded by additional therapeutic differences between the two groups and that started randomisation on or after Jan 1, 1965, which compared surgery plus adjuvant chemotherapy versus surgery alone, or surgery plus adjuvant radiotherapy and chemotherapy versus surgery plus adjuvant radiotherapy. Updated individual patient data were collected, checked, and included in meta-analyses stratified by trial. The primary endpoint was overall survival, defined as time from randomisation until death by any cause. All analyses were by intention to treat.The first meta-analysis of surgery plus chemotherapy versus surgery alone was based on 34 trial comparisons and 8447 patients (3323 deaths). We recorded a benefit of adding chemotherapy after surgery (hazard ratio [HR] 0.86, 95% CI 0.81-0.92, p<0.0001), with an absolute increase in survival of 4% (95% CI 3-6) at 5 years (from 60% to 64%). The second meta-analysis of surgery plus radiotherapy and chemotherapy versus surgery plus radiotherapy was based on 13 trial comparisons and 2660 patients (1909 deaths). We recorded a benefit of adding chemotherapy to surgery plus radiotherapy (HR 0.88, 95% CI 0.81-0.97, p=0.009), representing an absolute improvement in survival of 4% (95% CI 1-8) at 5 years (from 29% to 33%). In both meta-analyses we noted little variation in effect according to the type of chemotherapy, other trial characteristics, or patient subgroup.The addition of adjuvant chemotherapy after surgery for patients with operable non-small-cell lung cancer improves survival, irrespective of whether chemotherapy was adjuvant to surgery alone or adjuvant to surgery plus radiotherapy.UK Medical Research Council, Institut Gustave-Roussy, Programme Hospitalier de Recherche Clinique (AOM 05 209), Ligue Nationale Contre le Cancer, and Sanofi-Aventis.Copyright 2010 Elsevier Ltd. All rights reserved.","Adjuvant chemotherapy, with or without postoperative radiotherapy, in operable non-small-cell lung cancer: two meta-analyses of individual patient data."
"1225","JAMA.631","0.002",20371787,2010,"Caveolin-1 (CAV1) is an inhibitor of tissue fibrosis.To study the association of CAV1 gene variation with kidney transplant outcome, using kidney transplantation as a model of accelerated fibrosis.Candidate gene association and validation study. Genomic DNA from 785 white kidney transplant donors and their respective recipients (transplantations in Birmingham, England, between 1996 and 2006; median follow-up, 81 months) were analyzed for common variation in CAV1 using a single-nucleotide polymorphism (SNP) tagging approach. Validation of positive findings was sought in an independent kidney transplant donor-recipient cohort (transplantations in Belfast, Northern Ireland, between 1986 and 2005; n = 697; median follow-up, 69 months). Association between genotype and allograft failure was initially assessed by Kaplan-Meier analysis, then in an adjusted Cox model.Death-censored allograft failure, defined as a return to dialysis or retransplantation.The presence of donor AA genotype for the CAV1 rs4730751 SNP was associated with increased risk of allograft failure in the Birmingham group (donor AA vs non-AA genotype in adjusted Cox model, hazard ratio [HR], 1.97; 95% confidence interval [CI], 1.29-3.16; P = .002). No other tag SNPs showed a significant association. This finding was validated in the Belfast cohort (in adjusted Cox model, HR, 1.56; 95% CI, 1.07-2.27; P = .02). Overall graft failure rates were as follows: for the Birmingham cohort, donor genotype AA, 22 of 57 (38.6%); genotype CC, 96 of 431 (22.3%); and genotype AC, 66 of 297 (22.2%); and for the Belfast cohort, donor genotype AA, 32 of 48 (67%); genotype CC, 150 of 358 (42%); and genotype AC, 119 of 273 (44%).Among kidney transplant donors, the CAV1 rs4730751 SNP was significantly associated with allograft failure in 2 independent cohorts.","Association of caveolin-1 gene polymorphism with kidney transplant fibrosis and allograft failure."
"1226","JAMA.632","0.02",20371787,2010,"Caveolin-1 (CAV1) is an inhibitor of tissue fibrosis.To study the association of CAV1 gene variation with kidney transplant outcome, using kidney transplantation as a model of accelerated fibrosis.Candidate gene association and validation study. Genomic DNA from 785 white kidney transplant donors and their respective recipients (transplantations in Birmingham, England, between 1996 and 2006; median follow-up, 81 months) were analyzed for common variation in CAV1 using a single-nucleotide polymorphism (SNP) tagging approach. Validation of positive findings was sought in an independent kidney transplant donor-recipient cohort (transplantations in Belfast, Northern Ireland, between 1986 and 2005; n = 697; median follow-up, 69 months). Association between genotype and allograft failure was initially assessed by Kaplan-Meier analysis, then in an adjusted Cox model.Death-censored allograft failure, defined as a return to dialysis or retransplantation.The presence of donor AA genotype for the CAV1 rs4730751 SNP was associated with increased risk of allograft failure in the Birmingham group (donor AA vs non-AA genotype in adjusted Cox model, hazard ratio [HR], 1.97; 95% confidence interval [CI], 1.29-3.16; P = .002). No other tag SNPs showed a significant association. This finding was validated in the Belfast cohort (in adjusted Cox model, HR, 1.56; 95% CI, 1.07-2.27; P = .02). Overall graft failure rates were as follows: for the Birmingham cohort, donor genotype AA, 22 of 57 (38.6%); genotype CC, 96 of 431 (22.3%); and genotype AC, 66 of 297 (22.2%); and for the Belfast cohort, donor genotype AA, 32 of 48 (67%); genotype CC, 150 of 358 (42%); and genotype AC, 119 of 273 (44%).Among kidney transplant donors, the CAV1 rs4730751 SNP was significantly associated with allograft failure in 2 independent cohorts.","Association of caveolin-1 gene polymorphism with kidney transplant fibrosis and allograft failure."
"1227","JAMA.629","0.88",20424250,2010,"Hyperhomocysteinemia is frequently observed in patients with diabetic nephropathy. B-vitamin therapy (folic acid, vitamin B(6), and vitamin B(12)) has been shown to lower the plasma concentration of homocysteine.To determine whether B-vitamin therapy can slow progression of diabetic nephropathy and prevent vascular complications.A multicenter, randomized, double-blind, placebo-controlled trial (Diabetic Intervention with Vitamins to Improve Nephropathy [DIVINe]) at 5 university medical centers in Canada conducted between May 2001 and July 2007 of 238 participants who had type 1 or 2 diabetes and a clinical diagnosis of diabetic nephropathy.Single tablet of B vitamins containing folic acid (2.5 mg/d), vitamin B(6) (25 mg/d), and vitamin B(12) (1 mg/d), or matching placebo.Change in radionuclide glomerular filtration rate (GFR) between baseline and 36 months. Secondary outcomes were dialysis and a composite of myocardial infarction, stroke, revascularization, and all-cause mortality. Plasma total homocysteine was also measured.The mean (SD) follow-up during the trial was 31.9 (14.4) months. At 36 months, radionuclide GFR decreased by a mean (SE) of 16.5 (1.7) mL/min/1.73 m(2) in the B-vitamin group compared with 10.7 (1.7) mL/min/1.73 m(2) in the placebo group (mean difference, -5.8; 95% confidence interval [CI], -10.6 to -1.1; P = .02). There was no difference in requirement of dialysis (hazard ratio [HR], 1.1; 95% CI, 0.4-2.6; P = .88). The composite outcome occurred more often in the B-vitamin group (HR, 2.0; 95% CI, 1.0-4.0; P = .04). Plasma total homocysteine decreased by a mean (SE) of 2.2 (0.4) micromol/L at 36 months in the B-vitamin group compared with a mean (SE) increase of 2.6 (0.4) micromol/L in the placebo group (mean difference, -4.8; 95% CI, -6.1 to -3.7; P < .001, in favor of B vitamins).Among patients with diabetic nephropathy, high doses of B vitamins compared with placebo resulted in a greater decrease in GFR and an increase in vascular events.isrctn.org Identifier: ISRCTN41332305.","Effect of B-vitamin therapy on progression of diabetic nephropathy: a randomized controlled trial."
"1228","JAMA.630","0.04",20424250,2010,"Hyperhomocysteinemia is frequently observed in patients with diabetic nephropathy. B-vitamin therapy (folic acid, vitamin B(6), and vitamin B(12)) has been shown to lower the plasma concentration of homocysteine.To determine whether B-vitamin therapy can slow progression of diabetic nephropathy and prevent vascular complications.A multicenter, randomized, double-blind, placebo-controlled trial (Diabetic Intervention with Vitamins to Improve Nephropathy [DIVINe]) at 5 university medical centers in Canada conducted between May 2001 and July 2007 of 238 participants who had type 1 or 2 diabetes and a clinical diagnosis of diabetic nephropathy.Single tablet of B vitamins containing folic acid (2.5 mg/d), vitamin B(6) (25 mg/d), and vitamin B(12) (1 mg/d), or matching placebo.Change in radionuclide glomerular filtration rate (GFR) between baseline and 36 months. Secondary outcomes were dialysis and a composite of myocardial infarction, stroke, revascularization, and all-cause mortality. Plasma total homocysteine was also measured.The mean (SD) follow-up during the trial was 31.9 (14.4) months. At 36 months, radionuclide GFR decreased by a mean (SE) of 16.5 (1.7) mL/min/1.73 m(2) in the B-vitamin group compared with 10.7 (1.7) mL/min/1.73 m(2) in the placebo group (mean difference, -5.8; 95% confidence interval [CI], -10.6 to -1.1; P = .02). There was no difference in requirement of dialysis (hazard ratio [HR], 1.1; 95% CI, 0.4-2.6; P = .88). The composite outcome occurred more often in the B-vitamin group (HR, 2.0; 95% CI, 1.0-4.0; P = .04). Plasma total homocysteine decreased by a mean (SE) of 2.2 (0.4) micromol/L at 36 months in the B-vitamin group compared with a mean (SE) increase of 2.6 (0.4) micromol/L in the placebo group (mean difference, -4.8; 95% CI, -6.1 to -3.7; P < .001, in favor of B vitamins).Among patients with diabetic nephropathy, high doses of B vitamins compared with placebo resulted in a greater decrease in GFR and an increase in vascular events.isrctn.org Identifier: ISRCTN41332305.","Effect of B-vitamin therapy on progression of diabetic nephropathy: a randomized controlled trial."
"1229","American Journal of Epidemiology.104","0.001",20427327,2010,"The effect of change in reproductive hormones and menopause on incident obesity (body mass index > or =30 kg/m(2)) and severe obesity (body mass index > or =35 kg/m(2)) was evaluated over 9 years in 3,260 US women recruited in the multiethnic Study of Women's Health Across the Nation in 1996-1997. After 9 years, cumulative incidences of obesity and severe obesity reached 21.8% and 12.3%, respectively. In multivariate analysis, hormone changes, chronic health conditions, lower physical activity, race/ethnicity, and age were significantly associated with incident obesity and/or severe obesity. The odds of incident severe obesity increased with surgical menopause (odds ratio (OR) = 5.07, 95% confidence interval (CI): 2.29, 11.20; P < 0.001) and initiation of hormone therapy prior to 12 months of amenorrhea (OR = 2.94, 95% CI: 1.14, 7.58; P = 0.03). Predictors of obesity included an increase in free androgen index (OR = 1.37, 95% CI: 1.12, 1.68; P = 0.002) and a decrease in sex hormone-binding globulin (OR = 0.60, 95% CI: 0.45, 0.80; P = 0.0005). Similar results were found for severe obesity. Obesity rates varied by race, but no hormone-by-race interactions were observed. These longitudinal data demonstrate that higher androgens, lower sex hormone-binding globulin, surgical menopause, and early hormone therapy use predict incident obesity and/or severe obesity in a multiracial cohort of women transitioning into menopause.","Reproductive hormones and obesity: 9 years of observation from the Study of Women's Health Across the Nation."
"1230","American Journal of Epidemiology.116","0.03",20427327,2010,"The effect of change in reproductive hormones and menopause on incident obesity (body mass index > or =30 kg/m(2)) and severe obesity (body mass index > or =35 kg/m(2)) was evaluated over 9 years in 3,260 US women recruited in the multiethnic Study of Women's Health Across the Nation in 1996-1997. After 9 years, cumulative incidences of obesity and severe obesity reached 21.8% and 12.3%, respectively. In multivariate analysis, hormone changes, chronic health conditions, lower physical activity, race/ethnicity, and age were significantly associated with incident obesity and/or severe obesity. The odds of incident severe obesity increased with surgical menopause (odds ratio (OR) = 5.07, 95% confidence interval (CI): 2.29, 11.20; P < 0.001) and initiation of hormone therapy prior to 12 months of amenorrhea (OR = 2.94, 95% CI: 1.14, 7.58; P = 0.03). Predictors of obesity included an increase in free androgen index (OR = 1.37, 95% CI: 1.12, 1.68; P = 0.002) and a decrease in sex hormone-binding globulin (OR = 0.60, 95% CI: 0.45, 0.80; P = 0.0005). Similar results were found for severe obesity. Obesity rates varied by race, but no hormone-by-race interactions were observed. These longitudinal data demonstrate that higher androgens, lower sex hormone-binding globulin, surgical menopause, and early hormone therapy use predict incident obesity and/or severe obesity in a multiracial cohort of women transitioning into menopause.","Reproductive hormones and obesity: 9 years of observation from the Study of Women's Health Across the Nation."
"1231","American Journal of Epidemiology.117","0.002",20427327,2010,"The effect of change in reproductive hormones and menopause on incident obesity (body mass index > or =30 kg/m(2)) and severe obesity (body mass index > or =35 kg/m(2)) was evaluated over 9 years in 3,260 US women recruited in the multiethnic Study of Women's Health Across the Nation in 1996-1997. After 9 years, cumulative incidences of obesity and severe obesity reached 21.8% and 12.3%, respectively. In multivariate analysis, hormone changes, chronic health conditions, lower physical activity, race/ethnicity, and age were significantly associated with incident obesity and/or severe obesity. The odds of incident severe obesity increased with surgical menopause (odds ratio (OR) = 5.07, 95% confidence interval (CI): 2.29, 11.20; P < 0.001) and initiation of hormone therapy prior to 12 months of amenorrhea (OR = 2.94, 95% CI: 1.14, 7.58; P = 0.03). Predictors of obesity included an increase in free androgen index (OR = 1.37, 95% CI: 1.12, 1.68; P = 0.002) and a decrease in sex hormone-binding globulin (OR = 0.60, 95% CI: 0.45, 0.80; P = 0.0005). Similar results were found for severe obesity. Obesity rates varied by race, but no hormone-by-race interactions were observed. These longitudinal data demonstrate that higher androgens, lower sex hormone-binding globulin, surgical menopause, and early hormone therapy use predict incident obesity and/or severe obesity in a multiracial cohort of women transitioning into menopause.","Reproductive hormones and obesity: 9 years of observation from the Study of Women's Health Across the Nation."
"1232","American Journal of Epidemiology.118","5.00E-04",20427327,2010,"The effect of change in reproductive hormones and menopause on incident obesity (body mass index > or =30 kg/m(2)) and severe obesity (body mass index > or =35 kg/m(2)) was evaluated over 9 years in 3,260 US women recruited in the multiethnic Study of Women's Health Across the Nation in 1996-1997. After 9 years, cumulative incidences of obesity and severe obesity reached 21.8% and 12.3%, respectively. In multivariate analysis, hormone changes, chronic health conditions, lower physical activity, race/ethnicity, and age were significantly associated with incident obesity and/or severe obesity. The odds of incident severe obesity increased with surgical menopause (odds ratio (OR) = 5.07, 95% confidence interval (CI): 2.29, 11.20; P < 0.001) and initiation of hormone therapy prior to 12 months of amenorrhea (OR = 2.94, 95% CI: 1.14, 7.58; P = 0.03). Predictors of obesity included an increase in free androgen index (OR = 1.37, 95% CI: 1.12, 1.68; P = 0.002) and a decrease in sex hormone-binding globulin (OR = 0.60, 95% CI: 0.45, 0.80; P = 0.0005). Similar results were found for severe obesity. Obesity rates varied by race, but no hormone-by-race interactions were observed. These longitudinal data demonstrate that higher androgens, lower sex hormone-binding globulin, surgical menopause, and early hormone therapy use predict incident obesity and/or severe obesity in a multiracial cohort of women transitioning into menopause.","Reproductive hormones and obesity: 9 years of observation from the Study of Women's Health Across the Nation."
"1233","JAMA.5781","0.001",20442389,2010,"Despite potentially curative resection of stomach cancer, 50% to 90% of patients die of disease relapse. Numerous randomized clinical trials (RCTs) have compared surgery alone with adjuvant chemotherapy, but definitive evidence is lacking.To perform an individual patient-level meta-analysis of all RCTs to quantify the potential benefit of chemotherapy after complete resection over surgery alone in terms of overall survival and disease-free survival, and to further study the role of regimens, including monochemotherapy; combined chemotherapy with fluorouracil derivatives, mitomycin C, and other therapies but no anthracyclines; combined chemotherapy with fluorouracil derivatives, mitomycin C, and anthracyclines; and other treatments.Data from all RCTs comparing adjuvant chemotherapy with surgery alone in patients with resectable gastric cancer. We searched MEDLINE (up to 2009), the Cochrane Central Register of Controlled Trials, the National Institutes of Health trial registry, and published proceedings from major oncologic and gastrointestinal cancer meetings.All RCTs closed to patient recruitment before 2004 were eligible. Trials testing radiotherapy; neoadjuvant, perioperative, or intraperitoneal chemotherapy; or immunotherapy were excluded. Thirty-one eligible trials (6390 patients) were identified.As of 2010, individual patient data were available from 17 trials (3838 patients representing 60% of the targeted data) with a median follow-up exceeding 7 years.There were 1000 deaths among 1924 patients assigned to chemotherapy groups and 1067 deaths among 1857 patients assigned to surgery-only groups. Adjuvant chemotherapy was associated with a statistically significant benefit in terms of overall survival (hazard ratio [HR], 0.82; 95% confidence interval [CI], 0.76-0.90; P < .001) and disease-free survival (HR, 0.82; 95% CI, 0.75-0.90; P < .001). There was no significant heterogeneity for overall survival across RCTs (P = .52) or the 4 regimen groups (P = .13). Five-year overall survival increased from 49.6% to 55.3% with chemotherapy.Among the RCTs included, postoperative adjuvant chemotherapy based on fluorouracil regimens was associated with reduced risk of death in gastric cancer compared with surgery alone.","Benefit of adjuvant chemotherapy for resectable gastric cancer: a meta-analysis."
"1234","JAMA.5791","0.001",20442389,2010,"Despite potentially curative resection of stomach cancer, 50% to 90% of patients die of disease relapse. Numerous randomized clinical trials (RCTs) have compared surgery alone with adjuvant chemotherapy, but definitive evidence is lacking.To perform an individual patient-level meta-analysis of all RCTs to quantify the potential benefit of chemotherapy after complete resection over surgery alone in terms of overall survival and disease-free survival, and to further study the role of regimens, including monochemotherapy; combined chemotherapy with fluorouracil derivatives, mitomycin C, and other therapies but no anthracyclines; combined chemotherapy with fluorouracil derivatives, mitomycin C, and anthracyclines; and other treatments.Data from all RCTs comparing adjuvant chemotherapy with surgery alone in patients with resectable gastric cancer. We searched MEDLINE (up to 2009), the Cochrane Central Register of Controlled Trials, the National Institutes of Health trial registry, and published proceedings from major oncologic and gastrointestinal cancer meetings.All RCTs closed to patient recruitment before 2004 were eligible. Trials testing radiotherapy; neoadjuvant, perioperative, or intraperitoneal chemotherapy; or immunotherapy were excluded. Thirty-one eligible trials (6390 patients) were identified.As of 2010, individual patient data were available from 17 trials (3838 patients representing 60% of the targeted data) with a median follow-up exceeding 7 years.There were 1000 deaths among 1924 patients assigned to chemotherapy groups and 1067 deaths among 1857 patients assigned to surgery-only groups. Adjuvant chemotherapy was associated with a statistically significant benefit in terms of overall survival (hazard ratio [HR], 0.82; 95% confidence interval [CI], 0.76-0.90; P < .001) and disease-free survival (HR, 0.82; 95% CI, 0.75-0.90; P < .001). There was no significant heterogeneity for overall survival across RCTs (P = .52) or the 4 regimen groups (P = .13). Five-year overall survival increased from 49.6% to 55.3% with chemotherapy.Among the RCTs included, postoperative adjuvant chemotherapy based on fluorouracil regimens was associated with reduced risk of death in gastric cancer compared with surgery alone.","Benefit of adjuvant chemotherapy for resectable gastric cancer: a meta-analysis."
"1235","JAMA.583","1.59E-11",20460622,2010,"Genome-wide association studies (GWAS) have recently identified CLU, PICALM, and CR1 as novel genes for late-onset Alzheimer disease (AD).To identify and strengthen additional loci associated with AD and confirm these in an independent sample and to examine the contribution of recently identified genes to AD risk prediction in a 3-stage analysis of new and previously published GWAS on more than 35,000 persons (8371 AD cases).In stage 1, we identified strong genetic associations (P < 10(-3)) in a sample of 3006 AD cases and 14,642 controls by combining new data from the population-based Cohorts for Heart and Aging Research in Genomic Epidemiology consortium (1367 AD cases [973 incident]) with previously reported results from the Translational Genomics Research Institute and the Mayo AD GWAS. We identified 2708 single-nucleotide polymorphisms (SNPs) with P < 10(-3). In stage 2, we pooled results for these SNPs with the European AD Initiative (2032 cases and 5328 controls) to identify 38 SNPs (10 loci) with P < 10(-5). In stage 3, we combined data for these 10 loci with data from the Genetic and Environmental Risk in AD consortium (3333 cases and 6995 controls) to identify 4 SNPs with P < 1.7x10(-8). These 4 SNPs were replicated in an independent Spanish sample (1140 AD cases and 1209 controls). Genome-wide association analyses were completed in 2007-2008 and the meta-analyses and replication in 2009.Presence of Alzheimer disease.Two loci were identified to have genome-wide significance for the first time: rs744373 near BIN1 (odds ratio [OR],1.13; 95% confidence interval [CI],1.06-1.21 per copy of the minor allele; P = 1.59x10(-11)) and rs597668 near EXOC3L2/BLOC1S3/MARK4 (OR, 1.18; 95% CI, 1.07-1.29; P = 6.45x10(-9)). Associations of these 2 loci plus the previously identified loci CLU and PICALM with AD were confirmed in the Spanish sample (P < .05). However, although CLU and PICALM were confirmed to be associated with AD in this independent sample, they did not improve the ability of a model that included age, sex, and APOE to predict incident AD (improvement in area under the receiver operating characteristic curve from 0.847 to 0.849 in the Rotterdam Study and 0.702 to 0.705 in the Cardiovascular Health Study).Two genetic loci for AD were found for the first time to reach genome-wide statistical significance. These findings were replicated in an independent population. Two recently reported associations were also confirmed. These loci did not improve AD risk prediction. While not clinically useful, they may implicate biological pathways useful for future research.","Genome-wide analysis of genetic loci associated with Alzheimer disease."
"1236","JAMA.584","6.45E-09",20460622,2010,"Genome-wide association studies (GWAS) have recently identified CLU, PICALM, and CR1 as novel genes for late-onset Alzheimer disease (AD).To identify and strengthen additional loci associated with AD and confirm these in an independent sample and to examine the contribution of recently identified genes to AD risk prediction in a 3-stage analysis of new and previously published GWAS on more than 35,000 persons (8371 AD cases).In stage 1, we identified strong genetic associations (P < 10(-3)) in a sample of 3006 AD cases and 14,642 controls by combining new data from the population-based Cohorts for Heart and Aging Research in Genomic Epidemiology consortium (1367 AD cases [973 incident]) with previously reported results from the Translational Genomics Research Institute and the Mayo AD GWAS. We identified 2708 single-nucleotide polymorphisms (SNPs) with P < 10(-3). In stage 2, we pooled results for these SNPs with the European AD Initiative (2032 cases and 5328 controls) to identify 38 SNPs (10 loci) with P < 10(-5). In stage 3, we combined data for these 10 loci with data from the Genetic and Environmental Risk in AD consortium (3333 cases and 6995 controls) to identify 4 SNPs with P < 1.7x10(-8). These 4 SNPs were replicated in an independent Spanish sample (1140 AD cases and 1209 controls). Genome-wide association analyses were completed in 2007-2008 and the meta-analyses and replication in 2009.Presence of Alzheimer disease.Two loci were identified to have genome-wide significance for the first time: rs744373 near BIN1 (odds ratio [OR],1.13; 95% confidence interval [CI],1.06-1.21 per copy of the minor allele; P = 1.59x10(-11)) and rs597668 near EXOC3L2/BLOC1S3/MARK4 (OR, 1.18; 95% CI, 1.07-1.29; P = 6.45x10(-9)). Associations of these 2 loci plus the previously identified loci CLU and PICALM with AD were confirmed in the Spanish sample (P < .05). However, although CLU and PICALM were confirmed to be associated with AD in this independent sample, they did not improve the ability of a model that included age, sex, and APOE to predict incident AD (improvement in area under the receiver operating characteristic curve from 0.847 to 0.849 in the Rotterdam Study and 0.702 to 0.705 in the Cardiovascular Health Study).Two genetic loci for AD were found for the first time to reach genome-wide statistical significance. These findings were replicated in an independent population. Two recently reported associations were also confirmed. These loci did not improve AD risk prediction. While not clinically useful, they may implicate biological pathways useful for future research.","Genome-wide analysis of genetic loci associated with Alzheimer disease."
"1237","American Journal of Epidemiology.113","0.041",20462933,2010,"The etiology of glioma is barely known. Epidemiologic studies have provided evidence for an inverse relation between glioma risk and allergic disease. Genome-wide association data have identified common genetic variants at 5p15.33 (rs2736100, TERT), 8q24.21 (rs4295627, CCDC26), 9p21.3 (rs4977756, CDKN2A-CDKN2B), 11q23.3 (rs498872, PHLDB1), and 20q13.33 (rs6010620, RTEL1) as determinants of glioma risk. The authors investigated whether there is interaction between the effects of allergy and these 5 variants on glioma risk. Data from 5 case-control studies carried out in Denmark, Finland, Sweden, and the United Kingdom (2000-2004) were used, totaling 1,029 cases and 1,668 controls. Risk was inversely associated with asthma, hay fever, eczema, and ""any allergy,"" significantly for each factor except asthma, and was significantly positively associated with number of risk alleles for each of the 5 single nucleotide polymorphisms. There was interaction between asthma and rs498872 (greater protective effect of asthma with increasing number of risk alleles; per-allele interaction odds ratio (OR) = 0.65, P = 0.041), between ""any allergy"" and rs4977756 (smaller protective effect; interaction OR = 1.27, P = 0.047), and between ""any allergy"" and rs6010620 (greater protective effect; interaction OR = 0.70, P = 0.017). Case-only analyses provided further support for atopy interactions for rs4977756 and rs498872. This study provides evidence for possible gene-environment interactions in glioma development.","Interaction between 5 genetic variants and allergy in glioma risk."
"1238","American Journal of Epidemiology.114","0.047",20462933,2010,"The etiology of glioma is barely known. Epidemiologic studies have provided evidence for an inverse relation between glioma risk and allergic disease. Genome-wide association data have identified common genetic variants at 5p15.33 (rs2736100, TERT), 8q24.21 (rs4295627, CCDC26), 9p21.3 (rs4977756, CDKN2A-CDKN2B), 11q23.3 (rs498872, PHLDB1), and 20q13.33 (rs6010620, RTEL1) as determinants of glioma risk. The authors investigated whether there is interaction between the effects of allergy and these 5 variants on glioma risk. Data from 5 case-control studies carried out in Denmark, Finland, Sweden, and the United Kingdom (2000-2004) were used, totaling 1,029 cases and 1,668 controls. Risk was inversely associated with asthma, hay fever, eczema, and ""any allergy,"" significantly for each factor except asthma, and was significantly positively associated with number of risk alleles for each of the 5 single nucleotide polymorphisms. There was interaction between asthma and rs498872 (greater protective effect of asthma with increasing number of risk alleles; per-allele interaction odds ratio (OR) = 0.65, P = 0.041), between ""any allergy"" and rs4977756 (smaller protective effect; interaction OR = 1.27, P = 0.047), and between ""any allergy"" and rs6010620 (greater protective effect; interaction OR = 0.70, P = 0.017). Case-only analyses provided further support for atopy interactions for rs4977756 and rs498872. This study provides evidence for possible gene-environment interactions in glioma development.","Interaction between 5 genetic variants and allergy in glioma risk."
"1239","American Journal of Epidemiology.115","0.017",20462933,2010,"The etiology of glioma is barely known. Epidemiologic studies have provided evidence for an inverse relation between glioma risk and allergic disease. Genome-wide association data have identified common genetic variants at 5p15.33 (rs2736100, TERT), 8q24.21 (rs4295627, CCDC26), 9p21.3 (rs4977756, CDKN2A-CDKN2B), 11q23.3 (rs498872, PHLDB1), and 20q13.33 (rs6010620, RTEL1) as determinants of glioma risk. The authors investigated whether there is interaction between the effects of allergy and these 5 variants on glioma risk. Data from 5 case-control studies carried out in Denmark, Finland, Sweden, and the United Kingdom (2000-2004) were used, totaling 1,029 cases and 1,668 controls. Risk was inversely associated with asthma, hay fever, eczema, and ""any allergy,"" significantly for each factor except asthma, and was significantly positively associated with number of risk alleles for each of the 5 single nucleotide polymorphisms. There was interaction between asthma and rs498872 (greater protective effect of asthma with increasing number of risk alleles; per-allele interaction odds ratio (OR) = 0.65, P = 0.041), between ""any allergy"" and rs4977756 (smaller protective effect; interaction OR = 1.27, P = 0.047), and between ""any allergy"" and rs6010620 (greater protective effect; interaction OR = 0.70, P = 0.017). Case-only analyses provided further support for atopy interactions for rs4977756 and rs498872. This study provides evidence for possible gene-environment interactions in glioma development.","Interaction between 5 genetic variants and allergy in glioma risk."
"1240","JAMA.579","0.001",20483972,2010,"In a natural experiment in which some families received income supplements, prevalence of adolescent behavioral symptoms decreased significantly. These adolescents are now young adults.To examine the effects of income supplements in adolescence and adulthood on the prevalence of adult psychiatric disorders.Quasi-experimental, longitudinal.A representative sample of children aged 9, 11, or 13 years in 1993 (349 [25%] of whom are American Indian) were assessed for psychiatric and substance use disorders through age 21 years (1993-2006). Of the 1420 who participated in 1993, 1185 were interviewed as adults. From 1996, when a casino opened on the Indian reservation, every American Indian but no non-Indians received an annual income supplement that increased from $500 to around $9000.Prevalence of adult psychiatric disorders and substance use disorders based on the Diagnostic and Statistical Manual of Mental Disorders in 3 age cohorts, adjusted for age, sex, length of time in the family home, and number of Indian parents.As adults, significantly fewer Indians than non-Indians had a psychiatric disorder (106 Indians [weighted 30.2%] vs 337 non-Indians [weighted 36.0%]; odds ratio [OR], 0.46; 95% confidence interval [CI], 0.30-0.72; P = .001), particularly alcohol and cannabis abuse, dependence, or both. The youngest age-cohort of Indian youth had the longest exposure to the family income. Interactions between race/ethnicity and age cohort were significant. Planned comparisons showed that fewer of the youngest Indian age-cohort had any psychiatric disorder (31.4%) than the Indian middle cohort (41.7%; OR, 0.43; 95% CI, 0.24-0.78; P = .005) or oldest cohort (41.3%; OR, 0.69; 95% CI, 0.51-0.94; P = .01) or the youngest non-Indian cohort (37.1%; OR, 0.66; 95% CI, 0.48-0.90; P = .008). Study hypotheses were not upheld for nicotine or other drugs, or emotional or behavioral disorders. The income supplement received in adulthood had no impact on adult psychopathology.Lower prevalence of psychopathology in American Indian youth following a family income supplement, compared with the nonexposed, non-Indian population, persisted into adulthood.","Association of family income supplements in adolescence with development of psychiatric and substance use disorders in adulthood among an American Indian population."
"1241","JAMA.580","0.005",20483972,2010,"In a natural experiment in which some families received income supplements, prevalence of adolescent behavioral symptoms decreased significantly. These adolescents are now young adults.To examine the effects of income supplements in adolescence and adulthood on the prevalence of adult psychiatric disorders.Quasi-experimental, longitudinal.A representative sample of children aged 9, 11, or 13 years in 1993 (349 [25%] of whom are American Indian) were assessed for psychiatric and substance use disorders through age 21 years (1993-2006). Of the 1420 who participated in 1993, 1185 were interviewed as adults. From 1996, when a casino opened on the Indian reservation, every American Indian but no non-Indians received an annual income supplement that increased from $500 to around $9000.Prevalence of adult psychiatric disorders and substance use disorders based on the Diagnostic and Statistical Manual of Mental Disorders in 3 age cohorts, adjusted for age, sex, length of time in the family home, and number of Indian parents.As adults, significantly fewer Indians than non-Indians had a psychiatric disorder (106 Indians [weighted 30.2%] vs 337 non-Indians [weighted 36.0%]; odds ratio [OR], 0.46; 95% confidence interval [CI], 0.30-0.72; P = .001), particularly alcohol and cannabis abuse, dependence, or both. The youngest age-cohort of Indian youth had the longest exposure to the family income. Interactions between race/ethnicity and age cohort were significant. Planned comparisons showed that fewer of the youngest Indian age-cohort had any psychiatric disorder (31.4%) than the Indian middle cohort (41.7%; OR, 0.43; 95% CI, 0.24-0.78; P = .005) or oldest cohort (41.3%; OR, 0.69; 95% CI, 0.51-0.94; P = .01) or the youngest non-Indian cohort (37.1%; OR, 0.66; 95% CI, 0.48-0.90; P = .008). Study hypotheses were not upheld for nicotine or other drugs, or emotional or behavioral disorders. The income supplement received in adulthood had no impact on adult psychopathology.Lower prevalence of psychopathology in American Indian youth following a family income supplement, compared with the nonexposed, non-Indian population, persisted into adulthood.","Association of family income supplements in adolescence with development of psychiatric and substance use disorders in adulthood among an American Indian population."
"1242","JAMA.581","0.01",20483972,2010,"In a natural experiment in which some families received income supplements, prevalence of adolescent behavioral symptoms decreased significantly. These adolescents are now young adults.To examine the effects of income supplements in adolescence and adulthood on the prevalence of adult psychiatric disorders.Quasi-experimental, longitudinal.A representative sample of children aged 9, 11, or 13 years in 1993 (349 [25%] of whom are American Indian) were assessed for psychiatric and substance use disorders through age 21 years (1993-2006). Of the 1420 who participated in 1993, 1185 were interviewed as adults. From 1996, when a casino opened on the Indian reservation, every American Indian but no non-Indians received an annual income supplement that increased from $500 to around $9000.Prevalence of adult psychiatric disorders and substance use disorders based on the Diagnostic and Statistical Manual of Mental Disorders in 3 age cohorts, adjusted for age, sex, length of time in the family home, and number of Indian parents.As adults, significantly fewer Indians than non-Indians had a psychiatric disorder (106 Indians [weighted 30.2%] vs 337 non-Indians [weighted 36.0%]; odds ratio [OR], 0.46; 95% confidence interval [CI], 0.30-0.72; P = .001), particularly alcohol and cannabis abuse, dependence, or both. The youngest age-cohort of Indian youth had the longest exposure to the family income. Interactions between race/ethnicity and age cohort were significant. Planned comparisons showed that fewer of the youngest Indian age-cohort had any psychiatric disorder (31.4%) than the Indian middle cohort (41.7%; OR, 0.43; 95% CI, 0.24-0.78; P = .005) or oldest cohort (41.3%; OR, 0.69; 95% CI, 0.51-0.94; P = .01) or the youngest non-Indian cohort (37.1%; OR, 0.66; 95% CI, 0.48-0.90; P = .008). Study hypotheses were not upheld for nicotine or other drugs, or emotional or behavioral disorders. The income supplement received in adulthood had no impact on adult psychopathology.Lower prevalence of psychopathology in American Indian youth following a family income supplement, compared with the nonexposed, non-Indian population, persisted into adulthood.","Association of family income supplements in adolescence with development of psychiatric and substance use disorders in adulthood among an American Indian population."
"1243","JAMA.582","0.008",20483972,2010,"In a natural experiment in which some families received income supplements, prevalence of adolescent behavioral symptoms decreased significantly. These adolescents are now young adults.To examine the effects of income supplements in adolescence and adulthood on the prevalence of adult psychiatric disorders.Quasi-experimental, longitudinal.A representative sample of children aged 9, 11, or 13 years in 1993 (349 [25%] of whom are American Indian) were assessed for psychiatric and substance use disorders through age 21 years (1993-2006). Of the 1420 who participated in 1993, 1185 were interviewed as adults. From 1996, when a casino opened on the Indian reservation, every American Indian but no non-Indians received an annual income supplement that increased from $500 to around $9000.Prevalence of adult psychiatric disorders and substance use disorders based on the Diagnostic and Statistical Manual of Mental Disorders in 3 age cohorts, adjusted for age, sex, length of time in the family home, and number of Indian parents.As adults, significantly fewer Indians than non-Indians had a psychiatric disorder (106 Indians [weighted 30.2%] vs 337 non-Indians [weighted 36.0%]; odds ratio [OR], 0.46; 95% confidence interval [CI], 0.30-0.72; P = .001), particularly alcohol and cannabis abuse, dependence, or both. The youngest age-cohort of Indian youth had the longest exposure to the family income. Interactions between race/ethnicity and age cohort were significant. Planned comparisons showed that fewer of the youngest Indian age-cohort had any psychiatric disorder (31.4%) than the Indian middle cohort (41.7%; OR, 0.43; 95% CI, 0.24-0.78; P = .005) or oldest cohort (41.3%; OR, 0.69; 95% CI, 0.51-0.94; P = .01) or the youngest non-Indian cohort (37.1%; OR, 0.66; 95% CI, 0.48-0.90; P = .008). Study hypotheses were not upheld for nicotine or other drugs, or emotional or behavioral disorders. The income supplement received in adulthood had no impact on adult psychopathology.Lower prevalence of psychopathology in American Indian youth following a family income supplement, compared with the nonexposed, non-Indian population, persisted into adulthood.","Association of family income supplements in adolescence with development of psychiatric and substance use disorders in adulthood among an American Indian population."
"1244","Lancet.134","1.00E-04",20511018,2010,"Some heroin addicts persistently fail to benefit from conventional treatments. We aimed to compare the effectiveness of supervised injectable treatment with medicinal heroin (diamorphine or diacetylmorphine) or supervised injectable methadone versus optimised oral methadone for chronic heroin addiction.In this multisite, open-label, randomised controlled trial, we enrolled chronic heroin addicts who were receiving conventional oral treatment (>or=6 months), but continued to inject street heroin regularly (>or=50% of days in preceding 3 months). Randomisation by minimisation was used to assign patients to receive supervised injectable methadone, supervised injectable heroin, or optimised oral methadone. Treatment was provided for 26 weeks in three supervised injecting clinics in England. Primary outcome was 50% or more of negative specimens for street heroin on weekly urinalysis during weeks 14-26. Primary analysis was by intention to treat; data were adjusted for centre, regular crack use at baseline, and treatment with optimised oral methadone at baseline. Percentages were calculated with Rubin's rules and were then used to estimate numbers of patients in the multiple imputed samples. This study is registered, ISRCTN01338071.Of 301 patients screened, 127 were enrolled and randomly allocated to receive injectable methadone (n=42 patients), injectable heroin (n=43), or oral methadone (n=42); all patients were included in the primary analysis. At 26 weeks, 80% (n=101) patients remained in assigned treatment: 81% (n=34) on injectable methadone, 88% (n=38) on injectable heroin, and 69% (n=29) on oral methadone. Patients on injectable heroin were significantly more likely to have achieved the primary outcome (72% [n=31]) than were those on oral methadone (27% [n=11], OR 7.42, 95% CI 2.69-20.46, p<0.0001; adjusted: 66% [n=28] vs 19% [n=8], 8.17, 2.88-23.16, p<0.0001), with number needed to treat of 2.17 (95% CI 1.60-3.97). For injectable methadone (39% [n=16]; adjusted: 30% [n=14]) versus oral methadone, the difference was not significant (OR 1.74, 95% CI 0.66-4.60, p=0.264; adjusted: 1.79, 0.67-4.82, p=0.249). For injectable heroin versus injectable methadone, a significant difference was recorded (4.26, 1.63-11.14, p=0.003; adjusted: 4.57, 1.71-12.19, p=0.002), but the study was not powered for this comparison. Differences were evident within the first 6 weeks of treatment.Treatment with supervised injectable heroin leads to significantly lower use of street heroin than does supervised injectable methadone or optimised oral methadone. UK Government proposals should be rolled out to support the positive response that can be achieved with heroin maintenance treatment for previously unresponsive chronic heroin addicts.Community Fund (Big Lottery) Research section, through Action on Addiction.Copyright 2010 Elsevier Ltd. All rights reserved.","Supervised injectable heroin or injectable methadone versus optimised oral methadone as treatment for chronic heroin addicts in England after persistent failure in orthodox treatment (RIOTT): a randomised trial."
"1245","Lancet.135","1.00E-04",20511018,2010,"Some heroin addicts persistently fail to benefit from conventional treatments. We aimed to compare the effectiveness of supervised injectable treatment with medicinal heroin (diamorphine or diacetylmorphine) or supervised injectable methadone versus optimised oral methadone for chronic heroin addiction.In this multisite, open-label, randomised controlled trial, we enrolled chronic heroin addicts who were receiving conventional oral treatment (>or=6 months), but continued to inject street heroin regularly (>or=50% of days in preceding 3 months). Randomisation by minimisation was used to assign patients to receive supervised injectable methadone, supervised injectable heroin, or optimised oral methadone. Treatment was provided for 26 weeks in three supervised injecting clinics in England. Primary outcome was 50% or more of negative specimens for street heroin on weekly urinalysis during weeks 14-26. Primary analysis was by intention to treat; data were adjusted for centre, regular crack use at baseline, and treatment with optimised oral methadone at baseline. Percentages were calculated with Rubin's rules and were then used to estimate numbers of patients in the multiple imputed samples. This study is registered, ISRCTN01338071.Of 301 patients screened, 127 were enrolled and randomly allocated to receive injectable methadone (n=42 patients), injectable heroin (n=43), or oral methadone (n=42); all patients were included in the primary analysis. At 26 weeks, 80% (n=101) patients remained in assigned treatment: 81% (n=34) on injectable methadone, 88% (n=38) on injectable heroin, and 69% (n=29) on oral methadone. Patients on injectable heroin were significantly more likely to have achieved the primary outcome (72% [n=31]) than were those on oral methadone (27% [n=11], OR 7.42, 95% CI 2.69-20.46, p<0.0001; adjusted: 66% [n=28] vs 19% [n=8], 8.17, 2.88-23.16, p<0.0001), with number needed to treat of 2.17 (95% CI 1.60-3.97). For injectable methadone (39% [n=16]; adjusted: 30% [n=14]) versus oral methadone, the difference was not significant (OR 1.74, 95% CI 0.66-4.60, p=0.264; adjusted: 1.79, 0.67-4.82, p=0.249). For injectable heroin versus injectable methadone, a significant difference was recorded (4.26, 1.63-11.14, p=0.003; adjusted: 4.57, 1.71-12.19, p=0.002), but the study was not powered for this comparison. Differences were evident within the first 6 weeks of treatment.Treatment with supervised injectable heroin leads to significantly lower use of street heroin than does supervised injectable methadone or optimised oral methadone. UK Government proposals should be rolled out to support the positive response that can be achieved with heroin maintenance treatment for previously unresponsive chronic heroin addicts.Community Fund (Big Lottery) Research section, through Action on Addiction.Copyright 2010 Elsevier Ltd. All rights reserved.","Supervised injectable heroin or injectable methadone versus optimised oral methadone as treatment for chronic heroin addicts in England after persistent failure in orthodox treatment (RIOTT): a randomised trial."
"1246","Lancet.152","0.264",20511018,2010,"Some heroin addicts persistently fail to benefit from conventional treatments. We aimed to compare the effectiveness of supervised injectable treatment with medicinal heroin (diamorphine or diacetylmorphine) or supervised injectable methadone versus optimised oral methadone for chronic heroin addiction.In this multisite, open-label, randomised controlled trial, we enrolled chronic heroin addicts who were receiving conventional oral treatment (>or=6 months), but continued to inject street heroin regularly (>or=50% of days in preceding 3 months). Randomisation by minimisation was used to assign patients to receive supervised injectable methadone, supervised injectable heroin, or optimised oral methadone. Treatment was provided for 26 weeks in three supervised injecting clinics in England. Primary outcome was 50% or more of negative specimens for street heroin on weekly urinalysis during weeks 14-26. Primary analysis was by intention to treat; data were adjusted for centre, regular crack use at baseline, and treatment with optimised oral methadone at baseline. Percentages were calculated with Rubin's rules and were then used to estimate numbers of patients in the multiple imputed samples. This study is registered, ISRCTN01338071.Of 301 patients screened, 127 were enrolled and randomly allocated to receive injectable methadone (n=42 patients), injectable heroin (n=43), or oral methadone (n=42); all patients were included in the primary analysis. At 26 weeks, 80% (n=101) patients remained in assigned treatment: 81% (n=34) on injectable methadone, 88% (n=38) on injectable heroin, and 69% (n=29) on oral methadone. Patients on injectable heroin were significantly more likely to have achieved the primary outcome (72% [n=31]) than were those on oral methadone (27% [n=11], OR 7.42, 95% CI 2.69-20.46, p<0.0001; adjusted: 66% [n=28] vs 19% [n=8], 8.17, 2.88-23.16, p<0.0001), with number needed to treat of 2.17 (95% CI 1.60-3.97). For injectable methadone (39% [n=16]; adjusted: 30% [n=14]) versus oral methadone, the difference was not significant (OR 1.74, 95% CI 0.66-4.60, p=0.264; adjusted: 1.79, 0.67-4.82, p=0.249). For injectable heroin versus injectable methadone, a significant difference was recorded (4.26, 1.63-11.14, p=0.003; adjusted: 4.57, 1.71-12.19, p=0.002), but the study was not powered for this comparison. Differences were evident within the first 6 weeks of treatment.Treatment with supervised injectable heroin leads to significantly lower use of street heroin than does supervised injectable methadone or optimised oral methadone. UK Government proposals should be rolled out to support the positive response that can be achieved with heroin maintenance treatment for previously unresponsive chronic heroin addicts.Community Fund (Big Lottery) Research section, through Action on Addiction.Copyright 2010 Elsevier Ltd. All rights reserved.","Supervised injectable heroin or injectable methadone versus optimised oral methadone as treatment for chronic heroin addicts in England after persistent failure in orthodox treatment (RIOTT): a randomised trial."
"1247","Lancet.153","0.249",20511018,2010,"Some heroin addicts persistently fail to benefit from conventional treatments. We aimed to compare the effectiveness of supervised injectable treatment with medicinal heroin (diamorphine or diacetylmorphine) or supervised injectable methadone versus optimised oral methadone for chronic heroin addiction.In this multisite, open-label, randomised controlled trial, we enrolled chronic heroin addicts who were receiving conventional oral treatment (>or=6 months), but continued to inject street heroin regularly (>or=50% of days in preceding 3 months). Randomisation by minimisation was used to assign patients to receive supervised injectable methadone, supervised injectable heroin, or optimised oral methadone. Treatment was provided for 26 weeks in three supervised injecting clinics in England. Primary outcome was 50% or more of negative specimens for street heroin on weekly urinalysis during weeks 14-26. Primary analysis was by intention to treat; data were adjusted for centre, regular crack use at baseline, and treatment with optimised oral methadone at baseline. Percentages were calculated with Rubin's rules and were then used to estimate numbers of patients in the multiple imputed samples. This study is registered, ISRCTN01338071.Of 301 patients screened, 127 were enrolled and randomly allocated to receive injectable methadone (n=42 patients), injectable heroin (n=43), or oral methadone (n=42); all patients were included in the primary analysis. At 26 weeks, 80% (n=101) patients remained in assigned treatment: 81% (n=34) on injectable methadone, 88% (n=38) on injectable heroin, and 69% (n=29) on oral methadone. Patients on injectable heroin were significantly more likely to have achieved the primary outcome (72% [n=31]) than were those on oral methadone (27% [n=11], OR 7.42, 95% CI 2.69-20.46, p<0.0001; adjusted: 66% [n=28] vs 19% [n=8], 8.17, 2.88-23.16, p<0.0001), with number needed to treat of 2.17 (95% CI 1.60-3.97). For injectable methadone (39% [n=16]; adjusted: 30% [n=14]) versus oral methadone, the difference was not significant (OR 1.74, 95% CI 0.66-4.60, p=0.264; adjusted: 1.79, 0.67-4.82, p=0.249). For injectable heroin versus injectable methadone, a significant difference was recorded (4.26, 1.63-11.14, p=0.003; adjusted: 4.57, 1.71-12.19, p=0.002), but the study was not powered for this comparison. Differences were evident within the first 6 weeks of treatment.Treatment with supervised injectable heroin leads to significantly lower use of street heroin than does supervised injectable methadone or optimised oral methadone. UK Government proposals should be rolled out to support the positive response that can be achieved with heroin maintenance treatment for previously unresponsive chronic heroin addicts.Community Fund (Big Lottery) Research section, through Action on Addiction.Copyright 2010 Elsevier Ltd. All rights reserved.","Supervised injectable heroin or injectable methadone versus optimised oral methadone as treatment for chronic heroin addicts in England after persistent failure in orthodox treatment (RIOTT): a randomised trial."
"1248","Lancet.154","0.003",20511018,2010,"Some heroin addicts persistently fail to benefit from conventional treatments. We aimed to compare the effectiveness of supervised injectable treatment with medicinal heroin (diamorphine or diacetylmorphine) or supervised injectable methadone versus optimised oral methadone for chronic heroin addiction.In this multisite, open-label, randomised controlled trial, we enrolled chronic heroin addicts who were receiving conventional oral treatment (>or=6 months), but continued to inject street heroin regularly (>or=50% of days in preceding 3 months). Randomisation by minimisation was used to assign patients to receive supervised injectable methadone, supervised injectable heroin, or optimised oral methadone. Treatment was provided for 26 weeks in three supervised injecting clinics in England. Primary outcome was 50% or more of negative specimens for street heroin on weekly urinalysis during weeks 14-26. Primary analysis was by intention to treat; data were adjusted for centre, regular crack use at baseline, and treatment with optimised oral methadone at baseline. Percentages were calculated with Rubin's rules and were then used to estimate numbers of patients in the multiple imputed samples. This study is registered, ISRCTN01338071.Of 301 patients screened, 127 were enrolled and randomly allocated to receive injectable methadone (n=42 patients), injectable heroin (n=43), or oral methadone (n=42); all patients were included in the primary analysis. At 26 weeks, 80% (n=101) patients remained in assigned treatment: 81% (n=34) on injectable methadone, 88% (n=38) on injectable heroin, and 69% (n=29) on oral methadone. Patients on injectable heroin were significantly more likely to have achieved the primary outcome (72% [n=31]) than were those on oral methadone (27% [n=11], OR 7.42, 95% CI 2.69-20.46, p<0.0001; adjusted: 66% [n=28] vs 19% [n=8], 8.17, 2.88-23.16, p<0.0001), with number needed to treat of 2.17 (95% CI 1.60-3.97). For injectable methadone (39% [n=16]; adjusted: 30% [n=14]) versus oral methadone, the difference was not significant (OR 1.74, 95% CI 0.66-4.60, p=0.264; adjusted: 1.79, 0.67-4.82, p=0.249). For injectable heroin versus injectable methadone, a significant difference was recorded (4.26, 1.63-11.14, p=0.003; adjusted: 4.57, 1.71-12.19, p=0.002), but the study was not powered for this comparison. Differences were evident within the first 6 weeks of treatment.Treatment with supervised injectable heroin leads to significantly lower use of street heroin than does supervised injectable methadone or optimised oral methadone. UK Government proposals should be rolled out to support the positive response that can be achieved with heroin maintenance treatment for previously unresponsive chronic heroin addicts.Community Fund (Big Lottery) Research section, through Action on Addiction.Copyright 2010 Elsevier Ltd. All rights reserved.","Supervised injectable heroin or injectable methadone versus optimised oral methadone as treatment for chronic heroin addicts in England after persistent failure in orthodox treatment (RIOTT): a randomised trial."
"1249","Lancet.155","0.002",20511018,2010,"Some heroin addicts persistently fail to benefit from conventional treatments. We aimed to compare the effectiveness of supervised injectable treatment with medicinal heroin (diamorphine or diacetylmorphine) or supervised injectable methadone versus optimised oral methadone for chronic heroin addiction.In this multisite, open-label, randomised controlled trial, we enrolled chronic heroin addicts who were receiving conventional oral treatment (>or=6 months), but continued to inject street heroin regularly (>or=50% of days in preceding 3 months). Randomisation by minimisation was used to assign patients to receive supervised injectable methadone, supervised injectable heroin, or optimised oral methadone. Treatment was provided for 26 weeks in three supervised injecting clinics in England. Primary outcome was 50% or more of negative specimens for street heroin on weekly urinalysis during weeks 14-26. Primary analysis was by intention to treat; data were adjusted for centre, regular crack use at baseline, and treatment with optimised oral methadone at baseline. Percentages were calculated with Rubin's rules and were then used to estimate numbers of patients in the multiple imputed samples. This study is registered, ISRCTN01338071.Of 301 patients screened, 127 were enrolled and randomly allocated to receive injectable methadone (n=42 patients), injectable heroin (n=43), or oral methadone (n=42); all patients were included in the primary analysis. At 26 weeks, 80% (n=101) patients remained in assigned treatment: 81% (n=34) on injectable methadone, 88% (n=38) on injectable heroin, and 69% (n=29) on oral methadone. Patients on injectable heroin were significantly more likely to have achieved the primary outcome (72% [n=31]) than were those on oral methadone (27% [n=11], OR 7.42, 95% CI 2.69-20.46, p<0.0001; adjusted: 66% [n=28] vs 19% [n=8], 8.17, 2.88-23.16, p<0.0001), with number needed to treat of 2.17 (95% CI 1.60-3.97). For injectable methadone (39% [n=16]; adjusted: 30% [n=14]) versus oral methadone, the difference was not significant (OR 1.74, 95% CI 0.66-4.60, p=0.264; adjusted: 1.79, 0.67-4.82, p=0.249). For injectable heroin versus injectable methadone, a significant difference was recorded (4.26, 1.63-11.14, p=0.003; adjusted: 4.57, 1.71-12.19, p=0.002), but the study was not powered for this comparison. Differences were evident within the first 6 weeks of treatment.Treatment with supervised injectable heroin leads to significantly lower use of street heroin than does supervised injectable methadone or optimised oral methadone. UK Government proposals should be rolled out to support the positive response that can be achieved with heroin maintenance treatment for previously unresponsive chronic heroin addicts.Community Fund (Big Lottery) Research section, through Action on Addiction.Copyright 2010 Elsevier Ltd. All rights reserved.","Supervised injectable heroin or injectable methadone versus optimised oral methadone as treatment for chronic heroin addicts in England after persistent failure in orthodox treatment (RIOTT): a randomised trial."
"1250","Lancet.150","2.30E-48",20541252,2010,"Vitamin D is crucial for maintenance of musculoskeletal health, and might also have a role in extraskeletal tissues. Determinants of circulating 25-hydroxyvitamin D concentrations include sun exposure and diet, but high heritability suggests that genetic factors could also play a part. We aimed to identify common genetic variants affecting vitamin D concentrations and risk of insufficiency.We undertook a genome-wide association study of 25-hydroxyvitamin D concentrations in 33 996 individuals of European descent from 15 cohorts. Five epidemiological cohorts were designated as discovery cohorts (n=16 125), five as in-silico replication cohorts (n=9367), and five as de-novo replication cohorts (n=8504). 25-hydroxyvitamin D concentrations were measured by radioimmunoassay, chemiluminescent assay, ELISA, or mass spectrometry. Vitamin D insufficiency was defined as concentrations lower than 75 nmol/L or 50 nmol/L. We combined results of genome-wide analyses across cohorts using Z-score-weighted meta-analysis. Genotype scores were constructed for confirmed variants.Variants at three loci reached genome-wide significance in discovery cohorts for association with 25-hydroxyvitamin D concentrations, and were confirmed in replication cohorts: 4p12 (overall p=1.9x10(-109) for rs2282679, in GC); 11q12 (p=2.1x10(-27) for rs12785878, near DHCR7); and 11p15 (p=3.3x10(-20) for rs10741657, near CYP2R1). Variants at an additional locus (20q13, CYP24A1) were genome-wide significant in the pooled sample (p=6.0x10(-10) for rs6013897). Participants with a genotype score (combining the three confirmed variants) in the highest quartile were at increased risk of having 25-hydroxyvitamin D concentrations lower than 75 nmol/L (OR 2.47, 95% CI 2.20-2.78, p=2.3x10(-48)) or lower than 50 nmol/L (1.92, 1.70-2.16, p=1.0x10(-26)) compared with those in the lowest quartile.Variants near genes involved in cholesterol synthesis, hydroxylation, and vitamin D transport affect vitamin D status. Genetic variation at these loci identifies individuals who have substantially raised risk of vitamin D insufficiency.Full funding sources listed at end of paper (see Acknowledgments).Copyright 2010 Elsevier Ltd. All rights reserved.","Common genetic determinants of vitamin D insufficiency: a genome-wide association study."
"1251","Lancet.151","1.00E-26",20541252,2010,"Vitamin D is crucial for maintenance of musculoskeletal health, and might also have a role in extraskeletal tissues. Determinants of circulating 25-hydroxyvitamin D concentrations include sun exposure and diet, but high heritability suggests that genetic factors could also play a part. We aimed to identify common genetic variants affecting vitamin D concentrations and risk of insufficiency.We undertook a genome-wide association study of 25-hydroxyvitamin D concentrations in 33 996 individuals of European descent from 15 cohorts. Five epidemiological cohorts were designated as discovery cohorts (n=16 125), five as in-silico replication cohorts (n=9367), and five as de-novo replication cohorts (n=8504). 25-hydroxyvitamin D concentrations were measured by radioimmunoassay, chemiluminescent assay, ELISA, or mass spectrometry. Vitamin D insufficiency was defined as concentrations lower than 75 nmol/L or 50 nmol/L. We combined results of genome-wide analyses across cohorts using Z-score-weighted meta-analysis. Genotype scores were constructed for confirmed variants.Variants at three loci reached genome-wide significance in discovery cohorts for association with 25-hydroxyvitamin D concentrations, and were confirmed in replication cohorts: 4p12 (overall p=1.9x10(-109) for rs2282679, in GC); 11q12 (p=2.1x10(-27) for rs12785878, near DHCR7); and 11p15 (p=3.3x10(-20) for rs10741657, near CYP2R1). Variants at an additional locus (20q13, CYP24A1) were genome-wide significant in the pooled sample (p=6.0x10(-10) for rs6013897). Participants with a genotype score (combining the three confirmed variants) in the highest quartile were at increased risk of having 25-hydroxyvitamin D concentrations lower than 75 nmol/L (OR 2.47, 95% CI 2.20-2.78, p=2.3x10(-48)) or lower than 50 nmol/L (1.92, 1.70-2.16, p=1.0x10(-26)) compared with those in the lowest quartile.Variants near genes involved in cholesterol synthesis, hydroxylation, and vitamin D transport affect vitamin D status. Genetic variation at these loci identifies individuals who have substantially raised risk of vitamin D insufficiency.Full funding sources listed at end of paper (see Acknowledgments).Copyright 2010 Elsevier Ltd. All rights reserved.","Common genetic determinants of vitamin D insufficiency: a genome-wide association study."
"1252","JAMA.548","0.001",20571016,2010,"Severe sepsis, defined as infection complicated by acute organ dysfunction, occurs more frequently and leads to more deaths in black than in white individuals. The optimal approach to minimize these disparities is unclear.To determine the extent to which higher severe sepsis rates in black than in white patients are due to higher infection rates or to a higher risk of acute organ dysfunction.Analysis of infection-related hospitalizations from the 2005 hospital discharge data of 7 US states and infection-related emergency department visits from the 2003-2007 National Hospital Ambulatory Care Survey.Age- and sex-standardized severe sepsis and infection hospitalization rates and the risk of acute organ dysfunction.Of 8,661,227 non-childbirth-related discharges, 2,261,857 were associated with an infection, and of these, 381,787 (16.8%) had severe sepsis. Black patients had a 67% higher age- and sex-standardized severe sepsis rate than did white patients (9.4; 95% confidence interval [CI], 9.3-9.5 vs 5.6; 95% CI, 5.6-5.6 per 1000 population; P < .001) and 80% higher standardized mortality (1.8, 95% CI, 1.8-1.9 vs 1.0, 95% CI, 1.0-1.1 per 1000 population; P < .001). The higher severe sepsis rate was explained by both a higher infection rate in black patients (47.3; 95% CI, 47.1-47.4 vs 34.0; 95% CI, 33.9-34.0 per 1000 population; incidence rate ratio, 1.39; P < .001) and a higher risk of developing acute organ dysfunction (age- and sex-adjusted odds ratio [OR], 1.29; 95% CI, 1.27-1.30; P < .001). Differences in infection presented broadly across different sites and etiology of infection and for community- and hospital-acquired infections and occurred despite a lower likelihood of being admitted for infection from the emergency department (adjusted OR, 0.70; 95% CI, 0.64-0.76; P < .001). The higher risk of organ dysfunction persisted but was attenuated after adjusting for age, sex, comorbid conditions, poverty, and hospital effect (OR, 1.14; 95% CI, 1.13-1.16; P < .001). Racial disparities in infection and severe sepsis incidence and mortality rates were largest among younger adults (eg, the proportion of invasive pneumococcal disease occurring in adults < 65 years was 73.9% among black patients vs 44.5% among white patients, P < .001).Racial differences in severe sepsis are explained by both a higher infection rate and a higher risk of acute organ dysfunction in black than in white individuals.","Infection rate and acute organ dysfunction risk as explanations for racial differences in severe sepsis."
"1253","JAMA.549","0.001",20571016,2010,"Severe sepsis, defined as infection complicated by acute organ dysfunction, occurs more frequently and leads to more deaths in black than in white individuals. The optimal approach to minimize these disparities is unclear.To determine the extent to which higher severe sepsis rates in black than in white patients are due to higher infection rates or to a higher risk of acute organ dysfunction.Analysis of infection-related hospitalizations from the 2005 hospital discharge data of 7 US states and infection-related emergency department visits from the 2003-2007 National Hospital Ambulatory Care Survey.Age- and sex-standardized severe sepsis and infection hospitalization rates and the risk of acute organ dysfunction.Of 8,661,227 non-childbirth-related discharges, 2,261,857 were associated with an infection, and of these, 381,787 (16.8%) had severe sepsis. Black patients had a 67% higher age- and sex-standardized severe sepsis rate than did white patients (9.4; 95% confidence interval [CI], 9.3-9.5 vs 5.6; 95% CI, 5.6-5.6 per 1000 population; P < .001) and 80% higher standardized mortality (1.8, 95% CI, 1.8-1.9 vs 1.0, 95% CI, 1.0-1.1 per 1000 population; P < .001). The higher severe sepsis rate was explained by both a higher infection rate in black patients (47.3; 95% CI, 47.1-47.4 vs 34.0; 95% CI, 33.9-34.0 per 1000 population; incidence rate ratio, 1.39; P < .001) and a higher risk of developing acute organ dysfunction (age- and sex-adjusted odds ratio [OR], 1.29; 95% CI, 1.27-1.30; P < .001). Differences in infection presented broadly across different sites and etiology of infection and for community- and hospital-acquired infections and occurred despite a lower likelihood of being admitted for infection from the emergency department (adjusted OR, 0.70; 95% CI, 0.64-0.76; P < .001). The higher risk of organ dysfunction persisted but was attenuated after adjusting for age, sex, comorbid conditions, poverty, and hospital effect (OR, 1.14; 95% CI, 1.13-1.16; P < .001). Racial disparities in infection and severe sepsis incidence and mortality rates were largest among younger adults (eg, the proportion of invasive pneumococcal disease occurring in adults < 65 years was 73.9% among black patients vs 44.5% among white patients, P < .001).Racial differences in severe sepsis are explained by both a higher infection rate and a higher risk of acute organ dysfunction in black than in white individuals.","Infection rate and acute organ dysfunction risk as explanations for racial differences in severe sepsis."
"1254","JAMA.550","0.001",20571016,2010,"Severe sepsis, defined as infection complicated by acute organ dysfunction, occurs more frequently and leads to more deaths in black than in white individuals. The optimal approach to minimize these disparities is unclear.To determine the extent to which higher severe sepsis rates in black than in white patients are due to higher infection rates or to a higher risk of acute organ dysfunction.Analysis of infection-related hospitalizations from the 2005 hospital discharge data of 7 US states and infection-related emergency department visits from the 2003-2007 National Hospital Ambulatory Care Survey.Age- and sex-standardized severe sepsis and infection hospitalization rates and the risk of acute organ dysfunction.Of 8,661,227 non-childbirth-related discharges, 2,261,857 were associated with an infection, and of these, 381,787 (16.8%) had severe sepsis. Black patients had a 67% higher age- and sex-standardized severe sepsis rate than did white patients (9.4; 95% confidence interval [CI], 9.3-9.5 vs 5.6; 95% CI, 5.6-5.6 per 1000 population; P < .001) and 80% higher standardized mortality (1.8, 95% CI, 1.8-1.9 vs 1.0, 95% CI, 1.0-1.1 per 1000 population; P < .001). The higher severe sepsis rate was explained by both a higher infection rate in black patients (47.3; 95% CI, 47.1-47.4 vs 34.0; 95% CI, 33.9-34.0 per 1000 population; incidence rate ratio, 1.39; P < .001) and a higher risk of developing acute organ dysfunction (age- and sex-adjusted odds ratio [OR], 1.29; 95% CI, 1.27-1.30; P < .001). Differences in infection presented broadly across different sites and etiology of infection and for community- and hospital-acquired infections and occurred despite a lower likelihood of being admitted for infection from the emergency department (adjusted OR, 0.70; 95% CI, 0.64-0.76; P < .001). The higher risk of organ dysfunction persisted but was attenuated after adjusting for age, sex, comorbid conditions, poverty, and hospital effect (OR, 1.14; 95% CI, 1.13-1.16; P < .001). Racial disparities in infection and severe sepsis incidence and mortality rates were largest among younger adults (eg, the proportion of invasive pneumococcal disease occurring in adults < 65 years was 73.9% among black patients vs 44.5% among white patients, P < .001).Racial differences in severe sepsis are explained by both a higher infection rate and a higher risk of acute organ dysfunction in black than in white individuals.","Infection rate and acute organ dysfunction risk as explanations for racial differences in severe sepsis."
"1255","New England Journal of Medicine.23","0.003",20587587,2010,"We investigated whether intensive glycemic control, combination therapy for dyslipidemia, and intensive blood-pressure control would limit the progression of diabetic retinopathy in persons with type 2 diabetes. Previous data suggest that these systemic factors may be important in the development and progression of diabetic retinopathy.In a randomized trial, we enrolled 10,251 participants with type 2 diabetes who were at high risk for cardiovascular disease to receive either intensive or standard treatment for glycemia (target glycated hemoglobin level, <6.0% or 7.0 to 7.9%, respectively) and also for dyslipidemia (160 mg daily of fenofibrate plus simvastatin or placebo plus simvastatin) or for systolic blood-pressure control (target, <120 or <140 mm Hg). A subgroup of 2856 participants was evaluated for the effects of these interventions at 4 years on the progression of diabetic retinopathy by 3 or more steps on the Early Treatment Diabetic Retinopathy Study Severity Scale (as assessed from seven-field stereoscopic fundus photographs, with 17 possible steps and a higher number of steps indicating greater severity) or the development of diabetic retinopathy necessitating laser photocoagulation or vitrectomy.At 4 years, the rates of progression of diabetic retinopathy were 7.3% with intensive glycemia treatment, versus 10.4% with standard therapy (adjusted odds ratio, 0.67; 95% confidence interval [CI], 0.51 to 0.87; P=0.003); 6.5% with fenofibrate for intensive dyslipidemia therapy, versus 10.2% with placebo (adjusted odds ratio, 0.60; 95% CI, 0.42 to 0.87; P=0.006); and 10.4% with intensive blood-pressure therapy, versus 8.8% with standard therapy (adjusted odds ratio, 1.23; 95% CI, 0.84 to 1.79; P=0.29).Intensive glycemic control and intensive combination treatment of dyslipidemia, but not intensive blood-pressure control, reduced the rate of progression of diabetic retinopathy. (Funded by the National Heart, Lung, and Blood Institute and others; ClinicalTrials.gov numbers, NCT00000620 for the ACCORD study and NCT00542178 for the ACCORD Eye study.)2010 Massachusetts Medical Society","Effects of medical therapies on retinopathy progression in type 2 diabetes."
"1256","New England Journal of Medicine.23","0.006",20587587,2010,"We investigated whether intensive glycemic control, combination therapy for dyslipidemia, and intensive blood-pressure control would limit the progression of diabetic retinopathy in persons with type 2 diabetes. Previous data suggest that these systemic factors may be important in the development and progression of diabetic retinopathy.In a randomized trial, we enrolled 10,251 participants with type 2 diabetes who were at high risk for cardiovascular disease to receive either intensive or standard treatment for glycemia (target glycated hemoglobin level, <6.0% or 7.0 to 7.9%, respectively) and also for dyslipidemia (160 mg daily of fenofibrate plus simvastatin or placebo plus simvastatin) or for systolic blood-pressure control (target, <120 or <140 mm Hg). A subgroup of 2856 participants was evaluated for the effects of these interventions at 4 years on the progression of diabetic retinopathy by 3 or more steps on the Early Treatment Diabetic Retinopathy Study Severity Scale (as assessed from seven-field stereoscopic fundus photographs, with 17 possible steps and a higher number of steps indicating greater severity) or the development of diabetic retinopathy necessitating laser photocoagulation or vitrectomy.At 4 years, the rates of progression of diabetic retinopathy were 7.3% with intensive glycemia treatment, versus 10.4% with standard therapy (adjusted odds ratio, 0.67; 95% confidence interval [CI], 0.51 to 0.87; P=0.003); 6.5% with fenofibrate for intensive dyslipidemia therapy, versus 10.2% with placebo (adjusted odds ratio, 0.60; 95% CI, 0.42 to 0.87; P=0.006); and 10.4% with intensive blood-pressure therapy, versus 8.8% with standard therapy (adjusted odds ratio, 1.23; 95% CI, 0.84 to 1.79; P=0.29).Intensive glycemic control and intensive combination treatment of dyslipidemia, but not intensive blood-pressure control, reduced the rate of progression of diabetic retinopathy. (Funded by the National Heart, Lung, and Blood Institute and others; ClinicalTrials.gov numbers, NCT00000620 for the ACCORD study and NCT00542178 for the ACCORD Eye study.)2010 Massachusetts Medical Society","Effects of medical therapies on retinopathy progression in type 2 diabetes."
"1257","New England Journal of Medicine.24","0.29",20587587,2010,"We investigated whether intensive glycemic control, combination therapy for dyslipidemia, and intensive blood-pressure control would limit the progression of diabetic retinopathy in persons with type 2 diabetes. Previous data suggest that these systemic factors may be important in the development and progression of diabetic retinopathy.In a randomized trial, we enrolled 10,251 participants with type 2 diabetes who were at high risk for cardiovascular disease to receive either intensive or standard treatment for glycemia (target glycated hemoglobin level, <6.0% or 7.0 to 7.9%, respectively) and also for dyslipidemia (160 mg daily of fenofibrate plus simvastatin or placebo plus simvastatin) or for systolic blood-pressure control (target, <120 or <140 mm Hg). A subgroup of 2856 participants was evaluated for the effects of these interventions at 4 years on the progression of diabetic retinopathy by 3 or more steps on the Early Treatment Diabetic Retinopathy Study Severity Scale (as assessed from seven-field stereoscopic fundus photographs, with 17 possible steps and a higher number of steps indicating greater severity) or the development of diabetic retinopathy necessitating laser photocoagulation or vitrectomy.At 4 years, the rates of progression of diabetic retinopathy were 7.3% with intensive glycemia treatment, versus 10.4% with standard therapy (adjusted odds ratio, 0.67; 95% confidence interval [CI], 0.51 to 0.87; P=0.003); 6.5% with fenofibrate for intensive dyslipidemia therapy, versus 10.2% with placebo (adjusted odds ratio, 0.60; 95% CI, 0.42 to 0.87; P=0.006); and 10.4% with intensive blood-pressure therapy, versus 8.8% with standard therapy (adjusted odds ratio, 1.23; 95% CI, 0.84 to 1.79; P=0.29).Intensive glycemic control and intensive combination treatment of dyslipidemia, but not intensive blood-pressure control, reduced the rate of progression of diabetic retinopathy. (Funded by the National Heart, Lung, and Blood Institute and others; ClinicalTrials.gov numbers, NCT00000620 for the ACCORD study and NCT00542178 for the ACCORD Eye study.)2010 Massachusetts Medical Society","Effects of medical therapies on retinopathy progression in type 2 diabetes."
"1258","Lancet.142","1",20594588,2010,"Hyperglycaemia is associated with increased risk of cardiovascular complications in people with type 2 diabetes. We investigated whether reduction of blood glucose concentration decreases the rate of microvascular complications in people with type 2 diabetes.ACCORD was a parallel-group, randomised trial done in 77 clinical sites in North America. People with diabetes, high HbA(1c) concentrations (>7.5%), and cardiovascular disease (or >or=2 cardiovascular risk factors) were randomly assigned by central randomisation to intensive (target haemoglobin A(1c) [HbA(1c)] of <6.0%) or standard (7.0-7.9%) glycaemic therapy. In this analysis, the prespecified composite outcomes were: dialysis or renal transplantation, high serum creatinine (>291.7 micromol/L), or retinal photocoagulation or vitrectomy (first composite outcome); or peripheral neuropathy plus the first composite outcome (second composite outcome). 13 prespecified secondary measures of kidney, eye, and peripheral nerve function were also assessed. Investigators and participants were aware of treatment group assignment. Analysis was done for all patients who were assessed for microvascular outcomes, on the basis of treatment assignment, irrespective of treatments received or compliance to therapies. ACCORD is registered with ClinicalTrials.gov, number NCT00000620.10 251 patients were randomly assigned, 5128 to the intensive glycaemia control group and 5123 to standard group. Intensive therapy was stopped before study end because of higher mortality in that group, and patients were transitioned to standard therapy. At transition, the first composite outcome was recorded in 443 of 5107 patients in the intensive group versus 444 of 5108 in the standard group (HR 1.00, 95% CI 0.88-1.14; p=1.00), and the second composite outcome was noted in 1591 of 5107 versus 1659 of 5108 (0.96, 0.89-1.02; p=0.19). Results were similar at study end (first composite outcome 556 of 5119 vs 586 of 5115 [HR 0.95, 95% CI 0.85-1.07, p=0.42]; and second 1956 of 5119 vs 2046 of 5115, respectively [0.95, 0.89-1.01, p=0.12]). Intensive therapy did not reduce the risk of advanced measures of microvascular outcomes, but delayed the onset of albuminuria and some measures of eye complications and neuropathy. Seven secondary measures at study end favoured intensive therapy (p<0.05).Microvascular benefits of intensive therapy should be weighed against the increase in total and cardiovascular disease-related mortality, increased weight gain, and high risk for severe hypoglycaemia.US National Institutes of Health; National Heart, Lung, and Blood Institute; National Institute of Diabetes and Digestive and Kidney Diseases; National Institute on Aging; National Eye Institute; Centers for Disease Control and Prevention; and General Clinical Research Centers.Copyright 2010 Elsevier Ltd. All rights reserved.","Effect of intensive treatment of hyperglycaemia on microvascular outcomes in type 2 diabetes: an analysis of the ACCORD randomised trial."
"1259","Lancet.143","0.19",20594588,2010,"Hyperglycaemia is associated with increased risk of cardiovascular complications in people with type 2 diabetes. We investigated whether reduction of blood glucose concentration decreases the rate of microvascular complications in people with type 2 diabetes.ACCORD was a parallel-group, randomised trial done in 77 clinical sites in North America. People with diabetes, high HbA(1c) concentrations (>7.5%), and cardiovascular disease (or >or=2 cardiovascular risk factors) were randomly assigned by central randomisation to intensive (target haemoglobin A(1c) [HbA(1c)] of <6.0%) or standard (7.0-7.9%) glycaemic therapy. In this analysis, the prespecified composite outcomes were: dialysis or renal transplantation, high serum creatinine (>291.7 micromol/L), or retinal photocoagulation or vitrectomy (first composite outcome); or peripheral neuropathy plus the first composite outcome (second composite outcome). 13 prespecified secondary measures of kidney, eye, and peripheral nerve function were also assessed. Investigators and participants were aware of treatment group assignment. Analysis was done for all patients who were assessed for microvascular outcomes, on the basis of treatment assignment, irrespective of treatments received or compliance to therapies. ACCORD is registered with ClinicalTrials.gov, number NCT00000620.10 251 patients were randomly assigned, 5128 to the intensive glycaemia control group and 5123 to standard group. Intensive therapy was stopped before study end because of higher mortality in that group, and patients were transitioned to standard therapy. At transition, the first composite outcome was recorded in 443 of 5107 patients in the intensive group versus 444 of 5108 in the standard group (HR 1.00, 95% CI 0.88-1.14; p=1.00), and the second composite outcome was noted in 1591 of 5107 versus 1659 of 5108 (0.96, 0.89-1.02; p=0.19). Results were similar at study end (first composite outcome 556 of 5119 vs 586 of 5115 [HR 0.95, 95% CI 0.85-1.07, p=0.42]; and second 1956 of 5119 vs 2046 of 5115, respectively [0.95, 0.89-1.01, p=0.12]). Intensive therapy did not reduce the risk of advanced measures of microvascular outcomes, but delayed the onset of albuminuria and some measures of eye complications and neuropathy. Seven secondary measures at study end favoured intensive therapy (p<0.05).Microvascular benefits of intensive therapy should be weighed against the increase in total and cardiovascular disease-related mortality, increased weight gain, and high risk for severe hypoglycaemia.US National Institutes of Health; National Heart, Lung, and Blood Institute; National Institute of Diabetes and Digestive and Kidney Diseases; National Institute on Aging; National Eye Institute; Centers for Disease Control and Prevention; and General Clinical Research Centers.Copyright 2010 Elsevier Ltd. All rights reserved.","Effect of intensive treatment of hyperglycaemia on microvascular outcomes in type 2 diabetes: an analysis of the ACCORD randomised trial."
"1260","Lancet.144","0.42",20594588,2010,"Hyperglycaemia is associated with increased risk of cardiovascular complications in people with type 2 diabetes. We investigated whether reduction of blood glucose concentration decreases the rate of microvascular complications in people with type 2 diabetes.ACCORD was a parallel-group, randomised trial done in 77 clinical sites in North America. People with diabetes, high HbA(1c) concentrations (>7.5%), and cardiovascular disease (or >or=2 cardiovascular risk factors) were randomly assigned by central randomisation to intensive (target haemoglobin A(1c) [HbA(1c)] of <6.0%) or standard (7.0-7.9%) glycaemic therapy. In this analysis, the prespecified composite outcomes were: dialysis or renal transplantation, high serum creatinine (>291.7 micromol/L), or retinal photocoagulation or vitrectomy (first composite outcome); or peripheral neuropathy plus the first composite outcome (second composite outcome). 13 prespecified secondary measures of kidney, eye, and peripheral nerve function were also assessed. Investigators and participants were aware of treatment group assignment. Analysis was done for all patients who were assessed for microvascular outcomes, on the basis of treatment assignment, irrespective of treatments received or compliance to therapies. ACCORD is registered with ClinicalTrials.gov, number NCT00000620.10 251 patients were randomly assigned, 5128 to the intensive glycaemia control group and 5123 to standard group. Intensive therapy was stopped before study end because of higher mortality in that group, and patients were transitioned to standard therapy. At transition, the first composite outcome was recorded in 443 of 5107 patients in the intensive group versus 444 of 5108 in the standard group (HR 1.00, 95% CI 0.88-1.14; p=1.00), and the second composite outcome was noted in 1591 of 5107 versus 1659 of 5108 (0.96, 0.89-1.02; p=0.19). Results were similar at study end (first composite outcome 556 of 5119 vs 586 of 5115 [HR 0.95, 95% CI 0.85-1.07, p=0.42]; and second 1956 of 5119 vs 2046 of 5115, respectively [0.95, 0.89-1.01, p=0.12]). Intensive therapy did not reduce the risk of advanced measures of microvascular outcomes, but delayed the onset of albuminuria and some measures of eye complications and neuropathy. Seven secondary measures at study end favoured intensive therapy (p<0.05).Microvascular benefits of intensive therapy should be weighed against the increase in total and cardiovascular disease-related mortality, increased weight gain, and high risk for severe hypoglycaemia.US National Institutes of Health; National Heart, Lung, and Blood Institute; National Institute of Diabetes and Digestive and Kidney Diseases; National Institute on Aging; National Eye Institute; Centers for Disease Control and Prevention; and General Clinical Research Centers.Copyright 2010 Elsevier Ltd. All rights reserved.","Effect of intensive treatment of hyperglycaemia on microvascular outcomes in type 2 diabetes: an analysis of the ACCORD randomised trial."
"1261","Lancet.145","0.12",20594588,2010,"Hyperglycaemia is associated with increased risk of cardiovascular complications in people with type 2 diabetes. We investigated whether reduction of blood glucose concentration decreases the rate of microvascular complications in people with type 2 diabetes.ACCORD was a parallel-group, randomised trial done in 77 clinical sites in North America. People with diabetes, high HbA(1c) concentrations (>7.5%), and cardiovascular disease (or >or=2 cardiovascular risk factors) were randomly assigned by central randomisation to intensive (target haemoglobin A(1c) [HbA(1c)] of <6.0%) or standard (7.0-7.9%) glycaemic therapy. In this analysis, the prespecified composite outcomes were: dialysis or renal transplantation, high serum creatinine (>291.7 micromol/L), or retinal photocoagulation or vitrectomy (first composite outcome); or peripheral neuropathy plus the first composite outcome (second composite outcome). 13 prespecified secondary measures of kidney, eye, and peripheral nerve function were also assessed. Investigators and participants were aware of treatment group assignment. Analysis was done for all patients who were assessed for microvascular outcomes, on the basis of treatment assignment, irrespective of treatments received or compliance to therapies. ACCORD is registered with ClinicalTrials.gov, number NCT00000620.10 251 patients were randomly assigned, 5128 to the intensive glycaemia control group and 5123 to standard group. Intensive therapy was stopped before study end because of higher mortality in that group, and patients were transitioned to standard therapy. At transition, the first composite outcome was recorded in 443 of 5107 patients in the intensive group versus 444 of 5108 in the standard group (HR 1.00, 95% CI 0.88-1.14; p=1.00), and the second composite outcome was noted in 1591 of 5107 versus 1659 of 5108 (0.96, 0.89-1.02; p=0.19). Results were similar at study end (first composite outcome 556 of 5119 vs 586 of 5115 [HR 0.95, 95% CI 0.85-1.07, p=0.42]; and second 1956 of 5119 vs 2046 of 5115, respectively [0.95, 0.89-1.01, p=0.12]). Intensive therapy did not reduce the risk of advanced measures of microvascular outcomes, but delayed the onset of albuminuria and some measures of eye complications and neuropathy. Seven secondary measures at study end favoured intensive therapy (p<0.05).Microvascular benefits of intensive therapy should be weighed against the increase in total and cardiovascular disease-related mortality, increased weight gain, and high risk for severe hypoglycaemia.US National Institutes of Health; National Heart, Lung, and Blood Institute; National Institute of Diabetes and Digestive and Kidney Diseases; National Institute on Aging; National Eye Institute; Centers for Disease Control and Prevention; and General Clinical Research Centers.Copyright 2010 Elsevier Ltd. All rights reserved.","Effect of intensive treatment of hyperglycaemia on microvascular outcomes in type 2 diabetes: an analysis of the ACCORD randomised trial."
"1262","JAMA.5771","0.001",20606150,2010,"Hypertension guidelines advocate treating systolic blood pressure (BP) to less than 130 mm Hg for patients with diabetes mellitus; however, data are lacking for the growing population who also have coronary artery disease (CAD).To determine the association of systolic BP control achieved and adverse cardiovascular outcomes in a cohort of patients with diabetes and CAD.Observational subgroup analysis of 6400 of the 22,576 participants in the International Verapamil SR-Trandolapril Study (INVEST). For this analysis, participants were at least 50 years old and had diabetes and CAD. Participants were recruited between September 1997 and December 2000 from 862 sites in 14 countries and were followed up through March 2003 with an extended follow-up through August 2008 through the National Death Index for US participants.Patients received first-line treatment of either a calcium antagonist or beta-blocker followed by angiotensin-converting enzyme inhibitor, a diuretic, or both to achieve systolic BP of less than 130 and diastolic BP of less than 85 mm Hg. Patients were categorized as having tight control if they could maintain their systolic BP at less than 130 mm Hg; usual control if it ranged from 130 mm Hg to less than 140 mm Hg; and uncontrolled if it was 140 mm Hg or higher.Adverse cardiovascular outcomes, including the primary outcomes which was the first occurrence of all-cause death, nonfatal myocardial infarction, or nonfatal stroke.During 16,893 patient-years of follow-up, 286 patients (12.7%) who maintained tight control, 249 (12.6%) who had usual control, and 431 (19.8%) who had uncontrolled systolic BP experienced a primary outcome event. Patients in the usual-control group had a cardiovascular event rate of 12.6% vs a 19.8% event rate for those in the uncontrolled group (adjusted hazard ratio [HR], 1.46; 95% confidence interval [CI], 1.25-1.71; P < .001). However, little difference existed between those with usual control and those with tight control. Their respective event rates were 12.6% vs 12.7% (adjusted HR, 1.11; 95% CI, 0.93-1.32; P = .24). The all-cause mortality rate was 11.0% in the tight-control group vs 10.2% in the usual-control group (adjusted HR, 1.20; 95% CI, 0.99-1.45; P = .06); however, when extended follow-up was included, risk of all-cause mortality was 22.8% in the tight control vs 21.8% in the usual control group (adjusted HR, 1.15; 95% CI, 1.01-1.32; P = .04).Tight control of systolic BP among patients with diabetes and CAD was not associated with improved cardiovascular outcomes compared with usual control.clinicaltrials.gov Identifier: NCT00133692.","Tight blood pressure control and cardiovascular outcomes among hypertensive patients with diabetes and coronary artery disease."
"1263","JAMA.621","0.24",20606150,2010,"Hypertension guidelines advocate treating systolic blood pressure (BP) to less than 130 mm Hg for patients with diabetes mellitus; however, data are lacking for the growing population who also have coronary artery disease (CAD).To determine the association of systolic BP control achieved and adverse cardiovascular outcomes in a cohort of patients with diabetes and CAD.Observational subgroup analysis of 6400 of the 22,576 participants in the International Verapamil SR-Trandolapril Study (INVEST). For this analysis, participants were at least 50 years old and had diabetes and CAD. Participants were recruited between September 1997 and December 2000 from 862 sites in 14 countries and were followed up through March 2003 with an extended follow-up through August 2008 through the National Death Index for US participants.Patients received first-line treatment of either a calcium antagonist or beta-blocker followed by angiotensin-converting enzyme inhibitor, a diuretic, or both to achieve systolic BP of less than 130 and diastolic BP of less than 85 mm Hg. Patients were categorized as having tight control if they could maintain their systolic BP at less than 130 mm Hg; usual control if it ranged from 130 mm Hg to less than 140 mm Hg; and uncontrolled if it was 140 mm Hg or higher.Adverse cardiovascular outcomes, including the primary outcomes which was the first occurrence of all-cause death, nonfatal myocardial infarction, or nonfatal stroke.During 16,893 patient-years of follow-up, 286 patients (12.7%) who maintained tight control, 249 (12.6%) who had usual control, and 431 (19.8%) who had uncontrolled systolic BP experienced a primary outcome event. Patients in the usual-control group had a cardiovascular event rate of 12.6% vs a 19.8% event rate for those in the uncontrolled group (adjusted hazard ratio [HR], 1.46; 95% confidence interval [CI], 1.25-1.71; P < .001). However, little difference existed between those with usual control and those with tight control. Their respective event rates were 12.6% vs 12.7% (adjusted HR, 1.11; 95% CI, 0.93-1.32; P = .24). The all-cause mortality rate was 11.0% in the tight-control group vs 10.2% in the usual-control group (adjusted HR, 1.20; 95% CI, 0.99-1.45; P = .06); however, when extended follow-up was included, risk of all-cause mortality was 22.8% in the tight control vs 21.8% in the usual control group (adjusted HR, 1.15; 95% CI, 1.01-1.32; P = .04).Tight control of systolic BP among patients with diabetes and CAD was not associated with improved cardiovascular outcomes compared with usual control.clinicaltrials.gov Identifier: NCT00133692.","Tight blood pressure control and cardiovascular outcomes among hypertensive patients with diabetes and coronary artery disease."
"1264","JAMA.622","0.06",20606150,2010,"Hypertension guidelines advocate treating systolic blood pressure (BP) to less than 130 mm Hg for patients with diabetes mellitus; however, data are lacking for the growing population who also have coronary artery disease (CAD).To determine the association of systolic BP control achieved and adverse cardiovascular outcomes in a cohort of patients with diabetes and CAD.Observational subgroup analysis of 6400 of the 22,576 participants in the International Verapamil SR-Trandolapril Study (INVEST). For this analysis, participants were at least 50 years old and had diabetes and CAD. Participants were recruited between September 1997 and December 2000 from 862 sites in 14 countries and were followed up through March 2003 with an extended follow-up through August 2008 through the National Death Index for US participants.Patients received first-line treatment of either a calcium antagonist or beta-blocker followed by angiotensin-converting enzyme inhibitor, a diuretic, or both to achieve systolic BP of less than 130 and diastolic BP of less than 85 mm Hg. Patients were categorized as having tight control if they could maintain their systolic BP at less than 130 mm Hg; usual control if it ranged from 130 mm Hg to less than 140 mm Hg; and uncontrolled if it was 140 mm Hg or higher.Adverse cardiovascular outcomes, including the primary outcomes which was the first occurrence of all-cause death, nonfatal myocardial infarction, or nonfatal stroke.During 16,893 patient-years of follow-up, 286 patients (12.7%) who maintained tight control, 249 (12.6%) who had usual control, and 431 (19.8%) who had uncontrolled systolic BP experienced a primary outcome event. Patients in the usual-control group had a cardiovascular event rate of 12.6% vs a 19.8% event rate for those in the uncontrolled group (adjusted hazard ratio [HR], 1.46; 95% confidence interval [CI], 1.25-1.71; P < .001). However, little difference existed between those with usual control and those with tight control. Their respective event rates were 12.6% vs 12.7% (adjusted HR, 1.11; 95% CI, 0.93-1.32; P = .24). The all-cause mortality rate was 11.0% in the tight-control group vs 10.2% in the usual-control group (adjusted HR, 1.20; 95% CI, 0.99-1.45; P = .06); however, when extended follow-up was included, risk of all-cause mortality was 22.8% in the tight control vs 21.8% in the usual control group (adjusted HR, 1.15; 95% CI, 1.01-1.32; P = .04).Tight control of systolic BP among patients with diabetes and CAD was not associated with improved cardiovascular outcomes compared with usual control.clinicaltrials.gov Identifier: NCT00133692.","Tight blood pressure control and cardiovascular outcomes among hypertensive patients with diabetes and coronary artery disease."
"1265","JAMA.623","0.04",20606150,2010,"Hypertension guidelines advocate treating systolic blood pressure (BP) to less than 130 mm Hg for patients with diabetes mellitus; however, data are lacking for the growing population who also have coronary artery disease (CAD).To determine the association of systolic BP control achieved and adverse cardiovascular outcomes in a cohort of patients with diabetes and CAD.Observational subgroup analysis of 6400 of the 22,576 participants in the International Verapamil SR-Trandolapril Study (INVEST). For this analysis, participants were at least 50 years old and had diabetes and CAD. Participants were recruited between September 1997 and December 2000 from 862 sites in 14 countries and were followed up through March 2003 with an extended follow-up through August 2008 through the National Death Index for US participants.Patients received first-line treatment of either a calcium antagonist or beta-blocker followed by angiotensin-converting enzyme inhibitor, a diuretic, or both to achieve systolic BP of less than 130 and diastolic BP of less than 85 mm Hg. Patients were categorized as having tight control if they could maintain their systolic BP at less than 130 mm Hg; usual control if it ranged from 130 mm Hg to less than 140 mm Hg; and uncontrolled if it was 140 mm Hg or higher.Adverse cardiovascular outcomes, including the primary outcomes which was the first occurrence of all-cause death, nonfatal myocardial infarction, or nonfatal stroke.During 16,893 patient-years of follow-up, 286 patients (12.7%) who maintained tight control, 249 (12.6%) who had usual control, and 431 (19.8%) who had uncontrolled systolic BP experienced a primary outcome event. Patients in the usual-control group had a cardiovascular event rate of 12.6% vs a 19.8% event rate for those in the uncontrolled group (adjusted hazard ratio [HR], 1.46; 95% confidence interval [CI], 1.25-1.71; P < .001). However, little difference existed between those with usual control and those with tight control. Their respective event rates were 12.6% vs 12.7% (adjusted HR, 1.11; 95% CI, 0.93-1.32; P = .24). The all-cause mortality rate was 11.0% in the tight-control group vs 10.2% in the usual-control group (adjusted HR, 1.20; 95% CI, 0.99-1.45; P = .06); however, when extended follow-up was included, risk of all-cause mortality was 22.8% in the tight control vs 21.8% in the usual control group (adjusted HR, 1.15; 95% CI, 1.01-1.32; P = .04).Tight control of systolic BP among patients with diabetes and CAD was not associated with improved cardiovascular outcomes compared with usual control.clinicaltrials.gov Identifier: NCT00133692.","Tight blood pressure control and cardiovascular outcomes among hypertensive patients with diabetes and coronary artery disease."
"1266","JAMA.5741","0.001",20606151,2010,"Telomeres are essential to preserve the integrity of the genome. Critically short telomeres lead to replicative cell senescence and chromosomal instability and may thereby increase cancer risk.To determine the association between baseline telomere length and incident cancer and cancer mortality.Leukocyte telomere length was measured by quantitative polymerase chain reaction in 787 participants free of cancer at baseline in 1995 from the prospective, population-based Bruneck Study in Italy.Incident cancer and cancer mortality over a follow-up period of 10 years (1995-2005 with a follow-up rate of 100%).A total of 92 of 787 participants (11.7%) developed cancer (incidence rate, 13.3 per 1000 person-years). Short telomere length at baseline was associated with incident cancer independently of standard cancer risk factors (multivariable hazard ratio [HR] per 1-SD decrease in log(e)-transformed telomere length, 1.60; 95% confidence interval [CI], 1.30-1.98; P < .001). Compared with participants in the longest telomere length group, the multivariable HR for incident cancer was 2.15 (95% CI, 1.12-4.14) in the middle length group and 3.11 (95% CI, 1.65-5.84) in the shortest length group (P < .001). Incidence rates were 5.1 (95% CI, 2.9-8.7) per 1000 person-years in the longest telomere length group, 14.2 (95% CI, 10.0-20.1) per 1000 person-years in the middle length group, and 22.5 (95% CI, 16.9-29.9) per 1000 person-years in the shortest length group. The association equally applied to men and women and emerged as robust under a variety of circumstances. Furthermore, short telomere length was associated with cancer mortality (multivariable HR per 1-SD decrease in log(e)-transformed telomere length, 2.13; 95% CI, 1.58-2.86; P < .001) and individual cancer subtypes with a high fatality rate.In this study population, there was a statistically significant inverse relationship between telomere length and both cancer incidence and mortality.","Telomere length and risk of incident cancer and cancer mortality."
"1267","JAMA.5751","0.001",20606151,2010,"Telomeres are essential to preserve the integrity of the genome. Critically short telomeres lead to replicative cell senescence and chromosomal instability and may thereby increase cancer risk.To determine the association between baseline telomere length and incident cancer and cancer mortality.Leukocyte telomere length was measured by quantitative polymerase chain reaction in 787 participants free of cancer at baseline in 1995 from the prospective, population-based Bruneck Study in Italy.Incident cancer and cancer mortality over a follow-up period of 10 years (1995-2005 with a follow-up rate of 100%).A total of 92 of 787 participants (11.7%) developed cancer (incidence rate, 13.3 per 1000 person-years). Short telomere length at baseline was associated with incident cancer independently of standard cancer risk factors (multivariable hazard ratio [HR] per 1-SD decrease in log(e)-transformed telomere length, 1.60; 95% confidence interval [CI], 1.30-1.98; P < .001). Compared with participants in the longest telomere length group, the multivariable HR for incident cancer was 2.15 (95% CI, 1.12-4.14) in the middle length group and 3.11 (95% CI, 1.65-5.84) in the shortest length group (P < .001). Incidence rates were 5.1 (95% CI, 2.9-8.7) per 1000 person-years in the longest telomere length group, 14.2 (95% CI, 10.0-20.1) per 1000 person-years in the middle length group, and 22.5 (95% CI, 16.9-29.9) per 1000 person-years in the shortest length group. The association equally applied to men and women and emerged as robust under a variety of circumstances. Furthermore, short telomere length was associated with cancer mortality (multivariable HR per 1-SD decrease in log(e)-transformed telomere length, 2.13; 95% CI, 1.58-2.86; P < .001) and individual cancer subtypes with a high fatality rate.In this study population, there was a statistically significant inverse relationship between telomere length and both cancer incidence and mortality.","Telomere length and risk of incident cancer and cancer mortality."
"1268","Lancet.254","0.0039",20655105,2010,"HDL-cholesterol concentrations are inversely associated with occurrence of cardiovascular events. We addressed, using the JUPITER trial cohort, whether this association remains when LDL-cholesterol concentrations are reduced to the very low ranges with high-dose statin treatment.Participants in the randomised placebo-controlled JUPITER trial were adults without diabetes or previous cardiovascular disease, and had baseline concentrations of LDL cholesterol of less than 3.37 mmol/L and high-sensitivity C-reactive protein of 2 mg/L or more. Participants were randomly allocated by a computer-generated sequence to receive rosuvastatin 20 mg per day or placebo, with participants and adjudicators masked to treatment assignment. In the present analysis, we divided the participants into quartiles of HDL-cholesterol or apolipoprotein A1 and sought evidence of association between these quartiles and the JUPITER primary endpoint of first non-fatal myocardial infarction or stroke, hospitalisation for unstable angina, arterial revascularisation, or cardiovascular death. This trial is registered with ClinicalTrials.gov, number NCT00239681.For 17,802 patients in the JUPITER trial, rosuvastatin 20 mg per day reduced the incidence of the primary endpoint by 44% (p<0.0001). In 8901 (50%) patients given placebo (who had a median on-treatment LDL-cholesterol concentration of 2.80 mmol/L [IQR 2.43-3.24]), HDL-cholesterol concentrations were inversely related to vascular risk both at baseline (top quartile vs bottom quartile hazard ratio [HR] 0.54, 95% CI 0.35-0.83, p=0.0039) and on-treatment (0.55, 0.35-0.87, p=0.0047). By contrast, among the 8900 (50%) patients given rosuvastatin 20 mg (who had a median on-treatment LDL-cholesterol concentration of 1.42 mmol/L [IQR 1.14-1.86]), no significant relationships were noted between quartiles of HDL-cholesterol concentration and vascular risk either at baseline (1.12, 0.62-2.03, p=0.82) or on-treatment (1.03, 0.57-1.87, p=0.97). Our analyses for apolipoprotein A1 showed an equivalent strong relation to frequency of primary outcomes in the placebo group but little association in the rosuvastatin group.Although measurement of HDL-cholesterol concentration is useful as part of initial cardiovascular risk assessment, HDL-cholesterol concentrations are not predictive of residual vascular risk among patients treated with potent statin therapy who attain very low concentrations of LDL cholesterol.AstraZeneca.Copyright 2010 Elsevier Ltd. All rights reserved.","HDL cholesterol and residual risk of first cardiovascular events after treatment with potent statin therapy: an analysis from the JUPITER trial."
"1269","Lancet.255","0.0047",20655105,2010,"HDL-cholesterol concentrations are inversely associated with occurrence of cardiovascular events. We addressed, using the JUPITER trial cohort, whether this association remains when LDL-cholesterol concentrations are reduced to the very low ranges with high-dose statin treatment.Participants in the randomised placebo-controlled JUPITER trial were adults without diabetes or previous cardiovascular disease, and had baseline concentrations of LDL cholesterol of less than 3.37 mmol/L and high-sensitivity C-reactive protein of 2 mg/L or more. Participants were randomly allocated by a computer-generated sequence to receive rosuvastatin 20 mg per day or placebo, with participants and adjudicators masked to treatment assignment. In the present analysis, we divided the participants into quartiles of HDL-cholesterol or apolipoprotein A1 and sought evidence of association between these quartiles and the JUPITER primary endpoint of first non-fatal myocardial infarction or stroke, hospitalisation for unstable angina, arterial revascularisation, or cardiovascular death. This trial is registered with ClinicalTrials.gov, number NCT00239681.For 17,802 patients in the JUPITER trial, rosuvastatin 20 mg per day reduced the incidence of the primary endpoint by 44% (p<0.0001). In 8901 (50%) patients given placebo (who had a median on-treatment LDL-cholesterol concentration of 2.80 mmol/L [IQR 2.43-3.24]), HDL-cholesterol concentrations were inversely related to vascular risk both at baseline (top quartile vs bottom quartile hazard ratio [HR] 0.54, 95% CI 0.35-0.83, p=0.0039) and on-treatment (0.55, 0.35-0.87, p=0.0047). By contrast, among the 8900 (50%) patients given rosuvastatin 20 mg (who had a median on-treatment LDL-cholesterol concentration of 1.42 mmol/L [IQR 1.14-1.86]), no significant relationships were noted between quartiles of HDL-cholesterol concentration and vascular risk either at baseline (1.12, 0.62-2.03, p=0.82) or on-treatment (1.03, 0.57-1.87, p=0.97). Our analyses for apolipoprotein A1 showed an equivalent strong relation to frequency of primary outcomes in the placebo group but little association in the rosuvastatin group.Although measurement of HDL-cholesterol concentration is useful as part of initial cardiovascular risk assessment, HDL-cholesterol concentrations are not predictive of residual vascular risk among patients treated with potent statin therapy who attain very low concentrations of LDL cholesterol.AstraZeneca.Copyright 2010 Elsevier Ltd. All rights reserved.","HDL cholesterol and residual risk of first cardiovascular events after treatment with potent statin therapy: an analysis from the JUPITER trial."
"1270","Lancet.256","0.82",20655105,2010,"HDL-cholesterol concentrations are inversely associated with occurrence of cardiovascular events. We addressed, using the JUPITER trial cohort, whether this association remains when LDL-cholesterol concentrations are reduced to the very low ranges with high-dose statin treatment.Participants in the randomised placebo-controlled JUPITER trial were adults without diabetes or previous cardiovascular disease, and had baseline concentrations of LDL cholesterol of less than 3.37 mmol/L and high-sensitivity C-reactive protein of 2 mg/L or more. Participants were randomly allocated by a computer-generated sequence to receive rosuvastatin 20 mg per day or placebo, with participants and adjudicators masked to treatment assignment. In the present analysis, we divided the participants into quartiles of HDL-cholesterol or apolipoprotein A1 and sought evidence of association between these quartiles and the JUPITER primary endpoint of first non-fatal myocardial infarction or stroke, hospitalisation for unstable angina, arterial revascularisation, or cardiovascular death. This trial is registered with ClinicalTrials.gov, number NCT00239681.For 17,802 patients in the JUPITER trial, rosuvastatin 20 mg per day reduced the incidence of the primary endpoint by 44% (p<0.0001). In 8901 (50%) patients given placebo (who had a median on-treatment LDL-cholesterol concentration of 2.80 mmol/L [IQR 2.43-3.24]), HDL-cholesterol concentrations were inversely related to vascular risk both at baseline (top quartile vs bottom quartile hazard ratio [HR] 0.54, 95% CI 0.35-0.83, p=0.0039) and on-treatment (0.55, 0.35-0.87, p=0.0047). By contrast, among the 8900 (50%) patients given rosuvastatin 20 mg (who had a median on-treatment LDL-cholesterol concentration of 1.42 mmol/L [IQR 1.14-1.86]), no significant relationships were noted between quartiles of HDL-cholesterol concentration and vascular risk either at baseline (1.12, 0.62-2.03, p=0.82) or on-treatment (1.03, 0.57-1.87, p=0.97). Our analyses for apolipoprotein A1 showed an equivalent strong relation to frequency of primary outcomes in the placebo group but little association in the rosuvastatin group.Although measurement of HDL-cholesterol concentration is useful as part of initial cardiovascular risk assessment, HDL-cholesterol concentrations are not predictive of residual vascular risk among patients treated with potent statin therapy who attain very low concentrations of LDL cholesterol.AstraZeneca.Copyright 2010 Elsevier Ltd. All rights reserved.","HDL cholesterol and residual risk of first cardiovascular events after treatment with potent statin therapy: an analysis from the JUPITER trial."
"1271","Lancet.257","0.97",20655105,2010,"HDL-cholesterol concentrations are inversely associated with occurrence of cardiovascular events. We addressed, using the JUPITER trial cohort, whether this association remains when LDL-cholesterol concentrations are reduced to the very low ranges with high-dose statin treatment.Participants in the randomised placebo-controlled JUPITER trial were adults without diabetes or previous cardiovascular disease, and had baseline concentrations of LDL cholesterol of less than 3.37 mmol/L and high-sensitivity C-reactive protein of 2 mg/L or more. Participants were randomly allocated by a computer-generated sequence to receive rosuvastatin 20 mg per day or placebo, with participants and adjudicators masked to treatment assignment. In the present analysis, we divided the participants into quartiles of HDL-cholesterol or apolipoprotein A1 and sought evidence of association between these quartiles and the JUPITER primary endpoint of first non-fatal myocardial infarction or stroke, hospitalisation for unstable angina, arterial revascularisation, or cardiovascular death. This trial is registered with ClinicalTrials.gov, number NCT00239681.For 17,802 patients in the JUPITER trial, rosuvastatin 20 mg per day reduced the incidence of the primary endpoint by 44% (p<0.0001). In 8901 (50%) patients given placebo (who had a median on-treatment LDL-cholesterol concentration of 2.80 mmol/L [IQR 2.43-3.24]), HDL-cholesterol concentrations were inversely related to vascular risk both at baseline (top quartile vs bottom quartile hazard ratio [HR] 0.54, 95% CI 0.35-0.83, p=0.0039) and on-treatment (0.55, 0.35-0.87, p=0.0047). By contrast, among the 8900 (50%) patients given rosuvastatin 20 mg (who had a median on-treatment LDL-cholesterol concentration of 1.42 mmol/L [IQR 1.14-1.86]), no significant relationships were noted between quartiles of HDL-cholesterol concentration and vascular risk either at baseline (1.12, 0.62-2.03, p=0.82) or on-treatment (1.03, 0.57-1.87, p=0.97). Our analyses for apolipoprotein A1 showed an equivalent strong relation to frequency of primary outcomes in the placebo group but little association in the rosuvastatin group.Although measurement of HDL-cholesterol concentration is useful as part of initial cardiovascular risk assessment, HDL-cholesterol concentrations are not predictive of residual vascular risk among patients treated with potent statin therapy who attain very low concentrations of LDL cholesterol.AstraZeneca.Copyright 2010 Elsevier Ltd. All rights reserved.","HDL cholesterol and residual risk of first cardiovascular events after treatment with potent statin therapy: an analysis from the JUPITER trial."
"1272","JAMA.545","0.001",20664043,2010,"There is limited evidence on how the risk of breast cancer and its subtypes depend on low-penetrance susceptibility loci, individually or in combination.To analyze breast cancer risk, overall and by tumor subtype, in relation to 14 individual single-nucleotide polymorphisms (SNPs) previously linked to the disease, and in relation to a polygenic risk score.Study of 10,306 women with breast cancer (mean age at diagnosis, 58 years) and 10,393 women without breast cancer who in 2005-2008 provided blood samples for genotyping in a large prospective study of UK women; and meta-analysis of these results and of other published results.Estimated per-allele odds ratio (OR) for individual SNPs, and cumulative incidence of breast cancer to age 70 years in relation to a polygenic risk score based on the 4, 7, or 10 SNPs most strongly associated with risk.Odds ratios for breast cancer were greatest for FGFR2-rs2981582 and TNRC9-rs3803662 and, for these 2 SNPs, were significantly greater for estrogen receptor (ER)-positive than for ER-negative disease, both in our data and in meta-analyses of all published data (pooled per-allele ORs [95% confidence intervals] for ER-positive vs ER-negative disease: 1.30 [1.26-1.33] vs 1.05 [1.01-1.10] for FGFR2; interaction P < .001; and 1.24 [1.21-1.28] vs 1.12 [1.07-1.17] for TNRC9; interaction P < .001). The next strongest association was for 2q-rs13387042, for which the per-allele OR was significantly greater for bilateral than unilateral disease (1.39 [1.21-1.60] vs 1.15 [1.11-1.20]; interaction P = .008) and for lobular than ductal tumors (1.35 [1.23-1.49] vs 1.10 [1.05-1.15]; interaction P < .001). The estimated cumulative incidence (95% confidence interval) of breast cancer to age 70 years among women in the top and bottom fifths of a polygenic risk score based on 7 SNPs was 8.8% (8.3%-9.4%) and 4.4% (4.2%-4.8%), respectively. For ER-positive disease the corresponding risks were 7.4% (6.9%-8.0%) and 3.4% (3.1%-3.8%), respectively; while for ER-negative disease they were 1.4% (1.2%-1.6%) and 1.0% (0.8%-1.2%). The findings did not differ materially according to the number of SNPs included in the polygenic risk model.The polygenic risk score was substantially more predictive of ER-positive than of ER-negative breast cancer, particularly for absolute risk.","Incidence of breast cancer and its subtypes in relation to individual and multiple low-penetrance genetic susceptibility loci."
"1273","JAMA.546","0.001",20664043,2010,"There is limited evidence on how the risk of breast cancer and its subtypes depend on low-penetrance susceptibility loci, individually or in combination.To analyze breast cancer risk, overall and by tumor subtype, in relation to 14 individual single-nucleotide polymorphisms (SNPs) previously linked to the disease, and in relation to a polygenic risk score.Study of 10,306 women with breast cancer (mean age at diagnosis, 58 years) and 10,393 women without breast cancer who in 2005-2008 provided blood samples for genotyping in a large prospective study of UK women; and meta-analysis of these results and of other published results.Estimated per-allele odds ratio (OR) for individual SNPs, and cumulative incidence of breast cancer to age 70 years in relation to a polygenic risk score based on the 4, 7, or 10 SNPs most strongly associated with risk.Odds ratios for breast cancer were greatest for FGFR2-rs2981582 and TNRC9-rs3803662 and, for these 2 SNPs, were significantly greater for estrogen receptor (ER)-positive than for ER-negative disease, both in our data and in meta-analyses of all published data (pooled per-allele ORs [95% confidence intervals] for ER-positive vs ER-negative disease: 1.30 [1.26-1.33] vs 1.05 [1.01-1.10] for FGFR2; interaction P < .001; and 1.24 [1.21-1.28] vs 1.12 [1.07-1.17] for TNRC9; interaction P < .001). The next strongest association was for 2q-rs13387042, for which the per-allele OR was significantly greater for bilateral than unilateral disease (1.39 [1.21-1.60] vs 1.15 [1.11-1.20]; interaction P = .008) and for lobular than ductal tumors (1.35 [1.23-1.49] vs 1.10 [1.05-1.15]; interaction P < .001). The estimated cumulative incidence (95% confidence interval) of breast cancer to age 70 years among women in the top and bottom fifths of a polygenic risk score based on 7 SNPs was 8.8% (8.3%-9.4%) and 4.4% (4.2%-4.8%), respectively. For ER-positive disease the corresponding risks were 7.4% (6.9%-8.0%) and 3.4% (3.1%-3.8%), respectively; while for ER-negative disease they were 1.4% (1.2%-1.6%) and 1.0% (0.8%-1.2%). The findings did not differ materially according to the number of SNPs included in the polygenic risk model.The polygenic risk score was substantially more predictive of ER-positive than of ER-negative breast cancer, particularly for absolute risk.","Incidence of breast cancer and its subtypes in relation to individual and multiple low-penetrance genetic susceptibility loci."
"1274","JAMA.547","0.001",20664043,2010,"There is limited evidence on how the risk of breast cancer and its subtypes depend on low-penetrance susceptibility loci, individually or in combination.To analyze breast cancer risk, overall and by tumor subtype, in relation to 14 individual single-nucleotide polymorphisms (SNPs) previously linked to the disease, and in relation to a polygenic risk score.Study of 10,306 women with breast cancer (mean age at diagnosis, 58 years) and 10,393 women without breast cancer who in 2005-2008 provided blood samples for genotyping in a large prospective study of UK women; and meta-analysis of these results and of other published results.Estimated per-allele odds ratio (OR) for individual SNPs, and cumulative incidence of breast cancer to age 70 years in relation to a polygenic risk score based on the 4, 7, or 10 SNPs most strongly associated with risk.Odds ratios for breast cancer were greatest for FGFR2-rs2981582 and TNRC9-rs3803662 and, for these 2 SNPs, were significantly greater for estrogen receptor (ER)-positive than for ER-negative disease, both in our data and in meta-analyses of all published data (pooled per-allele ORs [95% confidence intervals] for ER-positive vs ER-negative disease: 1.30 [1.26-1.33] vs 1.05 [1.01-1.10] for FGFR2; interaction P < .001; and 1.24 [1.21-1.28] vs 1.12 [1.07-1.17] for TNRC9; interaction P < .001). The next strongest association was for 2q-rs13387042, for which the per-allele OR was significantly greater for bilateral than unilateral disease (1.39 [1.21-1.60] vs 1.15 [1.11-1.20]; interaction P = .008) and for lobular than ductal tumors (1.35 [1.23-1.49] vs 1.10 [1.05-1.15]; interaction P < .001). The estimated cumulative incidence (95% confidence interval) of breast cancer to age 70 years among women in the top and bottom fifths of a polygenic risk score based on 7 SNPs was 8.8% (8.3%-9.4%) and 4.4% (4.2%-4.8%), respectively. For ER-positive disease the corresponding risks were 7.4% (6.9%-8.0%) and 3.4% (3.1%-3.8%), respectively; while for ER-negative disease they were 1.4% (1.2%-1.6%) and 1.0% (0.8%-1.2%). The findings did not differ materially according to the number of SNPs included in the polygenic risk model.The polygenic risk score was substantially more predictive of ER-positive than of ER-negative breast cancer, particularly for absolute risk.","Incidence of breast cancer and its subtypes in relation to individual and multiple low-penetrance genetic susceptibility loci."
"1275","JAMA.577","0.008",20664043,2010,"There is limited evidence on how the risk of breast cancer and its subtypes depend on low-penetrance susceptibility loci, individually or in combination.To analyze breast cancer risk, overall and by tumor subtype, in relation to 14 individual single-nucleotide polymorphisms (SNPs) previously linked to the disease, and in relation to a polygenic risk score.Study of 10,306 women with breast cancer (mean age at diagnosis, 58 years) and 10,393 women without breast cancer who in 2005-2008 provided blood samples for genotyping in a large prospective study of UK women; and meta-analysis of these results and of other published results.Estimated per-allele odds ratio (OR) for individual SNPs, and cumulative incidence of breast cancer to age 70 years in relation to a polygenic risk score based on the 4, 7, or 10 SNPs most strongly associated with risk.Odds ratios for breast cancer were greatest for FGFR2-rs2981582 and TNRC9-rs3803662 and, for these 2 SNPs, were significantly greater for estrogen receptor (ER)-positive than for ER-negative disease, both in our data and in meta-analyses of all published data (pooled per-allele ORs [95% confidence intervals] for ER-positive vs ER-negative disease: 1.30 [1.26-1.33] vs 1.05 [1.01-1.10] for FGFR2; interaction P < .001; and 1.24 [1.21-1.28] vs 1.12 [1.07-1.17] for TNRC9; interaction P < .001). The next strongest association was for 2q-rs13387042, for which the per-allele OR was significantly greater for bilateral than unilateral disease (1.39 [1.21-1.60] vs 1.15 [1.11-1.20]; interaction P = .008) and for lobular than ductal tumors (1.35 [1.23-1.49] vs 1.10 [1.05-1.15]; interaction P < .001). The estimated cumulative incidence (95% confidence interval) of breast cancer to age 70 years among women in the top and bottom fifths of a polygenic risk score based on 7 SNPs was 8.8% (8.3%-9.4%) and 4.4% (4.2%-4.8%), respectively. For ER-positive disease the corresponding risks were 7.4% (6.9%-8.0%) and 3.4% (3.1%-3.8%), respectively; while for ER-negative disease they were 1.4% (1.2%-1.6%) and 1.0% (0.8%-1.2%). The findings did not differ materially according to the number of SNPs included in the polygenic risk model.The polygenic risk score was substantially more predictive of ER-positive than of ER-negative breast cancer, particularly for absolute risk.","Incidence of breast cancer and its subtypes in relation to individual and multiple low-penetrance genetic susceptibility loci."
"1276","JAMA.544","0.001",20736470,2010,"Observational studies have previously reported that elective intra-aortic balloon pump (IABP) insertion may improve outcomes following high-risk percutaneous coronary intervention (PCI). To date, this assertion has not been tested in a randomized trial.To determine whether routine intra-aortic balloon counterpulsation before PCI reduces major adverse cardiac and cardiovascular events (MACCE) in patients with severe left ventricular dysfunction and extensive coronary disease.The Balloon Pump-Assisted Coronary Intervention Study, a prospective, open, multicenter, randomized controlled trial conducted in 17 tertiary referral cardiac centers in the United Kingdom between December 2005 and January 2009. Patients (n = 301) had severe left ventricular dysfunction (ejection fraction < or = 30%) and extensive coronary disease (Jeopardy Score > or = 8/12); those with contraindications to or class I indications for IABP therapy were excluded.Elective insertion of IABP before PCI.Primary end point was MACCE, defined as death, acute myocardial infarction, cerebrovascular event, or further revascularization at hospital discharge (capped at 28 days). Secondary end points included all-cause mortality at 6 months, major procedural complications, bleeding, and access-site complications.MACCE at hospital discharge occurred in 15.2% (23/151) of the elective IABP and 16.0% (24/150) of the no planned IABP groups (P = .85; odds ratio [OR], 0.94 [95% confidence interval {CI}, 0.51-1.76]). All-cause mortality at 6 months was 4.6% and 7.4% in the respective groups (P = .32; OR, 0.61 [95% CI, 0.24-1.62]). Fewer major procedural complications occurred with elective IABP insertion compared with no planned IABP use (1.3% vs 10.7%, P < .001; OR, 0.11 [95% CI, 0.01-0.49]). Major or minor bleeding occurred in 19.2% and 11.3% (P = .06; OR, 1.86 [95% CI, 0.93-3.79]) and access-site complications in 3.3% and 0% (P = .06) of the elective and no planned IABP groups, respectively.Elective IABP insertion did not reduce the incidence of MACCE following PCI. These results do not support a strategy of routine IABP placement before PCI in all patients with severe left ventricular dysfunction and extensive coronary disease.isrctn.org Identifier: ISRCTN40553718; clinicaltrials.gov Identifier: NCT00910481.","Elective intra-aortic balloon counterpulsation during high-risk percutaneous coronary intervention: a randomized controlled trial."
"1277","JAMA.567","0.85",20736470,2010,"Observational studies have previously reported that elective intra-aortic balloon pump (IABP) insertion may improve outcomes following high-risk percutaneous coronary intervention (PCI). To date, this assertion has not been tested in a randomized trial.To determine whether routine intra-aortic balloon counterpulsation before PCI reduces major adverse cardiac and cardiovascular events (MACCE) in patients with severe left ventricular dysfunction and extensive coronary disease.The Balloon Pump-Assisted Coronary Intervention Study, a prospective, open, multicenter, randomized controlled trial conducted in 17 tertiary referral cardiac centers in the United Kingdom between December 2005 and January 2009. Patients (n = 301) had severe left ventricular dysfunction (ejection fraction < or = 30%) and extensive coronary disease (Jeopardy Score > or = 8/12); those with contraindications to or class I indications for IABP therapy were excluded.Elective insertion of IABP before PCI.Primary end point was MACCE, defined as death, acute myocardial infarction, cerebrovascular event, or further revascularization at hospital discharge (capped at 28 days). Secondary end points included all-cause mortality at 6 months, major procedural complications, bleeding, and access-site complications.MACCE at hospital discharge occurred in 15.2% (23/151) of the elective IABP and 16.0% (24/150) of the no planned IABP groups (P = .85; odds ratio [OR], 0.94 [95% confidence interval {CI}, 0.51-1.76]). All-cause mortality at 6 months was 4.6% and 7.4% in the respective groups (P = .32; OR, 0.61 [95% CI, 0.24-1.62]). Fewer major procedural complications occurred with elective IABP insertion compared with no planned IABP use (1.3% vs 10.7%, P < .001; OR, 0.11 [95% CI, 0.01-0.49]). Major or minor bleeding occurred in 19.2% and 11.3% (P = .06; OR, 1.86 [95% CI, 0.93-3.79]) and access-site complications in 3.3% and 0% (P = .06) of the elective and no planned IABP groups, respectively.Elective IABP insertion did not reduce the incidence of MACCE following PCI. These results do not support a strategy of routine IABP placement before PCI in all patients with severe left ventricular dysfunction and extensive coronary disease.isrctn.org Identifier: ISRCTN40553718; clinicaltrials.gov Identifier: NCT00910481.","Elective intra-aortic balloon counterpulsation during high-risk percutaneous coronary intervention: a randomized controlled trial."
"1278","JAMA.568","0.32",20736470,2010,"Observational studies have previously reported that elective intra-aortic balloon pump (IABP) insertion may improve outcomes following high-risk percutaneous coronary intervention (PCI). To date, this assertion has not been tested in a randomized trial.To determine whether routine intra-aortic balloon counterpulsation before PCI reduces major adverse cardiac and cardiovascular events (MACCE) in patients with severe left ventricular dysfunction and extensive coronary disease.The Balloon Pump-Assisted Coronary Intervention Study, a prospective, open, multicenter, randomized controlled trial conducted in 17 tertiary referral cardiac centers in the United Kingdom between December 2005 and January 2009. Patients (n = 301) had severe left ventricular dysfunction (ejection fraction < or = 30%) and extensive coronary disease (Jeopardy Score > or = 8/12); those with contraindications to or class I indications for IABP therapy were excluded.Elective insertion of IABP before PCI.Primary end point was MACCE, defined as death, acute myocardial infarction, cerebrovascular event, or further revascularization at hospital discharge (capped at 28 days). Secondary end points included all-cause mortality at 6 months, major procedural complications, bleeding, and access-site complications.MACCE at hospital discharge occurred in 15.2% (23/151) of the elective IABP and 16.0% (24/150) of the no planned IABP groups (P = .85; odds ratio [OR], 0.94 [95% confidence interval {CI}, 0.51-1.76]). All-cause mortality at 6 months was 4.6% and 7.4% in the respective groups (P = .32; OR, 0.61 [95% CI, 0.24-1.62]). Fewer major procedural complications occurred with elective IABP insertion compared with no planned IABP use (1.3% vs 10.7%, P < .001; OR, 0.11 [95% CI, 0.01-0.49]). Major or minor bleeding occurred in 19.2% and 11.3% (P = .06; OR, 1.86 [95% CI, 0.93-3.79]) and access-site complications in 3.3% and 0% (P = .06) of the elective and no planned IABP groups, respectively.Elective IABP insertion did not reduce the incidence of MACCE following PCI. These results do not support a strategy of routine IABP placement before PCI in all patients with severe left ventricular dysfunction and extensive coronary disease.isrctn.org Identifier: ISRCTN40553718; clinicaltrials.gov Identifier: NCT00910481.","Elective intra-aortic balloon counterpulsation during high-risk percutaneous coronary intervention: a randomized controlled trial."
"1279","JAMA.569","0.06",20736470,2010,"Observational studies have previously reported that elective intra-aortic balloon pump (IABP) insertion may improve outcomes following high-risk percutaneous coronary intervention (PCI). To date, this assertion has not been tested in a randomized trial.To determine whether routine intra-aortic balloon counterpulsation before PCI reduces major adverse cardiac and cardiovascular events (MACCE) in patients with severe left ventricular dysfunction and extensive coronary disease.The Balloon Pump-Assisted Coronary Intervention Study, a prospective, open, multicenter, randomized controlled trial conducted in 17 tertiary referral cardiac centers in the United Kingdom between December 2005 and January 2009. Patients (n = 301) had severe left ventricular dysfunction (ejection fraction < or = 30%) and extensive coronary disease (Jeopardy Score > or = 8/12); those with contraindications to or class I indications for IABP therapy were excluded.Elective insertion of IABP before PCI.Primary end point was MACCE, defined as death, acute myocardial infarction, cerebrovascular event, or further revascularization at hospital discharge (capped at 28 days). Secondary end points included all-cause mortality at 6 months, major procedural complications, bleeding, and access-site complications.MACCE at hospital discharge occurred in 15.2% (23/151) of the elective IABP and 16.0% (24/150) of the no planned IABP groups (P = .85; odds ratio [OR], 0.94 [95% confidence interval {CI}, 0.51-1.76]). All-cause mortality at 6 months was 4.6% and 7.4% in the respective groups (P = .32; OR, 0.61 [95% CI, 0.24-1.62]). Fewer major procedural complications occurred with elective IABP insertion compared with no planned IABP use (1.3% vs 10.7%, P < .001; OR, 0.11 [95% CI, 0.01-0.49]). Major or minor bleeding occurred in 19.2% and 11.3% (P = .06; OR, 1.86 [95% CI, 0.93-3.79]) and access-site complications in 3.3% and 0% (P = .06) of the elective and no planned IABP groups, respectively.Elective IABP insertion did not reduce the incidence of MACCE following PCI. These results do not support a strategy of routine IABP placement before PCI in all patients with severe left ventricular dysfunction and extensive coronary disease.isrctn.org Identifier: ISRCTN40553718; clinicaltrials.gov Identifier: NCT00910481.","Elective intra-aortic balloon counterpulsation during high-risk percutaneous coronary intervention: a randomized controlled trial."
"1280","JAMA.565","0.01",20736471,2010,"Attention-deficit/hyperactivity disorder (ADHD) in adulthood is a prevalent, distressing, and impairing condition that is not fully treated by pharmacotherapy alone and lacks evidence-based psychosocial treatments.To test cognitive behavioral therapy for ADHD in adults treated with medication but who still have clinically significant symptoms.Randomized controlled trial assessing the efficacy of cognitive behavioral therapy for 86 symptomatic adults with ADHD who were already being treated with medication. The study was conducted at a US hospital between November 2004 and June 2008 (follow-up was conducted through July 2009). Of the 86 patients randomized, 79 completed treatment and 70 completed the follow-up assessments.Patients were randomized to 12 individual sessions of either cognitive behavioral therapy or relaxation with educational support (which is an attention-matched comparison).The primary measures were ADHD symptoms rated by an assessor (ADHD rating scale and Clinical Global Impression scale) at baseline, posttreatment, and at 6- and 12-month follow-up. The assessor was blinded to treatment condition assignment. The secondary outcome measure was self-report of ADHD symptoms.Cognitive behavioral therapy achieved lower posttreatment scores on both the Clinical Global Impression scale (magnitude -0.0531; 95% confidence interval [CI], -1.01 to -0.05; P = .03) and the ADHD rating scale (magnitude -4.631; 95% CI, -8.30 to -0.963; P = .02) compared with relaxation with educational support. Throughout treatment, self-reported symptoms were also significantly more improved for cognitive behavioral therapy (beta = -0.41; 95% CI, -0.64 to -0.17; P <001), and there were more treatment responders in cognitive behavioral therapy for both the Clinical Global Impression scale (53% vs 23%; odds ratio [OR], 3.80; 95% CI, 1.50 to 9.59; P = .01) and the ADHD rating scale (67% vs 33%; OR, 4.29; 95% CI, 1.74 to 10.58; P = .002). Responders and partial responders in the cognitive behavioral therapy condition maintained their gains over 6 and 12 months.Among adults with persistent ADHD symptoms treated with medication, the use of cognitive behavioral therapy compared with relaxation with educational support resulted in improved ADHD symptoms, which were maintained at 12 months.clinicaltrials.gov Identifier: NCT00118911.","Cognitive behavioral therapy vs relaxation with educational support for medication-treated adults with ADHD and persistent symptoms: a randomized controlled trial."
"1281","JAMA.566","0.002",20736471,2010,"Attention-deficit/hyperactivity disorder (ADHD) in adulthood is a prevalent, distressing, and impairing condition that is not fully treated by pharmacotherapy alone and lacks evidence-based psychosocial treatments.To test cognitive behavioral therapy for ADHD in adults treated with medication but who still have clinically significant symptoms.Randomized controlled trial assessing the efficacy of cognitive behavioral therapy for 86 symptomatic adults with ADHD who were already being treated with medication. The study was conducted at a US hospital between November 2004 and June 2008 (follow-up was conducted through July 2009). Of the 86 patients randomized, 79 completed treatment and 70 completed the follow-up assessments.Patients were randomized to 12 individual sessions of either cognitive behavioral therapy or relaxation with educational support (which is an attention-matched comparison).The primary measures were ADHD symptoms rated by an assessor (ADHD rating scale and Clinical Global Impression scale) at baseline, posttreatment, and at 6- and 12-month follow-up. The assessor was blinded to treatment condition assignment. The secondary outcome measure was self-report of ADHD symptoms.Cognitive behavioral therapy achieved lower posttreatment scores on both the Clinical Global Impression scale (magnitude -0.0531; 95% confidence interval [CI], -1.01 to -0.05; P = .03) and the ADHD rating scale (magnitude -4.631; 95% CI, -8.30 to -0.963; P = .02) compared with relaxation with educational support. Throughout treatment, self-reported symptoms were also significantly more improved for cognitive behavioral therapy (beta = -0.41; 95% CI, -0.64 to -0.17; P <001), and there were more treatment responders in cognitive behavioral therapy for both the Clinical Global Impression scale (53% vs 23%; odds ratio [OR], 3.80; 95% CI, 1.50 to 9.59; P = .01) and the ADHD rating scale (67% vs 33%; OR, 4.29; 95% CI, 1.74 to 10.58; P = .002). Responders and partial responders in the cognitive behavioral therapy condition maintained their gains over 6 and 12 months.Among adults with persistent ADHD symptoms treated with medication, the use of cognitive behavioral therapy compared with relaxation with educational support resulted in improved ADHD symptoms, which were maintained at 12 months.clinicaltrials.gov Identifier: NCT00118911.","Cognitive behavioral therapy vs relaxation with educational support for medication-treated adults with ADHD and persistent symptoms: a randomized controlled trial."
"1282","JAMA.617","0.003",20736472,2010,"Protein kinase C-beta (PKC-beta) is a cell-signaling intermediate implicated in development of diabetic complications.To examine the risk association of PKC-beta 1 gene (PRKCB1) polymorphisms and end-stage renal disease (ESRD) in an 8-year prospective cohort of Chinese patients with type 2 diabetes.We genotyped 18 common tag single-nucleotide polymorphisms (SNPs) that span the PRKCB1 gene (r(2) = 0.80) in 1172 Chinese patients (recruited 1995-1998) without renal disease at baseline. A validation cohort included an additional 1049 patients with early-onset diabetes who were free of renal disease at baseline and were recruited after 1998.Associations of PRKCB1 polymorphisms under additive, dominant, and recessive genetic models with new onset of ESRD (defined as estimated glomerular filtration rate <15 mL/min/1.73 m(2) or dialysis or renal-related death) were assessed by Cox proportional hazard regression, adjusted for all conventional risk factors including use of medications.After a mean (SD) of 7.9 (1.9) years, 90 patients (7.7%) progressed to ESRD. Four common SNPs were associated with ESRD (P < .05). The closely linked T allele at rs3760106 and G allele rs2575390 (r(2) = 0.98) showed the strongest association with ESRD (hazard ratio [HR], 2.25; 95% confidence interval [CI], 1.31-3.87; P = .003, and HR, 2.26; 95% CI, 1.31-3.88; P = .003, respectively). Four common variants predicted ESRD in separate models. The HR for ESRD increased with increasing number of risk alleles (P < .001) in the joint effect analysis. The adjusted risk for ESRD was 6.04 (95% CI, 2.00-18.31) for patients with 4 risk alleles compared with patients with 0 or 1 risk allele. Incidence was 4.4 per 1000 person-years (95% CI, 0.5-8.2) among individuals with 0 or 1 risk allele compared with 20.0 per 1000 person-years (95% CI, 8.8-31.1) in those carrying 4 risk alleles (6.9% of the cohort). These results were validated in a separate prospective cohort of young-onset diabetic patients. Of 1049 patients in the validation cohort, 151 (14.3%) developed chronic kidney disease (CKD) during follow-up, and there were significant associations between both the T allele of rs3760106 and the G allele of rs2575390 and development of CKD (HR, 1.68; 95% CI, 1.10-2.57; P = .02, and HR, 1.62; 95% CI, 1.07-2.47; P = .02, respectively).Genetic variants in the PRKCB1 gene were independently associated with development of ESRD in Chinese patients with type 2 diabetes.","Genetic variants of the protein kinase C-beta 1 gene and development of end-stage renal disease in patients with type 2 diabetes."
"1283","JAMA.618","0.003",20736472,2010,"Protein kinase C-beta (PKC-beta) is a cell-signaling intermediate implicated in development of diabetic complications.To examine the risk association of PKC-beta 1 gene (PRKCB1) polymorphisms and end-stage renal disease (ESRD) in an 8-year prospective cohort of Chinese patients with type 2 diabetes.We genotyped 18 common tag single-nucleotide polymorphisms (SNPs) that span the PRKCB1 gene (r(2) = 0.80) in 1172 Chinese patients (recruited 1995-1998) without renal disease at baseline. A validation cohort included an additional 1049 patients with early-onset diabetes who were free of renal disease at baseline and were recruited after 1998.Associations of PRKCB1 polymorphisms under additive, dominant, and recessive genetic models with new onset of ESRD (defined as estimated glomerular filtration rate <15 mL/min/1.73 m(2) or dialysis or renal-related death) were assessed by Cox proportional hazard regression, adjusted for all conventional risk factors including use of medications.After a mean (SD) of 7.9 (1.9) years, 90 patients (7.7%) progressed to ESRD. Four common SNPs were associated with ESRD (P < .05). The closely linked T allele at rs3760106 and G allele rs2575390 (r(2) = 0.98) showed the strongest association with ESRD (hazard ratio [HR], 2.25; 95% confidence interval [CI], 1.31-3.87; P = .003, and HR, 2.26; 95% CI, 1.31-3.88; P = .003, respectively). Four common variants predicted ESRD in separate models. The HR for ESRD increased with increasing number of risk alleles (P < .001) in the joint effect analysis. The adjusted risk for ESRD was 6.04 (95% CI, 2.00-18.31) for patients with 4 risk alleles compared with patients with 0 or 1 risk allele. Incidence was 4.4 per 1000 person-years (95% CI, 0.5-8.2) among individuals with 0 or 1 risk allele compared with 20.0 per 1000 person-years (95% CI, 8.8-31.1) in those carrying 4 risk alleles (6.9% of the cohort). These results were validated in a separate prospective cohort of young-onset diabetic patients. Of 1049 patients in the validation cohort, 151 (14.3%) developed chronic kidney disease (CKD) during follow-up, and there were significant associations between both the T allele of rs3760106 and the G allele of rs2575390 and development of CKD (HR, 1.68; 95% CI, 1.10-2.57; P = .02, and HR, 1.62; 95% CI, 1.07-2.47; P = .02, respectively).Genetic variants in the PRKCB1 gene were independently associated with development of ESRD in Chinese patients with type 2 diabetes.","Genetic variants of the protein kinase C-beta 1 gene and development of end-stage renal disease in patients with type 2 diabetes."
"1284","JAMA.619","0.02",20736472,2010,"Protein kinase C-beta (PKC-beta) is a cell-signaling intermediate implicated in development of diabetic complications.To examine the risk association of PKC-beta 1 gene (PRKCB1) polymorphisms and end-stage renal disease (ESRD) in an 8-year prospective cohort of Chinese patients with type 2 diabetes.We genotyped 18 common tag single-nucleotide polymorphisms (SNPs) that span the PRKCB1 gene (r(2) = 0.80) in 1172 Chinese patients (recruited 1995-1998) without renal disease at baseline. A validation cohort included an additional 1049 patients with early-onset diabetes who were free of renal disease at baseline and were recruited after 1998.Associations of PRKCB1 polymorphisms under additive, dominant, and recessive genetic models with new onset of ESRD (defined as estimated glomerular filtration rate <15 mL/min/1.73 m(2) or dialysis or renal-related death) were assessed by Cox proportional hazard regression, adjusted for all conventional risk factors including use of medications.After a mean (SD) of 7.9 (1.9) years, 90 patients (7.7%) progressed to ESRD. Four common SNPs were associated with ESRD (P < .05). The closely linked T allele at rs3760106 and G allele rs2575390 (r(2) = 0.98) showed the strongest association with ESRD (hazard ratio [HR], 2.25; 95% confidence interval [CI], 1.31-3.87; P = .003, and HR, 2.26; 95% CI, 1.31-3.88; P = .003, respectively). Four common variants predicted ESRD in separate models. The HR for ESRD increased with increasing number of risk alleles (P < .001) in the joint effect analysis. The adjusted risk for ESRD was 6.04 (95% CI, 2.00-18.31) for patients with 4 risk alleles compared with patients with 0 or 1 risk allele. Incidence was 4.4 per 1000 person-years (95% CI, 0.5-8.2) among individuals with 0 or 1 risk allele compared with 20.0 per 1000 person-years (95% CI, 8.8-31.1) in those carrying 4 risk alleles (6.9% of the cohort). These results were validated in a separate prospective cohort of young-onset diabetic patients. Of 1049 patients in the validation cohort, 151 (14.3%) developed chronic kidney disease (CKD) during follow-up, and there were significant associations between both the T allele of rs3760106 and the G allele of rs2575390 and development of CKD (HR, 1.68; 95% CI, 1.10-2.57; P = .02, and HR, 1.62; 95% CI, 1.07-2.47; P = .02, respectively).Genetic variants in the PRKCB1 gene were independently associated with development of ESRD in Chinese patients with type 2 diabetes.","Genetic variants of the protein kinase C-beta 1 gene and development of end-stage renal disease in patients with type 2 diabetes."
"1285","JAMA.620","0.02",20736472,2010,"Protein kinase C-beta (PKC-beta) is a cell-signaling intermediate implicated in development of diabetic complications.To examine the risk association of PKC-beta 1 gene (PRKCB1) polymorphisms and end-stage renal disease (ESRD) in an 8-year prospective cohort of Chinese patients with type 2 diabetes.We genotyped 18 common tag single-nucleotide polymorphisms (SNPs) that span the PRKCB1 gene (r(2) = 0.80) in 1172 Chinese patients (recruited 1995-1998) without renal disease at baseline. A validation cohort included an additional 1049 patients with early-onset diabetes who were free of renal disease at baseline and were recruited after 1998.Associations of PRKCB1 polymorphisms under additive, dominant, and recessive genetic models with new onset of ESRD (defined as estimated glomerular filtration rate <15 mL/min/1.73 m(2) or dialysis or renal-related death) were assessed by Cox proportional hazard regression, adjusted for all conventional risk factors including use of medications.After a mean (SD) of 7.9 (1.9) years, 90 patients (7.7%) progressed to ESRD. Four common SNPs were associated with ESRD (P < .05). The closely linked T allele at rs3760106 and G allele rs2575390 (r(2) = 0.98) showed the strongest association with ESRD (hazard ratio [HR], 2.25; 95% confidence interval [CI], 1.31-3.87; P = .003, and HR, 2.26; 95% CI, 1.31-3.88; P = .003, respectively). Four common variants predicted ESRD in separate models. The HR for ESRD increased with increasing number of risk alleles (P < .001) in the joint effect analysis. The adjusted risk for ESRD was 6.04 (95% CI, 2.00-18.31) for patients with 4 risk alleles compared with patients with 0 or 1 risk allele. Incidence was 4.4 per 1000 person-years (95% CI, 0.5-8.2) among individuals with 0 or 1 risk allele compared with 20.0 per 1000 person-years (95% CI, 8.8-31.1) in those carrying 4 risk alleles (6.9% of the cohort). These results were validated in a separate prospective cohort of young-onset diabetic patients. Of 1049 patients in the validation cohort, 151 (14.3%) developed chronic kidney disease (CKD) during follow-up, and there were significant associations between both the T allele of rs3760106 and the G allele of rs2575390 and development of CKD (HR, 1.68; 95% CI, 1.10-2.57; P = .02, and HR, 1.62; 95% CI, 1.07-2.47; P = .02, respectively).Genetic variants in the PRKCB1 gene were independently associated with development of ESRD in Chinese patients with type 2 diabetes.","Genetic variants of the protein kinase C-beta 1 gene and development of end-stage renal disease in patients with type 2 diabetes."
"1286","Lancet.239","1.00E-04",20801495,2010,"Raised resting heart rate is a marker of cardiovascular risk. We postulated that heart rate is also a risk factor for cardiovascular events in heart failure. In the SHIFT trial, patients with chronic heart failure were treated with the selective heart-rate-lowering agent ivabradine. We aimed to test our hypothesis by investigating the association between heart rate and events in this patient population.We analysed cardiovascular outcomes in the placebo (n=3264) and ivabradine groups (n=3241) of this randomised trial, divided by quintiles of baseline heart rate in the placebo group. The primary composite endpoint was cardiovascular death or hospital admission for worsening heart failure. In the ivabradine group, heart rate achieved at 28 days was also analysed in relation to subsequent outcomes. Analysis adjusted to change in heart rate was used to study heart-rate reduction as mechanism for risk reduction by ivabradine directly.In the placebo group, patients with the highest heart rates (>or=87 beats per min [bpm], n=682, 286 events) were at more than two-fold higher risk for the primary composite endpoint than were patients with the lowest heart rates (70 to <72 bpm, n=461, 92 events; hazard ratio [HR] 2.34, 95% CI 1.84-2.98, p<0.0001). Risk of primary composite endpoint events increased by 3% with every beat increase from baseline heart rate and 16% for every 5-bpm increase. In the ivabradine group, there was a direct association between heart rate achieved at 28 days and subsequent cardiac outcomes. Patients with heart rates lower than 60 bpm at 28 days on treatment had fewer primary composite endpoint events during the study (n=1192; event rate 17.4%, 95% CI 15.3-19.6) than did patients with higher heart rates. The effect of ivabradine is accounted for by heart-rate reduction, as shown by the neutralisation of the treatment effect after adjustment for change of heart rate at 28 days (HR 0.95, 0.85-1.06, p=0.352).Our analysis confirms that high heart rate is a risk factor in heart failure. Selective lowering of heart rates with ivabradine improves cardiovascular outcomes. Heart rate is an important target for treatment of heart failure.Servier, France.Copyright 2010 Elsevier Ltd. All rights reserved.","Heart rate as a risk factor in chronic heart failure (SHIFT): the association between heart rate and outcomes in a randomised placebo-controlled trial."
"1287","Lancet.253","0.352",20801495,2010,"Raised resting heart rate is a marker of cardiovascular risk. We postulated that heart rate is also a risk factor for cardiovascular events in heart failure. In the SHIFT trial, patients with chronic heart failure were treated with the selective heart-rate-lowering agent ivabradine. We aimed to test our hypothesis by investigating the association between heart rate and events in this patient population.We analysed cardiovascular outcomes in the placebo (n=3264) and ivabradine groups (n=3241) of this randomised trial, divided by quintiles of baseline heart rate in the placebo group. The primary composite endpoint was cardiovascular death or hospital admission for worsening heart failure. In the ivabradine group, heart rate achieved at 28 days was also analysed in relation to subsequent outcomes. Analysis adjusted to change in heart rate was used to study heart-rate reduction as mechanism for risk reduction by ivabradine directly.In the placebo group, patients with the highest heart rates (>or=87 beats per min [bpm], n=682, 286 events) were at more than two-fold higher risk for the primary composite endpoint than were patients with the lowest heart rates (70 to <72 bpm, n=461, 92 events; hazard ratio [HR] 2.34, 95% CI 1.84-2.98, p<0.0001). Risk of primary composite endpoint events increased by 3% with every beat increase from baseline heart rate and 16% for every 5-bpm increase. In the ivabradine group, there was a direct association between heart rate achieved at 28 days and subsequent cardiac outcomes. Patients with heart rates lower than 60 bpm at 28 days on treatment had fewer primary composite endpoint events during the study (n=1192; event rate 17.4%, 95% CI 15.3-19.6) than did patients with higher heart rates. The effect of ivabradine is accounted for by heart-rate reduction, as shown by the neutralisation of the treatment effect after adjustment for change of heart rate at 28 days (HR 0.95, 0.85-1.06, p=0.352).Our analysis confirms that high heart rate is a risk factor in heart failure. Selective lowering of heart rates with ivabradine improves cardiovascular outcomes. Heart rate is an important target for treatment of heart failure.Servier, France.Copyright 2010 Elsevier Ltd. All rights reserved.","Heart rate as a risk factor in chronic heart failure (SHIFT): the association between heart rate and outcomes in a randomised placebo-controlled trial."
"1288","Lancet.235","1.00E-04",20801500,2010,"Chronic heart failure is associated with high mortality and morbidity. Raised resting heart rate is a risk factor for adverse outcomes. We aimed to assess the effect of heart-rate reduction by the selective sinus-node inhibitor ivabradine on outcomes in heart failure.Patients were eligible for participation in this randomised, double-blind, placebo-controlled, parallel-group study if they had symptomatic heart failure and a left-ventricular ejection fraction of 35% or lower, were in sinus rhythm with heart rate 70 beats per min or higher, had been admitted to hospital for heart failure within the previous year, and were on stable background treatment including a _ blocker if tolerated. Patients were randomly assigned by computer-generated allocation schedule to ivabradine titrated to a maximum of 7.5 mg twice daily or matching placebo. Patients and investigators were masked to treatment allocation. The primary endpoint was the composite of cardiovascular death or hospital admission for worsening heart failure. Analysis was by intention to treat. This trial is registered, number ISRCTN70429960.6558 patients were randomly assigned to treatment groups (3268 ivabradine, 3290 placebo). Data were available for analysis for 3241 patients in the ivabradine group and 3264 patients allocated placebo. Median follow-up was 22.9 (IQR 18-28) months. 793 (24%) patients in the ivabradine group and 937 (29%) of those taking placebo had a primary endpoint event (HR 0.82, 95% CI 0.75-0.90, p<0.0001). The effects were driven mainly by hospital admissions for worsening heart failure (672 [21%] placebo vs 514 [16%] ivabradine; HR 0.74, 0.66-0.83; p<0.0001) and deaths due to heart failure (151 [5%] vs 113 [3%]; HR 0.74, 0.58-0.94, p=0.014). Fewer serious adverse events occurred in the ivabradine group (3388 events) than in the placebo group (3847; p=0.025). 150 (5%) of ivabradine patients had symptomatic bradycardia compared with 32 (1%) of the placebo group (p<0.0001). Visual side-effects (phosphenes) were reported by 89 (3%) of patients on ivabradine and 17 (1%) on placebo (p<0.0001).Our results support the importance of heart-rate reduction with ivabradine for improvement of clinical outcomes in heart failure and confirm the important role of heart rate in the pathophysiology of this disorder.Servier, France.Copyright 2010 Elsevier Ltd. All rights reserved.","Ivabradine and outcomes in chronic heart failure (SHIFT): a randomised placebo-controlled study."
"1289","Lancet.236","1.00E-04",20801500,2010,"Chronic heart failure is associated with high mortality and morbidity. Raised resting heart rate is a risk factor for adverse outcomes. We aimed to assess the effect of heart-rate reduction by the selective sinus-node inhibitor ivabradine on outcomes in heart failure.Patients were eligible for participation in this randomised, double-blind, placebo-controlled, parallel-group study if they had symptomatic heart failure and a left-ventricular ejection fraction of 35% or lower, were in sinus rhythm with heart rate 70 beats per min or higher, had been admitted to hospital for heart failure within the previous year, and were on stable background treatment including a _ blocker if tolerated. Patients were randomly assigned by computer-generated allocation schedule to ivabradine titrated to a maximum of 7.5 mg twice daily or matching placebo. Patients and investigators were masked to treatment allocation. The primary endpoint was the composite of cardiovascular death or hospital admission for worsening heart failure. Analysis was by intention to treat. This trial is registered, number ISRCTN70429960.6558 patients were randomly assigned to treatment groups (3268 ivabradine, 3290 placebo). Data were available for analysis for 3241 patients in the ivabradine group and 3264 patients allocated placebo. Median follow-up was 22.9 (IQR 18-28) months. 793 (24%) patients in the ivabradine group and 937 (29%) of those taking placebo had a primary endpoint event (HR 0.82, 95% CI 0.75-0.90, p<0.0001). The effects were driven mainly by hospital admissions for worsening heart failure (672 [21%] placebo vs 514 [16%] ivabradine; HR 0.74, 0.66-0.83; p<0.0001) and deaths due to heart failure (151 [5%] vs 113 [3%]; HR 0.74, 0.58-0.94, p=0.014). Fewer serious adverse events occurred in the ivabradine group (3388 events) than in the placebo group (3847; p=0.025). 150 (5%) of ivabradine patients had symptomatic bradycardia compared with 32 (1%) of the placebo group (p<0.0001). Visual side-effects (phosphenes) were reported by 89 (3%) of patients on ivabradine and 17 (1%) on placebo (p<0.0001).Our results support the importance of heart-rate reduction with ivabradine for improvement of clinical outcomes in heart failure and confirm the important role of heart rate in the pathophysiology of this disorder.Servier, France.Copyright 2010 Elsevier Ltd. All rights reserved.","Ivabradine and outcomes in chronic heart failure (SHIFT): a randomised placebo-controlled study."
"1290","Lancet.252","0.014",20801500,2010,"Chronic heart failure is associated with high mortality and morbidity. Raised resting heart rate is a risk factor for adverse outcomes. We aimed to assess the effect of heart-rate reduction by the selective sinus-node inhibitor ivabradine on outcomes in heart failure.Patients were eligible for participation in this randomised, double-blind, placebo-controlled, parallel-group study if they had symptomatic heart failure and a left-ventricular ejection fraction of 35% or lower, were in sinus rhythm with heart rate 70 beats per min or higher, had been admitted to hospital for heart failure within the previous year, and were on stable background treatment including a _ blocker if tolerated. Patients were randomly assigned by computer-generated allocation schedule to ivabradine titrated to a maximum of 7.5 mg twice daily or matching placebo. Patients and investigators were masked to treatment allocation. The primary endpoint was the composite of cardiovascular death or hospital admission for worsening heart failure. Analysis was by intention to treat. This trial is registered, number ISRCTN70429960.6558 patients were randomly assigned to treatment groups (3268 ivabradine, 3290 placebo). Data were available for analysis for 3241 patients in the ivabradine group and 3264 patients allocated placebo. Median follow-up was 22.9 (IQR 18-28) months. 793 (24%) patients in the ivabradine group and 937 (29%) of those taking placebo had a primary endpoint event (HR 0.82, 95% CI 0.75-0.90, p<0.0001). The effects were driven mainly by hospital admissions for worsening heart failure (672 [21%] placebo vs 514 [16%] ivabradine; HR 0.74, 0.66-0.83; p<0.0001) and deaths due to heart failure (151 [5%] vs 113 [3%]; HR 0.74, 0.58-0.94, p=0.014). Fewer serious adverse events occurred in the ivabradine group (3388 events) than in the placebo group (3847; p=0.025). 150 (5%) of ivabradine patients had symptomatic bradycardia compared with 32 (1%) of the placebo group (p<0.0001). Visual side-effects (phosphenes) were reported by 89 (3%) of patients on ivabradine and 17 (1%) on placebo (p<0.0001).Our results support the importance of heart-rate reduction with ivabradine for improvement of clinical outcomes in heart failure and confirm the important role of heart rate in the pathophysiology of this disorder.Servier, France.Copyright 2010 Elsevier Ltd. All rights reserved.","Ivabradine and outcomes in chronic heart failure (SHIFT): a randomised placebo-controlled study."
"1291","JAMA.558","0.27",20805623,2010,"The optimal unfractionated heparin regimen for percutaneous coronary intervention (PCI) in patients with non-ST-segment elevation acute coronary syndromes treated with fondaparinux is uncertain.To compare the safety of 2 unfractionated heparin regimens during PCI in high-risk patients with non-ST-segment elevation acute coronary syndromes initially treated with fondaparinux.Double-blind randomized parallel-group trial in 179 hospitals in 18 countries involving 2026 patients undergoing PCI within 72 hours, nested within a cohort of 3235 high-risk patients with non-ST-segment elevation acute coronary syndromes initially treated with fondaparinux enrolled from February 2009 to March 2010.Patients received intravenously either low-dose unfractionated heparin, 50 U/kg, regardless of use of glycoprotein IIb/IIIa (GpIIb-IIIa) inhibitors or standard-dose unfractionated heparin, 85 U/kg (60 U/kg with GpIIb-IIIa inhibitors), adjusted by blinded activated clotting time (ACT).Composite of major bleeding, minor bleeding, or major vascular access-site complications up to 48 hours after PCI. Key secondary outcomes include composite of major bleeding at 48 hours with death, myocardial infarction, or target vessel revascularization within day 30.The primary outcome occurred in 4.7% of those in the low-dose group vs 5.8% in the standard-dose group (odds ratio [OR], 0.80; 95% confidence interval [CI], 0.54-1.19; P = .27). The rates of major bleeding were not different but the rates of minor bleeding were lower with 0.7% in the low-dose group vs 1.7% in the standard-dose group (OR, 0.40; 95% CI, 0.16-0.97; P = .04). For the key secondary outcome, the rates for low-dose group were 5.8% vs 3.9% in the standard-dose group (OR, 1.51; 95% CI, 1.00-2.28; P = .05) and for death, myocardial infarction, or target vessel revascularization it was 4.5% for the low-dose group vs 2.9% for the standard-dose group (OR, 1.58; 95% CI, 0.98-2.53; P = .06). Catheter thrombus rates were very low (0.5% in the low-dose group and 0.1% in the standard-dose group, P = .15).Low-dose compared with standard-dose unfractionated heparin did not reduce major peri-PCI bleeding and vascular access-site complications.clinicaltrials.gov Identifier: NCT00790907.","Low-dose vs standard-dose unfractionated heparin for percutaneous coronary intervention in acute coronary syndromes treated with fondaparinux: the FUTURA/OASIS-8 randomized trial."
"1292","JAMA.559","0.04",20805623,2010,"The optimal unfractionated heparin regimen for percutaneous coronary intervention (PCI) in patients with non-ST-segment elevation acute coronary syndromes treated with fondaparinux is uncertain.To compare the safety of 2 unfractionated heparin regimens during PCI in high-risk patients with non-ST-segment elevation acute coronary syndromes initially treated with fondaparinux.Double-blind randomized parallel-group trial in 179 hospitals in 18 countries involving 2026 patients undergoing PCI within 72 hours, nested within a cohort of 3235 high-risk patients with non-ST-segment elevation acute coronary syndromes initially treated with fondaparinux enrolled from February 2009 to March 2010.Patients received intravenously either low-dose unfractionated heparin, 50 U/kg, regardless of use of glycoprotein IIb/IIIa (GpIIb-IIIa) inhibitors or standard-dose unfractionated heparin, 85 U/kg (60 U/kg with GpIIb-IIIa inhibitors), adjusted by blinded activated clotting time (ACT).Composite of major bleeding, minor bleeding, or major vascular access-site complications up to 48 hours after PCI. Key secondary outcomes include composite of major bleeding at 48 hours with death, myocardial infarction, or target vessel revascularization within day 30.The primary outcome occurred in 4.7% of those in the low-dose group vs 5.8% in the standard-dose group (odds ratio [OR], 0.80; 95% confidence interval [CI], 0.54-1.19; P = .27). The rates of major bleeding were not different but the rates of minor bleeding were lower with 0.7% in the low-dose group vs 1.7% in the standard-dose group (OR, 0.40; 95% CI, 0.16-0.97; P = .04). For the key secondary outcome, the rates for low-dose group were 5.8% vs 3.9% in the standard-dose group (OR, 1.51; 95% CI, 1.00-2.28; P = .05) and for death, myocardial infarction, or target vessel revascularization it was 4.5% for the low-dose group vs 2.9% for the standard-dose group (OR, 1.58; 95% CI, 0.98-2.53; P = .06). Catheter thrombus rates were very low (0.5% in the low-dose group and 0.1% in the standard-dose group, P = .15).Low-dose compared with standard-dose unfractionated heparin did not reduce major peri-PCI bleeding and vascular access-site complications.clinicaltrials.gov Identifier: NCT00790907.","Low-dose vs standard-dose unfractionated heparin for percutaneous coronary intervention in acute coronary syndromes treated with fondaparinux: the FUTURA/OASIS-8 randomized trial."
"1293","JAMA.560","0.05",20805623,2010,"The optimal unfractionated heparin regimen for percutaneous coronary intervention (PCI) in patients with non-ST-segment elevation acute coronary syndromes treated with fondaparinux is uncertain.To compare the safety of 2 unfractionated heparin regimens during PCI in high-risk patients with non-ST-segment elevation acute coronary syndromes initially treated with fondaparinux.Double-blind randomized parallel-group trial in 179 hospitals in 18 countries involving 2026 patients undergoing PCI within 72 hours, nested within a cohort of 3235 high-risk patients with non-ST-segment elevation acute coronary syndromes initially treated with fondaparinux enrolled from February 2009 to March 2010.Patients received intravenously either low-dose unfractionated heparin, 50 U/kg, regardless of use of glycoprotein IIb/IIIa (GpIIb-IIIa) inhibitors or standard-dose unfractionated heparin, 85 U/kg (60 U/kg with GpIIb-IIIa inhibitors), adjusted by blinded activated clotting time (ACT).Composite of major bleeding, minor bleeding, or major vascular access-site complications up to 48 hours after PCI. Key secondary outcomes include composite of major bleeding at 48 hours with death, myocardial infarction, or target vessel revascularization within day 30.The primary outcome occurred in 4.7% of those in the low-dose group vs 5.8% in the standard-dose group (odds ratio [OR], 0.80; 95% confidence interval [CI], 0.54-1.19; P = .27). The rates of major bleeding were not different but the rates of minor bleeding were lower with 0.7% in the low-dose group vs 1.7% in the standard-dose group (OR, 0.40; 95% CI, 0.16-0.97; P = .04). For the key secondary outcome, the rates for low-dose group were 5.8% vs 3.9% in the standard-dose group (OR, 1.51; 95% CI, 1.00-2.28; P = .05) and for death, myocardial infarction, or target vessel revascularization it was 4.5% for the low-dose group vs 2.9% for the standard-dose group (OR, 1.58; 95% CI, 0.98-2.53; P = .06). Catheter thrombus rates were very low (0.5% in the low-dose group and 0.1% in the standard-dose group, P = .15).Low-dose compared with standard-dose unfractionated heparin did not reduce major peri-PCI bleeding and vascular access-site complications.clinicaltrials.gov Identifier: NCT00790907.","Low-dose vs standard-dose unfractionated heparin for percutaneous coronary intervention in acute coronary syndromes treated with fondaparinux: the FUTURA/OASIS-8 randomized trial."
"1294","JAMA.561","0.06",20805623,2010,"The optimal unfractionated heparin regimen for percutaneous coronary intervention (PCI) in patients with non-ST-segment elevation acute coronary syndromes treated with fondaparinux is uncertain.To compare the safety of 2 unfractionated heparin regimens during PCI in high-risk patients with non-ST-segment elevation acute coronary syndromes initially treated with fondaparinux.Double-blind randomized parallel-group trial in 179 hospitals in 18 countries involving 2026 patients undergoing PCI within 72 hours, nested within a cohort of 3235 high-risk patients with non-ST-segment elevation acute coronary syndromes initially treated with fondaparinux enrolled from February 2009 to March 2010.Patients received intravenously either low-dose unfractionated heparin, 50 U/kg, regardless of use of glycoprotein IIb/IIIa (GpIIb-IIIa) inhibitors or standard-dose unfractionated heparin, 85 U/kg (60 U/kg with GpIIb-IIIa inhibitors), adjusted by blinded activated clotting time (ACT).Composite of major bleeding, minor bleeding, or major vascular access-site complications up to 48 hours after PCI. Key secondary outcomes include composite of major bleeding at 48 hours with death, myocardial infarction, or target vessel revascularization within day 30.The primary outcome occurred in 4.7% of those in the low-dose group vs 5.8% in the standard-dose group (odds ratio [OR], 0.80; 95% confidence interval [CI], 0.54-1.19; P = .27). The rates of major bleeding were not different but the rates of minor bleeding were lower with 0.7% in the low-dose group vs 1.7% in the standard-dose group (OR, 0.40; 95% CI, 0.16-0.97; P = .04). For the key secondary outcome, the rates for low-dose group were 5.8% vs 3.9% in the standard-dose group (OR, 1.51; 95% CI, 1.00-2.28; P = .05) and for death, myocardial infarction, or target vessel revascularization it was 4.5% for the low-dose group vs 2.9% for the standard-dose group (OR, 1.58; 95% CI, 0.98-2.53; P = .06). Catheter thrombus rates were very low (0.5% in the low-dose group and 0.1% in the standard-dose group, P = .15).Low-dose compared with standard-dose unfractionated heparin did not reduce major peri-PCI bleeding and vascular access-site complications.clinicaltrials.gov Identifier: NCT00790907.","Low-dose vs standard-dose unfractionated heparin for percutaneous coronary intervention in acute coronary syndromes treated with fondaparinux: the FUTURA/OASIS-8 randomized trial."
"1295","JAMA.5681","0.001",20805624,2010,"Clinicians and trialists have difficulty with identifying which patients are highest risk for cardiovascular events. Prior ischemic events, polyvascular disease, and diabetes mellitus have all been identified as predictors of ischemic events, but their comparative contributions to future risk remain unclear.To categorize the risk of cardiovascular events in stable outpatients with various initial manifestations of atherothrombosis using simple clinical descriptors.Outpatients with coronary artery disease, cerebrovascular disease, or peripheral arterial disease or with multiple risk factors for atherothrombosis were enrolled in the global Reduction of Atherothrombosis for Continued Health (REACH) Registry and were followed up for as long as 4 years. Patients from 3647 centers in 29 countries were enrolled between 2003 and 2004 and followed up until 2008. Final database lock was in April 2009.Rates of cardiovascular death, myocardial infarction, and stroke.A total of 45,227 patients with baseline data were included in this 4-year analysis. During the follow-up period, a total of 5481 patients experienced at least 1 event, including 2315 with cardiovascular death, 1228 with myocardial infarction, 1898 with stroke, and 40 with both a myocardial infarction and stroke on the same day. Among patients with atherothrombosis, those with a prior history of ischemic events at baseline (n = 21,890) had the highest rate of subsequent ischemic events (18.3%; 95% confidence interval [CI], 17.4%-19.1%); patients with stable coronary, cerebrovascular, or peripheral artery disease (n = 15,264) had a lower risk (12.2%; 95% CI, 11.4%-12.9%); and patients without established atherothrombosis but with risk factors only (n = 8073) had the lowest risk (9.1%; 95% CI, 8.3%-9.9%) (P < .001 for all comparisons). In addition, in multivariable modeling, the presence of diabetes (hazard ratio [HR], 1.44; 95% CI, 1.36-1.53; P < .001), an ischemic event in the previous year (HR, 1.71; 95% CI, 1.57-1.85; P < .001), and polyvascular disease (HR, 1.99; 95% CI, 1.78-2.24; P < .001) each were associated with a significantly higher risk of the primary end point.Clinical descriptors can assist clinicians in identifying high-risk patients within the broad range of risk for outpatients with atherothrombosis.","Comparative determinants of 4-year cardiovascular event rates in stable outpatients at risk of or with atherothrombosis."
"1296","JAMA.5691","0.001",20805624,2010,"Clinicians and trialists have difficulty with identifying which patients are highest risk for cardiovascular events. Prior ischemic events, polyvascular disease, and diabetes mellitus have all been identified as predictors of ischemic events, but their comparative contributions to future risk remain unclear.To categorize the risk of cardiovascular events in stable outpatients with various initial manifestations of atherothrombosis using simple clinical descriptors.Outpatients with coronary artery disease, cerebrovascular disease, or peripheral arterial disease or with multiple risk factors for atherothrombosis were enrolled in the global Reduction of Atherothrombosis for Continued Health (REACH) Registry and were followed up for as long as 4 years. Patients from 3647 centers in 29 countries were enrolled between 2003 and 2004 and followed up until 2008. Final database lock was in April 2009.Rates of cardiovascular death, myocardial infarction, and stroke.A total of 45,227 patients with baseline data were included in this 4-year analysis. During the follow-up period, a total of 5481 patients experienced at least 1 event, including 2315 with cardiovascular death, 1228 with myocardial infarction, 1898 with stroke, and 40 with both a myocardial infarction and stroke on the same day. Among patients with atherothrombosis, those with a prior history of ischemic events at baseline (n = 21,890) had the highest rate of subsequent ischemic events (18.3%; 95% confidence interval [CI], 17.4%-19.1%); patients with stable coronary, cerebrovascular, or peripheral artery disease (n = 15,264) had a lower risk (12.2%; 95% CI, 11.4%-12.9%); and patients without established atherothrombosis but with risk factors only (n = 8073) had the lowest risk (9.1%; 95% CI, 8.3%-9.9%) (P < .001 for all comparisons). In addition, in multivariable modeling, the presence of diabetes (hazard ratio [HR], 1.44; 95% CI, 1.36-1.53; P < .001), an ischemic event in the previous year (HR, 1.71; 95% CI, 1.57-1.85; P < .001), and polyvascular disease (HR, 1.99; 95% CI, 1.78-2.24; P < .001) each were associated with a significantly higher risk of the primary end point.Clinical descriptors can assist clinicians in identifying high-risk patients within the broad range of risk for outpatients with atherothrombosis.","Comparative determinants of 4-year cardiovascular event rates in stable outpatients at risk of or with atherothrombosis."
"1297","JAMA.5701","0.001",20805624,2010,"Clinicians and trialists have difficulty with identifying which patients are highest risk for cardiovascular events. Prior ischemic events, polyvascular disease, and diabetes mellitus have all been identified as predictors of ischemic events, but their comparative contributions to future risk remain unclear.To categorize the risk of cardiovascular events in stable outpatients with various initial manifestations of atherothrombosis using simple clinical descriptors.Outpatients with coronary artery disease, cerebrovascular disease, or peripheral arterial disease or with multiple risk factors for atherothrombosis were enrolled in the global Reduction of Atherothrombosis for Continued Health (REACH) Registry and were followed up for as long as 4 years. Patients from 3647 centers in 29 countries were enrolled between 2003 and 2004 and followed up until 2008. Final database lock was in April 2009.Rates of cardiovascular death, myocardial infarction, and stroke.A total of 45,227 patients with baseline data were included in this 4-year analysis. During the follow-up period, a total of 5481 patients experienced at least 1 event, including 2315 with cardiovascular death, 1228 with myocardial infarction, 1898 with stroke, and 40 with both a myocardial infarction and stroke on the same day. Among patients with atherothrombosis, those with a prior history of ischemic events at baseline (n = 21,890) had the highest rate of subsequent ischemic events (18.3%; 95% confidence interval [CI], 17.4%-19.1%); patients with stable coronary, cerebrovascular, or peripheral artery disease (n = 15,264) had a lower risk (12.2%; 95% CI, 11.4%-12.9%); and patients without established atherothrombosis but with risk factors only (n = 8073) had the lowest risk (9.1%; 95% CI, 8.3%-9.9%) (P < .001 for all comparisons). In addition, in multivariable modeling, the presence of diabetes (hazard ratio [HR], 1.44; 95% CI, 1.36-1.53; P < .001), an ischemic event in the previous year (HR, 1.71; 95% CI, 1.57-1.85; P < .001), and polyvascular disease (HR, 1.99; 95% CI, 1.78-2.24; P < .001) each were associated with a significantly higher risk of the primary end point.Clinical descriptors can assist clinicians in identifying high-risk patients within the broad range of risk for outpatients with atherothrombosis.","Comparative determinants of 4-year cardiovascular event rates in stable outpatients at risk of or with atherothrombosis."
"1298","JAMA.613","0.01",20858879,2010,"Critically short telomeres produce apoptosis, cell senescence, and chromosomal instability in tissue culture and animal models. Variations in telomere length have been reported in severe aplastic anemia but their clinical significance is unknown.To investigate the relationship between telomere length and clinical outcomes in severe aplastic anemia.Single institution analysis of 183 patients with severe aplastic anemia who were treated in sequential prospective protocols at the National Institutes of Health from 2000 to 2008. The pretreatment leukocyte age-adjusted telomere length of patients with severe aplastic anemia consecutively enrolled in immunosuppression protocols with antithymocyte globulin plus cyclosporine for correlation with clinical outcomes were analyzed.Hematologic response, relapse, clonal evolution, and survival.There was no relationship between hematologic response and telomere length with response rates of 56.5% of 46 patients in the first, 54.3% of 46 in the second, 60% of 45 in the third, and 56.5% of 46 in the fourth quartiles. Multivariate analysis demonstrated that telomere length was associated with relapse, clonal evolution, and mortality. Evaluated as a continuous variable, telomere length inversely correlated with the probability of hematologic relapse (hazard ratio [HR], 0.16; 95% confidence interval [CI], 0.03-0.69; P = .01). The probability of clonal evolution was higher in patients in the first quartile (24.5%; 95% CI, 8.7%-37.5%) than in quartiles 2 through 4 (8.4%; 95% CI, 3.2%-13.3%; P = .009), and evolution to monosomy 7 or complex cytogenetics was more common in the first quartile (18.8%; 95% CI, 3.5%-31.6%) [corrected] than in quartiles 2 through 4 (4.5%; 95% CI, 0.5%-8.2%; P = .002) [corrected]. Survival between these 2 groups differed, with 66% (95% CI, 52.9%-82.5%) surviving 6 years in the first quartile compared with 83.8% (95% CI, 77.3%-90.9%) in quartiles 2 through 4 (P = .008).In a cohort of patients with severe aplastic anemia receiving immunosuppressive therapy, telomere length was unrelated to response but was associated with risk of relapse, clonal evolution, and overall survival.","Association of telomere length of peripheral blood leukocytes with hematopoietic relapse, malignant transformation, and survival in severe aplastic anemia."
"1299","BMJ.26","0.216",20940209,2010,"To assess the benefits and harms of reboxetine versus placebo or selective serotonin reuptake inhibitors (SSRIs) in the acute treatment of depression, and to measure the impact of potential publication bias in trials of reboxetine.Systematic review and meta-analysis including unpublished data.Bibliographic databases (Medline, Embase, PsycINFO, BIOSIS, and Cochrane Library), clinical trial registries, trial results databases, and regulatory authority websites up until February 2009, as well as unpublished data from the manufacturer of reboxetine (Pfizer, Berlin). ELIGIBILITY CRITERIA: Double blind, randomised, controlled trials of acute treatment (six weeks or more) with reboxetine versus placebo or SSRIs in adults with major depression.Remission and response rates (benefit outcomes), as well as rates of patients with at least one adverse event and withdrawals owing to adverse events (harm outcomes).The procedures for data extraction and assessment of risk of bias were always conducted by one person and checked by another. If feasible, data were pooled by meta-analyses (random effects model). Publication bias was measured by comparing results of published and unpublished trials.We analysed 13 acute treatment trials that were placebo controlled, SSRI controlled, or both, which included 4098 patients. Data on 74% (3033/4098) of these patients were unpublished. In the reboxetine versus placebo comparison, no significant differences in remission rates were shown (odds ratio 1.17, 95% confidence interval 0.91 to 1.51; P=0.216). Substantial heterogeneity (I(2)=67.3%) was shown in the meta-analysis of the eight trials that investigated response rates for reboxetine versus placebo. A sensitivity analysis that excluded a small inpatient trial showed no significant difference in response rates between patients receiving reboxetine and those receiving placebo (OR 1.24, 95% CI 0.98 to 1.56; P=0.071; I(2)=42.1%). Reboxetine was inferior to SSRIs (fluoxetine, paroxetine, and citalopram) for remission rates (OR 0.80, 95% CI 0.67 to 0.96; P=0.015) and response rates (OR 0.80, 95% CI 0.67 to 0.95; P=0.01). Reboxetine was inferior to placebo for both harm outcomes (P<0.001 for both), and to fluoxetine for withdrawals owing to adverse events (OR 1.79, 95% CI 1.06 to 3.05; P=0.031). Published data overestimated the benefit of reboxetine versus placebo by up to 115% and reboxetine versus SSRIs by up to 23%, and also underestimated harm.Reboxetine is, overall, an ineffective and potentially harmful antidepressant. Published evidence is affected by publication bias, underlining the urgent need for mandatory publication of trial data.","Reboxetine for acute treatment of major depression: systematic review and meta-analysis of published and unpublished placebo and selective serotonin reuptake inhibitor controlled trials."
"1300","BMJ.27","0.071",20940209,2010,"To assess the benefits and harms of reboxetine versus placebo or selective serotonin reuptake inhibitors (SSRIs) in the acute treatment of depression, and to measure the impact of potential publication bias in trials of reboxetine.Systematic review and meta-analysis including unpublished data.Bibliographic databases (Medline, Embase, PsycINFO, BIOSIS, and Cochrane Library), clinical trial registries, trial results databases, and regulatory authority websites up until February 2009, as well as unpublished data from the manufacturer of reboxetine (Pfizer, Berlin). ELIGIBILITY CRITERIA: Double blind, randomised, controlled trials of acute treatment (six weeks or more) with reboxetine versus placebo or SSRIs in adults with major depression.Remission and response rates (benefit outcomes), as well as rates of patients with at least one adverse event and withdrawals owing to adverse events (harm outcomes).The procedures for data extraction and assessment of risk of bias were always conducted by one person and checked by another. If feasible, data were pooled by meta-analyses (random effects model). Publication bias was measured by comparing results of published and unpublished trials.We analysed 13 acute treatment trials that were placebo controlled, SSRI controlled, or both, which included 4098 patients. Data on 74% (3033/4098) of these patients were unpublished. In the reboxetine versus placebo comparison, no significant differences in remission rates were shown (odds ratio 1.17, 95% confidence interval 0.91 to 1.51; P=0.216). Substantial heterogeneity (I(2)=67.3%) was shown in the meta-analysis of the eight trials that investigated response rates for reboxetine versus placebo. A sensitivity analysis that excluded a small inpatient trial showed no significant difference in response rates between patients receiving reboxetine and those receiving placebo (OR 1.24, 95% CI 0.98 to 1.56; P=0.071; I(2)=42.1%). Reboxetine was inferior to SSRIs (fluoxetine, paroxetine, and citalopram) for remission rates (OR 0.80, 95% CI 0.67 to 0.96; P=0.015) and response rates (OR 0.80, 95% CI 0.67 to 0.95; P=0.01). Reboxetine was inferior to placebo for both harm outcomes (P<0.001 for both), and to fluoxetine for withdrawals owing to adverse events (OR 1.79, 95% CI 1.06 to 3.05; P=0.031). Published data overestimated the benefit of reboxetine versus placebo by up to 115% and reboxetine versus SSRIs by up to 23%, and also underestimated harm.Reboxetine is, overall, an ineffective and potentially harmful antidepressant. Published evidence is affected by publication bias, underlining the urgent need for mandatory publication of trial data.","Reboxetine for acute treatment of major depression: systematic review and meta-analysis of published and unpublished placebo and selective serotonin reuptake inhibitor controlled trials."
"1301","BMJ.28","0.015",20940209,2010,"To assess the benefits and harms of reboxetine versus placebo or selective serotonin reuptake inhibitors (SSRIs) in the acute treatment of depression, and to measure the impact of potential publication bias in trials of reboxetine.Systematic review and meta-analysis including unpublished data.Bibliographic databases (Medline, Embase, PsycINFO, BIOSIS, and Cochrane Library), clinical trial registries, trial results databases, and regulatory authority websites up until February 2009, as well as unpublished data from the manufacturer of reboxetine (Pfizer, Berlin). ELIGIBILITY CRITERIA: Double blind, randomised, controlled trials of acute treatment (six weeks or more) with reboxetine versus placebo or SSRIs in adults with major depression.Remission and response rates (benefit outcomes), as well as rates of patients with at least one adverse event and withdrawals owing to adverse events (harm outcomes).The procedures for data extraction and assessment of risk of bias were always conducted by one person and checked by another. If feasible, data were pooled by meta-analyses (random effects model). Publication bias was measured by comparing results of published and unpublished trials.We analysed 13 acute treatment trials that were placebo controlled, SSRI controlled, or both, which included 4098 patients. Data on 74% (3033/4098) of these patients were unpublished. In the reboxetine versus placebo comparison, no significant differences in remission rates were shown (odds ratio 1.17, 95% confidence interval 0.91 to 1.51; P=0.216). Substantial heterogeneity (I(2)=67.3%) was shown in the meta-analysis of the eight trials that investigated response rates for reboxetine versus placebo. A sensitivity analysis that excluded a small inpatient trial showed no significant difference in response rates between patients receiving reboxetine and those receiving placebo (OR 1.24, 95% CI 0.98 to 1.56; P=0.071; I(2)=42.1%). Reboxetine was inferior to SSRIs (fluoxetine, paroxetine, and citalopram) for remission rates (OR 0.80, 95% CI 0.67 to 0.96; P=0.015) and response rates (OR 0.80, 95% CI 0.67 to 0.95; P=0.01). Reboxetine was inferior to placebo for both harm outcomes (P<0.001 for both), and to fluoxetine for withdrawals owing to adverse events (OR 1.79, 95% CI 1.06 to 3.05; P=0.031). Published data overestimated the benefit of reboxetine versus placebo by up to 115% and reboxetine versus SSRIs by up to 23%, and also underestimated harm.Reboxetine is, overall, an ineffective and potentially harmful antidepressant. Published evidence is affected by publication bias, underlining the urgent need for mandatory publication of trial data.","Reboxetine for acute treatment of major depression: systematic review and meta-analysis of published and unpublished placebo and selective serotonin reuptake inhibitor controlled trials."
"1302","BMJ.29","0.01",20940209,2010,"To assess the benefits and harms of reboxetine versus placebo or selective serotonin reuptake inhibitors (SSRIs) in the acute treatment of depression, and to measure the impact of potential publication bias in trials of reboxetine.Systematic review and meta-analysis including unpublished data.Bibliographic databases (Medline, Embase, PsycINFO, BIOSIS, and Cochrane Library), clinical trial registries, trial results databases, and regulatory authority websites up until February 2009, as well as unpublished data from the manufacturer of reboxetine (Pfizer, Berlin). ELIGIBILITY CRITERIA: Double blind, randomised, controlled trials of acute treatment (six weeks or more) with reboxetine versus placebo or SSRIs in adults with major depression.Remission and response rates (benefit outcomes), as well as rates of patients with at least one adverse event and withdrawals owing to adverse events (harm outcomes).The procedures for data extraction and assessment of risk of bias were always conducted by one person and checked by another. If feasible, data were pooled by meta-analyses (random effects model). Publication bias was measured by comparing results of published and unpublished trials.We analysed 13 acute treatment trials that were placebo controlled, SSRI controlled, or both, which included 4098 patients. Data on 74% (3033/4098) of these patients were unpublished. In the reboxetine versus placebo comparison, no significant differences in remission rates were shown (odds ratio 1.17, 95% confidence interval 0.91 to 1.51; P=0.216). Substantial heterogeneity (I(2)=67.3%) was shown in the meta-analysis of the eight trials that investigated response rates for reboxetine versus placebo. A sensitivity analysis that excluded a small inpatient trial showed no significant difference in response rates between patients receiving reboxetine and those receiving placebo (OR 1.24, 95% CI 0.98 to 1.56; P=0.071; I(2)=42.1%). Reboxetine was inferior to SSRIs (fluoxetine, paroxetine, and citalopram) for remission rates (OR 0.80, 95% CI 0.67 to 0.96; P=0.015) and response rates (OR 0.80, 95% CI 0.67 to 0.95; P=0.01). Reboxetine was inferior to placebo for both harm outcomes (P<0.001 for both), and to fluoxetine for withdrawals owing to adverse events (OR 1.79, 95% CI 1.06 to 3.05; P=0.031). Published data overestimated the benefit of reboxetine versus placebo by up to 115% and reboxetine versus SSRIs by up to 23%, and also underestimated harm.Reboxetine is, overall, an ineffective and potentially harmful antidepressant. Published evidence is affected by publication bias, underlining the urgent need for mandatory publication of trial data.","Reboxetine for acute treatment of major depression: systematic review and meta-analysis of published and unpublished placebo and selective serotonin reuptake inhibitor controlled trials."
"1303","BMJ.30","0.031",20940209,2010,"To assess the benefits and harms of reboxetine versus placebo or selective serotonin reuptake inhibitors (SSRIs) in the acute treatment of depression, and to measure the impact of potential publication bias in trials of reboxetine.Systematic review and meta-analysis including unpublished data.Bibliographic databases (Medline, Embase, PsycINFO, BIOSIS, and Cochrane Library), clinical trial registries, trial results databases, and regulatory authority websites up until February 2009, as well as unpublished data from the manufacturer of reboxetine (Pfizer, Berlin). ELIGIBILITY CRITERIA: Double blind, randomised, controlled trials of acute treatment (six weeks or more) with reboxetine versus placebo or SSRIs in adults with major depression.Remission and response rates (benefit outcomes), as well as rates of patients with at least one adverse event and withdrawals owing to adverse events (harm outcomes).The procedures for data extraction and assessment of risk of bias were always conducted by one person and checked by another. If feasible, data were pooled by meta-analyses (random effects model). Publication bias was measured by comparing results of published and unpublished trials.We analysed 13 acute treatment trials that were placebo controlled, SSRI controlled, or both, which included 4098 patients. Data on 74% (3033/4098) of these patients were unpublished. In the reboxetine versus placebo comparison, no significant differences in remission rates were shown (odds ratio 1.17, 95% confidence interval 0.91 to 1.51; P=0.216). Substantial heterogeneity (I(2)=67.3%) was shown in the meta-analysis of the eight trials that investigated response rates for reboxetine versus placebo. A sensitivity analysis that excluded a small inpatient trial showed no significant difference in response rates between patients receiving reboxetine and those receiving placebo (OR 1.24, 95% CI 0.98 to 1.56; P=0.071; I(2)=42.1%). Reboxetine was inferior to SSRIs (fluoxetine, paroxetine, and citalopram) for remission rates (OR 0.80, 95% CI 0.67 to 0.96; P=0.015) and response rates (OR 0.80, 95% CI 0.67 to 0.95; P=0.01). Reboxetine was inferior to placebo for both harm outcomes (P<0.001 for both), and to fluoxetine for withdrawals owing to adverse events (OR 1.79, 95% CI 1.06 to 3.05; P=0.031). Published data overestimated the benefit of reboxetine versus placebo by up to 115% and reboxetine versus SSRIs by up to 23%, and also underestimated harm.Reboxetine is, overall, an ineffective and potentially harmful antidepressant. Published evidence is affected by publication bias, underlining the urgent need for mandatory publication of trial data.","Reboxetine for acute treatment of major depression: systematic review and meta-analysis of published and unpublished placebo and selective serotonin reuptake inhibitor controlled trials."
"1304","JAMA.608","0.004",20959578,2010,"In the Women's Health Initiative randomized, placebo-controlled trial of estrogen plus progestin, after a mean intervention time of 5.6 (SD, 1.3) years (range, 3.7-8.6 years) and a mean follow-up of 7.9 (SD, 1.4) years, breast cancer incidence was increased among women who received combined hormone therapy. Breast cancer mortality among participants in the trial has not been previously reported.To determine the effects of therapy with estrogen plus progestin on cumulative breast cancer incidence and mortality after a total mean follow-up of 11.0 (SD, 2.7) years, through August 14, 2009.A total of 16,608 postmenopausal women aged 50 to 79 years with no prior hysterectomy from 40 US clinical centers were randomly assigned to receive combined conjugated equine estrogens, 0.625 mg/d, plus medroxyprogesterone acetate, 2.5 mg/d, or placebo pill. After the original trial completion date (March 31, 2005), reconsent was required for continued follow-up for breast cancer incidence and was obtained from 12,788 (83%) of the surviving participants.Invasive breast cancer incidence and breast cancer mortality.In intention-to-treat analyses including all randomized participants and censoring those not consenting to additional follow-up on March 31, 2005, estrogen plus progestin was associated with more invasive breast cancers compared with placebo (385 cases [0.42% per year] vs 293 cases [0.34% per year]; hazard ratio [HR], 1.25; 95% confidence interval [CI], 1.07-1.46; P = .004). Breast cancers in the estrogen-plus-progestin group were similar in histology and grade to breast cancers in the placebo group but were more likely to be node-positive (81 [23.7%] vs 43 [16.2%], respectively; HR, 1.78; 95% CI, 1.23-2.58; P = .03). There were more deaths directly attributed to breast cancer (25 deaths [0.03% per year] vs 12 deaths [0.01% per year]; HR, 1.96; 95% CI, 1.00-4.04; P = .049) as well as more deaths from all causes occurring after a breast cancer diagnosis (51 deaths [0.05% per year] vs 31 deaths [0.03% per year]; HR, 1.57; 95% CI, 1.01-2.48; P = .045) among women who received estrogen plus progestin compared with women in the placebo group.Estrogen plus progestin was associated with greater breast cancer incidence, and the cancers are more commonly node-positive. Breast cancer mortality also appears to be increased with combined use of estrogen plus progestin.clinicaltrials.gov Identifier: NCT00000611.","Estrogen plus progestin and breast cancer incidence and mortality in postmenopausal women."
"1305","JAMA.609","0.03",20959578,2010,"In the Women's Health Initiative randomized, placebo-controlled trial of estrogen plus progestin, after a mean intervention time of 5.6 (SD, 1.3) years (range, 3.7-8.6 years) and a mean follow-up of 7.9 (SD, 1.4) years, breast cancer incidence was increased among women who received combined hormone therapy. Breast cancer mortality among participants in the trial has not been previously reported.To determine the effects of therapy with estrogen plus progestin on cumulative breast cancer incidence and mortality after a total mean follow-up of 11.0 (SD, 2.7) years, through August 14, 2009.A total of 16,608 postmenopausal women aged 50 to 79 years with no prior hysterectomy from 40 US clinical centers were randomly assigned to receive combined conjugated equine estrogens, 0.625 mg/d, plus medroxyprogesterone acetate, 2.5 mg/d, or placebo pill. After the original trial completion date (March 31, 2005), reconsent was required for continued follow-up for breast cancer incidence and was obtained from 12,788 (83%) of the surviving participants.Invasive breast cancer incidence and breast cancer mortality.In intention-to-treat analyses including all randomized participants and censoring those not consenting to additional follow-up on March 31, 2005, estrogen plus progestin was associated with more invasive breast cancers compared with placebo (385 cases [0.42% per year] vs 293 cases [0.34% per year]; hazard ratio [HR], 1.25; 95% confidence interval [CI], 1.07-1.46; P = .004). Breast cancers in the estrogen-plus-progestin group were similar in histology and grade to breast cancers in the placebo group but were more likely to be node-positive (81 [23.7%] vs 43 [16.2%], respectively; HR, 1.78; 95% CI, 1.23-2.58; P = .03). There were more deaths directly attributed to breast cancer (25 deaths [0.03% per year] vs 12 deaths [0.01% per year]; HR, 1.96; 95% CI, 1.00-4.04; P = .049) as well as more deaths from all causes occurring after a breast cancer diagnosis (51 deaths [0.05% per year] vs 31 deaths [0.03% per year]; HR, 1.57; 95% CI, 1.01-2.48; P = .045) among women who received estrogen plus progestin compared with women in the placebo group.Estrogen plus progestin was associated with greater breast cancer incidence, and the cancers are more commonly node-positive. Breast cancer mortality also appears to be increased with combined use of estrogen plus progestin.clinicaltrials.gov Identifier: NCT00000611.","Estrogen plus progestin and breast cancer incidence and mortality in postmenopausal women."
"1306","JAMA.610","0.049",20959578,2010,"In the Women's Health Initiative randomized, placebo-controlled trial of estrogen plus progestin, after a mean intervention time of 5.6 (SD, 1.3) years (range, 3.7-8.6 years) and a mean follow-up of 7.9 (SD, 1.4) years, breast cancer incidence was increased among women who received combined hormone therapy. Breast cancer mortality among participants in the trial has not been previously reported.To determine the effects of therapy with estrogen plus progestin on cumulative breast cancer incidence and mortality after a total mean follow-up of 11.0 (SD, 2.7) years, through August 14, 2009.A total of 16,608 postmenopausal women aged 50 to 79 years with no prior hysterectomy from 40 US clinical centers were randomly assigned to receive combined conjugated equine estrogens, 0.625 mg/d, plus medroxyprogesterone acetate, 2.5 mg/d, or placebo pill. After the original trial completion date (March 31, 2005), reconsent was required for continued follow-up for breast cancer incidence and was obtained from 12,788 (83%) of the surviving participants.Invasive breast cancer incidence and breast cancer mortality.In intention-to-treat analyses including all randomized participants and censoring those not consenting to additional follow-up on March 31, 2005, estrogen plus progestin was associated with more invasive breast cancers compared with placebo (385 cases [0.42% per year] vs 293 cases [0.34% per year]; hazard ratio [HR], 1.25; 95% confidence interval [CI], 1.07-1.46; P = .004). Breast cancers in the estrogen-plus-progestin group were similar in histology and grade to breast cancers in the placebo group but were more likely to be node-positive (81 [23.7%] vs 43 [16.2%], respectively; HR, 1.78; 95% CI, 1.23-2.58; P = .03). There were more deaths directly attributed to breast cancer (25 deaths [0.03% per year] vs 12 deaths [0.01% per year]; HR, 1.96; 95% CI, 1.00-4.04; P = .049) as well as more deaths from all causes occurring after a breast cancer diagnosis (51 deaths [0.05% per year] vs 31 deaths [0.03% per year]; HR, 1.57; 95% CI, 1.01-2.48; P = .045) among women who received estrogen plus progestin compared with women in the placebo group.Estrogen plus progestin was associated with greater breast cancer incidence, and the cancers are more commonly node-positive. Breast cancer mortality also appears to be increased with combined use of estrogen plus progestin.clinicaltrials.gov Identifier: NCT00000611.","Estrogen plus progestin and breast cancer incidence and mortality in postmenopausal women."
"1307","JAMA.611","0.045",20959578,2010,"In the Women's Health Initiative randomized, placebo-controlled trial of estrogen plus progestin, after a mean intervention time of 5.6 (SD, 1.3) years (range, 3.7-8.6 years) and a mean follow-up of 7.9 (SD, 1.4) years, breast cancer incidence was increased among women who received combined hormone therapy. Breast cancer mortality among participants in the trial has not been previously reported.To determine the effects of therapy with estrogen plus progestin on cumulative breast cancer incidence and mortality after a total mean follow-up of 11.0 (SD, 2.7) years, through August 14, 2009.A total of 16,608 postmenopausal women aged 50 to 79 years with no prior hysterectomy from 40 US clinical centers were randomly assigned to receive combined conjugated equine estrogens, 0.625 mg/d, plus medroxyprogesterone acetate, 2.5 mg/d, or placebo pill. After the original trial completion date (March 31, 2005), reconsent was required for continued follow-up for breast cancer incidence and was obtained from 12,788 (83%) of the surviving participants.Invasive breast cancer incidence and breast cancer mortality.In intention-to-treat analyses including all randomized participants and censoring those not consenting to additional follow-up on March 31, 2005, estrogen plus progestin was associated with more invasive breast cancers compared with placebo (385 cases [0.42% per year] vs 293 cases [0.34% per year]; hazard ratio [HR], 1.25; 95% confidence interval [CI], 1.07-1.46; P = .004). Breast cancers in the estrogen-plus-progestin group were similar in histology and grade to breast cancers in the placebo group but were more likely to be node-positive (81 [23.7%] vs 43 [16.2%], respectively; HR, 1.78; 95% CI, 1.23-2.58; P = .03). There were more deaths directly attributed to breast cancer (25 deaths [0.03% per year] vs 12 deaths [0.01% per year]; HR, 1.96; 95% CI, 1.00-4.04; P = .049) as well as more deaths from all causes occurring after a breast cancer diagnosis (51 deaths [0.05% per year] vs 31 deaths [0.03% per year]; HR, 1.57; 95% CI, 1.01-2.48; P = .045) among women who received estrogen plus progestin compared with women in the placebo group.Estrogen plus progestin was associated with greater breast cancer incidence, and the cancers are more commonly node-positive. Breast cancer mortality also appears to be increased with combined use of estrogen plus progestin.clinicaltrials.gov Identifier: NCT00000611.","Estrogen plus progestin and breast cancer incidence and mortality in postmenopausal women."
"1308","JAMA.605","0.005",20978259,2010,"Patients with metastatic colorectal cancer who have KRAS codon 12- or KRAS codon 13-mutated tumors are presently excluded from treatment with the anti-epidermal growth factor receptor monoclonal antibody cetuximab.To test the hypothesis that KRAS codon 13 mutations are associated with a better outcome after treatment with cetuximab than observed with other KRAS mutations.We studied the association between KRAS mutation status (p.G13D vs other KRAS mutations) and response and survival in a pooled data set of 579 patients with chemotherapy-refractory colorectal cancer treated with cetuximab between 2001 and 2008. Patients were included in the CO.17, BOND, MABEL, EMR202600, EVEREST, BABEL, or SALVAGE clinical trials or received off-study treatment. Univariate and multivariate analyses, adjusting for possible prognostic factors and data set, were performed. The effect of the different mutations was studied in vitro by constructing isogenic cell lines with wild-type KRAS, p.G12V, or p.G13D mutant alleles and treating them with cetuximab.The main efficacy end point was overall survival. Secondary efficacy end points were response rate and progression-free survival.In comparison with patients with other KRAS-mutated tumors, patients with p.G13D-mutated tumors (n = 32) treated with cetuximab had longer overall survival (median, 7.6 [95% confidence interval {CI}, 5.7-20.5] months vs 5.7 [95% CI, 4.9-6.8] months; adjusted hazard ratio [HR], 0.50; 95% CI, 0.31-0.81; P = .005) and longer progression-free survival (median, 4.0 [95% CI, 1.9-6.2] months vs 1.9 [95% CI, 1.8-2.8] months; adjusted HR, 0.51; 95% CI, 0.32-0.81; P = .004). There was a significant interaction between KRAS mutation status (p.G13D vs other KRAS mutations) and overall survival benefit with cetuximab treatment (adjusted HR, 0.30; 95% CI, 0.14-0.67; P = .003). In vitro and mouse model analysis showed that although p.G12V-mutated colorectal cells were insensitive to cetuximab, p.G13D-mutated cells were sensitive, as were KRAS wild-type cells.In this analysis, use of cetuximab was associated with longer overall and progression-free survival among patients with chemotherapy-refractory colorectal cancer with p.G13D-mutated tumors than with other KRAS-mutated tumors. Evaluation of cetuximab therapy in these tumors in prospective randomized trials may be warranted.","Association of KRAS p.G13D mutation with outcome in patients with chemotherapy-refractory metastatic colorectal cancer treated with cetuximab."
"1309","JAMA.606","0.004",20978259,2010,"Patients with metastatic colorectal cancer who have KRAS codon 12- or KRAS codon 13-mutated tumors are presently excluded from treatment with the anti-epidermal growth factor receptor monoclonal antibody cetuximab.To test the hypothesis that KRAS codon 13 mutations are associated with a better outcome after treatment with cetuximab than observed with other KRAS mutations.We studied the association between KRAS mutation status (p.G13D vs other KRAS mutations) and response and survival in a pooled data set of 579 patients with chemotherapy-refractory colorectal cancer treated with cetuximab between 2001 and 2008. Patients were included in the CO.17, BOND, MABEL, EMR202600, EVEREST, BABEL, or SALVAGE clinical trials or received off-study treatment. Univariate and multivariate analyses, adjusting for possible prognostic factors and data set, were performed. The effect of the different mutations was studied in vitro by constructing isogenic cell lines with wild-type KRAS, p.G12V, or p.G13D mutant alleles and treating them with cetuximab.The main efficacy end point was overall survival. Secondary efficacy end points were response rate and progression-free survival.In comparison with patients with other KRAS-mutated tumors, patients with p.G13D-mutated tumors (n = 32) treated with cetuximab had longer overall survival (median, 7.6 [95% confidence interval {CI}, 5.7-20.5] months vs 5.7 [95% CI, 4.9-6.8] months; adjusted hazard ratio [HR], 0.50; 95% CI, 0.31-0.81; P = .005) and longer progression-free survival (median, 4.0 [95% CI, 1.9-6.2] months vs 1.9 [95% CI, 1.8-2.8] months; adjusted HR, 0.51; 95% CI, 0.32-0.81; P = .004). There was a significant interaction between KRAS mutation status (p.G13D vs other KRAS mutations) and overall survival benefit with cetuximab treatment (adjusted HR, 0.30; 95% CI, 0.14-0.67; P = .003). In vitro and mouse model analysis showed that although p.G12V-mutated colorectal cells were insensitive to cetuximab, p.G13D-mutated cells were sensitive, as were KRAS wild-type cells.In this analysis, use of cetuximab was associated with longer overall and progression-free survival among patients with chemotherapy-refractory colorectal cancer with p.G13D-mutated tumors than with other KRAS-mutated tumors. Evaluation of cetuximab therapy in these tumors in prospective randomized trials may be warranted.","Association of KRAS p.G13D mutation with outcome in patients with chemotherapy-refractory metastatic colorectal cancer treated with cetuximab."
"1310","JAMA.607","0.003",20978259,2010,"Patients with metastatic colorectal cancer who have KRAS codon 12- or KRAS codon 13-mutated tumors are presently excluded from treatment with the anti-epidermal growth factor receptor monoclonal antibody cetuximab.To test the hypothesis that KRAS codon 13 mutations are associated with a better outcome after treatment with cetuximab than observed with other KRAS mutations.We studied the association between KRAS mutation status (p.G13D vs other KRAS mutations) and response and survival in a pooled data set of 579 patients with chemotherapy-refractory colorectal cancer treated with cetuximab between 2001 and 2008. Patients were included in the CO.17, BOND, MABEL, EMR202600, EVEREST, BABEL, or SALVAGE clinical trials or received off-study treatment. Univariate and multivariate analyses, adjusting for possible prognostic factors and data set, were performed. The effect of the different mutations was studied in vitro by constructing isogenic cell lines with wild-type KRAS, p.G12V, or p.G13D mutant alleles and treating them with cetuximab.The main efficacy end point was overall survival. Secondary efficacy end points were response rate and progression-free survival.In comparison with patients with other KRAS-mutated tumors, patients with p.G13D-mutated tumors (n = 32) treated with cetuximab had longer overall survival (median, 7.6 [95% confidence interval {CI}, 5.7-20.5] months vs 5.7 [95% CI, 4.9-6.8] months; adjusted hazard ratio [HR], 0.50; 95% CI, 0.31-0.81; P = .005) and longer progression-free survival (median, 4.0 [95% CI, 1.9-6.2] months vs 1.9 [95% CI, 1.8-2.8] months; adjusted HR, 0.51; 95% CI, 0.32-0.81; P = .004). There was a significant interaction between KRAS mutation status (p.G13D vs other KRAS mutations) and overall survival benefit with cetuximab treatment (adjusted HR, 0.30; 95% CI, 0.14-0.67; P = .003). In vitro and mouse model analysis showed that although p.G12V-mutated colorectal cells were insensitive to cetuximab, p.G13D-mutated cells were sensitive, as were KRAS wild-type cells.In this analysis, use of cetuximab was associated with longer overall and progression-free survival among patients with chemotherapy-refractory colorectal cancer with p.G13D-mutated tumors than with other KRAS-mutated tumors. Evaluation of cetuximab therapy in these tumors in prospective randomized trials may be warranted.","Association of KRAS p.G13D mutation with outcome in patients with chemotherapy-refractory metastatic colorectal cancer treated with cetuximab."
"1311","JAMA.5661","1.00E-04",20978260,2010,"Clopidogrel, one of the most commonly prescribed medications, is a prodrug requiring CYP450 biotransformation. Data suggest its pharmacologic effect varies based on CYP2C19 genotype, but there is uncertainty regarding the clinical risk imparted by specific genotypes.To define the risk of major adverse cardiovascular outcomes among carriers of 1 (___ 26% prevalence in whites) and carriers of 2 (___ 2% prevalence in whites) reduced-function CYP2C19 genetic variants in patients treated with clopidogrel. Data Sources andA literature search was conducted (January 2000-August 2010) in MEDLINE, Cochrane Database of Systematic Reviews, and EMBASE. Genetic studies were included in which clopidogrel was initiated in predominantly invasively managed patients in a manner consistent with the current guideline recommendations and in which clinical outcomes were ascertained.Investigators from 9 studies evaluating CYP2C19 genotype and clinical outcomes in patients treated with clopidogrel contributed the relevant hazard ratios (HRs) and 95% confidence intervals (CIs) for specific cardiovascular outcomes by genotype.Among 9685 patients (91.3% who underwent percutaneous coronary intervention and 54.5% who had an acute coronary syndrome), 863 experienced the composite end point of cardiovascular death, myocardial infarction, or stroke; and 84 patients had stent thrombosis among the 5894 evaluated for such. Overall, 71.5% were noncarriers, 26.3% had 1 reduced-function CYP2C19 allele, and 2.2% had 2 reduced-function CYP2C19 alleles. A significantly increased risk of the composite end point was evident in both carriers of 1 (HR, 1.55; 95% CI, 1.11-2.17; P = .01) and 2 (HR, 1.76; 95% CI, 1.24-2.50; P = .002) reduced-function CYP2C19 alleles, as compared with noncarriers. Similarly, there was a significantly increased risk of stent thrombosis in both carriers of 1 (HR, 2.67; 95% CI, 1.69-4.22; P < .0001) and 2 (HR, 3.97; 95% CI, 1.75-9.02; P = .001) CYP2C19 reduced-function alleles, as compared with noncarriers.Among patients treated with clopidogrel for percutaneous coronary intervention, carriage of even 1 reduced-function CYP2C19 allele appears to be associated with a significantly increased risk of major adverse cardiovascular events, particularly stent thrombosis.","Reduced-function CYP2C19 genotype and risk of adverse clinical outcomes among patients treated with clopidogrel predominantly for PCI: a meta-analysis."
"1312","JAMA.602","0.01",20978260,2010,"Clopidogrel, one of the most commonly prescribed medications, is a prodrug requiring CYP450 biotransformation. Data suggest its pharmacologic effect varies based on CYP2C19 genotype, but there is uncertainty regarding the clinical risk imparted by specific genotypes.To define the risk of major adverse cardiovascular outcomes among carriers of 1 (___ 26% prevalence in whites) and carriers of 2 (___ 2% prevalence in whites) reduced-function CYP2C19 genetic variants in patients treated with clopidogrel. Data Sources andA literature search was conducted (January 2000-August 2010) in MEDLINE, Cochrane Database of Systematic Reviews, and EMBASE. Genetic studies were included in which clopidogrel was initiated in predominantly invasively managed patients in a manner consistent with the current guideline recommendations and in which clinical outcomes were ascertained.Investigators from 9 studies evaluating CYP2C19 genotype and clinical outcomes in patients treated with clopidogrel contributed the relevant hazard ratios (HRs) and 95% confidence intervals (CIs) for specific cardiovascular outcomes by genotype.Among 9685 patients (91.3% who underwent percutaneous coronary intervention and 54.5% who had an acute coronary syndrome), 863 experienced the composite end point of cardiovascular death, myocardial infarction, or stroke; and 84 patients had stent thrombosis among the 5894 evaluated for such. Overall, 71.5% were noncarriers, 26.3% had 1 reduced-function CYP2C19 allele, and 2.2% had 2 reduced-function CYP2C19 alleles. A significantly increased risk of the composite end point was evident in both carriers of 1 (HR, 1.55; 95% CI, 1.11-2.17; P = .01) and 2 (HR, 1.76; 95% CI, 1.24-2.50; P = .002) reduced-function CYP2C19 alleles, as compared with noncarriers. Similarly, there was a significantly increased risk of stent thrombosis in both carriers of 1 (HR, 2.67; 95% CI, 1.69-4.22; P < .0001) and 2 (HR, 3.97; 95% CI, 1.75-9.02; P = .001) CYP2C19 reduced-function alleles, as compared with noncarriers.Among patients treated with clopidogrel for percutaneous coronary intervention, carriage of even 1 reduced-function CYP2C19 allele appears to be associated with a significantly increased risk of major adverse cardiovascular events, particularly stent thrombosis.","Reduced-function CYP2C19 genotype and risk of adverse clinical outcomes among patients treated with clopidogrel predominantly for PCI: a meta-analysis."
"1313","JAMA.603","0.002",20978260,2010,"Clopidogrel, one of the most commonly prescribed medications, is a prodrug requiring CYP450 biotransformation. Data suggest its pharmacologic effect varies based on CYP2C19 genotype, but there is uncertainty regarding the clinical risk imparted by specific genotypes.To define the risk of major adverse cardiovascular outcomes among carriers of 1 (___ 26% prevalence in whites) and carriers of 2 (___ 2% prevalence in whites) reduced-function CYP2C19 genetic variants in patients treated with clopidogrel. Data Sources andA literature search was conducted (January 2000-August 2010) in MEDLINE, Cochrane Database of Systematic Reviews, and EMBASE. Genetic studies were included in which clopidogrel was initiated in predominantly invasively managed patients in a manner consistent with the current guideline recommendations and in which clinical outcomes were ascertained.Investigators from 9 studies evaluating CYP2C19 genotype and clinical outcomes in patients treated with clopidogrel contributed the relevant hazard ratios (HRs) and 95% confidence intervals (CIs) for specific cardiovascular outcomes by genotype.Among 9685 patients (91.3% who underwent percutaneous coronary intervention and 54.5% who had an acute coronary syndrome), 863 experienced the composite end point of cardiovascular death, myocardial infarction, or stroke; and 84 patients had stent thrombosis among the 5894 evaluated for such. Overall, 71.5% were noncarriers, 26.3% had 1 reduced-function CYP2C19 allele, and 2.2% had 2 reduced-function CYP2C19 alleles. A significantly increased risk of the composite end point was evident in both carriers of 1 (HR, 1.55; 95% CI, 1.11-2.17; P = .01) and 2 (HR, 1.76; 95% CI, 1.24-2.50; P = .002) reduced-function CYP2C19 alleles, as compared with noncarriers. Similarly, there was a significantly increased risk of stent thrombosis in both carriers of 1 (HR, 2.67; 95% CI, 1.69-4.22; P < .0001) and 2 (HR, 3.97; 95% CI, 1.75-9.02; P = .001) CYP2C19 reduced-function alleles, as compared with noncarriers.Among patients treated with clopidogrel for percutaneous coronary intervention, carriage of even 1 reduced-function CYP2C19 allele appears to be associated with a significantly increased risk of major adverse cardiovascular events, particularly stent thrombosis.","Reduced-function CYP2C19 genotype and risk of adverse clinical outcomes among patients treated with clopidogrel predominantly for PCI: a meta-analysis."
"1314","JAMA.604","0.001",20978260,2010,"Clopidogrel, one of the most commonly prescribed medications, is a prodrug requiring CYP450 biotransformation. Data suggest its pharmacologic effect varies based on CYP2C19 genotype, but there is uncertainty regarding the clinical risk imparted by specific genotypes.To define the risk of major adverse cardiovascular outcomes among carriers of 1 (___ 26% prevalence in whites) and carriers of 2 (___ 2% prevalence in whites) reduced-function CYP2C19 genetic variants in patients treated with clopidogrel. Data Sources andA literature search was conducted (January 2000-August 2010) in MEDLINE, Cochrane Database of Systematic Reviews, and EMBASE. Genetic studies were included in which clopidogrel was initiated in predominantly invasively managed patients in a manner consistent with the current guideline recommendations and in which clinical outcomes were ascertained.Investigators from 9 studies evaluating CYP2C19 genotype and clinical outcomes in patients treated with clopidogrel contributed the relevant hazard ratios (HRs) and 95% confidence intervals (CIs) for specific cardiovascular outcomes by genotype.Among 9685 patients (91.3% who underwent percutaneous coronary intervention and 54.5% who had an acute coronary syndrome), 863 experienced the composite end point of cardiovascular death, myocardial infarction, or stroke; and 84 patients had stent thrombosis among the 5894 evaluated for such. Overall, 71.5% were noncarriers, 26.3% had 1 reduced-function CYP2C19 allele, and 2.2% had 2 reduced-function CYP2C19 alleles. A significantly increased risk of the composite end point was evident in both carriers of 1 (HR, 1.55; 95% CI, 1.11-2.17; P = .01) and 2 (HR, 1.76; 95% CI, 1.24-2.50; P = .002) reduced-function CYP2C19 alleles, as compared with noncarriers. Similarly, there was a significantly increased risk of stent thrombosis in both carriers of 1 (HR, 2.67; 95% CI, 1.69-4.22; P < .0001) and 2 (HR, 3.97; 95% CI, 1.75-9.02; P = .001) CYP2C19 reduced-function alleles, as compared with noncarriers.Among patients treated with clopidogrel for percutaneous coronary intervention, carriage of even 1 reduced-function CYP2C19 allele appears to be associated with a significantly increased risk of major adverse cardiovascular events, particularly stent thrombosis.","Reduced-function CYP2C19 genotype and risk of adverse clinical outcomes among patients treated with clopidogrel predominantly for PCI: a meta-analysis."
"1315","JAMA.600","0.03",21060104,2010,"Current remission maintenance therapies for antineutrophil cytoplasmic antibody (ANCA)-associated vasculitis (AAV) are limited by partial efficacy and toxicity.To compare the effects of mycophenolate mofetil with azathioprine on the prevention of relapses in patients with AAV.Open-label randomized controlled trial, International Mycophenolate Mofetil Protocol to Reduce Outbreaks of Vasculitides (IMPROVE), to test the hypothesis that mycophenolate mofetil is more effective than azathioprine for preventing relapses in AAV. The trial was conducted at 42 centers in 11 European countries between April 2002 and January 2009 (42-month study). Eligible patients had newly diagnosed AAV (Wegener granulomatosis or microscopic polyangiitis) and were aged 18 to 75 years at diagnosis.Patients were randomly assigned to azathioprine (starting at 2 mg/kg/d) or mycophenolate mofetil (starting at 2000 mg/d) after induction of remission with cyclophosphamide and prednisolone.The primary end point was relapse-free survival, which was assessed using a Cox proportional hazards model. The secondary end points were Vasculitis Damage Index, estimated glomerular filtration rate, and proteinuria.A total of 156 patients were assigned to azathioprine (n = 80) or mycophenolate mofetil (n = 76) and were followed up for a median of 39 months (interquartile range, 0.66-53.6 months). All patients were retained in the analysis by intention to treat. Relapses were more common in the mycophenolate mofetil group (42/76 patients) compared with the azathioprine group (30/80 patients), with an unadjusted hazard ratio (HR) for mycophenolate mofetil of 1.69 (95% confidence interval [CI], 1.06-2.70; P = .03). Severe adverse events did not differ significantly between groups. There were 22 severe adverse events in 13 patients (16%) in the azathioprine group and there were 8 severe adverse events in 8 patients (7.5%) in the mycophenolate mofetil group (HR, 0.53 [95% CI, 0.23-1.18]; P = .12). The secondary outcomes of Vasculitis Damage Index, estimated glomerular filtration rate, and proteinuria did not differ significantly between groups.Among patients with AAV, mycophenolate mofetil was less effective than azathioprine for maintaining disease remission. Both treatments had similar adverse event rates.clinicaltrials.gov Identifier: NCT00307645.","Mycophenolate mofetil vs azathioprine for remission maintenance in antineutrophil cytoplasmic antibody-associated vasculitis: a randomized controlled trial."
"1316","JAMA.601","0.12",21060104,2010,"Current remission maintenance therapies for antineutrophil cytoplasmic antibody (ANCA)-associated vasculitis (AAV) are limited by partial efficacy and toxicity.To compare the effects of mycophenolate mofetil with azathioprine on the prevention of relapses in patients with AAV.Open-label randomized controlled trial, International Mycophenolate Mofetil Protocol to Reduce Outbreaks of Vasculitides (IMPROVE), to test the hypothesis that mycophenolate mofetil is more effective than azathioprine for preventing relapses in AAV. The trial was conducted at 42 centers in 11 European countries between April 2002 and January 2009 (42-month study). Eligible patients had newly diagnosed AAV (Wegener granulomatosis or microscopic polyangiitis) and were aged 18 to 75 years at diagnosis.Patients were randomly assigned to azathioprine (starting at 2 mg/kg/d) or mycophenolate mofetil (starting at 2000 mg/d) after induction of remission with cyclophosphamide and prednisolone.The primary end point was relapse-free survival, which was assessed using a Cox proportional hazards model. The secondary end points were Vasculitis Damage Index, estimated glomerular filtration rate, and proteinuria.A total of 156 patients were assigned to azathioprine (n = 80) or mycophenolate mofetil (n = 76) and were followed up for a median of 39 months (interquartile range, 0.66-53.6 months). All patients were retained in the analysis by intention to treat. Relapses were more common in the mycophenolate mofetil group (42/76 patients) compared with the azathioprine group (30/80 patients), with an unadjusted hazard ratio (HR) for mycophenolate mofetil of 1.69 (95% confidence interval [CI], 1.06-2.70; P = .03). Severe adverse events did not differ significantly between groups. There were 22 severe adverse events in 13 patients (16%) in the azathioprine group and there were 8 severe adverse events in 8 patients (7.5%) in the mycophenolate mofetil group (HR, 0.53 [95% CI, 0.23-1.18]; P = .12). The secondary outcomes of Vasculitis Damage Index, estimated glomerular filtration rate, and proteinuria did not differ significantly between groups.Among patients with AAV, mycophenolate mofetil was less effective than azathioprine for maintaining disease remission. Both treatments had similar adverse event rates.clinicaltrials.gov Identifier: NCT00307645.","Mycophenolate mofetil vs azathioprine for remission maintenance in antineutrophil cytoplasmic antibody-associated vasculitis: a randomized controlled trial."
"1317","JAMA.597","0.26",21078810,2010,"Atrial fibrillation (AF) is common, yet there remains an unmet medical need for additional treatment options. Current pharmacological treatments have limited efficacy and significant adverse events. Limited data from small trials suggest omega-3 polyunsaturated fatty acids may provide a safe, effective treatment option for AF patients.To evaluate the safety and efficacy of prescription omega-3 fatty acids (prescription omega-3) for the prevention of recurrent symptomatic AF.Prospective, randomized, double-blind, placebo-controlled, parallel-group multicenter trial involving 663 US outpatient participants with confirmed symptomatic paroxysmal (n = 542) or persistent (n = 121) AF, with no substantial structural heart disease, and in normal sinus rhythm at baseline were recruited from November 2006 to July 2009 (final follow-up was January 2010).Prescription omega-3 (8 g/d) or placebo for the first 7 days; prescription omega-3 (4 g/d) or placebo thereafter through week 24.The primary end point was symptomatic recurrence of AF (first recurrence) in participants with paroxysmal AF. Secondary analyses included first recurrence in the persistent stratum and both strata combined. Participants were followed up for 6 months.At 24 weeks, in the paroxysmal AF stratum, 129 of 269 participants (48%) in the placebo group and 135 of 258 participants (52%) in the prescription group had a recurrent symptomatic AF or flutter event. In the persistent AF stratum, 18 participants (33%) in the placebo group and 32 (50%) in the prescription group had documented symptomatic AF or flutter events. There was no difference between treatment groups for recurrence of symptomatic AF in the paroxysmal stratum (hazard ratio [HR], 1.15; 95% confidence interval [CI], 0.90-1.46; P = .26), in the persistent stratum (HR, 1.64; 95% CI, 0.92-2.92; P = .09), and both strata combined (HR, 1.22; 95% CI, 0.98-1.52; P = .08). Other, secondary end points were supportive of the primary result. A total of 5% of those receiving placebo and 4% of those receiving prescription omega-3 discontinued due to adverse events. Eicosapentaenoic and docosahexaenoic acid blood levels were significantly higher in the prescription group than in the placebo group at weeks 4 and 24.Among participants with paroxysmal AF, 24-week treatment with prescription omega-3 compared with placebo did not reduce recurrent AF over 6 months.clinicaltrials.gov Identifier: NCT00402363.","Efficacy and safety of prescription omega-3 fatty acids for the prevention of recurrent symptomatic atrial fibrillation: a randomized controlled trial."
"1318","JAMA.598","0.09",21078810,2010,"Atrial fibrillation (AF) is common, yet there remains an unmet medical need for additional treatment options. Current pharmacological treatments have limited efficacy and significant adverse events. Limited data from small trials suggest omega-3 polyunsaturated fatty acids may provide a safe, effective treatment option for AF patients.To evaluate the safety and efficacy of prescription omega-3 fatty acids (prescription omega-3) for the prevention of recurrent symptomatic AF.Prospective, randomized, double-blind, placebo-controlled, parallel-group multicenter trial involving 663 US outpatient participants with confirmed symptomatic paroxysmal (n = 542) or persistent (n = 121) AF, with no substantial structural heart disease, and in normal sinus rhythm at baseline were recruited from November 2006 to July 2009 (final follow-up was January 2010).Prescription omega-3 (8 g/d) or placebo for the first 7 days; prescription omega-3 (4 g/d) or placebo thereafter through week 24.The primary end point was symptomatic recurrence of AF (first recurrence) in participants with paroxysmal AF. Secondary analyses included first recurrence in the persistent stratum and both strata combined. Participants were followed up for 6 months.At 24 weeks, in the paroxysmal AF stratum, 129 of 269 participants (48%) in the placebo group and 135 of 258 participants (52%) in the prescription group had a recurrent symptomatic AF or flutter event. In the persistent AF stratum, 18 participants (33%) in the placebo group and 32 (50%) in the prescription group had documented symptomatic AF or flutter events. There was no difference between treatment groups for recurrence of symptomatic AF in the paroxysmal stratum (hazard ratio [HR], 1.15; 95% confidence interval [CI], 0.90-1.46; P = .26), in the persistent stratum (HR, 1.64; 95% CI, 0.92-2.92; P = .09), and both strata combined (HR, 1.22; 95% CI, 0.98-1.52; P = .08). Other, secondary end points were supportive of the primary result. A total of 5% of those receiving placebo and 4% of those receiving prescription omega-3 discontinued due to adverse events. Eicosapentaenoic and docosahexaenoic acid blood levels were significantly higher in the prescription group than in the placebo group at weeks 4 and 24.Among participants with paroxysmal AF, 24-week treatment with prescription omega-3 compared with placebo did not reduce recurrent AF over 6 months.clinicaltrials.gov Identifier: NCT00402363.","Efficacy and safety of prescription omega-3 fatty acids for the prevention of recurrent symptomatic atrial fibrillation: a randomized controlled trial."
"1319","JAMA.599","0.08",21078810,2010,"Atrial fibrillation (AF) is common, yet there remains an unmet medical need for additional treatment options. Current pharmacological treatments have limited efficacy and significant adverse events. Limited data from small trials suggest omega-3 polyunsaturated fatty acids may provide a safe, effective treatment option for AF patients.To evaluate the safety and efficacy of prescription omega-3 fatty acids (prescription omega-3) for the prevention of recurrent symptomatic AF.Prospective, randomized, double-blind, placebo-controlled, parallel-group multicenter trial involving 663 US outpatient participants with confirmed symptomatic paroxysmal (n = 542) or persistent (n = 121) AF, with no substantial structural heart disease, and in normal sinus rhythm at baseline were recruited from November 2006 to July 2009 (final follow-up was January 2010).Prescription omega-3 (8 g/d) or placebo for the first 7 days; prescription omega-3 (4 g/d) or placebo thereafter through week 24.The primary end point was symptomatic recurrence of AF (first recurrence) in participants with paroxysmal AF. Secondary analyses included first recurrence in the persistent stratum and both strata combined. Participants were followed up for 6 months.At 24 weeks, in the paroxysmal AF stratum, 129 of 269 participants (48%) in the placebo group and 135 of 258 participants (52%) in the prescription group had a recurrent symptomatic AF or flutter event. In the persistent AF stratum, 18 participants (33%) in the placebo group and 32 (50%) in the prescription group had documented symptomatic AF or flutter events. There was no difference between treatment groups for recurrence of symptomatic AF in the paroxysmal stratum (hazard ratio [HR], 1.15; 95% confidence interval [CI], 0.90-1.46; P = .26), in the persistent stratum (HR, 1.64; 95% CI, 0.92-2.92; P = .09), and both strata combined (HR, 1.22; 95% CI, 0.98-1.52; P = .08). Other, secondary end points were supportive of the primary result. A total of 5% of those receiving placebo and 4% of those receiving prescription omega-3 discontinued due to adverse events. Eicosapentaenoic and docosahexaenoic acid blood levels were significantly higher in the prescription group than in the placebo group at weeks 4 and 24.Among participants with paroxysmal AF, 24-week treatment with prescription omega-3 compared with placebo did not reduce recurrent AF over 6 months.clinicaltrials.gov Identifier: NCT00402363.","Efficacy and safety of prescription omega-3 fatty acids for the prevention of recurrent symptomatic atrial fibrillation: a randomized controlled trial."
"1320","BMJ.22","0.016",21106618,2010,"To evaluate the effectiveness of integrated motivational interviewing and cognitive behavioural therapy in addition to standard care for patients with psychosis and a comorbid substance use problem.Two centre, open, rater blind randomised controlled trial.Secondary care in the United Kingdom.327 patients with a clinical diagnosis of schizophrenia, schizophreniform disorder, or schizoaffective disorder and a diagnosis of dependence on or misuse of drugs, alcohol, or both according to the Diagnostic and Statistical Manual of Mental Disorders, fourth edition.The intervention was integrated motivational interviewing and cognitive behavioural therapy plus standard care, which was compared with standard care alone. Phase one of therapy-""motivation building""-concerns engaging the patient, then exploring and resolving ambivalence for change in substance use. Phase two-""action""-supports and facilitates change using cognitive behavioural approaches. Up to 26 therapy sessions were delivered over one year.The primary outcome was death from any cause or admission to hospital in the 12 months after completion of therapy. Secondary outcomes were frequency and amount of substance use (assessed using the timeline followback method), readiness to change, perceived negative consequences of use, psychotic symptom ratings, number and duration of relapses, and global assessment of functioning and deliberate self harm at 12 and 24 months, with additional timeline followback assessments at 6 and 18 months. Analysis was by intention to treat and robust treatment effect estimates were produced.327 participants were randomly allocated to either the intervention (n=164) or treatment as usual (n=163). At 24 months, 326 (99.7%) were assessed on the primary outcome and 246 (75.2%) on the main secondary outcomes. Treatment had no beneficial effect on hospital admissions or death during follow-up, with 23.3% (38/163) of the therapy group and 20.2% (33/163) of controls deceased or admitted (adjusted odds ratio 1.16, 95% confidence interval 0.68 to 1.99; P=0.579). Therapy had no effect on the frequency of substance use or the perceived negative consequences of misuse, but did have a statistically significant effect on amount used per substance using day (adjusted ORs for main substance 1.50, 95% CI 1.08 to 2.09; P=0.016; and all substances 1.48, 95% CI 1.07 to 2.05; P=0.017). Treatment had a statistically significant effect on readiness to change use at 12 months (adjusted OR 2.05, 95% CI 1.26 to 3.31; P=0.004) that was not maintained at 24 months (0.78, 95% CI 0.48 to 1.28; P=0.320). There were no effects of treatment on clinical outcomes such as relapses, psychotic symptoms, functioning, and self harm.Integrated motivational interviewing and cognitive behavioural therapy for people with psychosis and substance misuse do not improve outcome in terms of hospitalisation, symptom outcomes, or functioning. This approach does reduce the amount of substance used for at least one year after completion of therapy.Current Controlled Trials: ISRCTN14404480.","Integrated motivational interviewing and cognitive behavioural therapy for people with psychosis and comorbid substance misuse: randomised controlled trial."
"1321","BMJ.23","0.017",21106618,2010,"To evaluate the effectiveness of integrated motivational interviewing and cognitive behavioural therapy in addition to standard care for patients with psychosis and a comorbid substance use problem.Two centre, open, rater blind randomised controlled trial.Secondary care in the United Kingdom.327 patients with a clinical diagnosis of schizophrenia, schizophreniform disorder, or schizoaffective disorder and a diagnosis of dependence on or misuse of drugs, alcohol, or both according to the Diagnostic and Statistical Manual of Mental Disorders, fourth edition.The intervention was integrated motivational interviewing and cognitive behavioural therapy plus standard care, which was compared with standard care alone. Phase one of therapy-""motivation building""-concerns engaging the patient, then exploring and resolving ambivalence for change in substance use. Phase two-""action""-supports and facilitates change using cognitive behavioural approaches. Up to 26 therapy sessions were delivered over one year.The primary outcome was death from any cause or admission to hospital in the 12 months after completion of therapy. Secondary outcomes were frequency and amount of substance use (assessed using the timeline followback method), readiness to change, perceived negative consequences of use, psychotic symptom ratings, number and duration of relapses, and global assessment of functioning and deliberate self harm at 12 and 24 months, with additional timeline followback assessments at 6 and 18 months. Analysis was by intention to treat and robust treatment effect estimates were produced.327 participants were randomly allocated to either the intervention (n=164) or treatment as usual (n=163). At 24 months, 326 (99.7%) were assessed on the primary outcome and 246 (75.2%) on the main secondary outcomes. Treatment had no beneficial effect on hospital admissions or death during follow-up, with 23.3% (38/163) of the therapy group and 20.2% (33/163) of controls deceased or admitted (adjusted odds ratio 1.16, 95% confidence interval 0.68 to 1.99; P=0.579). Therapy had no effect on the frequency of substance use or the perceived negative consequences of misuse, but did have a statistically significant effect on amount used per substance using day (adjusted ORs for main substance 1.50, 95% CI 1.08 to 2.09; P=0.016; and all substances 1.48, 95% CI 1.07 to 2.05; P=0.017). Treatment had a statistically significant effect on readiness to change use at 12 months (adjusted OR 2.05, 95% CI 1.26 to 3.31; P=0.004) that was not maintained at 24 months (0.78, 95% CI 0.48 to 1.28; P=0.320). There were no effects of treatment on clinical outcomes such as relapses, psychotic symptoms, functioning, and self harm.Integrated motivational interviewing and cognitive behavioural therapy for people with psychosis and substance misuse do not improve outcome in terms of hospitalisation, symptom outcomes, or functioning. This approach does reduce the amount of substance used for at least one year after completion of therapy.Current Controlled Trials: ISRCTN14404480.","Integrated motivational interviewing and cognitive behavioural therapy for people with psychosis and comorbid substance misuse: randomised controlled trial."
"1322","BMJ.24","0.004",21106618,2010,"To evaluate the effectiveness of integrated motivational interviewing and cognitive behavioural therapy in addition to standard care for patients with psychosis and a comorbid substance use problem.Two centre, open, rater blind randomised controlled trial.Secondary care in the United Kingdom.327 patients with a clinical diagnosis of schizophrenia, schizophreniform disorder, or schizoaffective disorder and a diagnosis of dependence on or misuse of drugs, alcohol, or both according to the Diagnostic and Statistical Manual of Mental Disorders, fourth edition.The intervention was integrated motivational interviewing and cognitive behavioural therapy plus standard care, which was compared with standard care alone. Phase one of therapy-""motivation building""-concerns engaging the patient, then exploring and resolving ambivalence for change in substance use. Phase two-""action""-supports and facilitates change using cognitive behavioural approaches. Up to 26 therapy sessions were delivered over one year.The primary outcome was death from any cause or admission to hospital in the 12 months after completion of therapy. Secondary outcomes were frequency and amount of substance use (assessed using the timeline followback method), readiness to change, perceived negative consequences of use, psychotic symptom ratings, number and duration of relapses, and global assessment of functioning and deliberate self harm at 12 and 24 months, with additional timeline followback assessments at 6 and 18 months. Analysis was by intention to treat and robust treatment effect estimates were produced.327 participants were randomly allocated to either the intervention (n=164) or treatment as usual (n=163). At 24 months, 326 (99.7%) were assessed on the primary outcome and 246 (75.2%) on the main secondary outcomes. Treatment had no beneficial effect on hospital admissions or death during follow-up, with 23.3% (38/163) of the therapy group and 20.2% (33/163) of controls deceased or admitted (adjusted odds ratio 1.16, 95% confidence interval 0.68 to 1.99; P=0.579). Therapy had no effect on the frequency of substance use or the perceived negative consequences of misuse, but did have a statistically significant effect on amount used per substance using day (adjusted ORs for main substance 1.50, 95% CI 1.08 to 2.09; P=0.016; and all substances 1.48, 95% CI 1.07 to 2.05; P=0.017). Treatment had a statistically significant effect on readiness to change use at 12 months (adjusted OR 2.05, 95% CI 1.26 to 3.31; P=0.004) that was not maintained at 24 months (0.78, 95% CI 0.48 to 1.28; P=0.320). There were no effects of treatment on clinical outcomes such as relapses, psychotic symptoms, functioning, and self harm.Integrated motivational interviewing and cognitive behavioural therapy for people with psychosis and substance misuse do not improve outcome in terms of hospitalisation, symptom outcomes, or functioning. This approach does reduce the amount of substance used for at least one year after completion of therapy.Current Controlled Trials: ISRCTN14404480.","Integrated motivational interviewing and cognitive behavioural therapy for people with psychosis and comorbid substance misuse: randomised controlled trial."
"1323","BMJ.25","0.32",21106618,2010,"To evaluate the effectiveness of integrated motivational interviewing and cognitive behavioural therapy in addition to standard care for patients with psychosis and a comorbid substance use problem.Two centre, open, rater blind randomised controlled trial.Secondary care in the United Kingdom.327 patients with a clinical diagnosis of schizophrenia, schizophreniform disorder, or schizoaffective disorder and a diagnosis of dependence on or misuse of drugs, alcohol, or both according to the Diagnostic and Statistical Manual of Mental Disorders, fourth edition.The intervention was integrated motivational interviewing and cognitive behavioural therapy plus standard care, which was compared with standard care alone. Phase one of therapy-""motivation building""-concerns engaging the patient, then exploring and resolving ambivalence for change in substance use. Phase two-""action""-supports and facilitates change using cognitive behavioural approaches. Up to 26 therapy sessions were delivered over one year.The primary outcome was death from any cause or admission to hospital in the 12 months after completion of therapy. Secondary outcomes were frequency and amount of substance use (assessed using the timeline followback method), readiness to change, perceived negative consequences of use, psychotic symptom ratings, number and duration of relapses, and global assessment of functioning and deliberate self harm at 12 and 24 months, with additional timeline followback assessments at 6 and 18 months. Analysis was by intention to treat and robust treatment effect estimates were produced.327 participants were randomly allocated to either the intervention (n=164) or treatment as usual (n=163). At 24 months, 326 (99.7%) were assessed on the primary outcome and 246 (75.2%) on the main secondary outcomes. Treatment had no beneficial effect on hospital admissions or death during follow-up, with 23.3% (38/163) of the therapy group and 20.2% (33/163) of controls deceased or admitted (adjusted odds ratio 1.16, 95% confidence interval 0.68 to 1.99; P=0.579). Therapy had no effect on the frequency of substance use or the perceived negative consequences of misuse, but did have a statistically significant effect on amount used per substance using day (adjusted ORs for main substance 1.50, 95% CI 1.08 to 2.09; P=0.016; and all substances 1.48, 95% CI 1.07 to 2.05; P=0.017). Treatment had a statistically significant effect on readiness to change use at 12 months (adjusted OR 2.05, 95% CI 1.26 to 3.31; P=0.004) that was not maintained at 24 months (0.78, 95% CI 0.48 to 1.28; P=0.320). There were no effects of treatment on clinical outcomes such as relapses, psychotic symptoms, functioning, and self harm.Integrated motivational interviewing and cognitive behavioural therapy for people with psychosis and substance misuse do not improve outcome in terms of hospitalisation, symptom outcomes, or functioning. This approach does reduce the amount of substance used for at least one year after completion of therapy.Current Controlled Trials: ISRCTN14404480.","Integrated motivational interviewing and cognitive behavioural therapy for people with psychosis and comorbid substance misuse: randomised controlled trial."
"1324","JAMA.5651","0.001",21177505,2010,"In many cancers, specific subpopulations of cells appear to be uniquely capable of initiating and maintaining tumors. The strongest support for this cancer stem cell model comes from transplantation assays in immunodeficient mice, which indicate that human acute myeloid leukemia (AML) is driven by self-renewing leukemic stem cells (LSCs). This model has significant implications for the development of novel therapies, but its clinical relevance has yet to be determined.To identify an LSC gene expression signature and test its association with clinical outcomes in AML.Retrospective study of global gene expression (microarray) profiles of LSC-enriched subpopulations from primary AML and normal patient samples, which were obtained at a US medical center between April 2005 and July 2007, and validation data sets of global transcriptional profiles of AML tumors from 4 independent cohorts (n = 1047).Identification of genes discriminating LSC-enriched populations from other subpopulations in AML tumors; and association of LSC-specific genes with overall, event-free, and relapse-free survival and with therapeutic response.Expression levels of 52 genes distinguished LSC-enriched populations from other subpopulations in cell-sorted AML samples. An LSC score summarizing expression of these genes in bulk primary AML tumor samples was associated with clinical outcomes in the 4 independent patient cohorts. High LSC scores were associated with worse overall, event-free, and relapse-free survival among patients with either normal karyotypes or chromosomal abnormalities. For the largest cohort of patients with normal karyotypes (n = 163), the LSC score was significantly associated with overall survival as a continuous variable (hazard ratio [HR], 1.15; 95% confidence interval [CI], 1.08-1.22; log-likelihood P <.001). The absolute risk of death by 3 years was 57% (95% CI, 43%-67%) for the low LSC score group compared with 78% (95% CI, 66%-86%) for the high LSC score group (HR, 1.9 [95% CI, 1.3-2.7]; log-rank P = .002). In another cohort with available data on event-free survival for 70 patients with normal karyotypes, the risk of an event by 3 years was 48% (95% CI, 27%-63%) in the low LSC score group vs 81% (95% CI, 60%-91%) in the high LSC score group (HR, 2.4 [95% CI, 1.3-4.5]; log-rank P = .006). In multivariate Cox regression including age, mutations in FLT3 and NPM1, and cytogenetic abnormalities, the HRs for LSC score in the 3 cohorts with data on all variables were 1.07 (95% CI, 1.01-1.13; P = .02), 1.10 (95% CI, 1.03-1.17; P = .005), and 1.17 (95% CI, 1.05-1.30; P = .005).High expression of an LSC gene signature is independently associated with adverse outcomes in patients with AML.","Association of a leukemic stem cell gene expression signature with clinical outcomes in acute myeloid leukemia."
"1325","JAMA.593","0.002",21177505,2010,"In many cancers, specific subpopulations of cells appear to be uniquely capable of initiating and maintaining tumors. The strongest support for this cancer stem cell model comes from transplantation assays in immunodeficient mice, which indicate that human acute myeloid leukemia (AML) is driven by self-renewing leukemic stem cells (LSCs). This model has significant implications for the development of novel therapies, but its clinical relevance has yet to be determined.To identify an LSC gene expression signature and test its association with clinical outcomes in AML.Retrospective study of global gene expression (microarray) profiles of LSC-enriched subpopulations from primary AML and normal patient samples, which were obtained at a US medical center between April 2005 and July 2007, and validation data sets of global transcriptional profiles of AML tumors from 4 independent cohorts (n = 1047).Identification of genes discriminating LSC-enriched populations from other subpopulations in AML tumors; and association of LSC-specific genes with overall, event-free, and relapse-free survival and with therapeutic response.Expression levels of 52 genes distinguished LSC-enriched populations from other subpopulations in cell-sorted AML samples. An LSC score summarizing expression of these genes in bulk primary AML tumor samples was associated with clinical outcomes in the 4 independent patient cohorts. High LSC scores were associated with worse overall, event-free, and relapse-free survival among patients with either normal karyotypes or chromosomal abnormalities. For the largest cohort of patients with normal karyotypes (n = 163), the LSC score was significantly associated with overall survival as a continuous variable (hazard ratio [HR], 1.15; 95% confidence interval [CI], 1.08-1.22; log-likelihood P <.001). The absolute risk of death by 3 years was 57% (95% CI, 43%-67%) for the low LSC score group compared with 78% (95% CI, 66%-86%) for the high LSC score group (HR, 1.9 [95% CI, 1.3-2.7]; log-rank P = .002). In another cohort with available data on event-free survival for 70 patients with normal karyotypes, the risk of an event by 3 years was 48% (95% CI, 27%-63%) in the low LSC score group vs 81% (95% CI, 60%-91%) in the high LSC score group (HR, 2.4 [95% CI, 1.3-4.5]; log-rank P = .006). In multivariate Cox regression including age, mutations in FLT3 and NPM1, and cytogenetic abnormalities, the HRs for LSC score in the 3 cohorts with data on all variables were 1.07 (95% CI, 1.01-1.13; P = .02), 1.10 (95% CI, 1.03-1.17; P = .005), and 1.17 (95% CI, 1.05-1.30; P = .005).High expression of an LSC gene signature is independently associated with adverse outcomes in patients with AML.","Association of a leukemic stem cell gene expression signature with clinical outcomes in acute myeloid leukemia."
"1326","JAMA.594","0.006",21177505,2010,"In many cancers, specific subpopulations of cells appear to be uniquely capable of initiating and maintaining tumors. The strongest support for this cancer stem cell model comes from transplantation assays in immunodeficient mice, which indicate that human acute myeloid leukemia (AML) is driven by self-renewing leukemic stem cells (LSCs). This model has significant implications for the development of novel therapies, but its clinical relevance has yet to be determined.To identify an LSC gene expression signature and test its association with clinical outcomes in AML.Retrospective study of global gene expression (microarray) profiles of LSC-enriched subpopulations from primary AML and normal patient samples, which were obtained at a US medical center between April 2005 and July 2007, and validation data sets of global transcriptional profiles of AML tumors from 4 independent cohorts (n = 1047).Identification of genes discriminating LSC-enriched populations from other subpopulations in AML tumors; and association of LSC-specific genes with overall, event-free, and relapse-free survival and with therapeutic response.Expression levels of 52 genes distinguished LSC-enriched populations from other subpopulations in cell-sorted AML samples. An LSC score summarizing expression of these genes in bulk primary AML tumor samples was associated with clinical outcomes in the 4 independent patient cohorts. High LSC scores were associated with worse overall, event-free, and relapse-free survival among patients with either normal karyotypes or chromosomal abnormalities. For the largest cohort of patients with normal karyotypes (n = 163), the LSC score was significantly associated with overall survival as a continuous variable (hazard ratio [HR], 1.15; 95% confidence interval [CI], 1.08-1.22; log-likelihood P <.001). The absolute risk of death by 3 years was 57% (95% CI, 43%-67%) for the low LSC score group compared with 78% (95% CI, 66%-86%) for the high LSC score group (HR, 1.9 [95% CI, 1.3-2.7]; log-rank P = .002). In another cohort with available data on event-free survival for 70 patients with normal karyotypes, the risk of an event by 3 years was 48% (95% CI, 27%-63%) in the low LSC score group vs 81% (95% CI, 60%-91%) in the high LSC score group (HR, 2.4 [95% CI, 1.3-4.5]; log-rank P = .006). In multivariate Cox regression including age, mutations in FLT3 and NPM1, and cytogenetic abnormalities, the HRs for LSC score in the 3 cohorts with data on all variables were 1.07 (95% CI, 1.01-1.13; P = .02), 1.10 (95% CI, 1.03-1.17; P = .005), and 1.17 (95% CI, 1.05-1.30; P = .005).High expression of an LSC gene signature is independently associated with adverse outcomes in patients with AML.","Association of a leukemic stem cell gene expression signature with clinical outcomes in acute myeloid leukemia."
"1327","JAMA.595","0.005",21177505,2010,"In many cancers, specific subpopulations of cells appear to be uniquely capable of initiating and maintaining tumors. The strongest support for this cancer stem cell model comes from transplantation assays in immunodeficient mice, which indicate that human acute myeloid leukemia (AML) is driven by self-renewing leukemic stem cells (LSCs). This model has significant implications for the development of novel therapies, but its clinical relevance has yet to be determined.To identify an LSC gene expression signature and test its association with clinical outcomes in AML.Retrospective study of global gene expression (microarray) profiles of LSC-enriched subpopulations from primary AML and normal patient samples, which were obtained at a US medical center between April 2005 and July 2007, and validation data sets of global transcriptional profiles of AML tumors from 4 independent cohorts (n = 1047).Identification of genes discriminating LSC-enriched populations from other subpopulations in AML tumors; and association of LSC-specific genes with overall, event-free, and relapse-free survival and with therapeutic response.Expression levels of 52 genes distinguished LSC-enriched populations from other subpopulations in cell-sorted AML samples. An LSC score summarizing expression of these genes in bulk primary AML tumor samples was associated with clinical outcomes in the 4 independent patient cohorts. High LSC scores were associated with worse overall, event-free, and relapse-free survival among patients with either normal karyotypes or chromosomal abnormalities. For the largest cohort of patients with normal karyotypes (n = 163), the LSC score was significantly associated with overall survival as a continuous variable (hazard ratio [HR], 1.15; 95% confidence interval [CI], 1.08-1.22; log-likelihood P <.001). The absolute risk of death by 3 years was 57% (95% CI, 43%-67%) for the low LSC score group compared with 78% (95% CI, 66%-86%) for the high LSC score group (HR, 1.9 [95% CI, 1.3-2.7]; log-rank P = .002). In another cohort with available data on event-free survival for 70 patients with normal karyotypes, the risk of an event by 3 years was 48% (95% CI, 27%-63%) in the low LSC score group vs 81% (95% CI, 60%-91%) in the high LSC score group (HR, 2.4 [95% CI, 1.3-4.5]; log-rank P = .006). In multivariate Cox regression including age, mutations in FLT3 and NPM1, and cytogenetic abnormalities, the HRs for LSC score in the 3 cohorts with data on all variables were 1.07 (95% CI, 1.01-1.13; P = .02), 1.10 (95% CI, 1.03-1.17; P = .005), and 1.17 (95% CI, 1.05-1.30; P = .005).High expression of an LSC gene signature is independently associated with adverse outcomes in patients with AML.","Association of a leukemic stem cell gene expression signature with clinical outcomes in acute myeloid leukemia."
"1328","JAMA.596","0.005",21177505,2010,"In many cancers, specific subpopulations of cells appear to be uniquely capable of initiating and maintaining tumors. The strongest support for this cancer stem cell model comes from transplantation assays in immunodeficient mice, which indicate that human acute myeloid leukemia (AML) is driven by self-renewing leukemic stem cells (LSCs). This model has significant implications for the development of novel therapies, but its clinical relevance has yet to be determined.To identify an LSC gene expression signature and test its association with clinical outcomes in AML.Retrospective study of global gene expression (microarray) profiles of LSC-enriched subpopulations from primary AML and normal patient samples, which were obtained at a US medical center between April 2005 and July 2007, and validation data sets of global transcriptional profiles of AML tumors from 4 independent cohorts (n = 1047).Identification of genes discriminating LSC-enriched populations from other subpopulations in AML tumors; and association of LSC-specific genes with overall, event-free, and relapse-free survival and with therapeutic response.Expression levels of 52 genes distinguished LSC-enriched populations from other subpopulations in cell-sorted AML samples. An LSC score summarizing expression of these genes in bulk primary AML tumor samples was associated with clinical outcomes in the 4 independent patient cohorts. High LSC scores were associated with worse overall, event-free, and relapse-free survival among patients with either normal karyotypes or chromosomal abnormalities. For the largest cohort of patients with normal karyotypes (n = 163), the LSC score was significantly associated with overall survival as a continuous variable (hazard ratio [HR], 1.15; 95% confidence interval [CI], 1.08-1.22; log-likelihood P <.001). The absolute risk of death by 3 years was 57% (95% CI, 43%-67%) for the low LSC score group compared with 78% (95% CI, 66%-86%) for the high LSC score group (HR, 1.9 [95% CI, 1.3-2.7]; log-rank P = .002). In another cohort with available data on event-free survival for 70 patients with normal karyotypes, the risk of an event by 3 years was 48% (95% CI, 27%-63%) in the low LSC score group vs 81% (95% CI, 60%-91%) in the high LSC score group (HR, 2.4 [95% CI, 1.3-4.5]; log-rank P = .006). In multivariate Cox regression including age, mutations in FLT3 and NPM1, and cytogenetic abnormalities, the HRs for LSC score in the 3 cohorts with data on all variables were 1.07 (95% CI, 1.01-1.13; P = .02), 1.10 (95% CI, 1.03-1.17; P = .005), and 1.17 (95% CI, 1.05-1.30; P = .005).High expression of an LSC gene signature is independently associated with adverse outcomes in patients with AML.","Association of a leukemic stem cell gene expression signature with clinical outcomes in acute myeloid leukemia."
"1329","JAMA.596","0.02",21177505,2010,"In many cancers, specific subpopulations of cells appear to be uniquely capable of initiating and maintaining tumors. The strongest support for this cancer stem cell model comes from transplantation assays in immunodeficient mice, which indicate that human acute myeloid leukemia (AML) is driven by self-renewing leukemic stem cells (LSCs). This model has significant implications for the development of novel therapies, but its clinical relevance has yet to be determined.To identify an LSC gene expression signature and test its association with clinical outcomes in AML.Retrospective study of global gene expression (microarray) profiles of LSC-enriched subpopulations from primary AML and normal patient samples, which were obtained at a US medical center between April 2005 and July 2007, and validation data sets of global transcriptional profiles of AML tumors from 4 independent cohorts (n = 1047).Identification of genes discriminating LSC-enriched populations from other subpopulations in AML tumors; and association of LSC-specific genes with overall, event-free, and relapse-free survival and with therapeutic response.Expression levels of 52 genes distinguished LSC-enriched populations from other subpopulations in cell-sorted AML samples. An LSC score summarizing expression of these genes in bulk primary AML tumor samples was associated with clinical outcomes in the 4 independent patient cohorts. High LSC scores were associated with worse overall, event-free, and relapse-free survival among patients with either normal karyotypes or chromosomal abnormalities. For the largest cohort of patients with normal karyotypes (n = 163), the LSC score was significantly associated with overall survival as a continuous variable (hazard ratio [HR], 1.15; 95% confidence interval [CI], 1.08-1.22; log-likelihood P <.001). The absolute risk of death by 3 years was 57% (95% CI, 43%-67%) for the low LSC score group compared with 78% (95% CI, 66%-86%) for the high LSC score group (HR, 1.9 [95% CI, 1.3-2.7]; log-rank P = .002). In another cohort with available data on event-free survival for 70 patients with normal karyotypes, the risk of an event by 3 years was 48% (95% CI, 27%-63%) in the low LSC score group vs 81% (95% CI, 60%-91%) in the high LSC score group (HR, 2.4 [95% CI, 1.3-4.5]; log-rank P = .006). In multivariate Cox regression including age, mutations in FLT3 and NPM1, and cytogenetic abnormalities, the HRs for LSC score in the 3 cohorts with data on all variables were 1.07 (95% CI, 1.01-1.13; P = .02), 1.10 (95% CI, 1.03-1.17; P = .005), and 1.17 (95% CI, 1.05-1.30; P = .005).High expression of an LSC gene signature is independently associated with adverse outcomes in patients with AML.","Association of a leukemic stem cell gene expression signature with clinical outcomes in acute myeloid leukemia."
